<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">29222</article-id><article-id pub-id-type="doi">10.7554/eLife.29222</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Magnetic eye tracking in mice</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-9877"><name><surname>Payne</surname><given-names>Hannah L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4625-5706</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-8696"><name><surname>Raymond</surname><given-names>Jennifer L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8145-747X</contrib-id><email>jenr@stanford.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><institution content-type="dept">Department of Neurobiology</institution><institution>Stanford University</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-11737"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>National Institutes of Health</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>05</day><month>09</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e29222</elocation-id><history><date date-type="received" iso-8601-date="2017-06-02"><day>02</day><month>06</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-08-11"><day>11</day><month>08</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Payne et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Payne et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-29222-v1.pdf"/><related-object ext-link-type="url" xlink:href="https://elifesciences.org/articles/e29222v1"><date date-type="v1" iso-8601-date="2017-09-05"><day>05</day><month>09</month><year>2017</year></date></related-object><abstract><object-id pub-id-type="doi">10.7554/eLife.29222.001</object-id><p>Eye movements provide insights about a wide range of brain functions, from sensorimotor integration to cognition; hence, the measurement of eye movements is an important tool in neuroscience research. We describe a method, based on magnetic sensing, for measuring eye movements in head-fixed and freely moving mice. A small magnet was surgically implanted on the eye, and changes in the magnet angle as the eye rotated were detected by a magnetic field sensor. Systematic testing demonstrated high resolution measurements of eye position of &lt;0.1°. Magnetic eye tracking offers several advantages over the well-established eye coil and video-oculography methods. Most notably, it provides the first method for reliable, high-resolution measurement of eye movements in freely moving mice, revealing increased eye movements and altered binocular coordination compared to head-fixed mice. Overall, magnetic eye tracking provides a lightweight, inexpensive, easily implemented, and high-resolution method suitable for a wide range of applications.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>eye movements</kwd><kwd>oculomotor mechanics</kwd><kwd>vestibulo-ocular reflex</kwd><kwd>binocular vision</kwd><kwd>spatial vision</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R21-EY026152</award-id><principal-award-recipient><name><surname>Payne</surname><given-names>Hannah L</given-names></name><name><surname>Raymond</surname><given-names>Jennifer L</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>Simons Foundation/SFARI</institution></institution-wrap></funding-source><award-id>543031</award-id><principal-award-recipient><name><surname>Raymond</surname><given-names>Jennifer L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>An accurate, robust, and lightweight technique for measuring eye movements in mice was developed using magnetic sensing, yielding the first high resolution recordings of eye movements in freely moving mice.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many behaviors, from navigation and predation to avoidance of danger and pursuit of mates, are guided by vision (<xref ref-type="bibr" rid="bib9">Chapillon, 1999</xref>; <xref ref-type="bibr" rid="bib13">Coen and Murthy, 2016</xref>; <xref ref-type="bibr" rid="bib56">Mather and Baker, 1980</xref>; <xref ref-type="bibr" rid="bib63">Olberg et al., 2000</xref>; <xref ref-type="bibr" rid="bib89">Yilmaz and Meister, 2013</xref>). Vision is actively controlled by eye movements, which localize and stabilize images on the retina. Therefore, eye movements are often measured in studies of visually guided behaviors, both for documentation and control of the visual inputs impinging on the retina, and as a behavioral output. The analysis of eye movements can provide a window on a variety of sensory, motor, and cognitive functions, such as attention, learning and memory, and decision-making (<xref ref-type="bibr" rid="bib20">Duhamel et al., 1992</xref>; <xref ref-type="bibr" rid="bib48">Kustov and Robinson, 1996</xref>; <xref ref-type="bibr" rid="bib65">Raposo et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Raymond and Lisberger, 1996</xref>). Moreover, abnormal eye movements are associated with numerous cognitive disorders, including autism, schizophrenia, Parkinson’s disease, and Huntington’s disease (<xref ref-type="bibr" rid="bib2">Avanzini et al., 1979</xref>; <xref ref-type="bibr" rid="bib17">DeJong and Jones, 1971</xref>; <xref ref-type="bibr" rid="bib29">Holzman et al., 1976</xref>; <xref ref-type="bibr" rid="bib72">Rosenhall et al., 1988</xref>). Thus, the measurement of eye movements can advance our understanding of the sophisticated neural processes underlying a wide range of functions in healthy and diseased brains.</p><p>Given their broad utility, measurements of eye movements have been routinely implemented in neuroscientific studies of primates. In contrast, such measurements are uncommon in mice, a species that is widely used in molecular and genetic studies of behavior (<xref ref-type="bibr" rid="bib4">Beery and Zucker, 2011</xref>). Although less dependent on vision than primates, mice encode visual input with high selectivity (<xref ref-type="bibr" rid="bib61">Niell and Stryker, 2008</xref>), and use vision for a variety of functions including navigation (<xref ref-type="bibr" rid="bib9">Chapillon, 1999</xref>; <xref ref-type="bibr" rid="bib11">Chen et al., 2013a</xref>; <xref ref-type="bibr" rid="bib30">Hopkins, 1953</xref>; <xref ref-type="bibr" rid="bib74">Saleem et al., 2013</xref>), avoidance of predators (<xref ref-type="bibr" rid="bib89">Yilmaz and Meister, 2013</xref>), and recognition of territorial boundaries (<xref ref-type="bibr" rid="bib54">Mackintosh, 1973</xref>). Eye movements can alter the visual experience during these behaviors, and thus provide key information about how these behaviors are controlled. However, measurement of eye movements in mice is technically challenging.</p><p>The main obstacle to measuring eye movements in mice is their diminutive size. In particular, the small eye restricts what can be implanted on the eye’s surface: average eye diameter is only 3.4 mm in mice (<xref ref-type="bibr" rid="bib69">Remtulla and Hallett, 1985</xref>), compared to 6.4 mm in rat (<xref ref-type="bibr" rid="bib10">Chaudhuri et al., 1983</xref>), 9.2 mm in chicken (<xref ref-type="bibr" rid="bib77">Schwarz et al., 2013</xref>), 18 mm in rabbit (<xref ref-type="bibr" rid="bib32">Hughes, 1972</xref>), and 21 mm in rhesus macaque (<xref ref-type="bibr" rid="bib76">Schultz, 1940</xref>). The small size of the head and body also impede measurement of eye movements, especially during free motion, by restricting what can be affixed to the skull and carried by the mouse. Whereas neuroscientific studies of awake, behaving primates are typically conducted in head-fixed animals, behavioral paradigms in mice often leverage locomotion (<xref ref-type="bibr" rid="bib26">Fyhn et al., 2008</xref>; <xref ref-type="bibr" rid="bib53">Machado et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Moser et al., 2008</xref>; <xref ref-type="bibr" rid="bib90">Yoder and Taube, 2009</xref>), nose pokes (<xref ref-type="bibr" rid="bib65">Raposo et al., 2012</xref>), foraging (<xref ref-type="bibr" rid="bib18">Devito and Eichenbaum, 2011</xref>; <xref ref-type="bibr" rid="bib35">Jennings et al., 2015</xref>), social interaction (<xref ref-type="bibr" rid="bib79">Silverman et al., 2010</xref>), or other complex behaviors that require freedom of motion. The power of such behavioral paradigms has motivated significant efforts to analyze head and body kinematics (<xref ref-type="bibr" rid="bib26">Fyhn et al., 2008</xref>; <xref ref-type="bibr" rid="bib27">Goulding et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Hardcastle et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Machado et al., 2015</xref>; <xref ref-type="bibr" rid="bib86">Wiltschko et al., 2015</xref>; <xref ref-type="bibr" rid="bib90">Yoder and Taube, 2009</xref>) and to image the activity of neural populations (<xref ref-type="bibr" rid="bib3">Barretto et al., 2009</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2013b</xref>; <xref ref-type="bibr" rid="bib23">Flusberg et al., 2008</xref>; <xref ref-type="bibr" rid="bib35">Jennings et al., 2015</xref>) in freely moving mice. However, measurements of eye movements have been lacking in these studies, even for visually guided behaviors such as navigation. Thus, a method for analyzing eye movements in unrestrained mice would be a powerful tool for advancing our understanding of the murine behavioral repertoire and its neural underpinnings. Previously, the only eye tracking method compatible with free motion in small animals was the electro-oculogram, which is susceptible to inaccuracies (<xref ref-type="bibr" rid="bib1">Arden and Kelsey, 1962</xref>). Recently, video-oculography was used to measure visually driven eye movements in mice without head restraint, however the mice were constrained to a small platform, and only 20% of the measurements were useable (<xref ref-type="bibr" rid="bib47">Kretschmer et al., 2017</xref>). Here, we address the need for an accurate and reliable technique to measure eye movements in mice during the broad range of freely moving behaviors used in neuroscience research.</p><p>Our approach was designed to overcome the major limitations of previous eye tracking methods in mice, the most popular of which are the eye coil method and video-oculography. The eye coil, or scleral search coil, technique is considered the gold standard for measuring eye movements in most species (<xref ref-type="bibr" rid="bib7">Boyden and Raymond, 2003</xref>; <xref ref-type="bibr" rid="bib14">Collewijn et al., 1975</xref>; <xref ref-type="bibr" rid="bib36">Judge et al., 1980</xref>; <xref ref-type="bibr" rid="bib45">Koekkoek et al., 1997</xref>; <xref ref-type="bibr" rid="bib68">Remmel, 1984</xref>; <xref ref-type="bibr" rid="bib70">Robinson, 1963</xref>). A small coil of wire is surgically implanted beneath the conjunctiva on the surface of the eye, and eye position is determined from the current generated in the wire by an external magnetic field. A major advantage of the eye coil method is that it has high spatial (~0.1°) and temporal (&lt;1 ms) resolution (<xref ref-type="bibr" rid="bib14">Collewijn et al., 1975</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). Disadvantages arise from the difficulty of implementation, particularly in species with small eyes. The surgery requires lengthy training to master, and the fragile wires leading subcutaneously from the eye coil to a skull-mounted connector can break, requiring additional surgeries for repair or additional animals. Moreover, during measurements of eye movements, it is optimal for the animal’s head to remain stationary and centered within large magnetic field coils, so this approach has been applied almost exclusively in head-fixed animals (but see <xref ref-type="bibr" rid="bib15">Collewijn, 1977</xref>; <xref ref-type="bibr" rid="bib62">Ogorodnikov et al., 2006</xref>; <xref ref-type="bibr" rid="bib75">Sánchez-López and Escudero, 2015</xref>).</p><p>A second, common method for measuring eye movements is video-oculography, which uses a high-speed camera to record the position of the pupil (<xref ref-type="bibr" rid="bib59">Mitchiner et al., 1976</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; <xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>). The primary advantage of this approach is that it is non-invasive. However, there are also several disadvantages. Its spatial resolution is lower than that of the eye coil (<xref ref-type="bibr" rid="bib31">Houben et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Kimmel et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">McCamy et al., 2015</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). Inaccuracies can arise from changes in pupil diameter due to fluctuations in luminance or behavioral state (<xref ref-type="bibr" rid="bib39">Kaufman, 2002</xref>; <xref ref-type="bibr" rid="bib41">Kimmel et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">McCamy et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>). A camera or mirror must be placed in the animal’s field of view, which limits the experimenter’s control of visual stimuli. Finally, the head must remain stationary relative to the camera, which precludes use in freely moving mice, since even the miniaturized video-oculography system developed for the rat (<xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>) significantly exceeds the size of the mouse head.</p><p>A promising alternative to the eye coil and video-oculography techniques is an approach based on magnetic sensing. If a magnet is implanted on the surface of the eye, its magnetic field will rotate with the eye, allowing eye movements to be detected with a sensor that measures either the angle or the strength of the magnetic field. Three previous reports, two in goldfish (<xref ref-type="bibr" rid="bib71">Rodríguez et al., 2001</xref>; <xref ref-type="bibr" rid="bib73">Salas et al., 1999</xref>) and one in chickens (<xref ref-type="bibr" rid="bib77">Schwarz et al., 2013</xref>) have demonstrated the potential of magnetic sensing for measuring eye movements. We extended these initial efforts in several ways. First, we miniaturized the implant for the smaller mouse eye, while achieving spatial resolution comparable to the eye coil benchmark. Second, we rigorously tested robustness to the relative placement of the magnet and sensor. Third, we developed an improved method for calibrating the magnetic eye tracking system. These advances yielded the first high resolution recordings of eye movements in freely moving mice.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We developed a system for measuring eye movements in mice using magnetic sensing technology. A powerful neodymium magnet was surgically implanted beneath the conjunctiva so that it rotated with the eye, and a magnetic field sensor was used to detect the resulting changes in the angle of the magnetic field.</p><sec id="s2-1"><title>Magnetic sensor performance outside the animal</title><p>The performance of the magnetic eye tracking system was first tested outside the mouse, where the position of the magnet and sensor could be precisely controlled, allowing systematic comparison of different magnet-sensor alignments. Initially, a 0.75 × 2 mm cylinder magnet was positioned directly below and adjacent to the sensor, with the N-S axis of the magnet parallel to the plane of the sensor, and the magnet’s axis of rotation aligned to the center of the sensor (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>left</italic>, with δ = 0 mm). When the magnet was rotated ±90° about an axis perpendicular to the plane of the sensor, the magnetic sensor produced a voltage that depended on the angle of the magnet (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>center</italic>, <italic>black traces</italic>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.002</object-id><label>Figure 1.</label><caption><title>Systematic testing of magnet-sensor placement.</title><p>(<bold>A</bold>) Output of the magnetic sensor when a 0.75 × 2 mm cylinder magnet was rotated by a servo-controlled motor. <italic>Left</italic>, Schematic showing the relative position and orientation of the magnet and sensor, the axis of magnet rotation (<italic>dashed line and arrow</italic>) and the dimension along which magnet position was varied (δ, <italic>red arrow</italic>). <italic>Middle,</italic> Output from each channel of the magnetic sensor as vertical distance (δ) between the magnet and the surface of the sensor was varied from 0 mm (<italic>black</italic>) to 5 mm (<italic>light grey</italic>) (n = 5 repeated measurements). <italic>Right,</italic> Sensitivity of each channel of the magnetic sensor at each distance from the magnet. In this and all panels, SEM for repeated measurements was smaller than the symbol size. (<bold>B</bold>) Same as in (<bold>A</bold>), but the magnet was offset horizontally (δ) from both its axis of rotation and the center of the sensor. Vertical distance was fixed at 3 mm. (<bold>C</bold>) Same as in (<bold>B</bold>), but the sensor was offset horizontally from the center of the magnet, which rotated about its center. (<bold>D</bold>) Same as in (<bold>B</bold>), but comparing horizontal orientation of the magnet as in (<bold>A</bold>) with a 45° tilt relative to the plane of the sensor (p=0.168, n = 5 repeated measurements, two sample <italic>t</italic>-test). Vertical distance between the center of the magnet and the sensor was fixed at 3 mm.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-29222-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.29222.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Systematic testing of magnet-sensor placement for a disc magnet.</title><p>(<bold>A</bold>) Output of the magnetic sensor when a 1.5 × 0.5 mm disc magnet was rotated by a servo-controlled motor. <italic>Left</italic>, schematic of magnet-sensor orientation. <italic>Middle</italic>, output from each channel of the magnetic sensor as the vertical distance (δ) between the magnet and the surface of the sensor was varied from 0 mm (<italic>black</italic>) to 5 mm (<italic>light grey</italic>) (n = 5 repeated measurements). <italic>Right</italic>, sensitivity of each channel of the magnetic sensor at each distance from the magnet. (<bold>B</bold>) Same as in (<bold>A</bold>), but the magnet was horizontally offset (δ) from both its axis of rotation and the center of the sensor.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig1-figsupp1-v1"/></fig></fig-group><p>The magnetic sensor we used has two channels, which relay output from two sets of magnetoresistive elements at a 45° orientation relative to each other, so that the position tuning of the two channels is offset by 45° (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>center</italic>). Hence, during normal eye movements in mice, which are typically within ±10–20° (<xref ref-type="bibr" rid="bib84">van Alphen et al., 2010</xref>), at least one of the two channels should operate close to its range of greatest sensitivity and linearity (near 0° for Channel 1, and 45° for Channel 2 in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>center</italic>).</p><p>Robustness to deviations in magnet-sensor alignment is necessary for magnetic eye tracking in vivo, since surgical implantation of the magnet and sensor will inevitably result in some variation in placement. Most notably, the magnet cannot be directly adjacent to the sensor when implanted in the mouse eye. Therefore, we tested the effect of increasing the distance to the magnet on the sensitivity of the sensor to the angular position of the magnet. Sensitivity was calculated as the slope of the relationship between magnetic sensor voltage and angular position of the magnet, averaged in a ±22.5° range centered on the zero-crossings of each channel. Sensitivity decreased from 224.7 ± 0.3 mV/° at 0 mm to 28.1 ± 1.0 mV/° at 5 mm (average sensitivity of the two channels; sensitivity for each channel is shown separately in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, <italic>right</italic>). Notably, at 3 mm, a distance readily achievable in mice (see Materials and methods), the sensitivity was 127.0 ± 1.2 mV/°. This corresponded to a spatial resolution, as measured by the standard deviation of the signal at rest, of 0.016° ± 0.005°, which is nearly an order of magnitude below the noise floor measured by the best eye tracking methods in mice (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). Results obtained using a 1.5 × 0.5 mm disc magnet were similar to those for the cylinder magnet, with a sensitivity of 90.9 ± 0.7 mV/° at a distance of 3 mm (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Because of its marginally greater sensitivity, we focused on the cylinder magnet for all subsequent measurements.</p><p>In addition to characterizing how sensitivity varied with the vertical distance between the magnet and sensor, the effect of horizontal distance (displacement within a plane parallel to the plane of the sensor) was tested. In the animal, the magnet will not rotate exactly about its center, but instead will be horizontally offset by the radius of the eye. We tested the impact of this offset by fixing the vertical distance between magnet and sensor at 3 mm, and then horizontally displacing the magnet from the midpoint of the sensor and from its axis of rotation (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Sensitivity decreased with distance; nevertheless, the signals were still more than half maximum at 1.5 mm of horizontal offset (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), which corresponds to the radius of the mouse eye. When the sensor, rather than the magnet, was displaced from the axis of rotation, sensitivity decreased in a similar manner (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Therefore, the sensor’s ability to detect magnet angle is robust to horizontal as well as vertical variations in magnet-sensor alignment of magnitudes that would be expected in vivo.</p><p>Finally, we tested the effect of tilting the N-S axis of the magnet relative to the plane of the sensor, which also may occur during implantation. Tilting the magnet by 45° did not affect sensitivity (127.8 ± 4 mV/° no tilt, 128.0 ± 2.0 mV/° with 45° tilt, <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p></sec><sec id="s2-2"><title>Magnetic tracking of eye movements in mice</title><p>After characterizing the performance of the magnetic eye tracking system outside the mouse, we implemented magnetic eye tracking in head-fixed mice. A cylinder magnet was surgically implanted beneath the conjunctiva on the temporal margin of one eye, with the N-S axis aligned so that it created a rotating magnetic field during horizontal (nasal-temporal) eye movements (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; see Materials and methods). A magnetic sensor was affixed to the skull in a plane roughly parallel to the nasal-temporal axis of the eye. The head was restrained, via a surgically implanted head post, with the nasal-temporal axis of the eye in an earth-horizontal plane.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.004</object-id><label>Figure 2.</label><caption><title>Magnetic eye tracking in mice.</title><p>(<bold>A</bold>) Schematic of the magnetic eye tracking system, illustrating the orientation of the sensor relative to the magnet and eye. The magnet was implanted beneath the conjunctiva on the temporal side of the eye. The sensor was soldered to an 8-pin connector and positioned over the magnet in a plane parallel to that of horizontal (nasal-temporal) eye movements. An implanted head post was used to restrain the head so that the nasal-temporal axis of the eye was earth-horizontal. (<bold>B</bold>) Raw output from both channels of the magnetic sensor (<italic>blue traces</italic>) during the vestibulo-ocular reflex (VOR) in one example mouse. A vestibular stimulus (<italic>black trace</italic>, head position) was delivered by rotating the animal about an earth-vertical axis in the dark (0.2 Hz to 5 Hz, peak velocity ±10°/s). (<bold>C</bold>) Raw output from the magnetic sensor during the optokinetic response (OKR). A visual stimulus (<italic>black trace</italic>) was delivered by rotating a vertically striped drum, which surrounded the mouse, about an earth-vertical axis (0.2 Hz to 5 Hz, peak velocity ±10°/s).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-29222-fig2-v1"/></fig><p>The ability of the magnetic eye tracking system to detect eye movements was tested by delivering vestibular and visual stimuli known to evoke eye movements in head-fixed mice. The vestibulo-ocular reflex (VOR) drives compensatory eye movements in response to passive head rotation in the dark, in mice (<xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib38">Katoh et al., 1998</xref>; <xref ref-type="bibr" rid="bib42">Kimpo et al., 2005</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>) as in other species. Accordingly, when vestibular stimuli were delivered to mice implanted with the magnetic eye tracking system, the magnetic sensor detected robust eye movements driven by the VOR. Sinusoidal vestibular stimuli at a range of stimulus frequencies from 0.2 Hz to 5 Hz elicited sinusoidal eye movements at the corresponding frequencies (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><p>The magnetic eye tracking approach was also effective at detecting visually-driven eye movements in head-fixed mice. The optokinetic reflex (OKR) drives image-stabilizing eye movements in response to motion of a visual stimulus, in mice (<xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib38">Katoh et al., 1998</xref>) as in other species. Accordingly, when a striped drum was rotated around the mouse, the magnetic sensor detected robust eye movements driven by the OKR, at all stimulus frequencies tested (0.2 Hz–5 Hz; <xref ref-type="fig" rid="fig2">Figure 2C</xref>). Thus, the magnetic eye tracking system can detect both vestibularly- and visually-driven eye movements in head-fixed mice.</p></sec><sec id="s2-3"><title>Calibration of magnetic eye tracking using dual-angle video-oculography</title><p>To convert the raw output of the magnetic sensor (in volts) to eye position (in degrees), we developed an inexpensive yet accurate calibration system based on video-oculography. A major motivation for developing magnetic eye tracking in mice was to overcome the limitations of video-oculography, such as its limited spatial resolution and the incompatibility with free motion of the animal, which restrict its use for certain applications. However, these limitations do not preclude the use of video-oculography for calibration of the magnetic sensor.</p><p>We modified a standard video-oculography technique to simplify implementation and improve accuracy. In species other than primates, eye position is typically computed from video measurements using an estimate of <italic>R<sub>p</sub></italic>, the distance of the pupil from the center of corneal curvature (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). However, difficulty in estimating <italic>R<sub>p</sub></italic> and variations in <italic>R<sub>p</sub></italic> across individuals and during the course of an experiment are sources of inaccuracy (<xref ref-type="bibr" rid="bib39">Kaufman, 2002</xref>; <xref ref-type="bibr" rid="bib41">Kimmel et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">McCamy et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib87">Wisard et al., 2010</xref>; <xref ref-type="bibr" rid="bib91">Zoccolan et al., 2010</xref>). We eliminated the need to estimate <italic>R<sub>p</sub></italic> by using simultaneous image capture of the eye from two cameras. By positioning the cameras at a known, fixed angle relative to each other (40°, in our setup) and extracting the locations of the pupil and a reference corneal reflection (CR) in each camera’s image, the angle of the eye can be calculated using simple trigonometric identities (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>; see Materials and methods). To validate the dual-angle video-oculography system, two mice were anesthetized and the cameras were rotated at known angles around one eye, over a ± 25° range. The eye position measured with video-oculography agreed closely with true position over the full range (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Thus, dual-angle video-oculography accurately reports eye position, and hence can be used to calibrate the signals recorded by the magnetic sensor.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.005</object-id><label>Figure 3.</label><caption><title>Dual-angle video-oculography.</title><p>(<bold>A</bold>) Schematic of the eye as viewed from above, illustrating the dual-angle video-oculography technique. Two cameras were affixed to a platform, with their axes at an angle of 40° relative to each other, and with the cameras equidistant (5 cm) from the point at which their axes intersected. An infrared LED mounted directly above each camera created a corneal reflection (CR). The position of the camera platform was adjusted to align the image of each CR to the center of the corresponding camera’s image (CR<sub>1,</sub> CR<sub>2</sub>; <italic>red</italic>). This aligned both camera axes with the center of corneal curvature (<bold>C</bold>), and ensured that the two cameras were equidistant from the eye, and therefore had the same image magnification. The distances ∆<sub>1</sub> and ∆<sub>2</sub> from the CR to the center of the pupil (<bold>P</bold>) in each camera’s image were used to compute the angular position of the pupil relative to the cameras (<italic>θ</italic><sub>1</sub>, <italic>θ</italic><sub>2</sub>) (see Materials and methods, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>). (<bold>B</bold>) Example camera frames showing the software-detected pupil and CR locations for each camera. CR<sub>1</sub>ʹ and CR<sub>2</sub>ʹ (<italic>grey</italic>) are reflections generated by the infrared LED above the opposite camera, and are ignored. Other abbreviations as in (<bold>A</bold>). (<bold>C</bold>) Validation of dual-angle video-oculography. Eye position measured by using video-oculography is plotted against true angle as the camera system was rotated about the eye of two anesthetized mice.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-29222-fig3-v1"/></fig><p>To calibrate the signals recorded by the magnetic sensor in each mouse, eye movements were simultaneously recorded in awake, head-restrained mice using the video-oculography and magnetic eye tracking systems. During a brief (1–3 min) calibration session, 0.5 Hz or 1 Hz sinusoidal vestibular stimuli were used to elicit eye movements (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). A calibration factor for the magnetic sensor was extracted by using linear regression to predict video-derived horizontal eye position from the raw voltages of the magnetic sensor. The resulting calibration factor, in units of °/mV, could then be used to calculate eye position from the signals recorded by the magnetic sensor.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.006</object-id><label>Figure 4.</label><caption><title>Calibration of magnetic eye tracking using video-oculography.</title><p>(<bold>A</bold>) Simultaneously recorded magnetic sensor output (Ch1 <italic>dark blue</italic>, Ch2 <italic>light blue</italic>) and video-derived eye position (<italic>black</italic>) from one example mouse, measured during vestibular stimulation in the light. (<bold>B</bold>) Signals from the magnetic sensor, compared time point-by-time point against eye position measured by video-oculography, for the example mouse in (<bold>A</bold>). Results are shown for models of increasing complexity, from <italic>left</italic> to <italic>right</italic>: inputs to the regression model included the single best magnetic sensor channel alone (‘<italic>One channel</italic>’), both magnetic sensor channels (‘<italic>Two channel</italic>s’), or two channels plus quadratic terms (‘<italic>Quadratic</italic>’) (see Materials and methods). (<bold>C</bold>) Mean correlation coefficients between video and calibrated magnet output for each model (n = 24 mice). (<bold>D</bold>) Calibration of magnetic sensor using eye velocity. Example differentiated video and magnetic sensor traces are shown for same mouse as in (<bold>A</bold>). The sine wave fit to the magnetic sensor channel with higher r<sup>2</sup> relative to the video is shown. The output of the magnetic sensor channel was scaled by a calibration factor equal to the ratio of video sine wave amplitude (A<sub>vid</sub>) divided by magnetic sensor amplitude (A<sub>mag</sub>). (<bold>E</bold>) Stability of magnetic eye tracking over time. Sensitivity was quantified as the reciprocal of the calibration factor obtained using the velocity method, and was measured each day for one week, and six months after magnet implantation. Mean sensitivity did not change over one week (all p&gt;0.3, paired <italic>t</italic>-test, Days 2–7 vs. Day 1, n = 8). After six months (average time post-surgery 6.0 ± 0.4 months, range 5.2–7.7 months), sensitivity was lower but still robust (n = 8 mice; two additional mice had no detectable eye movement signals). (<bold>F</bold>) Changes in the calibration factor of individual mice over time. Although the mean sensitivity of the magnetic sensor was robust over months, the calibration factors of individual mice showed some fluctuations from day-to-day, as quantified by the absolute value of the percent change in calibration factor measured each day for one week, relative to Day 1.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-29222-fig4-v1"/></fig><p>The signal in one channel of the magnetic sensor was often considerably larger and more strongly correlated with the video-derived measurements of eye position than the signal in the other channel (see examples in <xref ref-type="fig" rid="fig2">Figure 2B,C</xref> and <xref ref-type="fig" rid="fig4">Figure 4A</xref>), as expected from tests outside the animal (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Nonetheless, the second channel might carry some additional information about eye position. Therefore, we assessed whether a better estimate of eye position could be obtained from a linear model incorporating both channels of the magnetic sensor, rather than the single best channel (the channel with the highest correlation coefficient to video-derived eye position, see Materials and methods). On average, incorporating both channels only improved the fit to the video-derived measurements by a small amount (3.5% additional variance explained, <xref ref-type="fig" rid="fig4">Figure 4B,C</xref>). We also estimated eye position using a model that included a nonlinear, quadratic term for each channel, and found little additional improvement (2.3% additional variance explained compared to the two-channel model, <xref ref-type="fig" rid="fig4">Figure 4B,C</xref>). All subsequent measurements of eye position were derived from the single best channel of the magnetic sensor.</p><p>An alternative method of calibration can be used in applications in which eye velocity is the most relevant measure, rather than eye position. Eye position signals obtained from the magnetic and video systems were each differentiated, saccades and motion artifacts were removed, and the resulting velocity traces were each fit with a sine wave (see Materials and methods). The ratio of the amplitudes of the sine wave fits for the video and magnetic signals provided a calibration factor that could then be used to convert the differentiated magnetic sensor voltage into eye velocity (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). This method has the advantage of not requiring precise temporal alignment between the video and magnetic recordings, since the amplitude of each signal is determined independently. Calibration factors obtained using the velocity method and the position method were similar in each mouse (p=0.55, paired <italic>t</italic>-test, n = 24).</p><p>To assess the robustness of magnetic eye tracking over time, eight mice were repeatedly calibrated each day for a week, using the velocity method. The reciprocal of the calibration factor represents the in vivo sensitivity of the magnetic sensor in mV/° (the slope in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, <italic>left</italic>). On average, the sensitivity of the magnetic sensor decreased by only 4.2% after one week (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, <italic>left</italic>). Even after many months, the magnetic implants were remarkably robust. In a population of ten mice recorded 5–7 months after implantation, only two had unusable eye movement signals. In the remainder, sensitivity was lower than on the first day it was measured, but still suitable for eye tracking measurements (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, <italic>right</italic>).</p><p>Although the implants were robust over many months, the calibration factors could fluctuate from day to day in individual mice. To quantify this, the absolute value of the percent change in the calibration factor <italic>k</italic>, relative to the calibration factor value on Day 1, was calculated for each day in each mouse: <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>⋅</mml:mo><mml:mn>100</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the calibration factor on Day <italic>n</italic>. On average, there was gradual drift in the calibration factors from their original values over time (<inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> increased with the number of days since original calibration; <xref ref-type="fig" rid="fig4">Figure 4F</xref>), indicating that regular recalibration is important to maintain accuracy.</p></sec><sec id="s2-4"><title>Linearity and spatial resolution of the magnetic eye tracking system</title><p>We benchmarked magnetic eye tracking against the well-established eye coil technique, by quantifying the linearity and spatial resolution of each technique. Because the dual-angle video-oculography system reports eye position with a high degree of linearity (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), the linearity of the magnetic and eye coil systems was assessed by regressing each signal against video-derived eye position, recorded simultaneously during vestibularly-driven eye movements in the light. Both eye coil and magnetic systems were highly correlated with the video system, and the correlation coefficient for the magnetic system was comparable to that for the eye coil system (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), indicating a similar level of linearity.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.007</object-id><label>Figure 5.</label><caption><title>Comparison of magnetic eye tracking with the eye coil technique.</title><p>(<bold>A</bold>) Correlation coefficient between the video and the eye coil data (<italic>gray;</italic> symbols represent individual mice, n = 9) and between the video and magnetic eye tracking data (<italic>blue,</italic> n = 8 mice) (p=0.937; two-sample <italic>t</italic>-test for eye coil vs. magnet). (<bold>B</bold>) Spatial resolution was similar for the eye coil and magnetic eye tracking systems (p=0.631, two-sample <italic>t</italic>-test), as measured by the standard deviation of eye position signals recorded during epochs when the eyes were relatively stationary in head-fixed mice in the light.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig5-v1"/></fig><p>The spatial resolution of the magnetic and eye coil systems was also compared. In head-fixed mice, spontaneous eye movements are interspersed with longer periods when the eyes are relatively stationary. The variability of the signals recorded during these stationary periods provides a measure of the eye tracking system’s spatial resolution in vivo, with a lower bound determined by the actual jitter in eye position (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; see Materials and methods). Quantified in this way, the magnetic and eye coil systems each had spatial resolutions of &lt;0.1° (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), similar to previous reports for the eye coil (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). Therefore, the spatial resolution, as well as the linearity, of magnetic eye tracking was comparable to that of the eye coil.</p><p>There has been controversy about whether eye coil implants alter eye movements in mice (<xref ref-type="bibr" rid="bib6">Boyden et al., 2006</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>). To evaluate whether the magnet implant has any effect on eye movements, video-oculography was used to compare the eye movements measured one day before versus six days after implantation of the magnet and sensor. Eye movement responses to vestibular stimuli at a range of stimulus frequencies were measured in the dark. Because the eye movements driven by the vestibulo-ocular reflex (VOR) in the dark are open-loop, they should provide a particularly sensitive measure of any disruption of normal oculomotor dynamics. Neither the gain nor the phase of the eye movement responses were altered after magnet implantation (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Likewise, the eye movements elicited by combined vestibular and visual inputs were unaltered by magnet implantation (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). The gain and phase of the VOR measured with magnetic eye tracking (<xref ref-type="fig" rid="fig6">Figure 6</xref>, <italic>dashed, blue lines</italic>) were in the range reported previously in mice by our laboratory (<xref ref-type="bibr" rid="bib43">Kimpo and Raymond, 2007</xref>) and other laboratories (<xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>), as were the gain and phase of the visually driven eye movements elicited by an optokinetic stimulus at a range of frequencies (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>; <xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib43">Kimpo and Raymond, 2007</xref>; <xref ref-type="bibr" rid="bib81">Tabata et al., 2010</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>, <xref ref-type="bibr" rid="bib83">2009</xref>, <xref ref-type="bibr" rid="bib84">2010</xref>). Thus, magnet implantation had no detectable effect on oculomotor behavior.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.008</object-id><label>Figure 6.</label><caption><title>The vestibulo-ocular reflex (VOR) before and after magnet implantation.</title><p>The gain (<italic>left</italic>) and phase (<italic>right</italic>) of the eye movement responses to vestibular stimuli, before (<italic>black</italic>) and six days after (<italic>blue</italic>) implantation of the magnet and sensor, measured using video-oculography with infrared illumination in otherwise complete darkness (<italic>solid lines</italic>). There was no effect of magnet implantation on either the gain or the phase of the VOR (p=0.725 gain, p=0.350 phase, for main effect of pre- vs post-implantation; p=0.497 gain, p=0.469 phase, for interaction with vestibular stimulus frequency; two-way repeated measures ANOVA, n = 8 mice). The gain and phase of the VOR measured simultaneously with magnetic eye tracking (post-implantation) are shown as well (<italic>blue, dashed lines</italic>).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig6-v1"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.29222.009</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Eye movements driven by combined vestibular and visual input, before and after magnet implantation.</title><p>The gain (left) and phase (right) of the eye movement responses to the combined vestibular and visual input provided by head rotations in an illuminated visual surround was measured using video-oculography (solid lines) before (black) and after (black) implantation of the magnet and sensor. There was no effect of magnet implantation on either the gain or the phase of the eye movements (p=0.447 gain, p=0.794 phase, for main effect of pre- vs post-implantation; p=0.618 gain, p=0.488 phase, for interaction with vestibular stimulus frequency; two-way repeated measures ANOVA, n = 8 mice). The gain and phase of the eye movements measured simultaneously with magnetic eye tracking (post-implantation) are shown also (blue, dashed lines). The visual input included both a mouse-stationary video apparatus, which would tend to suppress the eye movements driven by the vestibular stimulus, and an earth-stationary visual surround, which would tend to enhance the eye movements driven by the vestibular stimulus.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig6-figsupp1-v1"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.29222.010</object-id><label>Figure 6—figure supplement 2.</label><caption><title>The optokinetic response (OKR) measured with magnetic eye tracking.</title><p>The gain (<italic>left</italic>) and phase (<italic>right</italic>) of the OKR elicited by rotation of a random checkerboard patterned drum around the mouse, measured using the magnetic eye tracking system (n = 6 mice).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig6-figsupp2-v1"/></fig></fig-group></sec><sec id="s2-5"><title>Bilateral eye movement recordings</title><p>The coordination of movements of the two eyes can influence visual experience. We assessed the suitability of magnetic eye tracking for simultaneously measuring the movements of both eyes of a mouse. Specifically, we tested whether there was interference created by the magnet in one eye influencing the sensor over the opposite eye. In three mice, a magnet was implanted in only one eye, while sensors were implanted above both eyes. The signals from both sensors were recorded during eye movements elicited by a sinusoidal vestibular stimulus (1 Hz, ±10°/s). The amplitude of the signal in the sensor contralateral to the eye with the magnet was only 2.7 ± 0.9% of that in the ipsilateral sensor, indicating limited crosstalk. Therefore, magnetic eye tracking allows simultaneous recording from both eyes, making it possible to analyze binocular coordination in mice.</p></sec><sec id="s2-6"><title>Eye movement recordings in freely moving mice</title><p>The small size and weight of the magnetic eye tracking system provided an opportunity to record eye movements in freely moving mice. Horizontal eye movements were recorded bilaterally for 5–10 min as mice explored a 12&quot; arena surrounded by a stationary, vertically-striped visual stimulus. The eye movements recorded in this freely moving condition were compared with the eye movements recorded in the same mice while they were restrained in the center of the arena using their surgically implanted headpost. Overall, mice moved their eyes more when unrestrained, as evident in raw eye position traces (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) and in scatterplots of eye position and eye velocity (<xref ref-type="fig" rid="fig7">Figure 7B,D</xref>) from individual mice. On average, freely moving mice displayed a two-fold increase in the standard deviation of eye position (<xref ref-type="fig" rid="fig7">Figure 7C</xref>), as well as a four-fold increase in the mean speed of the eye (<xref ref-type="fig" rid="fig7">Figure 7E</xref>) compared to head-fixed mice.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.29222.011</object-id><label>Figure 7.</label><caption><title>Eye movements measured in freely moving mice.</title><p>(<bold>A</bold>) Example of bilateral eye movements in one mouse when it was head-fixed (<italic>top</italic>) compared to freely moving (<italic>bottom</italic>). <italic>Light purple</italic>, body still; d<italic>ark purple</italic>, body actively moving, as measured using overhead video images (see Materials and methods). (<bold>B</bold>) Scatterplot of left and right eye positions in the example mouse from (<bold>A</bold>), during head fixation (<italic>black</italic>, <italic>left</italic>) and during free motion (<italic>purple</italic>, <italic>right</italic>). (<bold>C</bold>) Variability of eye position in head-fixed and freely moving mice. The standard deviation of eye position increased in head-free (<italic>dark purple</italic>) compared with head-fixed (<italic>black</italic>) mice (p=1.9 × 10<sup>−4</sup>, paired <italic>t</italic>-test, n = 7). Eye movements recorded in head-free mice were further subdivided into periods when the body was still (<italic>light purple</italic>) versus actively moving (<italic>medium purple</italic>) (p=0.146, paired <italic>t</italic>-test, n = 7). <italic>Grey lines</italic>, individual mice; <italic>black lines,</italic> example mouse in (<bold>A</bold>). (<bold>D</bold>) Scatterplots of velocity of the left and right eye during head fixation and free motion, for the example mouse in (<bold>A</bold>). (<bold>E</bold>) Mean eye speed was higher in freely moving than head-fixed mice (p=9.7 × 10<sup>−5</sup>, paired <italic>t</italic>-test, n = 7). In unrestrained mice, eye speed was highest during periods of active body movement compared to periods when the body was relatively still (p=3.6 × 10<sup>−4</sup>, paired <italic>t</italic>-test, n = 7). (<bold>F</bold>) Correlation between horizontal eye velocity and head velocity about the yaw axis in freely moving mice (n = 4). (<bold>G</bold>) Binocular coordination in head-fixed and freely moving mice. Left, mean eye divergence (horizontal angle between the two eyes) increased during free motion compared to head fixation (p=0.029, paired t-test, n = 7). Right, the standard deviation of eye divergence also increased during free motion (p=0.009, paired t-test, n = 7).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-29222-fig7-v1"/></fig><p>The increase in eye movements observed in freely moving mice was associated with active body movement, rather than simply the absence of restraint. Eye movements recorded in unrestrained mice were subdivided according to whether the body was actively moving or relatively still, as quantified by a motion index extracted from overhead video (see Materials and methods). During active, self-generated body movements, the mean eye speed was higher compared to when the body was relatively still (<xref ref-type="fig" rid="fig7">Figure 7E</xref>).</p><p>The correlation of eye movements with body movements did not simply reflect a general increase in motor activity or arousal, but were, at least in part, directly driven by motion of the head. Head movements create both vestibular input and visual input (from relative motion of the earth-stationary visual surround), which are both known to drive eye movements in mice (<xref ref-type="fig" rid="fig2">Figure 2B,C</xref>; <xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib37">Katoh et al., 2008</xref>; <xref ref-type="bibr" rid="bib78">Shin et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>). More specifically, head rotations about the yaw axis could drive the horizontal eye movements detected by our magnetic eye tracking system. Head movements were recorded in unrestrained mice using an inertial measurement unit. There was a strong, linear relationship between self-generated head movements about the yaw axis and horizontal eye movements in the opposite direction (<xref ref-type="fig" rid="fig7">Figure 7F</xref>), suggesting that active head movements are a major driver of eye movements in freely moving mice.</p><p>Not only were the motion statistics of individual eyes altered in freely moving mice, but the binocular coordination was altered as well. Binocular coordination is likely to play a key role in the active control of vision in most species. Such coordination is currently best understood in head-fixed primates, with much less known in lateral-eyed, afoveate, and freely moving animals, where there can be important differences (<xref ref-type="bibr" rid="bib8">Carriot et al., 2014</xref>; <xref ref-type="bibr" rid="bib49">Land, 2015</xref>), as illustrated by a recent study in rats (<xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>). We found that the eye divergence (the horizontal angular distance between the two eyes) increased in unrestrained mice, compared to during head fixation (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, <italic>left</italic>), and the variability of eye divergence also increased (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, <italic>right</italic>). Thus, bilateral eye movements in mice are highly dependent on the motion of the animal, with the eyes both more active and more divergent in freely moving compared to head-fixed mice.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Magnetic eye tracking opens up exciting new scientific opportunities by providing a high-resolution (&lt;0.1°) method for measuring eye movements that overcomes the challenging physical constraints of small and freely moving animals. The methods described here extend previous reports of magnetic eye tracking (<xref ref-type="bibr" rid="bib71">Rodríguez et al., 2001</xref>; <xref ref-type="bibr" rid="bib73">Salas et al., 1999</xref>; <xref ref-type="bibr" rid="bib77">Schwarz et al., 2013</xref>) by miniaturizing the implant for use in mice, increasing the resolution, assessing tolerance for various magnet-sensor alignments, and improving the calibration procedure. Magnetic eye tracking has important advantages over the commonly used eye coil and video-oculography techniques, and hence could replace these older techniques in many current applications. We developed the magnetic eye tracking system in mice due to the widespread use of this species, but there are no obvious barriers to extending this technique into larger species, such as rats or monkeys. A larger eye and orbit may require that the sensor be implanted farther away from the magnet, however, this should be offset by the ability to implant a larger magnet.</p><sec id="s3-1"><title>Comparison to the eye coil</title><p>Magnetic eye tracking achieved performance similar to that of the eye coil technique, which is widely considered the gold standard for measuring eye movements (<xref ref-type="bibr" rid="bib70">Robinson, 1963</xref>). The spatial resolution of magnetic eye tracking (0.098°) was comparable to the resolution of the eye coil technique in mice, as measured by our lab (0.091°; <xref ref-type="fig" rid="fig5">Figure 5B</xref>) and other labs (0.09°, <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>), and was also comparable to the resolution of the eye coil technique in larger species such as monkeys (&lt;0.1°, <xref ref-type="bibr" rid="bib41">Kimmel et al., 2012</xref>) and humans (0.096°, <xref ref-type="bibr" rid="bib31">Houben et al., 2006</xref>). Further, the linearity of magnetic eye tracking was indistinguishable from that of the eye coil technique (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><p>The performance of the magnetic eye tracking system benefited from the use of angular magnetic field sensors containing anisotropic magnetoresistive (AMR) technology (<xref ref-type="bibr" rid="bib77">Schwarz et al., 2013</xref>). In contrast to Hall effect sensors, which measure magnetic field strength (<xref ref-type="bibr" rid="bib71">Rodríguez et al., 2001</xref>; <xref ref-type="bibr" rid="bib73">Salas et al., 1999</xref>), AMR sensors are designed to measure the angle of a magnetic field. AMR sensors can achieve high resolution, while satisfying the constraints of low power, low cost, and small sensor size (<xref ref-type="bibr" rid="bib50">Lenz and Edelstein, 2006</xref>). Despite the small size of the magnet required for mice, high resolution was achieved by placement of the magnet and sensor within the range established by systematic testing outside the animal.</p><p>With comparable spatial resolution, magnetic eye tracking offers several advantages over the eye coil technique. Most notably, the minimal equipment required for magnetic eye tracking permits its use in freely moving animals, as discussed further below. Magnetic eye tracking is also far less expensive than commercially available eye coil systems, making this approach available to more investigators. A third key advantage of magnetic eye tracking is the lack of fragile wires leading to the eye, which minimizes the difficulty of surgical implantation, greatly reducing the time required for the experimenter to learn and perform the procedure. The lack of fragile wires also extends the long-term reliability of the magnet implants. Only two out of ten mice followed for half a year after surgery had failed magnet implants, whereas the wires used for eye coil recordings often fail after several weeks following implantation (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; Raymond lab, unpublished observations). Improved reliability allows for larger sample sizes with less attrition, which is particularly important when using valuable transgenic mice.</p><p>A concern has been raised that the weight of an eye coil or the presence of wire leads might physically impair eye movements in mice (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). We found no evidence for an effect of magnet implantation on oculomotor performance (<xref ref-type="fig" rid="fig6">Figure 6</xref>; <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). However, we do find that the experience and skill of the surgeon improves the outcome of both magnet and eye coil implantation surgeries in mice.</p><p>We replicated the general finding of an increase in VOR gain and decrease in OKR gain as well as an increase in VOR and OKR phase lag with stimulus frequency, which is observed across species. The gain and phase of the VOR and OKR measured with magnetic eye tracking fall within the range reported previously in mice using video and eye coil techniques, although there is considerable variability in the previously reported values, arising, at least in part, from sensitivity to the parameters of the vestibular and visual stimuli used to elicit eye movements, as well as behavioral factors related to handling and stress (<xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib43">Kimpo and Raymond, 2007</xref>; <xref ref-type="bibr" rid="bib81">Tabata et al., 2010</xref>; <xref ref-type="bibr" rid="bib82">van Alphen et al., 2001</xref>, <xref ref-type="bibr" rid="bib83">2009</xref>, <xref ref-type="bibr" rid="bib84">2010</xref>).</p><p>Magnetic eye tracking has many advantages, but also some disadvantages relative to the eye coil method. One current limitation is that the magnet-sensor configuration we used measures angular eye position about only one axis. A single axis is sufficient for many applications (<xref ref-type="bibr" rid="bib33">Iwashita et al., 2001</xref>; <xref ref-type="bibr" rid="bib44">Kimpo et al., 2014</xref>; <xref ref-type="bibr" rid="bib46">Koyama et al., 2004</xref>; <xref ref-type="bibr" rid="bib58">Medrea and Cullen, 2013</xref>; <xref ref-type="bibr" rid="bib64">Prusky et al., 2004</xref>; <xref ref-type="bibr" rid="bib88">Wurtz, 1968</xref>), moreover further development to incorporate either a second sensor or a 3D magnetic field sensor should enable simultaneous measurement of eye movements along multiple axes simultaneously. A second disadvantage of magnetic eye tracking is that it requires a separate calibration device, whereas the eye coils can be calibrated by rotating the external magnetic field coils relative to the mouse. Early efforts at magnetic eye tracking employed an invasive calibration method involving physical rotation of the eye using a needle under a microscope (<xref ref-type="bibr" rid="bib71">Rodríguez et al., 2001</xref>; <xref ref-type="bibr" rid="bib73">Salas et al., 1999</xref>). We have minimized the difficulty of the calibration step by developing a rapid (&lt;10 min), accurate, noninvasive calibration procedure using an improved video-oculography method, which can be performed in awake mice.</p></sec><sec id="s3-2"><title>Dual-angle video-oculography</title><p>Standard video-oculography approaches are challenging in mice and other afoveates because of the difficulty in estimating <italic>R<sub>p</sub></italic> (the distance from the plane of the pupil to the center of corneal curvature), which is typically used to determine angular eye position from video images. <italic>R<sub>p</sub></italic> has been approximated as the average radius of the eye in a species (<xref ref-type="bibr" rid="bib38">Katoh et al., 1998</xref>; <xref ref-type="bibr" rid="bib55">Mangini et al., 1985</xref>; <xref ref-type="bibr" rid="bib77">Schwarz et al., 2013</xref>). However, this is an imperfect measure of <italic>R<sub>p</sub></italic> because the curvature of the cornea is different from the rest of the eye, and because the eye does not rotate exactly about its center (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). In addition, a single <italic>R<sub>p</sub></italic> value doesn’t account for variation across age, gender, genotype, or individuals (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; <xref ref-type="bibr" rid="bib87">Wisard et al., 2010</xref>). Methods have been devised for estimating <italic>R<sub>p</sub></italic> in individual animals (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; <xref ref-type="bibr" rid="bib91">Zoccolan et al., 2010</xref>), but these methods extend the time the animal must be head-restrained for an experimental session. Most notably, the above methods assume that <italic>R<sub>p</sub></italic> is constant over time, whereas <italic>R<sub>p</sub></italic> is known to change rapidly with shifts in arousal or light intensity (<xref ref-type="bibr" rid="bib39">Kaufman, 2002</xref>; <xref ref-type="bibr" rid="bib41">Kimmel et al., 2012</xref>; <xref ref-type="bibr" rid="bib57">McCamy et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>), which introduces inaccuracies.</p><p>Dual-angle video-oculography eliminates the need to estimate <italic>R<sub>p</sub></italic>, by calculating eye position from frame-by-frame comparison of the images from the two cameras. The result is highly linear and sufficiently accurate for the purpose of calibrating the magnetic eye tracking system. If enhanced with high-speed cameras and faster image processing, the dual-angle method could also stand alone as a powerful video-oculography technique.</p><p>Despite the improvements in video-oculography achieved by the dual-angle technique, magnetic eye tracking provides key advantages that make it preferable to video-oculography for many applications. First, the spatial resolution of magnetic eye tracking (0.1°) is superior to what has been reported for video-oculography in rodents (0.23°, <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>; ~1°, <xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>), in monkeys (video resolution 2‒3 × worse than eye coil, <xref ref-type="bibr" rid="bib41">Kimmel et al. (2012)</xref>; <xref ref-type="bibr" rid="bib57">McCamy et al., 2015</xref>) and in humans (0.56°, <xref ref-type="bibr" rid="bib31">Houben et al., 2006</xref>). Second, magnetic eye tracking achieves high temporal resolution with less expense. Although some video-oculography systems can sample at 1,000 Hz, they are costly and typically sacrifice image resolution. Since the dual-angle system is used only for calibration, high-speed cameras are not required. Third, removal of the bulky video-oculography equipment after calibration allows free, unobstructed interaction of the animal with the environment during eye tracking. Technological advances have reduced the size of cameras to fit on the head of a rat (<xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>), but the hardware required for magnetic eye tracking is more than an order of magnitude lighter (0.05 cm<sup>3</sup> and 0.180 g total) and is therefore trivial for a mouse to carry, allowing much greater mobility than possible with video-oculography (<xref ref-type="bibr" rid="bib47">Kretschmer et al., 2017</xref>). Also, either the video cameras themselves, or the edges of infrared-reflective mirrors, are visible to the animal during video-oculography, limiting experimental control of the visual environment. Thus, magnetic eye tracking is preferable for experiments in which spatial resolution, low cost, unobstructed vision, or compatibility with free motion is a priority.</p></sec><sec id="s3-3"><title>Applications</title><p>Magnetic eye tracking makes it possible to obtain reliable, high-resolution measurements of eye movements in small, freely moving animals, thereby creating new opportunities for studies of sensation, motor control, and cognition under more natural conditions. Neuroscientists are increasingly interested in studying the neural basis of behavior under conditions where the animal is free to move, particularly in rodents (e.g., <xref ref-type="bibr" rid="bib52">Licata et al., 2017</xref>; <xref ref-type="bibr" rid="bib16">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib40">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib21">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib34">Jaramillo and Zador, 2014</xref>). Free motion allows animals to perform orienting movements, which are a key part of any animal’s behavioral repertoire. During visually guided behaviors, coordinated movements of the trunk, head, and eyes can direct the animal’s gaze towards relevant visual stimuli (<xref ref-type="bibr" rid="bib5">Belton and McCrea, 1999</xref>; <xref ref-type="bibr" rid="bib21">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">Fang et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Freedman and Sparks, 1997</xref>; <xref ref-type="bibr" rid="bib25">Fuller, 1992</xref>; <xref ref-type="bibr" rid="bib56">Mather and Baker, 1980</xref>). Body location and head direction are routinely measured during visually guided behaviors such as navigation, and have been shown to be encoded by the activity of neurons in relevant circuits (<xref ref-type="bibr" rid="bib26">Fyhn et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Hardcastle et al., 2017</xref>; <xref ref-type="bibr" rid="bib90">Yoder and Taube, 2009</xref>). However, the technical challenges associated with measuring eye movements have limited the analysis of gaze control in freely moving animals. Our finding of robust eye movements in freely moving mice (<xref ref-type="fig" rid="fig7">Figure 7</xref>) suggests that gaze direction deviates substantially from head direction, as previously reported in rats (<xref ref-type="bibr" rid="bib85">Wallace et al., 2013</xref>). Therefore, gaze direction may be an additional variable represented and controlled by the relevant neural circuits.</p><p>The magnetic eye tracking system facilitates investigation of many open questions regarding the neural control of gaze, and its role in guiding the acquisition of visual information and control of visually-guided behaviors. Eye movements provide a window into many sensory, motor, and cognitive processes in healthy and diseased brains. Technical challenges have limited the application of this experimental measure in the increasingly common neuroscientific studies of freely moving rodents. Magnetic eye tracking provides a high-resolution, low cost, and easily implemented method, which can enable more investigators to capitalize on the power of eye movement analysis.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>Magnetic eye tracking and video-oculography were performed in 35 C57BL/6 mice and two hybrid C57BL/6 × 129S1/SvImJ F2 mice. Eye coil and video-oculography recordings were made in an additional nine C57BL/6 mice. All procedures were approved by Stanford University’s Administrative Panel on Laboratory Animal Care.</p></sec><sec id="s4-2"><title>Surgery</title><p>A plastic head post was secured to the skull with three screws and dental cement, for use in immobilizing the head. In most animals, a magnet was implanted in one or both eyes. Different magnets were assessed. Most mice were implanted with two neodymium magnets of size 0.75 × 1 mm (diameter × height, grade N50, axially magnetized, SuperMagnetMan.com), which were stacked end-to-end for a total size of 0.75 × 2 mm (weight: 6.8 mg). These magnets were coated in the biocompatible polymer parylene. The magnetic force firmly held the two magnets together, and the resulting shape is referred to as the ‘cylinder magnet’. Cylinder magnets were implanted in a single eye in 24 mice, and bilaterally in an additional seven mice. Mice were excluded from the analysis if reliable video-oculography was not possible following implantation due to scarring on the surface of the eye, or if an eye movement gain of less than 0.1 was recorded by the magnetic sensor during calibration, suggesting that the magnet-sensor alignment was inadequate. A 1.5 × 0.5 mm disc magnet was implanted in four additional mice, and performed similarly (data not shown). In pilot experiments, a smaller, 1.0 × 0.5 mm disc magnet was implanted in two mice, however, because the signals recorded using these magnets were very small (data not shown), we discontinued their use. Magnets were implanted following a procedure similar to that described previously for eye coil implantation (<xref ref-type="bibr" rid="bib7">Boyden and Raymond, 2003</xref>). The conjunctiva was blunt dissected to form a pocket on the temporal side of the eye, slightly dorsal to the midline of the eye and anterior to the lateral rectus muscle. The magnet was inserted into this pocket using non-magnetic forceps (Dumoxel #5, FST) and the pocket was sealed shut with VetBond. To minimize any chance of obstructing or otherwise affecting vision, care was taken to implant the magnet well away from the cornea and to restrict the VetBond to the area surrounding the magnet. The cylinder magnet was implanted with the N-S axis aligned roughly perpendicular to the axis about which the eye rotates during horizontal (nasal-temporal) eye movements (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The disc magnet was implanted flat on the surface of the eye, with the N-S axis pointing towards the eye’s center.</p><p>An angular magnetic field sensor (HMC1512, Honeywell Inc., size: 4.8 × 5.8 mm; weight: 76 mg) was secured to the skull above the eye using dental cement anchored to the same skull screws as were used to secure the head post. The HMC1512 sensor converts the direction of an external magnetic field into an analog voltage output. The magnetic field is sensed by anisotropic magnetoresistive (AMR) elements, which change their electrical resistance according to the angle <italic>θ</italic><sub>m</sub> of an applied magnetic field. Each set of AMR elements is configured as a Wheatstone bridge to produce a differential voltage proportional to sin(2<italic>θ<sub>m</sub></italic>). The HMC1512 contains two sets of AMR elements, rotated by 45° relative to each other.</p><p>The magnetic sensor was affixed to the skull above the implanted magnet, with its surface in a plane roughly parallel to the nasal-temporal axis of the eye and to the N-S axis of the implanted magnet (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). This positioning allowed detection of horizontal eye movements. The sensor was positioned as close as possible to the eye (2.7 ± 0.2 mm, n = 8 mice, distance from the bottom surface of the sensor to the nasal-temporal axis defined by the two corners of the eye).</p><p>In seven mice, magnets and magnetic sensors were implanted in both eyes. To assess cross-talk between a magnet in one eye and the sensor above the opposite eye, three of these mice were first implanted with a magnet in the left eye alone, with sensors above both eyes. A magnet was later implanted in the right eye as well.</p><p>In nine mice, eye coil implantation was performed as described previously (<xref ref-type="bibr" rid="bib7">Boyden and Raymond, 2003</xref>). Recordings from all mice were made after at least five days of recovery from surgery.</p></sec><sec id="s4-3"><title>Data acquisition</title><p>Differential outputs from the two magnetic sensor channels were amplified 60x by a custom preamplifier (David Profitt Engineering Services, Los Altos, CA), then digitized and stored using a Power1401 A-D converter with Spike2 software (Cambridge Electronic Design, Cambridge, England). Connections from the sensor to the amplifier were formed via an 8-pin right angle connector (Digi-Key: 609-3694-1-ND, pins; 609-3705-1-ND, socket), which could be rapidly soldered to the sensor without the need for extra wiring (total weight of sensor, solder, and connector: 180.4 mg). Magnet and eye coil data were digitally filtered with an identical 100 Hz low-pass Butterworth filter.</p></sec><sec id="s4-4"><title>Magnetic sensor testing outside the animal</title><p>Performance of different magnet-sensor configurations was first assessed outside the mouse. Magnet angle was precisely controlled using a servo-controlled turntable (angular resolution 0.053°, standard deviation at rest), and the position of the magnet relative to the sensor was controlled with a micromanipulator (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Repeated measurements were performed by removing the magnet from the apparatus and then repositioning it. Signal strength was compared across magnet-sensor configurations by calculating the sensitivity of the magnetic sensor to the angular position of the magnet, in mV/°. For each channel of the magnetic sensor, sensitivity was averaged in a ± 22.5° range around each zero crossing of that channel’s output.</p></sec><sec id="s4-5"><title>Magnetic eye tracking in head-fixed mice</title><p>To assess performance of the magnet-sensor system after implantation in mice, eye movements were elicited with vestibular and visual stimuli in head-fixed mice. The head of the mouse was restrained, via the surgically implanted head post, in a natural position with the nose tilted down approximately 30° relative to the stereotaxic plane, which put the nasal-temporal axis of the eye in a roughly earth-horizontal plane. To elicit horizontal eye movements, vestibular stimuli were delivered by a servo-controlled turntable (Ideal Aerosmith, Inc.) that rotated the mouse about an earth-vertical axis. During the freely moving experiments (<xref ref-type="fig" rid="fig7">Figure 7</xref>), the stationary drum surrounding the animal had black and white stripes, each subtending 7° of visual angle. For OKR measurements (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>), the drum was patterned with a random checkerboard, each square colored black or white with 50% probability and subtending 3° of visual angle. The vestibular and visual stimuli had sinusoidal motion profiles, at frequencies of 0.2, 0.5, 1, 2, or 5 Hz, with ±10°/s peak velocity. The gain of the eye movements driven by the vestibular and visual stimuli was calculated by dividing the amplitude of a sinusoidal fit to the eye velocity response by the amplitude of the stimulus (10°/s).</p></sec><sec id="s4-6"><title>Magnetic sensor calibration</title><p>Magnetic eye tracking requires calibration to convert the raw voltage signals from the magnetic sensor into eye position in degrees. Calibration was performed for each mouse by comparing signals from the magnetic sensor with eye movements recorded using a dual-angle video-oculography system developed for this purpose and described below. Once calibrated, the magnetic sensor could then be used alone, without the video system, allowing for testing in complete darkness, with higher temporal resolution, and while the mouse was freely moving.</p><p>During a calibration session, video frames and magnetic sensor voltages were collected simultaneously while eye movements were elicited in awake, head-fixed mice using a sinusoidal vestibular stimulus in the light (0.5 Hz or 1 Hz, ±10°/s peak velocity; <xref ref-type="fig" rid="fig4">Figure 4</xref>). Video frames were analyzed as described below to extract horizontal eye position. The vestibular stimulus and raw voltage traces from the magnetic sensor were recorded in Spike2 (CED, Cambridge, England). An infrared LED, driven by a TTL signal generated and recorded in Spike2, delivered 30 ms flashes of light at 1 Hz during the calibration session for use in aligning video and magnet traces.</p><p>Eye position data derived from the video recordings were upsampled to match the magnetic sensor data, and then differentiated by calculating the slope in a 50 ms sliding window to obtain eye velocity. Uncalibrated magnet data were differentiated in the same manner. An automatic velocity-threshold algorithm (video threshold: 50°/s, magnet threshold: 5 mV/ms) was used to detect saccades and motion artifacts in the video and magnet data. Time segments that were marked for removal in either the video data or the magnet data were excluded from both traces during further analysis.</p><p>The signals from the magnetic sensor were calibrated by comparing them with either eye position or eye velocity signals derived from the video recordings. To calibrate using eye position, the eye position recorded by the video was linearly regressed on the voltage signals from the magnetic sensor. Three possible choices for the set of explanatory variables in the regression were compared (<xref ref-type="fig" rid="fig4">Figure 4B,C</xref>).</p><p>The simplest option was to estimate eye position using each of the two magnetic sensor channels, one at a time:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mtext> </mml:mtext><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>2</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>1</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>2</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are the calibrated eye positions estimated fromy each channel, <inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> are the voltages recorded by the two magnetic sensor channels, and <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the model parameters. <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> correspond to the calibration factor for each channel, and <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf12"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to the offset. The channel that was more strongly correlated with the video-derived eye position was then selected for further analysis.</p><p>A second method for calibrating the eye position-related signals from the magnetic sensor was to fit the video-derived eye position using both magnetic sensor channels simultaneously:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To avoid overfitting, given the likelihood of correlated signals between the two channels, an L2 regularization penalty was applied to penalize model parameters with large weight (ridge regression). Ten-fold cross-validation was used to select the regularization parameter that minimized squared error on the held-out data. Once the regularization parameter was thus obtained, the regression was then run on all calibration data to yield the final model parameters <inline-formula><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>A third method for converting the signals from the magnetic sensor to an estimate of eye position included quadratic terms, to try to improve the fit should the eye position fall in a non-linear portion of the output from both channels of the sensor:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow/><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This quadratic regression was cross-validated with ridge regression as described above.</p><p>The recordings from the magnetic sensor could also be calibrated using signals related to eye velocity rather than eye position. The video and magnetic sensor signals related to eye position were differentiated using a 50 ms sliding window and then fit by sine waves, yielding a video-derived signal amplitude <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (in units of °/s), and magnetic sensor-derived amplitudes <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (in units of mV/s) for each sensor channel. The sensor channel with the higher r<sup>2</sup> from the fit to a sine wave was selected, and its differentiated output <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> was converted to eye velocity <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> using a calibration factor obtained from the ratio of <inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf20"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Overall, the calibration procedure added less than 10 min, and typically less than 5 min, to the experiment. The procedure includes placing the mouse in the head restraint (1–2 min), positioning the video cameras (1–3 min), data collection (1–3 min), and adjustment of video-oculography software parameters (0–2 min). Once calibration was complete, the video cameras were removed from the experimental setup.</p></sec><sec id="s4-7"><title>Analysis of spatial resolution</title><p>To compare the spatial resolution of the magnetic eye tracking and eye coil techniques, calibrated eye position signals were recorded while the mouse was head-fixed in the light. Two-second epochs when the eye movements were minimal were selected for analysis. Spatial resolution was calculated as the standard deviation of eye position during each stationary epoch, with three epochs selected and averaged for each mouse.</p></sec><sec id="s4-8"><title>Magnetic eye tracking in freely moving mice</title><p>Seven mice implanted bilaterally with magnets and sensors were allowed to freely explore a 12&quot; circular arena for 10–15 min (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The stationary arena was surrounded by a stationary, illuminated, vertically-striped drum. To quantify whether the mouse’s body was actively moving or relatively still, an overhead video acquired infrared images of the mouse in the arena. A motion index was calculated by first subtracting an average background image from all frames, and then quantifying the mean absolute difference in pixel values between each frame and the next. The resulting motion trace was smoothed with a 2 s moving average to create a motion index. The upper third of motion index values were classified as ‘Active’, and the lower third were classified as ‘Still’. Eye position variability and mean eye speed measured in both eyes of a given mouse were first averaged together before comparing the population means.</p><p>To measure head movements in freely moving mice, a lightweight (1.8 g) six degree-of-freedom inertial measurement unit (SEN-10121, Sparkfun Electronics) was attached to the mouse’s headpost with a screw. Roll, pitch, and yaw angles were converted into analog signals using an Arduino Mega (Arduino AG) and recorded simultaneously with eye position in Spike2.</p></sec><sec id="s4-9"><title>Dual-angle video-oculography</title><p>We developed a dual-angle video-oculography system for use in calibrating the magnetic eye tracking system. This system was designed to improve upon previous video-oculography systems in terms of accuracy, cost, and speed of use. The infrared-blocking filter was removed from two web cameras (Logitech C310) and replaced with a visible light-blocking filter. Small infrared LEDs (875 nm, radiant power 20 mW, angle of half intensity 20°, TSHA4400, Digi-Key) were positioned above each camera to create two corneal reflections (CRs), one for each camera, appearing along the radius of the cornea parallel to the axis of the camera.</p><p>The dual-angle system depends on two conditions. First, the two cameras must be fixed at a known angle relative to each other, for use in the calculation below. Second, they must be equidistant from the eye, so that the images from the two cameras have the same spatial scale. To achieve these requirements, the cameras were fixed to a platform separated by an angle of 40°, with each lens equidistant (in our setup, A = 5 cm) from a small placeholder target. Correct positioning was confirmed by verifying that the image of the target was the same size in the two cameras, and appeared at the horizontal midpoint of each camera’s image. For use in mice, the placeholder target was removed, and the entire platform was positioned so that the pupil appeared roughly centered between the two CRs, to ensure that the pupil remained fully in the image when the eye rotated. The position of the platform was further adjusted so that for each camera, the CR generated by that camera’s infrared LED appeared at the center of the h camera’s image (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), and the camera platform was then fixed in place. This ensured that the center of the eye’s corneal curvature was close to the point at which the two camera axes intersected, thus placing each camera equidistant from the eye as required by the configuration of the platform.</p><p>The pupil was visualized by illuminating the cornea with infrared light, which causes the pupil to appear dark (<xref ref-type="bibr" rid="bib19">DiScenna et al., 1995</xref>; <xref ref-type="bibr" rid="bib39">Kaufman, 2002</xref>; <xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>). Sufficient contrast of the pupil relative to the cornea was provided by the two infrared LEDs used to create the CRs. Most measurements with video-oculography were conducted with additional, visible light, which constricted the pupil sufficiently to provide a clear image of pupil boundaries. A few video-oculography experiments were conducted in low light conditions, with only the two infrared LEDs (<xref ref-type="fig" rid="fig6">Figure 6</xref>), which caused the pupil to dilate and become occluded by the eyelid. To constrict the pupil for these recordings, a single drop of 4% pilocarpine (Henry Schein, Melville, NY) was placed on the eye 3–5 min before the experiment.</p><p>Images were acquired in MATLAB (The MathWorks, Inc., Natick, MA) at 30 frames per second, and were analyzed offline. The locations of the pupil center (P) and CRs in the images were extracted using modified code from OpenEyes, an open source eye tracking library (www.‌thirtysixthspan.com‌/openEyes). OpenEyes uses the Starburst algorithm to locate the pupil edges (<xref ref-type="bibr" rid="bib51">Li and Parkhurst, 2006</xref>). We modified the code by employing a Hough transform, a feature extraction technique, to provide more accurate CR localization. The CRs were then masked before processing the pupil image to avoid false detection of pupil edges. Code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hpay/eyetrack">https://github.com/hpay/eyetrack</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/eyetrack">https://github.com/elifesciences-publications/eyetrack</ext-link><ext-link ext-link-type="uri" xlink:href="https://github.com/hpay/eyetrack">)</ext-link>.</p><p>The locations of the pupil and reference CRs in the images were used to calculate eye position by leveraging the geometry of the dual-angle setup. In each camera’s image, motion of the pupil location is due to both rotation and translation of the eye relative to the camera. The component of this motion attributable to rotation alone can be isolated by subtracting the CR location from the pupil location, to yield the distances <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>). Because the CR always appears on the radius of the cornea parallel to the axis of the camera, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are invariant to translations of the eye relative to the camera (<xref ref-type="bibr" rid="bib80">Stahl et al., 2000</xref>).</p><p>The distances between the pupil and the reference CRs are related to angular eye position by:<disp-formula id="equ5"><label>(5a)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><label>(6b)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the angles from the axis of the respective camera to the axis of the pupil (the line connecting the center of the pupil (P) to the center of corneal curvature (C); <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> both defined to be positive as drawn in <xref ref-type="fig" rid="fig3">Figure 3A</xref>), and <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the distance from the plane of the pupil to the center of corneal curvature (point C in <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Taking the ratio of the two distances eliminates <italic>R<sub>p</sub></italic>:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf28"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>40</mml:mn><mml:mo>°</mml:mo></mml:mrow></mml:math></inline-formula>,<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mn>40</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Using the trigonometric identity for angle subtraction and rearranging yields a formula for calculating angular eye position:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>atan</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mn>40</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mn>40</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In lieu of two cameras, a similar procedure could be implemented with a single camera, by using either angled mirrors or prisms to capture images of the eye from two distinct angles.</p><p>The video system was validated by anesthetizing two mice with ketamine (60 mg/kg)+dexmedetomidine (1 mg/kg) and physically rotating the two-camera platform via a mechanical arm that rotated about a vertical axis aligned with the mouse’s eye. At each location, five frames were captured and the resulting measurements were averaged (<xref ref-type="fig" rid="fig3">Figure 3C</xref>).</p></sec><sec id="s4-10"><title>Statistical analysis</title><p>Mean ± SEM is reported for all confidence intervals. Statistical tests were conducted using Matlab. All tests were two-tailed. Two sample <italic>t</italic>-tests were used to determine if there was a difference between two groups. Paired <italic>t</italic>-tests were used to determine if a significant change occurred at different times or behavioral conditions within the same animal. To assess changes in oculomotor responses after magnet implantation, a two-way repeated measures ANOVA was conducted, with stimulus frequency and time (before vs. after magnet implantation) as factors (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The significance level for all statistical tests was set at p&lt;0.05. The Lilliefors test (Matlab) was used to assess normality of the data. Based on this test, all data included in the statistical tests were deemed to have been sampled from a normal distribution.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We gratefully acknowledge Jason Schwarz and Eric Knudsen for their technical assistance, Bob Schneevis for construction of custom apparatus, and Aparna Suvrathan, Pragna Gaddam, Matthew Rienzo, and Donald Payne for helpful discussion and comments on the manuscript. Funding was provided by NIH R21 EY026152 (JLR) and a grant from the Simons Foundation/SFARI (543031, JLR).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures complied with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. Animals were handled strictly according the institutional animal care and use committee (IACUC) at Stanford University, accredited by the Association for Assessment and Accreditation of Laboratory Animal Care International (AAALAC). Protocols were approved by the Administrative Panel on Laboratory Animal Care at Stanford University (protocol #9143). All surgery was performed under isoflurane anesthesia, and every effort was made to minimize animal suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.29222.012</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-29222-transrepform-v1.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arden</surname> <given-names>GB</given-names></name><name><surname>Kelsey</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Changes produced by light in the standing potential of the human eye</article-title><source>The Journal of Physiology</source><volume>161</volume><fpage>189</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006881</pub-id><pub-id pub-id-type="pmid">13862112</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avanzini</surname> <given-names>G</given-names></name><name><surname>Girotti</surname> <given-names>F</given-names></name><name><surname>Caraceni</surname> <given-names>T</given-names></name><name><surname>Spreafico</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Oculomotor disorders in huntington's chorea</article-title><source>Journal of Neurology, Neurosurgery &amp; Psychiatry</source><volume>42</volume><fpage>581</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1136/jnnp.42.7.581</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barretto</surname> <given-names>RP</given-names></name><name><surname>Messerschmidt</surname> <given-names>B</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>In vivo fluorescence imaging with high-resolution microlenses</article-title><source>Nature methods</source><volume>6</volume><fpage>511</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1339</pub-id><pub-id pub-id-type="pmid">19525959</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beery</surname> <given-names>AK</given-names></name><name><surname>Zucker</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Sex bias in neuroscience and biomedical research</article-title><source>Neuroscience and biobehavioral reviews</source><volume>35</volume><fpage>565</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2010.07.002</pub-id><pub-id pub-id-type="pmid">20620164</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belton</surname> <given-names>T</given-names></name><name><surname>McCrea</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Contribution of the cerebellar flocculus to gaze control during active head movements</article-title><source>Journal of Neurophysiology</source><volume>81</volume><fpage>3105</fpage><lpage>3109</lpage><pub-id pub-id-type="pmid">10368427</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyden</surname> <given-names>ES</given-names></name><name><surname>Katoh</surname> <given-names>A</given-names></name><name><surname>Pyle</surname> <given-names>JL</given-names></name><name><surname>Chatila</surname> <given-names>TA</given-names></name><name><surname>Tsien</surname> <given-names>RW</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Selective engagement of plasticity mechanisms for motor memory storage</article-title><source>Neuron</source><volume>51</volume><fpage>823</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.026</pub-id><pub-id pub-id-type="pmid">16982426</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyden</surname> <given-names>ES</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Active reversal of motor memories reveals rules governing memory encoding</article-title><source>Neuron</source><volume>39</volume><fpage>1031</fpage><lpage>1042</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00562-2</pub-id><pub-id pub-id-type="pmid">12971901</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carriot</surname> <given-names>J</given-names></name><name><surname>Jamali</surname> <given-names>M</given-names></name><name><surname>Chacron</surname> <given-names>MJ</given-names></name><name><surname>Cullen</surname> <given-names>KE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Statistics of the vestibular input experienced during natural self-motion: implications for neural processing</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>8347</fpage><lpage>8357</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0692-14.2014</pub-id><pub-id pub-id-type="pmid">24920638</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chapillon</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Very brief exposure to visual distal cues is sufficient for young mice to navigate in the Morris water maze</article-title><source>Behavioural processes</source><volume>46</volume><fpage>15</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/S0376-6357(98)00057-6</pub-id><pub-id pub-id-type="pmid">24925495</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname> <given-names>A</given-names></name><name><surname>Hallett</surname> <given-names>PE</given-names></name><name><surname>Parker</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Aspheric curvatures, refractive indices and chromatic aberration for the rat eye</article-title><source>Vision Research</source><volume>23</volume><fpage>1351</fpage><lpage>1363</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(83)90146-3</pub-id><pub-id pub-id-type="pmid">6666037</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>King</surname> <given-names>JA</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>O’Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>How vision and movement combine in the hippocampal place code</article-title><source>PNAS</source><volume>110</volume><fpage>378</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215834110</pub-id><pub-id pub-id-type="pmid">23256159</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>JL</given-names></name><name><surname>Andermann</surname> <given-names>ML</given-names></name><name><surname>Keck</surname> <given-names>T</given-names></name><name><surname>Xu</surname> <given-names>NL</given-names></name><name><surname>Ziv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Imaging neuronal populations in behaving rodents: paradigms for studying neural circuits underlying behavior in the mammalian cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>17631</fpage><lpage>17640</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3255-13.2013</pub-id><pub-id pub-id-type="pmid">24198355</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Singing on the fly: sensorimotor integration and acoustic communication in Drosophila</article-title><source>Current opinion in neurobiology</source><volume>38</volume><fpage>38</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.013</pub-id><pub-id pub-id-type="pmid">26874218</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collewijn</surname> <given-names>H</given-names></name><name><surname>van der Mark</surname> <given-names>F</given-names></name><name><surname>Jansen</surname> <given-names>TC</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Precise recording of human eye movements</article-title><source>Vision Research</source><volume>15</volume><fpage>447</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(75)90098-X</pub-id><pub-id pub-id-type="pmid">1136166</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collewijn</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Eye- and head movements in freely moving rabbits</article-title><source>The Journal of Physiology</source><volume>266</volume><fpage>471</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1977.sp011778</pub-id><pub-id pub-id-type="pmid">857007</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeJong</surname> <given-names>JD</given-names></name><name><surname>Jones</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Akinesia, hypokinesia, and bradykinesia in the oculomotor system of patients with Parkinson's disease</article-title><source>Experimental Neurology</source><volume>32</volume><fpage>58</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(71)90165-8</pub-id><pub-id pub-id-type="pmid">5095610</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devito</surname> <given-names>LM</given-names></name><name><surname>Eichenbaum</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Memory for the order of events in specific sequences: contributions of the hippocampus and medial prefrontal cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>3169</fpage><lpage>3175</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4202-10.2011</pub-id><pub-id pub-id-type="pmid">21368028</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiScenna</surname> <given-names>AO</given-names></name><name><surname>Das</surname> <given-names>V</given-names></name><name><surname>Zivotofsky</surname> <given-names>AZ</given-names></name><name><surname>Seidman</surname> <given-names>SH</given-names></name><name><surname>Leigh</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Evaluation of a video tracking device for measurement of horizontal and vertical eye rotations during locomotion</article-title><source>Journal of Neuroscience Methods</source><volume>58</volume><fpage>89</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/0165-0270(94)00162-A</pub-id><pub-id pub-id-type="pmid">7475237</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duhamel</surname> <given-names>JR</given-names></name><name><surname>Colby</surname> <given-names>CL</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The updating of the representation of visual space in parietal cortex by intended eye movements</article-title><source>Science</source><volume>255</volume><fpage>90</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1126/science.1553535</pub-id><pub-id pub-id-type="pmid">1553535</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Bialek</surname> <given-names>M</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A cortical substrate for memory-guided orienting in the rat</article-title><source>Neuron</source><volume>72</volume><fpage>330</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.010</pub-id><pub-id pub-id-type="pmid">22017991</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Nakashima</surname> <given-names>R</given-names></name><name><surname>Matsumiya</surname> <given-names>K</given-names></name><name><surname>Kuriki</surname> <given-names>I</given-names></name><name><surname>Shioiri</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Eye-head coordination for visual cognitive processing</article-title><source>PLoS One</source><volume>10</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0121035</pub-id><pub-id pub-id-type="pmid">25799510</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flusberg</surname> <given-names>BA</given-names></name><name><surname>Nimmerjahn</surname> <given-names>A</given-names></name><name><surname>Cocker</surname> <given-names>ED</given-names></name><name><surname>Mukamel</surname> <given-names>EA</given-names></name><name><surname>Barretto</surname> <given-names>RP</given-names></name><name><surname>Ko</surname> <given-names>TH</given-names></name><name><surname>Burns</surname> <given-names>LD</given-names></name><name><surname>Jung</surname> <given-names>JC</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>High-speed, miniaturized fluorescence microscopy in freely moving mice</article-title><source>Nature Methods</source><volume>5</volume><fpage>935</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1256</pub-id><pub-id pub-id-type="pmid">18836457</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname> <given-names>EG</given-names></name><name><surname>Sparks</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Eye-head coordination during head-unrestrained gaze shifts in rhesus monkeys</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2328</fpage><lpage>2348</lpage><pub-id pub-id-type="pmid">9163361</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuller</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Head movement propensity</article-title><source>Experimental Brain Research</source><volume>92</volume><fpage>152</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1007/BF00230391</pub-id><pub-id pub-id-type="pmid">1486950</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Grid cells in mice</article-title><source>Hippocampus</source><volume>18</volume><fpage>1230</fpage><lpage>1238</lpage><pub-id pub-id-type="doi">10.1002/hipo.20472</pub-id><pub-id pub-id-type="pmid">18683845</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goulding</surname> <given-names>EH</given-names></name><name><surname>Schenk</surname> <given-names>AK</given-names></name><name><surname>Juneja</surname> <given-names>P</given-names></name><name><surname>MacKay</surname> <given-names>AW</given-names></name><name><surname>Wade</surname> <given-names>JM</given-names></name><name><surname>Tecott</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A robust automated system elucidates mouse home cage behavioral structure</article-title><source>PNAS</source><volume>105</volume><fpage>20575</fpage><lpage>20582</lpage><pub-id pub-id-type="doi">10.1073/pnas.0809053106</pub-id><pub-id pub-id-type="pmid">19106295</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Maheswaranathan</surname> <given-names>N</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Maheswaranathan</surname> <given-names>N</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex</article-title><source>Neuron</source><volume>94</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.025</pub-id><pub-id pub-id-type="pmid">28392071</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holzman</surname> <given-names>PS</given-names></name><name><surname>Levy</surname> <given-names>DL</given-names></name><name><surname>Proctor</surname> <given-names>LR</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Smooth pursuit eye movements, attention, and schizophrenia</article-title><source>Archives of General Psychiatry</source><volume>33</volume><fpage>1415</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1001/archpsyc.1976.01770120019001</pub-id><pub-id pub-id-type="pmid">999447</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopkins</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>Distance perception in mus musculus</article-title><source>Journal of Mammalogy</source><volume>34</volume><elocation-id>393</elocation-id><pub-id pub-id-type="doi">10.1093/jmammal/34.3.393</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houben</surname> <given-names>MM</given-names></name><name><surname>Goumans</surname> <given-names>J</given-names></name><name><surname>van der Steen</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Recording three-dimensional eye movements: scleral search coils versus video oculography</article-title><source>Investigative ophthalmology &amp; visual science</source><volume>47</volume><fpage>179</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1167/iovs.05-0234</pub-id><pub-id pub-id-type="pmid">16384960</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>A schematic eye for the rabbit</article-title><source>Vision Research</source><volume>12</volume><fpage>123</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(72)90143-5</pub-id><pub-id pub-id-type="pmid">5034626</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwashita</surname> <given-names>M</given-names></name><name><surname>Kanai</surname> <given-names>R</given-names></name><name><surname>Funabiki</surname> <given-names>K</given-names></name><name><surname>Matsuda</surname> <given-names>K</given-names></name><name><surname>Hirano</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamic properties, interactions and adaptive modifications of vestibulo-ocular reflex and optokinetic response in mice</article-title><source>Neuroscience Research</source><volume>39</volume><fpage>299</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1016/S0168-0102(00)00228-5</pub-id><pub-id pub-id-type="pmid">11248370</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname> <given-names>S</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mice and rats achieve similar levels of performance in an adaptive decision-making task</article-title><source>Frontiers in Systems Neuroscience</source><volume>8</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.3389/fnsys.2014.00173</pub-id><pub-id pub-id-type="pmid">25278849</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jennings</surname> <given-names>JH</given-names></name><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>Stamatakis</surname> <given-names>AM</given-names></name><name><surname>Taylor</surname> <given-names>JG</given-names></name><name><surname>Huang</surname> <given-names>J</given-names></name><name><surname>Veleta</surname> <given-names>K</given-names></name><name><surname>Kantak</surname> <given-names>PA</given-names></name><name><surname>Aita</surname> <given-names>M</given-names></name><name><surname>Shilling-Scrivo</surname> <given-names>K</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Otte</surname> <given-names>S</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visualizing hypothalamic network dynamics for appetitive and consummatory behaviors</article-title><source>Cell</source><volume>160</volume><fpage>516</fpage><lpage>527</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.12.026</pub-id><pub-id pub-id-type="pmid">25635459</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Judge</surname> <given-names>SJ</given-names></name><name><surname>Richmond</surname> <given-names>BJ</given-names></name><name><surname>Chu</surname> <given-names>FC</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Implantation of magnetic search coils for measurement of eye position: an improved method</article-title><source>Vision Research</source><volume>20</volume><fpage>535</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(80)90128-5</pub-id><pub-id pub-id-type="pmid">6776685</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katoh</surname> <given-names>A</given-names></name><name><surname>Chapman</surname> <given-names>PJ</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Disruption of learned timing in P/Q calcium channel mutants</article-title><source>PLoS One</source><volume>3</volume><elocation-id>e3635</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0003635</pub-id><pub-id pub-id-type="pmid">18982062</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katoh</surname> <given-names>A</given-names></name><name><surname>Kitazawa</surname> <given-names>H</given-names></name><name><surname>Itohara</surname> <given-names>S</given-names></name><name><surname>Nagao</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Dynamic characteristics and adaptability of mouse vestibulo-ocular and optokinetic response eye movements and the role of the flocculo-olivary system revealed by chemical lesions</article-title><source>PNAS</source><volume>95</volume><fpage>7705</fpage><lpage>7710</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.13.7705</pub-id><pub-id pub-id-type="pmid">9636214</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Video-oculography in the gerbil</article-title><source>Brain Research</source><volume>958</volume><fpage>472</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(02)03557-6</pub-id><pub-id pub-id-type="pmid">12470888</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Zariwala</surname> <given-names>HA</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><volume>455</volume><fpage>227</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature07200</pub-id><pub-id pub-id-type="pmid">18690210</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimmel</surname> <given-names>DL</given-names></name><name><surname>Mammo</surname> <given-names>D</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Tracking the eye non-invasively: simultaneous comparison of the scleral search coil and optical tracking techniques in the macaque monkey</article-title><source>Frontiers in behavioral neuroscience</source><volume>6</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3389/fnbeh.2012.00049</pub-id><pub-id pub-id-type="pmid">22912608</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimpo</surname> <given-names>RR</given-names></name><name><surname>Boyden</surname> <given-names>ES</given-names></name><name><surname>Katoh</surname> <given-names>A</given-names></name><name><surname>Ke</surname> <given-names>MC</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Distinct patterns of stimulus generalization of increases and decreases in VOR gain</article-title><source>Journal of neurophysiology</source><volume>94</volume><fpage>3092</fpage><lpage>3100</lpage><pub-id pub-id-type="doi">10.1152/jn.00048.2005</pub-id><pub-id pub-id-type="pmid">16033945</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimpo</surname> <given-names>RR</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Impaired motor learning in the vestibulo-ocular reflex in mice with multiple climbing fiber input to cerebellar Purkinje cells</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>5672</fpage><lpage>5682</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0801-07.2007</pub-id><pub-id pub-id-type="pmid">17522312</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimpo</surname> <given-names>RR</given-names></name><name><surname>Rinaldi</surname> <given-names>JM</given-names></name><name><surname>Kim</surname> <given-names>CK</given-names></name><name><surname>Payne</surname> <given-names>HL</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Gating of neural error signals during motor learning</article-title><source>eLife</source><volume>3</volume><elocation-id>e02076</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02076</pub-id><pub-id pub-id-type="pmid">24755290</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koekkoek</surname> <given-names>SK</given-names></name><name><surname>v Alphen</surname> <given-names>AM</given-names></name><name><surname>vd Burg</surname> <given-names>J</given-names></name><name><surname>Grosveld</surname> <given-names>F</given-names></name><name><surname>Galjart</surname> <given-names>N</given-names></name><name><surname>De Zeeuw</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Gain adaptation and phase dynamics of compensatory eye movements in mice</article-title><source>Genes and Function</source><volume>1</volume><fpage>175</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1046/j.1365-4624.1997.00018.x</pub-id><pub-id pub-id-type="pmid">9680293</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koyama</surname> <given-names>M</given-names></name><name><surname>Hasegawa</surname> <given-names>I</given-names></name><name><surname>Osada</surname> <given-names>T</given-names></name><name><surname>Adachi</surname> <given-names>Y</given-names></name><name><surname>Nakahara</surname> <given-names>K</given-names></name><name><surname>Miyashita</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Functional magnetic resonance imaging of macaque monkeys performing visually guided saccade tasks: comparison of cortical eye fields with humans</article-title><source>Neuron</source><volume>41</volume><fpage>795</fpage><lpage>807</lpage><pub-id pub-id-type="pmid">15003178</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kretschmer</surname> <given-names>F</given-names></name><name><surname>Tariq</surname> <given-names>M</given-names></name><name><surname>Chatila</surname> <given-names>W</given-names></name><name><surname>Wu</surname> <given-names>B</given-names></name><name><surname>Badea</surname> <given-names>TC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Comparison of optomotor and optokinetic reflexes in mice</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>300</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1152/jn.00055.2017</pub-id><pub-id pub-id-type="pmid">28424291</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kustov</surname> <given-names>AA</given-names></name><name><surname>Robinson</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Shared neural control of attentional shifts and eye movements</article-title><source>Nature</source><volume>384</volume><fpage>74</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1038/384074a0</pub-id><pub-id pub-id-type="pmid">8900281</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Land</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Eye movements of vertebrates and their relation to eye form and function</article-title><source>Journal of Comparative Physiology A</source><volume>201</volume><fpage>195</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1007/s00359-014-0964-5</pub-id><pub-id pub-id-type="pmid">25398576</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenz</surname> <given-names>J</given-names></name><name><surname>Edelstein</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Magnetic sensors and their applications</article-title><source>IEEE Sensors Journal</source><volume>6</volume><fpage>631</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1109/jsen.2006.874493</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>D</given-names></name><name><surname>Parkhurst</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Open-source software for real-time visible-spectrum eye tracking</article-title><conf-name>Proceedings of the COGAIN Conference</conf-name><conf-loc>Turin: Italy</conf-loc><fpage>1</fpage><lpage>3</lpage></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Licata</surname> <given-names>AM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Ryan</surname> <given-names>MB</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Posterior parietal cortex guides visual decisions in rats</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>105</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0105-17.2017</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machado</surname> <given-names>AS</given-names></name><name><surname>Darmohray</surname> <given-names>DM</given-names></name><name><surname>Fayad</surname> <given-names>J</given-names></name><name><surname>Marques</surname> <given-names>HG</given-names></name><name><surname>Carey</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A quantitative framework for whole-body coordination reveals specific deficits in freely walking ataxic mice</article-title><source>eLife</source><volume>4</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.7554/eLife.07892</pub-id><pub-id pub-id-type="pmid">26433022</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackintosh</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Factors affecting the recognition of territory boundaries by mice (Mus musculus)</article-title><source>Animal Behaviour</source><volume>21</volume><fpage>464</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(73)80006-5</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mangini</surname> <given-names>NJ</given-names></name><name><surname>Vanable</surname> <given-names>JW</given-names></name><name><surname>Williams</surname> <given-names>MA</given-names></name><name><surname>Pinto</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The optokinetic nystagmus and ocular pigmentation of hypopigmented mouse mutants</article-title><source>The Journal of comparative neurology</source><volume>241</volume><fpage>191</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1002/cne.902410207</pub-id><pub-id pub-id-type="pmid">4067014</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname> <given-names>JG</given-names></name><name><surname>Baker</surname> <given-names>RR</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A demonstration of navigation by small rodents using an orientation cage</article-title><source>Nature</source><volume>284</volume><fpage>259</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1038/284259a0</pub-id><pub-id pub-id-type="pmid">6987529</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCamy</surname> <given-names>MB</given-names></name><name><surname>Otero-Millan</surname> <given-names>J</given-names></name><name><surname>Leigh</surname> <given-names>RJ</given-names></name><name><surname>King</surname> <given-names>SA</given-names></name><name><surname>Schneider</surname> <given-names>RM</given-names></name><name><surname>Macknik</surname> <given-names>SL</given-names></name><name><surname>Martinez-Conde</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Simultaneous recordings of human microsaccades and drifts with a contemporary video eye tracker and the search coil technique</article-title><source>PLoS One</source><volume>10</volume><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0128428</pub-id><pub-id pub-id-type="pmid">26035820</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medrea</surname> <given-names>I</given-names></name><name><surname>Cullen</surname> <given-names>KE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory integration in early vestibular processing in mice: the encoding of passive vs. active motion</article-title><source>Journal of neurophysiology</source><volume>110</volume><fpage>2704</fpage><lpage>2717</lpage><pub-id pub-id-type="doi">10.1152/jn.01037.2012</pub-id><pub-id pub-id-type="pmid">24089394</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchiner</surname> <given-names>JC</given-names></name><name><surname>Pinto</surname> <given-names>LH</given-names></name><name><surname>Vanable</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Visually evoked eye movements in the mouse (Mus musculus)</article-title><source>Vision Research</source><volume>16</volume><fpage>1169</fpage><lpage>1171</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(76)90258-3</pub-id><pub-id pub-id-type="pmid">969230</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Place cells, grid cells, and the brain's spatial representation system</article-title><source>Annual review of neuroscience</source><volume>31</volume><fpage>69</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id><pub-id pub-id-type="pmid">18284371</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ogorodnikov</surname> <given-names>D</given-names></name><name><surname>Tarasenko</surname> <given-names>S</given-names></name><name><surname>Yakushin</surname> <given-names>S</given-names></name><name><surname>Cohen</surname> <given-names>B</given-names></name><name><surname>Raphan</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Head fixed field coil system for measuring eye movements in freely moving monkeys</article-title><conf-name>In <italic>Proceedings of the 28th IEEE EMBS Annual International Conference</italic></conf-name><volume>1</volume><fpage>5567</fpage><lpage>5570</lpage></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olberg</surname> <given-names>RM</given-names></name><name><surname>Worthington</surname> <given-names>AH</given-names></name><name><surname>Venator</surname> <given-names>KR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Prey pursuit and interception in dragonflies</article-title><source>Journal of Comparative Physiology A: Sensory, Neural, and Behavioral Physiology</source><volume>186</volume><fpage>155</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1007/s003590050015</pub-id><pub-id pub-id-type="pmid">10707313</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname> <given-names>GT</given-names></name><name><surname>Alam</surname> <given-names>NM</given-names></name><name><surname>Beekman</surname> <given-names>S</given-names></name><name><surname>Douglas</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Rapid quantification of adult and developing mouse spatial vision using a virtual optomotor system</article-title><source>Investigative ophthalmology &amp; visual science</source><volume>45</volume><fpage>4611</fpage><lpage>4616</lpage><pub-id pub-id-type="doi">10.1167/iovs.04-0541</pub-id><pub-id pub-id-type="pmid">15557474</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Schrater</surname> <given-names>PR</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Multisensory decision-making in rats and humans</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>3726</fpage><lpage>3735</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4998-11.2012</pub-id><pub-id pub-id-type="pmid">22423093</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname> <given-names>JL</given-names></name><name><surname>Lisberger</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Behavioral analysis of signals that guide learned changes in the amplitude and dynamics of the vestibulo-ocular reflex</article-title><source>The Journal of Neuroscience : The Official Journal of the Society for Neuroscience</source><volume>16</volume><fpage>7791</fpage><lpage>7802</lpage><pub-id pub-id-type="pmid">8922435</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname> <given-names>J</given-names></name><name><surname>Froudarakis</surname> <given-names>E</given-names></name><name><surname>Cadwell</surname> <given-names>CR</given-names></name><name><surname>Yatsenko</surname> <given-names>D</given-names></name><name><surname>Denfield</surname> <given-names>GH</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title><source>Neuron</source><volume>84</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.033</pub-id><pub-id pub-id-type="pmid">25374359</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remmel</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>An inexpensive eye movement monitor using the scleral search coil technique</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>31</volume><fpage>388</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1109/TBME.1984.325352</pub-id><pub-id pub-id-type="pmid">6745975</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remtulla</surname> <given-names>S</given-names></name><name><surname>Hallett</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>A schematic eye for the mouse, and comparisons with the rat</article-title><source>Vision Research</source><volume>25</volume><fpage>21</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(85)90076-8</pub-id><pub-id pub-id-type="pmid">3984214</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>A method of measuring eye movement using a scleral search coil in a magnetic field</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>10</volume><fpage>137</fpage><lpage>145</lpage><pub-id pub-id-type="pmid">14121113</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez</surname> <given-names>F</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name><name><surname>Vargas</surname> <given-names>JP</given-names></name><name><surname>Torres</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Eye-movement recording in freely moving animals</article-title><source>Physiology &amp; Behavior</source><volume>72</volume><fpage>455</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/S0031-9384(00)00314-0</pub-id><pub-id pub-id-type="pmid">11282128</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenhall</surname> <given-names>U</given-names></name><name><surname>Johansson</surname> <given-names>E</given-names></name><name><surname>Gillberg</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Oculomotor findings in autistic children</article-title><source>The Journal of Laryngology &amp; Otology</source><volume>102</volume><fpage>435</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1017/S0022215100105286</pub-id><pub-id pub-id-type="pmid">3397639</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salas</surname> <given-names>C</given-names></name><name><surname>Torres</surname> <given-names>B</given-names></name><name><surname>Rodríguez</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>A method for measuring eye movements using Hall-effect devices</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>31</volume><fpage>353</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.3758/BF03207732</pub-id><pub-id pub-id-type="pmid">10495822</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integration of visual motion and locomotion in mouse visual cortex</article-title><source>Nature neuroscience</source><volume>16</volume><fpage>1864</fpage><lpage>1869</lpage><pub-id pub-id-type="doi">10.1038/nn.3567</pub-id><pub-id pub-id-type="pmid">24185423</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sánchez-López</surname> <given-names>Á</given-names></name><name><surname>Escudero</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>An accurate and portable eye movement detector for studying sleep in small animals</article-title><source>Journal of sleep research</source><volume>24</volume><fpage>466</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1111/jsr.12276</pub-id><pub-id pub-id-type="pmid">25590417</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>AH</given-names></name></person-group><year iso-8601-date="1940">1940</year><article-title>The size of the orbit and of the eye in primates</article-title><source>American Journal of Physical Anthropology</source><volume>26</volume><fpage>389</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1002/ajpa.1330260138</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname> <given-names>JS</given-names></name><name><surname>Sridharan</surname> <given-names>D</given-names></name><name><surname>Knudsen</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Magnetic tracking of eye position in freely behaving chickens</article-title><source>Frontiers in systems neuroscience</source><volume>7</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.3389/fnsys.2013.00091</pub-id><pub-id pub-id-type="pmid">24312023</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname> <given-names>SL</given-names></name><name><surname>Zhao</surname> <given-names>GQ</given-names></name><name><surname>Raymond</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Signals and learning rules guiding oculomotor plasticity</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>10635</fpage><lpage>10644</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4510-12.2014</pub-id><pub-id pub-id-type="pmid">25100597</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverman</surname> <given-names>JL</given-names></name><name><surname>Yang</surname> <given-names>M</given-names></name><name><surname>Lord</surname> <given-names>C</given-names></name><name><surname>Crawley</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Behavioural phenotyping assays for mouse models of autism</article-title><source>Nature reviews. Neuroscience</source><volume>11</volume><fpage>490</fpage><lpage>502</lpage><pub-id pub-id-type="doi">10.1038/nrn2851</pub-id><pub-id pub-id-type="pmid">20559336</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stahl</surname> <given-names>JS</given-names></name><name><surname>van Alphen</surname> <given-names>AM</given-names></name><name><surname>De Zeeuw</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A comparison of video and magnetic search coil recordings of mouse eye movements</article-title><source>Journal of Neuroscience Methods</source><volume>99</volume><fpage>101</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(00)00218-1</pub-id><pub-id pub-id-type="pmid">10936649</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tabata</surname> <given-names>H</given-names></name><name><surname>Shimizu</surname> <given-names>N</given-names></name><name><surname>Wada</surname> <given-names>Y</given-names></name><name><surname>Miura</surname> <given-names>K</given-names></name><name><surname>Kawano</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Initiation of the optokinetic response (OKR) in mice</article-title><source>Journal of vision</source><volume>10</volume><elocation-id>13.1-17</elocation-id><pub-id pub-id-type="doi">10.1167/10.1.13</pub-id><pub-id pub-id-type="pmid">20143906</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Alphen</surname> <given-names>AM</given-names></name><name><surname>Stahl</surname> <given-names>JS</given-names></name><name><surname>De Zeeuw</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The dynamic characteristics of the mouse horizontal vestibulo-ocular and optokinetic response</article-title><source>Brain Research</source><volume>890</volume><fpage>296</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(00)03180-2</pub-id><pub-id pub-id-type="pmid">11164796</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Alphen</surname> <given-names>B</given-names></name><name><surname>Winkelman</surname> <given-names>BH</given-names></name><name><surname>Frens</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Age- and sex-related differences in contrast sensitivity in C57BL/6 mice</article-title><source>Investigative ophthalmology &amp; visual science</source><volume>50</volume><fpage>2451</fpage><lpage>2458</lpage><pub-id pub-id-type="doi">10.1167/iovs.08-2594</pub-id><pub-id pub-id-type="pmid">19117934</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Alphen</surname> <given-names>B</given-names></name><name><surname>Winkelman</surname> <given-names>BH</given-names></name><name><surname>Frens</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Three-dimensional optokinetic eye movements in the C57BL/6J mouse</article-title><source>Investigative Opthalmology &amp; Visual Science</source><volume>51</volume><fpage>623</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1167/iovs.09-4072</pub-id><pub-id pub-id-type="pmid">19696183</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallace</surname> <given-names>DJ</given-names></name><name><surname>Greenberg</surname> <given-names>DS</given-names></name><name><surname>Sawinski</surname> <given-names>J</given-names></name><name><surname>Rulla</surname> <given-names>S</given-names></name><name><surname>Notaro</surname> <given-names>G</given-names></name><name><surname>Kerr</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats maintain an overhead binocular field at the expense of constant fusion</article-title><source>Nature</source><volume>498</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1038/nature12153</pub-id><pub-id pub-id-type="pmid">23708965</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname> <given-names>AB</given-names></name><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Iurilli</surname> <given-names>G</given-names></name><name><surname>Peterson</surname> <given-names>RE</given-names></name><name><surname>Katon</surname> <given-names>JM</given-names></name><name><surname>Pashkovski</surname> <given-names>SL</given-names></name><name><surname>Abraira</surname> <given-names>VE</given-names></name><name><surname>Adams</surname> <given-names>RP</given-names></name><name><surname>Datta</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>mapping sub-second structure in mouse behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wisard</surname> <given-names>J</given-names></name><name><surname>Chrenek</surname> <given-names>MA</given-names></name><name><surname>Wright</surname> <given-names>C</given-names></name><name><surname>Dalal</surname> <given-names>N</given-names></name><name><surname>Pardue</surname> <given-names>MT</given-names></name><name><surname>Boatright</surname> <given-names>JH</given-names></name><name><surname>Nickerson</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Non-contact measurement of linear external dimensions of the mouse eye</article-title><source>Journal of neuroscience methods</source><volume>187</volume><fpage>156</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.01.006</pub-id><pub-id pub-id-type="pmid">20067806</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Visual cortex neurons: response to stimuli during rapid eye movements</article-title><source>Science</source><volume>162</volume><fpage>1148</fpage><lpage>1150</lpage><pub-id pub-id-type="doi">10.1126/science.162.3858.1148</pub-id><pub-id pub-id-type="pmid">4301650</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yilmaz</surname> <given-names>M</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rapid innate defensive responses of mice to looming visual stimuli</article-title><source>Current biology : CB</source><volume>23</volume><fpage>2011</fpage><lpage>2015</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.08.015</pub-id><pub-id pub-id-type="pmid">24120636</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoder</surname> <given-names>RM</given-names></name><name><surname>Taube</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Head direction cell activity in mice: robust directional signal depends on intact otolith organs</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>1061</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1679-08.2009</pub-id><pub-id pub-id-type="pmid">19176815</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoccolan</surname> <given-names>D</given-names></name><name><surname>Graham</surname> <given-names>BJ</given-names></name><name><surname>Cox</surname> <given-names>DD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A self-calibrating, camera-based eye tracker for the recording of rodent eye movements</article-title><source>Frontiers in neuroscience</source><volume>4</volume><elocation-id>193</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2010.00193</pub-id><pub-id pub-id-type="pmid">21152259</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.29222.013</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Schoenbaum</surname><given-names>Geoffrey</given-names></name><role>Reviewing Editor</role><aff><institution>National Institutes of Health</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Magnetic eye tracking in mice&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom, Geoffrey Schoenbaum (Reviewer #1), is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Richard Ivry as the Senior Editor. The following individuals involved in review of your submission have also agreed to reveal their identity: Matt Gardner (Reviewer #2) and José María Delgado-García (Reviewer #3).</p><p>The reviewers and Reviewing Editor have discussed the reviews with one another and drafted a decision letter to help you prepare a revised submission.</p><p>Summary:</p><p>In this manuscript the authors present a novel method using magnetic sensing that allows them to track eye movement in mice. This is timely given the increasing interest and in fact implementation of visual and touchscreen based tasks in rodents.</p><p>Essential revisions:</p><p>1) Please confirm that there are no substantial effects on vision (or discuss this potential issue) and the requirement for head restraint. While this is a general statement, it is particularly relevant with respect to the start of subsection “Surgery”.</p><p>2) Is there any issue moving into rodents with the approach outlined? Discussion of this is relevant when considering potential impact of this methodological advance.</p><p>Secondary suggestions for revision:</p><p>1) A technique's usefulness is dependent on several characteristics such as the scope of application, the necessity of a solution, its effectiveness and its ease of use. The authors' have comprehensively demonstrated its effectiveness, and the scope and need for a solution are more up to the reader to consider. Nonetheless, the authors' should provide a bit more detail on the ease of use of the technique for researchers who might be considering whether to try it. The authors' state that the daily calibration only takes a short bit of time, yet does require head-restraint. Does the calibration require the mice to be anesthetized-- we expect not, but the authors should make this explicit. It would be useful to add details on the daily calibration procedure in reference to steps and time taken for the full procedure.</p><p>2) The comparisons of eye movements on the head retrained and freely moving mice are intriguing. Is it possible that some of this additional movement could be from forces which are not generated by the eye muscles themselves such as eye movement due to acceleration of the head? Of course this would still be eye movement, but the more interesting question that the authors appear to be addressing is whether there is increased eye movement initiated by the animal, not whether the additional forces which necessarily occur during free movement cause the effect. This might be hard to address, but should be brought up due to the claims made in the paper.</p><p>3) The low frequency shifts in <xref ref-type="fig" rid="fig2">Figure 2</xref> are puzzling. Are these due to a slow shift in gaze, a measurement artifact or something else?</p><p>4) Given the many contributions of David Robinson to the study and understanding of the oculomotor system, including the precise quantification of eye motor responses and neural organization of the system, it would be appropriate to cite this work (especially since many of the references build on Robinson's contributions).</p><p>5) Subsection “Magnetic tracking of eye movements in mice&quot; paragraph two and three. For comparative purposes with other recording systems and with other species, the gain and phase (in degrees) of evoked VOR and OKN should be quantified and represented. Indicating that &quot;the magnetic sensor detected robust eye movements&quot; is not enough!</p><p>6) Subsection “Calibration of magnetic eye tracking using dual-angle video-oculography&quot; paragraph four. The system seems to be suitable for horizontal eye movements, but what about the vertical component? The point is that eye movements in a free moving mouse will probably be the result of angular (horizontal + vertical) eye movements.</p><p>7) <xref ref-type="fig" rid="fig2">Figure 2</xref>. Please provide information regarding gain and phase (in degrees) of recorded eye reflexes.</p><p>8) <xref ref-type="fig" rid="fig6">Figure 6. A</xref> comparison with previous description of gain and phase (expressed in degrees) in mice would be appropriate.</p><p>9) One reviewer stated, &quot;I think that Vetbond is not indicated for a direct contact with the eye.&quot;</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.29222.014</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) Please confirm that there are no substantial effects on vision (or discuss this potential issue) and the requirement for head restraint. While this is a general statement, it is particularly relevant with respect to the start of subsection “Surgery”.</italic> </p><p>With respect to potential effects of the implant on vision:</p><p>1) As we now indicate in the Materials and methods (subsection “Surgery”), we minimize the chance for any effect on vision by surgically implanting the magnet away from the pupil, in a pocket of the conjunctiva on the lateral portion of the eye. Notably, the magnet implantation surgery involves less manipulation of the eye than the eye coil implantation surgery that is performed in many studies of vision.</p><p>2) We now include additional data showing that visually-driven eye movements are normal in mice implanted with a magnet and sensor. First, we show that the gain and phase of the eye movements driven by combined visual and vestibular stimuli, as measured with video-oculography, are the same before vs. after magnet and sensor implantation (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Second, we show that the eye movement responses to a visual (optokinetic) stimulus alone are intact after magnet and sensory implantation (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Eye movements are a fairly sensitive behavioral measure of visual processing. Although we cannot rule out the possibility that more complex visual tasks could be affected by the magnet implantation, the observation that visually-driven eye movements are normal suggests that vision is largely intact.</p><p>With respect to the requirement for head restraint during calibration:</p><p>A major advantage of the magnetic eye tracking technique is that, once the system is calibrated, measurements of eye movements can be made without head restraint. However, as pointed out by the reviewers, head restraint is still required during the brief calibration procedure. As detailed below and in subsection “Magnetic sensor calibration” of the revised manuscript, the duration of restraint required for calibration is only 5-10 min, and the implantation of a head post for use in restraint adds minimally to the effort and invasiveness of the surgery.</p><p><italic>2) Is there any issue moving into rodents with the approach outlined? Discussion of this is relevant when considering potential impact of this methodological advance.</italic> </p><p>There are no obvious barriers to extending this technique to other species, such as rats or monkeys. A larger eye and orbit may require that the sensor be implanted farther away from the magnet, however, this should be offset by the ability to implant a larger magnet. We now include this point in the Discussion section.</p><p><italic>Secondary suggestions for revision:</italic> </p><p><italic>1) A technique's usefulness is dependent on several characteristics such as the scope of application, the necessity of a solution, its effectiveness and its ease of use. The authors' have comprehensively demonstrated its effectiveness, and the scope and need for a solution are more up to the reader to consider. Nonetheless, the authors' should provide a bit more detail on the ease of use of the technique for researchers who might be considering whether to try it. The authors' state that the daily calibration only takes a short bit of time, yet does require head-restraint. Does the calibration require the mice to be anesthetized-- we expect not, but the authors should make this explicit. It would be useful to add details on the daily calibration procedure in reference to steps and time taken for the full procedure.</italic> </p><p>To help potential users of the magnetic eye tracking technique assess the effort involved, we now provide additional detail about the time required for each step (subsection “Magnetic sensor calibration”). The calibration procedure includes placing the mouse in the head restraint (1 minute), positioning the video cameras (1-3 minutes), calibration data collection (1-3 minutes), and adjustment of video-oculography parameters (0-2 minutes). Overall, the calibration procedure adds less than 10 minutes to an experiment.</p><p>We also clarify that calibration does not involve subjecting the mice to anesthesia, by adding the word “awake” to the calibration description.</p><p>Finally, we note in the description of the implant surgery (subsection “Surgery”) that the addition of a headpost for the purpose of head restraint is a minor additional step during surgery. Anchoring the magnetic sensor directly to the skull using dental cement achieved the most stable recordings, so some form of skull implant is necessary-- adding a head post in addition to the sensor doesn’t increase the invasiveness of the procedure.</p><p><italic>2) The comparisons of eye movements on the head retrained and freely moving mice are intriguing. Is it possible that some of this additional movement could be from forces which are not generated by the eye muscles themselves such as eye movement due to acceleration of the head? Of course this would still be eye movement, but the more interesting question that the authors appear to be addressing is whether there is increased eye movement initiated by the animal, not whether the additional forces which necessarily occur during free movement cause the effect. This might be hard to address, but should be brought up due to the claims made in the paper.</italic> </p><p>The magnetic eye tracking technique opens up the opportunity to study this and many other questions about the control of eye movements, as indicated in the Discussion (subsection “Applications”). In the present manuscript, our primary goal was to introduce and validate this new measurement technique, and to illustrate its potential for addressing the many open questions about eye movements in freely moving animals. As such, our study was not designed to address the specific question of how the passive properties of the eye plant contribute to eye movements in freely moving mice. However, we have measured eye movements during head acceleration in anesthetized animals (unpublished observations), and see little eye movement response. Hence, we expect that the eye movements observed in freely moving mice are, to a great extent, actively driven by neural commands to the eye muscles.</p><p><italic>3) The low frequency shifts in <xref ref-type="fig" rid="fig2">Figure 2</xref> are puzzling. Are these due to a slow shift in gaze, a measurement artifact or something else?</italic> </p><p>These low frequency shifts in eye position are not a measurement artifact, nor are they unique to measurements made with the magnetic eye tracking technique. Slow shifts in eye position are well documented in the oculomotor literature and are observed across species (Stahl, 2004; Koekkoek et al., 1997; Stahl and Thumser, 2014; Tan and Collewijn, 1991). Importantly, this drift is observed in studies that use the noninvasive video-oculography technique to measure eye movements (Stahl, 2004; Koekkoek et al., 1997), so is not a measurement artifact of the magnetic eye tracking system (see also <xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><p>The signals controlling eye position are actively generated by the oculomotor circuitry. The “oculomotor integrator”, which holds the eyes at eccentric positions, is not a perfect integrator, hence the eyes tend to drift back toward null position. In mice, the oculomotor integrator has a short time constant, hence, drift is more pronounced (van Alphen et al., 2001). In the dark, this drift is also more pronounced because it is not opposed by visual feedback.</p><p>To avoid distracting the reader with this point, which is an important issue in oculomotor control, but is independent of the techniques used to measure eye movements, which are the focus of this manuscript, we have replaced some of the example traces in <xref ref-type="fig" rid="fig2">Figure 2</xref> with traces that exhibit less position drift (still all from the same mouse).</p><p><italic>4) Given the many contributions of David Robinson to the study and understanding of the oculomotor system, including the precise quantification of eye motor responses and neural organization of the system, it would be appropriate to cite this work (especially since many of the references build on Robinson's contributions).</italic> </p><p>We agree that the work of David Robinson has laid the foundation for quantitative analyses of the oculomotor system, and we have added another reference to his work.</p><p><italic>5) Subsection “Magnetic tracking of eye movements in mice “paragraph two and three. For comparative purposes with other recording systems and with other species, the gain and phase (in degrees) of evoked VOR and OKN should be quantified and represented. Indicating that &quot;the magnetic sensor detected robust eye movements&quot; is not enough!</italic> </p><p>We did not quantify the gain and phase of the VOR and optokinetic response (OKR) at this specific point in the text, because we had not yet described the calibration procedure, which is necessary to calculate the gain. The example traces in <xref ref-type="fig" rid="fig2">Figure 2</xref> are included to provide motivation for the development of the video calibration system. After describing the calibration procedure, we now quantify the gain and phase of the VOR measured with magnetic eye tracking in a population of mice in <xref ref-type="fig" rid="fig6">Figure 6</xref> (blue, dashed lines). Moreover, we have conducted additional experiments to quantify the gain and phase of the OKR in a population of mice (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). The gain and phase we measured with magnetic eye tracking at frequencies from 0.2 Hz to 5 Hz is in the range reported previously by our lab and other labs using the video or eye coil techniques (Iwashita et al., 2001; van Alphen et al., 2001; Kimpo and Raymond, 2007), although the VOR and OKR gain and phase have been shown to vary considerably with factors such as the spatial and temporal frequency, amplitude, and contrast of the vestibular and visual stimuli used to elicit the eye movement responses.</p><p><italic>6) Subsection “Calibration of magnetic eye tracking using dual-angle video-oculography&quot; paragraph four. The system seems to be suitable for horizontal eye movements, but what about the vertical component? The point is that eye movements in a free moving mouse will probably be the result of angular (horizontal + vertical) eye movements.</italic> </p><p>The control of eye movements is organized largely along three orthogonal axes (horizontal eye movements about an earth vertical axis and vertical eye movements about two earth horizontal axes, oriented at 45° and 135° relative to the midsagittal plane). Many oculomotor labs, including ours, have focused on the neural signals controlling eye movements along a single axis. It should be trivial to measure eye movements along a different axis (vertical vs. horizontal) by rotating the magnet and sensor positions. With additional technical development, incorporating either a second sensor or a 3D magnetic field sensor, it also should be possible to measure eye movements along multiple axes simultaneously, as mentioned in the Discussion.</p><p><italic>7) <xref ref-type="fig" rid="fig2">Figure 2</xref>. Please provide information regarding gain and phase (in degrees) of recorded eye reflexes.</italic> </p><p>We report quantitative information regarding the gain and phase of the vestibulo-ocular reflex (VOR) (<xref ref-type="fig" rid="fig6">Figure 6</xref>), the visually enhanced VOR (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), and the optokinetic response (OKR) (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>) for a range of stimulus frequencies.</p><p><italic>8) <xref ref-type="fig" rid="fig6">Figure 6. A</xref> comparison with previous description of gain and phase (expressed in degrees) in mice would be appropriate.</italic> </p><p>There is considerable variability in previous reports of the gain and phase of the VOR and OKR in mice, measured with eye coil (van Alphen et al., 2001; Kimpo and Raymond, 2007) or video (Iwashita et al., 2001; van Alphen et al., 2010; van Alphen et al., 2009; Tabata et al., 2010) techniques. These values are known to depend on parameters of the vestibular and visual stimuli, including temporal frequency, amplitude, and visual stimulus spatial frequency and contrast, as well as the age and gender of the animals. It is likely that additional behavioral variables related to handling, stress, and experience of the mouse also affect the eye movement responses. The values we measure with the magnetic eye tracking and video techniques fall within the range reported previously with video and eye coil methods. Moreover, there are certain consistencies across all studies, including an increase in VOR gain and decrease in OKR gain, plus an increase in VOR and OKR phase lag with stimulus frequency, which we also observe with magnetic eye tracking. We now include a brief discussion of this in the final paragraph of subsection “Linearity and spatial resolution of the magnetic eye tracking system”.</p><p><italic>9) One reviewer stated, &quot;I think that Vetbond is not indicated for a direct contact with the eye.&quot;</italic> </p><p>Cyanoacrylate has been safely used on the eye in humans (Lal et al., 2015), rabbits (Ollivier et al., 2001), dogs (Fridman et al., 2010), chickens (Carey et al., 1996) and mice (Boyden and Raymond, 2003). It was approved by our IACUC for use in magnetic eye tracking. Care is taken to restrict application of VetBond to only the pocket in the conjunctiva immediately surrounding the magnet, and we have observed no significant adverse effects. We have added a line about this to the Materials and methods. The cyanoacrylate should be absorbed within 14 days (Ollivier et al., 2001).</p><p><italic>References</italic></p><p>Carey, J.P., Fuchs, a F. and Rubel, E.W., 1996. Hair cell regeneration and recovery of the vestibuloocular reflex in the avian vestibular system. <italic>Journal of neurophysiology</italic>, 76(<xref ref-type="bibr" rid="bib5">5</xref>), pp.3301–3312.</p><p>Fridman, G.Y. et al., 2010. Vestibulo-ocular reflex responses to a multichannel vestibular prosthesis incorporating a 3D coordinate transformation for correction of misalignment. <italic>JARO – Journal of the Association for Research in Otolaryngology</italic>, 11(<xref ref-type="bibr" rid="bib3">3</xref>), pp.367–381.</p><p>Lal, I. et al., 2015. Efficacy of conjunctival resection with cyanoacrylate glue application in preventing recurrences of Mooren’s ulcer. <italic>British Journal of Ophthalmology</italic>, pp.971–975.</p><p>Ollivier, F., Delverdier, M. and Regnier, A., 2001. Tolerance of the rabbit cornea to an n-butyl-ester cyanoacrylate adhesive (Vetbond). <italic>Veterinary Ophthalmology</italic>, 4(<xref ref-type="bibr" rid="bib4">4</xref>), pp.261–266.</p><p>Stahl, J.S., 2004. Using eye movements to assess brain function in mice. <italic>Vision Research</italic>, 44, pp.3401–3410.</p><p>Stahl, J.S. and Thumser, Z.C., 2014. Flocculus Purkinje cell signals in mouse Cacna1a calcium channel mutants of escalating severity: an investigation of the role of firing irregularity in ataxia. <italic>Journal of neurophysiology</italic>, 112(<xref ref-type="bibr" rid="bib10">10</xref>), pp.2647–2663.</p><p>Tan, H.S. and Collewijn, H., 1991. Cholinergic modulation of optokinetic and vestibulo-ocular responses: a study with microinjections in the flocculus of the rabbit. <italic>Exp Brain Res</italic>, 85(<xref ref-type="bibr" rid="bib3">3</xref>), pp.475–481.</p></body></sub-article></article>