<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="article-commentary" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">03146</article-id><article-id pub-id-type="doi">10.7554/eLife.03146</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Insight</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Neural Processing</subject></subj-group></article-categories><title-group><article-title>Looking into the future</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-14278"><name><surname>Costa</surname><given-names>Vincent D</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="conf1"/><x> is in the </x></contrib><contrib contrib-type="author" corresp="yes" id="author-12499"><name><surname>Averbeck</surname><given-names>Bruno B</given-names></name><xref ref-type="aff" rid="aff2"/><xref ref-type="fn" rid="conf1"/><x> is in the </x></contrib><aff id="aff1"><institution>Laboratory of Neuropsychology, National Institute of Mental Health</institution>, <addr-line><named-content content-type="city">Maryland</named-content></addr-line>, <country>United States</country> <email>vincent.costa@nih.gov</email></aff><aff id="aff2"><institution>Laboratory of Neuropsychology, National Institute of Mental Health</institution>, <addr-line><named-content content-type="city">Maryland</named-content></addr-line>, <country>United States</country></aff></contrib-group><pub-date date-type="pub" publication-format="electronic"><day>28</day><month>05</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>3</volume><elocation-id>e03146</elocation-id><permissions><copyright-statement>© 2014, Costa and Averbeck</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Costa and Averbeck</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-03146-v1.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary-article" xlink:href="10.7554/eLife.02813"/><abstract><p>Eye tracking experiments show that neurons respond rapidly to eye movements, allowing our view of the world to remain stable.</p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>non-human primate</kwd><kwd>oculomotor system</kwd><kwd>population decoding</kwd><kwd>Bayesian inference</kwd><kwd>neural processing</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group></article-meta></front><body><boxed-text><p><bold>Related research article</bold> Graf ABA, Andersen RA. 2014. Inferring eye position from populations of lateral intraparietal neurons. <italic>eLife</italic> <bold>3</bold>:e02813. doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7554/eLife.02813">10.7554/eLife.02813</ext-link></p><p><bold>Image</bold> The direction of eye movements can be predicted by looking at the firing patterns of neuron populations in the parietal cortex</p><p><inline-graphic xlink:href="elife-03146-inf1-v1"/></p></boxed-text><p>In daily life, we carry out numerous tasks that require a high level of visual awareness. For example, we can reach for a cup of coffee without looking directly at it, we can walk down the street without bumping into other people, and we can drive a car without thinking about it. Because we can perform these tasks so easily, it seems as though our brain can work out the positions of objects with very little effort. In fact, to do this the brain must process a lot of complex information.</p><p>We see things because receptors on the retina are excited by photons of light, and our brain represents this information in the visual cortex. However, if we move our eyes, receptors in a different part of the retina are excited, and the new information is stored in a different part of the visual cortex—but we still know that the objects we can see are in the same place. How, then, does the brain ensure that we can continue to perform tasks that require us to know exactly where objects are, while all these changes are going on?</p><p>It has been proposed that a mechanism called gain field coding makes this possible (<xref ref-type="bibr" rid="bib9">Zipser and Andersen, 1988</xref>). This is a form of population coding: that is, it involves many neurons firing in response to a given visual image, rather than just one neuron firing. Neurons with gain field coding represent both the location of objects on the retina and the angle of gaze (i.e., where we are looking in space). From this information, computational models have shown that the location of objects in space can be calculated (<xref ref-type="bibr" rid="bib6">Pouget and Sejnowski, 1997</xref>). However, for this mechanism to work effectively, the angle of gaze must be reliably represented and rapidly updated after an eye movement. Now, in <italic>eLife</italic>, Arnulf Graf and Richard Andersen of the California Institute of Technology show that the neural population code for eye movements and eye position in a region of the brain called the parietal cortex is accurate, and is updated rapidly when eye movements are planned and executed (<xref ref-type="bibr" rid="bib4">Graf and Andersen, 2014</xref>).</p><p>To demonstrate this, monkeys carried out a task where they had to make saccades—rapid movements of the eyes (<xref ref-type="fig" rid="fig1">Figure 1</xref>). At the same time, the response of a population of neurons in an area of the parietal cortex called LIP (Lateral-Intra-Parietal) was recorded. Area LIP has previously been associated with behaviour related to eye movements (<xref ref-type="bibr" rid="bib3">Gnadt and Andersen, 1988</xref>).<fig id="fig1" position="float"><label>Figure 1.</label><caption><title>How the brain represents information about the locations of objects can be revealed through memory-guided saccade tasks, performed in the dark.</title><p>To find out how the neurons in area LIP of the parietal cortex respond to eye movements and eye position, Graf and Andersen trained monkeys to rapidly move (saccade) their eyes to the remembered location of a target, while the response of their neurons was monitored. The monkey initially fixated on one of nine target positions (top). Then, one of the surrounding target locations was flashed before disappearing (middle). The animals had to remember the target location for a short period of time and then move their eyes to look at this location when the fixation point disappeared (bottom). The experiments were carried out in the dark to eliminate the possibility that the recorded neural response was caused by any other visual information.</p></caption><graphic xlink:href="elife-03146-fig1-v1.tif"/></fig></p><p>The task performed by the monkeys had to be carefully designed to eliminate a range of possible confounding factors. If the targets were visible when eye movements were made towards them, any detected neural activity may have been representing the locations of those targets, rather than the eye movements. Therefore, eye movements were made in darkness and the planned movement had to be remembered by the monkey. The task also separated the direction of the eye movement from the position of the eye before and after the movement. This allowed Graf and Andersen to examine, unambiguously, whether information in the neural population code was representing either—or both—current and future eye position signals.</p><p>To determine whether the population code in the parietal cortex contained information about eye position and eye movements, Graf and Andersen used statistical models to analyse the neural activity and estimate these two variables at specific points in time. If these variables can be read out by a decoding analysis, this information will also be available in the brain and will, therefore, also be able to drive behaviour.</p><p>Graf and Andersen found that population coding of the initial eye position was represented well throughout the eye movement. In contrast, the coding of the final eye position began after the target location was flashed—at the point in the task when the animals were told where to move their eyes—and peaked following the completion of the eye movement. This finding builds on existing evidence that eye position can be decoded from area LIP before and after a saccade to a visual target (<xref ref-type="bibr" rid="bib5">Morris et al., 2013</xref>).</p><p>Contrary to recent suggestions by Xu et al. (<xref ref-type="bibr" rid="bib8">Xu et al., 2012</xref>), Graf and Andersen show that population coding of the post saccadic eye position signal was updated quickly after the saccade target was shown. There are two possible reasons for the discrepancies between these studies. First, Xu et al. assumed that eye position information could be characterised by a number called the gain field index. Xu et al. also only examined single neurons. Even though individual neurons represent fixation location and eye movements, different combinations of eye positions and target locations can cause some neurons to respond in the same way. However, looking at a population of neurons removes this ambiguity so that it is clear what the neurons are actually responding to—and this can be achieved with decoding analyses (<xref ref-type="bibr" rid="bib2">Georgopoulos et al., 1986</xref>).</p><p>It is well recognised that the brain computes and produces behaviour on the basis of distributed representations of neural activity, where patterns of activity across many neurons represent one action, and each neuron is involved in more than one action (<xref ref-type="bibr" rid="bib1">Fetz, 1992</xref>; <xref ref-type="bibr" rid="bib7">Rigotti et al., 2013</xref>). Distributed representations can be non-intuitive—but they are the way the brain represents and processes information. Graf and Anderson illustrate the use of decoding to extract information from a distributed representation across a population of neurons, and show that this approach can resolve debates about neural coding. This study also points to the importance of recording from large neural populations when investigating how complex tasks are performed, so the space in which population coding applies is fully explored.</p></body><back><fn-group content-type="competing-interest"><fn fn-type="conflict" id="conf1"><label>Competing interests:</label><p>The authors declare that no competing interests exist.</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fetz</surname><given-names>EE</given-names></name></person-group><year>1992</year><article-title>Are movement Parameters recognizably coded in the activity of single neurons</article-title><source>Behavioral and Brain Sciences</source><volume>15</volume><fpage>679</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511529788.008</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name><name><surname>Kettner</surname><given-names>RE</given-names></name></person-group><year>1986</year><article-title>Neuronal population coding of movement direction</article-title><source>Science</source><volume>233</volume><fpage>1416</fpage><lpage>1419</lpage><pub-id pub-id-type="doi">10.1126/science.3749885</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gnadt</surname><given-names>JW</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>1988</year><article-title>Memory related motor planning activity in posterior parietal cortex of macaque</article-title><source>Experimental Brain Research</source><volume>70</volume><fpage>216</fpage><lpage>220</lpage></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graf</surname><given-names>ABA</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>2014</year><article-title>Inferring eye position from populations of lateral intraparietal neurons</article-title><source>eLife</source><volume>3</volume><fpage>e02813</fpage><pub-id pub-id-type="doi">10.7554/eLife.02813</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>AP</given-names></name><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>Krekelberg</surname><given-names>B</given-names></name></person-group><year>2013</year><article-title>Eye-position signals in the dorsal visual system are accurate and precise on short timescales</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>12395</fpage><lpage>12406</lpage><pub-id pub-id-type="doi">10.1523/Jneurosci.0576-13.2013</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year>1997</year><article-title>Spatial transformations in the parietal cortex using basis functions</article-title><source>Journal of Cognitive Neuroscience</source><volume>9</volume><fpage>222</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1162/jocn.1997.9.2.222</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year>2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/Nature12160</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>BY</given-names></name><name><surname>Karachi</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name></person-group><year>2012</year><article-title>The postsaccadic unreliability of gain fields renders it unlikely that the motor system can use them to calculate target position in space</article-title><source>Neuron</source><volume>76</volume><fpage>1201</fpage><lpage>1209</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.034</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zipser</surname><given-names>D</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year>1988</year><article-title>A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons</article-title><source>Nature</source><volume>331</volume><fpage>679</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1038/331679a0</pub-id></element-citation></ref></ref-list></back></article>