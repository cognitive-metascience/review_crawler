<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">37945</article-id><article-id pub-id-type="doi">10.7554/eLife.37945</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Variance adaptation in navigational decision making</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-23588"><name><surname>Gepner</surname><given-names>Ruben</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-112565"><name><surname>Wolk</surname><given-names>Jason</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-112566"><name><surname>Wadekar</surname><given-names>Digvijay Shivaji</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2544-7533</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-112567"><name><surname>Dvali</surname><given-names>Sophie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-23398"><name><surname>Gershow</surname><given-names>Marc</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7528-6101</contrib-id><email>mhg4@nyu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Physics</institution><institution>New York University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Center for Neural Science</institution><institution>New York University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Neuroscience Institute</institution><institution>New York University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>11</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e37945</elocation-id><history><date date-type="received" iso-8601-date="2018-04-28"><day>28</day><month>04</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-10-29"><day>29</day><month>10</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Gepner et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Gepner et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-37945-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.37945.001</object-id><p>Sensory systems relay information about the world to the brain, which enacts behaviors through motor outputs. To maximize information transmission, sensory systems discard redundant information through adaptation to the mean and variance of the environment. The behavioral consequences of sensory adaptation to environmental variance have been largely unexplored. Here, we study how larval fruit flies adapt sensory-motor computations underlying navigation to changes in the variance of visual and olfactory inputs. We show that variance adaptation can be characterized by rescaling of the sensory input and that for both visual and olfactory inputs, the temporal dynamics of adaptation are consistent with optimal variance estimation. In multisensory contexts, larvae adapt independently to variance in each sense, and portions of the navigational pathway encoding mixed odor and light signals are also capable of variance adaptation. Our results suggest multiplication as a mechanism for odor-light integration.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision making</kwd><kwd>sensory systems</kwd><kwd>variance adaptation</kwd><kwd>multi-sensory integration</kwd><kwd>reverse correlation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1DP2EB022359</award-id><principal-award-recipient><name><surname>Wolk</surname><given-names>Jason</given-names></name><name><surname>Gershow</surname><given-names>Marc</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1455015</award-id><principal-award-recipient><name><surname>Gepner</surname><given-names>Ruben</given-names></name><name><surname>Wolk</surname><given-names>Jason</given-names></name><name><surname>Gershow</surname><given-names>Marc</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000879</institution-id><institution>Alfred P. Sloan Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Gershow</surname><given-names>Marc</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R90DA043849</award-id><principal-award-recipient><name><surname>Dvali</surname><given-names>Sophie</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Fruit fly larvae adapt their decision-making process to the variability of the environment, illuminating the structure of adaptation in the underlying neural substrates.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The world is not fixed but instead varies dramatically on multiple time scales, for example from cloudy to sunny, day to night, or summer to winter; and contexts: from sun to shade, or burrowing to walking. Nervous systems must respond appropriately in varied environments while obeying biophysical constraints and minimizing energy expenditure (<xref ref-type="bibr" rid="bib38">Niven and Laughlin, 2008</xref>). Sensory systems use strategies at all levels of organization, from sub-cellular to network-level structures, to detect and transmit relevant information about the world to the rest of the brain, often operating near the limits imposed by their physical properties (<xref ref-type="bibr" rid="bib5">Bialek, 1987</xref>; <xref ref-type="bibr" rid="bib38">Niven and Laughlin, 2008</xref>).</p><p>One strategy to maximize the conveyance of sensory information is to reduce redundancy by filtering out predictable portions of sensory inputs (<xref ref-type="bibr" rid="bib4">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib2">Attneave, 1954</xref>; <xref ref-type="bibr" rid="bib49">Srinivasan et al., 1982</xref>). Early evidence of efficiency in the way sensory neurons encode environmental information was found in the large monopolar cells of the blowfly retina, whose responses to intensity changes were found to be optimally matched to the range of stimuli encountered in the fly's natural environment (<xref ref-type="bibr" rid="bib28">Laughlin, 1981</xref>). If neurons' responses are indeed tuned to a specific environmental distribution of inputs, then when environmental conditions change, the neurons' coding must adapt to the new environment’s statistics to maintain an efficient representation of the world (<xref ref-type="bibr" rid="bib50">Tkačik and Bialek, 2016</xref>; <xref ref-type="bibr" rid="bib33">Maravall, 2013</xref>).</p><p>A rich field of study has explored adaptation of neural coding to the statistics, particularly the mean and variance, of sensory stimuli (<xref ref-type="bibr" rid="bib51">Wark et al., 2007</xref>). Variance adaptation has been measured across diverse organisms in visual, auditory, olfactory, and mechanosensory systems and in deeper brain regions (<xref ref-type="bibr" rid="bib7">Brenner et al., 2000</xref>; <xref ref-type="bibr" rid="bib15">Fairhall et al., 2001</xref>; <xref ref-type="bibr" rid="bib26">Kvale and Schreiner, 2004</xref>; <xref ref-type="bibr" rid="bib13">Dean et al., 2005</xref>; <xref ref-type="bibr" rid="bib35">Nagel and Doupe, 2006</xref>; <xref ref-type="bibr" rid="bib11">Dahmen et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Maravall et al., 2007</xref>; <xref ref-type="bibr" rid="bib12">De Baene et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Wen et al., 2009</xref>; <xref ref-type="bibr" rid="bib21">Gorur-Shandilya et al., 2017</xref>; <xref ref-type="bibr" rid="bib9">Clemens et al., 2018</xref>; <xref ref-type="bibr" rid="bib48">Smirnakis et al., 1997</xref>; <xref ref-type="bibr" rid="bib18">Gollisch and Meister, 2010</xref>; <xref ref-type="bibr" rid="bib10">Clifford et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Liu et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Kim and Rieke, 2001</xref>) pointing to a potentially universal function implemented by a broad range of mechanisms.</p><p>Classic experiments in blowfly H1 neurons showed that variance adaptation in the firing rate maximized information transmission (<xref ref-type="bibr" rid="bib7">Brenner et al., 2000</xref>; <xref ref-type="bibr" rid="bib15">Fairhall et al., 2001</xref>). Because the role of these neurons is to transmit information, we can say this adaptation is ‘optimal,’ in a well-defined theoretical sense. It is less clear how to test for optimality in the adaptation of behaviors to changes in environmental variance.</p><p>If the brain enacts behavior based on rescaled sensory input, one might expect that these behaviors should also adapt to stimulus variance. In rhesus monkeys performing an eye pursuit task (<xref ref-type="bibr" rid="bib29">Liu et al., 2016</xref>), adaptation to variance was observed in both the firing rates of MT neurons, maximizing information transmission, and in the ultimate eye movements, minimizing tracking errors, showing that efficiency in neural coding has observable effects on behavioral responses.</p><p>On the other hand, animals choose behaviors to achieve an end goal. For general sensory-driven behaviors, this goal, for example flying in a straight line or moving toward a potential food source, does not require maximizing the transmission of information about the stimulus to an observer of the behavior. In these cases, it might be adaptive for the brain to restore some or all information about environmental variance before choosing which behaviors to express.</p><p>To explore the role of variance adaptation in a general sensory information processing task, we studied how <italic>Drosophila</italic> larvae adapt their navigational decisions to variance in visual and olfactory stimuli. Navigation requires the larva to transform sensory information into motor output decisions in order to move to more favorable locations, and the larva’s navigational strategies have been characterized for a variety of sensory modalities (<xref ref-type="bibr" rid="bib20">Gomez-Marin and Louis, 2012</xref>; <xref ref-type="bibr" rid="bib17">Gershow et al., 2012</xref>; <xref ref-type="bibr" rid="bib20">Gomez-Marin and Louis, 2012</xref>; <xref ref-type="bibr" rid="bib19">Gomez-Marin et al., 2011</xref>; <xref ref-type="bibr" rid="bib23">Kane et al., 2013</xref>; <xref ref-type="bibr" rid="bib27">Lahiri et al., 2011</xref>; <xref ref-type="bibr" rid="bib30">Louis et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Luo et al., 2010</xref>; <xref ref-type="bibr" rid="bib44">Sawin et al., 1994</xref>). <italic>Drosophila</italic> larvae move in a series of relatively straight runs interspersed with reorienting turns. A key element of the larva’s navigational strategy is the decision to turn, that is to cease forward movement and execute a reorientation maneuver to select a new direction for the next run. This decision can be modeled as the output of a Linear-Nonlinear-Poisson (LNP) cascade and characterized through reverse correlation (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>; <xref ref-type="bibr" rid="bib22">Hernandez-Nunez et al., 2015</xref>; <xref ref-type="bibr" rid="bib1">Aljadeff et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Parnas et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Schwartz et al., 2006</xref>; <xref ref-type="bibr" rid="bib8">Chichilnisky, 2001</xref>).</p><p>In this work, we investigate how the navigational decision to turn adapts to the variance of sensory input by characterizing how changes in stimulus variance lead to changes in LNP model parameters. We show that larvae adapt to the variance of visual stimuli and of olfactory inputs processed by a range of olfactory-receptor neurons. We find that adaptation can be characterized as a rescaling of the input by a factor that changes with the variance of the stimulus. We show that the timescales of turn-rate adaptation are asymmetric with respect to the direction of variance switches and are consistent with optimal estimation of environmental variance (<xref ref-type="bibr" rid="bib52">Wark et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">DeWeese and Zador, 1998</xref>). We find that in a multi-sensory context, adaptation is implemented independently on visual and olfactory inputs and also in the pathway that processes combined odor and light signals. We propose that multisensory integration may result from multiplication of signals from odor and light channels.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>As a model for how organisms adapt their behavioral responses to changes in environmental variance, we explored visual and olfactory decision making by larval <italic>Drosophila</italic>. In previous work, we modeled the larva’s decision to turn (stopping a run in order to pick a new heading direction) as the output of a Linear-Nonlinear-Poisson (LNP) cascade (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). This model took as its input the derivative of stimulus intensity, and we used reverse-correlation to find the LNP model parameters (<xref ref-type="fig" rid="fig1">Figure 1b</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.002</object-id><label>Figure 1.</label><caption><title>Reverse correlation analysis of variance adaptation.</title><p>(<bold>a</bold>) Linear-Nonlinear-Poisson (LNP) model of the decision to turn. Sensory input is processed by a linear filter to produce an intermediate signal. The rate at which the larva initiates turns is a nonlinear function of this signal. Turns are initiated stochastically according to a Poisson process with this underlying turn rate. (<bold>b</bold>) Reverse correlation to determine LNP model parameters. The kernel of the linear filter is proportional to the 'turn-triggered-average', the average input preceding turns. The rate function is calculated by comparing the turn-conditioned filtered inputs to the entire input ensemble. (<bold>c</bold>) Experimental setup to test for behavioral adaptation to variance. We presented fluctuating light intensities - with randomly-picked derivatives - to groups of larvae crawling on an agar surface, and recorded their trajectories using IR lights and camera. Blue light provided a visual stimulus and red light activation of CsChrimson labeled neurons provided a fictive olfactory stimulus. The derivative of the light intensity was the input to our LNP model, and the variance of this input periodically changed between low and high values. (<bold>d</bold>) Turn-triggered averages measured at low and high variances for visual (Berlin, blue light) and fictive attractive odor (Or42a<italic>CsChrimson</italic>, red light) stimuli. To ease comparison of the temporal structure, the averages are scaled to have the same peak value. (<bold>e</bold>) Nonlinear rate functions measured at low and high variances. A single convolution kernel was calculated for the entire experiment; the turn rate as a function of the filtered input was calculated separately for low and high variance. Note logarithmic y-axis. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.37945.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Overview of analysis steps.</title><p>Overview of analysis steps Graphical demonstration of the calculation of the visual rate functions in <xref ref-type="fig" rid="fig1">Figure 1e</xref> (<bold>a</bold>) Example data from 1 cycle of one visual variance adaptation experiment. Top: led output value vs. time - 0 is off and 255 is max intensity. Middle: convolution of derivative of led output value with linear filter found via reverse correlation. Bottom: behavioral raster - each row represents one larva. Green shaded regions indicate larva was in a run, black circles represent turn initiations. Solid box indicates data used to compute high variance rate function. Dashed line indicates data used to compute low variance rate function. (<bold>b</bold>) Histogram of convolved stimulus values at the instant a turn was initiated, at low variance, for entire data set. (<bold>c</bold>) Histogram showing amount of time larva was in a run and therefore capable of initiating a turn vs. convolved stimulus, at low variance, for entire data set. Arrows show how elements of these histograms are extracted from the data. (<bold>d</bold>) Histogram of convolved stimulus values at the instant a turn was initiated, at high variance, for entire data set. (<bold>e</bold>) Histogram showing amount of time larva was in a run vs. convolved stimulus, at high variance, for entire data set. (<bold>f</bold>) Turn rate vs. convolved stimulus for high and low variance. Markers indicate rate found by dividing number of turns by minutes of run. Lines are maximum likelihood estimates of rate functions given convolved stimulii and observed behaviors.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig1-figsupp1-v1"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.37945.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Rate functions following single filter vs variance-specific filters.</title><p>Rate functions following single filter vs. variance-specific filters Rate functions of <xref ref-type="fig" rid="fig1">Figure 1e</xref> re-calculated using filters derived from high and low variance turn-triggered averages. (<bold>a,b</bold>) Berlin larvae responding to blue light. Rate functions at (<bold>a</bold>) high or (<bold>b</bold>) low variance calculated using either a filter derived from the entire data set (<xref ref-type="fig" rid="fig1">Figure 1e</xref>) or a filter derived from the turn-triggered average at high or low variance only. Note logarithmic y-axis, different x-axes. (<bold>c,d</bold>) Or42a&gt;csChrimson larvae responding to red light. Rate functions at (<bold>c</bold>) high or (<bold>d</bold>) low variance calculated using either a filter derived from the entire data set or a filter derived from the turn-triggered average at high or low variance only. Note logarithmic y-axis, different x-axes.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig1-figsupp2-v1"/></fig></fig-group><p>In this work, we extended the analysis to ask how larvae adapt their responses to changes in the variance of the input stimuli. We again provided visual stimuli through blue LED illumination and fictive olfactory stimuli through red LED activation of CsChrimson expressed in sensory neurons. The illumination was spatially uniform and temporally fluctuating, with derivatives randomly drawn from normal distributions. The variance of these normal distributions dictated the amplitude of temporal fluctuations. We changed the variance of these distributions (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), and studied the resulting changes in the behavioral response as measured by changes in the LN model parameters (<xref ref-type="fig" rid="fig1">Figure 1d,e</xref>).</p><p>There is a subtle difference between stimulus and model input. For instance, in work on adaptation in blowfly H1 (<xref ref-type="bibr" rid="bib7">Brenner et al., 2000</xref>; <xref ref-type="bibr" rid="bib15">Fairhall et al., 2001</xref>), the stimulus was light reflected from a pattern of black and white stripes, while the model input was the horizontal velocity of this pattern. The experimenters then measured adaptation to the variance of this input.</p><p>In our experiments, the stimulus was projected light whose intensity varied in a Brownian random walk. The model input was the time-derivative of the stimulus intensity. This has two important advantages. First, it provides a mean zero input that is uncorrelated on all time scales, simplifying analysis and interpretation. Second, when we change the variance of the input, we change the statistics of how quickly the light level changes, but we do not change the mean or variance of the light intensity itself, eliminating potential confounds due to adaptation to overall light intensity.</p><sec id="s2-1"><title>Larvae adapt their turn-rate to the variance in visual and olfactory sensory inputs</title><p>We first asked whether larvae adapt their behavior to changes in the variance of sensory input and if so, how. In one set of experiments, we presented wild-type larvae with blue light whose intensity derivatives were randomly drawn from normal distributions with low or high variance. In another set of experiments, we used a fictive olfactory stimulus generated by red light activation of CsChrimson expressed in Or42a sensory neurons.</p><p>In both sets of experiments, the environment switched between low and high variance <inline-formula><mml:math id="inf1"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>9</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> every 60 s. We expected that following a switch in variance, larvae would require some time to adapt their behaviors. We therefore discarded the first 15 s (this amount of time is justified later) following each transition and analyzed the larvae’s responses separately in low and high variance contexts.</p><p>In the LNP framework, adaptation to variance could take two forms - a change in the shape of the linear filter kernel (<xref ref-type="bibr" rid="bib24">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib3">Baccus and Meister, 2002</xref>), representing a change in the temporal dynamics of the response, and/or a change in the shape of the nonlinear function, representing a change in the strength of the response to a particular pattern of sensory input. Both forms of adaptation have been reported in sensory neurons (<xref ref-type="bibr" rid="bib51">Wark et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Maravall, 2013</xref>). In adult <italic>Drosophila</italic>, ORN firing rates adapt to variance of both natural and optogenetic inputs through a change in the nonlinearity (<xref ref-type="bibr" rid="bib21">Gorur-Shandilya et al., 2017</xref>).</p><p>We first examined the shape of the filter kernel. To find the kernel, we calculated the 'turn-triggered average’ (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>), the average input preceding a turn, at both low and high variance. Given an uncorrelated input and a large number of turns, the kernel is proportional to the turn-triggered average (<xref ref-type="bibr" rid="bib8">Chichilnisky, 2001</xref>), but the constant of proportionality is unknown and can be absorbed into the nonlinear stage. We therefore scaled both the low and high variance turn-triggered averages to have the same peak value. We found that for both visual and fictive olfactory stimuli, the scaled turn-triggered averages were nearly identical at low and high variance (<xref ref-type="fig" rid="fig1">Figure 1d</xref>), although at low variance, the averages had a slightly longer ‘shoulder’ 3–4 s prior to the eventual turn.</p><p>As the kernel shape did not strongly depend on the input variance, we first used the turn-triggered average for all data to estimate a single kernel for both low and high variance. We scaled this kernel so that the filter output had variance one in the low-variance condition. We then calculated the rate function at low and high variance to determine whether the magnitude of the larva’s response to stimulus changes adapted to environmental variance (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We found that for both visual and fictive olfactory stimuli the rate function (<xref ref-type="fig" rid="fig1">Figure 1e</xref>) was steeper at low variance than high variance, indicating a more sensitive response to the same input in the low variance context.</p><p>We then asked whether it might be more appropriate to use separate filters for low and high variance stimuli. We separately convolved the high and low variance stimuli with filters derived from the high and low variance turn-triggered averages (<xref ref-type="fig" rid="fig1">Figure 1d</xref>) and again calculated nonlinear rate functions at high (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2a,c</xref>) and low (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2b,d</xref>) variance. These rate functions were nearly identical to those we found using a single shared kernel. Thus, the different slopes of the rate functions at high and low variance (<xref ref-type="fig" rid="fig1">Figure 1e</xref>) are not due to mismatches in temporal dynamics between the filter derived from the pooled data and the variance-specific filters.</p><p>As it had little effect on the extracted rate functions and greatly simplified analysis, we used a single filter derived from pooled data in the remainder of our work.</p></sec><sec id="s2-2"><title>Larvae adapt to variance by rescaling the input</title><p>A larger response to the same input in a low variance context indicates variance adaptation. Several functional forms of adaptation have been proposed and measured. Rescaling the sensory input (<italic>input rescaling</italic>) by its standard deviation maximizes information transmission and has been observed in blowfly H1 neurons (<xref ref-type="bibr" rid="bib7">Brenner et al., 2000</xref>) and in salamander retina (<xref ref-type="bibr" rid="bib24">Kim and Rieke, 2001</xref>; <xref ref-type="bibr" rid="bib25">Kim and Rieke, 2003</xref>), equivalently characterized as a change in amplitude of the linear filter kernel. On the other hand, many biophysically plausible models of variance adaptation (<xref ref-type="bibr" rid="bib40">Ozuysal and Baccus, 2012</xref>) function by rescaling the <italic>output</italic> of a nonlinear function or by the summation of saturating nonlinear functions of correlated input (<xref ref-type="bibr" rid="bib37">Nemenman, 2012</xref>; <xref ref-type="bibr" rid="bib36">Nemenman, 2010</xref>; <xref ref-type="bibr" rid="bib6">Borst et al., 2005</xref>).</p><p>We asked whether the adaptation we observed in the nonlinear rate function could be better described as an input or output rescaling. We used maximum likelihood estimation to find the best fit model of each form for the entire visual or olfactory data set and measured the improvement compared to the best-fit model without rescaling (<xref ref-type="fig" rid="fig2">Figure 2a,d</xref>). We found that an input rescaling far better described the adaptation than an output rescaling, a straightforward consequence of the high and low variance rate functions having the same non-zero output at zero stimulus input. We therefore also considered whether recentering followed by rescaling of the output could describe the adaptation, but again found that input rescaling better described the adaptation.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.005</object-id><label>Figure 2.</label><caption><title>Comparing rescaling models of variance adaptation.</title><p>(<bold>a</bold>) Best fit rate functions to visual (Berlin with blue light stimulus) data of <xref ref-type="fig" rid="fig1">Figure 1</xref>, for various functional forms of rescaling, and for a null model with no rescaling. <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> indicates difference in Bayes Information Criterion between the adapting model and the null model. A negative value indicates the adapting model is preferred, and a difference of more than 10 is considered to be highly significant. (<bold>b,c</bold>) Ability of models to predict held-out data. In repeated ‘trials,’ each model was fit to a subset (14/17 experiments) of the data. The fit model was applied to calculate the likelihood of the data in the held out sets. Because test data sets varied in size, the log likelihood of each data set was normalized to the mean length of all test data sets. (<bold>b</bold>) Increase in log-likelihood of test data when predicted with rescaling models over the predictions of a null model without rescaling. Bars show mean increase and error bars the standard error of the mean. (<bold>c</bold>) Histogram of improvement of input rescaling model predictions over recentered output rescaling model predictions for each ‘trial.’ <inline-formula><mml:math id="inf3"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> log-likelihood <inline-formula><mml:math id="inf4"><mml:mo>&gt;</mml:mo></mml:math></inline-formula> 4.6 corresponds to <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>d–f</bold>) Same as (<bold>a–c</bold>), but for fictive olfactory (Or42a&gt;csChrimson with red light stimulus) data of panel 1. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-37945-fig2-v1"/></fig><p>Next we asked whether the models differed in their abilities to predict held out test data. We fit each model to a subset of 14 out of 17 experiments and found the likelihood of the data in the held out three experiments given the fit model. For each permutation of fit and test data, we calculated the improvement in the log likelihood of the test data compared to the predictions of a null model without rescaling. As with the fits to the entire data set, we found that the input rescaling model was better at predicting held out data than either output rescaling model, in the aggregate (<xref ref-type="fig" rid="fig2">Figure 2b,e</xref>) and on a trial-by-trial basis (<xref ref-type="fig" rid="fig2">Figure 2c,f</xref>).</p></sec><sec id="s2-3"><title>Asymmetric rates of variance adaptation to a variety of sensory inputs</title><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.006</object-id><label>Figure 3.</label><caption><title>Variance adaptation and temporal dynamics of input rescaling.</title><p>Larvae were exposed to alternating 20 s periods of high and low variance intensity derivative white noise. For Berlin, the stimulus was visual (blue light). For all other genotypes, the stimulus was optogenetic activation of the indicated receptor neuron type via CsChrimson and red illumination. (<bold>a</bold>) Turn-triggered averages measured at low and high variances. To ease comparison of the temporal structure, the averages are scaled to have the same peak value. (<bold>b</bold>) Nonlinear rate functions measured at low and high variances. A single convolution kernel was calculated for the entire experiment; the turn rate as a function of the filtered stimulus was calculated separately for low and high variance. Note logarithmic y-axis. (<bold>c</bold>) Scaling factor (<inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) vs. time since switch to low variance, averaged over many cycles. Schematic at top indicates low and high variance conditions. Colored lines (experiment) are maximum likelihood fits to data. Gray lines (step control) are maximum likelihood fits to data generated by a model in which the input rescaling changes instantly when the variance changes. <inline-formula><mml:math id="inf7"><mml:mi>α</mml:mi></mml:math></inline-formula> was normalized so that the average over the entire experiment was 1. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig3-v1"/></fig><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.007</object-id><label>Figure 4.</label><caption><title>Variance adaptation to a stimulus with uncorrelated values.</title><p>Berlin wild type animals were exposed to blue light. Every 0.25 s, the intensity of the light was chosen from a random normal distribution with fixed mean and low or high variance. (<bold>a</bold>) Turn-triggered average deviation from mean intensity, scaled to have same peak value at high and low variance. Analogous to <xref ref-type="fig" rid="fig1">Figure 1d</xref>. (<bold>b</bold>) Nonlinear rate functions measured at low and high variances. A single convolution kernel was calculated for the entire experiment; the turn rate as a function of the filtered input was calculated separately for low and high variance. Note logarithmic y-axis. Analogous to <xref ref-type="fig" rid="fig1">Figure 1e</xref>. (<bold>c</bold>) Scaling factor (<inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) vs. time since switch to low variance, averaged over many cycles. Colored lines (experiment) are maximum likelihood fits to data. Gray lines (step control) are maximum likelihood fits to data generated by a model in which the input rescaling changes instantly when the variance changes. <inline-formula><mml:math id="inf9"><mml:mi>α</mml:mi></mml:math></inline-formula> was normalized so that the average over the entire experiment was 1. Analogous to <xref ref-type="fig" rid="fig3">Figure 3c</xref>. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.37945.008</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Comparison of stimulii with uncorrelated random derivatives and uncorrelated random values.</title><p>Comparison of stimulii with uncorrelated random derivatives and uncorrelated random values Left: uncorrelated random derivatives. (<bold>a</bold>) Light levels (blue, below) and difference between subsequent light levels in light levels (black, above) vs. time for a single experiment. High variance periods are shaded in gray. Light levels range from 0 (fully off) to 255 (maximum intensity). (<bold>b</bold>) Zoomed in portion of trace in (<bold>a</bold>) showing transition from high to low variance. (<bold>c</bold>) Histogram of light levels over entirety of data used to produce <xref ref-type="fig" rid="fig1">Figure 1</xref>, separated into high and low variance portions (<bold>d</bold>) Normalized autocovariance of light levels for entire data set, separated into high and low variance portions. (<bold>e</bold>) Histogram of changes between light levels separated by 0.25 s, separated into high and low variance portions. (<bold>f</bold>) Normalized autocovariance of light level changes, separated into high and low variance portions. Right: uncorrelated random values. (<bold>g</bold>) Light levels (blue, below) and difference between subsequent light levels in light levels (black, above) vs. time for a single experiment. High variance periods are shaded in gray. Light levels range from 0 (fully off) to 255 (maximum intensity). (<bold>h</bold>) Zoomed in portion of trace in (<bold>g</bold>) showing transition from high to low variance. (<bold>i</bold>) Histogram of light levels over entirety of data used to produce <xref ref-type="fig" rid="fig4">Figure 4</xref>, separated into high and low variance portions (<bold>j</bold>) Normalized autocovariance of light levels for entire data set, separated into high and low variance portions. (<bold>k</bold>) Histogram of changes between light levels separated by 0.25 s, separated into high and low variance portions. (<bold>l</bold>) Normalized autocovariance of light level changes, separated into high and low variance portions. <italic>Note that in a,b,g,h changes in light levels are calculated every 8 ms, the actual update rate of the apparatus. In e,f,k,l changes in light levels are calculated every 250 ms, the update rate of the random value experiments</italic>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig4-figsupp1-v1"/></fig></fig-group><p>Having found that larvae adapt to the variance of visual stimuli and of optogenetically induced activity in the Or42a receptor neuron, we next explored the timescales and generality of the adaptation. We expected that following a change in environmental variance, larvae would require some time to adapt their responses, a process that could be described by adding time dependence to the nonlinear rate function. Since we found that adaptation was best described as a rescaling of the input to a nonlinear function, we modeled the time-variation of the rate function as a time-varying input rescaling<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(1)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>≡</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(2)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf10"><mml:mi>x</mml:mi></mml:math></inline-formula> is the output of the linear filter stage and <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> are constants to be determined.</p><p>To find the time scales of turn-rate adaptation to abrupt changes in sensory input variance, we decreased the period of the variance switching experiments to 40 s to increase the number of transitions. To test the generality of adaptation, we explored the visual response, activation of neurons that produce attractive responses (Or42a, Or42b), and activation of neurons that produce aversive responses (Or59a, Or35a, Gr21a). We found that in all cases, the linear filters were nearly the same at high and low variances and that the slope of the nonlinear rate function adapted to variance (<xref ref-type="fig" rid="fig3">Figure 3a,b</xref>).</p><p>We then estimated the time-varying input rescaling <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). We found that for all inputs this scaling factor decreased suddenly following a step increase in variance but increased more gradually following a step decrease. This is consistent with the response of an optimal variance estimator (<xref ref-type="bibr" rid="bib14">DeWeese and Zador, 1998</xref>).</p><p>We asked whether the temporal dynamics in our estimate of <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> arose from the larva’s behavior or from the estimation process itself. To control for the latter possibility, for each set of experiments, we developed a control model in which <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> switched instantly along with the variance while all other parameters of the model were unchanged. We used this control model to generate a fictional set of turn responses to the same input stimulus, matching the number of experiments and larvae to the original data set. We passed this fictive data set through our estimator and recovered <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, gray line). We found that, the estimator always reported a sharp and symmetric transition in <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Therefore the observed slower adaptation of <inline-formula><mml:math id="inf17"><mml:mi>α</mml:mi></mml:math></inline-formula> to variance decreases does not result from the estimation process.</p></sec><sec id="s2-4"><title>Variance adaptation under different stimulus statistics</title><p>In these experiments, we chose a stimulus whose <italic>derivatives</italic> at all time points were uncorrelated random gaussian variables. The trace of light intensity vs. time was therefore a Brownian random walk with reflecting boundary conditions, and changing the variance of the derivatives was equivalent to changing the diffusion constant (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a,b</xref>). An advantage of this stimulus is that the light levels themselves are uniformly distributed over the entire range, for both low and high variance conditions (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c</xref>), so that adaptation to variance cannot be explained, for instance, as due to saturation of channels or receptors at high light intensities.</p><p>It is also possible to perform behavioral reverse correlation using a stimulus with uncorrelated random values (<xref ref-type="bibr" rid="bib22">Hernandez-Nunez et al., 2015</xref>). We wondered whether we would also observe variance adaptation using such a stimulus. We exposed Berlin wild type larvae to a blue light stimulus with random intensity updated every 0.25 s. The mean of the intensities was constant, but the variance switched periodically (<inline-formula><mml:math id="inf18"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>9</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>). When the variance of the intensities switched so did the variance of the derivatives (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1g-i,k</xref>). While the intensities were uncorrelated on all time scales (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1j</xref>), subsequent changes in intensity were strongly anti-correlated (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1i</xref>).</p><p>We first considered a stimulus whose variance changed every 60 s. We analyzed the responses as we did for the analogous visual experiments of <xref ref-type="fig" rid="fig1">Figure 1</xref>. The linear filter, found as the mean subtracted and scaled turn-triggered average, encoded the same temporal dynamics at low and high variance (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). The nonlinear rate function was steeper in the low variance condition (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>) indicating variance adaptation. We then examined the temporal dynamics of adaptation using a stimulus whose variance switched every 20 s (in analogy to <xref ref-type="fig" rid="fig3">Figure 3</xref>) and found a faster adaptation to an increase in variance than a decrease (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). These results all agreed with those of our experiments using uncorrelated stimulus derivatives.</p></sec><sec id="s2-5"><title>Larvae adapt to variance through a simple rule</title><p>Although the temporal dynamics of the input rescaling are consistent with an optimal estimate of the variance, it is not straightforward to test whether the observed <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> truly reflects an optimal estimate. When the spike rate of a neuron adapts to environmental variance, there is a sound theoretical reason to believe it does so to maximize information transmission (<xref ref-type="bibr" rid="bib7">Brenner et al., 2000</xref>; <xref ref-type="bibr" rid="bib50">Tkačik and Bialek, 2016</xref>) and therefore that <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∝</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. However, for behavior, it is not clear if there is a theoretically optimal relation between <inline-formula><mml:math id="inf21"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>.</p><p>We therefore sought to experimentally determine the relation chosen by the larva between input rescaling and observed variance. To do this, we slowly varied the stimulus variance in time in a triangular pattern and continuously monitored the scaling parameter <inline-formula><mml:math id="inf23"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). If the variance changed slowly enough, the larva would be constantly adapted and the input rescaling <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> could be taken to be a function of the variance <inline-formula><mml:math id="inf25"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> at that time point only.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.009</object-id><label>Figure 5.</label><caption><title>Input rescaling as a function of variance.</title><p>Larvae were exposed to intensity derivative white noise whose standard deviation steadily increased and decreased in a 120 s period triangle wave. Top row: visual stimulus - blue light was presented to Berlin wild type. Bottom row: fictive attractive odor stimulus - red light activated CsChrimon expressed in Or42a receptor neurons. (<bold>a</bold>) Rescaling factors (<inline-formula><mml:math id="inf26"><mml:mi>α</mml:mi></mml:math></inline-formula>) and stimulus standard deviation (<inline-formula><mml:math id="inf27"><mml:mi>σ</mml:mi></mml:math></inline-formula>) vs. time since variance started increasing. (<bold>b</bold>) Rescaling factor (<inline-formula><mml:math id="inf28"><mml:mi>α</mml:mi></mml:math></inline-formula>) vs. stimulus standard deviation, as calculated from data in (a). Rising, falling indicate <inline-formula><mml:math id="inf29"><mml:mi>α</mml:mi></mml:math></inline-formula> vs. <inline-formula><mml:math id="inf30"><mml:mi>σ</mml:mi></mml:math></inline-formula> calculated using only data when variance was increasing or decreasing respectively. Solid black line is a fit to <xref ref-type="disp-formula" rid="equ2">Equation 3</xref> using all data. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig5-v1"/></fig><p>We related <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the time-varying rescaling parameter averaged over many cycles (colored lines, <xref ref-type="fig" rid="fig5">Figure 5a</xref>) to <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the cycle averaged stimulus standard deviation (black line, <xref ref-type="fig" rid="fig5">Figure 5a</xref>) to calculate <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). We estimated <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using the full data set and separately for periods of increasing and decreasing variance. If the larvae were not continuously adapted to the variance, we would expect to see different estimates of <inline-formula><mml:math id="inf35"><mml:mi>α</mml:mi></mml:math></inline-formula> during the rising and falling phases, due to hysteresis. We found the same scaling vs. variance curve for the rising and falling phases, indicating that our measured <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represented the larva’s adapted rescaling law.</p><p>To analytically describe the larva’s rescaling rule, we began with the input rescaling that maximizes information rescaling: <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∝</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. To better fit the data, we considered the possibility that the total variance might be due to both sensory input and other intrinsic noise sources: <inline-formula><mml:math id="inf38"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf39"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> is the variance we introduce through the sensory input and <inline-formula><mml:math id="inf40"><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, the intrinsic noise, is a fit parameter.</p><p>The solid line in <xref ref-type="fig" rid="fig5">Figure 5b</xref> shows the best fit to the data of this rescaling model<disp-formula id="equ2"><label>(3)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>∝</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>This model can be interpreted as an attempt at ‘optimal’ rescaling in the presence of intrinsic noise <inline-formula><mml:math id="inf41"><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and/or as an adaptation to prevent large behavioral responses to minute changes in an otherwise static environment.</p></sec><sec id="s2-6"><title>Adaptation is consistent with an optimal variance estimate</title><p>Now that we could relate <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the measured input rescaling, to the larva’s internal estimate of variance, we asked whether the larva’s estimate of variance made the best use of sensory input. We constructed an optimal Bayes estimator that periodically sampled the input stimulus and assumed that environmental variance changed diffusively. The variance estimator has two free parameters. One, <inline-formula><mml:math id="inf43"><mml:mi>τ</mml:mi></mml:math></inline-formula>, represents a prior assumption of the time-scale on which the variance is expected to fluctuate; the other, <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, represents the frequency with which the estimator receives new measurements. Measuring more often leads to faster adaptation.</p><p>We fed our experimental stimulus into this estimator to determine what an observer would determine the best estimate of the variance to be at each time in the experiment. This variance estimate depended on the stimulus history and the parameters <inline-formula><mml:math id="inf45"><mml:mi>τ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>.<disp-formula id="equ3"><label>(4)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We then calculated the appropriate input rescaling using <xref ref-type="disp-formula" rid="equ2">Equation 3</xref> and found the parameters of the static rate function that maximized the log-likelihood (Materials and methods) of the observed sequence of turns:<disp-formula id="equ4"><label>(5)</label><mml:math id="m4"><mml:mrow><mml:mi>ln</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>data</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>turn</mml:mi></mml:munder><mml:mi>ln</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mpadded width="+5pt"><mml:mi>no</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>turn</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula>with<disp-formula id="equ5"><label>(6)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>and dt = <inline-formula><mml:math id="inf47"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> second, the interval at which we sampled the behavioral state.</p><p>From these calculations, we found the values of <inline-formula><mml:math id="inf48"><mml:mi>τ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> that maximized the likelihood of the data: For visual response these were <inline-formula><mml:math id="inf50"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.85</mml:mn><mml:mo>±</mml:mo><mml:mn>.07</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> s and <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>±</mml:mo><mml:mn>2.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> s, and for Or42a activation, these were <inline-formula><mml:math id="inf52"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>.7</mml:mn><mml:mo>±</mml:mo><mml:mn>.15</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> s and <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>11</mml:mn><mml:mo>±</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> s (95<inline-formula><mml:math id="inf54"><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:math></inline-formula> confidence intervals, dotted white regions in <xref ref-type="fig" rid="fig6">Figure 6a</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.010</object-id><label>Figure 6.</label><caption><title>Optimal variance estimator predicts input rescaling.</title><p>We generated an estimate of the input variance using a Bayes estimator that sampled the stimulus at an interval of <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, with a prior <inline-formula><mml:math id="inf56"><mml:mi>τ</mml:mi></mml:math></inline-formula> that represented the expected correlation time of environmental variance, which we converted to an input rescaling parameter using the relation found in <xref ref-type="fig" rid="fig5">Figure 5</xref>. We found the static rate function parameters that in combination with this rescaling parameter best predicted the actual experimental data. We repeated this process for various combinations of <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:mi>τ</mml:mi></mml:math></inline-formula> to find the one that best modeled the experimental data (<bold>a</bold>) Difference from the optimal log likelihood of data given model for various choices for <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf60"><mml:mi>τ</mml:mi></mml:math></inline-formula>, for the visual and fictive olfactory (Or42a<inline-formula><mml:math id="inf61"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson) variance switching experiments of <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>b</bold>) Measured (black line) and predicted (colored lines) input rescaling vs. time for variance switching experiments, for the best fit value of <inline-formula><mml:math id="inf62"><mml:mi>τ</mml:mi></mml:math></inline-formula> and varying values of <inline-formula><mml:math id="inf63"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. The thickest colored line is the prediction of the best-fit estimator. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig6-v1"/></fig><p>We then compared the predicted rescaling vs. cycle time for the best fit model to the observed rescaling (<xref ref-type="fig" rid="fig6">Figure 6b</xref>) and found close agreement between the predicted and measured rescalings. When we compared the predictions produced by estimators with the same value of <inline-formula><mml:math id="inf64"><mml:mi>τ</mml:mi></mml:math></inline-formula> but different values of <inline-formula><mml:math id="inf65"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, we found substantial disagreement between the predicted and measured rescalings (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). Thus, the larva’s adaptation to environmental variance is consistent with an optimal estimate of that variance and indicates an input sampling rate of ~ 1.2–1.5 Hz.</p></sec><sec id="s2-7"><title>Larvae adapt to variance at multiple levels in the navigational pathway</title><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.011</object-id><label>Figure 7.</label><caption><title>Multisensory variance adaptation and temporal dynamics of input rescaling.</title><p>Or42a<inline-formula><mml:math id="inf66"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson larvae were exposed to both visual (dim blue light) and fictive olfactory (red light) stimuli with random intensity derivatives. <italic>Top row</italic>: visual input had constant variance, while olfactory input alternated between high and low variance every 20 s. <italic>Middle row</italic>: Olfactory input had constant variance and visual input alternated between high and low variance. <italic>Bottom row</italic>: Both olfactory and visual inputs had constant variance, but alternated between correlated and anti-correlated every 20 s. (<bold>a</bold>) Estimated input rescaling vs. time since variance switched to low, averaged over many cycles, for light and odor (top two rows) or combinations of light and odor (bottom row). (<bold>b</bold>) Turn rate vs. output of odor filter at high and low variance of the switching stimulus (top two rows) and vs. a linear combination of light and odor (bottom row). (<bold>c</bold>) Turn rate vs. output of light filter at high and low variance of the switching stimulus (top two rows). Note logarithmic y-axis in b,c. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig7-v1"/></fig><p>Previously, we studied how larvae combine visual and olfactory information to make navigational decisions. We found that in response to multisensory input, the turn rate was a function of a single linear combination of filtered odor and light signals (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). We also found that larvae used quantitatively the same linear combination of light and odor to make decisions controlling turn size and turn direction, suggesting that light and olfactory signals are combined early in the navigational pathway. Here, we asked whether adaptation to environmental variance occurs upstream or downstream of this combination.</p><p>To determine the locus of variance adaptation, we presented visual and olfactory white noise inputs simultaneously. The inputs were uncorrelated with themselves or each other; one input remained at constant variance while the other periodically switched between low and high variance. We analyzed the resulting behavior assuming that the turn rate was a nonlinear function of a linear combination of filtered light (<inline-formula><mml:math id="inf67"><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula>) and odor (<inline-formula><mml:math id="inf68"><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math></inline-formula>), each of which was subject to independent input rescaling<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(7)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(8)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>If the larva adapted to variance in each sense individually, we would expect that only the stimulus whose variance was changing would be subject to adaptation, for example for changing odor variance, we would expect <inline-formula><mml:math id="inf69"><mml:mi>α</mml:mi></mml:math></inline-formula> to vary in time and <inline-formula><mml:math id="inf70"><mml:mi>β</mml:mi></mml:math></inline-formula> to be constant. On the other hand, if the larva adapted to the variance of, and hence rescaled, the combined odor and light input, we would expect that whether the odor or light were switching variance, both <inline-formula><mml:math id="inf71"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf72"><mml:mi>β</mml:mi></mml:math></inline-formula> would change. We found that only the response to the switching stimulus adapted, while for the fixed-variance stimulus, the turn-rate remained constant (<xref ref-type="fig" rid="fig7">Figure 7</xref>), indicating that variance adaptation is accomplished on a uni-sensory basis and prior to multi-sensory combination.</p><p>Note that we have simplified the rate function to be an exponential of a linear (rather than quadratic) function of <inline-formula><mml:math id="inf73"><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf74"><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula>. This choice is motivated in the next section, but the same conclusion - that larvae adapt to variance on a unisensory basis - is reached if a quadratic combination of odor and light is used instead.</p><p>We next asked whether variance adaptation was a unique feature of the sensory systems or a more general feature of the navigational circuit. To probe whether variance adaptation can occur in the portion of the navigational circuit that processes combined odor and light information, we presented larvae with visual and olfactory stimuli of fixed variance, but changed the variance of the combined input.</p><p>To create a stimulus with constant <italic>uni-sensory</italic> variance but changing <italic>multi-sensory</italic> variance, we presented random white noise visual and olfactory stimuli of constant variance but altered the correlation between them. In the ‘high variance’ condition, changes in odor and light were negatively correlated (correlation coefficient = −0.8), so unfavorable decreases in odor coordinated with unfavorable increases in light. In the ‘low variance’ condition, changes in odor and light were positively correlated (correlation coefficient = +0.8), so that favorable increases in odor were coupled with unfavorable increases in light. A circuit element that received only light or odor inputs would be unable to distinguish between the ‘high’ and ‘low’ variance conditions, but an element that received a sum of light and odor inputs would observe a much more dynamic environment in the ‘high variance’ condition.</p><p>To analyze these experiments, we created a rotated coordinate system based on <inline-formula><mml:math id="inf75"><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf76"><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math></inline-formula>, the outputs of the odor and light filters (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>) (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>),<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(9)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>u</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(10)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>v</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf77"><mml:mi>θ</mml:mi></mml:math></inline-formula> is a parameter that controls the weighting of odor and light along the two axes of the rotated coordinate system. We constructed the stimulus so that for <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf79"><mml:mi>u</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf80"><mml:mi>v</mml:mi></mml:math></inline-formula> were uncorrelated, and had oppositely changing variances with <inline-formula><mml:math id="inf81"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>9</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. We then analyzed the resulting behavior as before, assuming the turn rate was a nonlinear function of <inline-formula><mml:math id="inf82"><mml:mi>u</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mi>v</mml:mi></mml:math></inline-formula>, each of which was subject to independent input rescaling<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(11)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>≡</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(12)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>As in our previous work (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>), we found a value of <inline-formula><mml:math id="inf84"><mml:mi>θ</mml:mi></mml:math></inline-formula> (<inline-formula><mml:math id="inf85"><mml:msup><mml:mn>38</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>) for which <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>b</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for the entire data set. For this value of <inline-formula><mml:math id="inf87"><mml:mi>θ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi>b</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> in both the low and high variance conditions.</p><p>Because <inline-formula><mml:math id="inf89"><mml:mi>v</mml:mi></mml:math></inline-formula> had negligible influence on the turn decision, there was no way to determine <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>α</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:math></inline-formula>. We found that <inline-formula><mml:math id="inf91"><mml:msub><mml:mi>α</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math></inline-formula> varied with time, increasing when the variance of <inline-formula><mml:math id="inf92"><mml:mi>u</mml:mi></mml:math></inline-formula> was lower, although the adaptation was less pronounced than for the uni-sensory variance changes (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This adaptation must be implemented by circuit elements that have access to both light and odor inputs, showing that elements of the navigational circuit well downstream of the sensory periphery also have the ability to adapt to variance.</p></sec><sec id="s2-8"><title>Input rescaling likely occurs near the sensory periphery; sense-specific variance adaptation suggests multiplication as a mechanism for multisensory integration</title><p>When presented with both light and fictive odor cues, larvae adapt to the variance of each sense individually prior to multi-sensory combination (<xref ref-type="fig" rid="fig7">Figure 7</xref>). We previously found that larvae <italic>linearly</italic> combine odor and light stimuli to make navigational decisions (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). Taken together, these results require a form of variance adaptation that preserves linearity.</p><p>Measurement of variance is an inherently nonlinear computation, and we are not aware of any biophysical model of variance adaptation that preserves a linear representation of the stimulus. Adaptation to variance can be achieved by rescaling the output of a rectifying nonlinearity (<xref ref-type="bibr" rid="bib40">Ozuysal and Baccus, 2012</xref>) or by summation of saturating nonlinearities with correlated inputs (<xref ref-type="bibr" rid="bib37">Nemenman, 2012</xref>; <xref ref-type="bibr" rid="bib6">Borst et al., 2005</xref>). A modified Hodgkin-Huxley model of salamander retinal ganglion cells (<xref ref-type="bibr" rid="bib25">Kim and Rieke, 2003</xref>; <xref ref-type="bibr" rid="bib24">Kim and Rieke, 2001</xref>) showed that scaling of the linear filter (equivalent to scaling the input to the nonlinear function) resulted from adaptation of slow Na+ channels to the mean firing rate of the neuron. While this model linearly rescales the filter, it requires feedback from the nonlinear output of the neuron.</p><p>Rectified signals encoding opposite polarities can be combined to produce a linear response (<xref ref-type="bibr" rid="bib54">Werblin, 2010</xref>; <xref ref-type="bibr" rid="bib34">Molnar et al., 2009</xref>), but there is no evidence of such competing pathways in the larva’s olfactory system. The adult fly adapts to variance beginning in the olfactory receptor neurons themselves (<xref ref-type="bibr" rid="bib21">Gorur-Shandilya et al., 2017</xref>), making it further unlikely that variance adaptation in the larva is accomplished through rescaling of downstream opponent pathways.</p><p>How does the larva adapt to variance through a nonlinear process, prior to apparently combining sensory signals <italic>linearly</italic>? We can resolve this puzzle by changing our model of multisensory integration. In our previous work (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>), we considered a model in which odor and light turning decisions were mediated by entirely separate pathways, both modeled as LNP processes (<xref ref-type="fig" rid="fig8">Figure 8a</xref>).<disp-formula id="equ9"><label>(13)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><fig-group><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.012</object-id><label>Figure 8.</label><caption><title>Multisensory combination models.</title><p>(<bold>a</bold>) Indepdendent pathways: two independent LNP models transform odor and light stimuli into decisions to turn; these turn decisions are combined by an OR operation at a late stage. This model is inconsistent with data from multisensory white noise experiments. (<bold>b</bold>) Early linear combination: Filtered odor and light signals are combined via linear summation prior to nonlinear transformation of the combined signal. This model is difficult to reconcile with adaptation to variance on a single-sense basis. (<bold>c</bold>) Multiplicative integration: Separate LN models for odor and light are combined via multiplication of the nonlinear function outputs. This model allows for unisensory variance adaptation via rescaling of a rectifying nonlinearity and is consistent with data from multisensory white noise experiments. Adapted from <xref ref-type="bibr" rid="bib16">Gepner et al. (2015)</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig8-v1"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.37945.013</object-id><label>Figure 8—figure supplement 1.</label><caption><title>Reanalysis of white noise experiments.</title><p>Reanalysis of white noise experiments (<bold>a</bold>) Results from <xref ref-type="bibr" rid="bib16">Gepner et al. (2015)</xref>. Left: turn-triggered average changes in visual stimulus (blue) and optogenetic activation (red) for entire data set. These were used to create the kernels for the linear convolution stage. Center: Turn-triggered ensemble - two-dimensional histogram of odor and light filter outputs at the moment of turn initiation. Right: rotated coordinate system; all turning decisions were described as a function of <inline-formula><mml:math id="inf93"><mml:mi>u</mml:mi></mml:math></inline-formula>, a linear combination of light and odor filter outputs. (<bold>b</bold>) Turn-triggered ensembles predicted by the best fit independent pathways, early linear combination, and multiplicative integration models to the entire data set. <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> indicates difference in Bayes Information Criterion between the left and right models. A negative value indicates the right model is preferred, and a difference of more than 10 is considered to be highly significant. By eye it is difficult to see a difference between the predictions of the multiplicative and linear combination models; the predicted turn-triggered ensembles differ by <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi/><mml:mo>≤</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the high probability regions. (<bold>c</bold>) Testing the predictions of the three models against held-out data. 9/12 experiments were used to fit the models and these fits were used to predict the turn rate in the held out three experiments. Left: Improvement in log-likelihood of test data given fit model over prediction of null model (fit to mean turn rate only) for all three models. Mean and standard error of mean are shown. The size of the error bars is due to mainly to sensitivity of the null model predictions to differences in the mean turn rate of the predicted and test data sets. Right: histogram of improvement of multiplicative integration over early linear combination, for each permutation of fit and test data (220 total). Because test data sets varied in size, the log likelihood of each data set was normalized to the mean length of all test data sets. Data from <xref ref-type="bibr" rid="bib16">Gepner et al. (2015)</xref>, which contains information on the number of experiments, larvae, and turns.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig8-figsupp1-v1"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.37945.014</object-id><label>Figure 8—figure supplement 2.</label><caption><title>Reanalysis of multisensory step experiments.</title><p>Reanalysis of multisensory step experiments Measured and fit turn rate for various combinations of favorable and unfavorable changes in odor and light stimuli. <inline-formula><mml:math id="inf96"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> indicates difference in Bayes Information Criterion between the top and bottom models. A negative value indicates the lower model is preferred, and a difference of more than 10 is considered to be highly significant. Figure adapted from <xref ref-type="bibr" rid="bib16">Gepner et al. (2015)</xref>, which contains information on the number of experiments, larvae, and turns.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig8-figsupp2-v1"/></fig></fig-group><p>This model would be easy to reconcile with modality-specific variance adaptation, but it was far less consistent with our observations of larvae’s responses to multisensory input than a competing model (<xref ref-type="fig" rid="fig8">Figure 8b</xref>) that described the two-input rate function <inline-formula><mml:math id="inf97"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as a one-input function of a linear combination of odor and light<disp-formula id="equ10"><label>(14)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>While this model makes predictions that are consistent with our multisensory white noise and step experiments, to be consistent with our multisensory variance adaptation experiments, it requires an unknown form of variance adaptation that preserves linearity.</p><p>We propose an alternate model (<xref ref-type="fig" rid="fig8">Figure 8c</xref>), that the two-input rate function might be the <italic>product</italic> of two unisensory rate functions, as recently found in human psychophysical experiments (<xref ref-type="bibr" rid="bib41">Parise and Ernst, 2016</xref>).<disp-formula id="equ11"><label>(15)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Multiplicative multisensory integration would allow unisensory adaptation to variance through a rectifying nonlinearity while preserving a fundamental feature we observed in multisensory decision making, the ability of favorable changes in one stimulus modality to compensate for unfavorable changes in the other.</p><p>In this work and previously (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>), we modeled the rate function as an exponential of a polynomial function of the filtered input. For a linear polynomial, there is no difference between adding odor and light inputs prior to the exponential nonlinearity and multiplying two exponential functions<disp-formula id="equ12"><label>(16)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In analyzing the multisensory experiments of <xref ref-type="fig" rid="fig7">Figure 7</xref>, we therefore modeled the rate as an exponential of a linear combination of odor and light, to avoid favoring one model of integration over the other.</p><p>For exponentials of a quadratic polynomial, like the 'ratio-of-gaussians’ (<xref ref-type="bibr" rid="bib43">Pillow and Simoncelli, 2006</xref>) we used previously, there are quantitative differences between adding the rate function inputs and multiplying rate function outputs, but these can be small, especially if the polynomials are nearly linear over the range of inputs provided in the experiment. We reanalyzed the data of <xref ref-type="bibr" rid="bib16">Gepner et al. (2015)</xref> to determine if multiplicative integration could describe the results as well. While the two models made very similar predictions, we found that for both white noise (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>) and step experiments (<xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>), the multiplicative model produced a statistically significantly better fit to the data than did the early linear combination model, even after accounting for the different number of model parameters. The multiplicative model also better predicted held-out data. Thus, the multiplicative model is at least as explanatory as the early linear combination model for multisensory experiments with constant variance inputs, and it can be reconciled more easily with our finding that larvae adapt to the variance of a sensory input prior to multisensory combination. Taken together, these results suggest multiplication as a mechanism for multisensory integration.</p></sec><sec id="s2-9"><title>Larvae adapt to variance of natural odor backgrounds</title><p>In all experiments presented so far, we explored variance adaptation using blue light to present a natural visual stimulus and red light to create fictive olfactory stimuli via optogenetic activation of sensory neurons. Although adaptation to variance of blue light clearly represents a natural response of the visual system, we might wonder to what extent adaptation to variance of fictive stimuli reflects particular properties of the optogenetic channel or peculiarities in fictive rather than natural sensory transduction. We therefore sought to directly measure whether larvae adapt to variance in a natural odor environment.</p><p>Although it is difficult to 'flicker’ an odor across an extended arena with the speed and precision required for reverse correlation, it is more straightforward to create an odor background of known variance, even if the actual gas concentrations at any particular point in space and time are unknown. We placed larvae in a flow chamber with a constant stream of carrier air and a varying amount of carbon dioxide injected at the inlet. The resulting concentration fluctuations propagated across the arena while being attenuated somewhat by diffusive mixing. Because the flow was laminar, the entire system could be described by linear equations, and the average fluctuation of carbon dioxide at any point in the arena was therefore linearly dependent on the magnitude of the fluctuations at the inlet. We varied the concentration of CO<inline-formula><mml:math id="inf98"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> at the inlet in a sinusoidal pattern<disp-formula id="equ13"><label>(17)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mtext>CO</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In all our experiments, <inline-formula><mml:math id="inf99"><mml:mi>μ</mml:mi></mml:math></inline-formula>, the mean concentration, was <inline-formula><mml:math id="inf100"><mml:mrow><mml:mn>5</mml:mn><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf101"><mml:mi>τ</mml:mi></mml:math></inline-formula>, the period of oscillation was 20 s. In the low variance condition, <inline-formula><mml:math id="inf102"><mml:mi>A</mml:mi></mml:math></inline-formula>, the amplitude of the oscillation was <inline-formula><mml:math id="inf103"><mml:mrow><mml:mn>1</mml:mn><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:mrow></mml:math></inline-formula>, while in the high variance condition <inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In both conditions, we presented identical red light inputs of constant variance to larvae expressing CsChrimson in CO<inline-formula><mml:math id="inf105"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neurons. We then asked whether the larva’s response to the fictive stimulus depended on the variance in the background concentration of natural carbon dioxide.</p><p>Using our standard reverse-correlation analysis, we extracted the linear kernel (which was the same in both low and high variance conditions) and nonlinear rate function. We found that the rate function was steeper in the low variance context (<inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.56</mml:mn><mml:mo>±</mml:mo><mml:mn>0.07</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), indicating that a fluctuating background of CO<inline-formula><mml:math id="inf107"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> reduces the larva’s sensitivity to <italic>optogenetic</italic> activation of the CO<inline-formula><mml:math id="inf108"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neurons (<xref ref-type="fig" rid="fig9">Figure 9a</xref>).</p><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.015</object-id><label>Figure 9.</label><caption><title>Adaptation to variance in a natural odor background.</title><p>(<bold>a</bold>) Optogenetic activation of odor receptor neurons with a fluctuating background of carbon dioxide. Above: Noise of constant variance was provided to either the CO<inline-formula><mml:math id="inf109"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neuron (Gr21a<inline-formula><mml:math id="inf110"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson) or an Ethyl Acetate receptor neuron (Or42a<inline-formula><mml:math id="inf111"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson) in a flow chamber with a time-varying CO<inline-formula><mml:math id="inf112"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> concentration. The mean CO<inline-formula><mml:math id="inf113"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> concentration was 5% in both high and low variance conditions, but the amplitude of the fluctuation was larger in the high variance condition. Below: turn rate as a function of filtered stimulus for both high and low variance conditions. Note logarithmic y-axis. (<bold>b</bold>) Visual stimulus with a fluctuating background of carbon dioxide. The same as (<bold>a</bold>) but the stimulus was blue noise of constant variance. <italic>Number of experiments, animals in</italic> <xref ref-type="table" rid="table1">Table 1</xref></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-37945-fig9-v1"/></fig><p>We next asked whether changing the background variance of CO<inline-formula><mml:math id="inf114"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> would influence the response of the larva to activation of the Or42a receptor neuron, which does not respond to carbon dioxide. We found that a higher variance CO<inline-formula><mml:math id="inf115"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> reduced the response of larvae to activation of the Or42a receptor neurons (<inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.35</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), but this effect was less pronounced than for activation of the CO<inline-formula><mml:math id="inf117"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neurons (<xref ref-type="fig" rid="fig9">Figure 9a</xref>).</p><p>While it is sensible that variation in CO<inline-formula><mml:math id="inf118"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> levels should affect the sensitivity of the larva to optogenetic perturbation of the CO<inline-formula><mml:math id="inf119"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neuron, it is somewhat surprising that CO<inline-formula><mml:math id="inf120"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> variation altered the response to perturbation of an olfactory neuron that does not respond to CO<inline-formula><mml:math id="inf121"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. This effect might be due to interactions between the Gr21a and Or42a neurons or pathways, for example lateral presynaptic inhibition (<xref ref-type="bibr" rid="bib39">Olsen and Wilson, 2008</xref>). Or the variation in response to optogenetic activation of the sensory neurons we measured could be due to other effects than variance adaptation -for example, a mathematical result of combining an oscillating signal with white noise prior to a rectifying nonlinearity.</p><p>Larvae did not modify their visual sensitivity in response to changes in fictive odor variance (<xref ref-type="fig" rid="fig7">Figure 7</xref>). We therefore expected that if the effect we observed were due to variance adaptation, it would be absent for white noise visual stimuli combined with natural odor backgrounds. Indeed, when we presented larvae with white noise visual stimuli in a fluctuating CO<inline-formula><mml:math id="inf122"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> background, we found that the visual response was insensitive to the magnitude of the fluctuations (<xref ref-type="fig" rid="fig9">Figure 9b</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In behavioral reverse correlation experiments, we analyzed the output of the entire sensory motor pathway using techniques developed to characterize sensory coding. Despite measuring a behavioral output rather than neural activity in early sensory neurons, we resolved features previously described in sensory systems, including adaptation to variance by input-rescaling, temporal dynamics of adaptation consistent with optimal variance estimators, and stimulus-specific variance adaptation.</p><sec id="s3-1"><title>Rates of adaptation suggest that sensory input filters are matched to motor output timescales</title><p>In LNP model fits to the reverse-correlation experiments, we found that the convolution kernels for visual and fictive olfactory stimuli have very similar shapes, suggesting that both visual and olfactory stimuli are low passed to the same temporal resolution (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). This was somewhat puzzling. In a natural environment and close to surfaces, we would expect that light levels could change much faster than could odor concentrations, whose kinetics would be determined by diffusion and laminar flow. Shouldn’t the larva therefore process light information <italic>faster</italic> than odor information?</p><p>One resolution to this puzzle is that in behavioral reverse correlation we are not directly measuring the sensory response, but instead the sensory response convolved with the larva’s motor output and further limited by the temporal resolution of our video analysis. Therefore, the measured shape of the filter could simply reflect the latency in the motor output pathway or in our analysis software.</p><p>But there are reasons to believe that the filter kernels reflect the true temporal dynamics of the sensory systems. The decision to cease a run and end a turn is a navigational response to stimulus changes generated by larva’s movement through the environment. For this decision, the larva should seek sensory input that changes at the frequency of its own peristaltic movement, and this time scale should be the same for light and odor.</p><p>More generally, there is little value in making a decision faster than it can be implemented by the motor output pathway and a cost (less accuracy) to higher bandwidth measurements. These arguments would suggest that the timescales measured in reverse correlation should be similar to the actual timescales of the sensory neuron filters. Indeed, electrophysiological (<xref ref-type="bibr" rid="bib45">Schulze et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Gorur-Shandilya et al., 2017</xref>) and optical (<xref ref-type="bibr" rid="bib47">Si et al., 2017</xref>) recordings in olfactory sensory neurons reveal that these neurons filter odor inputs with similar dynamics to those observed in our behavioral reverse correlation experiments.</p><p>Variance adaptation provides an independent measure of the bandwidth of the sensory input process. The time it takes larvae to adapt following a switch from high to low variance is long compared to the latencies of the motor output pathway and our analysis software, and, if the larvae’s estimates of variance are optimal, determined by the input sampling rate. If light and odor were sampled at different rates, we would expect different rates of adaptation following a switch to low variance. In fact, we see the same rates of adaptation for both light and odor, and these rates are consistent with an optimal estimator sampling the stimulus at a similar frequency to the bandwidth of the convolution kernels. These suggest that sensory input is indeed filtered to match the frequency of the larva’s own motion.</p><p>If the bandwidth of the filter kernels is set by the speed of the larva’s own motion and not the temporal dynamics of the environment <italic>per se</italic>, this would also explain why the temporal structures of the kernels do not adapt to changes in variance (<xref ref-type="fig" rid="fig1">Figure 1d</xref>, <xref ref-type="fig" rid="fig3">Figure 3a</xref>).</p></sec><sec id="s3-2"><title>Conclusion</title><p>In this study, we used behavioral reverse correlation to measure adaptation to environmental variance in a complete sensory-motor transformation. We found that larvae adapted to the variance of visual and fictive olfactory stimuli, that the rate of adaptation was consistent with an optimal estimate of the variance, and that larvae adapted to the variance in each sensory input individually. These results suggest a novel model of multisensory integration in the larva: multiplication of nonlinear representations of sensory input rather than addition of linear representations.</p><p>While variance adaptation has been well studied in early sensory neurons, the study of variance adaptation in complete sensory-motor transformations is in its early stages. This work contributes a study of variance adaptation in a navigational decision-making task as well as behavioral analysis of multi-sensory variance adaptation. Because the larva is transparent and amenable to genetic manipulation, the methods we developed here can be applied to optogenetic manipulation of interneurons as well, to understand whether variance adaptation to neural activity is a general feature of neural circuits or specific to early sensory inputs.</p><p>Changing the variance of background CO<inline-formula><mml:math id="inf123"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> levels changes the larva’s response to activation of the CO<inline-formula><mml:math id="inf124"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> receptor neuron but not its response to activation of the photoreceptors, suggesting that variance adaptation to a natural stimulus coupled with optogenetic activation of putative intermediate interneurons might be used to trace the flow of information through neural circuits.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type <break/>(species) or Resource</th><th>Designation</th><th>Source or reference</th><th>Identifiers</th><th>AdditionalInformation</th></tr></thead><tbody><tr><td>Strain <break/>(<italic>Drosophila melanogaster</italic>)</td><td>Berlin wild type</td><td>gift of Justin Blau, <break/>NYU</td><td/><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w1118;;20XUAS- <break/>CsChrimson-mVenus</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_55136">BDSC_55136</ext-link></td><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w*;;Gr21a-Gal4</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_23890">BDSC_23890</ext-link></td><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w*;;Or42a-Gal4</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_9969">BDSC_9969</ext-link></td><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w*;;Or42b-Gal4</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_9972">BDSC_9972</ext-link></td><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w*;;Or35a-Gal4</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_9968">BDSC_9968</ext-link></td><td/></tr><tr><td>Genetic reagent <break/>(<italic>D. melanogaster</italic>)</td><td>w*;;Or59a-Gal4</td><td>Bloomington Stock <break/>Center</td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/BDSC_9989">BDSC_9989</ext-link></td><td/></tr><tr><td>Software, <break/>algorithm</td><td>MAGATAnalyzer</td><td>(<xref ref-type="bibr" rid="bib17">Gershow et al., 2012</xref>) <break/><ext-link ext-link-type="uri" xlink:href="https://github.com/samuellab/MAGATAnalyzer-Matlab-Analysis">github.com/samuellab/MAGATAnalyzer-Matlab-Analysis/</ext-link></td><td>d9d72b2b43c82af...</td><td/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Fly strains</title><p>The following strains were used: Berlin wild type (gift of Justin Blau), w1118;; 20XUAS-CsChrimson-mVenus (Bloomington Stock 55136, gift of Vivek Jayaraman and Julie Simpson, Janelia Research Campus), w*;;Gr21a-Gal4 (Bloomington stock 23890), w*;;Or42a-Gal4 (Bloomington stock 9969), w*;;Or42b-Gal4 (Bloomington stock 9972), w*;;Or35a-Gal4 (Bloomington stock 9968), w*;;Or59a-Gal4 (Bloomington stock 9989)</p></sec><sec id="s4-2"><title>Crosses</title><p>About 50 virgin female UAS-CsChrimson flies were crossed with about 25 males of the selected Gal4 line. F1 progeny of both sexes were used for experiments.</p></sec><sec id="s4-3"><title>Larva collection</title><p>Flies were placed in 60 mm embryo-collection cages (59–100 , Genessee Scientific) and allowed to lay eggs for 3 hr at 25C on enriched food media ('Nutri-Fly German Food,' Genesee Scientific). For all experiments except the Berlin response to blue light (top rows of <xref ref-type="fig" rid="fig1">Figure 1d,e</xref>; <xref ref-type="fig" rid="fig2">Figure 2a,b</xref>; top row of <xref ref-type="fig" rid="fig3">Figure 3</xref>; top row of <xref ref-type="fig" rid="fig5">Figure 5</xref>; left column of <xref ref-type="fig" rid="fig6">Figure 6</xref>), the food was supplemented with 0.1 mM all-trans-retinal (ATR, Sigma Aldrich R2500), and cages were kept in the dark during egg laying. When eggs were not being collected for experiments, flies were kept on plain food at 20C.</p><p>Petri dishes containing eggs and larvae were kept at 25C (ATR +plates were wrapped in foil) for 48–60 hr. Second instar larvae were separated from the food using 30<inline-formula><mml:math id="inf125"><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:math></inline-formula> sucrose solution and washed in deionized water. Larval stage was verified by size and spiracle morphology. Preparations for experiments were carried out in a dark room, under dim red (for phototaxis experiments) or blue (for CsChrimson experiments) illumination. Prior to beginning experiments, larvae were dark adapted on a clean 2.5<inline-formula><mml:math id="inf126"><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:math></inline-formula> agar surface for a minimum of 10 min.</p></sec><sec id="s4-4"><title>Behavioral experiments</title><p>Approximately 40–50 larvae were placed on a darkened agar surface for behavioral experiments (as in <xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). The agar surface resided in a 23 cm square dish (Corning BioAssay Dish <inline-formula><mml:math id="inf127"><mml:mi mathvariant="normal">#</mml:mi></mml:math></inline-formula>431111, Fisher Scientific, Pittsburgh, PA), containing 2.5<inline-formula><mml:math id="inf128"><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:math></inline-formula> (wt/vol) bacteriological grade agar (Apex, cat <inline-formula><mml:math id="inf129"><mml:mi mathvariant="normal">#</mml:mi></mml:math></inline-formula>20–274, Genesee Scientific) and 0.75<inline-formula><mml:math id="inf130"><mml:mo lspace="0pt" rspace="3.5pt">%</mml:mo></mml:math></inline-formula> (wt/vol) activated charcoal (DARCO G-60, Fisher Scientific). The charcoal darkened the agar and improved contrast in our dark-field imaging setup. The plate was placed in a darkened enclosure and larvae were observed under strobed 850 nm infrared illumination (ODL-300–850, Smart Vision Lights, Muskegon, MI) using a 4 MP global shutter CMOS camera (Basler acA2040-90umNIR, Graftek Imaging) operating at 20 fps and a 35 mm focal length lens (Fujinon CF35HA-1, B<inline-formula><mml:math id="inf131"><mml:mo>&amp;</mml:mo></mml:math></inline-formula>H Photo, New York, NY), and equipped with an IR-pass filter (Hoya R-72, Edmund Optics). A microcontroller (Teensy ++2.0, PJRC, Sherwood, OR) coordinated the infrared strobe and control of the stimulus light source, so stimulus presentation and images could be aligned to within the width of the strobe window (2–5 ms). Videos were recorded using custom software written in LABVIEW and analyzed using the MAGAT analyzer software package (<xref ref-type="bibr" rid="bib17">Gershow et al., 2012</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/samuellab/MAGATAnalyzer-Matlab-Analysis">https://github.com/samuellab/MAGATAnalyzer-Matlab-Analysis</ext-link>). Further analysis was carried out using custom MATLAB scripts. <xref ref-type="table" rid="table1">Table 1</xref> gives the number of experiments, animals, turns, and head sweeps analyzed for each experimental condition.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.37945.016</object-id><label>Table 1.</label><caption><title>Number of experiments, animals, turns.</title><p># experiments - number of 20 min duration experiments; a different noise input was used for each experiment within a group; # animals - estimate of total number of individual larvae surveyed in each set; animal-hours - total amount of animal-time analyzed; # turns total number of turns observed</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Figure</th><th>Genotype</th><th># expts</th><th># animals</th><th>animal-hours</th><th># turns</th></tr></thead><tbody><tr><td rowspan="2"><xref ref-type="fig" rid="fig1">Figure 1</xref>,<xref ref-type="fig" rid="fig2">Figure 2</xref></td><td>Berlin</td><td>17</td><td>811</td><td>219.3</td><td>48711</td></tr><tr><td>Or42a<inline-formula><mml:math id="inf132"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>17</td><td>743</td><td>201.1</td><td>33822</td></tr><tr><td rowspan="6"><xref ref-type="fig" rid="fig3">Figure 3</xref></td><td>Berlin</td><td>30</td><td>1087</td><td>302.4</td><td>55776</td></tr><tr><td>Or42a<inline-formula><mml:math id="inf133"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>19</td><td>838</td><td>247.5</td><td>44806</td></tr><tr><td>Or42b<inline-formula><mml:math id="inf134"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>15</td><td>600</td><td>163.3</td><td>23826</td></tr><tr><td>Or59a<inline-formula><mml:math id="inf135"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>15</td><td>723</td><td>177.6</td><td>16418</td></tr><tr><td>Or35a<inline-formula><mml:math id="inf136"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>11</td><td>430</td><td>121.1</td><td>13149</td></tr><tr><td>Gr21a<inline-formula><mml:math id="inf137"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>19</td><td>786</td><td>230.1</td><td>36121</td></tr><tr><td><xref ref-type="fig" rid="fig4">Figure 4a,b</xref></td><td>Berlin</td><td>16</td><td>483</td><td>133</td><td>22741</td></tr><tr><td><xref ref-type="fig" rid="fig4">Figure 4c</xref></td><td>Berlin</td><td>18</td><td>699</td><td>189</td><td>28226</td></tr><tr><td rowspan="2"><xref ref-type="fig" rid="fig5">Figure 5</xref></td><td>Berlin</td><td>10</td><td>372</td><td>102.5</td><td>18397</td></tr><tr><td>Or42a<inline-formula><mml:math id="inf138"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td>13</td><td>553</td><td>147.2</td><td>21897</td></tr><tr><td><xref ref-type="fig" rid="fig7">Figure 7</xref></td><td>Or42a<inline-formula><mml:math id="inf139"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td/><td/><td/><td/></tr><tr><td colspan="2">Odor switches variance, visual constant</td><td>6</td><td>165</td><td>46.1</td><td>6772</td></tr><tr><td colspan="2">Odor constant variance, visual switches</td><td>10</td><td>391</td><td>105.4</td><td>15210</td></tr><tr><td colspan="2">Correlation switches</td><td>16</td><td>616</td><td>156.8</td><td>22142</td></tr><tr><td><xref ref-type="fig" rid="fig9">Figure 9a</xref></td><td>Gr21a<inline-formula><mml:math id="inf140"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td/><td/><td/><td/></tr><tr><td>High Variance CO<inline-formula><mml:math id="inf141"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>6</td><td>242</td><td>66.2</td><td>11286</td></tr><tr><td>Low Variance CO<inline-formula><mml:math id="inf142"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>6</td><td>242</td><td>62.4</td><td>10534</td></tr><tr><td><xref ref-type="fig" rid="fig9">Figure 9a</xref></td><td>Or42a<inline-formula><mml:math id="inf143"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td/><td/><td/><td/></tr><tr><td>High Variance CO<inline-formula><mml:math id="inf144"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>7</td><td>286</td><td>80.5</td><td>12976</td></tr><tr><td>Low Variance CO<inline-formula><mml:math id="inf145"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>7</td><td>276</td><td>77.9</td><td>12096</td></tr><tr><td><xref ref-type="fig" rid="fig9">Figure 9b</xref></td><td>Gr21a<inline-formula><mml:math id="inf146"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td/><td/><td/><td/></tr><tr><td>High Variance CO<inline-formula><mml:math id="inf147"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>3</td><td>121</td><td>33.2</td><td>7289</td></tr><tr><td>Low Variance CO<inline-formula><mml:math id="inf148"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>3</td><td>116</td><td>32.7</td><td>7023</td></tr><tr><td><xref ref-type="fig" rid="fig9">Figure 9b</xref></td><td>Or42a<inline-formula><mml:math id="inf149"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>CsChrimson</td><td/><td/><td/><td/></tr><tr><td>High Variance CO<inline-formula><mml:math id="inf150"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>2</td><td>94</td><td>25</td><td>5174</td></tr><tr><td>Low Variance CO<inline-formula><mml:math id="inf151"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td/><td>2</td><td>82</td><td>22.4</td><td>4571</td></tr></tbody></table></table-wrap><p>To determine the number of experiments to perform, we did a back-of-the-envelope calculation, assuming that we would find the time-varying rate function by histogram division, and set 30 experiments as the target for the visual switching experiment of <xref ref-type="fig" rid="fig3">Figure 3</xref>. When we actually analyzed the data using more sophisticated methods, we found that fewer experiments would yield adequate signal to noise. We then aimed for at least 10 experiments for each condition, although we did more or (in one instance) fewer depending on the fecundity of the flies. For <xref ref-type="fig" rid="fig9">Figure 9</xref>, only a single constant rate function is extracted using all the available data, so fewer experiments could be performed in each condition.</p><p>All replicates are biological replicates, except for the jackknife predictions of held-out data in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref> and bootstrapping to produce the shaded error regions on the turn-triggered averages.</p></sec><sec id="s4-5"><title>Stimuli</title><sec id="s4-5-1"><title>Light intensity</title><p>Stimuli were provided by changing the intensity of blue (central wavelength <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>447.5</mml:mn></mml:mrow></mml:math></inline-formula> nm) and red (<inline-formula><mml:math id="inf153"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>655</mml:mn></mml:mrow></mml:math></inline-formula> nm) lights on a custom-built LED board (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>) for visual and fictive olfactory signals respectively. The red light intensity varied from 0 to <inline-formula><mml:math id="inf154"><mml:mrow><mml:mn>900</mml:mn><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. For unisensory visual experiments, the blue light intensity varied from 0 to <inline-formula><mml:math id="inf155"><mml:mrow><mml:mn>50</mml:mn><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. For multi-sensory experiments (<xref ref-type="fig" rid="fig7">Figure 7</xref>), the blue light intensity varied from 0 to <inline-formula><mml:math id="inf156"><mml:mrow><mml:mn>3</mml:mn><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-5-2"><title>Light sequences</title><p>Light levels were specified by values between 0 (off) and 255 (maximum intensity). These values changed according to a Brownian random walk (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>), whose derivatives on all time scales are independent identically distributed Gaussian variables.</p><p>The light level was set by pulse width modulation and updated every <inline-formula><mml:math id="inf157"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>120</mml:mn></mml:mrow></mml:math></inline-formula> s. <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>I</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> represents the intensity at time <inline-formula><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>/</mml:mo><mml:mn>120</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. For all experiments except those of <xref ref-type="fig" rid="fig7">Figure 7</xref> (bottom row), sequences of light levels were generated according to these rules:<disp-formula id="equ14"><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(18)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>127</mml:mn></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(19)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(20)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mtext> if </mml:mtext></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(21)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>510</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mtext> if </mml:mtext></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>255</mml:mn></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf160"><mml:mrow><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was a Gaussian random variable with mean <inline-formula><mml:math id="inf161"><mml:mn>0</mml:mn></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf162"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. The sequence was generated in floating point (i.e. non-integer values were allowed) and converted to integers for output.</p><p>We analyzed behavioral responses to light intensity derivatives, so the input variance was dictated by <inline-formula><mml:math id="inf163"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. For low-variance conditions, <inline-formula><mml:math id="inf164"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and for the high variance condition <inline-formula><mml:math id="inf165"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula>. In the experiments displayed in the top two rows of <xref ref-type="fig" rid="fig7">Figure 7</xref>, the non-switching stimulus was generated with <inline-formula><mml:math id="inf166"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, although the same conclusions were reached when the non-switching stimulus was generated with <inline-formula><mml:math id="inf167"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf168"><mml:mn>9</mml:mn></mml:math></inline-formula>. In <xref ref-type="fig" rid="fig9">Figure 9</xref>, <inline-formula><mml:math id="inf169"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula> for all stimuli.</p><p>Sequences were not reused within an experimental group but might be reused between groups.</p><p>For multi-modal experiments in <xref ref-type="fig" rid="fig7">Figure 7</xref> (top and middle), independent sequences were used for each stimulus.</p><p>For the experiments with uncorrelated blue light intensities (<xref ref-type="fig" rid="fig4">Figure 4</xref>), a new light level was selected every 0.25 s. In the low variance condition, these were drawn from a normal distribution with mean 128 and standard deviation 17. In the high variance condition, the distribution had mean 128 and standard deviation 51. Out of range values (below 0 or above 255) were adjusted to 0 or 255 appropriately.</p></sec><sec id="s4-5-3"><title>Correlated multisensory sequences</title><p>For multi-modal experiments in <xref ref-type="fig" rid="fig7">Figure 7</xref> (bottom), we generated two correlated Brownian sequences <inline-formula><mml:math id="inf170"><mml:msup><mml:mi>I</mml:mi><mml:mi>o</mml:mi></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf171"><mml:msup><mml:mi>I</mml:mi><mml:mi>l</mml:mi></mml:msup></mml:math></inline-formula>:<disp-formula id="equ15"><label>(22)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ16"><label>(23)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf172"><mml:msup><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf173"><mml:msup><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msup></mml:math></inline-formula> were normally distributed with mean 0 and individual variances <inline-formula><mml:math id="inf174"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>.</p><p>The correlation coefficient of the odor and light inputs, <inline-formula><mml:math id="inf175"><mml:mi>c</mml:mi></mml:math></inline-formula>, is given by<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(24)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:msqrt><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:msqrt></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(25)</mml:mtext></mml:mtd><mml:mtd/><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In previous work, we found that larvae respond to a single combination of filtered odor and light inputs<disp-formula id="equ18"><label>(26)</label><mml:math id="m18"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We did not know <italic>a priori</italic> the exact value of <inline-formula><mml:math id="inf176"><mml:mi>θ</mml:mi></mml:math></inline-formula> we would find in a variance switching experiment, so we created a stimulus that would have a comparable switch in variance <inline-formula><mml:math id="inf177"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>9</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>The variance of <inline-formula><mml:math id="inf179"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="equ19"><label>(27)</label><mml:math id="m19"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>so to change the variance between <inline-formula><mml:math id="inf180"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf181"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we periodically changed the light-odor correlation coefficient between a positive and negative value: <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>±</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, and set <inline-formula><mml:math id="inf183"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>To generate this signal, we chose<disp-formula id="equ20"><label>(28)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ21"><label>(29)</label><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>±</mml:mo><mml:msqrt><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf184"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf185"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf186"><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf187"><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> are three different and uncorrelated Gaussian random variables with mean <inline-formula><mml:math id="inf188"><mml:mn>0</mml:mn></mml:math></inline-formula> and variance <inline-formula><mml:math id="inf189"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>. Keeping in mind that the odor kernel has opposite sign to the light kernel, the high variance condition is when <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.8</mml:mn><mml:mo>:</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msqrt><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the low variance condition is when <inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>+</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></p></sec><sec id="s4-5-4"><title>Natural carbon dioxide background</title><p>Reverse correlation experiments of <xref ref-type="fig" rid="fig9">Figure 9</xref> were conducted in a laminar flow chamber with a glass lid through which the behavioral arena could be observed. Mass Flow Controllers (AAlborg) were controlled via Labview to generate a sinusoidally varying CO<inline-formula><mml:math id="inf192"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> concentration via mixing of pure CO<inline-formula><mml:math id="inf193"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and filtered compressed air. Air flow was fixed at 4 L/min and CO<inline-formula><mml:math id="inf194"><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> flow varied sinusoidally, with a period of 20 s, either between 0.12 and 0.22 L/min or between 0 and 0.35 L/min, respectively for low and high variance experiments.</p></sec></sec><sec id="s4-6"><title>Data extraction</title><p>Videos of behaving larvae were recorded using LabView software into a compressed image format (mmf) that discards the stationary background (<xref ref-type="bibr" rid="bib17">Gershow et al., 2012</xref>; <xref ref-type="bibr" rid="bib23">Kane et al., 2013</xref>). These videos were processed using computer vision software (written in C++ using the openCV library) to find the position and posture (head, tail, midpoint, and midline) of each larva and to assemble these into tracks, each following the movement of a single larva through time. These tracks were analyzed by Matlab software to identify behaviors, especially runs, turns, and head sweeps.</p><p>The sequence of light intensities presented to the larvae was stored with the video recordings and used for reverse-correlation analysis.</p></sec><sec id="s4-7"><title>Data analysis</title><p>For all experiments, we discarded the first 60 s of data to let the larvae’s response to a novel environment dissipate. We use <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to indicate a static rate function that does not contain a variance adaptation term and <inline-formula><mml:math id="inf196"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to indicate full rate functions that include variance adaptation.</p><sec id="s4-7-1"><title>Kernels and rate functions</title><p>We calculated kernels and rate functions separately for low and high variance by pooling together all the data from low variance and high variance contexts. In <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig2">Figure 2</xref>, we discarded the first 15 s from each cycle. In <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig7">7</xref>, we discarded the first 10 s from each cycle.</p><p>Filters (<xref ref-type="fig" rid="fig1">Figures 1d</xref>, <xref ref-type="fig" rid="fig3">3a</xref> and <xref ref-type="fig" rid="fig4">4a</xref>): Filters, or kernels, were calculated as the ’turn-triggered’ average signal for each set of experiments (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). That is, we extracted the sequences of light-intensity derivatives, in bins of 0.1 s, surrounding every turn, and averaged them together. We scaled the low and high variance average signals to have the same maximum value.</p><p>For experiments with random intensities (<xref ref-type="fig" rid="fig4">Figure 4</xref>), we subtracted the mean of the stimulus from the turn-triggered average prior to scaling. To remove artifacts associated with the 4 Hz update rate, we low passed the turn-triggered averages using a Gaussian filter with <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula>s.</p><p>To calculate the shaded error regions, we adopted a bootstrapping approach (<xref ref-type="bibr" rid="bib55">Zhou et al., 2018</xref>). For each set of experiments (e.g. the 17 blue light experiments of <xref ref-type="fig" rid="fig1">Figure 1</xref>):</p><list list-type="order"><list-item><p>We generated a resampled data set by randomly selecting experiments and larvae with replacement</p><list list-type="order"><list-item><p>we selected, with replacement, a random subset of equal length. For example, if there were four experiments, a valid subset might be (1,1,3,2)</p></list-item><list-item><p>For each experiment in this subset, we selected, with replacement, a random subset of individual larvae.</p></list-item></list></list-item><list-item><p>We calculated the turn-triggered average of this resampled data set to create a single bootstrapped average.</p></list-item><list-item><p>We repeated the above steps 100 times</p></list-item><list-item><p>The shaded error region is the standard deviation at each time bin of the 100 bootstrapped averages.</p></list-item></list><p>Compared to simply calculating the standard error of the mean for each time bin, this approach respects the possibility of correlated sources of noise in the experiments.</p><p>Direct estimation of turn rates (<xref ref-type="fig" rid="fig1">Figures 1e</xref>, <xref ref-type="fig" rid="fig3">3b</xref>, <xref ref-type="fig" rid="fig7">7</xref> and <xref ref-type="fig" rid="fig9">9</xref>): The turn rates (in <inline-formula><mml:math id="inf198"><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), were calculated from the data as:<disp-formula id="equ22"><label>(30)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>60</mml:mn><mml:mo>⋅</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ23"><label>(31)</label><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>60</mml:mn><mml:mo>⋅</mml:mo><mml:mfrac><mml:msqrt><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:msqrt><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>20</mml:mn></mml:mfrac><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> was the sampling period. <inline-formula><mml:math id="inf200"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of turns observed with the filtered signal <inline-formula><mml:math id="inf201"><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math></inline-formula> within one of the <inline-formula><mml:math id="inf202"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula> bins containing <inline-formula><mml:math id="inf203"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the total number of data points where the filtered signal was in the histogram bin and larvae were in runs and thus capable of initiating turns.</p></sec><sec id="s4-7-2"><title>Maximum likelihood estimation of static turn rates</title><p>For <xref ref-type="fig" rid="fig1">Figures 1e</xref>, <xref ref-type="fig" rid="fig3">3b</xref> and <xref ref-type="fig" rid="fig9">9</xref>, we separately fit high and low variance rate functions to exponentials of quadratics:<disp-formula id="equ24"><label>(32)</label><mml:math id="m24"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mtext>high variance</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>low variance</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula>with <inline-formula><mml:math id="inf204"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf205"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf206"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> as independent parameters.</p><p>The probability of observing at least one turn in an interval <inline-formula><mml:math id="inf207"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> given an underlying turn rate <inline-formula><mml:math id="inf208"><mml:mi>r</mml:mi></mml:math></inline-formula> is <inline-formula><mml:math id="inf209"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. In the limit of short <inline-formula><mml:math id="inf210"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> this reduces to <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. The probability of not observing a turn in the same interval is <inline-formula><mml:math id="inf212"><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:math></inline-formula>.</p><p>For a model of the turn rate, the log-likelihood of the data given that model is therefore<disp-formula id="equ25"><label>(33)</label><mml:math id="m25"><mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mi>log</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf213"><mml:mi>x</mml:mi></mml:math></inline-formula> is the filtered signal, <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the turn rate predicted by the model, and <inline-formula><mml:math id="inf215"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>20</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the sampling rate in our experiments. <inline-formula><mml:math id="inf216"><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a sum over all points when larvae were in runs and thus capable of initiating turns.</p><p>We used the MATLAB function fminunc to find the parameters that maximize this log- likelihood.</p><p><xref ref-type="fig" rid="fig7">Figure 7b,c</xref> were fit in the same fashion but for exponentials of linear functions (<inline-formula><mml:math id="inf217"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≡</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>).</p></sec><sec id="s4-7-3"><title>Comparison of rescaling models (<xref ref-type="fig" rid="fig2">Figure 2</xref>)</title><p>For the experiments in <xref ref-type="fig" rid="fig1">Figure 1d–e</xref>, we model the rate function as: <inline-formula><mml:math id="inf218"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and ask if adaptation is better characterized by:</p><list id="I2" list-type="bullet"><list-item><p>an input rescaling:<disp-formula id="equ26"><mml:math id="m26"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>an output rescaling:<disp-formula id="equ27"><mml:math id="m27"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><p>or a ’re-centered’ output rescaling (where the basal rate is adjusted after rescaling):<disp-formula id="equ28"><mml:math id="m28"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item></list><p>For each model, we fit low and high-variance rate functions simultaneously (excluding the first 15 s of each cycle) by minimizing the negative-log-likelihood. We set <inline-formula><mml:math id="inf219"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and thus have four fit parameters for each model (<inline-formula><mml:math id="inf220"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf221"><mml:mi>b</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf222"><mml:mi>c</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf223"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). We plot the resulting low and high-variance rate functions for each model (<xref ref-type="fig" rid="fig2">Figure 2a,d</xref>), and also fit the data to a null model with no adaptation (only three fit parameters: <inline-formula><mml:math id="inf224"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf225"><mml:mi>b</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf226"><mml:mi>c</mml:mi></mml:math></inline-formula>), for which the low and high-variance rate functions are identical. We find that the input rescaling is the best model of the larvae’s turn-rate adaptation.</p><p>We then fit a subset (14/17 experiments) of the data to each model and find how well each one predicts the remainder of the data (3/17 experiments). By permuting the fitted and tested portions of the data, we find jackknife estimates of the log-likelihood of the test-data given the fit rate function (mean and standard error shown in <xref ref-type="fig" rid="fig2">Figure 2b,e</xref>). We then compare the input and recentered output models directly, showing the histogram of log-likelihoods for all different permutations of fitted and tested portions (<xref ref-type="fig" rid="fig2">Figure 2c,f</xref>).</p><p>In <xref ref-type="fig" rid="fig2">Figure 2b,c</xref> 20/680 and in <xref ref-type="fig" rid="fig2">Figure 2d,f</xref> 97/680 jack-knives resulted in the recentered output model producing a negative rate for some of the test data. These were excluded from analysis.</p><p>Assuming the entirety of a test data set is generated by the same process, we would expect that the log-likelihood of that data set given any model would be proportional to the length of the data set. To normalize out the effects of fluctuations in the number of animal-minutes in the held-out data sets, we therefore normalized the log-likelihood<disp-formula id="equ29"><label>(34)</label><mml:math id="m29"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf227"><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the likelihood of the test data in the <inline-formula><mml:math id="inf228"><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> jack-knife, <inline-formula><mml:math id="inf229"><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> is the total observation time in the <inline-formula><mml:math id="inf230"><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> test data set, and <inline-formula><mml:math id="inf231"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-7-4"><title>Bayes information criterion</title><p>The Bayes Information Criterion (BIC) is defined as<disp-formula id="equ30"><label>(35)</label><mml:math id="m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>BIC is closely related to the Aikake Information Criterion (AIC) but more strongly favors models with fewer parameters. <inline-formula><mml:math id="inf232"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> strongly favors the more negative model (roughly equivalent to <inline-formula><mml:math id="inf233"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>).</p><p>We chose <inline-formula><mml:math id="inf234"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the sample size to be the total number of larva-seconds. If we had chosen <inline-formula><mml:math id="inf235"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to be the total number of larvae, <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> would shift to favor models with more parameters by about seven per extra parameter. If we had chosen <inline-formula><mml:math id="inf237"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to be the total number images of individual larva analyzed, then <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> would shift to favor models with fewer parameters by 3 (<inline-formula><mml:math id="inf239"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>) per extra parameter. Neither of these changes would have affected which model fits were preferred or the significance of the differences between models.</p></sec><sec id="s4-7-5"><title>Calculation of <inline-formula><mml:math id="inf240"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figures 3c</xref>, <xref ref-type="fig" rid="fig5">5a</xref> and <xref ref-type="fig" rid="fig7">7a</xref>)</title><p>For uni-sensory experiments (<xref ref-type="fig" rid="fig3">Figures 3c</xref> and <xref ref-type="fig" rid="fig5">5a</xref>), we characterized adaptation of the turn rate as an input rescaling:<disp-formula id="equ31"><label>(36)</label><mml:math id="m31"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf241"><mml:mi>x</mml:mi></mml:math></inline-formula> is the (convolved) stimulus value, and <inline-formula><mml:math id="inf242"><mml:mi>λ</mml:mi></mml:math></inline-formula> is a fixed nonlinear function:<disp-formula id="equ32"><label>(37)</label><mml:math id="m32"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Our goal is to find the values of <inline-formula><mml:math id="inf243"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf244"><mml:mi>b</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf245"><mml:mi>c</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf246"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that maximize the probability of the data and a prior probability that constrains the smoothness of <inline-formula><mml:math id="inf247"><mml:mi>α</mml:mi></mml:math></inline-formula>. We grouped all experiments together and found a single <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for each time point between 60 s and 20 min; we did not use any prior knowledge of variance switching times in the extraction of best-fit parameters. We use an iterative process to find the best fit model parameters.</p><p>First, we assume that <inline-formula><mml:math id="inf249"><mml:mrow><mml:mi>α</mml:mi><mml:mo>≡</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, ignoring adaptation to variance, and calculate the best fit parameters of a static rate function, <inline-formula><mml:math id="inf250"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, using maximum likelihood estimation described above.</p><p>Next, we calculate the time-varying scaling parameter <inline-formula><mml:math id="inf251"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. At each time point <inline-formula><mml:math id="inf252"><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, we use Bayes’ rule to calculate the probability of a given value of <inline-formula><mml:math id="inf253"><mml:mi>α</mml:mi></mml:math></inline-formula><disp-formula id="equ33"><label>(38)</label><mml:math id="m33"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">Ω</mml:mi></mml:mfrac><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the LNP formulation, we assume that turns are generated by a memoryless Poisson process, so we simplify <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We assume that the prior probability <inline-formula><mml:math id="inf255"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of alpha depends only on <inline-formula><mml:math id="inf256"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, so <inline-formula><mml:math id="inf257"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We can then write<disp-formula id="equ34"><label>(39)</label><mml:math id="m34"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">Ω</mml:mi></mml:mfrac><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf258"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the distribution of <inline-formula><mml:math id="inf259"><mml:mi>α</mml:mi></mml:math></inline-formula> values at the previous time step, and <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the likelihood of seeing the observed turn times, <inline-formula><mml:math id="inf261"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, given that they are generated by a Poisson process with a mean rate <inline-formula><mml:math id="inf262"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ35"><label>(40)</label><mml:math id="m35"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mi>exp</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf263"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, using the fixed static rate function calculated previously. For <inline-formula><mml:math id="inf264"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we chose a Gaussian prior<disp-formula id="equ36"><label>(41)</label><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf265"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> is the time-step of the fitting routine and <inline-formula><mml:math id="inf266"><mml:mi>τ</mml:mi></mml:math></inline-formula> controls the smoothness of our estimate of <inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="fig" rid="fig3">Figure 3c</xref> and <inline-formula><mml:math id="inf268"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="fig" rid="fig5">Figure 5a</xref>, and with <inline-formula><mml:math id="inf269"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for both.</p><p>Using this formulation, we calculate the most likely value of <inline-formula><mml:math id="inf270"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> at each time point <inline-formula><mml:math id="inf271"><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf272"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and the uncertainty in this estimate (<inline-formula><mml:math id="inf273"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). We use the new values of <inline-formula><mml:math id="inf274"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to find new best fit parameters of the static rate function and iterate the process until the log-likehood converges.</p><p>Finally, to describe how <inline-formula><mml:math id="inf275"><mml:mi>α</mml:mi></mml:math></inline-formula> varies in response to changes in variance, we calculated an appropriately weighted average over cycle time. Call the time of the start of each cycle (e.g. switch to low variance) <inline-formula><mml:math id="inf276"><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, then<disp-formula id="equ37"><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(42)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(43)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To verify that the asymmetry in the timescales behavior is not an artifact of our analysis, we generate artificial turn-decisions from a rate-function that switches instantaneously when the variance switches. We then estimate the corresponding scaling factors for these new data and find that our estimator tracks the adaptation equally quickly for upward and downward switches (black curves in <xref ref-type="fig" rid="fig3">Figure 3c</xref>).</p><p>For multi-sensory experiments (<xref ref-type="fig" rid="fig7">Figure 7a</xref>), the rate is modeled as<disp-formula id="equ38"><mml:math id="m38"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Two dimensional, (<inline-formula><mml:math id="inf277"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>) distributions are calculated at each time step:<disp-formula id="equ39"><label>(44)</label><mml:math id="m39"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">Ω</mml:mi></mml:mfrac><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>with<disp-formula id="equ40"><label>(45)</label><mml:math id="m40"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The prior is now a two-dimensional Gaussian:<disp-formula id="equ41"><label>(46)</label><mml:math id="m41"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where<disp-formula id="equ42"><label>(47)</label><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mover><mml:mi>α</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>α</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>β</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ43"><label>(48)</label><mml:math id="m43"><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>μ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>μ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ44"><label>(49)</label><mml:math id="m44"><mml:mrow><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>τ</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mi>τ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>and <inline-formula><mml:math id="inf278"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> is the determinant of <inline-formula><mml:math id="inf279"><mml:mi mathvariant="normal">Σ</mml:mi></mml:math></inline-formula>.</p><p><inline-formula><mml:math id="inf280"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>s <inline-formula><mml:math id="inf281"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>s, and <inline-formula><mml:math id="inf282"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> so that no correlation between changes in <inline-formula><mml:math id="inf283"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf284"><mml:mi>β</mml:mi></mml:math></inline-formula> was introduced in our prior expectation.</p><p>To find <inline-formula><mml:math id="inf285"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf286"><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we marginalize the (<inline-formula><mml:math id="inf287"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) distribution at each time step and calculated the most likely value and uncertainty of <inline-formula><mml:math id="inf288"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf289"><mml:mi>β</mml:mi></mml:math></inline-formula> separately.</p><p>For the correlated stimuli (<xref ref-type="fig" rid="fig7">Figure 7a</xref>, bottom row), we first looked for an angle <inline-formula><mml:math id="inf290"><mml:mi>θ</mml:mi></mml:math></inline-formula> such that the rate function could be characterized by a linear combination of filtered odor and light inputs, <inline-formula><mml:math id="inf291"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>). We thus looked for a model of the form:<disp-formula id="equ45"><mml:math id="m45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(50)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(51)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf292"><mml:msub><mml:mi>α</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math></inline-formula> described the rescaling from high to low variance. We fit low and high-variance rate functions simultaneously (excluding the first 10 s of each cycle) by minimizing the negative-log-likelihood. We set <inline-formula><mml:math id="inf293"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and thus have four fit parameters (<inline-formula><mml:math id="inf294"><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf295"><mml:mi>a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf296"><mml:mi>θ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf297"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula>). In this way we found <inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>≈</mml:mo><mml:msup><mml:mn>38</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>Using this value of <inline-formula><mml:math id="inf299"><mml:mi>θ</mml:mi></mml:math></inline-formula>, we then fit the data to the two-coordinates model:<disp-formula id="equ46"><mml:math id="m46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(52)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd><mml:mtext>(53)</mml:mtext></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>with <inline-formula><mml:math id="inf300"><mml:mi>u</mml:mi></mml:math></inline-formula> defined above, <inline-formula><mml:math id="inf301"><mml:mi>v</mml:mi></mml:math></inline-formula> the coordinate orthogonal to <inline-formula><mml:math id="inf302"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>u</mml:mi><mml:mo>:</mml:mo><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. There, we found <inline-formula><mml:math id="inf303"><mml:mrow><mml:mi>b</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>We could then use the one-coordinate model (<xref ref-type="disp-formula" rid="equ45">Equation 51</xref>) and the iterative procedure described earlier in this section (<xref ref-type="disp-formula" rid="equ35">Equation 40</xref>) to calculate <inline-formula><mml:math id="inf304"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for the correlation time of the prior distribution (<xref ref-type="fig" rid="fig7">Figure 7a</xref>, bottom row).</p></sec><sec id="s4-7-6"><title>Bayesian-optimal estimates of the stimulus variance (<xref ref-type="fig" rid="fig6">Figure 6</xref>)</title><p>We calculate Bayesian-optimal estimates of the stimulus variance (<xref ref-type="bibr" rid="bib14">DeWeese and Zador, 1998</xref>):<disp-formula id="equ47"><label>(54)</label><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">Ω</mml:mi></mml:mfrac><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">Ω</mml:mi></mml:mfrac><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula><inline-formula><mml:math id="inf306"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> = <inline-formula><mml:math id="inf307"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the total change in light level over the sampling interval and forms the input to the estimator. <inline-formula><mml:math id="inf308"><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the estimate of the standard deviation of the light level changes and is the output of the model. We have replaced <inline-formula><mml:math id="inf309"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf310"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> because stimulus samples are uncorrelated.</p><p>The sampling time, <inline-formula><mml:math id="inf311"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, determines the rate at which the estimator picks out samples from the stimulus ensemble to make estimates of the variance. The estimator requires a prior model of how environmental variance changes with time. We chose a diffusive prior, parameterized by a correlation time <inline-formula><mml:math id="inf312"><mml:mi>τ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ48"><label>(55)</label><mml:math id="m48"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msqrt></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Decreasing <inline-formula><mml:math id="inf313"><mml:mi>τ</mml:mi></mml:math></inline-formula> increases the speed at which the estimator responds to changes in variance at the cost of decreasing stability during periods of constant variance. In the absence of measurement noise, decreasing <inline-formula><mml:math id="inf314"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> strictly improves the performance of the estimator, increasing response speed and stability.</p><p>To determine the values of <inline-formula><mml:math id="inf315"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf316"><mml:mi>τ</mml:mi></mml:math></inline-formula> that were most consistent with the larva’s behavior, we estimated the stimulus variance using a series of estimators with different choices of <inline-formula><mml:math id="inf317"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf318"><mml:mi>τ</mml:mi></mml:math></inline-formula>. For each such estimate of the signal variance:<disp-formula id="equ49"><label>(56)</label><mml:math id="m49"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>we calculated a mapping from variance to rescaling parameter using the relation:<disp-formula id="equ50"><label>(57)</label><mml:math id="m50"><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msqrt><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math></disp-formula>with <inline-formula><mml:math id="inf319"><mml:msub><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> taken from the switching experiments of <xref ref-type="fig" rid="fig3">Figure 3</xref> and <inline-formula><mml:math id="inf320"><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> chosen to enforce <inline-formula><mml:math id="inf321"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>For each set of <inline-formula><mml:math id="inf322"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf323"><mml:mi>τ</mml:mi></mml:math></inline-formula>, we now had a predicted rescaling for each time point in the experiments: <inline-formula><mml:math id="inf324"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. To compare these predictions to the data, we found the log-likelihood of the observed sequence of data given the rate <inline-formula><mml:math id="inf325"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with the parameters of the static rate function <inline-formula><mml:math id="inf326"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> found separately for each set of <inline-formula><mml:math id="inf327"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf328"><mml:mi>τ</mml:mi></mml:math></inline-formula> by maximum-likelihood-estimation.</p></sec></sec><sec id="s4-8"><title>New methods developed</title><p>Behavioral reverse correlation using visual and optogenetic stimulation follows previous work (<xref ref-type="bibr" rid="bib16">Gepner et al., 2015</xref>; <xref ref-type="bibr" rid="bib22">Hernandez-Nunez et al., 2015</xref>). Behavioral analysis software was developed in <xref ref-type="bibr" rid="bib17">Gershow et al. (2012)</xref>. New to this work are: presentation of stimuli with changing variance; analysis of adaptation to variance, including estimation of the time-varying rescaling parameter, estimation of the rescaling parameter vs. variance, and comparison of the adaptation with predictions of a Bayes estimator; combination of optogenetic and visual manipulation with fluctuating CO<sub>2</sub> background; multi-sensory variance adaptation including the use of correlated stimuli of constant variance to produce a multi-sensory signal with changing variance.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Ilya Nemenman for discussions at the Aspen Center for Physics and KITP summer programs on behavior. This work was supported by NIH grant 1DP2EB022359, NSF grant 1455015, and a Sloan Research Fellowship.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.37945.017</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-37945-transrepform-v1.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting files.</p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aljadeff</surname> <given-names>J</given-names></name><name><surname>Lansdell</surname> <given-names>BJ</given-names></name><name><surname>Fairhall</surname> <given-names>AL</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Analysis of neuronal spike trains, deconstructed</article-title><source>Neuron</source><volume>91</volume><fpage>221</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.039</pub-id><pub-id pub-id-type="pmid">27477016</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attneave</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>Some informational aspects of visual perception</article-title><source>Psychological Review</source><volume>61</volume><fpage>183</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1037/h0054663</pub-id><pub-id pub-id-type="pmid">13167245</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baccus</surname> <given-names>SA</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Fast and slow contrast adaptation in retinal circuitry</article-title><source>Neuron</source><volume>36</volume><fpage>909</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01050-4</pub-id><pub-id pub-id-type="pmid">12467594</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1961">1961</year><source>Possible Principles Underlying the Transformation of Sensory Messages</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bialek</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Physical limits to sensation and perception</article-title><source>Annual Review of Biophysics and Biophysical Chemistry</source><volume>16</volume><fpage>455</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1146/annurev.bb.16.060187.002323</pub-id><pub-id pub-id-type="pmid">3297091</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borst</surname> <given-names>A</given-names></name><name><surname>Flanagin</surname> <given-names>VL</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Adaptation without parameter change: Dynamic gain control in motion detection</article-title><source>PNAS</source><volume>102</volume><fpage>6172</fpage><lpage>6176</lpage><pub-id pub-id-type="doi">10.1073/pnas.0500491102</pub-id><pub-id pub-id-type="pmid">15833815</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname> <given-names>N</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>de Ruyter van Steveninck</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Adaptive rescaling maximizes information transmission</article-title><source>Neuron</source><volume>26</volume><fpage>695</fpage><lpage>702</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)81205-2</pub-id><pub-id pub-id-type="pmid">10896164</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chichilnisky</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A simple white noise analysis of neuronal light responses</article-title><source>Network: Computation in Neural Systems</source><volume>12</volume><fpage>199</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1080/713663221</pub-id><pub-id pub-id-type="pmid">11405422</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clemens</surname> <given-names>J</given-names></name><name><surname>Ozeri-Engelhard</surname> <given-names>N</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Fast intensity adaptation enhances the encoding of sound in Drosophila</article-title><source>Nature Communications</source><volume>9</volume><pub-id pub-id-type="doi">10.1038/s41467-017-02453-9</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clifford</surname> <given-names>CW</given-names></name><name><surname>Webster</surname> <given-names>MA</given-names></name><name><surname>Stanley</surname> <given-names>GB</given-names></name><name><surname>Stocker</surname> <given-names>AA</given-names></name><name><surname>Kohn</surname> <given-names>A</given-names></name><name><surname>Sharpee</surname> <given-names>TO</given-names></name><name><surname>Schwartz</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Visual adaptation: neural, psychological and computational aspects</article-title><source>Vision Research</source><volume>47</volume><fpage>3125</fpage><lpage>3131</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2007.08.023</pub-id><pub-id pub-id-type="pmid">17936871</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahmen</surname> <given-names>JC</given-names></name><name><surname>Keating</surname> <given-names>P</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>Schulz</surname> <given-names>AL</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Adaptation to stimulus statistics in the perception and neural representation of auditory space</article-title><source>Neuron</source><volume>66</volume><fpage>937</fpage><lpage>948</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.05.018</pub-id><pub-id pub-id-type="pmid">20620878</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Baene</surname> <given-names>W</given-names></name><name><surname>Premereur</surname> <given-names>E</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Properties of shape tuning of macaque inferior temporal neurons examined using rapid serial visual presentation</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>2900</fpage><lpage>2916</lpage><pub-id pub-id-type="doi">10.1152/jn.00741.2006</pub-id><pub-id pub-id-type="pmid">17251368</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean</surname> <given-names>I</given-names></name><name><surname>Harper</surname> <given-names>NS</given-names></name><name><surname>McAlpine</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural population coding of sound level adapts to stimulus statistics</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1684</fpage><lpage>1689</lpage><pub-id pub-id-type="doi">10.1038/nn1541</pub-id><pub-id pub-id-type="pmid">16286934</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWeese</surname> <given-names>M</given-names></name><name><surname>Zador</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Asymmetric dynamics in optimal variance adaptation</article-title><source>Neural Computation</source><volume>10</volume><fpage>1179</fpage><lpage>1202</lpage><pub-id pub-id-type="doi">10.1162/089976698300017403</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairhall</surname> <given-names>AL</given-names></name><name><surname>Lewen</surname> <given-names>GD</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>de Ruyter Van Steveninck</surname> <given-names>RR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Efficiency and ambiguity in an adaptive neural code</article-title><source>Nature</source><volume>412</volume><fpage>787</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1038/35090500</pub-id><pub-id pub-id-type="pmid">11518957</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gepner</surname> <given-names>R</given-names></name><name><surname>Mihovilovic Skanata</surname> <given-names>M</given-names></name><name><surname>Bernat</surname> <given-names>NM</given-names></name><name><surname>Kaplow</surname> <given-names>M</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Computations underlying <italic>Drosophila</italic> photo-taxis, odor-taxis, and multi-sensory integration</article-title><source>eLife</source><volume>4</volume><elocation-id>e06229</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06229</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Berck</surname> <given-names>M</given-names></name><name><surname>Mathew</surname> <given-names>D</given-names></name><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Kane</surname> <given-names>EA</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name><name><surname>Samuel</surname> <given-names>ADT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Controlling airborne cues to study small animal navigation</article-title><source>Nature Methods</source><volume>9</volume><fpage>290</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1853</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gollisch</surname> <given-names>T</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Eye smarter than scientists believed: neural computations in circuits of the retina</article-title><source>Neuron</source><volume>65</volume><fpage>150</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.12.009</pub-id><pub-id pub-id-type="pmid">20152123</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Stephens</surname> <given-names>GJ</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Active sampling and decision making in Drosophila chemotaxis</article-title><source>Nature Communications</source><volume>2</volume><elocation-id>441</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1455</pub-id><pub-id pub-id-type="pmid">21863008</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Active sensation during orientation behavior in the Drosophila larva: more sense than luck</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>208</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.11.008</pub-id><pub-id pub-id-type="pmid">22169055</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorur-Shandilya</surname> <given-names>S</given-names></name><name><surname>Demir</surname> <given-names>M</given-names></name><name><surname>Long</surname> <given-names>J</given-names></name><name><surname>Clark</surname> <given-names>DA</given-names></name><name><surname>Emonet</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Olfactory receptor neurons use gain control and complementary kinetics to encode intermittent odorant stimuli</article-title><source>eLife</source><volume>6</volume><elocation-id>e27670</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27670</pub-id><pub-id pub-id-type="pmid">28653907</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernandez-Nunez</surname> <given-names>L</given-names></name><name><surname>Belina</surname> <given-names>J</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Si</surname> <given-names>G</given-names></name><name><surname>Claus</surname> <given-names>L</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name><name><surname>Samuel</surname> <given-names>ADT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reverse-correlation analysis of navigation dynamics in Drosophila larva using optogenetics</article-title><source>eLife</source><volume>4</volume><elocation-id>e06225</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06225</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kane</surname> <given-names>EA</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Afonso</surname> <given-names>B</given-names></name><name><surname>Larderet</surname> <given-names>I</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Carter</surname> <given-names>AR</given-names></name><name><surname>de Bivort</surname> <given-names>BL</given-names></name><name><surname>Sprecher</surname> <given-names>SG</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sensorimotor structure of Drosophila larva phototaxis</article-title><source>PNAS</source><volume>110</volume><fpage>E3868</fpage><lpage>E3877</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215295110</pub-id><pub-id pub-id-type="pmid">24043822</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>KJ</given-names></name><name><surname>Rieke</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal contrast adaptation in the input and output signals of salamander retinal ganglion cells</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>287</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-01-00287.2001</pub-id><pub-id pub-id-type="pmid">11150346</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>KJ</given-names></name><name><surname>Rieke</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Slow Na+ inactivation and variance adaptation in salamander retinal ganglion cells</article-title><source>The Journal of Neuroscience : The Official Journal of the Society for Neuroscience</source><volume>23</volume><fpage>1506</fpage><lpage>1516</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-04-01506.2003</pub-id><pub-id pub-id-type="pmid">12598639</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kvale</surname> <given-names>MN</given-names></name><name><surname>Schreiner</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Short-term adaptation of auditory receptive fields to dynamic stimuli</article-title><source>Journal of Neurophysiology</source><volume>91</volume><fpage>604</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1152/jn.00484.2003</pub-id><pub-id pub-id-type="pmid">14762146</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lahiri</surname> <given-names>S</given-names></name><name><surname>Shen</surname> <given-names>K</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Tang</surname> <given-names>A</given-names></name><name><surname>Kane</surname> <given-names>E</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Garrity</surname> <given-names>P</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Two alternating motor programs drive navigation in Drosophila larva</article-title><source>PLoS One</source><volume>6</volume><elocation-id>e23180</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0023180</pub-id><pub-id pub-id-type="pmid">21858019</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>A simple coding procedure enhances a neuron's information capacity</article-title><source>Zeitschrift Für Naturforschung C</source><volume>36</volume><fpage>910</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1515/znc-1981-9-1040</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>B</given-names></name><name><surname>Macellaio</surname> <given-names>MV</given-names></name><name><surname>Osborne</surname> <given-names>LC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Efficient sensory cortical coding optimizes pursuit eye movements</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12759</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12759</pub-id><pub-id pub-id-type="pmid">27611214</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Louis</surname> <given-names>M</given-names></name><name><surname>Huber</surname> <given-names>T</given-names></name><name><surname>Benton</surname> <given-names>R</given-names></name><name><surname>Sakmar</surname> <given-names>TP</given-names></name><name><surname>Vosshall</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bilateral olfactory sensory input enhances chemotaxis behavior</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>187</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1038/nn2031</pub-id><pub-id pub-id-type="pmid">18157126</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Rosenzweig</surname> <given-names>M</given-names></name><name><surname>Kang</surname> <given-names>K</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name><name><surname>Garrity</surname> <given-names>PA</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Navigational decision making in Drosophila thermotaxis</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>4261</fpage><lpage>4272</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4090-09.2010</pub-id><pub-id pub-id-type="pmid">20335462</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maravall</surname> <given-names>M</given-names></name><name><surname>Petersen</surname> <given-names>RS</given-names></name><name><surname>Fairhall</surname> <given-names>AL</given-names></name><name><surname>Arabzadeh</surname> <given-names>E</given-names></name><name><surname>Diamond</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Shifts in coding properties and maintenance of information transmission during adaptation in barrel cortex</article-title><source>PLoS Biology</source><volume>5</volume><elocation-id>e19</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0050019</pub-id><pub-id pub-id-type="pmid">17253902</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Maravall</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Adaptation and sensory coding</chapter-title><source>Principles of Neural Coding</source><publisher-loc>United States</publisher-loc><publisher-name>CRC press</publisher-name><fpage>357</fpage><lpage>378</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molnar</surname> <given-names>A</given-names></name><name><surname>Hsueh</surname> <given-names>HA</given-names></name><name><surname>Roska</surname> <given-names>B</given-names></name><name><surname>Werblin</surname> <given-names>FS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Crossover inhibition in the retina: circuitry that compensates for nonlinear rectifying synaptic transmission</article-title><source>Journal of Computational Neuroscience</source><volume>27</volume><fpage>569</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1007/s10827-009-0170-6</pub-id><pub-id pub-id-type="pmid">19636690</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagel</surname> <given-names>KI</given-names></name><name><surname>Doupe</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Temporal processing and adaptation in the songbird auditory forebrain</article-title><source>Neuron</source><volume>51</volume><fpage>845</fpage><lpage>859</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.030</pub-id><pub-id pub-id-type="pmid">16982428</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nemenman</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Information theory and adaptation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1011.5466">https://arxiv.org/abs/1011.5466</ext-link></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nemenman</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Gain control in molecular information processing: lessons from neuroscience</article-title><source>Physical Biology</source><volume>9</volume><elocation-id>026003</elocation-id><pub-id pub-id-type="doi">10.1088/1478-3975/9/2/026003</pub-id><pub-id pub-id-type="pmid">22475952</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niven</surname> <given-names>JE</given-names></name><name><surname>Laughlin</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Energy limitation as a selective pressure on the evolution of sensory systems</article-title><source>Journal of Experimental Biology</source><volume>211</volume><fpage>1792</fpage><lpage>1804</lpage><pub-id pub-id-type="doi">10.1242/jeb.017574</pub-id><pub-id pub-id-type="pmid">18490395</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname> <given-names>SR</given-names></name><name><surname>Wilson</surname> <given-names>RI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lateral presynaptic inhibition mediates gain control in an olfactory circuit</article-title><source>Nature</source><volume>452</volume><fpage>956</fpage><lpage>960</lpage><pub-id pub-id-type="doi">10.1038/nature06864</pub-id><pub-id pub-id-type="pmid">18344978</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozuysal</surname> <given-names>Y</given-names></name><name><surname>Baccus</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Linking the computational structure of variance adaptation to biophysical mechanisms</article-title><source>Neuron</source><volume>73</volume><fpage>1002</fpage><lpage>1015</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.029</pub-id><pub-id pub-id-type="pmid">22405209</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parise</surname> <given-names>CV</given-names></name><name><surname>Ernst</surname> <given-names>MO</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Correlation detection as a general mechanism for multisensory integration</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11543</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11543</pub-id><pub-id pub-id-type="pmid">27265526</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parnas</surname> <given-names>M</given-names></name><name><surname>Lin</surname> <given-names>AC</given-names></name><name><surname>Huetteroth</surname> <given-names>W</given-names></name><name><surname>Miesenböck</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Odor discrimination in Drosophila: from neural population codes to behavior</article-title><source>Neuron</source><volume>79</volume><fpage>932</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.006</pub-id><pub-id pub-id-type="pmid">24012006</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dimensionality reduction in neural models: An information-theoretic generalization of spike-triggered average and covariance analysis</article-title><source>Journal of Vision</source><volume>6</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1167/6.4.9</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawin</surname> <given-names>EP</given-names></name><name><surname>Harris</surname> <given-names>LR</given-names></name><name><surname>Campos</surname> <given-names>AR</given-names></name><name><surname>Sokolowski</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Sensorimotor transformation from light reception to phototactic behavior inDrosophila larvae (Diptera: Drosophilidae)</article-title><source>Journal of Insect Behavior</source><volume>7</volume><fpage>553</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1007/BF02025449</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulze</surname> <given-names>A</given-names></name><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Rajendran</surname> <given-names>VG</given-names></name><name><surname>Lott</surname> <given-names>G</given-names></name><name><surname>Musy</surname> <given-names>M</given-names></name><name><surname>Ahammad</surname> <given-names>P</given-names></name><name><surname>Deogade</surname> <given-names>A</given-names></name><name><surname>Sharpe</surname> <given-names>J</given-names></name><name><surname>Riedl</surname> <given-names>J</given-names></name><name><surname>Jarriault</surname> <given-names>D</given-names></name><name><surname>Trautman</surname> <given-names>ET</given-names></name><name><surname>Werner</surname> <given-names>C</given-names></name><name><surname>Venkadesan</surname> <given-names>M</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dynamical feature extraction at the sensory periphery guides chemotaxis</article-title><source>eLife</source><volume>4</volume><elocation-id>e06694</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06694</pub-id><pub-id pub-id-type="pmid">26077825</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>O</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spike-triggered neural characterization</article-title><source>Journal of Vision</source><volume>6</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/6.4.13</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Si</surname> <given-names>G</given-names></name><name><surname>Kanwal</surname> <given-names>JK</given-names></name><name><surname>Hu</surname> <given-names>Y</given-names></name><name><surname>Tabone</surname> <given-names>CJ</given-names></name><name><surname>Baron</surname> <given-names>J</given-names></name><name><surname>Berck</surname> <given-names>ME</given-names></name><name><surname>Vignoud</surname> <given-names>G</given-names></name><name><surname>Samuel</surname> <given-names>ADT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Invariances in a combinatorial olfactory receptor code</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/208538</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smirnakis</surname> <given-names>SM</given-names></name><name><surname>Berry</surname> <given-names>MJ</given-names></name><name><surname>Warland</surname> <given-names>DK</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Adaptation of retinal processing to image contrast and spatial scale</article-title><source>Nature</source><volume>386</volume><fpage>69</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1038/386069a0</pub-id><pub-id pub-id-type="pmid">9052781</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname> <given-names>MV</given-names></name><name><surname>Laughlin</surname> <given-names>SB</given-names></name><name><surname>Dubs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Predictive coding: a fresh view of inhibition in the retina</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>216</volume><fpage>427</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1098/rspb.1982.0085</pub-id><pub-id pub-id-type="pmid">6129637</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkačik</surname> <given-names>G</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Information processing in living systems</article-title><source>Annual Review of Condensed Matter Physics</source><volume>7</volume><fpage>89</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1146/annurev-conmatphys-031214-014803</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wark</surname> <given-names>B</given-names></name><name><surname>Lundstrom</surname> <given-names>BN</given-names></name><name><surname>Fairhall</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Sensory adaptation</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>423</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.07.001</pub-id><pub-id pub-id-type="pmid">17714934</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wark</surname> <given-names>B</given-names></name><name><surname>Fairhall</surname> <given-names>A</given-names></name><name><surname>Rieke</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Timescales of inference in visual adaptation</article-title><source>Neuron</source><volume>61</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.019</pub-id><pub-id pub-id-type="pmid">19285471</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname> <given-names>B</given-names></name><name><surname>Wang</surname> <given-names>GI</given-names></name><name><surname>Dean</surname> <given-names>I</given-names></name><name><surname>Delgutte</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dynamic range adaptation to sound level statistics in the auditory nerve</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13797</fpage><lpage>13808</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5610-08.2009</pub-id><pub-id pub-id-type="pmid">19889991</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werblin</surname> <given-names>FS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Six different roles for crossover inhibition in the retina: correcting the nonlinearities of synaptic transmission</article-title><source>Visual Neuroscience</source><volume>27</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1017/S0952523810000076</pub-id><pub-id pub-id-type="pmid">20392301</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>B</given-names></name><name><surname>Hofmann</surname> <given-names>D</given-names></name><name><surname>Pinkoviezky</surname> <given-names>I</given-names></name><name><surname>Sober</surname> <given-names>SJ</given-names></name><name><surname>Nemenman</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chance, long tails, and inference in a non-Gaussian, Bayesian theory of vocal learning in songbirds</article-title><source>PNAS</source><volume>115</volume><fpage>E8538</fpage><lpage>E8546</lpage><pub-id pub-id-type="doi">10.1073/pnas.1713020115</pub-id><pub-id pub-id-type="pmid">30127024</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.37945.019</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Variance Adaptation in Navigational Decision Making&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Eve Marder as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Gepner et al. present data showing that larval navigational behavior adapts to the variance of various stimuli. They use optical stimuli to probe visual pathways naturally and olfactory pathways via channelrhodopsin; both pathways show contrast adaptation, but not cross-adaptation between the two pathways. (A very elegant experiment with correlated vs. uncorrelated noise between the two channels showed some mild interactions.) They measure the timescale of the adaptation and show that the different kinetics for adapting to contrast increments vs. decrements are consistent with an optimal detection theory. The authors also used a more natural stimulus paradigm to show that this sort of adaptation is not purely a function of their artificial stimuli.</p><p>Throughout, the authors fit their data to a variety of models. They showed that their data were best explained by input rescaling, that their data were consistent with a model in which a Bayes' optimal estimate of variance occurs on timescales of ~1s, and that signals are combined with a potentially multiplicative interaction.</p><p>The experiments are well done and the analysis is convincing.</p><p>Essential revisions:</p><p>Two major concerns arose in consultation:</p><p>1) The protocol for contrast adaptation looks different from the classical ones in the field, and reviewer #1, point 1 requests clarification and a new experiment that should be doable in a short time.</p><p>2) We would like to see a quantification of how filter shape depends on stimulus variance, and reviewer #2, point 1 provides details of the analyses needed.</p><p><italic>Reviewer #1:</italic> </p><p>1) If I understand it correctly, the change in stimulus variance is related to a change in correlation time of the light intensity, rather than in its variance about a mean, in order to get the derivatives to scale as intended. Does this cause any problems? What if you just do it the naïve way, by scaling the entire light intensity trace contrast, so that the derivatives and deviations both scale up? Is the answer the same? I think this is potentially important because contrast adaptation is crucially dependent on the timescale on which one computes contrast, and by changing the timescale of the stimulus correlations, one might change regimes. (As an extreme case, if fluctuations were made incredibly slow, one would presumably begin to measure adaptation to the mean, rather than to the contrast.)</p><p>2) The authors frame the adaptation as rescaling the nonlinearity, but what if adaptation rescales the linear filter amplitude. These are mathematically equivalent, and if you do the rescaling of the linear filter amplitude, then the Figure 8B model seems like it could be reconciled with the independent adaptation of the two channels. Is this a problem for excluding Figure 8B for this reason?</p><p>3) The multiplicative model is different from additive in the case of polynomial terms of order &gt;1 in the exponential. However, if you expand everything in Taylor series, is the multiplication just allowing a few more higher order interactions between the terms? The relative coefficients of those higher order terms is restricted by this multiplication step. But what happens if you fit models that just allow up-to-cubic interactions between the x<sub>O</sub> and x<sub>L</sub> filtered terms before applying the exponential? (This would be a nonlinear interaction before applying the second nonlinearity.) Can you do better than multiplication? If so, would that imply that there's some kind of nonlinear summation of the terms with potentially small nonlinearities that is in fact the best fit? Or is multiplicative really a better model because it requires fewer fitting terms? A BIC evaluation seems like it could resolve this.</p><p><italic>Reviewer #2:</italic></p><p>1) A major point of confusion for me was that the authors claim that the linear filters are conserved across different values of stimulus variance. Unless I missed it, there is no quantification of this (except for the claim of 'having established that the kernel shape did not depend on the input variance', subsection “Larvae Adapt Their Turn-Rate to the Variance in Visual and Olfactory Sensory In-puts”), and the figures shown (Figure 1D, Figure 3A) suggest that there actually is a consistent effect of increasing variance on filter shape – namely the relative height of the left shoulder of the filter. While this is not a qualitative change in filter shape, it does change to what extent larvae take into account information about the stimulus further away from the turn. Hence, I would like to see a quantification of how filter shape depends on stimulus variance (e.g., by plotting f_hi vs f_low – if filter shape is preserved across variances, all points should be close to the diagonal – it looks as if filter values close to the peak will lie on the diagonal, but filter values around -6 to -4 seconds prior to the turn should lie off diagonal). Using the actual filter shape for each variance, rather than the filter derived from pooled data, might affect (in both directions) the reported effects of variance on the shape of the nonlinearity.</p><p>2) There were also some issues with the writing. For example, the abstract is lacking a description of the niche this work aims to fill, and a statement on the general relevance of the findings – as another example, the authors don't example why it is interesting that multisensory integration involves a multiplicative step and what the implication is for behavior. I also often had to go back to their previous paper (Gepner et al., 2015) and dig into the details of their model or look up details on the coordinate transform (see comment below). The rationale for each plot is not made sufficiently clear to the reader. It would help if the authors show more raw data to provide an intuition for the derived plots – e.g., what happens to animal turning following the switch in variance from low to high or high to low (such as in Figure 3)?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.37945.020</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>[…] Essential revisions:</p><p>Two major concerns arose in consultation:</p><p>1) The protocol for contrast adaptation looks different from the classical ones in the field, and reviewer #1, point 1 requests clarification and a new experiment that should be doable in a short time.</p><p>2) We would like to see a quantification of how filter shape depends on stimulus variance, and reviewer #2, point 1 provides details of the analyses needed.</p></disp-quote><p>We thank the reviewers for their positive assessment of our work and their valuable suggestions. Our point-by-point responses follow.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>1) If I understand it correctly, the change in stimulus variance is related to a change in correlation time of the light intensity, rather than in its variance about a mean, in order to get the derivatives to scale as intended. Does this cause any problems? What if you just do it the naïve way, by scaling the entire light intensity trace contrast, so that the derivatives and deviations both scale up? Is the answer the same? I think this is potentially important because contrast adaptation is crucially dependent on the timescale on which one computes contrast, and by changing the timescale of the stimulus correlations, one might change regimes. (As an extreme case, if fluctuations were made incredibly slow, one would presumably begin to measure adaptation to the mean, rather than to the contrast.)</p></disp-quote><p>In all the experiments presented in the initial submission of our paper, the light intensity obeys a random walk. In a random walk without boundary conditions, the correlation time is infinite, because the average (and most probable) future location is always the current location.<disp-formula id="equ52"><mml:math id="m52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msqrt></mml:mfrac><mml:mo>−</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> independent of </mml:mtext><mml:mi>τ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Our led output levels are bounded below by 0 and above by a maximum output level, so the intensity obeys the statistics of a random walk with reflecting boundary conditions. In this case, there is a finite correlation time, which depends on the diffusion constant and the boundary conditions. In the high variance condition, the correlation time is ~12 seconds and in the low variance condition the correlation time is approximately 104 seconds (Figure 4—figure supplement 1D).</p><p>We observe adaptation to high variance almost immediately after the switch, while adaptation to low variance occurs over about 10 seconds. Both of these are much faster than the correlation time of the stimulus in their respective conditions.</p><p>We initially chose to use a stimulus with uncorrelated derivatives rather than uncorrelated values because previous work has shown that the derivative of the stimulus is more salient to larva than its value, and also to align with our previous work. With uncorrelated derivatives, the light intensities themselves are the same in high and low variance conditions – both span the entire range from 0 to max intensity. In an uncorrelated value stimulus, the high variance condition necessarily includes higher light intensities than are sampled in the low variance condition (compare Figure 4—figure supplement 1C and J). As a result, we worried that adaptation to high variance might be interpreted as due to effects associated with high light intensities, e.g. saturation of receptors or ion channels.</p><p>The reviewer’s questions about the structure of our stimulus are well thought out and likely quite common, and we welcome the opportunity to address them in depth in this response letter. We also now include a short discussion and a new Figure 4—figure supplement 1, which shows the stimulus and help visualize what happens when the variance changes.</p><p>As the reviewer requested, we also carried out an experiment in which light levels were randomly selected from a normal distribution with constant mean and changing variance. We analyzed these in the LNP framework with the kernel computed from the “turn-triggered-average” stimulus value, and we recapitulated the results from the uncorrelated derivative experiments: larvae adapt to variance via a rescaling of the nonlinear function, and they adapt more quickly to increases of variance than decreases. These results are shown in new Figure 4.</p><disp-quote content-type="editor-comment"><p>2) The authors frame the adaptation as rescaling the nonlinearity, but what if adaptation rescales the linear filter amplitude. These are mathematically equivalent, and if you do the rescaling of the linear filter amplitude, then the Figure 8B model seems like it could be reconciled with the independent adaptation of the two channels. Is this a problem for excluding Figure 8B for this reason?</p></disp-quote><p>We agree that rescaling the kernel and rescaling the input to the nonlinear function are completely equivalent. We also agree that formally, the Figure 8B model works if you are able to rescale the kernel while preserving the linearity of its output. While this is mathematically simple, it is difficult to understand how this might be achieved in a biological system.</p><p>Measuring the variance of a signal requires a nonlinear computation, and both spiking and synaptic transmission rectify, so it is natural that biophysical models of adaptation take advantage of these nonlinearities. For instance, Kim and Rieke, (2003) show how an apparent linear rescaling of the filter results from biophysical nonlinearities, including spiking. The LNK model (Ozuysal and Baccus, 2012) accomplishes variance adaptation using a kinetics block following a rectifying nonlinearity. In both of these cases, the LN cascade takes place within a single neuron. Similarly, the Somponlinsky model (Borst et al., 2005) requires a saturating nonlinearity. We are not aware of any mechanistic model of variance adaptation that does not require a nonlinear transformation of the input.</p><p>Our finding (Gepner, Mihovilovic and Skanata, 2015) that larvae linearly combine odor and light signals (Figure 8B, this work) requires that these signals be transmitted linearly from the sensory peripheries to some part of the brain responsible for multisensory combination. Because it is difficult to send both positive and negative signals through the same synaptic pathway, this was already somewhat puzzling. But one might, for instance, imagine that for both light and odor, 0 change was represented by a significant amount of excitation which was then balanced by tonic inhibition at the point of combination.</p><p>Now we have added the finding that adaptation to variance is upstream of multisensory combination. While one can imagine more elaborate arrangements that would allow the framework of Figure 8B to accommodate variance adaptations, we do not know how variance adaptation might be achieved while preserving linearity. And because variance measurement requires a nonlinear computation, the most parsimonious explanation is that feedback from the rectifying nonlinearity already present in our model should be used to achieve adaptation.</p><p>In summary, there is nothing mathematically wrong with this extension of the Figure 8b model to accommodate variance adaptation. But we believe that rescaling the light and odor kernels in response to changes in variance, linearly combining the odor and light filter outputs, and then using that linear combination as the input to a rectifying nonlinearity is biologically implausible. Hence, we sought an alternate model that was more biologically plausible while remaining at least as accurate mathematically.</p><p>We have rewritten the discussion of the combination models (which has been moved to the Results section, per reviewer 2’s suggestion) to clarify these points.</p><disp-quote content-type="editor-comment"><p>3) The multiplicative model is different from additive in the case of polynomial terms of order &gt;1 in the exponential. However, if you expand everything in Taylor series, is the multiplication just allowing a few more higher order interactions between the terms? The relative coefficients of those higher order terms is restricted by this multiplication step. But what happens if you fit models that just allow up-to-cubic interactions between the x<sub>O</sub> and x<sub>L</sub> filtered terms before applying the exponential? (This would be a nonlinear interaction before applying the second nonlinearity.) Can you do better than multiplication? If so, would that imply that there's some kind of nonlinear summation of the terms with potentially small nonlinearities that is in fact the best fit? Or is multiplicative really a better model because it requires fewer fitting terms? A BIC evaluation seems like it could resolve this.</p></disp-quote><p>We believe (see discussion above) that the multiplicative model (Figure 8C), is more biologically plausible than the linear combination model (Figure 8B) in the face of our finding that larvae adapt to the variance of each sense individually (Figure 7). For consistency, we felt it was also important to show that the multiplicative model was at least as explanatory of our previous experiments as the linear combination model.</p><p>When we reexamined the data from Gepner, Mihovilovic and Skanata et al. using the multiplicative combination model, we found that it increased the likelihood of that data given the best-fit model by a statistically significant amount compared to the best fit linear combination model. However, if one looks at the actual predictions made by these two models (Figure 8—figure supplement 1B, Figure 8—figure supplement 2), there are only minute differences. It would be possible, especially with more data, to compare these two models at higher polynomial orders, but presumably the best-fit rate functions would remain quite similar. Our goal was to show that the multiplicative model could explain our past data; we believe the current analysis satisfies this goal and hence have not extended the analysis to higher orders.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>1) A major point of confusion for me was that the authors claim that the linear filters are conserved across different values of stimulus variance. […] Hence, I would like to see a quantification of how filter shape depends on stimulus variance (e.g., by plotting f_hi vs f_low – if filter shape is preserved across variances, all points should be close to the diagonal – it looks as if filter values close to the peak will lie on the diagonal, but filter values around -6 to -4 seconds prior to the turn should lie off diagonal). Using the actual filter shape for each variance, rather than the filter derived from pooled data, might affect (in both directions) the reported effects of variance on the shape of the nonlinearity.</p></disp-quote><p>We have added bootstrapped error bars to the recovered turn triggered averages. We have also re-analyzed the data of Figure 1 using different filter shapes for the low and high variance conditions (Figure 1—figure supplement 2). The derived rate functions are identical within the precision of our measurement. Specifically, using a variance-specific kernel would not change the rate-function presented in Figure 1E.</p><p>We estimate the time-varying rescaling parameter(s) (Figure 3, Figure 4, Figure 5 and Figure 7) with maximum likelihood estimation on the static rate function parameters and temporal sequence of rescaling parameter(s). To perform this estimate, we use the pre-computed convolved stimulus as the input to the nonlinear function. It would be computationally challenging to extend our approach to include a time-varying filter on the raw stimulus input. We would not want to use pre-computed low and high variance kernels separately on the low and high variance portions of the stimulus, because an important feature of our analysis is that rescaling emerges from fitting the observed turn rate to the input stimulus without any pre-computation of the variance.</p><p>Figure—figure supplement 2 now shows an analysis of Figure 1 data using separate high and low variance kernels. We have rewritten subsection “Larvae Adapt Their Turn-Rate to the Variance in Visual and Olfactory Sensory Inputs” to remove the claim that the linear filter is the same at high and low variance and instead to emphasize that the most dramatic effect is the rescaling of the nonlinear function.</p><disp-quote content-type="editor-comment"><p>2) There were also some issues with the writing. For example, the abstract is lacking a description of the niche this work aims to fill, and a statement on the general relevance of the findings – as another example, the authors don't example why it is interesting that multisensory integration involves a multiplicative step and what the implication is for behavior. I also often had to go back to their previous paper (Gepner et al., 2015) and dig into the details of their model or look up details on the coordinate transform (see comment below). The rationale for each plot is not made sufficiently clear to the reader. It would help if the authors show more raw data to provide an intuition for the derived plots – e.g., what happens to animal turning following the switch in variance from low to high or high to low (such as in Figure 3)?</p></disp-quote><p>We have edited the abstract and introduction to improve readability. We added Figure 1—figure supplement 1 to sketch how we extract high and low variance turn rates from the applied stimulus and observed behavioral raster.</p></body></sub-article></article>