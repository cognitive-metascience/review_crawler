<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">17328</article-id><article-id pub-id-type="doi">10.7554/eLife.17328</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Midbrain dopamine neurons signal aversion in a reward-context-dependent manner</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-53313"><name><surname>Matsumoto</surname><given-names>Hideyuki</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-57274"><name><surname>Tian</surname><given-names>Ju</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-10010"><name><surname>Uchida</surname><given-names>Naoshige</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5755-9409</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="other" rid="par-6"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-37870"><name><surname>Watabe-Uchida</surname><given-names>Mitsuko</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7864-754X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Center for Brain Science</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Molecular and Cellular Biology</institution>, <institution>Harvard University</institution>, <addr-line><named-content content-type="city">Cambridge</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Costa</surname><given-names>Rui M</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>Fundação Champalimaud</institution>, <country>Portugal</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>mitsuko@mcb.harvard.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>19</day><month>10</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e17328</elocation-id><history><date date-type="received"><day>27</day><month>04</month><year>2016</year></date><date date-type="accepted"><day>23</day><month>09</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Matsumoto et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Matsumoto et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-17328-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.17328.001</object-id><p>Dopamine is thought to regulate learning from appetitive and aversive events. Here we examined how optogenetically-identified dopamine neurons in the lateral ventral tegmental area of mice respond to aversive events in different conditions. In low reward contexts, most dopamine neurons were exclusively inhibited by aversive events, and expectation reduced dopamine neurons’ responses to reward and punishment. When a single odor predicted both reward and punishment, dopamine neurons’ responses to that odor reflected the integrated value of both outcomes. Thus, in low reward contexts, dopamine neurons signal value prediction errors (VPEs) integrating information about both reward and aversion in a common currency. In contrast, in high reward contexts, dopamine neurons acquired a short-latency excitation to aversive events that masked their VPE signaling. Our results demonstrate the importance of considering the contexts to examine the representation in dopamine neurons and uncover different modes of dopamine signaling, each of which may be adaptive for different environments.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.001">http://dx.doi.org/10.7554/eLife.17328.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.17328.002</object-id><title>eLife digest</title><p>There are many types of learning; one type of learning means that rewards and punishments can shape future behavior. Dopamine is a molecule that allows neurons in the brain to communicate with one another, and it is released in response to unexpected rewards. Most neuroscientists believe that dopamine is important to learn from the reward; however, there are different opinions about whether dopamine is important to learn from punishments or not.</p><p>Previous studies that tried to examine how dopamine activities change in response to punishment have reported different results. One of the likely reasons for the controversy is that it was difficult to measure only the activity of dopamine-releasing neurons.</p><p>To overcome this issue, Matsumoto et al. used genetically engineered mice in which shining a blue light into their brain would activate their dopamine neurons but not any other neurons. Tiny electrodes were inserted into the brains of these mice, and a blue light was used to confirm that these electrodes were recording from the dopamine-producing neurons. Specifically if the electrode detected an electrical impulse when blue light was beamed into the brain, then the recorded neuron was confirmed to be a dopamine-producing neuron.</p><p>Measuring the activities of these dopamine neurons revealed that they were indeed activated by reward but inhibited by punishment. In other words, dopamine neurons indeed can signal punishments as negative and rewards as positive on a single axis. Further experiments showed that, if the mice predicted both a reward and a punishment, the dopamine neurons could integrate information from both to direct learning.</p><p>Matsumoto et al. also saw that when mice received rewards too often, their dopamine neurons did not signal punishment correctly. These results suggest that how we feel about punishment may depend on how often we experience rewards.</p><p>In addition to learning, dopamine has also been linked to many psychiatric symptoms such as addiction and depression. The next challenge will be to examine how the frequency of rewards changes an animal’s state and responses to punishment in more detail, and how this relates to normal and abnormal behaviors.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.002">http://dx.doi.org/10.7554/eLife.17328.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>dopamine</kwd><kwd>value</kwd><kwd>prediction error</kwd><kwd>aversion</kwd><kwd>context</kwd><kwd>eye blink</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>JSPS postdoctoral fellowship for research abroad</award-id><principal-award-recipient><name><surname>Matsumoto</surname><given-names>Hideyuki</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008732</institution-id><institution>Uehara Memorial Foundation</institution></institution-wrap></funding-source><award-id>The Uehara Memorial Foundation postdoctoral fellowship</award-id><principal-award-recipient><name><surname>Matsumoto</surname><given-names>Hideyuki</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution>Sackler Scholar Programme in Psychology</institution></institution-wrap></funding-source><award-id>Predoctoral fellowship</award-id><principal-award-recipient><name><surname>Tian</surname><given-names>Ju</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH095953</award-id><principal-award-recipient><name><surname>Uchida</surname><given-names>Naoshige</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH101207</award-id><principal-award-recipient><name><surname>Uchida</surname><given-names>Naoshige</given-names></name></principal-award-recipient></award-group><award-group id="par-6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01MH110404</award-id><principal-award-recipient><name><surname>Uchida</surname><given-names>Naoshige</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Dopamine neurons signal value prediction errors (VPEs) integrating information about both reward and aversion, in low reward contexts, whereas VPEs in some dopamine neurons are distorted in high reward contexts.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Dopamine is thought to be a key regulator of learning from appetitive as well as aversive events (<xref ref-type="bibr" rid="bib51">Schultz et al., 1997</xref>; <xref ref-type="bibr" rid="bib64">Wenzel et al., 2015</xref>). It has been proposed that dopamine neurons act as a teaching signal in the brain by signaling the discrepancy between the values of actual and predicted rewards, that is, reward prediction error (RPE) (<xref ref-type="bibr" rid="bib3">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib19">Hart et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Roesch et al., 2007</xref>; <xref ref-type="bibr" rid="bib47">Schultz, 2010</xref>; <xref ref-type="bibr" rid="bib51">Schultz et al., 1997</xref>). Although accumulating evidence supports this idea with respect to rewarding and reward-predicting events (<xref ref-type="bibr" rid="bib3">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Eshel et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Hart et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Roesch et al., 2007</xref>; <xref ref-type="bibr" rid="bib47">Schultz, 2010</xref>; <xref ref-type="bibr" rid="bib51">Schultz et al., 1997</xref>), how dopamine neurons integrate information about aversive events remains highly controversial.</p><p>Pioneering work by Wolfram Schultz and colleagues introduced the idea that dopamine neurons signal RPE. This work demonstrated that dopamine neurons in the midbrain of monkeys exhibit a highly specific set of responses to reward (<xref ref-type="bibr" rid="bib36">Mirenowicz and Schultz, 1994</xref>). When the animal receives reward unexpectedly, dopamine neurons fire a burst of action potentials. If a sensory cue reliably predicts reward, however, dopamine neurons decrease their response to reward, and instead burst to the cue. Finally, if an expected reward is omitted, dopamine neurons pause their firing at the time they usually receive reward (<xref ref-type="bibr" rid="bib20">Hollerman and Schultz, 1998</xref>; <xref ref-type="bibr" rid="bib51">Schultz et al., 1997</xref>). Subsequently, the idea of RPE coding by dopamine neurons has been substantiated by further experiments in a variety of species including monkeys (<xref ref-type="bibr" rid="bib3">Bayer and Glimcher, 2005</xref>; <xref ref-type="bibr" rid="bib20">Hollerman and Schultz, 1998</xref>; <xref ref-type="bibr" rid="bib63">Waelti et al., 2001</xref>), rats (<xref ref-type="bibr" rid="bib16">Flagel et al., 2011</xref>; <xref ref-type="bibr" rid="bib40">Pan et al., 2005</xref>; <xref ref-type="bibr" rid="bib44">Roesch et al., 2007</xref>), mice (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Eshel et al., 2015</xref>) and humans (<xref ref-type="bibr" rid="bib10">D'Ardenne et al., 2008</xref>). This signal is proposed to underlie associative learning (<xref ref-type="bibr" rid="bib42">Rescorla and Wagner, 1972</xref>), and bears a striking resemblance to machine learning algorithms (<xref ref-type="bibr" rid="bib54">Sutton and Barto, 1998</xref>).</p><p>Many of the previous studies that characterized dopamine responses used rewarded outcomes with varying degrees of predictability. Comparatively fewer studies have used aversive stimuli in the context of prediction errors. Among studies that have used aversive stimuli, these provide differing reports as to how dopamine neurons respond to aversive stimuli (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>; <xref ref-type="bibr" rid="bib48">Schultz, 2015</xref>; <xref ref-type="bibr" rid="bib64">Wenzel et al., 2015</xref>).</p><p>It is thought that the majority of dopamine neurons are inhibited by aversive stimuli (<xref ref-type="bibr" rid="bib35">Mileykovskiy and Morales, 2011</xref>; <xref ref-type="bibr" rid="bib37">Mirenowicz and Schultz, 1996</xref>; <xref ref-type="bibr" rid="bib55">Tan et al., 2012</xref>; <xref ref-type="bibr" rid="bib60">Ungless et al., 2004</xref>). However, a number of electrophysiological recording studies have reported that dopamine neurons are activated by aversive stimuli both in anesthetized (<xref ref-type="bibr" rid="bib4">Brischoux et al., 2009</xref>; <xref ref-type="bibr" rid="bib8">Coizet et al., 2006</xref>; <xref ref-type="bibr" rid="bib50">Schultz and Romo, 1987</xref>) and awake animals (<xref ref-type="bibr" rid="bib18">Guarraci and Kapp, 1999</xref>; <xref ref-type="bibr" rid="bib22">Joshua et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>), although the proportions and locations of aversion-activated neurons differed among these studies. The differences in the results between these studies could be due to the heterogeneity of dopamine neurons or to differences in experimental conditions (e.g. type of aversive stimuli; type of anesthesia). Furthermore, another study using fast-scan cyclic voltammetry found that dopamine neurons are excited during successful avoidance of aversive stimuli (<xref ref-type="bibr" rid="bib39">Oleson et al., 2012</xref>), which could be 'rewarding'. Therefore, some of the excitatory responses to aversive stimuli may not be due to aversiveness alone.</p><p>Some of these discrepancies could correspond to differences in dopamine signaling depending on the projection target. <xref ref-type="bibr" rid="bib45">Roitman et al. (2008)</xref> monitored dopamine dynamics in the nucleus accumbens using cyclic voltammetry while the animal received intra-oral administrations of a sucrose or quinine solution (<xref ref-type="bibr" rid="bib45">Roitman et al., 2008</xref>). This study found that these stimuli caused opposite responses: dopamine release was increased by sucrose and decreased by quinine (<xref ref-type="bibr" rid="bib33">McCutcheon et al., 2012</xref>), suggesting that at least the majority of dopamine neurons projecting to the nucleus accumbens are inhibited by aversive stimuli. <xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka (2009)</xref> examined the diversity of dopamine neurons in context of prediction error. They showed that dopamine neurons that are activated by the prediction of aversive stimuli are located in the lateral part of the substantia nigra pars compacta (SNc), supporting the notion that dopamine subpopulations are spatially segregated (<xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>). Consistent with this finding, <xref ref-type="bibr" rid="bib29">Lerner et al. (2015)</xref> showed, using calcium imaging with fiber photometry, that SNc neurons projecting to the dorsolateral striatum are activated by aversive stimuli (electric shock) whereas those projecting to the dorsomedial striatum are inhibited (<xref ref-type="bibr" rid="bib29">Lerner et al., 2015</xref>). <xref ref-type="bibr" rid="bib27">Lammel et al. (2011)</xref> provided further evidence for spatial heterogeneity by showing that dopamine neurons projecting to the medial prefrontal cortex, located in the medial ventral tegmental area (VTA) exhibited a form of synaptic plasticity (AMPA/NMDA ratio) in response to aversive stimuli (formalin injection) whereas dopamine neurons projecting to the dorsolateral striatum did not (<xref ref-type="bibr" rid="bib27">Lammel et al., 2011</xref>) although how these neurons change their firing patterns in response to aversive stimuli remains unknown.</p><p>In contrast to the above findings suggesting that dopamine neurons are heterogeneous with respect to signaling aversive events, Schultz, Fiorillo and colleagues have argued that dopamine neurons largely ignore aversiveness (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>; <xref ref-type="bibr" rid="bib48">Schultz, 2015</xref>; <xref ref-type="bibr" rid="bib52">Stauffer et al., 2016</xref>). One argument is that the excitation of dopamine neurons caused by aversive stimuli may be due to a 'generalization' or 'spill-over' effect of rewarding stimuli. Specifically, <xref ref-type="bibr" rid="bib37">Mirenowicz and Schultz (1996)</xref> showed that when rewarding and aversive stimuli are predicted by similar cues (e.g. in a same sensory modality), aversion-predicting cues increase their tendency to activate dopamine neurons ('generalization') (<xref ref-type="bibr" rid="bib37">Mirenowicz and Schultz, 1996</xref>). <xref ref-type="bibr" rid="bib24">Kobayashi and Schultz (2014)</xref> showed that in a high-reward context, cues that predict a neutral outcome (e.g. a salient picture) increased their tendency to activate dopamine neurons compared to the neutral cues in a low reward context (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>). Based on these and other observations (<xref ref-type="bibr" rid="bib15">Fiorillo et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Nomoto et al., 2010</xref>), they proposed that the early response reflects attributes such as stimulus generalization and intensity, and the later response reflects the subjective reward value and utility (<xref ref-type="bibr" rid="bib49">Schultz, 2016</xref>; <xref ref-type="bibr" rid="bib52">Stauffer et al., 2016</xref>).</p><p>One influential paper by <xref ref-type="bibr" rid="bib14">Fiorillo (2013)</xref> concluded that dopamine neurons represent prediction errors with respect to reward but not aversiveness (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). That is, dopamine neurons ignore aversive events. Recording from non-human primates, Fiorillo used three pieces of evidence to support this claim: First, dopamine neurons’ responses to aversive outcomes (air puff) were indistinguishable from their responses to neutral outcomes. Second, although most dopamine neurons reduced their reward responses when the reward was predicted, their response to aversive events was unaffected by prediction. Third, dopamine neurons did not integrate the value of aversive events when combined with rewarding events. From these results, the author proposed that the brain represents reward and aversiveness independently along two dimensions (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). As a result, the author proposed that different molecules regulate different types of reinforcement learning: dopamine for reward and a different molecule for aversiveness. If proven true, these ideas are fundamental in understanding how the brain learns from reward and aversion. However, it remains to be clarified whether these observations can be generalized.</p><p>The conclusions in many of the studies cited above relied upon indirect methods such as spike waveforms and firing properties (<xref ref-type="bibr" rid="bib61">Ungless and Grace, 2012</xref>) in order to identify dopamine neurons. These identification methods differed among studies and have recently been called into question (<xref ref-type="bibr" rid="bib26">Lammel et al., 2008</xref>; <xref ref-type="bibr" rid="bib30">Margolis et al., 2006</xref>; <xref ref-type="bibr" rid="bib61">Ungless and Grace, 2012</xref>). The ambiguity of cell-type identification criteria across studies makes it difficult to consolidate data on dopamine signaling. For example, Ungless et al. showed that some neurons in the VTA that were excited by aversive events and identified as dopaminergic using standard electrophysiological criteria were revealed not to be dopaminergic when they were examined with juxtacellular labeling (<xref ref-type="bibr" rid="bib60">Ungless et al., 2004</xref>). Furthermore, Schultz has argued that some previous recording studies may not have targeted areas rich in dopamine neurons (<xref ref-type="bibr" rid="bib49">Schultz, 2016</xref>).</p><p>To circumvent this problem, we tagged dopamine neurons with a light-gated cation channel, channelrhodopsin-2 (ChR2) and unambiguously identified dopamine neurons based on their responses to light (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>). In the present study, we monitored the activity of identified dopamine neurons using a series of behavioral tasks designed to determine how dopamine neurons encode prediction of aversive events in addition to reward. Our results demonstrate that, in contrast to the proposal by <xref ref-type="bibr" rid="bib14">Fiorillo (2013)</xref>, dopamine neurons in VTA indeed are able to encode complete VPE, integrating information about both appetitive and aversive events in a common currency. Importantly, the ability of dopamine neurons to encode VPE depends on both reward contexts and the animal’s trial-by-trial behavioral state.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Identification of dopamine neurons and task designs</title><p>We recorded the spiking activity of total 176 neurons in the VTA using tetrodes while mice performed classical conditioning tasks (<xref ref-type="table" rid="tbl1">Table 1</xref>). To identify neurons as dopaminergic, we optogenetically tagged dopamine neurons (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>). We then used a method developed previously (Stimulus-Associated spike Latency Test [SALT]) (<xref ref-type="bibr" rid="bib12">Eshel et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Kvitsiani et al., 2013</xref>; <xref ref-type="bibr" rid="bib56">Tian and Uchida, 2015</xref>) to determine whether light pulses significantly changed a neuron’s spike timing (p&lt;0.001, <xref ref-type="fig" rid="fig1">Figure 1</xref>). To ensure that spike sorting was not contaminated by light artifacts, we compared the waveforms between spontaneous and light-evoked spikes, as described previously (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>). Dopamine neurons were mostly recorded from the central and posterior part of the lateral VTA including the parabrachial pigmented nucleus (PBP), parainterfascicular nucleus (PIF) and paranigral nucleus (PN) (<xref ref-type="fig" rid="fig1">Figure 1G,K,O</xref>). We obtained 72 optogenetically-identified dopamine neurons in total (5 ± 4 neurons per mouse; mean ± S.D.; <italic>n</italic> = 14 mice).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.003</object-id><label>Figure 1.</label><caption><title>Optogenetic identification of dopamine neurons in the ventral tegmental area (VTA).</title><p>(<bold>A</bold>) Voltage trace from 10 pulses of 10 Hz light stimulation (cyan bars, top) of a representative dopamine neuron. A spontaneous spike and a light-triggered spike were magnified at the bottom. (<bold>B</bold>) Responses from this neuron to 10 Hz (left) and 50 Hz (right) stimulation. (<bold>C</bold>) Isolation of an identified dopamine neuron from noise and other units. (<bold>D</bold>) Histogram of p values testing whether light-activation induced significant changes in spike timing (<italic>n</italic> = 62 neurons) in the mixed prediction task. The p values were derived from SALT (Stimulus-Associated spike Latency Test; see Materials and methods). Neurons with p values &lt; 0.001 and waveform correlations &gt; 0.9 were considered identified (grey). P values and waveform correlations were calculated using light stimulation with all the frequencies (1–50 Hz). (<bold>E</bold>) Probability of light-evoked spike as a function of stimulation frequency for each dopamine neuron (grey) and the average across dopamine neurons (blue circles and bars, median and interquartile range). (<bold>F</bold>) Histograms of the mean (left) and S.D. (right) spike latency to light stimulation with all the frequencies (1–50 Hz) for 26 identified dopamine neurons. (<bold>G</bold>) Reconstruction of the positions of individual dopamine neurons recorded in the mixed prediction task. Each circle represents a lesion site from individual animals used in the mixed prediction task. Each horizontal line on the track (indicated by a vertical line over the lesion site) indicates estimated recording positions of individual dopamine neurons. Labeled structures: parabrachial pigmented nucleus of the VTA (PBP), parainterfascicular nucleus of the VTA (PIF), paranigral nucleus of the VTA (PN), red nucleus (RN), substantia nigra pars compacta (SNc), and substantia nigra pars reticulata (SNr). Scale bar, 1 mm. (<bold>H–J</bold>) Optogenetic identification of dopamine neurons recorded in high and low reward probability tasks (29 dopamine neurons identified out of 73 neurons). Conventions are the same as in <bold>D–F</bold>. (<bold>K</bold>) Reconstruction of the positions of individual dopamine neurons recorded in high (red) and low (cyan) reward probability tasks. Conventions are the same as in <bold>G</bold>. (<bold>L–N</bold>) Optogenetic identification of dopamine neurons recorded in high reward probability task 2 (17 dopamine neurons identified out of 41 neurons). (<bold>O</bold>) Reconstruction of the positions of individual dopamine neurons recorded in high reward probability task 2 (magenta).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.003">http://dx.doi.org/10.7554/eLife.17328.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig1-v1"/></fig><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.004</object-id><label>Table 1.</label><caption><p>Summary of task conditions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.004">http://dx.doi.org/10.7554/eLife.17328.004</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Task</th><th colspan="5">CS (% outcome)</th><th rowspan="2">Reward trials (%)</th><th rowspan="2">Free reward (%)</th></tr><tr><th>Outcome</th><th>Odor A <break/>(Reward CS)</th><th>Odor B <break/>(Nothing CS)</th><th>Odor C <break/>(Air puff CS)</th><th>Odor D <break/>(Reward and air puff CS)</th></tr></thead><tbody><tr><td rowspan="2">Mixed prediction task</td><td>Water</td><td>25</td><td>0</td><td>0</td><td>25</td><td rowspan="2">13</td><td rowspan="2">2</td></tr><tr><td>Air puff</td><td>0</td><td>0</td><td>75</td><td>75</td></tr><tr><td rowspan="2">Low reward probability task</td><td>Water</td><td>20</td><td>0</td><td>0</td><td rowspan="2"/><td rowspan="2">7</td><td rowspan="2">6</td></tr><tr><td>Air puff</td><td>0</td><td>0</td><td>90</td></tr><tr><td rowspan="2">High reward probability task</td><td>Water</td><td>90</td><td>0</td><td>0</td><td rowspan="2"/><td rowspan="2">30</td><td rowspan="2">6</td></tr><tr><td>Air puff</td><td>0</td><td>0</td><td>90</td></tr><tr><td rowspan="2">High reward probability task 2</td><td>Water</td><td>90</td><td>0</td><td>0</td><td rowspan="2"/><td rowspan="2">30</td><td rowspan="2">7</td></tr><tr><td>Air puff</td><td>0</td><td>0</td><td>80</td></tr></tbody></table></table-wrap></p><p>We devised several different tasks to characterize dopamine activities in response to mild aversive air puff (<xref ref-type="table" rid="tbl1">Table 1</xref>). 'Mixed prediction task' (low reward context) was designed to examine interaction between the prediction of reward and the prediction of aversiveness. 'Low reward probability task' (low reward context) and 'high reward probability task' (high reward context) were specifically designed to test the effects of reward probability on dopamine responses: two task conditions differed only with respect to reward probabilities. 'High reward probability task 2' (high reward context) was originally conducted to replicate the diverse responses to aversive stimuli in dopamine neurons, which were reported in multiple previous studies. The effects of reward contexts were also examined with the mixed prediction task and the high reward probability task 2.</p><p>In the present study, we first focused on the characterization of dopamine activities in low reward contexts (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig4">4</xref>). Then, we compared dopamine activities between low and high reward contexts (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Finally, we examined dopamine activities in relation to behaviors in different contexts (<xref ref-type="fig" rid="fig6">Figure 6</xref>).<fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.005</object-id><label>Figure 2.</label><caption><title>Dopamine neurons integrate values of both valences, reward and aversion.</title><p>(<bold>A</bold>) Task design in the mixed prediction task. (<bold>B</bold>) Mean ± S.E.M. of firing rates of optogenetically-identified dopamine neurons during all four trial conditions; reward (blue), nothing (black), punishment (red), and both reward and punishment (magenta). (<bold>C</bold>) Scatter plot of the mean responses during the CS epoch (0–1 s, indicated by a solid black line in <bold>B</bold>) for reward versus nothing. The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. Black filled circles indicate neurons with significant difference between responses to the CS predicting reward and that predicting nothing (unpaired <italic>t</italic> test, p&lt;0.05). (<bold>D</bold>) Scatter plot of the mean responses during the CS epoch for nothing versus punishment. Black filled circles indicate neurons with significant difference between responses to the CS predicting nothing and that predicting punishment. (<bold>E</bold>) Comparison of the responses of individual neurons (<italic>n</italic> = 26) during CS (0–1 s) predicting reward (blue), nothing (black) and punishment (red). For all box plots, the central mark is the median, the edges of the box are the 25th and 75th percentiles, and the whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted individually as plus symbols. **<italic>t</italic>(25) = 3.7, p=0.001, paired <italic>t</italic> test. One outlier &gt;5 Hz in response to Odor A is not represented. (<bold>F</bold>) Scatter plot of the mean responses during the CS epoch for reward versus reward and punishment. Black filled circles indicate neurons with significant difference between responses to the CS predicting reward and that predicting reward and punishment. (<bold>G</bold>) Scatter plot of the mean responses during the CS epoch for reward and punishment versus punishment. Black filled circles indicate neurons with significant difference between responses to the CS predicting punishment and that predicting reward and punishment. (<bold>H</bold>) Comparison of the responses during CS predicting reward (blue), both reward and punishment (magenta), and punishment (red). <sup>1</sup><italic>t</italic>(25) = 2.5, p=0.02; ***<italic>t</italic>(25) = 4.4, p=2.0 × 10<sup>−4</sup>, paired <italic>t</italic> test. One outlier &gt;5 Hz in response to Odor A is not represented.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.005">http://dx.doi.org/10.7554/eLife.17328.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig2-v1"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Comparison of CS responses using dopamine neurons from two animals instead of three.</title><p>(<bold>A–C</bold>) Comparison of the responses of individual dopamine neurons (<bold>A</bold>, <italic>n</italic> = 18; <bold>B</bold>, <italic>n</italic> = 18; and <bold>C</bold>, <italic>n</italic> = 16 from two mice) during CS (0–1 s) predicting reward (blue), nothing (black) and punishment (red). For all box plots, the central mark is the median, the edges of the box are the 25th and 75th percentiles, and the whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted individually as plus symbols. One outlier &gt;5 Hz in response to Odor A is not represented in <bold>A</bold> and <bold>B</bold>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.006">http://dx.doi.org/10.7554/eLife.17328.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig2-figsupp1-v1"/></fig></fig-group><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.007</object-id><label>Figure 3.</label><caption><title>Dopamine neurons signal aversive prediction error.</title><p>(<bold>A</bold>) Mean ± S.E.M. of firing rate of dopamine neurons in response to predicted (red) and unpredicted air puff (purple). (<bold>B</bold>) Scatter plot of the responses to predicted and unpredicted air puff (0–600 ms after air puff, indicated by a black solid line in <bold>A</bold>). Each data point represents an individual dopamine neuron. The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. Black filled circles indicate neurons with significant difference between responses to unpredicted and predicted air puff (unpaired <italic>t</italic> test, p&lt;0.05). (<bold>C</bold>) Comparison of the responses to predicted and unpredicted air puff (<italic>n</italic> = 38). For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. *<italic>t</italic>(37) = 2.4, p=0.02, paired <italic>t</italic> test. (<bold>D</bold>) Histogram of changes in firing rate during the US epoch (0–600 ms) of predicted versus unpredicted air puff. The population average of the auROC curve was significantly different from 0.5 (<italic>n</italic> = 38, *<italic>t</italic>(37) = 2.5, p=0.015, one-sample <italic>t</italic> test). Red arrow indicates mean auROC value. (<bold>E</bold>) Mean ± S.E.M. of firing rate around the outcome period in air puff omission (red) and nothing (black) trials. (<bold>F</bold>) A scatter plot of the firing rate during the outcome period in air puff omission trials and nothing trials (0–1000 ms after US onset, indicated by a black solid line in <bold>E</bold>) subtracted by the baseline firing rate (−1–0 s from odor onset) for each neuron. Black filled circles indicate neurons with significant difference between firing rates during the outcome period in air puff omitted and nothing trials. (<bold>G</bold>) Comparison of the responses during air puff omission trial and nothing trial conditions. **<italic>t</italic>(37) = 2.8, p=0.008, paired <italic>t</italic> test. (<bold>H</bold>) Histogram of changes in firing rate during the US epoch (0–1000 ms) of air puff omission versus nothing trials. The population average of auROC curve was significantly different from 0.5 (<italic>n</italic> = 38, *<italic>t</italic>(37) = 2.7, p=0.011, one-sample <italic>t</italic> test).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.007">http://dx.doi.org/10.7554/eLife.17328.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Reward prediction error coding by dopamine neurons in low reward contexts.</title><p>(<bold>A</bold>) Mean ± S.E.M. of firing rate of dopamine neurons in response to predicted (blue) and unpredicted water (cyan). Data were collected from two different low reward probability tasks—the mixed prediction task and the low reward probability task. (<bold>B</bold>) Scatter plot of the responses to predicted and unpredicted water (0–600 ms after water, indicated by a black solid line in <bold>A</bold>). Each data point represents an individual dopamine neuron (<italic>n</italic> = 37). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. Black filled circles indicate neurons with significant difference between response to unpredicted water and that to predicted water (unpaired <italic>t</italic> test, p&lt;0.05). (<bold>C</bold>) Comparison of the responses to predicted and unpredicted water (<italic>n</italic> = 37 dopamine neurons). Central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. ***<italic>t</italic>(36) = 4.5, p=7.6 × 10<sup>−5</sup>, paired <italic>t</italic> test. (<bold>D</bold>) Histogram of changes in firing rate during the US epoch (0–600 ms) of predicted versus unpredicted water. The population average of auROC curve was significantly different from 0.5 (<italic>n</italic> = 37, ***<italic>t</italic>(36) = 4.4, p=8.1 × 10<sup>−5</sup>, one-sample <italic>t</italic> test). Red arrow indicates mean auROC value.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.008">http://dx.doi.org/10.7554/eLife.17328.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig3-figsupp1-v1"/></fig></fig-group><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.009</object-id><label>Figure 4.</label><caption><title>Correlation between responses related to aversive stimuli in dopamine neurons.</title><p>(<bold>A</bold>) Scatter plot of the responses to unpredicted air puff (0–600 ms from air puff onset) and the effects of prediction on the responses to air puff US (subtraction of responses to unpredicted air puff from responses to predicted air puff, 0–600 ms from air puff onset) in dopamine neurons. Each data point represents an individual dopamine neuron (<italic>n</italic> = 38). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. Solid line, best-fit linear regression. Pearson’s correlation, <italic>r</italic> = 0.69, p=1.9 × 10<sup>−6</sup>. (<bold>B</bold>) Scatter plot of the responses to CS predicting air puff (0–1000 ms from odor onset) and the effects of prediction on the responses to air puff in dopamine neurons (<italic>n</italic> = 38). Pearson’s correlation, <italic>r</italic> = 0.39, p=0.016. (<bold>C</bold>) Scatter plot of the responses of individual dopamine neurons (<italic>n</italic> = 37) to unpredicted water and air puff (0–600 ms from water and air puff onsets, respectively). No correlation between these two responses (Pearson’s correlation, <italic>r</italic> = -0.04, p=0.834).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.009">http://dx.doi.org/10.7554/eLife.17328.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.010</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Correlation between responses related to air puff omission and the effects of prediction on the responses to air puff US.</title><p>Scatter plot of the firing rate during the outcome period in air puff omission trials (0–1 s after air puff onset) subtracted by the baseline firing rate (−1–0 s from odor onset) and the effects of prediction on the responses to air puff (subtraction of responses to unpredicted air puff from responses to predicted air puff, 0–600 ms from air puff onset). Each data point represents an individual dopamine neuron (<italic>n</italic> = 38). Pearson’s correlation, <italic>r</italic> = -0.38, p=0.02. Solid line, best-fit linear regression.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.010">http://dx.doi.org/10.7554/eLife.17328.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig4-figsupp1-v1"/></fig></fig-group><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.011</object-id><label>Figure 5.</label><caption><title>Representation of negative value of aversive stimuli depends on reward context.</title><p>(<bold>A</bold>) Task design in the high reward probability task. (<bold>B</bold>) Mean ± S.E.M. of firing rate of optogenetically-identified dopamine neurons during two trial conditions; nothing (black) and punishment (red). (<bold>C</bold>) Scatter plot of the mean responses during the CS epoch (0–1 s, indicated by a solid black line in <bold>B</bold>) for punishment versus nothing. The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. Filled grey circles (11 out of 17 circles), dopamine neurons showing significant inhibition to punishment CS than the average baseline firing rate (<italic>n</italic> = 80 trials, p&lt;0.05, one-sample <italic>t</italic> test). (<bold>D</bold>) Comparison of the responses of individual neurons during CS (0–1 s) predicting nothing (black) and punishment (red). For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. <italic>t</italic>(16) = 2.1, p&gt;0.05, paired <italic>t</italic> test. n.s., not significant. (<bold>E</bold>) Histogram of changes in firing rate during the CS epoch (0–1 s) of nothing versus punishment. The population average of the area under the receiver-operating characteristic (auROC) curve was not significantly different from 0.5 (<italic>n</italic> = 17, <italic>t</italic>(16) = 1.9, p&gt;0.05, one-sample <italic>t</italic> test). Red arrow indicates mean auROC value. (<bold>F</bold>) Task design in the low reward probability task. (<bold>G</bold>) Mean ± S.E.M. of firing rate of optogenetically-identified dopamine neurons during two trial conditions; nothing (black) and punishment (red). (<bold>H</bold>) Scatter plot of the mean responses during the CS epoch (0–1 s, indicated by a solid black line in <bold>G</bold>) for punishment versus nothing. Filled grey circles (12 out of 12 circles), dopamine neurons showing significant inhibition to punishment CS than the average baseline firing rate (<italic>n</italic> = 80 trials, p&lt;0.05, one-sample <italic>t</italic> test). (<bold>I</bold>) Comparison of the responses of individual neurons during CS (0–1 s) predicting nothing (black) and punishment (red). **<italic>t</italic>(11) = 3.8, p=0.003, paired <italic>t</italic> test. (<bold>J</bold>) Histogram of changes in firing rate during the CS epoch (0–1 s) of nothing versus punishment. The population average of the auROC curve was significantly different from 0.5 (<italic>n</italic> = 12, **<italic>t</italic>(11) = 4.2, p=0.002, one-sample <italic>t</italic> test). (<bold>K</bold>) Comparison of the percentage of dopamine neurons showing significant inhibition to punishment CS than baseline (Air puff CS &lt; Baseline) between high and low reward probability tasks. *<italic>chi</italic>(1) = 5.34, p=0.02, chi-square test. Error bar, S.E.M.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.011">http://dx.doi.org/10.7554/eLife.17328.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig5-v1"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.012</object-id><label>Figure 5—figure supplement 1.</label><caption><title>The response to air puff-predicting CS was consistently smaller than that to nothing-predicting CS in low reward contexts.</title><p>(<bold>A–F</bold>) Comparisons of responses of individual dopamine neurons during CS (0–1 s) predicting nothing (black) and punishment (red) in high reward probability task 2 (<bold>A</bold>, <italic>n</italic> = 17, <italic>t</italic>(16) = 0.35, p=0.73, paired <italic>t</italic> test), high reward probability task (<bold>B</bold>, <italic>n</italic> = 17, <italic>t</italic>(16) = 2.1, p=0.05), high reward contexts (data collected from two high reward probability tasks; <bold>C</bold>, <italic>n</italic> = 34, <italic>t</italic>(33) = 1.5, p=0.14), mixed prediction task (<bold>D</bold>, <italic>n</italic> = 26, **<italic>t</italic>(25) = 3.7, p=1.2 × 10<sup>−3</sup>), low reward probability task (<bold>E</bold>, <italic>n</italic> = 12, **<italic>t</italic>(11) = 3.8, p=2.8 × 10<sup>−3</sup>), and low reward contexts (data pooled from mixed prediction task and low reward probability task; <bold>F</bold>, <italic>n</italic> = 38, ***<italic>t</italic>(37) = 5.0, p=1.5 × 10<sup>−5</sup>). For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. n.s., not significant. (<bold>G</bold>) Comparison of the percentage of dopamine neurons showing significant inhibition to punishment CS than baseline (Air puff CS &lt; Baseline) between high and low reward contexts (<italic>n</italic> = 34 and 38, respectively). **<italic>chi</italic>(1) = 7.25, p=7.1 × 10<sup>−3</sup>, chi-square test. Error bar, S.E.M. (<bold>H</bold>) Comparison of the percentage of dopamine neurons showing significant inhibition to punishment CS than nothing CS (Air puff CS &lt; Nothing CS) between high and low reward contexts (<italic>n</italic> = 34 and 38, respectively). *<italic>chi</italic>(1) = 4.57, p=0.03, chi-square test.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.012">http://dx.doi.org/10.7554/eLife.17328.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig5-figsupp1-v1"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.013</object-id><label>Figure 5—figure supplement 2.</label><caption><title>The later response to air puff-predicting CS was smaller than that to nothing-predicting CS in the low reward probability task.</title><p>(<bold>A–B</bold>) Comparison of the later responses (200–1000 ms after odor onset) of individual neurons to CSs predicting nothing (black) and punishment (red) in different reward probability tasks (<bold>A</bold>, <italic>n</italic> = 12 dopamine neurons in the low reward probability task; <bold>B</bold>, <italic>n</italic> = 17 in the high reward probability task). For all box plots, the central mark is the median, the edges of the box are the 25th and 75th percentiles, and the whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted individually as plus symbols. **<italic>t</italic>(11) = 4.0, p=2.0 × 10<sup>−3</sup>; and <italic>t</italic>(16) = 2.0, p=0.07, paired <italic>t</italic> test. n.s., not significant. (<bold>C</bold>) Comparison of the percentage of dopamine neurons showing significant inhibition to punishment CS than nothing CS (Air puff CS &lt; Nothing CS) between high and low reward probability tasks. *<italic>chi</italic>(1) = 4.44, p=0.04, chi-square test. Error bar, S.E.M.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.013">http://dx.doi.org/10.7554/eLife.17328.013</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig5-figsupp2-v1"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.014</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Scatter plot of responses of individual dopamine neurons to air puff-predicting CS and unpredicted air puff in high reward contexts.</title><p>Scatter plot of the responses to air puff-predicting CS (0–1 s from odor onset) and unpredicted air puff US (0–600 ms from air puff onset). Each data point represents an individual dopamine neuron (<italic>n</italic> = 34). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.014">http://dx.doi.org/10.7554/eLife.17328.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig5-figsupp3-v1"/></fig></fig-group><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.17328.015</object-id><label>Figure 6.</label><caption><title>Relation between CS response of dopamine neurons and behavior.</title><p>(<bold>A</bold>) Eye blinking behavior during all three trial conditions in an example session in the high reward probability task. Red color indicates small eye area. (<bold>B</bold>) Average eye area during all three trial conditions in the example session; reward (blue), nothing (black) and punishment (air puff, red). (<bold>C</bold>) Comparison of the eye area during baseline (−1–0 s from odor onset, black) and delay period (1–2 s, red) in punishment trial condition from an example animal (<italic>n</italic> = 21 sessions). For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. ***<italic>t</italic>(20) = 14.7, p=3.4 × 10<sup>−12</sup>, paired <italic>t</italic> test. (<bold>D</bold>) Comparison of the responses of individual dopamine neurons (<italic>n</italic> = 23) during punishment CS (0–1 s) between blink (dark red) and no-blink trials (magenta). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. **<italic>t</italic>(22) = 3.0, p=0.007, paired <italic>t</italic> test. (<bold>E</bold>) Comparison of the responses of individual dopamine neurons during punishment CS (0–1 s) in blink and no-blink trials in high and low reward probability tasks (<italic>n</italic> = 13 and 10 neurons from these two tasks, respectively). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. ***<italic>t</italic>(9) = 7.4, p=4.3 × 10<sup>−5</sup>, one-sample <italic>t</italic> test;*<italic>t</italic>(9) = 3.0, p=0.016; and <italic>t</italic>(12) = 1.3, p=0.207, paired <italic>t</italic> test. n.s., not significant. (<bold>F</bold>) Comparison of the responses of individual dopamine neurons during reward-predicting CS (0–1 s) between trials with anticipatory and no anticipatory licks (≥3 and &lt;3 licks s<sup>−1</sup> during delay period, respectively). In 90% water trials (left), only 9 out of 34 dopamine neurons were collected, as the number of trials in which the animal did not show anticipatory licking was small. In 20–25% water trials (right), 33 out of 38 dopamine neurons were collected. The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. <sup>1</sup><italic>t</italic>(8) = 2.322, p=0.0488, paired <italic>t</italic> test; <sup>2</sup><italic>t</italic>(8) = 3.141, p=0.0138, one-sample <italic>t</italic> test.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.015">http://dx.doi.org/10.7554/eLife.17328.015</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig6-v1"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.016</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Extraction of eye area from video frames.</title><p>(<bold>A</bold>) A histogram showing the distribution of pixels with different intensity (0–255 levels, bottom) in an example frame of the right eye region (top). A threshold 234 pixel intensity was used to separate eye area from the background. (<bold>B</bold>) Pixels with intensity smaller than the eye threshold was set to 1 (white) and others were set to 0 (black). (<bold>C</bold>) White small patches outside of the eye on the binary image in <bold>B</bold> were removed. (<bold>D</bold>) Smoothing the eye patch. (<bold>E</bold>) The averaged pixel intensities of example video frames were plotted. Troughs of the value indicate short infrared light source off (&lt;25 ms) delivered 2 s after every US onset.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.016">http://dx.doi.org/10.7554/eLife.17328.016</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig6-figsupp1-v1"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.017</object-id><label>Figure 6—figure supplement 2.</label><caption><title>All the animals showed anticipatory eye-blinking to air puff in both low and high reward probability conditions.</title><p>(<bold>A–H</bold>) Comparison of the eye area during baseline (−1–0 s from odor onset, black) and delay period (1–2 s from odor onset, red) in punishment (air puff) trial condition. For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. Each boxplot represents data from each animal (5 from the high reward probability task, and 3 from the low reward probability task). ***<italic>t</italic>(21) = 3.9, p=8.5 × 10<sup>−4</sup> (<italic>n</italic> = 22 sessions), paired <italic>t</italic> test in <bold>A</bold>; ***<italic>t</italic>(17) = 6.3, p=8.4 × 10<sup>−6</sup> (<italic>n</italic> = 18 sessions), paired <italic>t</italic> test in <bold>B</bold>; *<italic>U</italic> = 342, p=0.02 (<italic>n</italic> = 32 sessions), Mann-Whitney <italic>U</italic> test in <bold>C</bold>; ***<italic>t</italic>(20) = 14.7, p=3.4 × 10<sup>−12</sup> (<italic>n</italic> = 21 sessions), paired <italic>t</italic> test in <bold>D</bold>; *<italic>t</italic>(16) = 2.9, p=0.01(<italic>n</italic> = 17 sessions), paired <italic>t</italic> test in <bold>E</bold>; ***<italic>t</italic>(15) = 4.2, p=7.0 × 10<sup>−4</sup> (<italic>n</italic> = 16 sessions), paired <italic>t</italic> test in <bold>F</bold>; ***<italic>t</italic>(25) = 8.2, p=1.4 × 10<sup>−8</sup> (<italic>n</italic> = 26 sessions), paired <italic>t</italic> test in <bold>G</bold>; and ***<italic>t</italic>(18) = 5.2, p=5.6 × 10<sup>−5</sup> (<italic>n</italic> = 19 sessions), paired <italic>t</italic> test in <bold>H</bold>. (<bold>I</bold>) Comparison of the eye area during delay period (1–2 s after odor onset) in all three trial conditions; reward (blue), nothing (black) and punishment (red). Data were from 8 mice. *<sup>1</sup><italic>t</italic>(7) = 3.6, p=0.009; and *<sup>2</sup><italic>t</italic>(7) = 3.2, p=0.01, paired <italic>t</italic> test.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.017">http://dx.doi.org/10.7554/eLife.17328.017</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig6-figsupp2-v1"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.018</object-id><label>Figure 6—figure supplement 3.</label><caption><title>Correlation between eye-blinking behavior and inhibitory responses to air puff-predicting CS during the later response window in low reward contexts.</title><p>Comparison of the responses of individual dopamine neurons during late period of punishment CS (200–1000 ms) in the high and low reward probability tasks (<italic>n</italic> = 13 and 10 neurons from these two tasks, respectively). The baseline firing rate (−1–0 s from odor onset) was subtracted for each neuron. For all box plots, central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and outliers are plotted as plus symbols. ***<italic>t</italic>(9) = 7.0, p=6.4 × 10<sup>−5</sup>, one-sample <italic>t</italic> test; *<italic>t</italic>(9) = 3.0, p=0.016; and <italic>t</italic>(12) = 0.22, p=0.83, paired <italic>t</italic> test. n.s., not significant.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.018">http://dx.doi.org/10.7554/eLife.17328.018</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig6-figsupp3-v1"/></fig><fig id="fig6s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.17328.019</object-id><label>Figure 6—figure supplement 4.</label><caption><title>Anticipated licking behavior during delay period.</title><p>(<bold>A</bold>) Histograms of the lick rate during the delay period (1–2 s from odor onset) during 90% water trials (blue) and nothing trials (black) from all the sessions in which dopamine neurons were identified. (<bold>B</bold>) Comparison of the lick rates during the delay period between 90% water trials and 20–25% water trials (<italic>n</italic> = 34 and 38 sessions, respectively). Central mark is the median, box edges are 25th and 75th percentiles, whiskers extend to the most extreme data points not considered outliers (points 1.5 × interquartile range away from the 25th or 75th percentile), and an outlier is plotted as plus symbols. ***<italic>t</italic>(70) = 8.8, p=5.3 × 10<sup>−13</sup>, unpaired <italic>t</italic> test.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.17328.019">http://dx.doi.org/10.7554/eLife.17328.019</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-17328-fig6-figsupp4-v1"/></fig></fig-group></p></sec><sec id="s2-2"><title>Dopamine neurons integrate values of both valences, appetitive and aversive</title><p>A previous study reported that dopamine neurons do not integrate information about aversiveness along with reward-related information when rewarding liquid and an air puff are delivered to a monkey at the same time (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). However, this method may produce complex interactions between the two different outcomes. To test how reward and aversion interact and affect dopamine responses, we devised a 'mixed prediction' paradigm (<xref ref-type="fig" rid="fig2">Figure 2</xref>) in which a single odor (Odor D in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, conditioned stimulus, CS) predicted both a rewarding and a mildly aversive event in a complementary and probabilistic manner: a reward (water) was delivered in 25% of the trials and an aversive event (air puff) was delivered in the remaining 75% of the trials. For comparison, we included the following trial types: Odor A predicted water in 25% of trials (nothing in 75%), Odor C predicted air puff in 75% of trials (nothing in 25%), and Odor B predicted no outcome. Each behavioral trial began with the odor CS (1 s), followed by a 1-s delay and an unconditioned stimulus (US). We chose higher probability for air puff than water in order to balance the strength of positive and negative values in the task; we suspect that the magnitude of the negative value of mild air puff is much smaller than the magnitude of the positive value of water, which could cause us to overlook a small effect of predicted air puff on the CS response.</p><p>We first asked whether the recorded dopamine neurons were inhibited or excited by odor cues (CSs) that predicted different outcomes. We found that the vast majority of the neurons were inhibited by the air puff-predicting CS while excited by the reward-predicting CS (<xref ref-type="fig" rid="fig2">Figure 2B–D</xref>). On average, the firing rate during the CS period was significantly lower for the air puff-predicting CS than for the CS predicting nothing, while it was higher for the reward-predicting CS than for the CS that predicted nothing (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). A similar tendency was observed using data from two animals instead of three (i.e. leaving one animal out of three) (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Among 26 identified dopamine neurons, 85% (22 neurons) were significantly modulated by these three odors (p&lt;0.05, one-way ANOVA), and 59% (13 of 22 significant neurons) showed the monotonic CS value coding (water &gt; nothing &gt; air puff). These results suggest that the firing of identified dopamine neurons was negatively modulated by the stimulus predicting aversive events.</p><p>We next examined whether prediction of aversion in addition to reward changed the response of dopamine neurons. In contrast to the previous study (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>), we found that the majority of neurons showed an intermediate response to the CS predicting both water and air puff (Odor D) compared to the CSs predicting water only (Odor A) or air puff only (Odor C) (<xref ref-type="fig" rid="fig2">Figure 2B,F,G</xref>). As a population, the net response to these CSs increased monotonically according to the values of both water and air puff, with the CS response to Odor D falling in between that of Odor A and Odor C (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). 89% (23 of 26 neurons) of identified dopamine neurons were significantly modulated by these three odors (p&lt;0.05, one-way ANOVA), and 65% (15 of 23 significant neurons) showed the monotonic CS value coding (water &gt; water and air puff &gt; air puff). These results indicate that VTA dopamine neurons combine values for both reward and punishment along a one-dimensional value axis.</p></sec><sec id="s2-3"><title>Dopamine neurons signal prediction errors for aversion</title><p>It has been shown that dopamine neurons’ responses to reward are greatly reduced when the reward is predicted, a signature of prediction error coding (<xref ref-type="bibr" rid="bib51">Schultz et al., 1997</xref>). We replicated these findings here even in low reward probability conditions (20–25%, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>; see Materials and methods). We next examined whether these dopamine neurons show prediction error coding for aversive events. To address this question, we occasionally delivered air puff during inter-trial intervals without any predicting cues. These responses to unpredicted air puff were compared to the responses to air puff in trials when air puff was predicted by an odor cue. We found that the inhibitory response to an air puff was significantly reduced when the air puff was predicted by an odor cue (<xref ref-type="fig" rid="fig3">Figure 3A–D</xref>). To further examine whether dopamine neurons showed prediction error coding for aversive events, we compared the firing rate during the outcome period in air puff omission trials with that in trials that predict nothing. We found that the omission of a predicted air puff slightly but significantly increased firing rates, compared to no change in nothing trials (<xref ref-type="fig" rid="fig3">Figure 3E–H</xref>) although we observed variability in air puff omission responses. Together, these results demonstrate that dopamine neurons signal prediction errors for aversive events in addition to rewarding events. These results indicate that dopamine neurons have the ability to signal VPEs for both appetitive and aversive events, supporting previous work by Matsumoto and Hikosaka (<xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>) and contrasting with previous work by Fiorillo (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>).</p></sec><sec id="s2-4"><title>Homogeneous response function of dopamine neurons</title><p>Although we found that most dopamine neurons were inhibited by air puff (mildly aversive event), there was a considerable variability in the extent to which individual dopamine neurons were inhibited. Does this diversity support a functional diversity across dopamine neurons in the lateral VTA?</p><p>In a previous study, dopamine neurons in the lateral VTA exhibited neuron-to-neuron variability in the magnitude of response to a given size of reward (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>). Despite this variability in responsivity, the response functions of individual dopamine neurons were scaled versions of each other, indicating a remarkable homogeneity. One consequence of this scaled relationship is that neurons that responded strongly to a given size of reward were more greatly suppressed by reward expectation. In other words, reward expectation suppressed a neuron’s reward response in proportion to the size of its response to unexpected reward.</p><p>Does the same relationship hold for inhibitory responses to air puff? To address this question, we examined the correlation between aversion-related responses in dopamine neurons (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We indeed found a similar relationship: dopamine neurons that were strongly inhibited by air puff also exhibited a larger prediction-dependent reduction of their responses to air puff (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, Pearson’s <italic>r</italic> = 0.69, p=1.9 × 10<sup>−6</sup>). In other words, the ratio between individual dopamine neurons’ responses to unpredicted versus predicted air puff was preserved across neurons. In addition, similar to reward responses (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>), inhibitory responses to the air puff-predicting CS were correlated with prediction-dependent reduction of responses to air puff US (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, Pearson’s <italic>r</italic> = 0.39, p=0.016). These results indicate that the response function was preserved across dopamine neurons in the case of aversive stimuli.</p><p>We next examined the relationship between responses of dopamine neurons to reward and to aversion. We compared responses of dopamine neurons to unpredicted water and unpredicted air puff (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). We observed no obvious unique clusters across neurons, supporting the notion that there was no clear subpopulation of dopamine neurons specialized in signaling reward versus aversion in the lateral VTA. Rather, we found that most of dopamine neurons were inhibited by unpredicted aversive stimuli and excited by unpredicted rewarding stimuli. Interestingly, we did not find any negative or positive correlation of neurons’ responses to water and air puff; the proportion of the response magnitudes in response to reward versus aversion was diverse across neurons. These results indicate that although the response function either for reward prediction error or for aversion prediction error was homogeneous across dopamine neurons, these two functions were relatively independent, suggesting that different mechanisms may produce dopamine responses to reward and aversion.</p></sec><sec id="s2-5"><title>Reward-context dependent representation of aversion in dopamine neurons</title><p>Although the above results suggested that most of the dopamine neurons that we recorded from the lateral VTA were inhibited by aversive events, contrasting results were obtained in some previous studies. In monkeys, it was found that, on average, the responses to aversive stimuli were indistinguishable from responses evoked by neutral stimuli (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). In addition, previous studies in mice (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Tian and Uchida, 2015</xref>) mirrored these contrasting results in VTA dopamine neurons. These results suggest that the difference between studies is not due to a species difference, raising the possibility that our task parameters altered the dopamine response.</p><p>Multiple studies found that even non-rewarding stimuli can excite dopamine neurons with short latency. A recent study reported that whether a neutral stimulus elicits these short-latency excitations depends on reward context, and that excitation is larger in a high versus a low reward context (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>). We noted that the reward probability used in the task described above (mixed prediction task) was much lower (15% rewarded trials overall) than in previous studies (e.g. 50% rewarded trials overall in <xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>). This raises the possibility that in a high reward context, short-latency excitations to aversive stimuli masked inhibitory responses to aversive stimuli, and thus clear inhibition by aversive stimuli has not been observed in previous studies because these studies typically used relatively high reward probabilities.</p><p>To directly test whether reward probability affected dopamine neurons’ responses to aversive events, we recorded the activity of dopamine neurons in two task conditions that differed only with respect to reward probabilities (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In the high reward probability condition, the probability of water in Odor A trials was 90% (36% reward trials overall) (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) while in the low reward probability condition, the reward probability in Odor A trials was 20% (13% reward trials overall) (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). Consistent with the previous study (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>), nothing-predicting CS (neutral cue) elicited short-latency excitation more prominently in the high reward compared to the low reward probability condition (<xref ref-type="fig" rid="fig5">Figure 5B,G</xref>). Next we examined the response to the air puff-predicting CS. In the low reward context, the difference between the responses to air puff- and nothing-predicting CSs remained significantly different (<xref ref-type="fig" rid="fig5">Figure 5H–J</xref>), consistent with the above experiment (<xref ref-type="fig" rid="fig2">Figure 2</xref>). In contrast, we found that in the high reward probability condition, dopamine neurons exhibited biphasic responses to the air puff-predicting CS: short-latency excitation followed by later inhibition. Furthermore, dopamine neurons’ net responses to the air puff-predicting CS and nothing-predicting CS were no longer significantly different (<xref ref-type="fig" rid="fig5">Figure 5C–E</xref>). This result, obtained in a high reward probability condition, is similar to those obtained in previous studies (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>; <xref ref-type="bibr" rid="bib56">Tian and Uchida, 2015</xref>). In the low reward context, all the dopamine neurons (12 of 12 dopamine neurons; p&lt;0.05, one-sample <italic>t</italic> test; filled grey circles in <xref ref-type="fig" rid="fig5">Figure 5H</xref>) were inhibited by the air puff-predicting CS whereas in the high reward context, a large fraction of dopamine neurons (6 of 17 dopamine neurons; p&gt;0.05, one-sample <italic>t</italic> test; filled white circles in <xref ref-type="fig" rid="fig5">Figure 5C</xref>) did not show consistent inhibition by air puff CS. That is, in the high reward context, a little fraction of neurons showed a stronger inhibition to the air puff CS compared to the nothing CS (100% and 65%, low and high reward context, respectively; p=0.02, chi-square test; <xref ref-type="fig" rid="fig5">Figure 5K</xref>).</p><p>We obtained additional data using a task condition similar to the high reward context (high reward probability task 2; see Materials and methods, and <xref ref-type="table" rid="tbl1">Table 1</xref>) (<italic>n</italic> = 17 identified dopamine neurons). Furthermore, the mixed prediction task (<xref ref-type="fig" rid="fig2">Figure 2</xref>) provides additional data for a low reward context (<italic>n</italic> = 26 identified dopamine neurons). Similar results were obtained by using dopamine neurons in each of these experiments or by pooling neurons from these experiments separately for high and low reward contexts (<italic>n</italic> = 34 and 38 identified dopamine neurons, respectively) (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><p>The above analyses used a relatively large time window that contains the entire response period (0–1,000 ms). Because dopamine responses in high reward contexts exhibited biphasic responses (early excitation followed by later inhibition), we further analyzed the data by separating these time windows into smaller bins. Because there is no known mechanism by which downstream neurons can read out these windows separately, analysis using a large window can be considered more conservative. However, previous studies have proposed that different information may be conveyed in these time windows (<xref ref-type="bibr" rid="bib49">Schultz, 2016</xref>; <xref ref-type="bibr" rid="bib52">Stauffer et al., 2016</xref>).</p><p>We obtained similar results even if we compared only later time bins (200–1,000 ms), excluding the early excitation phase (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). By excluding the early excitation period (0–200 ms), many dopamine neurons showed inhibition to air puff-predicting CS in both low and high reward contexts compared to the baseline firing (92% and 82%, respectively). However, during this inhibition phase, most dopamine neurons (65%) did not distinguish the air puff CS from the nothing CS in the high reward context while most dopamine neurons (75%) showed more inhibition to the air puff CS than to the nothing CS in the low reward context (i.e. 35% and 75% of neurons distinguished air puff CS from nothing CS in high and low reward contexts, respectively; p=0.04, chi-square test; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2C</xref>). This suggests that although many dopamine neurons exhibit inhibitory responses during the later response window in high reward contexts, the information that this inhibition conveys may be different from that in low reward contexts; the inhibition in the high reward context largely reflected 'no reward' rather than the negative value of an air puff (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). Neurons that showed a large excitation to the air puff CS were not necessarily the same group of neurons which showed excitation to the air puff itself, consistent with a previous study (<xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>) (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).</p><p>These results demonstrate that dopamine neurons’ responses to aversion-predicting cues are greatly affected by reward contexts, and suggest that dopamine neurons’ ability to faithfully represent negative values of aversive cues are undermined in high reward contexts.</p></sec><sec id="s2-6"><title>Trial-to-trial variability in dopamine responses to aversive stimuli</title><p>In order to examine dopamine responses to aversive stimuli more carefully in relation to behavior, we characterized dopamine activities and anticipatory eye-blinking on a trial-by-trial basis. We quantified the area of the right eye (including both sclera and pupil) concurrently with neuronal recording in high and low reward probability contexts (<xref ref-type="fig" rid="fig6">Figure 6</xref>; <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>; see also Materials and methods). We observed that the eye area became smaller after the onset of a CS predicting air puff and became larger after a CS predicting reward (<xref ref-type="fig" rid="fig6">Figure 6A,B</xref>). In air puff trials, the eye area during the delay period was significantly smaller than before CS presentation (−1–0 s from CS onset), indicating anticipatory eye-blinking (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, <italic>n</italic> = 21 sessions, p=3.4 × 10<sup>−12</sup>, paired <italic>t</italic> test). We confirmed that in both low and high reward probability conditions, all of the animals showed significant anticipatory eye-blinking (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). The eye area during the delay period was significantly smaller in air puff trials than in nothing trials (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2I</xref>). These results indicate that our air puff conditions were aversive enough to cause anticipatory eye-blinking during the recording experiments, although we noticed that the amount of eye-blinking differed across trials.</p><p>Because the level of anticipatory eye-blinking varied across trials, we next divided air puff trials in each session into two groups, 'blink' (small eye size) and 'no-blink' (big eye size) trials (see Materials and methods), and then examined the correlation between blinking and the responses of dopamine neurons to the air puff CS. We found that the firing rates of dopamine neurons to air puff CS in blink trials were significantly smaller than that in no-blink trials (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). In other words, inhibition of dopamine neurons during the CS period, but not excitation, predicted aversion-related behavior.</p><p>The correlation between trial-by-trial dopamine activity and anticipatory blinking was even clearer if we consider reward contexts (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). In the low reward probability condition, the inhibitory response of dopamine neurons in blink trials was significantly greater than in no-blink trials (p=0.02, paired <italic>t</italic> test). Of note, in the high reward probability condition, the inhibitory response of dopamine neurons was greatly reduced even when the animals showed anticipatory eye-blinking (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, p=0.009, unpaired <italic>t</italic> test). This result suggests that dopamine responses may not directly trigger eye-blinking behavior. Rather, the results are consistent with the idea that dopamine neurons’ inhibitory responses to aversive cues signal negative values of the outcome, but not the action itself. Importantly, dopamine neurons showed significant inhibition only when animals showed anticipatory eye-blinking in the low reward context (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, p=4.3 × 10<sup>−5</sup>, one-sample <italic>t</italic> test). The results do not change even when we only used a later window of dopamine CS responses, excluding the early excitation period (0–200 ms) (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>).</p><p>Whereas mice showed anticipatory blinking in 48% of air puff trials (90% air puff trials), they showed more consistent anticipatory licking in water trials (98% in 90% water trials) (see Materials and methods). This could be due to the fact that we used only a mildly aversive air puff (to prevent the animal from being discouraged to perform the task altogether), whereas water is highly rewarding. Although the number of trials in which the animal did not show anticipatory licking was small, we observed a similar relationship between dopamine responses and behavior: dopamine neurons were consistently excited by the 90% reward cue when they showed anticipatory licking, but not when they did not show anticipatory licking (<xref ref-type="fig" rid="fig6">Figure 6F</xref>). These results indicate the importance of both reward contexts and behavioral outcomes to understand how dopamine neurons represent reward and aversion. Without monitoring behaviors, investigators may easily miss weak inhibitory responses to mildly aversive stimuli in dopamine neurons.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>There have been divergent and inconsistent results with respect to how dopamine neurons encode aversive events. In the present study, we aimed to specifically examine how dopamine neurons integrate aversiveness and reward by carefully controlling various experimental parameters. The following three points are particularly notable. First, we used an optogenetic tagging method to unambiguously identify dopamine neurons while recording spiking activity in behaving mice. Second, we used a series of behavioral paradigms with probabilistic outcomes that are designed to test specific hypotheses regarding the integration of different outcomes and the effect of reward contexts. Third, we monitored aversion-related behaviors (eye blinking) to examine the trial-by-trial relationship to dopamine responses. By harnessing these controlled experimental conditions, our results indicate that dopamine neurons have different modes of signaling. In low reward contexts (the mixed prediction task and the low reward probability task), dopamine neurons were inhibited by aversive events more strongly than by neutral events, tracking the aversiveness of stimuli on a trial-by-trial basis. Furthermore, dopamine neurons signaled VPEs by faithfully combining information about both appetitive and aversive events into a common currency of value. Thus, dopamine can function as a precise teaching signal for updating integrated values for both reward and aversion. However, in high reward contexts (the high reward probability task and the high reward probability task 2), dopamine neurons exhibited early excitations, which undermined their ability to produce negative responses for aversive events.</p><sec id="s3-1"><title>Integration of aversiveness and reward in dopamine neurons</title><p>Dopamine has long been thought to be a key regulator of reinforcement learning. One dominant theory posits that dopamine acts as a teaching signal that broadcasts an RPE signal to the rest of the brain. Recent studies using optogenetics have established that activation of dopamine neurons alone is sufficient for appetitive conditioning (<xref ref-type="bibr" rid="bib53">Steinberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib58">Tsai et al., 2009</xref>; <xref ref-type="bibr" rid="bib65">Witten et al., 2011</xref>) whereas suppression is sufficient for aversive conditioning (<xref ref-type="bibr" rid="bib6">Chang et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Danjo et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Ilango et al., 2014</xref>; <xref ref-type="bibr" rid="bib55">Tan et al., 2012</xref>; <xref ref-type="bibr" rid="bib62">van Zessen et al., 2012</xref>), although activation of dopamine neurons that project to the cortex or dopamine neurons in the dorsal raphe has potential to induce aversion and/or other functions (<xref ref-type="bibr" rid="bib28">Lammel et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Matthews et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Popescu et al., 2016</xref>). Furthermore, pharmacological studies have suggested that normal dopamine signaling is required for appetitive as well as aversive conditioning (<xref ref-type="bibr" rid="bib9">Cooper et al., 1974</xref>; <xref ref-type="bibr" rid="bib16">Flagel et al., 2011</xref>; <xref ref-type="bibr" rid="bib64">Wenzel et al., 2015</xref>). These results have provided convergent evidence supporting the role of dopamine in learning. However, whether dopamine neurons signal prediction errors with respect to aversive events remained controversial, and remained an obstacle towards establishing the role of dopamine as the teaching signal proposed in reinforcement learning theories.</p><p>Comparatively fewer experiments have used combinations of aversive stimuli and rewarding stimuli to characterize the dopamine response. <xref ref-type="bibr" rid="bib14">Fiorillo (2013)</xref> proposed that reward and aversion are processed separately in the brain, based on the observation that dopamine neurons signaled information about reward but largely ignored aversive events (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). This result contradicts some previous studies that showed consistent inhibition of dopamine neurons by aversive stimuli or the cues that predict them (<xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>; <xref ref-type="bibr" rid="bib33">McCutcheon et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Roitman et al., 2008</xref>). Our results suggest that there are different modes of dopamine signaling: in one mode, dopamine neurons indeed integrate the information about reward and aversion and signal VPE. This is an ideal teaching signal for reinforcement learning to maximize future values. Further, we found that the response function to aversive stimuli was preserved across dopamine neurons, suggesting that each dopamine neuron has the potential to contribute a prediction error of aversiveness, as well as of reward (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>).</p><p>However, in a high reward context, dopamine neurons largely lose their ability to signal integrated VPEs. Our results in high reward contexts are consistent with those observed previously (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>), and we also showed that similar results were obtained in previous recordings of optogenetically-identified dopamine neurons (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Tian and Uchida, 2015</xref>). This raises the possibility that one of the apparent differences observed between previous electrophysiological studies is due to different experimental parameters with respect to reward contexts. It should be noted that many physiological experiments tend to include highly rewarding training sessions in order to motivate animals. In natural environments in which wild animals forage, rewards might not be as abundant as in these experimental conditions. Our results indicate that dopamine neurons signal VPE with high fidelity in low reward contexts.</p><p>In examining the temporal dynamics of dopamine responses, we realized that on average, the peak of excitation for reward cues occurred earlier than the trough of inhibition for aversive cues. Interestingly, dopamine responses to the cue predicting both rewarding and aversive outcomes in our mixed prediction tasks first showed excitation and then inhibition, different from the flatter responses to nothing cues. This clear temporal difference raises the possibility that information about values from rewarding and aversive outcomes are not yet integrated in presynaptic neurons and arise from different sources of inputs to dopamine neurons. A recent electrophysiological recording study from monosynaptic inputs to dopamine neurons also suggested that different presynaptic neurons may convey values for rewarding versus aversive stimuli (<xref ref-type="bibr" rid="bib57">Tian et al., 2016</xref>). Consistent with this idea, we did not observe a correlation between the magnitude of single dopamine neurons’ responses to reward and aversiveness (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), in contrast to correlations within reward-related responses (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>) and within aversiveness-related responses (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>). Of note, a previous study (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>) showed that, in high reward context, neurons that were highly responsive to unexpected rewards tended to also be highly responsive to aversive events: they showed greater levels of suppression below baseline. The results in the previous study are reminiscent of Fiorillo’s study, which found that the inhibitory phase in biphasic responses of dopamine neurons did not encode negative values of aversive stimulus, but rather encode 'no reward' (<xref ref-type="bibr" rid="bib14">Fiorillo, 2013</xref>). The results in the previous study (<xref ref-type="bibr" rid="bib13">Eshel et al., 2016</xref>) could be consistent with the present results if the inhibition represents 'no reward' but not the negative value of aversive stimulus, and this no-reward response is correlated with other reward-related responses of dopamine neurons.</p></sec><sec id="s3-2"><title>Reward-context dependent representation in dopamine neurons</title><p>Our results indicate that dopamine neurons represent aversive information in a reward context dependent manner. Our results are consistent with a previous study which proposed that dopamine neurons change their response patterns depending on reward context (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>). The authors found that neutral stimuli excited dopamine neurons more strongly in high- compared to low-reward contexts (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>). The present study extends this finding to aversive stimuli. Short latency excitations of dopamine neurons have been observed in various experiments and have been attributed to generalization (<xref ref-type="bibr" rid="bib24">Kobayashi and Schultz, 2014</xref>; <xref ref-type="bibr" rid="bib37">Mirenowicz and Schultz, 1996</xref>), stimulus intensities (<xref ref-type="bibr" rid="bib15">Fiorillo et al., 2013</xref>), motivational salience (<xref ref-type="bibr" rid="bib5">Bromberg-Martin et al., 2010</xref>; <xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>), trial starts (<xref ref-type="bibr" rid="bib5">Bromberg-Martin et al., 2010</xref>) or stimulus detection (<xref ref-type="bibr" rid="bib38">Nomoto et al., 2010</xref>). Our data do not distinguish these possibilities and the short latency excitation in the high reward context is likely to comprise a combination of these. Importantly, however, our data in the high reward context showed that the short-latency excitations compromised the monotonic value coding of dopamine neurons, and the difference between responses to air puff-predicting CS and nothing-predicting CS was diminished. This means that dopamine neurons did not simply add a constant amount of spikes (the same amount of excitation) on top of the monotonic value coding. Thus, our observations suggest that the combination of these factors and/or additional factors distorted normal value coding in dopamine neurons in high reward context.</p><p>In our experiments, high- and low-reward contexts differed with respect to the probability of rewarded trials. This suggests that dopamine responses to aversion depend on the frequency of reward, which may in turn change the animal’s state. It remains to be examined how the frequency of rewards changes dopamine responses and whether dopamine responses could be modulated by other manipulations of the environment such as the amount of reward or the strength or frequency of aversive events.</p><p>In addition to overall reward contexts, we found that the inhibitory responses of dopamine neurons changed on a finer time-scale; the inhibition of dopamine neurons by air puff-predicting cues was correlated with trial-by-trial variability of aversion-related behaviors in low reward contexts. A similar correlation was observed between excitation of dopamine neurons by reward-predicting cues and reward-related behaviors. These results suggest that dopamine neurons track the predictions of values (reward and aversiveness) which may reflect animals’ states over various time-scales.</p><p>A previous study also examined dopamine responses to aversive stimuli in relation to behaviors. Using cyclic voltammetry, the authors showed that, in response to electrical shock-predicting cues, the dopamine concentration in the ventral striatum increased when the rats exhibited an active avoidance behavior while it decreased when the rats showed freezing behavior (<xref ref-type="bibr" rid="bib39">Oleson et al., 2012</xref>). It is therefore proposed that dopamine responses depend on whether the animal exhibits active avoidance or passive reaction (<xref ref-type="bibr" rid="bib39">Oleson et al., 2012</xref>; <xref ref-type="bibr" rid="bib64">Wenzel et al., 2015</xref>). In the present study, we found that the degree of inhibition, not excitation, of dopamine neurons in response to the air puff-predicting CS was positively correlated with anticipatory eye-blinking behaviors (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). According to the above idea (<xref ref-type="bibr" rid="bib39">Oleson et al., 2012</xref>; <xref ref-type="bibr" rid="bib64">Wenzel et al., 2015</xref>), the anticipatory eye-blinking that we observed may be categorized as a passive avoidance behavior, which could be the reason as to why we observed inhibition, but not excitation of dopamine neurons correlated with anticipatory eye-blinking behaviors.</p></sec><sec id="s3-3"><title>Diversity of dopamine neurons</title><p>Whereas dopamine neurons displayed a relatively uniform response function to aversion in low reward contexts, we observed diverse responses in high reward contexts, including some inhibitory and some excitatory responses to aversive events. What caused diverse responses to aversion in high reward contexts? Increasing evidence supports the diversity of dopamine neurons depending on the location of the cell body and projection targets (<xref ref-type="bibr" rid="bib28">Lammel et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Roeper, 2013</xref>). For example, it was reported that neurons in the lateral SNc signal salience (<xref ref-type="bibr" rid="bib29">Lerner et al., 2015</xref>; <xref ref-type="bibr" rid="bib31">Matsumoto and Hikosaka, 2009</xref>) or 'stable value' as opposed to 'flexible value' in the medial SNc (<xref ref-type="bibr" rid="bib23">Kim et al., 2015</xref>). Another study showed that dopamine neurons in the ventromedial VTA exhibited excitation to an aversive stimulus (<xref ref-type="bibr" rid="bib4">Brischoux et al., 2009</xref>). Previous studies showed that responses to aversive stimuli are diverse across dopamine neurons with different projection targets (<xref ref-type="bibr" rid="bib27">Lammel et al., 2011</xref>; <xref ref-type="bibr" rid="bib29">Lerner et al., 2015</xref>). Although the majority of dopamine neurons in the lateral VTA, our main recording site, project to the ventral and anterior dorsal striatum (<xref ref-type="bibr" rid="bib26">Lammel et al., 2008</xref>; <xref ref-type="bibr" rid="bib34">Menegas et al., 2015</xref>), our study did not distinguish the exact projection targets of dopamine neurons. It remains to be determined which subpopulations of dopamine neurons switch signaling modes depending on low versus high reward contexts.</p><p>Our results demonstrated the importance of considering global contexts and behaviors and of unambiguously identifying dopamine neuron. It remains to be examined in future studies how reward frequency changes both the animal’s state and dopamine responses to punishment, and how these changes relate to our normal and abnormal behaviors. Further, there are complex temporal dynamics and diversity of dopamine activities. Considering these factors together is challenging but represents a firm step towards fully understanding the nature and function of dopamine signals.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>We used 15 adult male mice heterozygous for Cre recombinase under control of the &lt;<italic>Slc6a3</italic>&gt; gene that encodes the dopamine transporter (DAT) (B6.SJL-<italic>Slc6a3<sup>tm1.1(cre)Bkmn</sup></italic>/J, Jackson Laboratory; RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:006660">IMSR_JAX:006660</ext-link>) (<xref ref-type="bibr" rid="bib2">Bäckman et al., 2006</xref>). All mice were backcrossed with C57/BL6 mice. Eleven out of 15 mice were further crossed with tdTomato-reporter mice (<italic>Gt(ROSA)26Sor<sup>tm9(CAG-tdTomato)Hze</sup></italic>, Jackson Laboratory) to express tdTomato in dopamine neurons. Electrophysiological data were collected from 14 mice, and video data were from 8 mice. Animals were singly housed on a 12 hr dark/12 hr light cycle (dark from 06:00 to 18:00) and each performed the conditioning task at the same time of day, between 08:00 and 16:00. All procedures were approved by Harvard University Institutional Animal Care and Use Committee.</p></sec><sec id="s4-2"><title>Surgery and viral injections</title><p>Total 1 µl of adeno-associated virus (AAV), serotype 5, carrying an inverted ChR2 (H134R)-EYFP flanked by double <italic>loxP</italic> sites (<xref ref-type="bibr" rid="bib1">Atasoy et al., 2008</xref>) [AAV5-DIO-ChR2-EYFP (<xref ref-type="bibr" rid="bib58">Tsai et al., 2009</xref>)] was injected stereotactically into the VTA (3.1 mm posterior to bregma, 0.5 mm lateral, 3.9 mm deep from dura and 3.5 mm posterior to bregma, 0.5 mm lateral, 4.2 mm deep from dura). We previously showed that expression of this virus in dopamine neurons is highly selective and efficient (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>).</p><p>After &gt; 1 week from virus injection, a custom-made metal plate (a head plate) was implanted. A microdrive containing electrodes and an optical fiber was implanted in the VTA stereotactically in the same surgery. All the surgeries were performed under aseptic conditions under isoflurane inhalation anesthesia (1–2% at 0.8–1.0 L min<sup>−1</sup>). The animals were given analgesics (ketoprofen, 1.3 mg kg<sup>−1</sup> intraperitoneal, and buprenorphine, 0.1 mg kg<sup>−1</sup> intraperitoneal) postoperatively.</p></sec><sec id="s4-3"><title>Behavioral task</title><p>After &gt;1 week of recovery, mice were water-deprived in their home cage. Animals were habituated for 1–2 days with the head restrained by a head plate before training on the task. Odors were delivered with a custom-designed olfactometer (<xref ref-type="bibr" rid="bib59">Uchida and Mainen, 2003</xref>). Each odor was dissolved in mineral oil at 1:10 dilution. 30 µl of diluted odor was placed inside a filter-paper housing (Thomas Scientific, Swedesboro, NJ). Odors were selected pseudorandomly from isoamyl acetate, eugenol, 1-hexanol, citral, and 4-heptanone for each animal. Odorized air was further diluted with filtered air by 1:8 to produce a 900 ml min<sup>−1</sup> total flow rate.</p><p>We delivered an odor for 1 s, followed by 1 s of delay and an outcome. Trials were pseudorandomly interleaved. In the mixed prediction task, during initial training period (1–3 days), an odor (not used for Odors A–D) preceded a drop of water (4 μl) and Odor B preceded no outcome. After the initial training, Odors A–D were paired with water with 25% probability, no outcome (100% nothing), air puff with 75% probability, and water with 25% probability and air puff with remaining 75% probability. In high and low reward probability tasks, 2 odors (not used for Odors A–C) preceded a drop of water and no outcome, respectively, during initial training period. Later, Odor A was paired with water with 90% probability in the high reward probability task, and 20% probability in the low reward probability task. The probabilities of no outcome in Odor B trials and air puff in Odor C trials were 100% and 90%, respectively, in both reward probability tasks. In high reward probability task 2, 2 odors (Odor A and Odor B) preceded a drop of water and no outcome, respectively, during initial training period. Later, Odor A was paired with water with 90% probability and Odor C was paired with air puff with 80% probability. Air puff was delivered to the animal's right eye. The strength of air puff was enough to cause anticipated eye-blinking behavior. In order to control any sounds caused by air puff accumulation, the air was accumulated at the offset of odor delivery in all the trial types and released at 2.3 s after the offset of odor delivery outside of a hemi-soundproof behavioral box except for air puff trials. Licks were detected by breaks of an infrared beam placed in front of the water tube.</p><p>To quantify eye-blinking behavior trial-by-trial, animal’s face including right eye was recorded by a CCD camera (Point Grey). The sampling rate was 60 Hz. To monitor animal’s eye under dark conditions, we put infrared light sources inside the behavior box. To synchronize the video frames with event time stamps for further analysis, the infrared light source was turned off briefly (&lt;25 ms) 2 s after the onset of US.</p><p>We also added no-odor trials (4% of the trials in the mixed prediction task, 12% in high and low reward probability tasks, and 13% in the high reward probability task 2) in which either water reward or air puff was presented unpredictably. Inter-trial intervals (ITIs) were drawn from an exponential distribution, resulting in a flat ITI hazard function truncated at 15 s such that expectation about the start of the next trial did not increase over time. Data in the mixed prediction task were obtained from 63 sessions (19–25 sessions per animal, 21 ± 3 sessions; mean ± S.D., <italic>n</italic> = 3 mice); data in the high reward probability task were obtained from 38 sessions (2–19 sessions per animal, 10 ± 8 sessions, <italic>n</italic> = 4 mice); data in the low reward probability task were obtained from 20 sessions (2–10 sessions per animal, 7 ± 4 sessions, <italic>n</italic> = 3 mice); data in the high reward probability task 2 were obtained from 39 sessions (1–22 sessions per animal, 10 ± 9 sessions, <italic>n</italic> = 4 mice). The animals performed between 208 and 476 trials per day (371 ± 81 trials; mean ± S.D.) in the mixed prediction task, 272 trials per day in both high and low reward probability tasks, and between 182 and 454 trials per day (322 ± 42 trials; mean ± S.D.) in the high reward probability task 2.</p></sec><sec id="s4-4"><title>Electrophysiology</title><p>We recorded extracellularly from multiple neurons simultaneously using a custom-built 200-μm-fiberoptic-coupled screw-driven microdrive with six or eight implanted tetrodes (four wires wound together). Tetrodes were glued to the fiber optic (Thorlabs) with epoxy (Devcon). The ends of the tetrodes were 350–500 μm from the end of the fiber optic. Neural signals and time stamps for behavior were recorded using a DigiLynx recording system (Neuralynx). Broadband signals from each wire filtered between 0.1 and 9000 Hz were recorded continuously at 32 kHz. To extract the timing of spikes, signals were band-pass-filtered between 300 and 6000 Hz. Spikes were sorted offline using MClust-3.5 software (David Redish). At the end of each session, the fiber and tetrodes were lowered by 20–80 μm to record new neurons. Sessions of recordings were continued until the tetrodes reached the bottom of the brain where no units were recorded and large fluctuations of voltage traces were recorded from tetrodes. After the completion of the recording sessions, tetrodes were moved up to the depth where units were recorded or the depth where light-identified dopamine neurons were recorded to ensure that the following electrolytic lesions were in the brain.</p><p>To verify that our recordings targeted dopamine neurons, we used ChR2 to observe stimulation-locked spikes (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>). The optical fiber was coupled with a diode-pumped solid-state laser with analogue amplitude modulation (Laserglow Technologies). Before and after each behavioral session, we delivered trains of 10 light pulses, each 5-ms long, at 1, 2, 5, 10, 20 and 50 Hz at 473 nm at 5–20 mW mm<sup>−2</sup>. Spike shape was measured using a broadband signal (0.1–9000 Hz) sampled at 30 kHz. This ensured that particular features of the spike waveform were not missed.</p><p>We used two criteria to include a neuron in our data set. First, the neuron must have been well isolated [L-ratio &lt; 0.05 (<xref ref-type="bibr" rid="bib46">Schmitzer-Torbert and Redish, 2004</xref>), except for two units with L-ratio = 0.055 and 0.057]. Second, the neuron must have been recorded in or between the sessions when dopamine neurons were identified on the same tetrode to ensure that all neurons came from VTA. Recording sites were further verified histologically with electrolytic lesions using 5–20 s of 30 μA direct current and from the optical fiber track. Recording sites of individual dopamine neurons were reconstructed on the Franklin and Paxinos brain atlas (<xref ref-type="bibr" rid="bib17">Franklin and Paxinos, 2008</xref>). The depths were estimated from the lesion site in each animal.</p></sec><sec id="s4-5"><title>Data analysis</title><p>To measure firing rates, peristimulus time histograms (PSTHs) were constructed using 1-ms bins. To calculate spike density functions, PSTHs were smoothed using a box filter (100 ms duration, t ± 50 ms). Average firing rates of responses to conditioned stimulus (CS) were calculated using a time window of 0–1000 or 200–1000 ms after odor onset. To obtain responses to the unconditioned stimulus (US), we used a time window of 0–600 ms after the onset of US except that responses to air puff omission and nothing (no outcome) were calculated using a time window 0–1000 ms. Slightly different window sizes were also tested and gave qualitatively the same results. The baseline firing rates were obtained based on the activity in a time window during inter-trial-interval immediately preceding odor onset (-1000 to 0 ms before odor onset). The baseline firing rates were computed by using data from all trial types.</p><p>We calculated the area under the receiver-operating characteristic (auROC) value of each neuron using the trial-by-trial responses to CS, unpredicted and predicted outcomes in time windows previously described.</p><p>The area of the right eye region was calculated as follows (see also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>): (1) Eye threshold: Since in our recording settings, most of the face background area was saturated (close to 255 pixel intensity), a threshold around 234 pixel intensity was used to separate eye area from the background. Pixels with intensity smaller than the threshold were set to 1 (white) and others were set to 0 (black). (2) Remove dark patches outside of the eye: To remove the occasional dark patches outside of eye area in the raw image (e.g., top panel in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref>), connected areas smaller than 500 pixels were deleted. (3) Smooth the eye patch: We performed morphological opening to remove spiky edges. Then we filled all black spots on the binary image (e.g., in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>) smaller than 500 pixels to remove the bright spots inside of the eye area due to reflection. (4) Compute eye area: We found the largest connected regions on the binary image in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1D</xref> and computed the area of this region in pixels and also computed the eccentricity by fitting the area to an eclipse (MATLAB regionprops function). These codes for extracting eye areas from video files are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/hide-matsumoto/prog_hide_matsumoto_2016">https://github.com/hide-matsumoto/prog_hide_matsumoto_2016</ext-link>.</p><p>To analyze the eye-blinking behavior trial-by-trial, we synchronized video frames with Neuralynx timestamps as follows: (1) Detect frames when infrared light was off. When infrared light source was briefly turned off (&lt;25 ms), average pixel intensity of the frame steeply decreased. Thus, when the average pixel intensity of each frame in the session was plotted over time, the light-off frames were detected as troughs of the value (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1E</xref>). (2) We then matched these frames that have troughs of average pixel intensity with time stamps of infrared light source-off saved in Neuralynx. (3) Interpolate time of other frames: The timing of a video frame was interpolated using the time stamps of the two closest light-off frames. The eye areas extracted from video frames were further analyzed using event time stamps saved in Neuralynx.</p><p>To compare eye areas across sessions, the computed eye areas were normalized by the maximum eye area (99th percentile of all the eye areas) in every session. Trials were categorized into two groups, blink and no-blink trials, using the criteria that the averaged eye area during delay period in each air puff trial was larger (no-blink trials) or smaller (blink trials) than 0.5.</p><p>To check the percentage of trials that the animals showed anticipatory licking during the delay period (1–2 s from odor onset), trials were categorized into two groups, lick and no-lick trials, using the criteria that the lick rate during the delay period was larger (lick trials) or smaller (no-lick trials) than 3. The threshold (3 licks s<sup>−1</sup>) was determined by comparing the distributions of the lick rates during the delay period in rewarded trials and those in nothing trials (<xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4A</xref>).</p><p>For each statistical analysis provided in the manuscript, the Kolmogorov–Smirnov normality test was first performed on the data to determine whether parametric or non-parametric tests were required. Data were analyzed in MATLAB (MathWorks) and were shown as mean ± S.E.M., unless otherwise stated. For unpaired <italic>t</italic> test, the equality of variance between two groups was first validated statistically. For paired and unpaired comparisons, two-sided tests were used. Bonferroni correction was applied for significance tests with multiple comparisons. To test monotonicity of CS responses, we chose neurons showing that (1) their CS responses were significantly modulated by odors (examined by one-way ANOVA), (2) the response to reward-predicting CS was significantly larger than that to air puff-predicting CS (p&lt;0.05, unpaired <italic>t</italic> test), and (3) the averaged response to CS predicting nothing (or CS predicting both reward and air puff) was intermediate between that to reward-predicting CS and that to air puff-predicting CS. Sample sizes in this study were based on previous literature in the field (<xref ref-type="bibr" rid="bib7">Cohen et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Eshel et al., 2015</xref>, <xref ref-type="bibr" rid="bib13">2016</xref>; <xref ref-type="bibr" rid="bib56">Tian and Uchida, 2015</xref>) and were not pre-determined by a sample size calculation. Randomization and blinding were not employed.</p></sec><sec id="s4-6"><title>Immunohistochemistry</title><p>After recording, mice were transcardially perfused with saline and then with 4% paraformaldehyde under anesthesia. Brains were cut in 100 μm coronal sections. Brain sections from DAT-cre mice were immunostained with antibodies to tyrosine hydroxylase (AB152, 1:400, Millipore; RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/AB_390204">AB_390204</ext-link>) and secondary antibodies labeled with Alexa594 (1:200, Invitrogen) to visualize dopamine neurons. Sections were further stained with 4′,6-diamidino-2-phenylindole (DAPI, Vector Laboratories) to visualize nuclei. Recording sites were further verified to be amid EYFP- and tdTomato-positive or tyrosine hydroxylase-positive neurons in VTA.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank H Kim for eye monitoring system, C Starkweather, N Eshel and other members of the Uchida lab for discussions and C Dulac for sharing resources. This work was supported by a fellowship from Japan Society for the Promotion of Science (HM), the Uehara Memorial Foundation (HM), the Sackler Scholar Programme in Psychobiology (JT) and NIH grants R01MH095953 (NU), R01MH101207 (NU), and R01MH110404 (NU).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf2"><p>NU: Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>HM, Performed video analysis of eye blinking behaviors, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>JT, Performed video analysis of eye blinking behaviors</p></fn><fn fn-type="con" id="con3"><p>NU, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>MW-U, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved Harvard animal care and use committee (IACUC) protocols (#26-03) of Harvard University. All surgery was performed under isofluorane anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atasoy</surname><given-names>D</given-names></name><name><surname>Aponte</surname><given-names>Y</given-names></name><name><surname>Su</surname><given-names>HH</given-names></name><name><surname>Sternson</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A FLEX switch targets Channelrhodopsin-2 to multiple cell types for imaging and long-range circuit mapping</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7025</fpage><lpage>7030</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1954-08.2008</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bäckman</surname><given-names>CM</given-names></name><name><surname>Malik</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Shan</surname><given-names>L</given-names></name><name><surname>Grinberg</surname><given-names>A</given-names></name><name><surname>Hoffer</surname><given-names>BJ</given-names></name><name><surname>Westphal</surname><given-names>H</given-names></name><name><surname>Tomac</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Characterization of a mouse strain expressing Cre recombinase from the 3' untranslated region of the dopamine transporter locus</article-title><source>Genesis</source><volume>44</volume><fpage>383</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1002/dvg.20228</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bayer</surname><given-names>HM</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title><source>Neuron</source><volume>47</volume><fpage>129</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.020</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brischoux</surname><given-names>F</given-names></name><name><surname>Chakraborty</surname><given-names>S</given-names></name><name><surname>Brierley</surname><given-names>DI</given-names></name><name><surname>Ungless</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Phasic excitation of dopamine neurons in ventral VTA by noxious stimuli</article-title><source>PNAS</source><volume>106</volume><fpage>4894</fpage><lpage>4899</lpage><pub-id pub-id-type="doi">10.1073/pnas.0811507106</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name><name><surname>Matsumoto</surname><given-names>M</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dopamine in motivational control: rewarding, aversive, and alerting</article-title><source>Neuron</source><volume>68</volume><fpage>815</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.11.022</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CY</given-names></name><name><surname>Esber</surname><given-names>GR</given-names></name><name><surname>Marrero-Garcia</surname><given-names>Y</given-names></name><name><surname>Yau</surname><given-names>HJ</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brief optogenetic inhibition of dopamine neurons mimics endogenous negative reward prediction errors</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/nn.4191</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>JY</given-names></name><name><surname>Haesler</surname><given-names>S</given-names></name><name><surname>Vong</surname><given-names>L</given-names></name><name><surname>Lowell</surname><given-names>BB</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title><source>Nature</source><volume>482</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature10754</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coizet</surname><given-names>V</given-names></name><name><surname>Dommett</surname><given-names>EJ</given-names></name><name><surname>Redgrave</surname><given-names>P</given-names></name><name><surname>Overton</surname><given-names>PG</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Nociceptive responses of midbrain dopaminergic neurones are modulated by the superior colliculus in the rat</article-title><source>Neuroscience</source><volume>139</volume><fpage>1479</fpage><lpage>1493</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2006.01.030</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>BR</given-names></name><name><surname>Howard</surname><given-names>JL</given-names></name><name><surname>Grant</surname><given-names>LD</given-names></name><name><surname>Smith</surname><given-names>RD</given-names></name><name><surname>Breese</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Alteration of avoidance and ingestive behavior after destruction of central catecholamine pathways with 6-hydroxydopamine</article-title><source>Pharmacology Biochemistry and Behavior</source><volume>2</volume><fpage>639</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1016/0091-3057(74)90033-1</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Ardenne</surname><given-names>K</given-names></name><name><surname>McClure</surname><given-names>SM</given-names></name><name><surname>Nystrom</surname><given-names>LE</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>BOLD responses reflecting dopaminergic signals in the human ventral tegmental area</article-title><source>Science</source><volume>319</volume><fpage>1264</fpage><lpage>1267</lpage><pub-id pub-id-type="doi">10.1126/science.1150605</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danjo</surname><given-names>T</given-names></name><name><surname>Yoshimi</surname><given-names>K</given-names></name><name><surname>Funabiki</surname><given-names>K</given-names></name><name><surname>Yawata</surname><given-names>S</given-names></name><name><surname>Nakanishi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Aversive behavior induced by optogenetic inactivation of ventral tegmental area dopamine neurons is mediated by dopamine D2 receptors in the nucleus accumbens</article-title><source>PNAS</source><volume>111</volume><fpage>6455</fpage><lpage>6460</lpage><pub-id pub-id-type="doi">10.1073/pnas.1404323111</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eshel</surname><given-names>N</given-names></name><name><surname>Bukwich</surname><given-names>M</given-names></name><name><surname>Rao</surname><given-names>V</given-names></name><name><surname>Hemmelder</surname><given-names>V</given-names></name><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arithmetic and local circuitry underlying dopamine prediction errors</article-title><source>Nature</source><volume>525</volume><fpage>243</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1038/nature14855</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eshel</surname><given-names>N</given-names></name><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Bukwich</surname><given-names>M</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dopamine neurons share common response function for reward prediction error</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>479</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.1038/nn.4239</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorillo</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Two dimensions of value: dopamine neurons represent reward but not aversiveness</article-title><source>Science</source><volume>341</volume><fpage>546</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1126/science.1238699</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorillo</surname><given-names>CD</given-names></name><name><surname>Song</surname><given-names>MR</given-names></name><name><surname>Yun</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multiphasic temporal dynamics in responses of midbrain dopamine neurons to appetitive and aversive stimuli</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>4710</fpage><lpage>4725</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3883-12.2013</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flagel</surname><given-names>SB</given-names></name><name><surname>Clark</surname><given-names>JJ</given-names></name><name><surname>Robinson</surname><given-names>TE</given-names></name><name><surname>Mayo</surname><given-names>L</given-names></name><name><surname>Czuj</surname><given-names>A</given-names></name><name><surname>Willuhn</surname><given-names>I</given-names></name><name><surname>Akers</surname><given-names>CA</given-names></name><name><surname>Clinton</surname><given-names>SM</given-names></name><name><surname>Phillips</surname><given-names>PE</given-names></name><name><surname>Akil</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A selective role for dopamine in stimulus-reward learning</article-title><source>Nature</source><volume>469</volume><fpage>53</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1038/nature09588</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Franklin</surname><given-names>KB</given-names></name><name><surname>Paxinos</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>The Mouse Brain in Stereotaxic Coordinates</source><publisher-loc>San Diego</publisher-loc><publisher-name>Elsevier Academic Press</publisher-name></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guarraci</surname><given-names>FA</given-names></name><name><surname>Kapp</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>An electrophysiological characterization of ventral tegmental area dopaminergic neurons during differential pavlovian fear conditioning in the awake rabbit</article-title><source>Behavioural Brain Research</source><volume>99</volume><fpage>169</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(98)00102-8</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>AS</given-names></name><name><surname>Rutledge</surname><given-names>RB</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name><name><surname>Phillips</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>698</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2489-13.2014</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollerman</surname><given-names>JR</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Dopamine neurons report an error in the temporal prediction of reward during learning</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>304</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1038/1124</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ilango</surname><given-names>A</given-names></name><name><surname>Kesner</surname><given-names>AJ</given-names></name><name><surname>Keller</surname><given-names>KL</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>Ikemoto</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Similar roles of substantia nigra and ventral tegmental dopamine neurons in reward and aversion</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>817</fpage><lpage>822</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1703-13.2014</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshua</surname><given-names>M</given-names></name><name><surname>Adler</surname><given-names>A</given-names></name><name><surname>Mitelman</surname><given-names>R</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Midbrain dopaminergic neurons and striatal cholinergic interneurons encode the difference between reward and aversive events at different epochs of probabilistic classical conditioning trials</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>11673</fpage><lpage>11684</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3839-08.2008</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>HF</given-names></name><name><surname>Ghazizadeh</surname><given-names>A</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dopamine neurons encoding long-term memory of object value for habitual behavior</article-title><source>Cell</source><volume>163</volume><fpage>1165</fpage><lpage>1175</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.10.063</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayashi</surname><given-names>S</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reward contexts extend dopamine signals to unrewarded stimuli</article-title><source>Current Biology</source><volume>24</volume><fpage>56</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.061</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kvitsiani</surname><given-names>D</given-names></name><name><surname>Ranade</surname><given-names>S</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Taniguchi</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>JZ</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distinct behavioural and network correlates of two interneuron types in prefrontal cortex</article-title><source>Nature</source><volume>498</volume><fpage>363</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nature12176</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammel</surname><given-names>S</given-names></name><name><surname>Hetzel</surname><given-names>A</given-names></name><name><surname>Häckel</surname><given-names>O</given-names></name><name><surname>Jones</surname><given-names>I</given-names></name><name><surname>Liss</surname><given-names>B</given-names></name><name><surname>Roeper</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Unique properties of mesoprefrontal neurons within a dual mesocorticolimbic dopamine system</article-title><source>Neuron</source><volume>57</volume><fpage>760</fpage><lpage>773</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.01.022</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammel</surname><given-names>S</given-names></name><name><surname>Ion</surname><given-names>DI</given-names></name><name><surname>Roeper</surname><given-names>J</given-names></name><name><surname>Malenka</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Projection-specific modulation of dopamine neuron synapses by aversive and rewarding stimuli</article-title><source>Neuron</source><volume>70</volume><fpage>855</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.03.025</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammel</surname><given-names>S</given-names></name><name><surname>Lim</surname><given-names>BK</given-names></name><name><surname>Malenka</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reward and aversion in a heterogeneous midbrain dopamine system</article-title><source>Neuropharmacology</source><volume>76</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1016/j.neuropharm.2013.03.019</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>TN</given-names></name><name><surname>Shilyansky</surname><given-names>C</given-names></name><name><surname>Davidson</surname><given-names>TJ</given-names></name><name><surname>Evans</surname><given-names>KE</given-names></name><name><surname>Beier</surname><given-names>KT</given-names></name><name><surname>Zalocusky</surname><given-names>KA</given-names></name><name><surname>Crow</surname><given-names>AK</given-names></name><name><surname>Malenka</surname><given-names>RC</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Tomer</surname><given-names>R</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Intact-brain analyses reveal distinct information carried by SNc dopamine subcircuits</article-title><source>Cell</source><volume>162</volume><fpage>635</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.07.014</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margolis</surname><given-names>EB</given-names></name><name><surname>Lock</surname><given-names>H</given-names></name><name><surname>Hjelmstad</surname><given-names>GO</given-names></name><name><surname>Fields</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The ventral tegmental area revisited: is there an electrophysiological marker for dopaminergic neurons?</article-title><source>The Journal of Physiology</source><volume>577</volume><fpage>907</fpage><lpage>924</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2006.117069</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsumoto</surname><given-names>M</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title><source>Nature</source><volume>459</volume><fpage>837</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1038/nature08028</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matthews</surname><given-names>GA</given-names></name><name><surname>Nieh</surname><given-names>EH</given-names></name><name><surname>Vander Weele</surname><given-names>CM</given-names></name><name><surname>Halbert</surname><given-names>SA</given-names></name><name><surname>Pradhan</surname><given-names>RV</given-names></name><name><surname>Yosafat</surname><given-names>AS</given-names></name><name><surname>Glober</surname><given-names>GF</given-names></name><name><surname>Izadmehr</surname><given-names>EM</given-names></name><name><surname>Thomas</surname><given-names>RE</given-names></name><name><surname>Lacy</surname><given-names>GD</given-names></name><name><surname>Wildes</surname><given-names>CP</given-names></name><name><surname>Ungless</surname><given-names>MA</given-names></name><name><surname>Tye</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dorsal raphe dopamine neurons represent the experience of social isolation</article-title><source>Cell</source><volume>164</volume><fpage>617</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.12.040</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCutcheon</surname><given-names>JE</given-names></name><name><surname>Ebner</surname><given-names>SR</given-names></name><name><surname>Loriaux</surname><given-names>AL</given-names></name><name><surname>Roitman</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Encoding of aversion by dopamine and the nucleus accumbens</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>137</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00137</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menegas</surname><given-names>W</given-names></name><name><surname>Bergan</surname><given-names>JF</given-names></name><name><surname>Ogawa</surname><given-names>SK</given-names></name><name><surname>Isogai</surname><given-names>Y</given-names></name><name><surname>Umadevi Venkataraju</surname><given-names>K</given-names></name><name><surname>Osten</surname><given-names>P</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dopamine neurons projecting to the posterior striatum form an anatomically distinct subclass</article-title><source>eLife</source><volume>4</volume><elocation-id>e10032</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10032</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mileykovskiy</surname><given-names>B</given-names></name><name><surname>Morales</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Duration of inhibition of ventral tegmental area dopamine neurons encodes a level of conditioned fear</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>7471</fpage><lpage>7476</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5731-10.2011</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirenowicz</surname><given-names>J</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Importance of unpredictability for reward responses in primate dopamine neurons</article-title><source>Journal of Neurophysiology</source><volume>72</volume><fpage>1024</fpage><lpage>1027</lpage></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirenowicz</surname><given-names>J</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Preferential activation of midbrain dopamine neurons by appetitive rather than aversive stimuli</article-title><source>Nature</source><volume>379</volume><fpage>449</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1038/379449a0</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nomoto</surname><given-names>K</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name><name><surname>Sakagami</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Temporally extended dopamine responses to perceptually demanding reward-predictive stimuli</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>10692</fpage><lpage>10702</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4828-09.2010</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oleson</surname><given-names>EB</given-names></name><name><surname>Gentry</surname><given-names>RN</given-names></name><name><surname>Chioma</surname><given-names>VC</given-names></name><name><surname>Cheer</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Subsecond dopamine release in the nucleus accumbens predicts conditioned punishment and its successful avoidance</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>14804</fpage><lpage>14808</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3087-12.2012</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>WX</given-names></name><name><surname>Schmidt</surname><given-names>R</given-names></name><name><surname>Wickens</surname><given-names>JR</given-names></name><name><surname>Hyland</surname><given-names>BI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Dopamine cells respond to predicted events during classical conditioning: evidence for eligibility traces in the reward-learning network</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>6235</fpage><lpage>6242</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1478-05.2005</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popescu</surname><given-names>AT</given-names></name><name><surname>Zhou</surname><given-names>MR</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Phasic dopamine release in the medial prefrontal cortex enhances stimulus discrimination</article-title><source>PNAS</source><volume>113</volume><fpage>E3169</fpage><lpage>3176</lpage><pub-id pub-id-type="doi">10.1073/pnas.1606098113</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rescorla</surname><given-names>RA</given-names></name><name><surname>Wagner</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1972">1972</year><chapter-title>A theory of pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</chapter-title><person-group person-group-type="editor"><name><surname>Black</surname> <given-names>A. H</given-names></name><name><surname>Prokasy</surname> <given-names>W. F</given-names></name></person-group><source>Classical Conditioning II: Current Research and Theory</source><publisher-loc>New York</publisher-loc><publisher-name>Appleton-Century-Crofts</publisher-name><fpage>64</fpage><lpage>99</lpage></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roeper</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dissecting the diversity of midbrain dopamine neurons</article-title><source>Trends in Neurosciences</source><volume>36</volume><fpage>336</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2013.03.003</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roesch</surname><given-names>MR</given-names></name><name><surname>Calu</surname><given-names>DJ</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1615</fpage><lpage>1624</lpage><pub-id pub-id-type="doi">10.1038/nn2013</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>MF</given-names></name><name><surname>Wheeler</surname><given-names>RA</given-names></name><name><surname>Wightman</surname><given-names>RM</given-names></name><name><surname>Carelli</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Real-time chemical responses in the nucleus accumbens differentiate rewarding and aversive stimuli</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1376</fpage><lpage>1377</lpage><pub-id pub-id-type="doi">10.1038/nn.2219</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitzer-Torbert</surname><given-names>N</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal activity in the rodent dorsal striatum in sequential navigation: separation of spatial and reward responses on the multiple T task</article-title><source>Journal of Neurophysiology</source><volume>91</volume><fpage>2259</fpage><lpage>2272</lpage><pub-id pub-id-type="doi">10.1152/jn.00687.2003</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dopamine signals for reward value and risk: basic and recent data</article-title><source>Behavioral and Brain Functions</source><volume>6</volume><elocation-id>24</elocation-id><pub-id pub-id-type="doi">10.1186/1744-9081-6-24</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal reward and decision signals: From theories to data</article-title><source>Physiological Reviews</source><volume>95</volume><fpage>853</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1152/physrev.00023.2014</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dopamine reward prediction-error signalling: a two-component response</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>183</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1038/nrn.2015.26</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Responses of nigrostriatal dopamine neurons to high-intensity somatosensory stimulation in the anesthetized monkey</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>201</fpage><lpage>217</lpage></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stauffer</surname><given-names>WR</given-names></name><name><surname>Lak</surname><given-names>A</given-names></name><name><surname>Kobayashi</surname><given-names>S</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Components and characteristics of the dopamine reward utility signal</article-title><source>Journal of Comparative Neurology</source><volume>524</volume><fpage>1699</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1002/cne.23880</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinberg</surname><given-names>EE</given-names></name><name><surname>Keiflin</surname><given-names>R</given-names></name><name><surname>Boivin</surname><given-names>JR</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Janak</surname><given-names>PH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A causal link between prediction errors, dopamine neurons and learning</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>966</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1038/nn.3413</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Reinforcement Learning: An Introduction</source><publisher-name>Cambridge Univ Press</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>KR</given-names></name><name><surname>Yvon</surname><given-names>C</given-names></name><name><surname>Turiault</surname><given-names>M</given-names></name><name><surname>Mirzabekov</surname><given-names>JJ</given-names></name><name><surname>Doehner</surname><given-names>J</given-names></name><name><surname>Labouèbe</surname><given-names>G</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Tye</surname><given-names>KM</given-names></name><name><surname>Lüscher</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>GABA neurons of the VTA drive conditioned place aversion</article-title><source>Neuron</source><volume>73</volume><fpage>1173</fpage><lpage>1183</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.02.015</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Habenula lesions reveal that multiple mechanisms underlie dopamine prediction errors</article-title><source>Neuron</source><volume>87</volume><fpage>1304</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.028</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>R</given-names></name><name><surname>Cohen</surname><given-names>JY</given-names></name><name><surname>Osakada</surname><given-names>F</given-names></name><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distributed and mixed information in monosynaptic inputs to dopamine neurons</article-title><source>Neuron</source><volume>91</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.018</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>HC</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Adamantidis</surname><given-names>A</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>de Lecea</surname><given-names>L</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Phasic firing in dopaminergic neurons is sufficient for behavioral conditioning</article-title><source>Science</source><volume>324</volume><fpage>1080</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1126/science.1168878</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Speed and accuracy of olfactory discrimination in the rat</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1224</fpage><lpage>1229</lpage><pub-id pub-id-type="doi">10.1038/nn1142</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungless</surname><given-names>MA</given-names></name><name><surname>Magill</surname><given-names>PJ</given-names></name><name><surname>Bolam</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Uniform inhibition of dopamine neurons in the ventral tegmental area by aversive stimuli</article-title><source>Science</source><volume>303</volume><fpage>2040</fpage><lpage>2042</lpage><pub-id pub-id-type="doi">10.1126/science.1093360</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungless</surname><given-names>MA</given-names></name><name><surname>Grace</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Are you or aren't you? Challenges associated with physiologically identifying dopamine neurons</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.02.003</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Zessen</surname><given-names>R</given-names></name><name><surname>Phillips</surname><given-names>JL</given-names></name><name><surname>Budygin</surname><given-names>EA</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activation of VTA GABA neurons disrupts reward consumption</article-title><source>Neuron</source><volume>73</volume><fpage>1184</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.02.016</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waelti</surname><given-names>P</given-names></name><name><surname>Dickinson</surname><given-names>A</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dopamine responses comply with basic assumptions of formal learning theory</article-title><source>Nature</source><volume>412</volume><fpage>43</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1038/35083500</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wenzel</surname><given-names>JM</given-names></name><name><surname>Rauscher</surname><given-names>NA</given-names></name><name><surname>Cheer</surname><given-names>JF</given-names></name><name><surname>Oleson</surname><given-names>EB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A role for phasic dopamine release within the nucleus accumbens in encoding aversion: a review of the neurochemical literature</article-title><source>ACS Chemical Neuroscience</source><volume>6</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1021/cn500255p</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Steinberg</surname><given-names>EE</given-names></name><name><surname>Lee</surname><given-names>SY</given-names></name><name><surname>Davidson</surname><given-names>TJ</given-names></name><name><surname>Zalocusky</surname><given-names>KA</given-names></name><name><surname>Brodsky</surname><given-names>M</given-names></name><name><surname>Yizhar</surname><given-names>O</given-names></name><name><surname>Cho</surname><given-names>SL</given-names></name><name><surname>Gong</surname><given-names>S</given-names></name><name><surname>Ramakrishnan</surname><given-names>C</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name><name><surname>Tye</surname><given-names>KM</given-names></name><name><surname>Janak</surname><given-names>PH</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Recombinase-driver rat lines: tools, techniques, and optogenetic application to dopamine-mediated reinforcement</article-title><source>Neuron</source><volume>72</volume><fpage>721</fpage><lpage>733</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.10.028</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.17328.020</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Costa</surname><given-names>Rui M</given-names></name><role>Reviewing editor</role><aff id="aff4"><institution>Fundação Champalimaud</institution>, <country>Portugal</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Midbrain dopamine neurons signal aversion in a reward-context-dependent manner&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The reviewers appreciated the new data evaluating the relationship between aversive and appetitive coding in dopamine neurons of the VTA in this study, and also the effort in doing these analyses with carefully identified dopamine. However, the overall opinion was that the authors have to more carefully analyze their existing data, and to ensure the data clearly support the conclusions they make. Below is a summary of the 3 main types of concern that should be addressed:</p><p>1) A general comment brought up by all reviewers is that the authors should analyze the phasic neuronal responses with better temporal specificity, i.e., not just averaging over one larger time bin. The reviewers felt that it is not justified to ignore temporal dynamics in the aversive CS response, and that the conclusions (for example regarding stimulus generalization) will be changed/tempered if this is done.</p><p>2) The reviewers felt that the relationship between the behavior and the neural activity was not being fully fleshed out, and so new analyses are important to substantiate some of the claims. Namely relationship between CS and US in different predicted and unpredicted conditions, meaning of control tasks, and analyses of anticipatory licking, etc.</p><p>3) Another concern was the small n for many conclusions and the need for some additional statistical analyses. Although new experiments may be beyond the scope of this review, some conclusions may be biased by a low n (no significance in some cases vs. significance in other cases). Also, ANOVA and multiple comparison correction may be needed in some cases.</p><p>Also below are the detailed points of each reviewer to help in your revised submission.</p><p><italic>Reviewer #1:</italic> </p><p>Matsumoto and colleagues describe the responses of identified dopamine (DA) neurons recorded from the lateral VTA of mice during multiple variations of an odor discrimination task. The methodology, including the DA neuron identification and recording, is similar to prior work from this group, and reflects a careful and sophisticated approach towards investigating the responses of individual identified neurons to outcomes and the cues that predict them. The authors' aim is to investigate the encoding by DA neurons of aversive stimuli, given the mixed findings in the literature. The approach taken here is to compare the neuronal responses to cues in a discrimination procedure in which reward-predictive and airpuff-predictive cues, as well as cues predicting both, or nothing, are presented pseudorandomly. The authors find that the encoding of aversive-predicting cues varies with the relative probability of other cues being reinforced by reward, such that DA response to airpuff-paired cues are decreases in spiking in low density reward sessions, and DA responses to airpuff-paired cues are increases in spiking in high density reward sessions (although decreases are also clearly visible in the neural response – see below). These are interesting findings. The results do add substantially to our understanding of DA neural responses by providing careful parametric comparisons in, very critically, <italic>identified</italic> DA neurons, using opto-tagging. Importantly, the notion that overall reward density may alter responses to cues – reward paired, or not – was shown previously by Schultz and colleagues, and this is acknowledged by the authors. The present data add to our understanding of the regulation of DA neuron responses to reward- and punishment-paired cues and will be of strong interest to scientists studying dopamine systems, as well as more generally, reward, addiction, and learning. The paper would benefit from more careful consideration of the specific attributes and limitations of these studies in forming their interpretations.</p><p>In addition, an explanation of how the differing signals in response to the negative cue in high and low reward contexts might be expected to impact current or future behavior differentially is missing, given that the behavioral data presented indicate that anticipatory eye blinking is similar in both contexts – however their conclusion on this point may be a function of their analysis approach. Specifics follow.</p><p>1) The authors conclude that &quot;In low reward contexts, dopamine neurons were inhibited by aversive events more strongly than by neutral events, tracking aversiveness of stimuli on a trial-by-trial basis […] However, in high reward contexts, dopamine neurons exhibited early excitations, which undermined their ability to produce negative responses for aversive events.&quot; While their data as currently analyzed support this statement, it begs the question of what these different &quot;modes&quot; mean for learning and behavior since they presumably would communicate different information to downstream structures. The authors show that mice tend to show anticipatory blinking for airpuff in response to the cue whether it is a low or high reward context, but the relationship between the suppression of firing in response to the airpuff-predictive cue only holds for the low reward context, because consistent suppression in the DA neuron response is not seen in response to this cue in the high reward context. Yet this does not take the biphasic nature of the neural response to the aversive stimulus in the high reward context into account. In light of this (as well as the comment that follows), the pupillary/blink response appears to occur on a timescale parallel to that of the late component of the neural response, which in the case of the aversive cue, is an inhibition. Thus, it appears to me that there may indeed by a correlation with behavior and the neural signal. Can the authors investigate this issue more deeply?</p><p>2) The authors further state that: &quot;[…]dopamine neurons signaled VPEs by faithfully combining information about both appetitive and aversive events into a common currency of value.&quot; Their evidence for this is that the average firing rate of DA neurons following a cue that predicts either an airpuff or reward is between that of a reward-predicting and an airpuff-predicting cue – however, this conclusion may depend overmuch on the averaging of the signal over the first second of cue presentation. Examination of the population histograms clearly show that this signal is dynamic, and that averaging the response over the full first second of cue presentation may obscure a multiphasic response to the aversive cues – there looks to be an excitation followed by an inhibition in the high reward context. Again, this is a response pattern described by Schultz and colleagues, who suggests that the early response reflects attributes such as stimulus generalization and intensity, and it is the later response that reflects the prediction error/value signal. This interpretation should receive deeper treatment in the current manuscript. Maybe the averaging across the full second is the most direct statistical approach, but the biphasic nature of the signal should be acknowledged.</p><p>3) It has been proposed that excitatory responses to cues that do not predict reward in multi-cue procedures (wherein some cues do predict reward) reflect stimulus generalization, among other factors. This seems to be one possible explanation for the finding that increases in response to the airpuff cue are more often seen in a high reward context than a low reward context. In addition, the authors data further support this notion since the cue that predicts no reward also shows an initial excitation in the high reward, but not low reward, context. Have the authors thought to use cues of differing modalities to reduce the sensory similarity? If not, the authors should consider that their data do not contradict a generalization and/or salience notion, although they appear to say they do.</p><p>4) The authors conclude that &quot;dopamine neurons do not encode aversion in a conventional classical conditioning task&quot;. Given the clear evidence provided by the authors that reward context impacts the response of VTA dopamine neurons provided by the authors, the authors have not provided an appropriate test of this hypothesis. To conclude this, the authors would need to conduct their recordings in a procedure without interleaved rewarded trials.</p><p>5) I am curious what the potential differences in the responses to the conditioned stimuli and the unconditioned stimuli for a given neuron might be. Indeed, it would be useful if the authors reported the extent to which the encoding observed during the cue is similar to encoding during the outcome, i.e., if a neuron is inhibited by an airpuff-predicting cue, is it also inhibited by unexpected air puff. This is especially interesting given the points above, that the high reward context increase in firing at the outset of the odor cues seems parsimoniously explained as generalization, while the neural responses to the respective outcomes could still be increases and decreases for sucrose and airpuffs, respectively. In other words, do DA neuron responses to presentation of airpuff itself change in different reward contexts, or is this strictly a feature of the conditioned stimuli.</p><p><italic>Reviewer #2:</italic> </p><p>In this manuscript, Matsumoto et al. investigated the response of midbrain dopaminergic neurons to an aversive stimulus in a variety of contexts. Although dopamine is thought to be important for learning from both reward and punishment, there has been disagreement about how dopaminergic neurons integrate aversive and rewarding stimuli. The authors show that dopaminergic activity is inhibited by an air puff and an air puff-predicting odor in low reward contexts. The air puff response is modulated by expectation and individual dopaminergic neurons are able to integrate the value of reward and punishment. Finally, they show that manipulating reward context affects dopaminergic responses to punishment, such that in high reward contexts there is actually an excitatory response to punishments. The latter condition appears to replicate various previous studies. The data provides a valuable contribution to the debate over how dopaminergic neurons respond to aversive stimuli. The use of optogenetic tagging allows for compelling identification of dopaminergic neurons and the authors tested several task structures in order to reconcile discrepancies in the field.</p><p>There are several ways in which the analysis and presentation should be improved:</p><p>1) In <xref ref-type="fig" rid="fig2">Figure 2</xref> the authors conclude that in a high reward context, dopaminergic neurons respond to aversive stimuli with short-latency excitation &quot;masked inhibitory responses&quot; such that there is no longer a significant difference between responses to odor B and odor C. The importance of reward context is a major conclusion of the paper but its complete disruption of aversive signaling is confusing (and not entirely convincing) as presented. Why not analyze the different temporal phases of the response separately? It appears that if the responses were compared during the late inhibitory phase of the response (evident in <xref ref-type="fig" rid="fig2">Figure 2B</xref>), then there would indeed be a difference in the response to odor B and odor C in both the high reward and low reward contexts. In other words, the simplest explanation of the effect of &quot;high reward context&quot; is to create a short-latency excitatory response to the aversive stimulus. The authors argue this response is different from the short-latency 'generalization' response described by Schultz and colleagues, but not clear what that means. Specifically, in the Discussion it is noted that a high reward context &quot;compromised the monotonic value coding of dopamine neurons,&quot; but this was not clearly explained or analyzed. Additionally, the argument that the excitatory response to punishment in a high reward context is not due to generalization is unclear. The authors write that &quot;dopamine neurons did not simply add the same amount of excitation on top of the monotonic value coding.&quot; In fact, in <xref ref-type="fig" rid="fig2">Figure 2</xref>, it seems like there is an excitatory &quot;generalization&quot; response that is being added to the pause in firing to the CS-.</p><p>2) Although there is a clear increase in the amplitude of the response to air puff when it is unpredicted, there is large variability in the response to an omitted air puff. Although on average there is a very small increase in firing rate, a very large number of neurons decrease their activity in response to air puff omission (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). The authors should discuss the heterogeneity of this response, which appears to complicate their conclusions.</p><p>3) It seems surprising that there is no correlation between the response to unpredicted air puff and unpredicted water delivery (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). In Eshel et al. (2016) there is a correlation between predicted air puff and unpredicted water responses as well as between the air puff cue and the unpredicted water responses. So why wouldn't there be a correlation between unpredicted air puff and reward? Doesn't this mean that predicted and unpredicted air puff responses are themselves uncorrelated, which would contradict the earlier panels in <xref ref-type="fig" rid="fig5">Figure 5</xref>?</p><p>4) The protocol for the classical conditioning experiment conducted for <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> is unclear. It appears that the only difference from the high reward task is the probability of punishment following odor C which is 80% instead of 90%, yet the excitatory component of the response to the punishment-predicting CS appears considerably larger than in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><p>5) Not clear exactly what the eye blink response analysis achieves in the paper, nor why eye blinks were analyzed but not anticipatory licking.</p><p>6) There is no reported method for the correction for multiple comparisons in multiple instances when more than 2 groups are being analyzed in the same panel. Additionally, a two-way ANOVA should be used to analyze the effect of reward probability and anticipatory blinking in <xref ref-type="fig" rid="fig4">Figure 4F</xref>.</p><p><italic>Reviewer #3:</italic> </p><p>In this manuscript Matsumoto and colleagues present a series of experiments that address the issue of how dopamine neurons respond to aversive events. They make a number of important and interesting observations. On the whole I thought the manuscript was well-written. I have a few concerns that I list below:</p><p>1) I feel that the Introduction would benefit from some elaboration in a few places.</p><p>Introduction, fourth paragraph: should make it clear that Oleson et al. (2012) measured dopamine release using FSCV.</p><p>Introduction, fifth paragraph: I am not clear how Roitman et al. (2008) resolved the issue and this was published several years earlier, so the wording is confusing in my view.</p><p>Introduction, fifth paragraph: should make it clear that Lerner et al. (2015) measured calcium activity, not action potential firing.</p><p>Introduction, last paragraph: this paragraph alludes to the issue of neurochemical identity in a way that I think should be more explicit since it is of particular relevance to this study. For example, Ungless et al. (2004) showed that some VTA neurons that are excited by aversive events are in fact not dopaminergic. It is noted, for example by Schultz (2016) in a recent review, that Matsumoto &amp; Hikosaka (2009) recorded many neurons in areas where dopamine neurons were rare. This more strongly justifies the use of the opto-tagging approach that the authors have taken.</p><p>2) One general concern I had was the low numbers of mice in several of the experimental groups (e.g., <xref ref-type="fig" rid="fig1">Figure 1</xref>, n=3).</p><p>3) How do the authors know that the mice can tell the difference between the low and high reward situations?</p><p>4) In the subsection “Integration of aversiveness and reward in dopamine neurons”, first paragraph: add the caveat that activation of meso-cortical dopamine neurons and dorsal raphe dopamine neurons can induce conditioned-place aversion (Lammel et al. 2014 &amp; Matthews et al. 2016).</p><p>4) In the subsection “Diversity of dopamine neurons”: note also that Brischoux et al. (2009) reported that ventromedial dopamine neurons exhibited aversive activations.</p><p>5) I found some of the red/purple colour schemes difficult to tell apart. I would suggest some different colour schemes (particularly for <xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Midbrain dopamine neurons signal aversion in a reward-context-dependent manner&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Timothy Behrens (Senior editor), a Reviewing editor, and two reviewers.</p><p>The manuscript has been improved but there are some remaining issues regarding its readability that need to be addressed before acceptance, as outlined below by Reviewer 2. After consultation between the reviewers, both thought that increased readability and explanation of why each experiment was performed would greatly enhance the clarity and impact of the study.</p><p><italic>Reviewer #2:</italic> </p><p>I felt that the reviewers were responsive to our comments and that this study provides a valuable contribution to the discussion regarding the integration of rewarding and aversive cues in dopamine neurons.</p><p>My only remaining comment is that I find the text in the Results and Discussion a bit difficult to follow. There are a number of experiments/analyses, and as it currently stands, the motivation for each experiment/analysis, as well as the relevant conclusions, is not always completely transparent. Therefore, the authors could consider editing the Results/Discussion for improved readability.</p><p><italic>Reviewer #3:</italic> </p><p>This new version addresses the previous concerns that I raised.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.17328.021</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>The reviewers appreciated the new data evaluating the relationship between aversive and appetitive coding in dopamine neurons of the VTA in this study, and also the effort in doing these analyses with carefully identified dopamine. However, the overall opinion was that the authors have to more carefully analyze their existing data, and to ensure the data clearly support the conclusions they make. Below is a summary of the 3 main types of concern that should be addressed:</italic> </p><p>We appreciate all of the reviewers for their constructive criticism and suggestions. We have performed additional analyses and modified our manuscript according to reviewer’s comments. We hope that our manuscript has improved.</p><p><italic>1) A general comment brought up by all reviewers is that the authors should analyze the phasic neuronal responses with better temporal specificity, i.e., not just averaging over one larger time bin. The reviewers felt that it is not justified to ignore temporal dynamics in the aversive CS response, and that the conclusions (for example regarding stimulus generalization) will be changed/tempered if this is done.</italic> </p><p>We appreciate reviewers’ criticism on the choice of time windows. We are aware that, in previous studies, it has become a common practice to pick a time window somewhat arbitrarily, especially for the analysis of dopamine activities. Although these studies have shown that dopamine neurons often show multi-phasic responses and different information appears to be conveyed in different time windows, no study has shown that postsynaptic neurons are equipped with a special mechanism to separately read out information from these windows. We therefore chose to use a relatively large time window (0–1,000 ms) that covers the entire response period as this would be a more conservative approach, and used this method throughout the manuscript. This rationale is now explained in Results (subsection “Reward-context dependent representation of aversion in dopamine neurons”, fifth paragraph).</p><p><italic>The above analyses used a relatively large time window that contains the entire response period (0–1,000 ms). Because dopamine responses in high reward contexts exhibited biphasic responses (early excitation followed by later inhibition), we further analyzed the data by separating these time windows into smaller bins. Because there is no known mechanism by which downstream neurons can read out these windows separately, analysis using a large window can be considered more conservative. However, previous studies have indicated that different information may be conveyed in these time windows (Schultz, 2016; Stauffer et al., 2016).</italic></p><p>However, we agree that it is important to know what information is conveyed by different time windows, as Schultz recently proposed (Schultz, 2016, Nat Rev Neurosci). We therefore performed new analyses using the time window in which dopamine neurons are predominantly inhibited, i.e. the later response phase (200–1,000 ms). Analyses using the small time window generally confirmed that there is a similar trend. For instance, fewer neurons showed a significant difference between nothing-predictive- and air puff-predictive CSs in a high reward context. These results are now shown in Figure 4—figure supplement 2, and discussed in Results as follows:</p><p>“We obtained similar results even if we compared only later time bins (200–1,000 ms), excluding the early excitation phase (Figure 4—figure supplement 2). […] Neurons that showed a large excitation to the air puff CS were not necessarily the same group of neurons which showed excitation to the air puff itself, consistent with a previous study (Matsumoto and Hikosaka, 2009) (Figure 4—figure supplement 3).”</p><p>We have also performed analyses on the relation between trial-to-trial variability of dopamine activities and anticipatory blinking using the later time window (200–1,000 ms). This analysis is now shown in <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> and discussed in Results as follows:</p><p>“The correlation between trial-by-trial dopamine activity and anticipatory blinking was even clearer if we consider reward contexts (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). […] The results do not change even when we only used a later window of dopamine CS responses, excluding the early excitation period (0–200 ms) (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).”</p><p><italic>2) The reviewers felt that the relationship between the behavior and the neural activity was not being fully fleshed out, and so new analyses are important to substantiate some of the claims. Namely relationship between CS and US in different predicted and unpredicted conditions, meaning of control tasks, and analyses of anticipatory licking, etc.</italic></p><p>We found that both reward context and behavioral outcome (blink) were important for dopamine neurons to show inhibition to mildly aversive cues but one was not sufficient. We rephrased this part both in Results and Discussion. We also added a new analysis in Figure 4—figure supplement 3 for the analysis of the relationship between CS and US, and <xref ref-type="fig" rid="fig5">Figure 5F</xref> and Figure 5—figure supplement 4 for the analysis of the relationship between anticipatory licking behavior and responses to reward CS. For more details of each analysis, please see our Response to each reviewer’s comment.</p><p><italic>3) Another concern was the small n for many conclusions and the need for some additional statistical analyses. Although new experiments may be beyond the scope of this review, some conclusions may be biased by a low n (no significance in some cases vs. significance in other cases). Also, ANOVA and multiple comparison correction may be needed in some cases.</italic> </p><p>In this study, we used 14 mice for electrophysiological experiments, recorded from 176 neurons and identified 72 dopamine neurons in total. We agree that some of the task conditions contain relatively fewer number of neurons. However, for most of the analyses, we replicated the same results using two separate sets of experiments. To demonstrate the robustness of our basic findings, now we show data analyses using combined data in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1G,J,K</xref> and Las well as side-by-side comparisons of comparable task conditions (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1E,F,H,I</xref>).</p><p>We performed one-way ANOVA for comparing the means of CS responses (1: reward-, nothing-, versus air puff-predicting CSs and 2: reward-, reward + air puff-, versus air puff-predicting CSs). We described the results in Results (subsection “Dopamine neurons integrate values of both valences, appetitive and aversive”, last two paragraphs). Also, Bonferroni correction was applied for significance tests with multiple comparisons. We added this sentence in Materials and methods (subsection “Data analysis”, last paragraph).</p><p><italic>Also below are the detailed points of each reviewer to help in your revised submission.</italic> </p><p><italic>Reviewer #1:</italic> </p><p><italic>1) The authors conclude that &quot;In low reward contexts, dopamine neurons were inhibited by aversive events more strongly than by neutral events, tracking aversiveness of stimuli on a trial-by-trial basis […] However, in high reward contexts, dopamine neurons exhibited early excitations, which undermined their ability to produce negative responses for aversive events.&quot; While their data as currently analyzed support this statement, it begs the question of what these different &quot;modes&quot; mean for learning and behavior since they presumably would communicate different information to downstream structures. The authors show that mice tend to show anticipatory blinking for airpuff in response to the cue whether it is a low or high reward context, but the relationship between the suppression of firing in response to the airpuff-predictive cue only holds for the low reward context, because consistent suppression in the DA neuron response is not seen in response to this cue in the high reward context. Yet this does not take the biphasic nature of the neural response to the aversive stimulus in the high reward context into account. In light of this (as well as the comment that follows), the pupillary/blink response appears to occur on a timescale parallel to that of the late component of the neural response, which in the case of the aversive cue, is an inhibition. Thus, it appears to me that there may indeed by a correlation with behavior and the neural signal. Can the authors investigate this issue more deeply?</italic> </p><p>Please also refer to our response to the editor’s point #1 regarding specific time windows. The question of “what these different modes mean for learning and behavior” is important. One possibility would be that dopamine directly controls or modifies some behaviors. In our task, however, temporal dynamics of dopamine activities and blinking are different: dopamine responses are tightly locked to salient events such as CS or US, while blinking occurs much later than dopamine responses. This appears to suggest that dopamine activities are not tightly time-locked with blinking behaviors. The suggested idea is that certain time window of inhibitory activities might cause blinking. We did not see this correlation between dopamine activities and blinking when we used a big time window. Now we have analyzed our data using only the later phase of responses in high reward contexts, and show that the results are very similar to those obtained using a big time window. We have now added this analysis in <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>.</p><p>We interpret these results to support the idea that the dopamine signal (value coding) is an abstract value representation rather than immediate trigger of actions. Blinking is a good indicator for mice predicting air puff but may not be perfectly correlated with the negative value of the air puff. Dopamine neurons may signal negative value but not action itself. As a result, depending on contexts, prediction of air puff may be correlated with dopamine activity (in low reward context) or not (in high reward context). We rephrased these parts for clarification in Results (e.g. subsection “Trial-to-trial variability dopamine responses to aversive stimuli”, third paragraph) and Discussion.</p><p>“The correlation between trial-by-trial dopamine activity and anticipatory blinking was even clearer if we consider reward contexts (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). [,,,] The results do not change even when we only used a later window of dopamine CS responses, excluding the early excitation period (0–200 ms) (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>).”</p><p><italic>2) The authors further state that: &quot;[…]dopamine neurons signaled VPEs by faithfully combining information about both appetitive and aversive events into a common currency of value.&quot; Their evidence for this is that the average firing rate of DA neurons following a cue that predicts either an airpuff or reward is between that of a reward-predicting and an airpuff-predicting cue – however, this conclusion may depend overmuch on the averaging of the signal over the first second of cue presentation. Examination of the population histograms clearly show that this signal is dynamic, and that averaging the response over the full first second of cue presentation may obscure a multiphasic response to the aversive cues – there looks to be an excitation followed by an inhibition in the high reward context. Again, this is a response pattern described by Schultz and colleagues, who suggests that the early response reflects attributes such as stimulus generalization and intensity, and it is the later response that reflects the prediction error/value signal. This interpretation should receive deeper treatment in the current manuscript. Maybe the averaging across the full second is the most direct statistical approach, but the biphasic nature of the signal should be acknowledged.</italic> </p><p>Please also refer to the answer to the editor’s point #1. As the referee points out, it is important that previous studies have indicated that different information may be conveyed at different time windows. We now discuss the difference between the early and late phases of responses observed in the Schultz’s and Fiorillo’s studies in Introduction (sixth paragraph) and other places (e.g., in Results; subsection “Reward-context dependent representation of aversion in dopamine neurons”, second and fifth paragraphs).</p><p>As explained in our response to the editor’s point #1, we focused on a big time window because it remains unclear whether downstream neurons can read out information from specific, somewhat arbitrary response windows. In addition, our data indicates that defining a value- or prediction-error-specific time window is not very easy.</p><p>In our tasks, we did not observe a time window which solely signaled generalization and/or stimulus intensity regardless of the stimulus identity. For instance, <xref ref-type="fig" rid="fig1">Figure 1B</xref> shows that CS responses diverse in as quickly as 60 ms reflecting the predicted values of upcoming USs suggesting that our dopamine neurons can change their responses in a value dependent manner even in the early phase of the responses. The discrimination of odor identity in dopamine neurons in our task is fast, different from the previous tasks which used ambiguous cue on purpose (Nomoto et al., 2010, J Neurosci), and temporally overlaps with the early excitation during biphasic responses in high reward contexts.</p><p>Despite these difficulties in defining a time window, we have now performed analyses using only the late phase of the responses (200–1,000 ms). We did not observe value coding in this time window in response to air puff CSs in the high reward context, consistent with Fiorillo’s study (Fiorillo, 2013, Science). We added this result in Figure 4—figure supplement 2B. As for our mixed prediction tasks in <xref ref-type="fig" rid="fig1">Figure 1</xref>, if we split into two phases, the first phase includes many positive values of reward cues and the second phase includes many negative values of aversive cues, and so these patterns do not correspond to generalization and/or stimulus intensity and value, respectively. We think that this temporal shift of response peaks reflects the timing of responses encoding reward vs. aversion values with aversive information arriving slightly later, rather than the idea that the early period encodes generalization/intensity and the later period encodes values. We speculate that these shifted responses reflect the different sources of inputs signaling reward or aversion to dopamine neurons, which were not integrated yet in inputs. We have added these points in Discussion (page 17, lines 483-503).</p><p>“In examining the temporal dynamics of dopamine responses, we realized that on average, the peak of excitation for reward cues occurred earlier than the trough of inhibition for aversive cues. […] The results in the previous study (Eshel et al., 2016) could be consistent with the present results if the inhibition represents “no reward” but not the negative value of aversive stimulus, and this no-reward response is correlated with other reward-related responses of dopamine neurons.”</p><p>Because of the two limitations discussed above, we still prefer to report our main results, especially those pertaining to <xref ref-type="fig" rid="fig1">Figure 1</xref>, using a large time window.</p><p><italic>3) It has been proposed that excitatory responses to cues that do not predict reward in multi-cue procedures (wherein some cues do predict reward) reflect stimulus generalization, among other factors. This seems to be one possible explanation for the finding that increases in response to the airpuff cue are more often seen in a high reward context than a low reward context. In addition, the authors data further support this notion since the cue that predicts no reward also shows an initial excitation in the high reward, but not low reward, context. Have the authors thought to use cues of differing modalities to reduce the sensory similarity? If not, the authors should consider that their data do not contradict a generalization and/or salience notion, although they appear to say they do.</italic> </p><p>Thank you very much for the comment and suggestion. We think that our data do not contradict with previous important findings about stimulus generalization etc. but rather expanded those findings. We tested how much these components disturb value coding of dopamine neurons. In addition to stimulus generalization, there are many other interpretations about the cause of early excitations. In each experiment, authors specifically designed to extract each factor from others. We think that the excitation that we observed in our tasks is caused by a combination of these factors, not only by stimulus generalization. The proposed experiment is an important experiment to understand which component is most affected by reward contexts but does not affect our statement that these components disturb value coding in dopamine neurons in high reward contexts. We revised our discussion on this point in the Discussion to be clearer (e.g. page 18, lines 507-524).</p><p><italic>4) The authors conclude that &quot;dopamine neurons do not encode aversion in a conventional classical conditioning task&quot;. Given the clear evidence provided by the authors that reward context impacts the response of VTA dopamine neurons provided by the authors, the authors have not provided an appropriate test of this hypothesis. To conclude this, the authors would need to conduct their recordings in a procedure without interleaved rewarded trials.</italic> </p><p>We apologize that this figure title was very misleading. We fixed this title. Thank you for letting us know.</p><p><italic>5) I am curious what the potential differences in the responses to the conditioned stimuli and the unconditioned stimuli for a given neuron might be. Indeed, it would be useful if the authors reported the extent to which the encoding observed during the cue is similar to encoding during the outcome, i.e., if a neuron is inhibited by an airpuff-predicting cue, is it also inhibited by unexpected air puff. This is especially interesting given the points above, that the high reward context increase in firing at the outset of the odor cues seems parsimoniously explained as generalization, while the neural responses to the respective outcomes could still be increases and decreases for sucrose and airpuffs, respectively. In other words, do DA neuron responses to presentation of airpuff itself change in different reward contexts, or is this strictly a feature of the conditioned stimuli.</italic> </p><p>Thank you for the helpful comment. We observed similar phenomena in the responses to the unconditioned stimulus, i.e., air puff itself. In the low reward context, the response to air puff was mostly negative whereas the response was variable in the high reward context. Although we see a significant difference between responses to unpredicted air puff in high- and low-reward contexts using the neurons in the current data set (p = 0.001, n = 34 and n = 38, respectively, unpaired <italic>t</italic>-test), we would like to examine these phenomena more carefully because individual variability is big across neurons.</p><p>At the single neuron level, neurons which showed a large excitation to air puff CS were not necessarily the same group of neurons which showed excitation to air puff itself, consistent with a previous study (Matsumoto and Hikosaka, 2009, Nature). We now report this result in Figure 4—figure supplement 3 and in Results (page 12, lines 348-351).</p><p>“Neurons that showed a large excitation to the air puff CS were not necessarily the same group of neurons which showed excitation to the air puff itself, consistent with a previous study (Matsumoto and Hikosaka, 2009) (Figure 4—figure supplement 3).”</p><p><italic>Reviewer #2:</italic> </p><p><italic>In this manuscript, Matsumoto et al. investigated the response of midbrain dopaminergic neurons to an aversive stimulus in a variety of contexts. Although dopamine is thought to be important for learning from both reward and punishment, there has been disagreement about how dopaminergic neurons integrate aversive and rewarding stimuli. The authors show that dopaminergic activity is inhibited by an air puff and an air puff-predicting odor in low reward contexts. The air puff response is modulated by expectation and individual dopaminergic neurons are able to integrate the value of reward and punishment. Finally, they show that manipulating reward context affects dopaminergic responses to punishment, such that in high reward contexts there is actually an excitatory response to punishments. The latter condition appears to replicate various previous studies. The data provides a valuable contribution to the debate over how dopaminergic neurons respond to aversive stimuli. The use of optogenetic tagging allows for compelling identification of dopaminergic neurons and the authors tested several task structures in order to reconcile discrepancies in the field.</italic></p><p><italic>There are several ways in which the analysis and presentation should be improved:</italic> </p><p><italic>1) In <xref ref-type="fig" rid="fig2">Figure 2</xref> the authors conclude that in a high reward context, dopaminergic neurons respond to aversive stimuli with short-latency excitation &quot;masked inhibitory responses&quot; such that there is no longer a significant difference between responses to odor B and odor C. The importance of reward context is a major conclusion of the paper but its complete disruption of aversive signaling is confusing (and not entirely convincing) as presented. Why not analyze the different temporal phases of the response separately? It appears that if the responses were compared during the late inhibitory phase of the response (evident in <xref ref-type="fig" rid="fig2">Figure 2B</xref>), then there would indeed be a difference in the response to odor B and odor C in both the high reward and low reward contexts. In other words, the simplest explanation of the effect of &quot;high reward context&quot; is to create a short-latency excitatory response to the aversive stimulus. The authors argue this response is different from the short-latency 'generalization' response described by Schultz and colleagues, but not clear what that means. Specifically, in the Discussion it is noted that a high reward context &quot;compromised the monotonic value coding of dopamine neurons,&quot; but this was not clearly explained or analyzed. Additionally, the argument that the excitatory response to punishment in a high reward context is not due to generalization is unclear. The authors write that &quot;dopamine neurons did not simply add the same amount of excitation on top of the monotonic value coding.&quot; In fact, in <xref ref-type="fig" rid="fig2">Figure 2</xref>, it seems like there is an excitatory &quot;generalization&quot; response that is being added to the pause in firing to the CS-.</italic> </p><p>Thank you for the criticism and suggestions. We now added these analyses in Figure 4—figure supplement 2. Please also see our responses to the editor’s point #1 and reviewer 1’s point #2 and #3.</p><p><italic>2) Although there is a clear increase in the amplitude of the response to air puff when it is unpredicted, there is large variability in the response to an omitted air puff. Although on average there is a very small increase in firing rate, a very large number of neurons decrease their activity in response to air puff omission (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). The authors should discuss the heterogeneity of this response, which appears to complicate their conclusions.</italic> </p><p>We agree that air puff omission responses are very small and variable. Because we only mentioned the smallness, we now mentioned the variability in Results.</p><p>“To further examine whether dopamine neurons showed prediction error coding for aversive events, we compared the firing rate during the outcome period in air puff omission trials with that in trials that predict nothing. We found that the omission of a predicted air puff slightly but significantly increased firing rates, compared to no change in nothing trials (<xref ref-type="fig" rid="fig2">Figure 2E–H</xref>) although we observed variability in air puff omission responses.”</p><p>The air puff omission responses are correlated with air puff prediction and we did not observe clear clusters using these factors. We now added this analysis in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</p><p><italic>3) It seems surprising that there is no correlation between the response to unpredicted air puff and unpredicted water delivery (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). In Eshel et al. (2016) there is a correlation between predicted air puff and unpredicted water responses as well as between the air puff cue and the unpredicted water responses. So why wouldn't there be a correlation between unpredicted air puff and reward? Doesn't this mean that predicted and unpredicted air puff responses are themselves uncorrelated, which would contradict the earlier panels in <xref ref-type="fig" rid="fig5">Figure 5</xref>?</italic> </p><p>As we found in the present study, the negative value of aversive stimulus is well represented in low reward contexts and the responses to aversiveness-related events are correlated with one another in these conditions. Importantly, the previous study (Eshel et al., 2016, Nat Neurosci) was conducted using a high reward context. A previous study found that the inhibition phase after excitation in biphasic responses is not related to aversiveness but to “no reward” (Fiorillo, 2013, Science). Consistent with this idea, we observe that in high reward contexts, cues predicting nothing often caused inhibition in dopamine neurons instead of no responses. In the previous study (Eshel et al., 2016, Nat Neurosci), the authors used cues which signaled either water or air puff (no cue signaling nothing). In this sense, the cue signaling air puff actually signals “no reward”. We interpret that the correlation which authors observed in responses between unpredicted water and air puff CS was mainly due to this “no reward” responses. Further, as the paper stated, the correlation was weak and not statistically significant.</p><p>The correlation between predicted air puff and unpredicted water in the previous study (Eshel et al., 2016, Nat Neurosci) was also complicated due to similar reasons. We examined author’s data more carefully and found that the correlation came from rebound after inhibition, but not inhibition itself; as Fiorillo reported (Fiorillo et al., 2013a, J Neurosci; Fiorillo et al., 2013b, J Neurosci), dopamine neurons actually often showed three phases (excitation, inhibition and excitation). We observed high correlation between this rebound and water responses but not between inhibition and water responses in high reward contexts.</p><p>Our present study is improved to more directly test the relation between rewarding and aversive value representations in dopamine neurons. We observed a correlation both within aversiveness-related representation and within reward related-representation but not between these. We now added this statement more clearly in Results (subsection “Homogeneous response function of dopamine neurons”, third paragraph) and Discussion (subsection “Integration of aversiveness and reward in dopamine neurons”, last paragraph).</p><p><italic>4) The protocol for the classical conditioning experiment conducted for <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> is unclear. It appears that the only difference from the high reward task is the probability of punishment following odor C which is 80% instead of 90%, yet the excitatory component of the response to the punishment-predicting CS appears considerably larger than in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</italic> </p><p>Thank you for pointing this out. Yes, this is a very similar task except that the reward probability was slightly higher and the training procedure was slightly different. In this task (high reward probability task 2), we used 6.5% unpredicted reward delivery in comparison with 6% unpredicted water delivery in the high reward probability task. In addition, in the task 2, the odor predicting 90% water during experiments was same with the odor predicting 100% water during the initial training (a few days). It might be possible that animals might predict water with slightly higher probability than 90% during recording in the task 2 (i.e. higher reward context in the task 2). We now added a detailed task description in Materials and methods (subsection “Behavioral task”, second and last paragraphs). We did not see a significant difference in air puff CS responses between these two tasks (p = 0.19, unpaired <italic>t</italic>-test, n = 17 versus 17). We agree that this was confusing and we now added the pooled data for responses to air puff- and nothing-predicting CSs in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1G</xref>.</p><p><italic>5) Not clear exactly what the eye blink response analysis achieves in the paper, nor why eye blinks were analyzed but not anticipatory licking.</italic> </p><p>Please see our responses to the editor’s point #2 and reviewer 1’s point #1. The main message from the analysis on the neural activity-behavior correlations is to point out the importance of not only the contexts but also behavior in order to understand potential causes of the discrepancies between studies. For reward responses, there are not much physiological discrepancies, which may be due to strong rewarding effects of water, compared to relatively mild aversion with mild air puff. Although anticipatory licking is much more consistent, we observed similar tendency of dopamine responses in relation to anticipatory licking. We now added these results in <xref ref-type="fig" rid="fig5">Figure 5F</xref> and Figure 5—figure supplement 4 and in Results (last paragraph).</p><p><italic>6) There is no reported method for the correction for multiple comparisons in multiple instances when more than 2 groups are being analyzed in the same panel. Additionally, a two-way ANOVA should be used to analyze the effect of reward probability and anticipatory blinking in <xref ref-type="fig" rid="fig4">Figure 4F</xref>.</italic> </p><p>Thank you for the suggestions. A two-way ANOVA cannot be used in <xref ref-type="fig" rid="fig5">Figure 5E</xref> (the original <xref ref-type="fig" rid="fig4">Figure 4F</xref>) because these are two different data sets. We agree that the figure was confusing and we modified the graphs (boxplots derived from two different tasks were displaced separately). We applied Bonferroni’s correction for significance tests with multiple comparisons and added this statement in Materials and methods.</p><p><italic>Reviewer #3:</italic> </p><p><italic>In this manuscript Matsumoto and colleagues present a series of experiments that address the issue of how dopamine neurons respond to aversive events. They make a number of important and interesting observations. On the whole I thought the manuscript was well-written. I have a few concerns that I list below:</italic> </p><p><italic>1) I feel that the Introduction would benefit from some elaboration in a few places.</italic> </p><p>Thank you for the advice. We expanded some discussions in Introduction.</p><p><italic>Introduction, fourth paragraph: should make it clear that Oleson et al. (2012) measured dopamine release using FSCV.</italic> </p><p>RESPONSE: We added this information (Introduction, fourth paragraph).</p><p><italic>Introduction, fifth paragraph: I am not clear how Roitman et al. (2008) resolved the issue and this was published several years earlier, so the wording is confusing in my view.</italic> </p><p>We rephrased the sentence (Introduction, fifth paragraph).</p><p><italic>Introduction, fifth paragraph: should make it clear that Lerner et al. (2015) measured calcium activity, not action potential firing.</italic> </p><p>We added this information (Introduction, fifth paragraph).</p><p><italic>Introduction, last paragraph: this paragraph alludes to the issue of neurochemical identity in a way that I think should be more explicit since it is of particular relevance to this study. For example, Ungless et al. (2004) showed that some VTA neurons that are excited by aversive events are in fact not dopaminergic. It is noted, for example by Schultz (2016) in a recent review, that Matsumoto &amp; Hikosaka (2009) recorded many neurons in areas where dopamine neurons were rare. This more strongly justifies the use of the opto-tagging approach that the authors have taken.</italic> </p><p>Thank you for letting us know! We now added these sentences in Introduction (eighth paragraph) and emphasized more about identification in Abstract and Discussion.</p><p>However, regarding the citation of Schultz’s statement on potential problems in recording locations in some previous studies, our opinion is that we are not in a position to strongly support either view (Schultz’s or the original researchers’). We, therefore, would like to not include this sentence (“Furthermore, Schultz has argued that some previous recording studies may not have targeted areas rich in dopamine neurons (Schultz, 2016)”) if the reviewers are fine with it.</p><p><italic>2) One general concern I had was the low numbers of mice in several of the experimental groups (e.g., <xref ref-type="fig" rid="fig1">Figure 1, n</xref>=3).</italic> </p><p>Please see the answer to the editor’s point #3. The number of animals is comparable to other electrophysiology studies of dopamine neurons using monkeys (Fiorillo, 2013, Science; Fiorillo et al., 2013a, J Neurosci; Fiorillo et al., 2013b, J Neurosci; Kobayashi and Schultz, 2014, Curr Biol; Matsumoto and Hikosaka, 2009, Nature) and mice (Cohen et al., 2012, Nature; Eshel et al., 2015, Nature; Tian and Uchida, 2015, Neuron). We also observed similar tendencies by using data from two instead of three animals (after leaving out one out of three animals). We added this data in Figure 1—figure supplement 1.</p><p><italic>3) How do the authors know that the mice can tell the difference between the low and high reward situations?</italic> </p><p>This is an important point. We observed that the level of anticipatory licking to reward cue was different between these two contexts (stronger with the reward CS predicting high probability of water). We have added this result in Figure 5—figure supplement 4B. Dopamine responses are also different between these two contexts. However, how reward contexts changed mouse conditions (consciously or unconsciously) is an important question to be resolved in future experiments.</p><p><italic>4) In the subsection “Integration of aversiveness and reward in dopamine neurons”, first paragraph: add the caveat that activation of meso-cortical dopamine neurons and dorsal raphe dopamine neurons can induce conditioned-place aversion (Lammel et al. 2014 &amp; Matthews et al. 2016).</italic> </p><p>Thank you for pointing out these references. We have added these references in Discussion(subsection “Integration of aversiveness and reward in dopamine neurons”, first paragraph).</p><p><italic>4) In the subsection “Diversity of dopamine neurons”: note also that Brischoux et al. (2009) reported that ventromedial dopamine neurons exhibited aversive activations.</italic> </p><p>Thank you. We have added this information in Discussion (subsection “Diversity of dopamine neurons”, first paragraph).</p><p><italic>5) I found some of the red/purple colour schemes difficult to tell apart. I would suggest some different colour schemes (particularly for <xref ref-type="fig" rid="fig1">Figure 1</xref>).</italic> </p><p>Thank you for pointing this out. We changed the blue and purple colors lighter in Figures.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p><italic>The manuscript has been improved but there are some remaining issues regarding its readability that need to be addressed before acceptance, as outlined below by Reviewer 2. After consultation between the reviewers, both thought that increased readability and explanation of why each experiment was performed would greatly enhance the clarity and impact of the study.</italic> </p><p>Thank you for the advice. We added one paragraph specifically devoted to explanations of each experiment and comparisons between task conditions at the beginning of the Results, together with <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="table" rid="tbl1">Table 1</xref>.</p><p><italic>Reviewer #2:</italic> </p><p><italic>I felt that the reviewers were responsive to our comments and that this study provides a valuable contribution to the discussion regarding the integration of rewarding and aversive cues in dopamine neurons.</italic> </p><p><italic>My only remaining comment is that I find the text in the Results and Discussion a bit difficult to follow. There are a number of experiments/analyses, and as it currently stands, the motivation for each experiment/analysis, as well as the relevant conclusions, is not always completely transparent. Therefore, the authors could consider editing the Results/Discussion for improved readability.</italic> </p><p>We added explanations of each experiment as mentioned above. We also rearranged Discussion and deleted some sentences for better readability.</p></body></sub-article></article>