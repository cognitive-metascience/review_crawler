<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">20787</article-id><article-id pub-id-type="doi">10.7554/eLife.20787</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Transformation of spatiotemporal dynamics in the macaque vestibular system from otolith afferents to cortex</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-66060"><name><surname>Laurens</surname><given-names>Jean</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9101-2802</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-66479"><name><surname>Liu</surname><given-names>Sheng</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-66485"><name><surname>Yu</surname><given-names>Xiong-Jie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-66527"><name><surname>Chan</surname><given-names>Raymond</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-66480"><name><surname>Dickman</surname><given-names>David</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-11799"><name><surname>DeAngelis</surname><given-names>Gregory C</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1635-1273</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-55289"><name><surname>Angelaki</surname><given-names>Dora E</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9650-8962</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Neuroscience</institution>, <institution>Baylor College of Medicine</institution>, <addr-line><named-content content-type="city">Houston</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">State Key Laboratory of Ophthalmology</institution>, <institution>Zhongshan Opthalmic Center, Sun Yat-sen University</institution>, <addr-line><named-content content-type="city">Guangzhou</named-content></addr-line>, <country>China</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Zhejiang University Interdisciplinary Institute of Neuroscience and Technology</institution>, <institution>Zhejiang University</institution>, <addr-line><named-content content-type="city">Hangzhou</named-content></addr-line>, <country>China</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Qiushi Academy for Advanced Studies</institution>, <institution>Zhejiang University</institution>, <addr-line><named-content content-type="city">Hangzhou</named-content></addr-line>, <country>China</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Deptartment of Brain and Cognitive Sciences</institution>, <institution>University of Rochester</institution>, <addr-line><named-content content-type="city">Rochester</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Raymond</surname><given-names>Jennifer L</given-names></name><aff id="aff6"><institution>Stanford University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>angelaki@bcm.edu</email></corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>11</day><month>01</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e20787</elocation-id><history><date date-type="received"><day>18</day><month>08</month><year>2016</year></date><date date-type="accepted"><day>22</day><month>12</month><year>2016</year></date></history><permissions><copyright-statement>© 2017, Laurens et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Laurens et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-20787-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.20787.001</object-id><p>Sensory signals undergo substantial recoding when neural activity is relayed from sensors through pre-thalamic and thalamic nuclei to cortex. To explore how temporal dynamics and directional tuning are sculpted in hierarchical vestibular circuits, we compared responses of macaque otolith afferents with neurons in the vestibular and cerebellar nuclei, as well as five cortical areas, to identical three-dimensional translational motion. We demonstrate a remarkable spatio-temporal transformation: otolith afferents carry spatially aligned cosine-tuned translational acceleration and jerk signals. In contrast, brainstem and cerebellar neurons exhibit non-linear, mixed selectivity for translational velocity, acceleration, jerk and position. Furthermore, these components often show dissimilar spatial tuning. Moderate further transformation of translation signals occurs in the cortex, such that similar spatio-temporal properties are found in multiple cortical areas. These results suggest that the first synapse represents a key processing element in vestibular pathways, robustly shaping how self-motion is represented in central vestibular circuits and cortical areas.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.001">http://dx.doi.org/10.7554/eLife.20787.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>vestibular</kwd><kwd>brainstem</kwd><kwd>cerebellum</kwd><kwd>cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd><italic>Rhesus Macaque</italic></kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>EY12814</award-id><principal-award-recipient><name><surname>Laurens</surname><given-names>Jean</given-names></name><name><surname>Liu</surname><given-names>Sheng</given-names></name><name><surname>Yu</surname><given-names>Xiong-Jie</given-names></name><name><surname>Dickman</surname><given-names>David</given-names></name><name><surname>Angelaki</surname><given-names>Dora E</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>DC04260</award-id><principal-award-recipient><name><surname>Laurens</surname><given-names>Jean</given-names></name><name><surname>Liu</surname><given-names>Sheng</given-names></name><name><surname>Yu</surname><given-names>Xiong-Jie</given-names></name><name><surname>Dickman</surname><given-names>David</given-names></name><name><surname>Angelaki</surname><given-names>Dora E</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>EY016178</award-id><principal-award-recipient><name><surname>DeAngelis</surname><given-names>Gregory C</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The spatial and dynamic properties of self-motion signals are acquired at the first stage of otolith signal transformation, which is in the brainstem and cerebellum, and conserved across brainstem, cerebellar and cortical areas.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many sensory systems have been studied along their hierarchy, from primary receptor cells to cortical neurons. Such systematic analyses provide a foundation for comprehending the neural computations that convert early sensory activity into higher level constructs that underlie perception, action, and other cognitive functions. For the vestibular system, however, such analysis has been largely limited to reflex generation in the brainstem and cerebellum. On the other hand, there are multiple cortical areas that respond to vestibular stimuli, typically together with other sensory and motor signals (<xref ref-type="bibr" rid="bib36">Grüsser et al., 1990</xref>; <xref ref-type="bibr" rid="bib17">Bremmer et al., 2002</xref>; <xref ref-type="bibr" rid="bib31">Fukushima et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Klam and Graf, 2006</xref>; <xref ref-type="bibr" rid="bib20">Chen et al., 2010</xref>, <xref ref-type="bibr" rid="bib21">2011a</xref>, <xref ref-type="bibr" rid="bib22">2011b</xref>, <xref ref-type="bibr" rid="bib23">2011c</xref>; <xref ref-type="bibr" rid="bib37">Gu et al., 2006</xref>, <xref ref-type="bibr" rid="bib39">2016</xref>). How do the spatial and temporal properties of neurons in cortical areas differ from those in subcortical vestibular hubs?</p><p>Primary otolith afferents are spatially cosine-tuned and their temporal dynamics are broadly thought to encode translational acceleration (<xref ref-type="bibr" rid="bib28">Fernández and Goldberg, 1976a</xref>, <xref ref-type="bibr" rid="bib29">1976b</xref>, <xref ref-type="bibr" rid="bib30">1976c</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib41">Jamali et al., 2009</xref>). Neural response properties in the vestibular nuclei (VN), which receive the bulk of vestibular afferent projections outside the cerebellum (<xref ref-type="bibr" rid="bib14">Barmack, 2003</xref>; <xref ref-type="bibr" rid="bib59">Newlands and Perachio, 2003</xref>; <xref ref-type="bibr" rid="bib12">Angelaki and Cullen, 2008</xref>), are different. It has been proposed that spatio-temporal convergence of otolith afferents onto central VN cells results in complex, non-cosine-tuned properties, where spatial and temporal coding might not always be multiplicatively separable (<xref ref-type="bibr" rid="bib2">Angelaki, 1991</xref>, <xref ref-type="bibr" rid="bib4">1992b</xref>; <xref ref-type="bibr" rid="bib6">Angelaki et al., 1992</xref>; <xref ref-type="bibr" rid="bib7">Angelaki, 1993</xref>; <xref ref-type="bibr" rid="bib8">Angelaki et al., 1993</xref>; <xref ref-type="bibr" rid="bib19">Bush et al., 1993</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib27">Dickman and Angelaki, 2002</xref>; <xref ref-type="bibr" rid="bib24">Chen-Huang and Peterson, 2006</xref>, <xref ref-type="bibr" rid="bib25">2010</xref>). Some studies have supported this prediction in the vestibular brainstem (<xref ref-type="bibr" rid="bib8">Angelaki et al., 1993</xref>; <xref ref-type="bibr" rid="bib19">Bush et al., 1993</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib24">Chen-Huang and Peterson, 2006</xref>, <xref ref-type="bibr" rid="bib25">2010</xref>), but direct comparisons with cortical responses (e.g., <xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>) have never been made.</p><p>Here, we use data obtained from transient translational displacements along multiple directions in three-dimensional (3D) space to compare the spatio-temporal response properties of neurons in the vestibular and rostral medial cerebellar nuclei (VN/CN; <xref ref-type="bibr" rid="bib52">Liu et al., 2013</xref>) with responses in multiple cortical areas, including the parietoinsular vestibular cortex (PIVC; <xref ref-type="bibr" rid="bib20">Chen et al., 2010</xref>), visual posterior sylvian area (VPS, a visual/vestibular convergent area just posterior to PIVC; <xref ref-type="bibr" rid="bib22">Chen et al., 2011b</xref>), ventral intraparietal area (VIP; <xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>), dorsal medial superior temporal area (MSTd; <xref ref-type="bibr" rid="bib37">Gu et al., 2006</xref>; <xref ref-type="bibr" rid="bib67">Takahashi et al., 2007</xref>; <xref ref-type="bibr" rid="bib38">Gu et al., 2010</xref>) and the frontal eye fields (FEF; <xref ref-type="bibr" rid="bib39">Gu et al., 2016</xref>). In addition, we have also recorded from primary otolith afferent fibers from the vestibular subdivision of the eighth nerve in response to identical stimuli (<xref ref-type="bibr" rid="bib74">Yu et al., 2015</xref>). We report a remarkable spatio-temporal transformation between otolith afferents and VN/CN cells, and this transformation determines the main response properties carried forward to cortical neurons.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Data set, model composition and example model fits</title><p>The neural data set used to fit 3D spatio-temporal models consisted of the average temporal response profile (PSTH) of each neuron for 26 directions of translation corresponding to all possible combinations of azimuth and elevation angles in increments of 45° (<xref ref-type="bibr" rid="bib37">Gu et al., 2006</xref>). The temporal waveform of the translational stimulus followed a Gaussian velocity profile (<xref ref-type="fig" rid="fig1">Figure 1</xref>, top), with corresponding biphasic acceleration (<xref ref-type="fig" rid="fig1">Figure 1</xref>, middle) and triphasic jerk (derivative of acceleration; <xref ref-type="fig" rid="fig1">Figure 1</xref>, bottom) components. We considered only cells with significant spatial and temporal response modulation, as detailed by <xref ref-type="bibr" rid="bib21">Chen et al. (2011a)</xref> (see also Materials and methods). This inclusion criterion yielded a total of 27 otolith afferents (OA), 49 VN cells, 61 CN cells, 115 PIVC cells (from <xref ref-type="bibr" rid="bib20">Chen et al., 2010</xref>), 66 VPS cells (<xref ref-type="bibr" rid="bib22">Chen et al., 2011b</xref>), 139 MSTd cells (from <xref ref-type="bibr" rid="bib37">Gu et al., 2006</xref>), 62 VIP cells (from <xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>) and 57 FEF cells (from <xref ref-type="bibr" rid="bib39">Gu et al., 2016</xref>) (see <xref ref-type="table" rid="tbl1">Table 1</xref>).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.002</object-id><label>Figure 1.</label><caption><title>Schematic of model with velocity, acceleration and jerk components.</title><p>The fitted function, <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> is the sum of three components, each consisting of a weight <inline-formula><mml:math id="inf2"><mml:mrow><mml:mo> </mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:math></inline-formula>, a 3D spatial tuning function (<inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula> represented on a sphere) and a temporal response profile (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), scaled and multiplied together. Spatial tuning functions illustrate that preferred directions need not be identical for each temporal component.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.002">http://dx.doi.org/10.7554/eLife.20787.002</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig1-v1"/></fig><table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.003</object-id><label>Table 1.</label><caption><p>Overview of the data. The table provides a list of the brain regions included in the current analyses, the number (m) of monkeys used in each area (note that neurons were recorded in more than one area in some monkeys), the number (n) of neurons analyzed from each area and references to previous publications where technical details are provided. Neurons were either reported here for the first time (<italic>new data</italic>) or re-analyzed from previous publications (references in last column).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.003">http://dx.doi.org/10.7554/eLife.20787.003</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2"><p>Area name and abbreviation</p></th><th><p>m</p> </th><th><p>n</p> </th><th><p>Methodological details and original publication</p></th></tr></thead><tbody><tr><td><p>Otolith Afferent fibers, eighth cranial nerve</p></td><td><p>OA</p></td><td><p>2</p></td><td><p>27</p></td><td><p>New data/<xref ref-type="bibr" rid="bib74">Yu et al. (2015)</xref></p> </td></tr><tr><td><p>Vestibular Nuclei</p></td><td><p>VN</p></td><td><p>4</p></td><td><p>49</p></td><td><p>New data/<xref ref-type="bibr" rid="bib52">Liu et al. (2013)</xref></p> </td></tr><tr><td><p>Rostral medial Cerebellar Nuclei</p></td><td><p>CN</p></td><td><p>5</p></td><td><p>61</p></td><td><p>New data/<xref ref-type="bibr" rid="bib52">Liu et al. (2013)</xref></p> </td></tr><tr><td><p>Parietoinsular Vestibular Cortex</p></td><td><p>PIVC</p></td><td><p>2</p></td><td><p>115</p></td><td><p><xref ref-type="bibr" rid="bib20">Chen et al. (2010)</xref></p> </td></tr><tr><td><p>Visual Posterior Sylvian area</p></td><td><p>VPS</p></td><td><p>3</p></td><td><p>69</p></td><td><p><xref ref-type="bibr" rid="bib21">Chen et al. (2011a)</xref></p> </td></tr><tr><td><p>Dorsal Medial Superior Temporal area</p></td><td><p>MSTd</p></td><td><p>3</p></td><td><p>139</p></td><td><p><xref ref-type="bibr" rid="bib37">Gu et al. (2006</xref>, <xref ref-type="bibr" rid="bib38">2010</xref>); <xref ref-type="bibr" rid="bib67">Takahashi et al. (2007)</xref></p> </td></tr><tr><td><p>Ventral Intraparietal area</p></td><td><p>VIP</p></td><td><p>3</p></td><td><p>62</p></td><td><p><xref ref-type="bibr" rid="bib21">Chen et al. (2011a)</xref></p> </td></tr><tr><td><p>Frontal Eye Field</p></td><td><p>FEF</p></td><td><p>3</p></td><td><p>57</p></td><td><p><xref ref-type="bibr" rid="bib39">Gu et al. (2016)</xref></p> </td></tr><tr><td colspan="2"><p>Total</p></td><td><p>19</p></td><td><p>579</p></td><td/></tr></tbody></table></table-wrap></p><p>Multiple models of varying complexity were fit to the PSTHs of each neuron (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In its most general form, the standard model consisted of the sum of three response components, having temporal dynamics associated with velocity, acceleration and jerk. For each component, the temporal profile of the stimulus (<inline-formula><mml:math id="inf5"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) was multiplied by a 3D spatial tuning function (<inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> cosine tuning with an offset; see Materials and methods) and a weight (<inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf12"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>). This required four fitted parameters for each component. The sum of these three components was added to the resting discharge (<inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>), and a temporal delay term (<inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) was introduced (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Thus, the maximum number of free parameters (‘VAJ’ model), was 14. For an easy comparison of the relative importance of the three temporal components, we also present the normalized weights (<inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), which are equal to the weights divided by <inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>+<inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>+<inline-formula><mml:math id="inf20"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>Simpler models, consisting of either single or double component contributions were also fit to the responses of each cell, as described above, and included Acceleration-only (‘A’), Velocity-only (‘V’), Jerk-only (‘J’), Velocity+Acceleration (‘VA’), Velocity+Jerk (‘VJ’) and Acceleration+Jerk (‘AJ’) models. Because different models have different numbers of free parameters (6 parameters for the single-component models and 10 for the double-component models), the relative quality of the different model fits was assessed using the Bayesian Information Criterion (BIC; <xref ref-type="bibr" rid="bib63">Schwarz, 1978</xref>).</p><p><xref ref-type="fig" rid="fig2">Figure 2</xref> illustrates example fits of the VAJ model for an OA (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The biphasic response PSTHs resembled the stimulus acceleration profile, with its amplitude being spatially modulated. Peak responses, with opposite signs, were observed during upward and downward motion. Furthermore, the cell responded weakly to stimuli with 0° elevation regardless of azimuth, corresponding to orthogonal directions relative to upward/downward motion. This response pattern is characteristic of cosine spatial tuning, where the response is modulated as a function of the cosine between the stimulus direction and the cell’s preferred direction.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.004</object-id><label>Figure 2.</label><caption><title>Spatio-temporal tuning of an example otolith afferent that was best fit by the AJ model.</title><p>(<bold>A</bold>) PSTHs (gray) and model fits (cyan) for each of the 26 stimulus directions, defined by the corresponding (azimuth, elevation) angles. The vertical lines at t = 1s represent the timing of peak stimulus velocity. (<bold>B</bold>) Component weights for the fit of the VAJ model (left axis: raw weight in spikes/s, right axis: normalized weights, such that their sum = 1). (<bold>C</bold>) Partial R<sup>2</sup> of the three components, representing their contribution to the cell’s firing; R<sup>2</sup><sub>VAJ</sub>: goodness of fit of the full VAJ model; Sep.I: separability index, indicating how well the cell can be modeled using the same spatial tuning function for all three temporal response components (see Materials and methods). (<bold>D</bold>–<bold>F</bold>) Color intensity plots of the spatial tuning of velocity, acceleration and jerk components, respectively. For illustrative purposes, the sensitivities to velocity, acceleration and jerk, are multiplied by the peak amplitude of the respective temporal profiles such that the three spatial tuning functions are expressed in spikes/s. Therefore, (<bold>D</bold>) represents the contribution of the velocity component at the time of peak velocity (plus the delay <inline-formula><mml:math id="inf21"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>); (<bold>E</bold>) represents the contribution of acceleration at the time of peak acceleration (plus <inline-formula><mml:math id="inf22"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>); (<bold>F</bold>) represents the contribution of jerk at the time of peak jerk (plus <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>). The crosses in (<bold>D</bold>–<bold>F</bold>) indicate the preferred direction of each component. Note that a positive sensitivity to jerk (for upward jerk in this cell) corresponds to a negative response at t = 0 (see <bold>G</bold>) since jerk is negative at that time. (<bold>G</bold>) Offset (<inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) versus cosine tuning amplitude (<inline-formula><mml:math id="inf25"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>) of the three temporal components. (<bold>H</bold>–<bold>J</bold>) Temporal profiles of the three components [velocity (green), acceleration (red) and jerk (blue) scaled by the respective component weight] for the stimulus directions indicated in <bold>A</bold>. The x marks illustrate the times for which the spatial tuning in <bold>D</bold>-<bold>F</bold> has been plotted.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.004">http://dx.doi.org/10.7554/eLife.20787.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig2-v1"/></fig></p><p>For the example OA, the acceleration component had a large weight (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, red) and partial R<sup>2</sup> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, red); the jerk component had a lower, but still sizable, weight and partial R<sup>2</sup> (blue), whereas the velocity component was negligible (<xref ref-type="fig" rid="fig2">Figure 2B–D</xref>). Accordingly, the AJ model was selected as best describing this cell’s response based on BIC analysis (even though <xref ref-type="fig" rid="fig2">Figure 2</xref> illustrates the fits and parameters of the VAJ model). Note that the spatial tuning of acceleration and jerk were very similar (color maps in <xref ref-type="fig" rid="fig2">Figure 2E,F</xref>), indicating that spatial and temporal properties are separable (i.e. one does not depend on the other). This property is reflected in the cell’s separability index (Sep.I, <xref ref-type="fig" rid="fig2">Figure 2C</xref>, black; see Materials and methods) of 1. <xref ref-type="fig" rid="fig2">Figure 2G</xref> further summarizes the spatial tuning properties of all three components by plotting the their response offset against the amplitude of cosine tuning, each multiplied by the weight of the respective components. Since the acceleration and jerk responses are purely cosine-tuned, these components have zero offset while both the response offset and the cosine tuning of the velocity component are close to zero. The fitted temporal response components at three example stimulus directions are shown in <xref ref-type="fig" rid="fig2">Figure 2G,H,I</xref> (marked accordingly in the PSTHs of <xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><p>In contrast to otolith afferents, many central neurons exhibited distinct spatial tuning for the different temporal response components, as illustrated by data from an example VN neuron (<xref ref-type="fig" rid="fig3">Figure 3A–I</xref>). Here, all dynamic components contributed substantially to the cell’s response (<xref ref-type="fig" rid="fig3">Figure 3B,C</xref>), and the VAJ model had the best BIC. Unlike otolith afferents, this VN cell had a strong velocity modulation, which was positive along the preferred direction (close to downward; <xref ref-type="fig" rid="fig3">Figure 3D and H</xref>, green). However, the velocity component also exhibited a small positive (rather than negative) response during horizontal and upward motion directions. Thus, the velocity response component was positive in all directions (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), which was modeled with a response offset greater than the amplitude of the cosine tuning (<xref ref-type="fig" rid="fig3">Figure 3G</xref>, green). The acceleration response was roughly cosine tuned, alternating from a positive response in downward movement directions to a negative response for upward movement directions (<xref ref-type="fig" rid="fig3">Figure 3E</xref>; see also <xref ref-type="fig" rid="fig3">Figure 3H–J</xref>, red); accordingly, its offset was close to zero (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). Finally, the jerk response tuning was broad and mostly positive (<xref ref-type="fig" rid="fig3">Figure 3F</xref>; see also <xref ref-type="fig" rid="fig3">Figure 3G–I</xref>, blue).<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.005</object-id><label>Figure 3.</label><caption><title>Spatio-temporal tuning and VAJ model fit for an example VN cell.</title><p>Format as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Note that the neuron responds to translation in all directions (<bold>A</bold>), with different temporal response profiles that result from velocity, acceleration and jerk components having different spatial tuning (<bold>D</bold>–<bold>F</bold>), thus resulting in a relatively small separability index (<bold>C</bold>). Note also that the cell is characterized by nearly uniform tuning to velocity and jerk (<bold>D</bold>,<bold>F</bold>), which is modeled as a high offset combined with a relatively small cosine tuning amplitude (<bold>G</bold>, green and blue). Additional example cells are presented in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s6">6</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.005">http://dx.doi.org/10.7554/eLife.20787.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.006</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Spatio-temporal tuning of an example CN cell.</title><p>(<bold>A</bold>–<bold>J</bold>) Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>. The cell's firing increases during motion in all directions due to its nearly uniform tuning to velocity and jerk (<bold>D</bold>,<bold>F</bold>), which is modeled as a low cosine tuning amplitude and a high offset (<bold>G</bold>, green and blue). Note that the cell’s PSTH varies as a function of motion direction due to the cell's cosine tuning to acceleration (<bold>E</bold>, low offset in <bold>G</bold>, red)– despite very broad non-linear tuning to velocity and jerk. This pattern represents the most frequently encountered type of central neuron. Also note that the separability index was high, despite the strongly non-cosine tuning of velocity and jerk. This is because the spatial tuning of velocity and jerk is often very broad, and the separability index is a measure of the tuning similarity of the different temporal components. Thus, a separability index close to one does not necessarily imply cosine (afferent-like) spatial tuning.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.006">http://dx.doi.org/10.7554/eLife.20787.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp1-v1"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.007</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Spatio-temporal tuning of an example PIVC cell, exhibiting a strong, cosine-like response to jerk.</title><p>Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.007">http://dx.doi.org/10.7554/eLife.20787.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp2-v1"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.008</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Spatio-temporal tuning of an example VPS cell, whose temporal response is dominated by velocity, exhibiting a nearly uniform response to motion in all directions (<bold>D</bold>; high offset and low cosine tuning amplitude in <bold>G</bold>, green) and a high separability index (=1), despite strongly non-linear responsiveness.</title><p>Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.008">http://dx.doi.org/10.7554/eLife.20787.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp3-v1"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.009</object-id><label>Figure 3—figure supplement 4.</label><caption><title>Spatio-temporal tuning of an example MSTd cell, whose temporal response is dominated by velocity.</title><p>This cell exhibits both cosine tuning and offset response to velocity (G, green), resulting in relatively narrow velocity tuning characterized by a strong positive response to downward motion but little response to motion in other directions. Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.009">http://dx.doi.org/10.7554/eLife.20787.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp4-v1"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.010</object-id><label>Figure 3—figure supplement 5.</label><caption><title>Spatio-temporal tuning of an example VIP cell, exhibiting a decrease in firing in response to motion in all directions due to a uniform negative tuning to velocity and jerk.</title><p>Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.010">http://dx.doi.org/10.7554/eLife.20787.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp5-v1"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.011</object-id><label>Figure 3—figure supplement 6.</label><caption><title>Spatio-temporal tuning of an example FEF cell, exhibiting a narrowly tuned response to upward directions, consisting of mostly velocity and acceleration components.</title><p>The response is fit with cosine tuning and a small offset (note that the fitted function always includes a rectification, such that the cell is silent during downward motion). Format as in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.011">http://dx.doi.org/10.7554/eLife.20787.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig3-figsupp6-v1"/></fig></fig-group></p><p>Since the acceleration, velocity and jerk components had distinct spatial tuning, this VN neuron’s separability index (0.73) was much lower than that for OAs, and the interplay of these components created strikingly distinct (i.e. mono-, bi- and tri-phasic) PSTH shapes for different stimulus directions (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). For example, a combination of positive velocity and acceleration responses (<xref ref-type="fig" rid="fig3">Figure 3G</xref>) created a largely monophasic profile during downward motion (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, bottom). In contrast, the PSTH was biphasic during upward motion, which was essentially driven by acceleration and jerk (<xref ref-type="fig" rid="fig3">Figure 3I</xref>). Note that the jerk temporal modulation was most obvious at horizontal stimulus directions, when the cosine-tuned acceleration was minimal (<xref ref-type="fig" rid="fig3">Figure 3H</xref>). The fit of the VAJ model captures a large portion of this diversity in the shapes of PSTHs across stimulus directions.</p><p>The preferred directions (PDs) for velocity and acceleration were 28° apart (difference in 3D, with peaks at [azimuth, elevation] = [333°, 49°], and [3°, 74°], respectively; <xref ref-type="fig" rid="fig3">Figure 3D,E</xref>, ‘+’ in color contour plots). However, the jerk component had a nearly opposite preferred direction (at [azimuth, elevation] = [189°, −61°]; <xref ref-type="fig" rid="fig3">Figure 3F</xref>) and the difference with the preferred direction of the acceleration component was 167°. Note, however, that, given the strongly non-cosine-tuned properties of velocity and jerk (as captured by the non-zero offset parameters), PD was inadequate to fully characterize the spatial properties of most central cells.</p><p>Additional examples of cell responses and model fits (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s6">6</xref> illustrate a diversity of non-linear response types encountered in central neurons. Remarkably, some neurons had either purely positive responses in all directions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref> and <xref ref-type="fig" rid="fig3s2">3</xref>) or purely suppressive responses in all directions (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>), whereas other cells responded only in a narrow range of motion directions (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplements 4</xref> and <xref ref-type="fig" rid="fig3s6">6</xref>). The VAJ model captured this variety of responses reasonably well, and therefore, an analysis of its parameters allowed us to draw quantitative conclusions from comparisons of cell tuning across neuronal populations.</p></sec><sec id="s2-2"><title>Summary of best-fitting models</title><p>Model fits were generally good (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), with median R<sup>2</sup> values of 0.78 for OA (CI=[0.67–0.88]), 0.65 for VN (CI=[0.59–0.73]), 0.64 for CN (CI=[0.57–0.68]), 0.71 for PIVC (CI=[0.67–0.75]), 0.67 for VPS (CI=[0.62–0.71]), 0.59 for MSTd (CI=[0.55–0.64]), 0.66 for VIP (CI=[0.59–0.66]) and 0.59 for FEF (CI=[0.52–0.66]). The percentage of neurons that were best fit by each of the 7 (V, A, J, VA, VJ, AJ and VAJ) models is shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. Remarkably, there was a sharp contrast between OAs and central cells. Forty-eight percent of OAs were best fit by the A model and 33% by the AJ model, whereas only 19% were best fit by the VAJ model. This indicates that acceleration responses are ubiquitous in OAs, whereas half of them respond to jerk and only a few to velocity. In contrast, 6% of central cells were best fit by the V model, 20% and 10% by the VA and VJ model, and 60% by the VAJ model, indicating that velocity responses were very common in central neurons. For comparison with previous work (<xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>), we also tested a more complex model in which the non-linear function assumed the form of an exponential. We found that this model performed only marginally better (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>); thus, we did not consider it further in this study.<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.012</object-id><label>Figure 4.</label><caption><title>Summary of model fits.</title><p>(<bold>A</bold>) Distribution of R<sup>2</sup><sub>VAJ</sub> values for each brain area. The boxes represent the median (center of the notch) and lower and upper quartiles of the population. Two medians are different at 5% level if the notches do not overlap. Individual data points are represented by circles. (<bold>B</bold>) Percentage of best model fits based on BIC. (<bold>C</bold>–<bold>E</bold>) Partial correlation coefficients of each of the three components, which reflect how much variance is accounted for by adding that component to the joint model of the other two components. Comparisons with model fits using an exponential spatial non-linearity function are shown in in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.012">http://dx.doi.org/10.7554/eLife.20787.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.013</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Fitting performance using an exponential spatial non-linearity function.</title><p>We fitted neuronal responses with an extension of the VAJ model in which the spatial non-linearity function is an exponential <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>x</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula>, as in <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref>. This function was normalized between −1 and 1, which reduced it to two free parameters, and therefore, the extended VAJ model had 17 free parameters. Fit quality was measured by R<sup>2</sup><sub>VAJ</sub> (here referred to as R<sup>2</sup><sub>exponential</sub> for the extended VAJ model and R<sup>2</sup><sub>affine</sub> for the model used in the rest of the study, where <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an affine function). (<bold>A</bold>) As expected, the extended VAJ model produced better fits (i.e., R<sup>2</sup><sub>exponential</sub> &gt; R<sup>2</sup><sub>affine</sub>). However, the performance improvement was modest, as indicated by the ratio R<sup>2</sup><sub>affine</sub> / R<sup>2</sup><sub>exponential</sub>. This ratio was close to one for the majority of neurons; its median value was 0.97, and it was greater than 0.9 for 91% of the cells. (<bold>B</bold>) For a few cells (n = 6, 1%), the ratio was less than 0.8. However, R<sup>2</sup><sub>exponential</sub> was also low (&lt;0.6) for these cells. This indicates that these cells were poorly fit (with typically low and noisy responses), such that the extended model was prone to overfitting. We conclude that the extended model provides little quantitative benefit compared to its increased complexity; thus, we adopted the simpler affine model in this study.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.013">http://dx.doi.org/10.7554/eLife.20787.013</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig4-figsupp1-v1"/></fig></fig-group></p><p>The pattern of results seen in <xref ref-type="fig" rid="fig4">Figure 4B</xref> was also reflected in the partial R<sup>2</sup> values (squared partial correlation coefficients, <xref ref-type="fig" rid="fig4">Figure 4C–E</xref>), which indicate how much each model component contributed to neural responses. In OAs, acceleration had high partial R<sup>2</sup> values (median: 0.51, CI=[0.36–0.61]), while the jerk and velocity contributions were small (median partial R<sup>2</sup>: 0.07, CI=[0.02–0.13] and 0.03, CI=[0.02–0.06], respectively). In central neurons, the velocity contribution was greatest (median partial R<sup>2</sup>: 0.38, CI=[0.35–0.4]), followed by acceleration and jerk (median partial R<sup>2 </sup>: 0.23, CI=[0.21–0.25] and 0.14, CI=[0.13–0.15], respectively).</p><p>Next, we will summarize in detail the model fits of otolith afferents, followed by a quantitative description of model parameters in other brain areas.</p></sec><sec id="s2-3"><title>Model fits to otolith afferent responses</title><p>As shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, about half (n = 13) of OAs were best fit by the ‘A’ model (<xref ref-type="fig" rid="fig5">Figure 5</xref>, filled symbols), whereas the remainder (n = 14) were best fit by models of higher complexity (‘AJ’ and ‘VAJ’, open symbols in <xref ref-type="fig" rid="fig5">Figure 5</xref>). We found that these two groups had distinct firing properties. In particular ‘A’ afferents had a lower normalized coefficient of variation CV* (<xref ref-type="bibr" rid="bib34">Goldberg et al., 1984</xref>) than ‘AJ/VAJ’ afferents (median 0.026, CI=[0.024–0.033] versus 0.06, CI=[0.04–0.08], Wilcoxon rank sum test, p=10<sup>−3</sup>; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). We also found that the higher the CV<sup>*</sup> the higher the weights for velocity, acceleration and jerk (<inline-formula><mml:math id="inf28"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mtext>green</mml:mtext><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>W</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>-red, <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>J</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>-blue; <xref ref-type="fig" rid="fig5">Figure 5B</xref>, Spearman’s rank correlation p&lt;10<sup>−2</sup> for all three variables), as response gain increases with CV*. Importantly, the relative contributions of acceleration and jerk, as indicated by the normalized weights w<sub>A</sub> and w<sub>J</sub>, (<xref ref-type="fig" rid="fig5">Figure 5C</xref>) were oppositely correlated with CV<sup>*</sup> (Spearman’s rank correlation, p&lt;10<sup>−3</sup> for both). Specifically, the normalized weight on acceleration declined with CV* while the normalized weight on jerk increased with CV*. In contrast, the contribution of velocity remained minimal (median = 0.06, CI=[0.05–0.08]) and did not correlate with CV<sup>*</sup> (Spearman’s rank correlation, p=0.75; <xref ref-type="fig" rid="fig5">Figure 5C</xref>, green).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.014</object-id><label>Figure 5.</label><caption><title>Summary of model fits for otolith afferents.</title><p>(<bold>A</bold>) Difference in CV* between afferents that respond to acceleration only (‘A’) or acceleration, jerk and optionally velocity (‘AJ’ and ‘VAJ’). (<bold>B</bold>–<bold>C</bold>) Raw and normalized weights for velocity, acceleration and jerk are plotted as a function of CV*. Filled symbols, ‘A’ afferents; open symbols: ‘AJ’ and ‘VAJ’ afferents. Note that weights for each OA were taken from the VAJ model such that all cells could be included in these plots. Solid lines: statistically significant (p&lt;10<sup>−2</sup>) type I regression lines. Broken lines: non-significant (p&gt;0.05) regression lines. (<bold>D</bold>) The absolute difference between the 3D preferred directions of component pairs (<bold>A</bold>–<bold>J</bold>, <bold>V</bold>–<bold>A</bold>, <bold>V</bold>–<bold>J</bold>) plotted versus CV*. Here, angular differences are included only when both response components were significant for each cell. Symbols and lines as in <bold>B</bold>,<bold>C</bold>. Because A and J components were nearly aligned (black symbols), V-A (red) and V-J (blue) angular differences were similar for each cell.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.014">http://dx.doi.org/10.7554/eLife.20787.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig5-v1"/></fig></p><p>The preferred directions of the acceleration and jerk components were always aligned for OAs, as illustrated by the clustering of the A-J preferred direction differences (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, black) close to 0° (median = 7°, CI=[4-9]). Thus, the two temporal components that dominated otolith afferent responses were spatially aligned, which is consistent with separable spatio-temporal tuning. Although velocity weights were overall small, the preferred direction of the velocity component relative to acceleration or jerk components (V-A or V-J) showed a significant dependence on CV* (both r = 0.7, p&lt;0.01, Spearman's rank correlation; <xref ref-type="fig" rid="fig5">Figure 5D</xref>). For afferents with the most regular firing rates, the small velocity components tended to be orthogonal to acceleration and jerk components (V-A and V-J preferred direction differences ~90°). In contrast, the small velocity components of irregular otolith afferent responses tended to have direction preferences opposite to those of acceleration and jerk components (V-A and V-J relative angle differences ~180°; <xref ref-type="fig" rid="fig5">Figure 5D</xref>). The presence of this velocity component in OAs has not been identified before using sinusoidal stimuli (see Discussion).</p></sec><sec id="s2-4"><title>Model fits to central cell responses and comparison across areas</title><p>Identical models were fit to the responses of central neurons, with results summarized in <xref ref-type="fig" rid="fig6">Figures 6</xref>–<xref ref-type="fig" rid="fig9">9</xref>. We found large differences between the spatio-temporal properties of all central neurons, as compared to otolith afferents. The fitted velocity, acceleration and jerk component weights across areas are illustrated as <italic>ternary plots</italic>, which graphically depict the ratios of three variables that sum to a constant (in this case, the normalized weights, <inline-formula><mml:math id="inf30"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>+<inline-formula><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>+<inline-formula><mml:math id="inf32"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) as positions in an equilateral triangle (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The value of each weight is 1 in one corner of the triangle and each weight decreases with increasing distance from this corner.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.015</object-id><label>Figure 6.</label><caption><title>Dynamic components weights.</title><p>(<bold>A</bold>–<bold>C</bold>) Ternary plots summarizing normalized weights for the acceleration, velocity and jerk components of VAJ model fits. Each data point represents the normalized velocity, acceleration and jerk weights for a single cell, color coded by brain area. (<bold>D</bold>–<bold>F</bold>) Cumulative distributions of normalized velocity (<bold>D</bold>), acceleration (<bold>E</bold>) and jerk (<bold>F</bold>) weights. Note the similarity in normalized velocity and acceleration weights across all central brain areas.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.015">http://dx.doi.org/10.7554/eLife.20787.015</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig6-v1"/></fig><fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.016</object-id><label>Figure 7.</label><caption><title>Comparison of preferred directions across dynamic components.</title><p>(<bold>A</bold>) Distribution of the separability index across brain areas. (<bold>B</bold>–<bold>D</bold>) Summary of the angular difference between preferred directions of component pairs. The distribution of angles across the population is color-coded (red/yellow: aligned; green/cyan: opposite; grey: orthogonal). The ‘sum’ bar represents the distribution across all central brain areas (VN to FEF). For each comparison, only cells for which both components had significant spatial tuning have been considered (i.e. single-component best fits have not been included at all, whereas 2-component best fits have only been included in only one plot). The distribution H<sub>1</sub> represents the expected distribution if directions are distributed randomly on a sphere, in which case orthogonal pairs (e.g. from 85° to 95°) are more likely to occur than aligned or opposite pairs (e.g. from 0° to 10°). The distribution H<sub>2</sub> assumes only ‘aligned’ responses (like the A-J components of OAs). Bold/italic labels indicate distributions that are/are not significantly different from H<sub>1</sub> (top) (Kolomogorov-Smirnov Test; p-values indicated in <xref ref-type="table" rid="tbl3">Table 3</xref>). Distributions of the preferred direction of each dynamic component are shown in <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.016">http://dx.doi.org/10.7554/eLife.20787.016</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig7-v1"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.017</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Distributions of the PD of each dynamic component.</title><p>The PDs of all cells with significant tuning are represented in spherical coordinates (azimuth <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, elevation <inline-formula><mml:math id="inf34"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) that are projected on a plane using an equal-area Mollweide projection (a uniform distribution on a sphere corresponds to a uniform distribution on the Mollweide plane). The uniformity of PDs was tested by computing a 3D Rayleigh vector R (equal to the average of <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) across neurons, for each region and each component. The observed R values were compared to a distribution P(R|H<sub>0</sub>) (under the hypothesis H<sub>0</sub> that PD are distributed uniformly) that was estimated by drawing n directions uniformly (where n is the number of neurons), computing the corresponding R values, and repeating the operation 1000 times. We found that no component was significantly different from uniform (at p=0.01, corresponding to p=0.2 with Bonferroni correction).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.017">http://dx.doi.org/10.7554/eLife.20787.017</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig7-figsupp1-v1"/></fig></fig-group><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.018</object-id><label>Figure 8.</label><caption><title>Summary of response amplitude and baseline firing rate parameters.</title><p>Cumulative distributions of (<bold>A</bold>) peak-to-trough response amplitude (maximum across all directions), and (<bold>B</bold>) baseline firing rate (<inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>). OA: otolith afferents (brown); VN: vestibular nuclei (yellow); CN: cerebellar nuclei (orange); PIVC: parietoinsular vestibular cortex (red); VPS: visual posterior sylvian (blue); MSTd: dorsal medial superior temporal area (cyan); VIP: central intraparietal area (green). FEF: frontal eye fields (black).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.018">http://dx.doi.org/10.7554/eLife.20787.018</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig8-v1"/></fig><fig-group><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.019</object-id><label>Figure 9.</label><caption><title>Summary of spatial tuning non-linearity for (<bold>A</bold>) velocity, (<bold>B</bold>) acceleration and (<bold>C</bold>) jerk.</title><p>The spatial tuning curves <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> are modeled by adding an offset (<inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, respectively) to a cosine-tuned response <inline-formula><mml:math id="inf39"><mml:mi>x</mml:mi></mml:math></inline-formula>, i.e., <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>)</mml:mo><mml:mo>.</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> (the curves <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> follow similar forms). The relative amplitudes of the response to velocity, acceleration and jerk depend on the weights <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, the weighted cosine-tuned response components (abscissa) are: <inline-formula><mml:math id="inf43"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf44"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and the weighted offset response components are: <inline-formula><mml:math id="inf45"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (ordinate). Purely cosine-tuned cells have zero offset (<inline-formula><mml:math id="inf46"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf47"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), while cells with positive or negative omnidirectional responses have a large offset and little modulation (<inline-formula><mml:math id="inf48"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf49"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for positive responses, <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for negative responses). Distributions of the offset parameters are shown in <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.019">http://dx.doi.org/10.7554/eLife.20787.019</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig9-v1"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.20787.020</object-id><label>Figure 9—figure supplement 1.</label><caption><title>Cumulative distributions of offset parameters for velocity (<bold>A</bold>), acceleration (<bold>B</bold>) and jerk (<bold>C</bold>) components across all brain areas.</title><p>Note the larger offset values for velocity and jerk, compared to acceleration.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.020">http://dx.doi.org/10.7554/eLife.20787.020</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig9-figsupp1-v1"/></fig></fig-group></p><p>As described above, OAs (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) respond predominantly to acceleration and display varying degree of sensitivity to jerk, while their response to velocity is minimal. Accordingly, they cluster between the A and J corners. The ternary plots of VN and CN neurons (yellow and orange, respectively) show a strikingly different pattern. Qualitatively, it is readily apparent that VN/CN cells carry substantially less acceleration signals, and much more velocity signals than otolith afferents. Quantitatively (see <xref ref-type="table" rid="tbl2">Table 2</xref>), the normalized acceleration weight (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), which is high for otolith afferents, becomes significantly smaller for VN and CN neurons (p&lt;10<sup>−8</sup>, Wilcoxon rank sum test). In parallel, the velocity weights (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) are significantly greater for VN and CN neurons, as compared to otolith afferents (p&lt;10<sup>−14</sup>, Wilcoxon rank sum test). There is little difference between jerk weights (<xref ref-type="fig" rid="fig6">Figure 6F</xref>) of VN/CN neurons and otolith afferents (p=0.03, Wilcoxon’s rank sum test). Remarkably, despite dramatic differences in the relative weighting of acceleration and velocity signals between central cells and otolith afferents, VN and CN have similar properties overall, and there is no significant difference between weight values for the two areas (Wilcoxon’s rank sum test, <inline-formula><mml:math id="inf52"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p=0.75; <inline-formula><mml:math id="inf53"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>; p=0.47; <inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p=0.28).<table-wrap id="tbl2" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.021</object-id><label>Table 2.</label><caption><p>Model parameters based on area (median and CI).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.021">http://dx.doi.org/10.7554/eLife.20787.021</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom"/><th valign="bottom"/><th valign="bottom"><p><bold>OA</bold></p> </th><th valign="bottom"><p><bold>VN</bold></p> </th><th valign="bottom"><p><bold>CN</bold></p> </th><th valign="bottom"><p><bold>PIVC</bold></p> </th><th valign="bottom"><p><bold>VPS</bold></p> </th><th valign="bottom"><p><bold>MSTd</bold></p> </th><th valign="bottom"><p><bold>VIP</bold></p> </th><th valign="bottom"><p><bold>FEF</bold></p> </th></tr></thead><tbody><tr><td colspan="2"><p>W<sub>0</sub> (spikes/s)</p></td><td><p>23 [16-30]</p></td><td><p>147 [122-172]</p></td><td><p>144 [127-160]</p></td><td><p>144 [129-159]</p></td><td><p>122 [103-142]</p></td><td><p>99 [88-110]</p></td><td><p>99 [87-110]</p></td><td><p>93 [78-108]</p></td></tr><tr><td colspan="2"><p>Peak-to-trough</p></td><td><p>16 [11-21]</p></td><td><p>66 [55-78]</p></td><td><p>65 [57-73]</p></td><td><p>66 [58-73]</p></td><td><p>54 [45-63]</p></td><td><p>43 [38-48]</p></td><td><p>41 [36-47]</p></td><td><p>40 [32-47]</p></td></tr><tr><td colspan="2"><p>FR<sub>0</sub> (spikes/s)</p></td><td><p>74 [61-87]</p></td><td><p>41 [34-47]</p></td><td><p>49 [43-56]</p></td><td><p>19 [15-22]</p></td><td><p>12 [9-15]</p></td><td><p>18 [16-21]</p></td><td><p>11 [10-13]</p></td><td><p>15 [11-18]</p></td></tr><tr><td colspan="2"><p>w<sub>v</sub></p></td><td><p>0.07 [0.05–0.08]</p> </td><td><p>0.31 [0.28–0.34]</p> </td><td><p>0.32 [0.30–0.35]</p> </td><td><p>0.33 [0.31–0.36]</p> </td><td><p>0.35 [0.32–0.39]</p> </td><td><p>0.43 [0.41–0.44]</p> </td><td><p>0.37 [0.34–0.39]</p> </td><td><p>0.37 [0.33–0.40]</p> </td></tr><tr><td colspan="2"><p>w<sub>a</sub></p></td><td><p>0.60 [0.57–0.63]</p> </td><td><p>0.40 [0.36–0.45]</p> </td><td><p>0.37 [0.34–0.41]</p> </td><td><p>0.41 [0.38–0.43]</p> </td><td><p>0.38 [0.35–0.42]</p> </td><td><p>0.30 [0.28–0.33]</p> </td><td><p>0.38 [0.35–0.41]</p> </td><td><p>0.37 [0.33–0.40]</p> </td></tr><tr><td colspan="2"><p>w<sub>j</sub></p></td><td><p>0.34 [0.30–0.37]</p> </td><td><p>0.28 [0.25–0.31]</p> </td><td><p>0.30 [0.28–0.33]</p> </td><td><p>0.26 [0.24–0.28]</p> </td><td><p>0.26 [0.24–0.28]</p> </td><td><p>0.27 [0.26–0.28]</p> </td><td><p>0.25 [0.23–0.27]</p> </td><td><p>0.27 [0.24–0.29]</p> </td></tr><tr><td colspan="2"><p>o<sub>v</sub></p></td><td><p>0.58 [0.32–0.84]</p> </td><td><p>0.39 [0.26–0.51]</p> </td><td><p>0.44 [0.32–0.57]</p> </td><td><p>0.42 [0.34–0.50]</p> </td><td><p>0.38 [0.28–0.47]</p> </td><td><p>0.38 [0.32–0.44]</p> </td><td><p>0.33 [0.22–0.44]</p> </td><td><p>0.29 [0.16–0.42]</p> </td></tr><tr><td colspan="2"><p>o<sub>a</sub></p></td><td><p>0.00 [-0.01–0.01]</p> </td><td><p>0.06 [-0.02–0.14]</p> </td><td><p>0.06 [-0.01–0.14]</p> </td><td><p>0.07 [0.02–0.12]</p> </td><td><p>0.02 [-0.07–0.12]</p> </td><td><p>0.14 [0.09–0.20]</p> </td><td><p>0.06 [-0.01–0.13]</p> </td><td><p>0.17 [0.05–0.29]</p> </td></tr><tr><td colspan="2"><p>o<sub>j</sub></p></td><td><p>0.02 [-0.00–0.05]</p> </td><td><p>0.34 [0.22–0.46]</p> </td><td><p>0.35 [0.23–0.46]</p> </td><td><p>0.36 [0.29–0.44]</p> </td><td><p>0.38 [0.27–0.48]</p> </td><td><p>0.51 [0.45–0.58]</p> </td><td><p>0.43 [0.31–0.54]</p> </td><td><p>0.23 [0.07–0.39]</p> </td></tr><tr><td colspan="2"><p>μ<sub>0</sub> (s)</p></td><td><p>0.06 [0.05–0.07]</p> </td><td><p>0.04 [0.02–0.07]</p> </td><td><p>0.04 [0.02–0.07]</p> </td><td><p>0.04 [0.03–0.05]</p> </td><td><p>0.05 [0.02–0.07]</p> </td><td><p>0.14 [0.12–0.16]</p> </td><td><p>0.07 [0.05–0.10]</p> </td><td><p>0.06 [0.03–0.09]</p> </td></tr><tr><td rowspan="7"><p>Best fitting model</p></td><td><p>V</p></td><td><p>0%</p> </td><td><p>2%</p> </td><td><p>3%</p> </td><td><p>4%</p> </td><td><p>6%</p> </td><td><p>9%</p> </td><td><p>6%</p> </td><td><p>7%</p> </td></tr><tr><td><p>A</p></td><td><p>48%</p> </td><td><p>2%</p> </td><td><p>3%</p> </td><td><p>3%</p> </td><td><p>1%</p> </td><td><p>2%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td></tr><tr><td><p>J</p></td><td><p>0%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td><td><p>1%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td></tr><tr><td><p>VA</p></td><td><p>0%</p> </td><td><p>18%</p> </td><td><p>15%</p> </td><td><p>17%</p> </td><td><p>23%</p> </td><td><p>22%</p> </td><td><p>19%</p> </td><td><p>21%</p> </td></tr><tr><td><p>VJ</p></td><td><p>0%</p> </td><td><p>4%</p> </td><td><p>7%</p> </td><td><p>7%</p> </td><td><p>4%</p> </td><td><p>22%</p> </td><td><p>6%</p> </td><td><p>9%</p> </td></tr><tr><td><p>AJ</p></td><td><p>33%</p> </td><td><p>0%</p> </td><td><p>5%</p> </td><td><p>3%</p> </td><td><p>4%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td><td><p>0%</p> </td></tr><tr><td><p>VAJ</p></td><td><p>19%</p> </td><td><p>74%</p> </td><td><p>67%</p> </td><td><p>66%</p> </td><td><p>62%</p> </td><td><p>44%</p> </td><td><p>69%</p> </td><td><p>63%</p> </td></tr></tbody></table></table-wrap><table-wrap id="tbl3" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.022</object-id><label>Table 3.</label><caption><p>p-values of the Kolmogorov-Smirnov tests in <xref ref-type="fig" rid="fig7">Figure 7</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.022">http://dx.doi.org/10.7554/eLife.20787.022</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th><p>OA</p></th><th><p>VN</p></th><th><p>CN</p></th><th><p>PIVC</p></th><th><p>VPS</p></th><th><p>MSTd</p></th><th><p>VIP</p></th><th><p>FEF</p></th><th><p>Sum</p></th></tr></thead><tbody><tr><td><p>V-A PD angles</p></td><td><p>0.01</p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td></tr><tr><td><p>V-J PD angles</p></td><td><p>0.01</p></td><td><p>0.006</p></td><td><p>0.2</p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−3</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−4</sup></p></td></tr><tr><td><p>A-J PD angles</p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>0.14</p></td><td><p>0.1</p></td><td><p>&lt;10<sup>−4</sup></p></td><td><p>&lt;10<sup>−3</sup></p></td><td><p>&lt;10<sup>−3</sup></p></td><td><p>0.02</p></td><td><p>0.002</p></td><td><p>&lt;10<sup>−4</sup></p></td></tr></tbody></table></table-wrap></p><p>As illustrated in <xref ref-type="fig" rid="fig6">Figure 6B,C</xref> and <xref ref-type="fig" rid="fig6">Figure 6D–F</xref>, the similarity in the relative weights among VN and CN neurons also extends to cortical areas (<xref ref-type="table" rid="tbl2">Table 2</xref>). The most noticeable difference among cortical areas is the slightly greater velocity weight in visual/vestibular multisensory areas (MSTd, VPS, VIP and FEF; median: 0.39, CI=[0.38–0.41]), as compared to those without optic flow responsiveness (VN, CN, PIVC; median 0.32, CI=[0.31–0.35]) (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, cold vs. warm colors, respectively; p&lt;10<sup>−9</sup>, Wilcoxon rank sum test). In fact, the normalized acceleration weight decreased, while the velocity weight increased from PIVC (median <inline-formula><mml:math id="inf55"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.41 [0.38–0.44] CI; median <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.33 [0.29 0.35] CI) to VIP (median <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.39 [0.35–0.42] CI; median <inline-formula><mml:math id="inf58"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.38 [0.34 0.4] CI) to MSTd (median <inline-formula><mml:math id="inf59"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.28 [0.26–0.32] CI; median <inline-formula><mml:math id="inf60"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>= 0.43 [0.4 0.45] CI), and these differences were significant (PIVC vs. MSTd: <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p=3.10<sup>−9</sup>: p = 3.10<sup>−8</sup>; VIP vs. MSTd: <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p = 4.10<sup>−4</sup><inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p = 3.10<sup>−3</sup>; PIVC vs. VIP: <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p=0.04; <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p = 0.3, rank sum test). Yet, these differences are substantially smaller than the transformation of vestibular translation signals between otolith afferents and VN/CN neurons.</p><p>To further characterize the transformation of spatio-temporal response properties from afferents to cortex, <xref ref-type="fig" rid="fig7">Figure 7A</xref> shows distributions of the separability index. OAs that were fit with the AJ or VAJ models (n = 14) generally have very high separability indices (median 0.98, CI=[0.97–0.99]), indicating that their strongest temporal components have similar preferred directions and spatial tuning. The remaining OAs carry only an acceleration component, a property that automatically confers a high separability index (median = 0.99, CI = [0.98–0.99]). In contrast, central brain areas have overall lower separability indices (median 0.89, CI=[0.88–0.9]; Wilcoxon rank sum test, p&lt;10<sup>−12</sup>). Some central cells are also spatio-temporally separable, but many others are not. For the latter neurons, each temporal component typically has a distinct directional tuning curve, resulting from a dependence of the temporal response profile on stimulus direction (e.g. <xref ref-type="fig" rid="fig3">Figure 3</xref>). Within central cells, we found a significant difference between the separability indices of VN/CN and cortical regions (median 0.82, [0.81 0.84] CI versus 0.9, [0.89 0.91] CI, Wilcoxon rank sum test, p&lt;10<sup>−8</sup>). Differences in the separability index were much smaller among cortical areas (ANOVA, F<sub>1,4</sub> = 2.51, p=0.04).</p><p>The preferred directions of neurons were widely scattered in all brain regions, such that the distributions did not differ significantly from uniform in any individual region (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). <xref ref-type="fig" rid="fig7">Figure 7B–D</xref> shows the color-coded distribution of the angular difference in 3D preferred direction for each pair of significant temporal components. Bold/italic labels below each bar graph indicate distributions that are/are not significantly different from a uniform (‘H<sub>1</sub>’) distribution. For comparison, a distribution that reflects purely aligned tuning (‘H<sub>2</sub>’) is also shown.</p><p>Here too, the largest differences are seen between otolith afferents and central cells. The preferred directions for acceleration and jerk are aligned in all afferents that are tuned to these components (<xref ref-type="fig" rid="fig7">Figure 7D</xref>; see also <xref ref-type="fig" rid="fig5">Figure 5D</xref>, black). Because few afferents are tuned to velocity (based on BIC analysis), the angles between the velocity component and the jerk or acceleration components were not significantly different from uniform overall (even though they show a strong dependence on CV*; <xref ref-type="fig" rid="fig5">Figure 5D</xref>).</p><p>In contrast to otolith afferents, central neurons respond predominantly to the velocity and acceleration components of the stimulus (<xref ref-type="fig" rid="fig4">Figure 4C,D</xref>; <xref ref-type="fig" rid="fig6">Figure 6</xref>). We found that these components have aligned spatial tuning for a large subpopulation of central neurons (<xref ref-type="fig" rid="fig7">Figure 7B</xref>, red); thus, the distributions were all significantly different from uniform (‘H<sub>1</sub>’). In addition, they were all also clearly different from a purely aligned distribution (<xref ref-type="fig" rid="fig7">Figure 7B–D</xref>, right bars titled ‘H<sub>2</sub>’). This finding is consistent with the wide spread of separability indices (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). Overall, similar observations also hold for the distributions of V-J and A-J preferred direction differences (<xref ref-type="fig" rid="fig7">Figure 7C,D</xref>). Note that the small separability index of VN/CN neurons (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) is in line with a greater dispersion of differences in preferred directions between A, V and J components in VN and CN neurons (color-coded in red in <xref ref-type="fig" rid="fig7">Figure 7B–D</xref>). For example, only 19% of preferred directions (VA, VJ and AJ angles pooled) were aligned within 30° of each other in VN/CN versus 33% in other central brain regions.</p><p>Large differences between otolith afferent and central responses were also observed when comparing other model parameters (<xref ref-type="fig" rid="fig8">Figure 8</xref>; see also <xref ref-type="table" rid="tbl2">Table 2</xref>). Otolith afferents had the smallest modulation amplitude (peak-to-trough amplitude of the spatio-temporal response curves, computed from the VAJ model fit) as compared to all other brain areas (median = 10 spikes/s, CI=[8-18] for OA versus 43 spikes/s, CI=[41-46] for all central neurons, Wilcoxon rank sum test: p=10<sup>−11</sup>; <xref ref-type="fig" rid="fig8">Figure 8A</xref>). Furthermore, modulation amplitude varied significantly across central brain regions (one-way ANOVA, F<sub>6,545</sub> = 10, p=1.5*10<sup>−10</sup>). VN, CN and PIVC neurons were the most responsive (<xref ref-type="fig" rid="fig8">Figure 8A</xref>, warm colors), with aggregate modulation amplitude (median = 58 spikes/s, CI=[54-63]) greater than visual/vestibular multisensory areas VPS, MSTd, VIP and FEF (<xref ref-type="fig" rid="fig8">Figure 8A</xref>, cold colors; median: 35 spikes/s, CI=[33-39], Wilcoxon’s rank sum test: p&lt;10<sup>−13</sup>). The reverse pattern of results was observed for the baseline response (one-way ANOVA across all brain regions: F<sub>7,571</sub> = 74, p&lt;10<sup>−75</sup>). FR<sub>o</sub>, which was greatest in otolith afferents (median = 72 spikes/s, CI=[54-90], <xref ref-type="fig" rid="fig8">Figure 8B</xref>, brown), intermediate in VN/CN (median = 45 spikes/s, CI=[38-49], <xref ref-type="fig" rid="fig8">Figure 8B</xref>, yellow/orange), and smallest in cortical areas (median = 12 spikes/s, CI=[11-13], <xref ref-type="fig" rid="fig8">Figure 8B</xref>). Thus, small gain modulation and high baseline firing rates in primary otolith afferents are converted into high gain modulation and low baseline firing rates in central brainstem, cerebellar and cortical neurons. Note, however, that this baseline firing rate could include a steady-state response to gravity (since animals were always oriented upright), which is unequivocal in otolith afferents but reduced across the population in brainstem, cerebellar and cortical neurons (<xref ref-type="bibr" rid="bib11">Angelaki et al., 2004</xref>; <xref ref-type="bibr" rid="bib50">Liu and Angelaki, 2009</xref>; <xref ref-type="bibr" rid="bib51">Liu et al., 2011</xref>; <xref ref-type="bibr" rid="bib64">Shaikh et al., 2005</xref>). An interesting picture also emerges when evaluating the spatial tuning, as summarized next.</p></sec><sec id="s2-5"><title>Spatial tuning curves</title><p>As illustrated in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s6">6</xref>, neuronal responses often showed non-linear spatial tuning that could be modeled by adding an offset to a cosine tuning function. The relative importance of offset and cosine-tuned responses are summarized in <xref ref-type="fig" rid="fig9">Figure 9</xref>. As illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>, OAs mainly encode acceleration and jerk with cosine tuning. Accordingly, the offset parameters of the acceleration and jerk components cluster around zero for OAs (<xref ref-type="fig" rid="fig9">Figure 9B,C</xref>). In contrast, the weak velocity components of OAs display higher offsets (median offset parameter <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 0.65, CI = [0.35–0.8]; <xref ref-type="fig" rid="fig9">Figure 9A</xref>).</p><p>Acceleration responses in central brain regions displayed more variable offsets, which nonetheless clustered around zero (median offset parameter <inline-formula><mml:math id="inf67"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 0.08, CI = [0.06–0.11], <xref ref-type="fig" rid="fig9">Figure 9B</xref>). In absolute value, the cosine tuning amplitude was greater than the offset magnitude (i.e. <inline-formula><mml:math id="inf68"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>) for 88% of central neurons. These results indicate that acceleration responses tends to remain cosine-tuned throughout the brain.</p><p>In contrast, velocity responses usually displayed large positive offsets in all central brain regions (<xref ref-type="fig" rid="fig9">Figure 9A</xref>): the median offset parameter <inline-formula><mml:math id="inf69"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> increased to 0.5 (CI = [0.47–0.52], rank sum test compared to <inline-formula><mml:math id="inf70"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: p=10<sup>−43</sup>; <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1A</xref>) and 50% of cells exhibited positive offsets greater than the amplitude of their cosine tuning component (i.e. <inline-formula><mml:math id="inf71"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>). Interestingly, a sizeable fraction (6%) of central cells exhibited negative offsets greater than their tuning (i.e. <inline-formula><mml:math id="inf72"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>), leading to omnidirectional inhibitory responses (as in <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>). Finally, we found that jerk responses in central neurons also exhibited positive offsets (median 0.49, CI=[0.46 0.52]; <xref ref-type="fig" rid="fig9">Figure 9C</xref>) comparable to velocity responses.</p></sec><sec id="s2-6"><title>Position temporal modulation</title><p>The VAJ model has been based on the main response components encountered in all brain areas. We also fitted neuronal responses with a PVAJ model that included a position component, in addition to velocity, acceleration and jerk. For each cell, we extracted the amplitude of the position response component (<xref ref-type="fig" rid="fig10">Figure 10A</xref>, inset, black) and the total peak to peak modulation (<xref ref-type="fig" rid="fig10">Figure 10A</xref>, inset, red) for each spatial direction. The maximum total modulation (across all spatial directions) is plotted versus the maximum position modulation in <xref ref-type="fig" rid="fig10">Figure 10A</xref>. We define the position ratio as the ratio of these two modulations. The diagonal and the two broken lines represent position ratios of 1:1, 1:3 and 1:10, respectively. Cells with a strong position response have a position ratio close to 1:1 and appear close to the diagonal, whereas cells with a weak position response appear far above the diagonal.<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.20787.023</object-id><label>Figure 10.</label><caption><title>Contribution of position signals to vestibular responses.</title><p>(<bold>A</bold>) Scatter plot of the maximum total peak to peak modulation vs. the maximal position modulation (see inset; computed across all spatial directions for each cell). We define the position ratio as the ratio of these two modulations. The diagonal and the two broken lines represent position ratios of 1:1, 1:3 and 1:10, respectively. (<bold>B</bold>) Position ratio in all brain areas (the histogram in MSTd is also represented as the marginal cyan distribution in A). The number and percentage of cells with a position ratio higher than 1:3 (grey region) is indicated for each area. All cells that are not significantly tuned to position are represented by open symbols and bars in A and B (and excluded from C,D). (<bold>C</bold>) Analysis of the angles between the PD of the position (P), velocity (V), acceleration (<bold>A</bold>) and jerk (J) components (as in <xref ref-type="fig" rid="fig7">Figure 7</xref>) for area MSTd. Only cells for which the position ratio is between 1:3 and 1:1 are included (other brain areas are not considered due to the lower numbers of cells). The P and V components have opposite PDs (green) for most MSTd neurons. In contrast, the distribution of P-A angles is symmetric, and similar numbers of cells have aligned and opposite PDs. Accordingly, the distribution of V-A angles is also symmetric. (<bold>D</bold>) Cosine tuning and offset components of position responses in MSTd (cells with position ratio greater than 1:3). The cells form two groups, one with positive offsets (26/39 cells, median offset = 0.46, [0.41 0.55] CI) corresponding to omnidirectional excitatory responses and another with large negative offsets (13/39 cells, median offset = −0.65, [-0.79–0.49] CI) corresponding to omnidirectional inhibitory responses.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.20787.023">http://dx.doi.org/10.7554/eLife.20787.023</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-20787-fig10-v1"/></fig></p><p>Many central neurons had significant position contributions (<xref ref-type="fig" rid="fig10">Figure 10A,B</xref>, filled symbols and bars): OA: 1/27 (4%), VN: 41/49 (84%), CN: 47/61 (77%), PIVC: 63/115 (55%), VPS: 51/69 (74%), MSTd: 108/139 (78%), VIP: 40/62 (65%), FEF: 45/57 (79%). Furthermore, the percentage of neurons with normalized position weights greater than 1:3 varied across areas (<xref ref-type="fig" rid="fig10">Figure 10B</xref>, gray-highlighted areas). In agreement with the findings of <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref>, the position contribution was larger in MSTd, as compared to PIVC and VIP (areas for which the distribution is significantly different from MSTd are indicated by stars; *p&lt;0.01; **p&lt;0.001; two-sample Kolmogorov-Smirnoff tests). In addition to MSTd (cyan), we also found prominent position responses in VN (yellow), CN (orange) and FEF (black). The spatial properties of the position component were generally similar to those of the velocity component (shown for MSTd in <xref ref-type="fig" rid="fig10">Figure 10C,D</xref>), showing both inseparability and non-linear spatial tuning. Note, however, that future studies should record pre- and post-stimulus firing rates for a longer duration, such that these position responses can be quantified more reliably.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>To understand the spatio-temporal processing of translational motion along the hierarchy of the vestibular system, from primary sensory neurons to subcortical and central cortical structures, we have performed a systematic comparison of spatio-temporal response properties to identical 3D naturalistic stimuli. Our analysis has revealed remarkably different spatio-temporal properties between central neurons and primary otolith afferents. Whereas otolith afferents encode mostly linear acceleration, central neuron responses are dominated by components related to stimulus velocity. Furthermore, central neurons also encode jerk (the derivative of linear acceleration), as well as position (displacement). However, this position response component needs to be further investigated in future studies using stimuli that allow a precise quantification of the pre-stimulus and post-stimulus firing rates (see Materials and methods).</p><p>The observed increase in velocity contribution to the spatio-temporal properties of central cells, as compared to otolith afferents, was accompanied by the presence of non-linearities. Whereas the linear acceleration component of central cells continued to be, like otolith afferents, mostly cosine-tuned, the velocity component included substantial omni-directional contributions, and jerk had intermediate properties. Thus, central neurons, like afferents, continued to carry information about the direction of linear acceleration, but they also encoded another type of signal: the presence or absence of translational motion without regard for direction. This component, which was strong in both the cortex and vestibular/cerebellar nuclei, cannot be characterized with the steady-state sinusoidal stimuli that have traditionally been the stimuli of choice in the vestibular system.</p><p>In contrast to the large differences in the types of signals encoded by otolith afferents versus their target cells in the vestibular nuclei, we found only moderate differences in the relative contributions of velocity, acceleration and jerk among central subcortical (vestibular and cerebellar nuclei) and cortical neurons. However, there were systematic differences in both the baseline firing and amplitude of stimulus-driven responses. Otolith afferents and vestibular/cerebellar nuclei neurons had high baseline firing compared to cortical neurons. Furthermore, response amplitude to an identical stimulus was lowest in otolith afferents and greatest in vestibular/cerebellar nuclei, PIVC and VPS – the areas known to form the core of the central vestibular system (<xref ref-type="bibr" rid="bib13">Angelaki et al., 2009</xref>; <xref ref-type="bibr" rid="bib53">Lopez and Blanke, 2011</xref>). In contrast, response amplitude is lower in MSTd, VIP and FEF, which are visual/vestibular multisensory areas. This result is consistent with <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref>, who speculated that the vestibular pathway might go from OA to VN/CN to PIVC to VIP to MSTd. However, although modulation strength remains high in VN/CN and PIVC, it is nevertheless reduced in multisensory visual areas MSTd, VIP and FEF. Note that, although otolith afferents have low peak-to-trough modulation, their information content is high because of the high firing rate regularity (<xref ref-type="bibr" rid="bib42">Jamali et al., 2013</xref>).</p><p>It is important to point out that <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref> compared neural responses in a more limited number of cortical areas during motion within a single plane and reported a gradual shift from acceleration dominance in PIVC to velocity dominance in MSTd, as well as stronger position contributions in MSTd than PIVC or VIP. The present findings are consistent with both conclusions. However, when the full 3D properties are considered in the present analyses, we find that the spatio-temporal tuning properties of individual cortical areas also exhibit remarkable similarities. Note also that the model of <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref> did not include a jerk component, which may also contribute to the results. Purkinje cells in the cerebellar vermal lobules X and IX, which were also previously fitted using the planar model (<xref ref-type="bibr" rid="bib72">Yakusheva et al., 2013</xref>), also showed similar properties to central brain areas when analyzed using the full 3D model used here (unpublished). In summary, these results suggest that the signal transformation that takes place between sensory afferents and their targets in the brainstem and cerebellum represents a key processing element in the vestibular system. Using identical passive stimuli, cortical areas show moderate differences, as compared to the response properties in the brainstem and cerebellum.</p><p>Understanding the central processing of translation signals is complicated for at least two reasons. First, afferents from a single otolith organ differ in both spatial and temporal response properties (<xref ref-type="bibr" rid="bib28">Fernández and Goldberg, 1976a</xref>, <xref ref-type="bibr" rid="bib29">1976b</xref>, <xref ref-type="bibr" rid="bib30">1976c</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib73">Yu et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Jamali et al., 2013</xref>) and extensive convergence in the vestibular nuclei (<xref ref-type="bibr" rid="bib45">Kushiro et al., 2000</xref>; <xref ref-type="bibr" rid="bib66">Straka et al., 2002</xref>; <xref ref-type="bibr" rid="bib69">Uchino et al., 2001</xref>; <xref ref-type="bibr" rid="bib70">Uchino and Kushiro, 2011</xref>) creates complex spatio-temporal convergence properties (<xref ref-type="bibr" rid="bib6">Angelaki et al., 1992</xref>; <xref ref-type="bibr" rid="bib19">Bush et al., 1993</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib27">Dickman and Angelaki, 2002</xref>; <xref ref-type="bibr" rid="bib24">Chen-Huang and Peterson, 2006</xref>, <xref ref-type="bibr" rid="bib25">2010</xref>).</p><p>Second, otolith afferents cannot distinguish tilt relative to gravity from translational acceleration. However, this <italic>tilt/translation ambiguity</italic> has been resolved in the cortex, where neurons that are selective for inertial (translational) accelerations are found (PIVC: <xref ref-type="bibr" rid="bib51">Liu et al., 2011</xref>; MSTd: <xref ref-type="bibr" rid="bib50">Liu and Angelaki, 2009</xref>). This property of cortical neurons is likely inherited from subcortical signals, as there is growing evidence that this computation is implemented through otolith/canal convergence in the brainstem and cerebellum (VN/CN: <xref ref-type="bibr" rid="bib11">Angelaki et al., 2004</xref>; <xref ref-type="bibr" rid="bib52">Liu et al., 2013</xref>; caudal cerebellar vermis: <xref ref-type="bibr" rid="bib71">Yakusheva et al., 2007</xref>; <xref ref-type="bibr" rid="bib48">Laurens et al., 2013a</xref>, <xref ref-type="bibr" rid="bib49">2013b</xref>). It is thus possible that the large differences in spatio-temporal response properties that we have found between otolith afferents and VN/CN neurons arise from neural computations that resolve the tilt/translation ambiguity, a vital and critically important function for spatial orientation.</p><sec id="s3-1"><title>Dynamic properties of otolith afferents</title><p>Otolith afferents have been previously characterized in terms of preferred direction in three-dimensions (<xref ref-type="bibr" rid="bib28">Fernández and Goldberg, 1976a</xref>; <xref ref-type="bibr" rid="bib68">Tomko et al., 1981</xref>; <xref ref-type="bibr" rid="bib73">Yu et al., 2012</xref>) and response dynamics (<xref ref-type="bibr" rid="bib1">Anderson et al., 1978</xref>; <xref ref-type="bibr" rid="bib29">Fernández and Goldberg, 1976b</xref>; <xref ref-type="bibr" rid="bib35">Goldberg et al., 1990</xref>; <xref ref-type="bibr" rid="bib65">Si et al., 1997</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib60">Purcell et al., 2003</xref>; <xref ref-type="bibr" rid="bib41">Jamali et al., 2009</xref>). These two properties are separable, with the activity of each afferent fiber being determined by the product of a temporal ‘transfer’ function and a cosine-tuned spatial function (<xref ref-type="bibr" rid="bib28">Fernández and Goldberg, 1976a</xref>, <xref ref-type="bibr" rid="bib29">1976b</xref>, <xref ref-type="bibr" rid="bib30">1976c</xref>). As a result of this separability, otolith afferents have the same response dynamics along different spatial directions.</p><p>It has long been recognized that otolith afferents differ in their response dynamics based upon the regularity of their spontaneous discharge (<xref ref-type="bibr" rid="bib1">Anderson et al., 1978</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib15">Blanks and Precht, 1978</xref>; <xref ref-type="bibr" rid="bib29">Fernández and Goldberg, 1976b</xref>, <xref ref-type="bibr" rid="bib30">1976c</xref>; <xref ref-type="bibr" rid="bib35">Goldberg et al., 1990</xref>; <xref ref-type="bibr" rid="bib41">Jamali et al., 2009</xref>, <xref ref-type="bibr" rid="bib42">2013</xref>; <xref ref-type="bibr" rid="bib60">Purcell et al., 2003</xref>). Indeed, we found that normalized jerk weights for otolith afferents increased with CV*, whereas acceleration weights decreased with CV*. Thus, the most regular afferents encoded pure acceleration, whereas more irregular afferents encoded mixtures of acceleration and jerk. These findings are consistent with previous studies reporting phase leads and gain advances in less regularly-firing afferents during sinusoidal stimulation (<xref ref-type="bibr" rid="bib1">Anderson et al., 1978</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib29">Fernández and Goldberg, 1976b</xref>; <xref ref-type="bibr" rid="bib35">Goldberg et al., 1990</xref>; <xref ref-type="bibr" rid="bib42">Jamali et al., 2013</xref>; <xref ref-type="bibr" rid="bib60">Purcell et al., 2003</xref>; <xref ref-type="bibr" rid="bib65">Si et al., 1997</xref>). Less regular-firing afferents also included a small but consistent velocity component, whose preferred direction relative to that of the jerk and acceleration components is correlated with CV*. Such a response component has not been described previously using sinusoidal stimulation.</p></sec><sec id="s3-2"><title>Spatio-temporal convergence – theoretical predictions and previous experimental findings using sinusoidal stimuli</title><p>Because VN neurons receive extensive convergence from otolith afferents that vary in their 3D spatial and temporal properties, a computational challenge arises. How would the properties of central neurons transform this information into signals that can be used by the rest of the brain? Theoretical analysis of such convergence showed that central neurons receiving otolith afferent convergence should, in general, exhibit spatio-temporal convergence properties, where spatial and temporal coding might not necessarily be separable; this results in complex spatial (non-cosine-tuned) properties, where central neurons carry different proportions of velocity, acceleration and jerk signals along different spatial directions (<xref ref-type="bibr" rid="bib3">Angelaki, 1992a</xref>, <xref ref-type="bibr" rid="bib4">1992b</xref>, <xref ref-type="bibr" rid="bib5">1992c</xref>; <xref ref-type="bibr" rid="bib62">Schor and Angelaki, 1992</xref>; <xref ref-type="bibr" rid="bib8">Angelaki et al., 1993</xref>; <xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>). Evidence for simultaneous coding of both translational acceleration and jerk was indeed demonstrated in VN responses of decerebrate rodents (<xref ref-type="bibr" rid="bib8">Angelaki et al., 1993</xref>).</p><p>It took several more years until some experimental evidence for spatio-temporal convergence properties was provided for neurons in the primate VN (<xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib24">Chen-Huang and Peterson, 2006</xref>, <xref ref-type="bibr" rid="bib25">2010</xref>) and CN (<xref ref-type="bibr" rid="bib64">Shaikh et al., 2005</xref>). However, to our knowledge, all previously published studies of responses of VN/CN neurons to translation used sinusoidal stimuli. There are many reasons why such stimuli are problematic. First, VN and CN responses are characterized by non-minimum phase properties, i.e., phase and gain changes do not parallel each other, thus complicating identification of temporal dynamics using sinusoids (<xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib27">Dickman and Angelaki, 2002</xref>; <xref ref-type="bibr" rid="bib64">Shaikh et al., 2005</xref>). Second, responses proportional to the temporal derivative and integral of translational acceleration cannot be easily separated using sinusoidal stimuli (e.g., a phase difference of 90° relative to acceleration could reflect either velocity coding in one direction or jerk coding in the opposite direction). The traditional approach of testing sinusoidal responses at different frequencies to distinguish velocity from jerk contributions using linear systems analyses is complicated by the presence of non-minimum phase properties, thus making system identification challenging (<xref ref-type="bibr" rid="bib10">Angelaki and Dickman, 2000</xref>; <xref ref-type="bibr" rid="bib27">Dickman and Angelaki, 2002</xref>; <xref ref-type="bibr" rid="bib64">Shaikh et al., 2005</xref>). Furthermore, if indeed response dynamics vary with stimulus direction, a complete characterization of the spatio-temporal properties requires testing cells at multiple frequencies and multiple directions in 3D (<xref ref-type="bibr" rid="bib24">Chen-Huang and Peterson, 2006</xref>, <xref ref-type="bibr" rid="bib25">2010</xref>). Third, non-linearities in spatio-temporal tuning, as reported here (see also <xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>; <xref ref-type="bibr" rid="bib55">Massot et al., 2012</xref>) can violate the assumptions of traditional linear systems analysis, thus rendering previous conclusions based on steady-state frequency analysis problematic.</p><p>These limitations have been circumvented here, for the first time, by the use of 3D transient stimuli and a comparison of neural responses in multiple subcortical and cortical areas. Importantly, in contrast to <xref ref-type="bibr" rid="bib23">Chen et al. (2011c)</xref>, who fit cortical responses during translation in a single plane, we have developed models that characterize cell responses in 3D. With the exception of <xref ref-type="bibr" rid="bib25">Chen-Huang and Peterson (2010)</xref>, who characterized 3D responses in the VN using sinusoidal stimuli (see limitations above), nothing is known about spatio-temporal convergence in any brain region using transient stimuli. Yet, as previously also emphasized by <xref ref-type="bibr" rid="bib25">Chen-Huang and Peterson (2010)</xref>, understanding the full extent of the underlying spatio-temporal computations is only achievable when data are analyzed in 3D, and conclusions drawn by characterizing responses along a single direction or within a single plane can be rather incomplete. Our current findings have provided the first such quantification of 3D spatio-temporal convergence properties using transient stimuli along many spatial directions.</p><p>In contrast to cosine-tuning of otolith afferents, central neuron responses often show strongly nonlinear and rectified responses to both translational velocity and jerk. Most central cells show omni-directional tuning components. The existence of broad or uniform tuning, as opposed to cosine tuning, suggests that many afferents converge onto one central neuron. Indeed, broadly tuned neurons respond to motion in directions that are orthogonal to their PD. In contrast, in OA, all directions that are orthogonal to the PD are null directions.</p><p>These results suggest that the transformation of responses from sensory afferents to brainstem neurons represents a key processing element, possibly because it is coupled to the resolution of a tilt/translation ambiguity that represents a critically important function for spatial orientation. Although there is no direct evidence yet for such a link, theoretical solutions to the ambiguity problem require strong non-linearities (<xref ref-type="bibr" rid="bib16">Borah et al., 1988</xref>; <xref ref-type="bibr" rid="bib57">Merfeld, 1995</xref>; <xref ref-type="bibr" rid="bib33">Glasauer and Merfeld, 1997</xref>; <xref ref-type="bibr" rid="bib58">Merfeld et al., 1999</xref>; <xref ref-type="bibr" rid="bib9">Angelaki et al., 1999</xref>, <xref ref-type="bibr" rid="bib11">2004</xref>; <xref ref-type="bibr" rid="bib46">Laurens and Droulez, 2007</xref>; <xref ref-type="bibr" rid="bib47">Laurens and Angelaki, 2011</xref>).</p></sec><sec id="s3-3"><title>Functional implications</title><p>The functional significance of the observed spatio-temporal transformation that exists between otolith afferents and VN/CN cells, as well as all other cortical regions examined, remains to be determined. Still, it is striking that all central neurons simultaneously carry velocity, acceleration and jerk signals, with the relative contributions of each component depending on stimulus direction. Remarkably, we observed moderate further spatio-temporal processing (other than differences and response amplitude and baseline firing rate) beyond the VN/CN, such that roughly similar properties characterize all the cortical representations of vestibular translation signals examined to date.</p><p>Previous studies (<xref ref-type="bibr" rid="bib61">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Fusi et al., 2016</xref>) have proposed a role for the mixed non-linear responses widely observed in prefrontal cortex. It has been proposed that mixed selectivity plays an important computational role: high-dimensional representations with mixed selectivity allow a simple linear readout to generate a diverse array of potential responses (<xref ref-type="bibr" rid="bib32">Fusi et al., 2016</xref>). In contrast, representations based on highly specialized neurons are low dimensional and may preclude a linear readout from generating several responses that depend on multiple task-relevant variables. Complex non-linear operations can be performed by simple linear summations of non-linear neurons, and in turn linear summation may be easily learned by neuronal networks. Thus, a rich variety of non-linearly transformed signals may facilitate the learning of complex computations.</p><p>It is possible that the described spatio-temporal transformations in VN/CN might reflect the need to perform non-linear, three-dimensional spatio-temporal operations necessary to implement an internal model of head motion (<xref ref-type="bibr" rid="bib57">Merfeld, 1995</xref>; <xref ref-type="bibr" rid="bib47">Laurens and Angelaki, 2011</xref>), whose influence has been documented in subcortical neurons (<xref ref-type="bibr" rid="bib11">Angelaki et al., 2004</xref>; <xref ref-type="bibr" rid="bib71">Yakusheva et al., 2007</xref>; <xref ref-type="bibr" rid="bib48">Laurens et al., 2013a</xref>, <xref ref-type="bibr" rid="bib49">2013b</xref>). Complex spatio-temporal representations of movement may be passed on to cortical (<xref ref-type="bibr" rid="bib50">Liu and Angelaki, 2009</xref>; <xref ref-type="bibr" rid="bib51">Liu et al., 2011</xref>) neurons to subserve their respective roles in spatial cognition. This hypothesis remains to be tested in future experiments.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects and apparatus</title><p>We include data from a total of 19 rhesus monkeys (Macaca mulatta). Each animal was chronically implanted with an eye coil, a head-restraint ring, and a plastic recording grid that contains an array of holes through which guide tubes were passed for extracellular electrophysiological recordings. All surgical and experimental procedures were approved by the Institutional Animal Care and Use Committee at Washington University and Baylor College of Medicine and were performed in accordance with institutional and NIH guidelines.</p></sec><sec id="s4-2"><title>Data sample</title><p>The data sample analyzed in the present study includes neurons recorded from multiple cortical areas (PIVC VIP, VPS, MSTd and FEF) using epoxy-coated tungsten microelectrodes (1–2 MΩ). Basic methodology and neural response properties of these cortical areas can be found in previous publications: PIVC: <xref ref-type="bibr" rid="bib20">Chen et al. (2010)</xref>, VPS: <xref ref-type="bibr" rid="bib21">Chen et al. (2011a)</xref>, VIP: <xref ref-type="bibr" rid="bib22">Chen et al. (2011b)</xref>, MSTd: <xref ref-type="bibr" rid="bib37">Gu et al. (2006)</xref>, <xref ref-type="bibr" rid="bib38">2010</xref>; <xref ref-type="bibr" rid="bib67">Takahashi et al. (2007)</xref> and FEF: <xref ref-type="bibr" rid="bib39">Gu et al. (2016)</xref>. In order to compare with cortical neurons, we also recorded new data from ‘vestibular-only’ neurons without eye movement-related activity in the VN/CN (5–7 MΩ impedance electrodes) and otolith afferents (18–20 MΩ) using identical stimulation protocols (see below). To localize areas VN and CN, we first identified the abducens nuclei bilaterally based on their characteristic burst-tonic activity during horizontal eye movements (for details see <xref ref-type="bibr" rid="bib56">Meng et al., 2005</xref>; <xref ref-type="bibr" rid="bib52">Liu et al., 2013</xref>). The vestibular nerve was isolated beneath the auditory meatus as it entered the brain, as detailed in previous publications (<xref ref-type="bibr" rid="bib40">Haque et al., 2004</xref>; <xref ref-type="bibr" rid="bib73">Yu et al., 2012</xref>, <xref ref-type="bibr" rid="bib74">2015</xref>). Note that the VN/CN sample in the current study also includes some of the same neurons included in <xref ref-type="bibr" rid="bib52">Liu et al. (2013)</xref>. Samples of at least 40 neurons per region were collected; a sample size of 27 OA was considered sufficient due to the homogeneity of responses across OA.</p></sec><sec id="s4-3"><title>Experimental protocols and analysis</title><p>Monkeys were seated comfortably in a primate chair, which was secured to a six-degree-of-freedom motion platform (MOOG 6DOF2000E). We examined each cell's 3D spatio-temporal tuning by recording neural responses while the animal was translated along each of 26 directions spaced evenly within a sphere. This stimulus set includes all combinations of movement vectors having eight different azimuth angles (0, 45, 90, 135, 180, 225, 270 and 315°; forward, backward, leftward and rightward movements correspond to 90, 270, 0 and 180° respectively) and three different elevation angles, 0° (the stereotaxic horizontal plane) and ±45°, for a subtotal of 8×3 = 24 directions, as well as two additional movement vectors with elevation angles of −90°and 90° corresponding to upward and downward directions, respectively. Each movement trajectory consisted of a Gaussian velocity profile (0.2 s standard deviation) with corresponding biphasic acceleration and triphasic jerk profiles. The total displacement was 13 cm and the peak acceleration was 0.1 g. The frequency content of this stimulus is illustrated in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. All movements originated from the center of the movement range of the motion platform, and the platform returned to this starting position during the 2 s inter-trial interval. Stimuli were presented in random order within a single block of trials (at least five repetitions).</p><p>Data (neural activity and the translational acceleration stimulus) were collected either in complete darkness or during fixation of a central, head-fixed target in an otherwise dark room. Previous findings have established that otolith afferents, VN, CN and PIVC neurons are not sensitive to visual stimuli or eye movements (for details see <xref ref-type="bibr" rid="bib18">Bryan and Angelaki, 2009</xref>; <xref ref-type="bibr" rid="bib52">Liu et al., 2013</xref>; <xref ref-type="bibr" rid="bib20">Chen et al., 2010</xref>). For MSTd, VPS, VIP and FEF neurons, which are sensitive to eye movements and/or visual motion, we have previously verified that vestibular translation responses during fixation are similar to those in complete darkness (details and comparison figures can be found in: <xref ref-type="bibr" rid="bib37">Gu et al., 2006</xref>; <xref ref-type="bibr" rid="bib67">Takahashi et al., 2007</xref> and <xref ref-type="bibr" rid="bib26">Chowdhury et al., 2009</xref> for MSTd, <xref ref-type="bibr" rid="bib21">Chen et al., 2011a</xref> for VPS, <xref ref-type="bibr" rid="bib22">Chen et al., 2011b</xref> for VIP and <xref ref-type="bibr" rid="bib39">Gu et al., 2016</xref> for FEF).</p><p>Quantitative data analyses were performed off-line using custom-written scripts in Matlab (MathWorks), available at the following adress: <ext-link ext-link-type="uri" xlink:href="https://github.com/JeanLaurens/Spatiotemporal_Dynamics">https://github.com/JeanLaurens/Spatiotemporal_Dynamics</ext-link>. Peristimulus time histograms (PSTHs) were constructed for each direction of translation using 25 ms time bins and were smoothed with a Gaussian kernel (σ = 100 ms). We applied both temporal response modulation and space-time structure criteria to determine if a cell had responses strong enough to be included in the present analyses (see <xref ref-type="bibr" rid="bib21">Chen et al. (2011a)</xref> for details). For the temporal response criterion, we first found the peak (trough) time of the PSTH for each stimulus direction. Using the peak (trough) time, we obtained a distribution of response values from the PSTHs for each trial at that point in time. We then compared this peak (trough) distribution with the distribution of values obtained from baseline firing using the Wilcoxon signed-rank test. If responses to two neighboring stimulus directions (45° apart) had significantly (p&lt;0.01) different peak (trough) distributions compared to their own baseline distributions, then the cell passed the temporal response modulation criterion. For the space-time structure criterion, we performed a two-way ANOVA on the full set of single-trial PSTHs, with space and time as factors (<xref ref-type="bibr" rid="bib23">Chen et al., 2011c</xref>). Cells were considered to have space-time structure when both factors as well as their interaction were highly significant (p&lt;0.001).</p><p>To ensure robustness, non-parametric statistics were used and median results were reported whenever it was possible. Confidence intervals of medians were computed based on bootstrap resampling.</p></sec><sec id="s4-4"><title>Spatiotemporal curve fitting</title><p>To characterize and quantify the spatiotemporal dynamics of vestibular responses, trial-averaged PSTHs for each direction of translation were fit with spatiotemporal functions of varying complexity. In its simplest single-component form, the fitted function consists of a spatial tuning component,<inline-formula><mml:math id="inf73"><mml:mrow><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and a temporal response profile <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, multiplied together to obtain the spatiotemporal response function (<xref ref-type="fig" rid="fig1">Figure 1</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>·</mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the response amplitude and <inline-formula><mml:math id="inf76"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the baseline firing rate. Note that <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are normalized and unitless, such that <inline-formula><mml:math id="inf79"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are both expressed in spikes/s. Other parameters are defined below.</p><p><bold><italic>The spatial tuning</italic></bold> is modelled as a cosine function <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> fed through a non-linear function <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. The cosine tuning function <inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>depends on parameters <inline-formula><mml:math id="inf84"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (preferred azimuth) and <inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>(preferred elevation):<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⊤</mml:mo></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> maps the unit vector in spherical coordinates to Cartesian coordinates (<xref ref-type="bibr" rid="bib54">Mardia and Jupp, 1999</xref>). Because <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is equal to the cosine of the angle between <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf89"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, it has a value of 1 at the preferred direction (PD), a value of −1 at the opposite direction (called anti-preferred direction) and a value of 0 in any direction orthogonal to the PD (called ‘an orthogonal direction’).</p><p>The non-linear function,<inline-formula><mml:math id="inf90"><mml:mrow><mml:mo> </mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> generalizes the spatial tuning from a pure cosine function by adding an offset parameter, <inline-formula><mml:math id="inf91"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. It takes the form<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The offset parameter, <inline-formula><mml:math id="inf92"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, ranging from −1 to 1, allows us to model omnidirectional response components, while the term <inline-formula><mml:math id="inf93"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> represents cosine tuning as a function of motion direction. Note that scaling <inline-formula><mml:math id="inf94"><mml:mi>x</mml:mi></mml:math></inline-formula> by <inline-formula><mml:math id="inf95"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> ensures that the function <inline-formula><mml:math id="inf96"><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is normalized, such that <inline-formula><mml:math id="inf97"><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf98"><mml:mi>x</mml:mi></mml:math></inline-formula> in <inline-formula><mml:math id="inf99"><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf100"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for at least one value of <inline-formula><mml:math id="inf101"><mml:mi>x</mml:mi></mml:math></inline-formula>.</p><p><bold><italic>The temporal profile</italic></bold>, <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is defined as follows:<disp-formula id="equ4"><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd id="mjx-eqn-4_12"><mml:mtext>(4)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="9.5pc"/></mml:mtd><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>⌈</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⌉</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-5_11"><mml:mtext>(5)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="8pc"/></mml:mtd><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>⌈</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⌉</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mlabeledtr><mml:mtd id="mjx-eqn-6_10"><mml:mtext>(6)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">J</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="10.9pc"/></mml:mtd><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>⌈</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⌉</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd><mml:mtd/></mml:mlabeledtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In <xref ref-type="disp-formula" rid="equ4">Equations 4–6</xref>, <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo> </mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (temporal delay) is a fitted parameter, whereas <inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>σ</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:math></inline-formula> (temporal Gaussian width) is set by the stimulus (<inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>σ</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:math></inline-formula> = 0.2 s). The operator <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>⌈</mml:mo><mml:mo>.</mml:mo><mml:mo>⌉</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> indicates that the temporal profiles were normalized so that the difference between the maximum and the minimum values of each profile is 1 (<xref ref-type="fig" rid="fig1">Figure 1</xref>, blue, red and green waveforms, respectively).</p><p>The simplest spatio-temporal model consisted of Velocity-only (‘V’ model), Acceleration-only (‘A’ model) or Jerk-only (‘J’ model) terms based on <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, where the temporal profile was given by <xref ref-type="disp-formula" rid="equ4">Equations 4, 5 or 6</xref>, respectively. The most general model was the Velocity+Acceleration+Jerk (VAJ) model, given by the following equation:<disp-formula id="equ5"><label>(7)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf109"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the velocity, acceleration and jerk components, respectively. Each of the three spatial tuning functions (<inline-formula><mml:math id="inf110"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>has its own set of parameters (<inline-formula><mml:math id="inf111"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="inf112"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo> </mml:mo></mml:mrow></mml:math></inline-formula>and <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, respectively), and <inline-formula><mml:math id="inf114"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf115"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf116"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the respective weights on each component. Note that a single delay parameter <inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is used in the VAJ model. Additional models of intermediate complexity—Velocity + Acceleration (‘VA’), Velocity + Jerk (‘VJ’), Acceleration + Jerk (‘AJ’)—were also tested. The 1-component models (‘V’, ‘A’ or ‘J’) have six free parameters, the two-component models (‘VA’, ‘VJ’ or ‘AJ’) have 10 free parameters, and the three-component model (‘VAJ’) has 14 parameters.</p><p>How well each model fit the neural responses was quantified as the proportion of variance accounted for by the model (R<sup>2</sup>), and was computed by regressing the responses of each neuron against the values of each fitted function (across the 26 heading directions and the entire 2 s response profile). To evaluate the best model while accounting for the number of model parameters, we used the Bayesian Information Criterion (BIC), defined as:<disp-formula id="equ6"><label>(8)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf118"><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula> is the residual sum of squares, <inline-formula><mml:math id="inf119"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of data points (considering that the response profile was 2 s long and filtered by a Gaussian kernel with σ = 100 ms, we assumed that the data amounted to 10 independent time points per profile and therefore n = 260) and <inline-formula><mml:math id="inf120"><mml:mi>p</mml:mi></mml:math></inline-formula> is the number of function parameters (<xref ref-type="bibr" rid="bib44">Konishi and Kitagawa, 2008</xref>). The best model based on this criterion is the one with the lowest BIC value.</p><p>The importance of each model component was also assessed by computing its partial coefficient of correlation given the two other components. For instance, the partial correlation coefficient of the A component R<sub>A|VJ</sub> reflects how much variance is explained by adding the A component to the VJ model and is computed accorded to:<disp-formula id="equ7"><label>(9)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The VAJ model includes a separate spatial tuning curve for each dynamic component (acceleration, velocity and jerk). However, for certain cells, the dynamic components have an identical spatial tuning; a property called ‘spatio-temporal separability’. We tested if the tuning of cells was separable by fitting an additional ‘Separable VAJ’ model (which has eight parameters) that includes an identical spatial tuning curve for all components. This model was used to compute a ‘separability index, (Sep I)’:<disp-formula id="equ8"><label>(10)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In order to validate our approach, we simulated 1000 Poisson-spiking neurons, divided equally among each model type, and verified that fitting the standard model could satisfactorily retrieve the spatio-temporal tuning of neurons.</p><p>Finally, we also tested a four-component (PVAJ) model (18 parameters), in which a position (integral of velocity) component was added to the other three terms (velocity, acceleration and jerk). However, the recorded data used to evaluate these models were limited to at most 200 ms following motion offset, which makes the contribution of position modulation hard to evaluate reliably. For this reason, we focus mainly on the findings of the VAJ model (but see <xref ref-type="fig" rid="fig10">Figure 10</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The work was supported by NIH grants EY12814 and DC04260. GCD was supported by EY016178. The authors would like to thank A Chen, Y Gu, A Bryan for recording the central neurons whose properties have been analyzed here.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>JL, Formal analysis, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>SL, Investigation, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>X-JY, Investigation, Writing—original draft</p></fn><fn fn-type="con" id="con4"><p>RC, Data curation, Formal analysis, Writing—original draft</p></fn><fn fn-type="con" id="con5"><p>DD, Conceptualization, Supervision, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>GCD, Conceptualization, Supervision, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>DEA, Conceptualization, Supervision, Funding acquisition, Investigation, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocol #AN-5795 of the Baylor College of Medicine. Data collected in previous studies were obtained according to the National Institutes of Health Guidelines, as described in the corresponding publications. All surgery was performed under isoflurane anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JH</given-names></name><name><surname>Blanks</surname><given-names>RH</given-names></name><name><surname>Precht</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Response characteristics of semicircular canal and otolith systems in cat. I. dynamic responses of primary vestibular fibers</article-title><source>Experimental Brain Research</source><volume>32</volume><fpage>491</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1007/BF00239549</pub-id><pub-id pub-id-type="pmid">28960</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Dynamic polarization vector of spatially tuned neurons</article-title><source>IEEE Transactions on Biomedical Engineering</source><volume>38</volume><fpage>1053</fpage><lpage>1060</lpage><pub-id pub-id-type="doi">10.1109/10.99068</pub-id><pub-id pub-id-type="pmid">1748439</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1992">1992a</year><article-title>Two-dimensional coding of linear acceleration and the angular velocity sensitivity of the otolith system</article-title><source>Biological Cybernetics</source><volume>67</volume><fpage>511</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1007/BF00198758</pub-id><pub-id pub-id-type="pmid">1472575</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1992">1992b</year><article-title>Spatio-temporal convergence (STC) in otolith neurons</article-title><source>Biological Cybernetics</source><volume>67</volume><fpage>83</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1007/BF00201805</pub-id><pub-id pub-id-type="pmid">1606247</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1992">1992c</year><article-title>Vestibular neurons encoding two-dimensional linear acceleration assist in the estimation of rotational velocity during off-vertical axis rotation</article-title><source>Annals of the New York Academy of Sciences</source><volume>656</volume><fpage>910</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1992.tb25292.x</pub-id><pub-id pub-id-type="pmid">1599218</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Bush</surname><given-names>GA</given-names></name><name><surname>Perachio</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>A model for the characterization of the spatial properties in vestibular neurons</article-title><source>Biological Cybernetics</source><volume>66</volume><fpage>231</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1007/BF00198476</pub-id><pub-id pub-id-type="pmid">1540674</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spatial and temporal coding in single neurons</article-title><source>Biological Cybernetics</source><volume>69</volume><fpage>147</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1007/BF00226198</pub-id><pub-id pub-id-type="pmid">8373885</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Bush</surname><given-names>GA</given-names></name><name><surname>Perachio</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Two-dimensional spatiotemporal coding of linear acceleration in vestibular nuclei neurons</article-title><source>Journal of Neuroscience</source><volume>13</volume><fpage>1403</fpage><lpage>1417</lpage><pub-id pub-id-type="pmid">8463828</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>McHenry</surname><given-names>MQ</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Newlands</surname><given-names>SD</given-names></name><name><surname>Hess</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Computation of inertial motion: neural strategies to resolve ambiguous otolith information</article-title><source>Journal of Neuroscience</source><volume>19</volume><fpage>316</fpage><lpage>327</lpage><pub-id pub-id-type="pmid">9870961</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Spatiotemporal processing of linear acceleration: primary afferent and central vestibular neuron responses</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>2113</fpage><lpage>2132</lpage><pub-id pub-id-type="pmid">11024100</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Shaikh</surname><given-names>AG</given-names></name><name><surname>Green</surname><given-names>AM</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neurons compute internal models of the physical laws of motion</article-title><source>Nature</source><volume>430</volume><fpage>560</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1038/nature02754</pub-id><pub-id pub-id-type="pmid">15282606</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Vestibular system: the many facets of a multimodal sense</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>125</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.060407.125555</pub-id><pub-id pub-id-type="pmid">18338968</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Klier</surname><given-names>EM</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A vestibular sensation: probabilistic approaches to spatial perception</article-title><source>Neuron</source><volume>64</volume><fpage>448</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.010</pub-id><pub-id pub-id-type="pmid">19945388</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barmack</surname><given-names>NH</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Central vestibular system: vestibular nuclei and posterior cerebellum</article-title><source>Brain Research Bulletin</source><volume>60</volume><fpage>511</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1016/S0361-9230(03)00055-8</pub-id><pub-id pub-id-type="pmid">12787870</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanks</surname> <given-names>RHI</given-names></name><name><surname>Precht</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Functional characterization of primary vestibular afferents in the frog</article-title><source>Experimental Brain Research</source><volume>25</volume><fpage>369</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1007/bf00241728</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borah</surname><given-names>J</given-names></name><name><surname>Young</surname><given-names>LR</given-names></name><name><surname>Curry</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Optimal estimator model for human spatial orientation</article-title><source>Annals of the New York Academy of Sciences</source><volume>545</volume><fpage>51</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1988.tb19555.x</pub-id><pub-id pub-id-type="pmid">3071213</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>Klam</surname><given-names>F</given-names></name><name><surname>Duhamel</surname><given-names>JR</given-names></name><name><surname>Ben Hamed</surname><given-names>S</given-names></name><name><surname>Graf</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual-vestibular interactive responses in the macaque ventral intraparietal area (VIP)</article-title><source>European Journal of Neuroscience</source><volume>16</volume><fpage>1569</fpage><lpage>1586</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.2002.02206.x</pub-id><pub-id pub-id-type="pmid">12405971</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bryan</surname><given-names>AS</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Optokinetic and vestibular responsiveness in the macaque rostral vestibular and fastigial nuclei</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>714</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1152/jn.90612.2008</pub-id><pub-id pub-id-type="pmid">19073813</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>GA</given-names></name><name><surname>Perachio</surname><given-names>AA</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Encoding of head acceleration in vestibular neurons. I. spatiotemporal response properties to linear acceleration</article-title><source>Journal of Neurophysiology</source><volume>69</volume><fpage>2039</fpage><lpage>2055</lpage><pub-id pub-id-type="pmid">8350132</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Macaque parieto-insular vestibular cortex: responses to self-motion and optic flow</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>3022</fpage><lpage>3042</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4029-09.2010</pub-id><pub-id pub-id-type="pmid">20181599</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011a</year><article-title>A comparison of vestibular spatiotemporal tuning in macaque parietoinsular vestibular cortex, ventral intraparietal area, and medial superior temporal area</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>3082</fpage><lpage>3094</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4476-10.2011</pub-id><pub-id pub-id-type="pmid">21414929</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011b</year><article-title>Convergence of vestibular and visual self-motion signals in an area of the posterior sylvian fissure</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11617</fpage><lpage>11627</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1266-11.2011</pub-id><pub-id pub-id-type="pmid">21832191</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011c</year><article-title>Representation of vestibular and visual cues to self-motion in ventral intraparietal cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>12036</fpage><lpage>12052</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0395-11.2011</pub-id><pub-id pub-id-type="pmid">21849564</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen-Huang</surname><given-names>C</given-names></name><name><surname>Peterson</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Three dimensional spatial-temporal convergence of otolith related signals in vestibular only neurons in squirrel monkeys</article-title><source>Experimental Brain Research</source><volume>168</volume><fpage>410</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1007/s00221-005-0098-7</pub-id><pub-id pub-id-type="pmid">16193271</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen-Huang</surname><given-names>C</given-names></name><name><surname>Peterson</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Frequency-dependent spatiotemporal tuning properties of non-eye movement related vestibular neurons to three-dimensional translations in squirrel monkeys</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>3219</fpage><lpage>3237</lpage><pub-id pub-id-type="doi">10.1152/jn.00904.2009</pub-id><pub-id pub-id-type="pmid">20375245</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname><given-names>SA</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Does the middle temporal area carry vestibular signals related to self-motion?</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>12020</fpage><lpage>12030</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0004-09.2009</pub-id><pub-id pub-id-type="pmid">19776288</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Vestibular convergence patterns in vestibular nuclei neurons of alert primates</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>3518</fpage><lpage>3533</lpage><pub-id pub-id-type="doi">10.1152/jn.00518.2002</pub-id><pub-id pub-id-type="pmid">12466465</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernández</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1976">1976a</year><article-title>Physiology of peripheral neurons innervating otolith organs of the squirrel monkey. II. directional selectivity and force-response relations</article-title><source>Journal of Neurophysiology</source><volume>39</volume><fpage>985</fpage><lpage>995</lpage><pub-id pub-id-type="pmid">824413</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernández</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1976">1976b</year><article-title>Physiology of peripheral neurons innervating otolith organs of the squirrel monkey. III. response dynamics</article-title><source>Journal of Neurophysiology</source><volume>39</volume><fpage>996</fpage><lpage>1008</lpage><pub-id pub-id-type="pmid">824414</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernández</surname><given-names>C</given-names></name><name><surname>Goldberg</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1976">1976c</year><article-title>Physiology of peripheral neurons innervating otolith organs of the squirrel monkey. I. response to static tilts and to long-duration centrifugal force</article-title><source>Journal of Neurophysiology</source><volume>39</volume><fpage>970</fpage><lpage>984</lpage><pub-id pub-id-type="pmid">824412</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukushima</surname> <given-names>J</given-names></name><name><surname>Akao</surname><given-names>T</given-names></name><name><surname>Kurkin</surname><given-names>S</given-names></name><name><surname>Kaneko</surname><given-names>CR</given-names></name><name><surname>Fukushima</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The vestibular-related frontal cortex and its role in smooth-pursuit eye movements and vestibular-pursuit interactions</article-title><source>Journal of Vestibular Research : Equilibrium &amp; Orientation</source><volume>16</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="pmid">16917164</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Glasauer</surname><given-names>S</given-names></name><name><surname>Merfeld</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1997">1997</year><chapter-title>Modelling three-dimensional vestibular responses during complex motion stimulation</chapter-title><person-group person-group-type="editor"><name><surname>Fetter</surname> <given-names>M</given-names></name><name><surname>Haslwanter</surname> <given-names>T</given-names></name><name><surname>Misslisch</surname> <given-names>H</given-names></name></person-group><source>Three-Dimensional Kinematics of Eye, Head and Limb Movements</source><publisher-loc>Amsterdam</publisher-loc><publisher-name>Harwood academic</publisher-name><fpage>387</fpage><lpage>398</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>JM</given-names></name><name><surname>Smith</surname><given-names>CE</given-names></name><name><surname>Fernández</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Relation between discharge regularity and responses to externally applied galvanic currents in vestibular nerve afferents of the squirrel monkey</article-title><source>Journal of Neurophysiology</source><volume>51</volume><fpage>1236</fpage><lpage>1256</lpage><pub-id pub-id-type="pmid">6737029</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>JM</given-names></name><name><surname>Desmadryl</surname><given-names>G</given-names></name><name><surname>Baird</surname><given-names>RA</given-names></name><name><surname>Fernández</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The vestibular nerve of the chinchilla. IV. discharge properties of utricular afferents</article-title><source>Journal of Neurophysiology</source><volume>63</volume><fpage>781</fpage><lpage>790</lpage><pub-id pub-id-type="pmid">2341876</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grüsser</surname><given-names>OJ</given-names></name><name><surname>Pause</surname><given-names>M</given-names></name><name><surname>Schreiter</surname><given-names>U</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Localization and responses of neurones in the parieto-insular vestibular cortex of awake monkeys (Macaca fascicularis)</article-title><source>The Journal of Physiology</source><volume>430</volume><fpage>537</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1990.sp018306</pub-id><pub-id pub-id-type="pmid">2086773</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Watkins</surname><given-names>PV</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Visual and nonvisual contributions to three-dimensional heading selectivity in the medial superior temporal area</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>73</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2356-05.2006</pub-id><pub-id pub-id-type="pmid">16399674</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Adeyemo</surname><given-names>B</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Decoding of MSTd population activity accounts for variations in the precision of heading perception</article-title><source>Neuron</source><volume>66</volume><fpage>596</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.04.026</pub-id><pub-id pub-id-type="pmid">20510863</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Cheng</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multisensory convergence of visual and vestibular heading cues in the pursuit area of the frontal eye field</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>3785</fpage><lpage>3801</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv183</pub-id><pub-id pub-id-type="pmid">26286917</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haque</surname><given-names>A</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Spatial tuning and dynamics of vestibular semicircular canal afferents in rhesus monkeys</article-title><source>Experimental Brain Research</source><volume>155</volume><fpage>81</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1007/s00221-003-1693-0</pub-id><pub-id pub-id-type="pmid">15064888</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jamali</surname><given-names>M</given-names></name><name><surname>Sadeghi</surname><given-names>SG</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Response of vestibular nerve afferents innervating utricle and saccule during passive and active translations</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>141</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1152/jn.91066.2008</pub-id><pub-id pub-id-type="pmid">18971293</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jamali</surname><given-names>M</given-names></name><name><surname>Carriot</surname><given-names>J</given-names></name><name><surname>Chacron</surname><given-names>MJ</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Strong correlations between sensitivity and variability give rise to constant discrimination thresholds across the otolith afferent population</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>11302</fpage><lpage>11313</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0459-13.2013</pub-id><pub-id pub-id-type="pmid">23825433</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klam</surname><given-names>F</given-names></name><name><surname>Graf</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Discrimination between active and passive head movements by macaque ventral and medial intraparietal cortex neurons</article-title><source>The Journal of Physiology</source><volume>574</volume><fpage>367</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2005.103697</pub-id><pub-id pub-id-type="pmid">16556655</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Konishi</surname><given-names>S</given-names></name><name><surname>Kitagawa</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Information Criteria and Statistical Modeling</source><publisher-name>Springer Science &amp; Business Media</publisher-name><pub-id pub-id-type="doi">10.1007/978-0-387-71887-3</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kushiro</surname><given-names>K</given-names></name><name><surname>Zakir</surname><given-names>M</given-names></name><name><surname>Sato</surname><given-names>H</given-names></name><name><surname>Ono</surname><given-names>S</given-names></name><name><surname>Ogawa</surname><given-names>Y</given-names></name><name><surname>Meng</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Uchino</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Saccular and utricular inputs to single vestibular neurons in cats</article-title><source>Experimental Brain Research</source><volume>131</volume><fpage>406</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1007/s002219900312</pub-id><pub-id pub-id-type="pmid">10803410</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurens</surname><given-names>J</given-names></name><name><surname>Droulez</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Bayesian processing of vestibular information</article-title><source>Biological Cybernetics</source><volume>96</volume><fpage>389</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1007/s00422-006-0133-1</pub-id><pub-id pub-id-type="pmid">17146661</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurens</surname><given-names>J</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The functional significance of velocity storage and its dependence on gravity</article-title><source>Experimental Brain Research</source><volume>210</volume><fpage>407</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1007/s00221-011-2568-4</pub-id><pub-id pub-id-type="pmid">21293850</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurens</surname><given-names>J</given-names></name><name><surname>Meng</surname><given-names>H</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Computation of linear acceleration through an internal model in the macaque cerebellum</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1701</fpage><lpage>1708</lpage><pub-id pub-id-type="doi">10.1038/nn.3530</pub-id><pub-id pub-id-type="pmid">24077562</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurens</surname><given-names>J</given-names></name><name><surname>Meng</surname><given-names>H</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Neural representation of orientation relative to gravity in the macaque cerebellum</article-title><source>Neuron</source><volume>80</volume><fpage>1508</fpage><lpage>1518</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.029</pub-id><pub-id pub-id-type="pmid">24360549</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Vestibular signals in macaque extrastriate visual cortex are functionally appropriate for heading perception</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>8936</fpage><lpage>8945</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1607-09.2009</pub-id><pub-id pub-id-type="pmid">19605631</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Response dynamics and tilt versus translation discrimination in parietoinsular vestibular cortex</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>563</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq123</pub-id><pub-id pub-id-type="pmid">20624839</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Choice-related activity and correlated noise in subcortical vestibular neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>89</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1038/nn.3267</pub-id><pub-id pub-id-type="pmid">23178975</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopez</surname><given-names>C</given-names></name><name><surname>Blanke</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The thalamocortical vestibular system in animals and humans</article-title><source>Brain Research Reviews</source><volume>67</volume><fpage>119</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2010.12.002</pub-id><pub-id pub-id-type="pmid">21223979</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mardia</surname><given-names>KV</given-names></name><name><surname>Jupp</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Directional Statistics</source><publisher-name>John Wiley &amp; Sons, Ltd</publisher-name><pub-id pub-id-type="doi">10.1002/9780470316979</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massot</surname><given-names>C</given-names></name><name><surname>Schneider</surname><given-names>AD</given-names></name><name><surname>Chacron</surname><given-names>MJ</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The vestibular system implements a linear-nonlinear transformation in order to encode self-motion</article-title><source>PLoS Biology</source><volume>10</volume><elocation-id>e1001365</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001365</pub-id><pub-id pub-id-type="pmid">22911113</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>H</given-names></name><name><surname>Green</surname><given-names>AM</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Pursuit--vestibular interactions in brain stem neurons during rotation and translation</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>3418</fpage><lpage>3433</lpage><pub-id pub-id-type="doi">10.1152/jn.01259.2004</pub-id><pub-id pub-id-type="pmid">15647394</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merfeld</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Modeling the vestibulo-ocular reflex of the squirrel monkey during eccentric rotation and roll tilt</article-title><source>Experimental Brain Research</source><volume>106</volume><fpage>123</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1007/BF00241362</pub-id><pub-id pub-id-type="pmid">8542968</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merfeld</surname><given-names>DM</given-names></name><name><surname>Zupan</surname><given-names>L</given-names></name><name><surname>Peterka</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Humans use internal models to estimate gravity and linear acceleration</article-title><source>Nature</source><volume>398</volume><fpage>615</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1038/19303</pub-id><pub-id pub-id-type="pmid">10217143</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newlands</surname><given-names>SD</given-names></name><name><surname>Perachio</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Central projections of the vestibular nerve: a review and single fiber study in the mongolian gerbil</article-title><source>Brain Research Bulletin</source><volume>60</volume><fpage>475</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1016/S0361-9230(03)00051-0</pub-id><pub-id pub-id-type="pmid">12787868</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>IM</given-names></name><name><surname>Newlands</surname><given-names>SD</given-names></name><name><surname>Perachio</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Responses of gerbil utricular afferents to translational motion</article-title><source>Experimental Brain Research</source><volume>152</volume><fpage>317</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1007/s00221-003-1530-5</pub-id><pub-id pub-id-type="pmid">12898100</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schor</surname><given-names>RH</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The algebra of neural response vectors</article-title><source>Annals of the New York Academy of Sciences</source><volume>656</volume><fpage>190</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1992.tb25209.x</pub-id><pub-id pub-id-type="pmid">1599143</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Estimating the dimension of a model</article-title><source>The Annals of Statistics</source><volume>6</volume><fpage>461</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344136</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaikh</surname><given-names>AG</given-names></name><name><surname>Ghasia</surname><given-names>FF</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Properties of cerebellar fastigial neurons during translation, rotation, and eye movements</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>853</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1152/jn.00879.2004</pub-id><pub-id pub-id-type="pmid">15371498</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>X</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Response properties of pigeon otolith afferents to linear acceleration</article-title><source>Experimental Brain Research</source><volume>117</volume><fpage>242</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1007/s002210050219</pub-id><pub-id pub-id-type="pmid">9419070</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Straka</surname><given-names>H</given-names></name><name><surname>Holler</surname><given-names>S</given-names></name><name><surname>Goto</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Patterns of canal and otolith afferent input convergence in frog second-order vestibular neurons</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2287</fpage><lpage>2301</lpage><pub-id pub-id-type="doi">10.1152/jn.00370.2002</pub-id><pub-id pub-id-type="pmid">12424270</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>May</surname><given-names>PJ</given-names></name><name><surname>Newlands</surname><given-names>SD</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Multimodal coding of three-dimensional rotation and translation in area MSTd: comparison of visual and vestibular selectivity</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>9742</fpage><lpage>9756</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0817-07.2007</pub-id><pub-id pub-id-type="pmid">17804635</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomko</surname><given-names>DL</given-names></name><name><surname>Peterka</surname><given-names>RJ</given-names></name><name><surname>Schor</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Responses to head tilt in cat eighth nerve afferents</article-title><source>Experimental Brain Research</source><volume>41</volume><fpage>216</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1007/BF00238878</pub-id><pub-id pub-id-type="pmid">7215485</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchino</surname><given-names>Y</given-names></name><name><surname>Sato</surname><given-names>H</given-names></name><name><surname>Zakir</surname><given-names>M</given-names></name><name><surname>Kushiro</surname><given-names>K</given-names></name><name><surname>Imagawa</surname><given-names>M</given-names></name><name><surname>Ogawa</surname><given-names>Y</given-names></name><name><surname>Ono</surname><given-names>S</given-names></name><name><surname>Meng</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Katsuta</surname><given-names>M</given-names></name><name><surname>Isu</surname><given-names>N</given-names></name><name><surname>Wilson</surname><given-names>VJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Commissural effects in the otolith system</article-title><source>Experimental Brain Research</source><volume>136</volume><fpage>421</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1007/s002210000611</pub-id><pub-id pub-id-type="pmid">11291722</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchino</surname><given-names>Y</given-names></name><name><surname>Kushiro</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Differences between otolith- and semicircular canal-activated neural circuitry in the vestibular system</article-title><source>Neuroscience Research</source><volume>71</volume><fpage>315</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1016/j.neures.2011.09.001</pub-id><pub-id pub-id-type="pmid">21968226</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yakusheva</surname><given-names>TA</given-names></name><name><surname>Shaikh</surname><given-names>AG</given-names></name><name><surname>Green</surname><given-names>AM</given-names></name><name><surname>Blazquez</surname><given-names>PM</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Purkinje cells in posterior cerebellar vermis encode motion in an inertial reference frame</article-title><source>Neuron</source><volume>54</volume><fpage>973</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.06.003</pub-id><pub-id pub-id-type="pmid">17582336</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yakusheva</surname><given-names>TA</given-names></name><name><surname>Blazquez</surname><given-names>PM</given-names></name><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatiotemporal properties of optic flow and vestibular tuning in the cerebellar nodulus and uvula</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>15145</fpage><lpage>15160</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2118-13.2013</pub-id><pub-id pub-id-type="pmid">24048845</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>XJ</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Detection thresholds of macaque otolith afferents</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>8306</fpage><lpage>8316</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1067-12.2012</pub-id><pub-id pub-id-type="pmid">22699911</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>XJ</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Xj</surname><given-names>Y</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal thresholds and choice-related activity of otolith afferent fibers during heading perception</article-title><source>PNAS</source><volume>112</volume><fpage>6467</fpage><lpage>6472</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507402112</pub-id><pub-id pub-id-type="pmid">25941358</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.20787.024</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Raymond</surname><given-names>Jennifer L</given-names></name><aff id="aff7"><institution>Stanford University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Evolution of spatiotemporal dynamics from otolith sensory afferents to cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom, Jennifer L Raymond (Reviewer #1), is a member of our Board of Reviewing Editors and the evaluation has been overseen by David Van Essen as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper characterizes the spatial and temporal coding properties of neurons throughout the vestibular system hierarchy. This work may be unprecedented in its comprehensive and systematic characterization of neurons at so many different levels of a sensory system, using a common set of stimuli and analysis methods. 579 neurons were recorded in 8 subcortical and cortical regions carrying vestibular signals (otolith afferents, vestibular and cerebellar nuclei, and 5 cortical areas: PIVC, VIP, VPS, MSTd, FEF) during transient, translational vestibular stimuli delivered in 24 directions in 3D space. Neural responses were fit with a model that included velocity, acceleration and jerk, and linear or nonlinear spatio-temporal combinations of these quantities. The analysis is principled, systematic, uniformly applied across brain areas, and validated using simulated neurons with defined coding properties. The authors find that whereas there are clear differences in response selectivity between of primary otolith afferents and central neurons, responses of neurons in vestibular and cerebellar nuclei and five distinct cerebrocortical areas are remarkably similar to each other. The finding of similar spatio-temporal coding properties in all brain regions beyond the otolithic afferents suggests that a key step in the processing of vestibular information is performed at the first synapse. Overall, the work is sound and carefully executed. It is impressive in its completeness, providing a comprehensive picture of vestibular signal transformations across brain regions. The central findings provide a valuable resource for the vestibular field, and provide the opportunity for useful comparisons across sensory modalities. Although generally enthusiastic, the Reviewers had several suggestions for additional analysis, and for how the presentation of the Results and Discussion could be improved to increase the impact of this impressive body of research.</p><p>Essential revisions:</p><p>1) The main conclusion, that the big signal transformation happened at the first processing stage and that all the higher vestibular areas are more similar in their coding properties, is well supported. However, the difficulty for the reader to draw any conclusion beyond this creates an impression that not much was gained from the massive effort invested. A more nuanced treatment of differences between central brain areas seems merited, and would do the rich data set more justice. Some specific examples, raised by the Reviewers:</p><p>a) A previous study from this group (Yakusheva et al., J Neurosci 2013) had shown that vestibular responses of Purkinje cells in the nodulus/ ventral uvula were similar to those of MSTd, but not PIVC or VIP neurons. Purkinje cells are not recorded here, but it would be useful to cite this previous study to provide context for the current results, especially since the take-home message appears to be quite different (MSTd and Purkinje neurons were similar to each other but different from PIVC and VIP neurons in Yakusheva et al. 2013, but in the current manuscript the argument is that all central areas are more or less equivalent).</p><p>b) The ternary plots in <xref ref-type="fig" rid="fig6">Figure 6</xref> seem to emphasize similarities between regions. For example, VIP and MSTd are plotted together in C, and this and the superposition of the envelopes of all of the data in D obscures the fact that these two regions actually have quite distinct velocity weights. Similarly, there are many more neurons in 6C (representing MSTd, VIP, FEF) that have 0 acceleration weights (fall along the bottom of the triangle) than in the other plots/ regions, but the envelope representation in 6D obscures that fact. Comparing this (<xref ref-type="fig" rid="fig6">Figure 6</xref>) approach to data visualization vs. the approach in <xref ref-type="fig" rid="fig10">Figure 10</xref>, it is not clear to me whether different conclusions about variability across regions are not reached partly because of differences in data analysis/ presentation. In <xref ref-type="fig" rid="fig10">Figure 10</xref>, where actual histograms are presented for position components for each region, the conclusion reached is quite different – that only MSTd has a sizable position component. Would we more easily pick out differences across regions in the velocity/ acceleration/ jerk weights of <xref ref-type="fig" rid="fig6">Figure 6</xref> if they had been represented this way (or with cumulative histograms for each of the 3 weights, as in <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>)?</p><p>c) The text describing <xref ref-type="fig" rid="fig7">Figure 7</xref> says that central brain areas have lower separability indices. Although this is true for OAs vs higher areas overall, in moving from the vestibular nuceli (VN) more centrally, there is a progressive increase in the separability index. The central cells also have more variability in their separability index than the OAs. Some comment about this seems warranted--the existing text provides too superficial consideration of the results.</p><p>2) The general message is that &quot;there is a bit of everything everywhere&quot; with only marginal differences across regions; but the complicated analysis (many parameters reported one by one, or 3 at a time <xref ref-type="fig" rid="fig6">Figure 6</xref>) and incomplete/indirect reporting (see point 3 below) leaves open another possibility: might there be clusters in the ~ 17 dimension parameter space, which would show a stronger segregation across brain regions?</p><p>3) In general, the analysis was well done and well presented, but it might be improved in several ways.</p><p>a) This model is &quot;instantaneous&quot;, meaning that the rate is related to an instantaneous value of the movement (velocity, acceleration, jerk), and that the history of cell firing is not influencing the firing rate. The three sets of curves (gaussian profile and the 2 first derivative) provide a good set of functions of time for the decomposition of PSTHs: e.g. for a simple profile with a peak, the mean/sd of the peak will correspond to the speed, the assymetry (skewness) will correspond to the acceleration, and the sharpness of the peak (kurtosis) will correspond to the jerk. The shape of the PSTH may indeed be conditioned by the sensitivity of a cell to the speed/acceleration/jerk, but alternate causes, such as long-term impact of movement parameters or of past cellular activity (i.e. violation from the &quot;instantaneous hypothesis&quot;), might also explain the shape of the PSTH; indeed, this is observed in many examples of the <xref ref-type="fig" rid="fig3">Figure 3</xref>, where significant departure from baseline are observed at the end of the psth, when virtually all movement is over for hundreds of milliseconds: see <xref ref-type="fig" rid="fig3">Figure 3</xref> (e.g. end of the PSTH Az 315 deg, Elev 45 deg) or <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> (e.g. end of Az 270, Elev -45), <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> (e.g. Az 90, Elev 0 deg), <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> (end of Az 315, Elev 45). All these example suggest that to some degree, the firing of the cells may be affected by past events (movement or cell activity) at much longer time scales than the few tens to hundred milliseconds used for the delay. Therefore, the correspondence between the weights of the fits to a gaussian profile and its first derivatives and an actual sensitivity to velocity, acceleration and jerk is somewhat questionable.</p><p>b) A second concern is linked to the use of a non-linear transformation: to describe the spatial dependency of the PSTHs, the sensitivity to the movement components (velocity, acceleration, jerk) is tuned by a non-linear transformation of the cosine of the angle between a (fitted) preferred direction -which may vary across components- and the actual movement direction. The description of these non-linear function is remarkably obfuscated (described by three successive set of variables: a,b,c in y(x)=a.b^x+c, then by y(-1),y(0),y(1), then by Z0 and k0….), but the end result is more clearly shown in <xref ref-type="fig" rid="fig9">Figure 9</xref>. One of the important points is that these non-linear functions are not mapping the cosine result (range [-1,1]) onto the full [-1,1] range, but onto a subset of this range. Then, the fit predicts the (spatial dependency of the) rate based on a weighted sum of the non-linearly transformed cosine function. In the MS, theses weights of the components of the fit are used to compare the sensitivities of the cells (e.g. <xref ref-type="fig" rid="fig6">Figure 6</xref>). This procedures calls for a few comments:</p><p>First, it is unclear if non-linearity is really necessary: inspection of the classes of the 'non-linear functions' (<xref ref-type="fig" rid="fig9">Figure 9</xref>) shows set of profiles close to linearity which could be as well approximated by linear (ax+b) functions; the main difference across classes seems more on the target interval than on the shape. The non-linear version will always do better since it permits a finer tuning (1 more parameter), but the benefit may be only marginal (I think the authors could reasonably easily test this) and come at the price a quite obscure process.</p><p>Second, because the range over which the cosine is mapped by the non-linear function may be much smaller than the -1,1 range, the weights are not reflecting the two qualitative aspects of the spatial tuning: for example, if a cell has a large gaussian PSTH in all direction, with a 10% modulation of the amplitude of the peak, this will show up as a strong weight of velocity (and a 'broad-positive' non linear function), while it would indeed better described as a strong sensitivity to speed (length of the velocity vector) but a weak sensitivity to velocity (as a vector). In this case, the large weight of the velocity would correspond only to a small dynamic range over spatial orientations; the same large weight for another cell with cosine tuning would correspond to a full dynamic range over spatial orientations. Therefore, a single value of the weight is mixing qualitatively different information (e.g. speed value as in <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3D</xref>, versus velocity vector as in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4D</xref>). The only things that disambiguate the information are the parameters of the non-linear function, but 1) they are not so trivial (the authors found it is easier to report them as 'arbitrary' categories…), 2) they are reported independently from the values of the weight. A linear version of the transformation ('a.cos(x)+b', provided that it would not degrade too much the performance of the fits) could be easier to report and avoid the categorization: 'a' (in the a.cos(x)+b) would signal the dynamic range over 3D, and 'b' would signal the directionaly-invariant component of the response; it would become possible for example to generate bivariate plots (such as 'weight' vs 'a') which would answer simple questions such as: is the dynamic range for velocity coding identical in all brain areas for strongly velocity-tuned cells? Currently, the choice of reporting makes the answer to this question unclear. Since some of their conclusion is that there are no regional differences, I do not feel so certain they took the most powerful approach to reveal them.</p><p>c) It is not clear why the color-coded stacked bar plots are used in <xref ref-type="fig" rid="fig7">Figures 7B-D</xref>, and <xref ref-type="fig" rid="fig10">Figure 10C</xref> – here the color map is representing PD-angles, which presumably vary continuously, but they have been categorized unnecessarily – cumulative histograms, or at least a continuous color map, here could allow more direct comparisons across regions.</p><p>4) The discussion could be more enlightening:</p><p>General interest could be broadened by a brief comparison with other sensory systems</p><p>Why would the brain maintain such complicated representation of movement (a parameter and its two first derivatives or its integral, with unrelated preferred directions in many cases and non-linear spatial sensitivity to departure from preferred direction) across all brain areas, without further processing beyond the first synapse?</p><p>The last paragraph is obscure: what would be the relation between tilt/translation disambiguation and the mixtures of sensitivity described in the study?</p><p>Some of the big picture, clearly laid out in the Introduction, is lost in the Results and Discussion sections. For example, it would be useful for the authors to remind us of why we care about space time separability</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.20787.025</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) The main conclusion, that the big signal transformation happened at the first processing stage and that all the higher vestibular areas are more similar in their coding properties, is well supported. However, the difficulty for the reader to draw any conclusion beyond this creates an impression that not much was gained from the massive effort invested. A more nuanced treatment of differences between central brain areas seems merited, and would do the rich data set more justice.</italic> </p><p>It was indeed a massive effort to do this analysis that took many years and multiple people. As summarized below, following the reviewers’ comments, we now re-ran the whole analysis again, and the results have been simplified significantly (thank you reviewers!). We have also tried to better highlight the main conclusions: (1) large differences between brainstem and otolith afferents, (2) similar spatio-temporal properties in central areas – however, there are systematic differences in response amplitude and spontaneous firing rate (3) strong presence of both velocity and jerk tuning in central neurons, (4) strongly non-linear tuning, particularly for velocity and jerk in central neurons, (5) position-tuning mostly in MSTd. We have also substantially beefed up the Discussion to address the reviewers’ concerns.</p><p><italic>Some specific examples, raised by the Reviewers:</italic> </p><p><italic>a) A previous study from this group (Yakusheva et al., J Neurosci 2013) had shown that vestibular responses of Purkinje cells in the nodulus/ ventral uvula were similar to those of MSTd, but not PIVC or VIP neurons. Purkinje cells are not recorded here, but it would be useful to cite this previous study to provide context for the current results, especially since the take-home message appears to be quite different (MSTd and Purkinje neurons were similar to each other but different from PIVC and VIP neurons in Yakusheva et al. 2013, but in the current manuscript the argument is that all central areas are more or less equivalent).</italic> </p><p>We have now added this reference, and also pointed out the differences between central regions. Most importantly, the present analysis is not directly comparable with the previous analysis, which was restricted to motion in a single plane, did not include the jerk component, and used a different form of nonlinearity. Yet, results in this paper and in the previous analyses (including Chen et al. 2011c) are rather consistent. This is now better highlighted in the Discussion.</p><p> <italic>b) The ternary plots in <xref ref-type="fig" rid="fig6">Figure 6</xref> seem to emphasize similarities between regions. For example, VIP and MSTd are plotted together in C, and this and the superposition of the envelopes of all of the data in D obscures the fact that these two regions actually have quite distinct velocity weights. Similarly, there are many more neurons in 6C (representing MSTd, VIP, FEF) that have 0 acceleration weights (fall along the bottom of the triangle) than in the other plots/ regions, but the envelope representation in 6D obscures that fact. Comparing this (<xref ref-type="fig" rid="fig6">Figure 6</xref>) approach to data visualization vs. the approach in <xref ref-type="fig" rid="fig10">Figure 10</xref>, it is not clear to me whether different conclusions about variability across regions are not reached partly because of differences in data analysis/ presentation. In <xref ref-type="fig" rid="fig10">Figure 10</xref>, where actual histograms are presented for position components for each region, the conclusion reached is quite different – that only MSTd has a sizable position component. Would we more easily pick out differences across regions in the velocity/ acceleration/ jerk weights of <xref ref-type="fig" rid="fig6">Figure 6</xref> if they had been represented this way (or with cumulative histograms for each of the 3 weights, as in <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>)?</italic> </p><p>We thank the reviewer for this suggestion. We found that cumulative distribution plots did indeed provide a convenient way to compare brain areas, so we have added cumulative plots to <xref ref-type="fig" rid="fig6">Figure 6</xref>. We have also modified the ternary plots, as described next.</p><p> <italic>c) The text describing <xref ref-type="fig" rid="fig7">Figure 7</xref> says that central brain areas have lower separability indices. Although this is true for OAs vs higher areas overall, in moving from the vestibular nuceli (VN) more centrally, there is a progressive increase in the separability index. The central cells also have more variability in their separability index than the OAs. Some comment about this seems warranted--the existing text provides too superficial consideration of the results.</italic> </p><p>Indeed, we found that VN and CN have lower separability indexes than other brain regions. We have found that the PD of the 3 components are less aligned in VN and CN compared to other brain regions, which explains the lower separability, and we now describe this in the text.</p><p><italic>2) The general message is that &quot;there is a bit of everything everywhere&quot; with only marginal differences across regions; but the complicated analysis (many parameters reported one by one, or 3 at a time <xref ref-type="fig" rid="fig6">Figure 6</xref>) and incomplete/indirect reporting (see point 3 below) leaves open another possibility: might there be clusters in the ~ 17 dimension parameter space, which would show a stronger segregation across brain regions?</italic> </p><p>We have conducted a variety of cluster analyses as well as factor analyses. We found that the results of these analyses resemble the results described here. The OAs stand out from other cells very clearly, while the other neuronal populations tend to overlap in a single cloud of dots. MSTd, which tends to have the highest velocity responses, tends to be somewhat offset from, but still overlaps largely with the other regions. Thus, as this cluster analysis does not add anything new, we have not included it in the manuscript. We hope that we managed to simplify the reporting of our results, in particular by adopting the simpler non-linearity suggested by the reviewers (where the model with the largest number of parameters now has 14, not 17).</p><p><italic>3) In general, the analysis was well done and well presented, but it might be improved in several ways.</italic> </p><p><italic>a) This model is &quot;instantaneous&quot;, meaning that the rate is related to an instantaneous value of the movement (velocity, acceleration, jerk), and that the history of cell firing is not influencing the firing rate. The three sets of curves (gaussian profile and the 2 first derivative) provide a good set of functions of time for the decomposition of PSTHs: e.g. for a simple profile with a peak, the mean/sd of the peak will correspond to the speed, the assymetry (skewness) will correspond to the acceleration, and the sharpness of the peak (kurtosis) will correspond to the jerk. The shape of the PSTH may indeed be conditioned by the sensitivity of a cell to the speed/acceleration/jerk, but alternate causes, such as long-term impact of movement parameters or of past cellular activity (i.e. violation from the &quot;instantaneous hypothesis&quot;), might also explain the shape of the PSTH; indeed, this is observed in many examples of the <xref ref-type="fig" rid="fig3">Figure 3</xref>, where significant departure from baseline are observed at the end of the psth, when virtually all movement is over for hundreds of milliseconds: see <xref ref-type="fig" rid="fig3">Figure 3</xref> (e.g. end of the PSTH Az 315 deg, Elev 45 deg) or <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> (e.g. end of Az 270, Elev -45), <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> (e.g. Az 90, Elev 0 deg), <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> (end of Az 315, Elev 45). All these example suggest that to some degree, the firing of the cells may be affected by past events (movement or cell activity) at much longer time scales than the few tens to hundred milliseconds used for the delay. Therefore, the correspondence between the weights of the fits to a gaussian profile and its first derivatives and an actual sensitivity to velocity, acceleration and jerk is somewhat questionable.</italic> </p><p>From a purely descriptive point of view, responses that persist through the end of the trial may be explained by sensitivity to position that has been modeled by the PVAJ model (<xref ref-type="fig" rid="fig10">Figure 10</xref>). However, we also acknowledge that our model is essentially descriptive and not mechanistic. Therefore, the dynamic responses that we attribute to velocity or jerk could be the result of non-linear dynamic processes of a more complex nature than simple integration or differentiation. In other words, our model is limited to describing spatiotemporal dynamics as a combination of basis functions that are related to the stimulus, rather than as a combination of inputs to each neuron. While the latter type of model may be possible, we feel that it would be a major undertaking and may not be sufficiently constrained to be successful. Despite this limitation (which is now added to the Discussion), we think that our approach still adequately characterizes the nature of the transformations of vestibular signals.</p><p> <italic>b) A second concern is linked to the use of a non-linear transformation: to describe the spatial dependency of the PSTHs, the sensitivity to the movement components (velocity, acceleration, jerk) is tuned by a non-linear transformation of the cosine of the angle between a (fitted) preferred direction -which may vary across components- and the actual movement direction. The description of these non-linear function is remarkably obfuscated (described by three successive set of variables: a,b,c in y(x)=a.b^x+c, then by y(-1),y(0),y(1), then by Z0 and k0….), but the end result is more clearly shown in <xref ref-type="fig" rid="fig9">Figure 9</xref>.</italic> </p><p>We have completely changed (and thus greatly simplified) the manuscript based on these suggestions. Thank you! (a great example of a useful review process!)</p><p><italic>One of the important points is that these non-linear functions are not mapping the cosine result (range [-1,1]) onto the full [-1,1] range, but onto a subset of this range. Then, the fit predicts the (spatial dependency of the) rate based on a weighted sum of the non-linearly transformed cosine function. In the MS, theses weights of the components of the fit are used to compare the sensitivities of the cells (e.g. <xref ref-type="fig" rid="fig6">Figure 6</xref>). This procedures calls for a few comments:</italic> </p><p><italic>First,, it is unclear if non-linearity is really necessary: inspection of the classes of the 'non-linear functions' (<xref ref-type="fig" rid="fig9">Figure 9</xref>) shows set of profiles close to linearity which could be as well approximated by linear (ax+b) functions; the main difference across classes seems more on the target interval than on the shape. The non-linear version will always do better since it permits a finer tuning (1 more parameter), but the benefit may be only marginal (I think the authors could reasonably easily test this) and come at the price a quite obscure process.</italic> </p><p>We thank the reviewer for this suggestion. We fitted an affine function, and found, indeed, very similar results (as described in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We are now using these new fits throughout the manuscript. Note that (ax+b) is not a linear function but an affine function (in linear algebra, two necessary conditions for a function f(x) to be linear are f(0)=0 and f(a+b)=f(a)+f(b)) and therefore this function is still referred to as non-linear through the text.</p><p><italic>Second, because the range over which the cosine is mapped by the non-linear function may be much smaller than the -1,1 range, the weights are not reflecting the two qualitative aspects of the spatial tuning: for example, if a cell has a large gaussian PSTH in all direction, with a 10% modulation of the amplitude of the peak, this will show up as a strong weight of velocity (and a 'broad-positive' non linear function), while it would indeed better described as a strong sensitivity to speed (length of the velocity vector) but a weak sensitivity to velocity (as a vector). In this case, the large weight of the velocity would correspond only to a small dynamic range over spatial orientations; the same large weight for another cell with cosine tuning would correspond to a full dynamic range over spatial orientations. Therefore, a single value of the weight is mixing qualitatively different information (e.g. speed value as in <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3D</xref>, versus velocity vector as in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4D</xref>). The only things that disambiguate the information are the parameters of the non-linear function, but 1) they are not so trivial (the authors found it is easier to report them as 'arbitrary' categories…), 2) they are reported independently from the values of the weight. A linear version of the transformation ('a.cos(x)+b', provided that it would not degrade too much the performance of the fits) could be easier to report and avoid the categorization: 'a' (in the a.cos(x)+b) would signal the dynamic range over 3D, and 'b' would signal the directionaly-invariant component of the response; it would become possible for example to generate bivariate plots (such as 'weight' vs 'a') which would answer simple questions such as: is the dynamic range for velocity coding identical in all brain areas for strongly velocity-tuned cells? Currently, the choice of reporting makes the answer to this question unclear. Since some of their conclusion is that there are no regional differences, I do not feel so certain they took the most powerful approach to reveal them.</italic> </p><p>We have followed the reviewer’s suggestions, for which we are thankful. More precisely, we now parametrize the non-linear function as y(x) = o + (1-|o|).cos(x) (ensuring that the function is normalized, such tht |y(x)|&lt;=1 and y(-1)=-1 or y(1)=1). Next we took the weight w into account and plotted w.o as a function of w.(1-|o|). The term w.o represents the directionally-invariant component (we called it ‘offset’) and the term w.(1-|o|) represents the dynamic range (we called it ‘cosine tuning’).</p><p> <italic>c) It is not clear why the color-coded stacked bar plots are used in <xref ref-type="fig" rid="fig7">Figures 7B-D</xref>, and <xref ref-type="fig" rid="fig10">Figure 10C</xref> – here the color map is representing PD-angles, which presumably vary continuously, but they have been categorized unnecessarily – cumulative histograms, or at least a continuous color map, here could allow more direct comparisons across regions.</italic> </p><p>We have introduced continuous color maps in these plots and also reversed the green and red colors (red colors are now indicating aligned PD).</p><p><italic>4) The Discussion could be more enlightening:</italic> </p><p><italic>General interest could be broadened by a brief comparison with other sensory systems</italic> </p><p><italic>Why would the brain maintain such complicated representation of movement (a parameter and its two first derivatives or its integral, with unrelated preferred directions in many cases and non-linear spatial sensitivity to departure from preferred direction) across all brain areas, without further processing beyond the first synapse?</italic> </p><p><italic>The last paragraph is obscure: what would be the relation between tilt/translation disambiguation and the mixtures of sensitivity described in the study?</italic> </p><p><italic>Some of the big picture, clearly laid out in the Introduction, is lost in the Results and Discussion sections. For example, it would be useful for the authors to remind us of why we care about space time separability</italic> </p><p>We have tried to re-work and improve the Discussion. We rewrote the last paragraph to provide a clearer hypothesis about the role of non-linear encoding of motion, and referred to previous work of ‘mixed selectivity’ in the prefrontal and parietal cortex.</p></body></sub-article></article>