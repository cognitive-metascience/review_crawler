<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">50933</article-id><article-id pub-id-type="doi">10.7554/eLife.50933</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Feedback contribution to surface motion perception in the human early visual cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-152702"><name><surname>Marquardt</surname><given-names>Ingo</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5178-9951</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-57716"><name><surname>De Weerd</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-153196"><name><surname>Schneider</surname><given-names>Marian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-133513"><name><surname>Gulban</surname><given-names>Omer Faruk</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7761-3727</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-153197"><name><surname>Ivanov</surname><given-names>Dimo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-175615"><name><surname>Wang</surname><given-names>Yawen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-153198"><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="corresp" rid="cor3">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Cognitive Neuroscience</institution>, <institution>Maastricht University</institution>, <addr-line><named-content content-type="city">Maastricht</named-content></addr-line>, <country>Netherlands</country></aff><aff id="aff2"><institution content-type="dept">Faculty of Psychology and Neuroscience</institution>, <institution>Maastricht University</institution>, <addr-line><named-content content-type="city">Maastricht</named-content></addr-line>, <country>Netherlands</country></aff><aff id="aff3"><institution content-type="dept">Techna Institute &amp; Koerner Scientist in MR Imaging</institution>, <institution>University Health Network</institution>, <addr-line><named-content content-type="city">Toronto</named-content></addr-line>, <country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-74960"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution>, <country>Germany</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>ingo.marquardt@maastrichtuniversity.nl</email> (IM);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>p.deweerd@maastrichtuniversity.nl</email> (Pd);</corresp><corresp id="cor3"><label>*</label>For correspondence: <email>Kamil.Uludag@rmp.uhn.ca</email> (KU);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>04</day><month>06</month><year>2020</year></pub-date><volume>9</volume><elocation-id>e50933</elocation-id><history><date date-type="received"><day>08</day><month>08</month><year>2019</year></date><date date-type="accepted"><day>03</day><month>06</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Marquardt et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Marquardt et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-50933-v2.pdf"/><abstract><p>Human visual surface perception has neural correlates in early visual cortex, but the role of feedback during surface segmentation in human early visual cortex remains unknown. Feedback projections preferentially enter superficial and deep anatomical layers, which provides a hypothesis for the cortical depth distribution of fMRI activity related to feedback. Using ultra-high field fMRI, we report a depth distribution of activation in line with feedback during the (illusory) perception of surface motion. Our results fit with a signal re-entering in superficial depths of V1, followed by a feedforward sweep of the re-entered information through V2 and V3. The magnitude and sign of the BOLD response strongly depended on the presence of texture in the background, and was additionally modulated by the presence of illusory motion perception compatible with feedback. In summary, the present study demonstrates the potential of depth-resolved fMRI in tackling biomechanical questions on perception.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>452-11-002</award-id><principal-award-recipient><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>406-14-085</award-id><principal-award-recipient><name><surname>Marquardt</surname><given-names>Ingo</given-names></name><name><surname>Uludağ</surname><given-names>Kâmil</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Healthy participants gave informed consent before the experiment, and the study protocol was approved by the local ethics committee of the Faculty for Psychology &amp; Neuroscience, Maastricht University. (reference  number: ERCPN 180_03_06_2017 ).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The fMRI dataset, experimental stimuli, and analysis code are publicly available. The fMRI dataset is available on Zenodo (https://doi.org/10.5281/zenodo.3366301). The software used for the presentation of retinotopic mapping stimuli, and for the corresponding analysis, is available on github (https://github.com/ingo-m/pyprf). Example videos of the main experimental stimuli are available on Zenodo (https://doi.org/10.5281/zenodo.2583017). If you would like to reproduce the experimental stimuli, the respective PsychoPy code can be found on github (https://github.com/ingo-m/PacMan/tree/master/stimuli/experiment). The respective repository also contains the analysis code and a brief description how to reproduce the analysis (https://github.com/ingo-m/PacMan). High-level visualisations (e.g. cortical depth profiles &amp; signal timecourses) and group-level statistical tests are implemented in a separate repository (https://github.com/ingo-m/py_depthsampling/tree/PacMan).</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Marquardt</collab><collab>De Weerd</collab><collab>Schneider</collab><collab>Gulban</collab><collab>Ivanov</collab><collab>Uludağ</collab></person-group><year iso-8601-date="2019">2019</year><source>Dataset: Feedback contribution to surface motion perception in the human early visual cortex</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3366301">https://doi.org/10.5281/zenodo.3366301</ext-link><comment>Zenodo, doi.org/10.5281/zenodo.3366301</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-50933-supp-v2.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>