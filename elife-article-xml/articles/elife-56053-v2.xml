<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">56053</article-id><article-id pub-id-type="doi">10.7554/eLife.56053</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Population coupling predicts the plasticity of stimulus responses in cortical circuits</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-175905"><name><surname>Sweeney</surname><given-names>Yann</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2164-2438</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-17772"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4507-8648</contrib-id><email>c.clopath@imperial.ac.uk</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>Department of Bioengineering, Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>21</day><month>04</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e56053</elocation-id><history><date date-type="received" iso-8601-date="2020-02-14"><day>14</day><month>02</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-04-16"><day>16</day><month>04</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Sweeney and Clopath</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Sweeney and Clopath</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-56053-v2.pdf"/><abstract><p>Some neurons have stimulus responses that are stable over days, whereas other neurons have highly plastic stimulus responses. Using a recurrent network model, we explore whether this could be due to an underlying diversity in their synaptic plasticity. We find that, in a network with diverse learning rates, neurons with fast rates are more coupled to population activity than neurons with slow rates. This plasticity-coupling link predicts that neurons with high population coupling exhibit more long-term stimulus response variability than neurons with low population coupling. We substantiate this prediction using recordings from the Allen Brain Observatory, finding that a neuron’s population coupling is correlated with the plasticity of its orientation preference. Simulations of a simple perceptual learning task suggest a particular functional architecture: a stable ‘backbone’ of stimulus representation formed by neurons with low population coupling, on top of which lies a flexible substrate of neurons with high population coupling.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>synaptic plasticity</kwd><kwd>visual cortex</kwd><kwd>neural network models</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/N013956/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/N019008/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>200790/Z/16/Z</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/R035806/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>564408</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Networks simulations and in vivo imaging suggest a stable backbone of stimulus representation formed by neurons with low population coupling, alongside a flexible substrate of neurons with high population coupling.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The brain encodes information about the external world via its neural activity. One aspect of such encoding is that neurons in sensory cortex often have a preferred stimulus which evokes a stronger response than other stimuli. These stimulus responses can change during learning or adaptation: if a particular stimulus feature is overexpressed within an environment, for example, more neurons will be recruited to encode this feature (<xref ref-type="bibr" rid="bib44">Sengpiel et al., 1999</xref>). Advances in neural imaging techniques allow us to interrogate such changes by tracking stimulus responses of hundreds of neurons over many days in vivo (<xref ref-type="bibr" rid="bib3">Andermann, 2010</xref>; <xref ref-type="bibr" rid="bib27">Mank et al., 2008</xref>). These recordings reveal a substantial, and puzzling, variability in the long-term stability of responses in sensory cortex: some neurons retain highly stable preferences to specific stimuli, whereas the stimulus preference of other neurons change from day to day (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>; <xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Poort et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Lütcke et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Rule et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>). The degree of stimulus response stability typically depends on brain region; whisking responses in mouse barrel cortex are highly plastic, whereas visual responses in mouse V1 are more stable but still exhibit fluctuations (<xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib26">Lütcke et al., 2013</xref>). Moreover, it is possible to induce stimulus response plasticity through perturbations such as sensory deprivation (<xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>), or to increase task-related stimulus response stability through rewarded learning (<xref ref-type="bibr" rid="bib35">Poort et al., 2015</xref>).</p><p>Current theories which address the long-term variability of stimulus responses primarily ask how motor learning occurs with unstable representations (<xref ref-type="bibr" rid="bib12">Driscoll et al., 2017</xref>; <xref ref-type="bibr" rid="bib1">Ajemian et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Rokni et al., 2007</xref>), or seek to explain it as a form of probabilistic sampling (<xref ref-type="bibr" rid="bib21">Kappel et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Kappel et al., 2015</xref>). Although the stability of neural representation is correlated with firing rate in hippocampal place cells (<xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki, 2016</xref>) and in visual cortex (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>), it is not known how cellular or network properties influence a neuron’s stimulus response stability (<xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>). We are therefore lacking a theory of why some neurons’ stimulus responses are more stable than others, and how this affects perception and learning. By investigating how synaptic plasticity mediates stimulus response variability, we aim here to establish how this diversity of stimulus response stability emerges, and whether it is functionally relevant.</p><p>We propose that the observed diversity of stimulus response stability may be explained by a diversity of neurons’ inherent plasticity (or learning rate) within a network. Consequently, we explore how diverse learning rates across neurons impact synaptic connectivity in a recurrent network model of mouse visual cortex. We find that neurons with fast learning rates exhibit more variability of their stimulus selectivity than neurons with slow learning rates. Intriguingly, we also find that fast neurons have higher population coupling, a measure of how correlated an individual neurons activity is with the rest of the population (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>).</p><p>This unexpected plasticity-coupling link, in which more plastic neurons are also more coupled to the rest of the population, provides a mechanism for the diverse population coupling previously observed in sensory cortex (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). Moreover, the plasticity-coupling link predicts that neurons with high population coupling exhibit more long-term stimulus response variability than neurons with low population coupling. We substantiate this prediction with in vivo calcium imaging of mouse visual cortex from the Allen Brain Observatory (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>), finding that a neuron is more likely to exhibit variability of its orientation preference if it has high population coupling.</p><p>Finally, we explore the functional implications of both diverse population coupling and diverse learning rates within our network model. We find that strong population coupling helps plastic neurons alter their stimulus preference during a simple perceptual learning task, but hinders the ability of stable neurons to provide an instructive signal for learning. The plasticity-coupling link exploits this dependence by ensuring that highly plastic neurons - the substrate for perceptual learning - are strongly coupled to the population, while less plastic neurons are weakly coupled and act as a stable ‘backbone’ of stimulus representation.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A ‘plasticity-coupling link’ emerges in networks with diverse learning rates: fast neurons have higher population coupling than slow neurons</title><p>Our aim is to explore whether the diversity of stimulus response stability can be explained by a diversity of neurons’ inherent plasticity (or learning rate) within a network. To this end, we use network simulations to characterise the impact of diverse learning rates on recurrent synaptic connectivity in sensory cortex.</p><p>We first explore the impact of diverse learning rates in a simple, fully connected network of rate neurons (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, Materials and methods). Excitatory recurrent synapses in our network undergo Hebbian plasticity and synaptic scaling, while inhibitory synapses undergo homeostatic inhibitory plasticity (<xref ref-type="bibr" rid="bib50">Vogels et al., 2011</xref>). Extending traditional models of Hebbian plasticity in which synaptic weight updates depend only on the correlation of pre- and post-synaptic activity, we introduce diversity by assigning either a fast or slow Hebbian learning rate (<inline-formula><mml:math id="inf1"><mml:mi>α</mml:mi></mml:math></inline-formula>) to individual neurons. The learning rate is expressed postsynaptically, such that the synaptic input weights onto neurons with a large <inline-formula><mml:math id="inf2"><mml:mi>α</mml:mi></mml:math></inline-formula> are more plastic than those with a small <inline-formula><mml:math id="inf3"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Neurons with fast learning rates develop more non-specific connections, and higher population coupling, than neurons with slow learning rates.</title><p>(<bold>A</bold>) Connection diagram of the recurrent network model with excitatory (E) and inhibitory (I) neurons. Dashed lines denote plastic synapses and solid lines denote static synapses. (<bold>B</bold>) Synaptic weight dynamics during presentation of random sequences of stimuli to the network. Synaptic inputs onto slow neurons (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, gray) and onto fast neurons (<inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, black). Synapses between neurons which share the same feedforward stimulus preference (specific) have solid lines, and synapses between neurons which have different feedforward stimulus preference (non-specific) have dashed lines. (<bold>C</bold>) Excitatory synaptic weight matrix of the recurrent network after synaptic plasticity. Neuron IDs are organised by feedforward stimulus preference. For each of the four stimulus groups the first six neurons are slow (<inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) and the next six neurons are fast (<inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>). (<bold>D</bold>) Connection specificity (ratio of specific to non-specific synaptic input strength) after synaptic plasticity for slow and fast neurons (left), and the standard deviation over time of the connection specificity for slow and fast neurons (right). (<bold>E</bold>) Amount of non-specific (light blue) and specific (dark blue) synaptic input for neurons in a network with diverse learning rates, as the learning rate of the postsynaptic neuron is varied along a logarithmic scale. Population coupling of neurons with different learning rates (red points).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Plasticity-coupling link requires moderate noise and slow synaptic scaling.</title><p>The slope of the linear dependence between <inline-formula><mml:math id="inf8"><mml:mi>α</mml:mi></mml:math></inline-formula> and population coupling within a network with diverse <inline-formula><mml:math id="inf9"><mml:mi>α</mml:mi></mml:math></inline-formula>, for different values of the synaptic scaling rate (<inline-formula><mml:math id="inf10"><mml:mi>ζ</mml:mi></mml:math></inline-formula>) and injected noise (<inline-formula><mml:math id="inf11"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula>). The presence of noise introduces transient correlations across the network which lead to fluctuations of both specific and non-specific synaptic weights. This ensures that non-specific synaptic weights do not all tend towards zero. Likewise, if synaptic scaling is too fast compared with Hebbian plasticity - contrary to experimentally observed timescales (<xref ref-type="bibr" rid="bib49">Turrigiano et al., 1998</xref>) - then only specific synapses, which share highly correlated inputs, can sustain strong weights while non-specific synapses tend towards zero.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig1-figsupp1-v2.tif"/></fig></fig-group><p>Each neuron receives feedforward input from 1 of 4 possible visual stimuli representing gratings of different orientations, and independent noise. The Hebbian plasticity rule potentiates connections between neurons which share the same feedforward stimulus preference, due to their coactivity. This drives the emergence of strong bidirectional connections amongst stimulus-specific groups of neurons, while the remaining non-specific connections weaken (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>; <xref ref-type="bibr" rid="bib22">Ko et al., 2013</xref>; <xref ref-type="bibr" rid="bib8">Clopath et al., 2010</xref>). Fast neurons develop these strong, specific connections sooner than slow neurons (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, solid lines). However, the increased learning rate also leads to stronger synaptic weight fluctuations. These fluctuations occur both for synapses from neurons which share stimulus preference (specific connections) and for synapses from neurons which have different stimulus preference (non-specific connections). For slow neurons, in contrast, non-specific and specific connections tend towards either zero or the maximum synaptic weights respectively, remaining relatively stable after convergence (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, black lines). This leads to connection specificity that is stronger and more stable compared with fast neurons (<xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>The observed dependence of connection specificity on learning rate is conserved if, instead of just two values of <inline-formula><mml:math id="inf12"><mml:mi>α</mml:mi></mml:math></inline-formula> representing either fast or slow neurons, we simulate plasticity in a network of neurons with a diverse range of <inline-formula><mml:math id="inf13"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Increasing <inline-formula><mml:math id="inf14"><mml:mi>α</mml:mi></mml:math></inline-formula> predominantly drives an increase in non-specific connections rather than a decrease in specific connections. This leads to an overall increase in the amount of synaptic input amongst neurons with high <inline-formula><mml:math id="inf15"><mml:mi>α</mml:mi></mml:math></inline-formula>.</p><p>Population coupling is a recently characterised feature of neural activity which describes how correlated a neuron’s activity is with the overall population activity, and which can be measured from calcium imaging recordings of neural activity (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). Since population coupling is correlated with the amount of local synaptic input in cortical networks (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>), this measure could be a useful and experimentally observable proxy for the specificity of recurrent connectivity in our networks. We therefore investigate its suitability by measuring the population coupling of neurons in our network after synaptic plasticity (Materials and methods). Interestingly, population coupling increases with learning rate, closely following the dependence of non-specific connectivity on <inline-formula><mml:math id="inf16"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, red points).</p><p>The dependence of a neuron’s population coupling on its learning rate <inline-formula><mml:math id="inf17"><mml:mi>α</mml:mi></mml:math></inline-formula>, which we call a ‘plasticity-coupling link’, could provide a framework for relating the functional role of a neuron within a network to its dynamics. We therefore explore conditions necessary for this plasticity-coupling link by embedding a single plastic neuron within a static network and varying key model parameters (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). A strong plasticity-coupling link requires both moderate amounts of noise within the network and relatively slow synaptic scaling compared with Hebbian plasticity, in agreement with experimental data (<xref ref-type="bibr" rid="bib49">Turrigiano et al., 1998</xref>). We next investigate whether this plasticity-coupling link is robustly observed in more biologically detailed networks.</p></sec><sec id="s2-2"><title>Diverse population coupling emerges in cortical networks with diverse learning rates</title><p>As the plasticity-coupling link is robustly observed in a fully-connected small network with simple stimulus responses, we next investigate i) whether the plasticity-coupling link is also present in larger networks which more accurately represent the synaptic connectivity and stimulus response properties observed in mouse visual cortex, and ii) whether the diverse population coupling observed in sensory cortex emerges simply by introducing diverse learning rates (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>).</p><p>We explore this in a network of 250 excitatory neurons with randomly generated Gabor receptive fields. This network has been shown to reproduce receptive field correlations and synaptic weight statistics that are observed in mouse visual cortex (<xref ref-type="bibr" rid="bib51">Watanabe et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Cossell et al., 2015</xref>) (see Materials and methods section; Receptive-field based network model). We compare networks in which there is a uniform <inline-formula><mml:math id="inf18"><mml:mi>α</mml:mi></mml:math></inline-formula> across all neurons to networks with diverse <inline-formula><mml:math id="inf19"><mml:mi>α</mml:mi></mml:math></inline-formula>.</p><p>Both networks with uniform <inline-formula><mml:math id="inf20"><mml:mi>α</mml:mi></mml:math></inline-formula> and networks with diverse <inline-formula><mml:math id="inf21"><mml:mi>α</mml:mi></mml:math></inline-formula> develop strong synaptic connections between neurons with similar receptive fields. There is, however, a broader range of summed synaptic inputs in diverse networks, when compared with uniform networks (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). This occurs because the total excitatory synaptic input onto a neuron covaries with <inline-formula><mml:math id="inf22"><mml:mi>α</mml:mi></mml:math></inline-formula> in the diverse network (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Diverse population coupling from diverse learning rates in a cortical network model.</title><p>(<bold>A</bold>) Distribution of summed synaptic input onto each neuron in networks with diverse learning rates (blue), and networks with uniform learning rates (green) (<bold>B</bold>) Mean recurrent excitatory synaptic input received by a neuron correlates with its learning rate, <inline-formula><mml:math id="inf23"><mml:mi>α</mml:mi></mml:math></inline-formula>. (<bold>C</bold>) The population coupling of a neuron is correlated with the amount of recurrent synaptic input it receives for the network with diverse learning rates (blue), as opposed to the network with uniform learning rates (green). Error bars for each bin show 95% confidence interval. Lines show linear regression fit for all datapoints (shaded coloured area indicates 95% confidence interval) (<bold>D</bold>) Diverse population coupling occurs in our recurrent network model. The population coupling distribution is wider for networks with diverse learning rates (blue) compared to networks with uniform learning rates (green, p&lt;1e-5, Levene test). (<bold>E</bold>) The variability of stimulus selectivity is correlated with population coupling in networks with diverse learning rates (blue, r = 0.18, p=1e-5, Spearman correlation), but not in networks with uniform learning rates (green, p=0.4, Spearman correlation). Lines show linear regression fit for all datapoints (shaded coloured area indicates 95% confidence interval) (<bold>F</bold>) Dependence of network properties on the amplitude of injected noise (<inline-formula><mml:math id="inf24"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula>). Stimulus selectivity decreases with increasing <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula> for networks with both diverse and uniform learning rates (blue and green lines, respectively). The distribution of population coupling broadens with increasing noise for networks with diverse learning rates, but not for networks with uniform learning rates (blue and green dashed lines, respectively). Panel A-E use <inline-formula><mml:math id="inf26"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>5.0</mml:mn></mml:mrow></mml:math></inline-formula> (shaded gray area).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Dependence of the distribution of population coupling on the range of learning rate (<bold>A-C</bold>) and the amplitude of injected noise (<bold>D</bold>).</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig2-figsupp1-v2.tif"/></fig></fig-group><p>In agreement with our previous observations, the population coupling of a neuron is determined by its total excitatory synaptic input in networks with diverse <inline-formula><mml:math id="inf27"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, blue line. r = 0.29, p&lt;1e-5, Spearman correlation). Diverse learning rates within a cortical network indeed lead to a broad distribution of population coupling, as observed by <xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref>; <xref ref-type="fig" rid="fig2">Figure 2D</xref>, blue). Although the network with uniform <inline-formula><mml:math id="inf28"><mml:mi>α</mml:mi></mml:math></inline-formula> also exhibits some heterogeneity of population coupling, in this network a neuron’s population coupling is not correlated with the amount of synaptic input it receives (<xref ref-type="fig" rid="fig2">Figure 2C,D</xref>, green. p=0.52, Spearman correlation). The network with diverse <inline-formula><mml:math id="inf29"><mml:mi>α</mml:mi></mml:math></inline-formula> exhibits population coupling which is both broadly distributed and correlated with synaptic input - in agreement with (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>) - while the absence of correlation in the network with uniform <inline-formula><mml:math id="inf30"><mml:mi>α</mml:mi></mml:math></inline-formula> is in contrast with experiments which demonstrate a correlation between synaptic input and population coupling (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). This suggests that networks with diverse learning rates better match experimental observations than networks with uniform learning rates.</p><p>We next investigate the long-term variability of stimulus selectivity within both networks by measuring the fluctuations of neuronal stimulus selectivity throughout a period of synaptic plasticity (Materials and methods). We find that the magnitude of these fluctuations is independent of population coupling in the uniform network (p=0.4, Spearman correlation), but is correlated with population coupling in the diverse network (r = 0.18, p=1e-5, Spearman correlation <xref ref-type="fig" rid="fig2">Figure 2E</xref>).</p><p>We then characterise the dependence of population coupling and stimulus selectivity on the amplitude of external input noise, again for networks with either uniform or diverse <inline-formula><mml:math id="inf31"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). As the majority of excitatory synaptic input received by neurons in visual cortex is recurrent, we simulate a regime with relatively weak feedforward stimulus-related input and high noise for <xref ref-type="fig" rid="fig2">Figure 2A-E</xref> (<xref ref-type="bibr" rid="bib11">Cossell et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Lin et al., 2015</xref>). This results in a broader distribution of population coupling and weaker stimulus selectivity for networks with diverse <inline-formula><mml:math id="inf32"><mml:mi>α</mml:mi></mml:math></inline-formula>, compared to networks with uniform <inline-formula><mml:math id="inf33"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). The dynamics of cortical activity observed in vivo are therefore more closely captured by networks with diverse <inline-formula><mml:math id="inf34"><mml:mi>α</mml:mi></mml:math></inline-formula>, compared to networks with uniform <inline-formula><mml:math id="inf35"><mml:mi>α</mml:mi></mml:math></inline-formula>.</p><p>Overall, these simulations show that the plasticity-coupling link observed in our small network model is robust in a larger network with receptive field properties and neuronal responses similar to mouse visual cortex. Networks with diverse <inline-formula><mml:math id="inf36"><mml:mi>α</mml:mi></mml:math></inline-formula> exhibit a broader range of population coupling than networks with uniform <inline-formula><mml:math id="inf37"><mml:mi>α</mml:mi></mml:math></inline-formula>. Moreover, diverse learning rates introduce a correlation between a neuron’s population coupling and its total excitatory synaptic input, in agreement with experimental observations (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). Taken together, diverse learning rates provide a parsimonious explanation for the diverse population coupling observed in sensory cortical networks.</p></sec><sec id="s2-3"><title>Experimental validation: population coupling is correlated with stimulus response variability in vivo</title><p>We have demonstrated that the population coupling of a neuron in a recurrent network model depends on its inherent plasticity. This plasticity-coupling link predicts a correlation between a neuron’s population coupling and the variability of its stimulus selectivity. We now test this prediction using 2-photon calcium imaging of visual cortex in awake adult mice (Materials and methods). The data we analyse is publicly available and was collected by the Allen Institute for Brain Science (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>). Mice passively viewed drifting or static gratings, interleaved with natural movies, while the simultaneous responses of ~ 15, 000 excitatory neurons from 64 animals were recorded (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We measure the population coupling of each neuron over the entire recording session, and the preferred orientation of each neuron during the first 10 min and last 10 min of the experiment (Materials and methods, <xref ref-type="fig" rid="fig3">Figure 3B</xref>). We then compare these two measurements of orientation preference to identify whether the preferred orientation of some neurons vary over the course of the experiment.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Population coupling is correlated with stimulus response variability in mouse visual cortex in vivo.</title><p>(<bold>A</bold>) Diagram of stimulus and data analysis protocol (<bold>B</bold>) dF/F calcium fluorescence traces of neurons (red traces) in an example experiment from the Allen Brain Observatory. Mean activity is shown in black, and the population coupling of each neuron is indicated by its colour changing from light to dark red with increased population coupling. (<bold>C</bold>) The population coupling distribution of all neurons across all experiments (black, 64 experiments, 15,281 neurons) and in simulations (gray, 15 experiments, 3750 neurons). (<bold>D</bold>) Absolute difference in preferred orientation (black, static gratings, <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) and preferred direction (gray, drifting gratings, <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) between the beginning and the end of the recording session. (<bold>E</bold>) <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (left, black, static gratings) and <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (right, gray, drifting gratings) are correlated with population coupling. Data shown for all neurons with reliable stimulus responses across all experiments, binned by population coupling. Error bars for each bin show 95% confidence interval. Linear regression fit for all datapoints (shaded gray area indicates 95% confidence interval). (<bold>F</bold>) Distribution of ratios of the mean population coupling of neurons that change their preferred orientation (<inline-formula><mml:math id="inf42"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) or preferred direction (<inline-formula><mml:math id="inf43"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) versus mean population coupling of neurons that conserve their preferred orientation (<inline-formula><mml:math id="inf44"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) or preferred directions (<inline-formula><mml:math id="inf45"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), for each individual static grating experiment (black), drifting grating (gray) experiment, or network simulation (light gray). Dashed vertical line indicates expected value if a neuron’s orientation or direction preference variability is not dependent on its population coupling (*** p&lt;0.001, one sample t-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Orientation selectivity index is anti-correlated with population coupling.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Dependence of plasticity-coupling link on response reliability in ABI experimental data.</title><p>(<bold>A-B</bold>) Ratios of the mean population coupling of neurons that change their preferred orientation or preferred direction versus mean population coupling of neurons that conserve their preferred orientation or preferred directions, for each individual static grating experiment (black) and drifting grating (gray) experiment, for neurons with the top 75% most reliable neurons (<bold>A</bold>), or for all neurons (<bold>B</bold>). (<bold>C-D</bold>)<inline-formula><mml:math id="inf46"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (left, gray, static gratings) and <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (right, black, drifting gratings) are correlated with population coupling. Data shown for the neurons with the top 75% of stimulus response reliability (<bold>C</bold>) or for all neurons (<bold>D</bold>), binned by population coupling. Linear regression fit for all datapoints (shaded gray area indicates 95% confidence interval). (<bold>E</bold>) (top) Distribution of response reliability for all neurons across all drifting grating (gray, left) and static grating (black, right) experiments. (bottom) Relationship between response reliability and change in direction selectivity (<inline-formula><mml:math id="inf48"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) (left) and population coupling (right). (<bold>F</bold>) Relationship between population coupling and <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (top) or <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (bottom), when response reliability is regressed out as a potentially confounding factor.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Changes in spatial frequency selectivity (<inline-formula><mml:math id="inf51"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>SF</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, (<bold>A</bold>)) and temporal frequency selectivity (<inline-formula><mml:math id="inf52"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>TF</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, (<bold>B</bold>)) are correlated with population coupling.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Potentially confounding factor.</title><p>(<bold>A</bold>) Changes in direction selectivity versus direction selectivity index (DSI). (<bold>B</bold>) Population coupling versus direction selectivity index (DSI). (<bold>C</bold>) Changes in direction selectivity versus mean calcium fluorescence. (<bold>D</bold>) Changes in direction selectivity versus peak calcium fluorescence. (<bold>E</bold>) Relationship between population coupling and <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (blue), and when DSI is regressed out as a potentially confounding factor (black). (<bold>F</bold>) Relationship between population coupling and <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> (blue), and when peak calcium fluorescence is regressed out as a potentially confounding factor (black).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig3-figsupp4-v2.tif"/></fig></fig-group><p>There is a broad distribution of population coupling, in agreement with previous observations (<xref ref-type="fig" rid="fig3">Figure 3C</xref>; <xref ref-type="bibr" rid="bib43">Sedigh-Sarvestani et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). Roughly 75% of neurons express variability of their preferred orientation or direction between the beginning and the end of the experiment. The distribution of changes in preferred orientation (<inline-formula><mml:math id="inf55"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) and preferred direction (<inline-formula><mml:math id="inf56"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) is skewed towards smaller magnitudes (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p><p>Population coupling is weakly but significantly correlated with the average change in preferred orientation and in preferred direction (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, r = 0.1, p&lt;1e-5 and r = 0.12, p&lt;1e-5, Spearman correlation). We characterise this dependence for each experiment by comparing the population coupling of neurons with variable preferences (those with <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>&gt; 0 or <inline-formula><mml:math id="inf58"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>&gt; 0) versus those with stable preference. While there is substantial variability of the strength of the effect, the majority of experiments show a trend in which neurons with plastic orientation preferences have a higher mean population coupling than those with stable orientation or direction preferences (<xref ref-type="fig" rid="fig3">Figure 3F</xref>, p&lt;0.001 for both static and drifting gratings, t-test). We observed similar correlations between population coupling and the average change in preferred spatial frequency and in preferred temporal frequency (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3E</xref>, r = 0.054, p=0.001 and r = 0.058, p=0.001, Spearman correlation).</p><p>As the mean activity level of a neuron could conceivably determine its stimulus preference stability (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>; <xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki, 2016</xref>), we tested this and found no dependence of the tendency of a individual neuron to change stimulus preference on its average calcium fluorescence (p=0.88, Spearman correlation, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). We also found that this relationship between the change in selectivity and population coupling remained when controlling for peak calcium fluorescence or selectivity index as a potential confounding factor (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>).</p><p><xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref> did not observe any correlations between population coupling of a neuron and its orientation selectivity. In contrast, our network model predicts that neurons with high population coupling are less selective than neurons with low population coupling. We tested whether there was this predicted dependence between population coupling and orientation selectivity in these data. We indeed found a weak anti-correlation between population coupling and orientation selectivity index (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, r = −0.05, p&lt;1e-6, Pearson correlation).</p></sec><sec id="s2-4"><title>Diverse learning rates maintain both a stable backbone and a flexible substrate of stimulus representation</title><p>Our analysis thus far explored the impact of diverse rates of plasticity on synaptic connectivity. We established a link between diverse population coupling and diverse stimulus response variability, both of which are observed in sensory cortex. We now explore the functional implications of diverse population coupling and learning rates within recurrent networks. In order to simplify our analysis we consider both forms of diversity in isolation.</p><p>The presence of diverse rates of plasticity in a network suggests a dichotomy of roles: less plastic neurons could form stable stimulus representations while more plastic neurons could allow flexible representation. This could, for example, be beneficial during perceptual learning. We test this hypothesis by simulating an extended period of perceptual learning in our small network model (Materials and methods, <xref ref-type="fig" rid="fig4">Figure 4A</xref>). We do this using a simple paradigm in which a randomly chosen feedforward stimuli is associated with an increased external input. This external input could be mediated by a reward, or some other top-down signal. Hebbian plasticity potentiates the recurrent synaptic connections from neurons which are tuned to the stimulus onto all neurons. This increases the selectivity of all neurons to the associated stimulus (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Plasticity-coupling link enables both robust stimulus representation and a flexible substrate for perceptual learning.</title><p>(<bold>A</bold>) The evolution of mean selectivity to the feedforward stimulus (top) and a stimulus associated with an additional external input (bottom) in networks composed either entirely of neurons with slow <inline-formula><mml:math id="inf59"><mml:mi>α</mml:mi></mml:math></inline-formula> (black), fast <inline-formula><mml:math id="inf60"><mml:mi>α</mml:mi></mml:math></inline-formula> (gray), or a mix of both fast and slow <inline-formula><mml:math id="inf61"><mml:mi>α</mml:mi></mml:math></inline-formula> (dashed black). Shaded gray region indicates when the additional external input is present, and the coloured circles indicate the stimulus the external input is associated with at that time (this switches every 25 s) (<bold>B</bold>) Synaptic connectivity after plasticity for a network of neurons with slow (small circles) or fast (large circles) learning rates. Neurons in the network receive input selective to 1 of 4 possible stimuli (colour denotes stimulus preference). Synaptic inputs onto fast neurons and slow neurons are coloured gray and black respectively. The spatial organisation of neurons is for visualisation purposes only. (<bold>C–D</bold>) Investigating the impact of population coupling on perceptual learning. (<bold>C</bold>) Coupling of either the plastic neuron or static neurons to the population is set by adjusting <inline-formula><mml:math id="inf62"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula> respectively. Perceptual learning is simulated through an additional external input whenever the preferred stimulus of the red neurons is present. This leads to the predominant synaptic weight onto the plastic neuron (black) switching from the neuron with the same original preferred stimulus (blue) to the neuron with the associated preferred stimulus (red). (<bold>D</bold>) Amount of perceptual learning which occurs at the plastic neuron, as the population coupling of either the plastic neuron (<inline-formula><mml:math id="inf64"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula>, x-axis) or static (<inline-formula><mml:math id="inf65"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>static</mml:mtext></mml:msub></mml:math></inline-formula>, y-axis) is varied. Perceptual learning is quantified by the ratio of the red synaptic weight (associated stimulus) to the blue synaptic weight (original preferred stimulus of the plastic neuron) after plasticity. Red regions (<inline-formula><mml:math id="inf66"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math></inline-formula>) indicate successful perceptual learning, and occur only when <inline-formula><mml:math id="inf67"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula> is high and <inline-formula><mml:math id="inf68"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>static</mml:mtext></mml:msub></mml:math></inline-formula> is low. (<bold>E</bold>) Relative stimulus decoding performance of fixed recurrent networks after a period of plasticity in order to develop the network. Networks were developed using either entirely neurons with fast learning rates, slow learning rates, or a 50/50 mix of both learning rates. The feedforward stimulus strength (x-axes) and noise (y-axes) were varied along a logarithmic scale. (<bold>F</bold>) Illustration of the synergistic effect of the plasticity-coupling link on perceptual learning. The plasticity-coupling link ensures that slow neurons have low population coupling and fast neurons have high population coupling, which panel D demonstrates is necessary for perceptual learning.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-fig4-v2.tif"/></fig><p>We evaluate the ability of our network to continually learn these stimulus associations in the case where <inline-formula><mml:math id="inf69"><mml:mi>α</mml:mi></mml:math></inline-formula> is slow for all neurons, <inline-formula><mml:math id="inf70"><mml:mi>α</mml:mi></mml:math></inline-formula> is fast for all neurons, or where there is diverse <inline-formula><mml:math id="inf71"><mml:mi>α</mml:mi></mml:math></inline-formula> (both slow and fast) for each feedforward stimulus group.</p><p>We find that a network with only fast <inline-formula><mml:math id="inf72"><mml:mi>α</mml:mi></mml:math></inline-formula> quickly learns the stimulus associations (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, bottom). However, repeated associations with neurons that do not share feedforward stimuli cause the specificity of recurrent connectivity to decrease, thus degrading the representation of feedforward stimuli (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, top). Although neurons still form associations with the feedforward stimulus, this is because we keep the feedforward stimulus weights fixed; one can imagine that this feedforward selectivity may also degrade if these weights were plastic. Conversely, the network with only slow <inline-formula><mml:math id="inf73"><mml:mi>α</mml:mi></mml:math></inline-formula> retains a stable representation of the feedforward stimuli but performs poorly in representing the associated stimulus (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). The network with diverse <inline-formula><mml:math id="inf74"><mml:mi>α</mml:mi></mml:math></inline-formula> overcomes these issues by having fast neurons which flexibly learn stimulus associations and slow neurons which maintain a ‘backbone’ of stimulus representation (see diagram, <xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p></sec><sec id="s2-5"><title>The plasticity-coupling link enables efficient perceptual learning</title><p>Having demonstrated the advantage of diverse learning rates within a network for perceptual learning, we now ask whether diverse population coupling has any impact on a network’s performance in this task. Given the plasticity-coupling link, we are particularly interested in whether the impact of population coupling on performance is dependent on a neuron’s rate of plasticity. To investigate this, we choose the extreme case in which there is a single neuron with plastic synaptic inputs embedded in an otherwise static recurrent network. Since all other synapses in the network are static (see diagram, <xref ref-type="fig" rid="fig4">Figure 4C</xref>), we focus on how synaptic inputs onto the plastic neuron evolve during learning. We adjust the population coupling (PC) of either the single plastic neuron (<inline-formula><mml:math id="inf75"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula>) or the static neurons (<inline-formula><mml:math id="inf76"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>static</mml:mtext></mml:msub></mml:math></inline-formula>), and measure the ability of the plastic neuron to learn a stimulus association (Materials and methods). We simulate perceptual learning by turning on an extra external input to all neurons in the network whenever the associated stimulus (red) is presented to the network (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). We judge the plastic neuron to have learned the association if the synaptic weight from the presynaptic neuron selective to the associated stimulus becomes stronger than the weight from the presynaptic neuron selective to the non-associated stimulus (blue). We find that strongly coupling the plastic neuron to the population improves performance, while strongly coupling the static neurons to the population impairs performance (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><p>We can understand this by considering that, for learning to occur, synaptic potentiation must happen between the static neuron corresponding to the associated stimulus (red) and the plastic neuron. Increasing the plastic neuron’s coupling to the rest of the population amplifies the correlation between the pre- and post- synaptic neuron when the associated stimulus is present, since the entire population receives an extra external input. On the other hand, strong coupling amongst the presynaptic static neurons decreases their stimulus selectivity, since they will be more co-active regardless of the stimulus identity. This corrupts the signal during stimulus association. These two effects combine, such that the new stimulus association is learned only when there is low population coupling amongst static neurons (<inline-formula><mml:math id="inf77"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>static</mml:mtext></mml:msub></mml:math></inline-formula>) and high population coupling for the plastic neuron (<inline-formula><mml:math id="inf78"><mml:msub><mml:mtext>PC</mml:mtext><mml:mtext>plastic</mml:mtext></mml:msub></mml:math></inline-formula>) (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, labelled <inline-formula><mml:math id="inf79"><mml:mi mathvariant="normal">Φ</mml:mi></mml:math></inline-formula>). In order to enhance perceptual learning with diverse learning rates, plastic neurons should therefore be more coupled to the rest of the population than stable neurons. Correlated diversity of population coupling and plasticity helps achieve this (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), ensuring that neurons best suited to the necessary stimulus representation remain stable, while neurons best suited to learning stimulus associations remain flexible. The plasticity-coupling link therefore efficiently exploits the functional advantages conferred by both diverse learning rates and diverse population coupling.</p></sec><sec id="s2-6"><title>Diverse learning rates lead to networks with improved stimulus coding capabilities</title><p>Until now we have considered the effect of population coupling on a network’s ability to learn stimulus associations. We are also interested in the impact of population coupling on a task that does not involve synaptic plasticity, since the differences in non-specific connectivity alone may affect a neuron’s computational capability. We choose stimulus decoding as a simple example, and measure performance at decoding pairs of stimuli in a static network, after it has gone through a period of synaptic plasticity (Materials and methods). We compare three different network types; one which has been developed while it had only slow <inline-formula><mml:math id="inf80"><mml:mi>α</mml:mi></mml:math></inline-formula>, one developed with only fast <inline-formula><mml:math id="inf81"><mml:mi>α</mml:mi></mml:math></inline-formula>, and one developed with diverse <inline-formula><mml:math id="inf82"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). In a network with only slow <inline-formula><mml:math id="inf83"><mml:mi>α</mml:mi></mml:math></inline-formula>, and therefore low population coupling, stimulus decoding performs relatively well when there are high levels of noise in the input. Networks with only fast <inline-formula><mml:math id="inf84"><mml:mi>α</mml:mi></mml:math></inline-formula> perform relatively well when there are low levels of noise. A network with diverse <inline-formula><mml:math id="inf85"><mml:mi>α</mml:mi></mml:math></inline-formula> seems to advantageously combine both of these properties, so that its performance is high across the entire range of input strength and noise levels.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have studied the impact of diverse learning rates in a recurrent network model of visual cortex. Intriguingly, a plasticity-coupling link emerges in networks with diverse learning rates, in which neurons with fast learning rates are more coupled to population activity than neurons with slow learning rates. We substantiated a key prediction of our plasticity-coupling link with in vivo calcium imaging of mouse visual cortex from the Allen Brain Observatory (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>), finding that a neuron is more likely to exhibit stimulus preference variability if it has high population coupling. Based on our findings we propose that the plasticity-coupling link efficiently combines stable and flexible stimulus representation.</p><sec id="s3-1"><title>Stability and plasticity of stimulus responses</title><p>The architecture of a plastic substrate of neurons on top of a stable ‘backbone’ (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) has been hypothesised before, and there is some compelling experimental evidence for this proposal (<xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki, 2016</xref>; <xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>; <xref ref-type="bibr" rid="bib32">Panas et al., 2015</xref>). In particular, tracking of hippocampal cell assemblies reveal subsets of either plastic, highly active neurons or rigid, less active neurons (<xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki, 2016</xref>). Likewise, a statistical-mechanical analysis of network activity in hippocampal cell cultures identified both neurons which are highly active and contribute predominantly to network stability, and neurons which exhibit more long-term activity fluctuations without compromising overall network stability (<xref ref-type="bibr" rid="bib32">Panas et al., 2015</xref>). In primary visual cortex - which we model - neurons exhibit characteristic fluctuations of their stimulus selectivity during baseline measurements, but nonetheless tend to retain their preferred stimulus following recovery from sensory deprivation (<xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>). This provides evidence for a stable ‘backbone’ of recurrent connectivity which is resistant to sensory perturbations (<xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>). (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>) investigated the stability of locomotion-dependent modulation of visual responses across 14 days and, in contrast to <xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki (2016)</xref>, found that highly responsive neurons exhibited reasonably stable stimulus preference while weakly responsive neurons exhibit plastic stimulus preference. However, these experiments tracked different stimulus features - and over longer timescales - when compared with our study. Moreover, our inclusion of a homeostatic inhibitory plasticity rule that precisely controls excitatory firing rate precludes us from making predictions about the dependence of a neurons average firing rate and its propensity for stimulus preference plasticity (<xref ref-type="bibr" rid="bib50">Vogels et al., 2011</xref>). Similar links between plasticity and population dynamics could emerge in other experiments that chronically image cortical network activity (<xref ref-type="bibr" rid="bib12">Driscoll et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">Singh et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Peron et al., 2015</xref>).</p><p>Since the majority of experiments which track stimulus preference evolution do so during visual discrimination paradigms, it is likely that top-down influences such as attention or reward modulation play significant roles in their observed dynamics (<xref ref-type="bibr" rid="bib31">Pakan et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Caras and Sanes, 2017</xref>; <xref ref-type="bibr" rid="bib35">Poort et al., 2015</xref>; <xref ref-type="bibr" rid="bib42">Schoups et al., 2001</xref>). An exception is (<xref ref-type="bibr" rid="bib16">Goltstein et al., 2013</xref>), in which stimulus preference is measured in the anaesthetised state, meaning that top-down inputs are likely to be absent. Likewise, (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>) tracked stimulus response stability during passive viewing, similar to the experimental setup of the data we analyse (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>). As well as top-down modulation, further features missing from our network model are a realistic inhibitory circuitry (<xref ref-type="bibr" rid="bib47">Tremblay et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Letzkus et al., 2015</xref>), and incorporating changes in network dynamics which occur during sleep (<xref ref-type="bibr" rid="bib17">Grosmark and Buzsáki, 2016</xref>; <xref ref-type="bibr" rid="bib45">Singh et al., 2015</xref>), both of which are widely viewed to play an important role in regulating the plasticity of neural representation.</p></sec><sec id="s3-2"><title>A plasticity-coupling link in vivo</title><p>Our analysis of in vivo calcium imaging substantiates a key prediction of our network model by observing a correlation between the stimulus preference plasticity of a neuron and its population coupling (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Note that this relationship does not arise in our receptive-field network model with uniform learning rates (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), so it is not a trivial consequence of any network model that exhibits diverse population coupling. Although the correlations we measured are quite small, this variability reflects what is observed in our network model (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), and is not surprising given that there are likely many unobserved factors - aside from population coupling - which contribute to the dynamics of a neuron’s observed stimulus response. Indeed, our network with uniform learning rates demonstrates significant stimulus response variability (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, green), but crucially does not capture the correlation between this variability and population coupling which we observe both in vivo and in the network with diverse learning rates.</p><p>An advantage of the Allen Brain Observatory is the large amount of data and easily replicable data processing pipeline which allows us to build upon previous work investigating population coupling in the same dataset (<xref ref-type="bibr" rid="bib43">Sedigh-Sarvestani et al., 2017</xref>). Since the population coupling of a neuron is correlated across brain states, and is only weakly dependent on stimulus type and mean fluorescence, we believe that it provides a good measure of a neurons functional integration within the local network, and would - according to our model - therefore provide a reasonable estimate of its propensity for perceptual learning (<xref ref-type="fig" rid="fig4">Figure 4D</xref>; <xref ref-type="bibr" rid="bib43">Sedigh-Sarvestani et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). In agreement with our network model, and in contrast with observations from <xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref>, population coupling is anti-correlated with orientation selectivity in the Allen Brain Observatory dataset (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The disparity between these two experiments could be due to different experimental conditions, or the effect may not have been previously observed due to the smaller number of neurons used n = 431 in <xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref>. Moreover, our observation that the changes in stimulus preferences (<inline-formula><mml:math id="inf86"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) are often non-zero but skewed towards small absolute values (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) are in agreement with the hypothesis that stimulus preference is a slowly drifting property (<xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>). Unfortunately, the experimental protocol limits us to directly comparing stimulus preference at only two timepoints; the beginning and end of a 62 min imaging session (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Nonetheless, significant changes in synaptic efficacies can be expressed within this time (<xref ref-type="bibr" rid="bib29">Meyer et al., 2014</xref>). We hope that these findings will stimulate further experiments that allow us to more precisely test for the presence of a plasticity-coupling link across longer timepoints, and during learning.</p><p>While analysing fluctuations in stimulus selectivity in network simulations allow us to perform a like-for-like comparison with what could be measured from the experimental data, there are alternative approaches which may capture more complex stimulus representations (<xref ref-type="bibr" rid="bib14">Gallego et al., 2020</xref>), and the plasticity of these representations. Exploring how plasticity relates to neurons involvement in such low-dimensional latent dynamics would be an interesting direction for further work.</p></sec><sec id="s3-3"><title>Population coupling and neuron function</title><p>Our network model provides a parsimonious explanation for the diverse population coupling recently observed in sensory cortex (<xref ref-type="bibr" rid="bib30">Okun et al., 2015</xref>). Population coupling is dependent on the amount of recurrent synaptic input a neurons receives, in agreement with experimental data (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Note that this dependence is not present in networks with uniform learning rates, even though they too exhibit diverse population coupling. Moreover, the width of the population coupling distribution increases as the recurrent network approaches a dynamic regime dominated by high noise and diverse selectivity, typical in cortical networks (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). These findings suggest that different population couplings may simply be a feature of varying learning rates and does not necessarily mean (although we cannot exclude it) that the observed diversity reflects entirely different cell classes. Furthermore, one can imagine alternative mechanisms that lead to diverse population coupling in recurrent networks, such as imposing heterogeneous targets for the number of synaptic inputs received by each neuron. Investigating such alternative mechanisms was outside the scope of our study, but would provide an interesting avenue for further theoretical research.</p><p>The proposed plasticity-coupling link presents a counterintuitive interpretation of the role of ‘soloists’ and ‘choristers’ originally described by <xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref>. While one may naively suppose that the weakly coupled ‘soloists’ are suited to undergo plasticity during learning, we propose that it is in fact the strongly coupled ‘choristers’ with a more plastic representation.</p><p>The functional impact of population coupling on learning is crucial: in order to enhance perceptual learning, plastic neurons in recurrent networks should be more coupled to the rest of the population than stable neurons (<xref ref-type="fig" rid="fig4">Figure 4D,F</xref>). We find that high population coupling helps plastic neuron change their stimulus preference towards an associated stimulus, but hinders the ability of stable neurons to provide an instructive signal for learning. Correlated diversity of population coupling and learning rate therefore enables both robust stimulus representation (low <inline-formula><mml:math id="inf87"><mml:mi>α</mml:mi></mml:math></inline-formula>, PC) and a flexible substrate suitable for perceptual learning (high <inline-formula><mml:math id="inf88"><mml:mi>α</mml:mi></mml:math></inline-formula>, PC). Strikingly, this relationship is precisely what the predicted plasticity-coupling link ensures (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Moreover, a recent theoretical study of sensory decoding proposed that untuned neurons contribute to decoding when they are correlated with tuned neurons (<xref ref-type="bibr" rid="bib53">Zylberberg, 2017</xref>). Again, this is the relationship predicted by our model, since plastic neurons are less tuned than rigid neurons and are more strongly coupled to the population (<xref ref-type="fig" rid="fig1">Figure 1D,E</xref>).</p><p>An alternative hypothesis for how population coupling relates to neural plasticity can be found in normative theories of learning. Consider a recurrent neural network trained with gradient descent to perform some function. Regardless of the function being learned, on average, neurons with greater impact on the rest of the network will have larger synaptic updates than other neurons. This is because the gradient of any function with respect to a neuron will depend on its ability to influence future activity, and neurons that contribute more to the gradient will be updated more. Neurons with a strong tendency to activate other neurons will have high levels of population coupling, while neurons with a tendency to inhibit other neurons (disynaptically, since these are excitatory neurons) will have low levels of population coupling. Neurons with limited impact will have moderate levels of population coupling. Thus, a gradient-based account would predict that there should be a U-shaped curve relating population coupling to plasticity. Our data showed may show some initial decrease in plasticity as population coupling increases (<xref ref-type="fig" rid="fig3">Figure 3F</xref>), but these questions outstrip the focus of this work. Consideration of whether alternative models based on gradients could explain this data may nonetheless be a fruitful avenue of enquiry for future experiments.</p></sec><sec id="s3-4"><title>Previous theoretical work</title><p>There are many previous theoretical explorations of how diversity in the synaptic plasticity of individual neurons affects learning. A recent study proposes a conceptually similar mechanism for modulating the stability or flexibility of memory formation, by implementing either symmetric or asymmetric STDP learning rules (<xref ref-type="bibr" rid="bib33">Park et al., 2017</xref>). Diversity in synaptic learning rates was also explored within the traditional machine learning framework, whereby fast weights store temporary memories of recent events, compared with slow weights which capture regularities in input structure (<xref ref-type="bibr" rid="bib4">Ba et al., 2016</xref>). Our work is related to previous approaches for overcoming catastrophic forgetting, which is often observed in neural networks during learning (<xref ref-type="bibr" rid="bib18">Grossberg, 1987</xref>; <xref ref-type="bibr" rid="bib7">Carpenter and Grossberg, 1987</xref>; <xref ref-type="bibr" rid="bib28">McClelland et al., 1995</xref>; <xref ref-type="bibr" rid="bib13">Fusi et al., 2005</xref>; <xref ref-type="bibr" rid="bib40">Roxin and Fusi, 2013</xref>; <xref ref-type="bibr" rid="bib5">Benna and Fusi, 2016</xref>). These approaches typically involve partitioning memories across timescales by implementing either synaptic states with different timescales, or neural architectures with different timescales. Here, we intead based our approach on experimental observations that suggest diverse learning rates within a sensory cortical network (<xref ref-type="bibr" rid="bib37">Ranson, 2017</xref>; <xref ref-type="bibr" rid="bib10">Clopath et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Poort et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Lütcke et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Rule et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Rose et al., 2016</xref>). Finally, individual synaptic updates in our model are defined by the learning rate of the postsynaptic neuron (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>). Further work could explore whether our observed outcomes change if updates are instead dependent on the learning rate of the presynaptic neuron.</p><p>The plasticity-coupling link’s impact on perceptual learning suggests a dichotomy of roles amongst neurons in a network, tied to a particular functional architecture: a stable ‘backbone’ of stimulus representation formed by neurons with slow synaptic plasticity and low population coupling, on top of which lies a flexible substrate of neurons with fast synaptic plasticity and high population coupling. Diverse learning rates naturally enable this architecture, and offer a compelling candidate mechanism for mediating both forms of diversity - population coupling and stimulus response stability - recently observed in cortical networks. Finally, the plasticity-coupling link provides neuroscientists with a means to assess the tendency of particular neurons to influence future learning: those which are highly coupled to population activity are most likely to express plasticity. Ongoing advances in chronic multi-neuron calcium imaging, alongside neuron-specific optogenetic stimulation, will allow us to further probe and exploit these possibilities.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Our network model simulations were written in python 2.7 with numpy and scipy.</p><sec id="s4-1"><title>Neuron model</title><p>For both the fully connected and the receptive field networks we use a simple firing rate neuron model, given by the transfer function <inline-formula><mml:math id="inf89"><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> defined below, and as used previously by <xref ref-type="bibr" rid="bib36">Rajan et al. (2010)</xref>; <xref ref-type="bibr" rid="bib19">Hennequin et al. (2014)</xref>.<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext> if </mml:mtext><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mtext> if </mml:mtext><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0.</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This leads to firing rates with a baseline of <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and a maximum of <inline-formula><mml:math id="inf91"><mml:msub><mml:mi>r</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula>. Following (<xref ref-type="bibr" rid="bib36">Rajan et al., 2010</xref>), the firing rates <inline-formula><mml:math id="inf92"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of neuron <inline-formula><mml:math id="inf93"><mml:mi>i</mml:mi></mml:math></inline-formula> driven by external input <inline-formula><mml:math id="inf94"><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> in a network are described below.<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo> <mml:mtext>,</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf95"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the weight of the synaptic connection from neuron <inline-formula><mml:math id="inf96"><mml:mi>j</mml:mi></mml:math></inline-formula> to neuron <inline-formula><mml:math id="inf97"><mml:mi>i</mml:mi></mml:math></inline-formula>. All parameters are shown in <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Simulation Parameters.</title></caption><table frame="hsides" rules="groups"><tbody><tr><td><inline-formula><mml:math id="inf98"><mml:msub><mml:mi>H</mml:mi><mml:mtext>stim</mml:mtext></mml:msub></mml:math></inline-formula></td><td>8.0</td><td><inline-formula><mml:math id="inf99"><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula></td><td>1.0</td><td><inline-formula><mml:math id="inf100"><mml:msub><mml:mi>r</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula></td><td>20.0</td><td><inline-formula><mml:math id="inf101"><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula></td><td>5.0</td></tr><tr><td><inline-formula><mml:math id="inf102"><mml:msub><mml:mi>α</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf103"><mml:mrow><mml:mn mathsize="90%">2.0</mml:mn><mml:mo>⁢</mml:mo><mml:mtext mathsize="90%">x</mml:mtext><mml:mo>⁢</mml:mo><mml:msup><mml:mn mathsize="90%">10</mml:mn><mml:mrow><mml:mo mathsize="90%" stretchy="false">-</mml:mo><mml:mn mathsize="90%">6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> Hz</td><td><inline-formula><mml:math id="inf104"><mml:mi>ζ</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf105"><mml:mrow><mml:mn mathsize="90%">2.0</mml:mn><mml:mo>⁢</mml:mo><mml:mtext mathsize="90%">x</mml:mtext><mml:mo>⁢</mml:mo><mml:msup><mml:mn mathsize="90%">10</mml:mn><mml:mrow><mml:mo mathsize="90%" stretchy="false">-</mml:mo><mml:mn mathsize="90%">4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> Hz</td><td><inline-formula><mml:math id="inf106"><mml:mi>η</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf107"><mml:mrow><mml:mn mathsize="90%">1.0</mml:mn><mml:mo>⁢</mml:mo><mml:mtext mathsize="90%">x</mml:mtext><mml:mo>⁢</mml:mo><mml:msup><mml:mn mathsize="90%">10</mml:mn><mml:mrow><mml:mo mathsize="90%" stretchy="false">-</mml:mo><mml:mn mathsize="90%">5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> Hz</td><td/><td/></tr><tr><td><inline-formula><mml:math id="inf108"><mml:msub><mml:mi>w</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula></td><td>0.042</td><td><inline-formula><mml:math id="inf109"><mml:msub><mml:mi>w</mml:mi><mml:mtext>max-inh</mml:mtext></mml:msub></mml:math></inline-formula></td><td>50</td><td><inline-formula><mml:math id="inf110"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>total</mml:mtext><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td>0.75</td><td/><td/></tr><tr><td><inline-formula><mml:math id="inf111"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula></td><td>1</td><td><inline-formula><mml:math id="inf112"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula></td><td>10 ms</td><td><inline-formula><mml:math id="inf113"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>EE</mml:mtext></mml:msubsup></mml:math></inline-formula></td><td>0.5w<sub>max</sub></td><td><inline-formula><mml:math id="inf114"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>IE</mml:mtext></mml:msubsup></mml:math></inline-formula></td><td>0.2</td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Modelling synaptic plasticity with diverse learning rates</title><p>We use a simple Hebbian learning rule with homeostatic synaptic scaling to model synaptic plasticity of recurrent excitatory to excitatory (E-E) synapses (<xref ref-type="bibr" rid="bib15">Gerstner and Kistler, 2002</xref>),<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi>ζ</mml:mi><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi/><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:msup><mml:mi>W</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi/><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>W</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi/><mml:mtext>total</mml:mtext></mml:msub><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the learning rate of the postsynaptic neuron and <inline-formula><mml:math id="inf116"><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf117"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are the activities of the pre- and postsynaptic neuron respectively. <inline-formula><mml:math id="inf118"><mml:mi>ζ</mml:mi></mml:math></inline-formula> is the time constant of synaptic scaling, and <inline-formula><mml:math id="inf119"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>total</mml:mtext><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the target amount of total recurrent synaptic input which each neuron can receive under the synaptic scaling rule.</p><p>This form of excitatory plasticity introduces competition amongst presynaptic synaptic weights and leads to the development of stimulus selectivity, as discussed in <xref ref-type="bibr" rid="bib22">Ko et al. (2013)</xref>; <xref ref-type="bibr" rid="bib8">Clopath et al. (2010)</xref>. We use a homeostatic rule to model inhibitory synaptic plasticity of recurrent inhibitory to excitatory (I-E) weights (<xref ref-type="bibr" rid="bib50">Vogels et al., 2011</xref>),<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mtext>W</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo> <mml:mtext>,</mml:mtext></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf120"><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is the homeostatic target firing rate, <inline-formula><mml:math id="inf121"><mml:mi>η</mml:mi></mml:math></inline-formula> is the learning rate, and <inline-formula><mml:math id="inf122"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the weight of the synaptic connection from inhibitory neuron <inline-formula><mml:math id="inf123"><mml:mi>j</mml:mi></mml:math></inline-formula> to excitatory neuron <inline-formula><mml:math id="inf124"><mml:mi>i</mml:mi></mml:math></inline-formula>.</p><p>Excitatory weights are bounded so that their values lie between 0 and <inline-formula><mml:math id="inf125"><mml:msub><mml:mi>w</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula>, and inhibitory weights are bounded so that they lie between <inline-formula><mml:math id="inf126"><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mtext>max-inh</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> and 0.</p><p>While including two homeostatic mechanisms in our network model may seem redundant, they play different regulatory roles. Inhibitory plasticity largely controls the balance of excitation and inhibition received by a neuron, ensuring that it operates within its dynamic range. Synaptic scaling ensures that the total amount of recurrent excitation in the network is kept fixed as we vary its external input, while also introducing competition between presynaptic weights so that stimulus selectivity emerges. The synergistic effect of including multiple forms of plasticity has been widely studied in theoretical studies (<xref ref-type="bibr" rid="bib52">Zenke et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="bib48">Triesch, 2007</xref>; <xref ref-type="bibr" rid="bib9">Clopath et al., 2016</xref>).</p><p>Note that the speed of all learning rates <inline-formula><mml:math id="inf127"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf128"><mml:mi>ζ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf129"><mml:mi>η</mml:mi></mml:math></inline-formula> are artificially increased in order to reduce the computational times resources required to simulate our network model. The timescales of synaptic plasticity in our network models are in the order of hundreds of seconds, while synaptic plasticity during perceptual learning occurs over the course of days in vivo. This increased learning rate does not qualitatively affect our results, as there is a sufficient separation of timescales between synaptic plasticity and network dynamics, and is a standard assumption in network models of synaptic plasticity (<xref ref-type="bibr" rid="bib52">Zenke et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Litwin-Kumar and Doiron, 2014</xref>).</p></sec><sec id="s4-3"><title>Fully connected network model</title><p>The fully connected network consists of <inline-formula><mml:math id="inf130"><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:math></inline-formula> excitatory neurons and a global inhibitory neuron (<inline-formula><mml:math id="inf131"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). The dynamics of both inhibitory (I) and excitatory (E) neurons are described by <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> and <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. There is dense all-to-all synaptic connectivity in the E-E, E-I and I-E populations, and no I-I connectivity. Self-connections, or autapses, are not permitted in this network. <inline-formula><mml:math id="inf132"><mml:mi>W</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> is a square matrix with <inline-formula><mml:math id="inf133"><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> elements.</p><p>For <xref ref-type="fig" rid="fig1">Figure 1</xref>, we use a network with 48 excitatory neurons, and four input stimuli. Each neuron <inline-formula><mml:math id="inf134"><mml:mi>i</mml:mi></mml:math></inline-formula> has a preferred stimulus <inline-formula><mml:math id="inf135"><mml:msubsup><mml:mi>θ</mml:mi><mml:mtext>i</mml:mtext><mml:mtext>pref</mml:mtext></mml:msubsup></mml:math></inline-formula>, such that there are 12 neurons corresponding to each input stimulus. Each neuron receives its preferred stimulus input <inline-formula><mml:math id="inf136"><mml:msub><mml:mi>H</mml:mi><mml:mtext>stim</mml:mtext></mml:msub></mml:math></inline-formula>, and an independent noise source generated by an Ornstein-Uhlenbeck process, OU, with a mean of 0, variance of <inline-formula><mml:math id="inf137"><mml:msub><mml:mi>σ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula> and correlation time <inline-formula><mml:math id="inf138"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>OU</mml:mtext></mml:msub></mml:math></inline-formula>. The external input <inline-formula><mml:math id="inf139"><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> to a neuron <inline-formula><mml:math id="inf140"><mml:mi>i</mml:mi></mml:math></inline-formula> is therefore given by<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mtext>i</mml:mtext><mml:mtext>pref</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mtext>input</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mtext>stim</mml:mtext></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mtext>OU</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo> <mml:mtext>, </mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf141"><mml:mi>δ</mml:mi></mml:math></inline-formula> is the Kronecker delta function. For <xref ref-type="fig" rid="fig1">Figure 1B–D</xref>, these input groups are further divided so that there are six slow neurons (with <inline-formula><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) and six fast neurons (with <inline-formula><mml:math id="inf143"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) per group. For <xref ref-type="fig" rid="fig1">Figure 1E</xref>, each input group of 12 neurons contains a single neuron corresponding to each of the 12 learning rates. The learning rates are logarithmically spaced between <inline-formula><mml:math id="inf144"><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf145"><mml:mrow><mml:mn>75</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>s</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>All excitatory-to-inhibitory synapses are uniformly initialised with weights <inline-formula><mml:math id="inf146"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>EE</mml:mtext></mml:msubsup></mml:math></inline-formula>, excitatory-to-inhibitory synapses with weights <inline-formula><mml:math id="inf147"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>EI</mml:mtext></mml:msubsup></mml:math></inline-formula>, and inhibitory-to-excitatory synapses with weights <inline-formula><mml:math id="inf148"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init</mml:mtext><mml:mtext>IE</mml:mtext></mml:msubsup></mml:math></inline-formula>. We simulate the evolution of synaptic weights during visually evoked activity by sequentially presenting the network with a randomly chosen stimulus from the four input stimuli. Each stimulus is presented for 500 ms. The total simulation time is 500 s, and synaptic weights are updated at each timestep with the learning rules given by <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> and <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>.</p><p>For <xref ref-type="fig" rid="fig1">Figure 1D</xref>, connection specificity is defined as the average ratio of specific to non-specific excitatory synaptic weights received by neurons. Synaptic inputs from neurons in the same input stimulus group as the postsynaptic neuron are specific (i.e. they share the same feedforward stimulus preference), while all other synaptic inputs are non-specific. Specificity fluctuations are defined as the standard deviation of the connection specificity over time, where specificity is sampled every second from 200 to 500 seconds.</p></sec><sec id="s4-4"><title>Measuring population coupling</title><p>As introduced by <xref ref-type="bibr" rid="bib30">Okun et al. (2015)</xref>, the population coupling <inline-formula><mml:math id="inf149"><mml:msub><mml:mtext>PC</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of a neuron <inline-formula><mml:math id="inf150"><mml:mi>i</mml:mi></mml:math></inline-formula> is measured by calculating the Pearson correlation coefficient of each neurons’ activity <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> with the average activity of the rest of the population;<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mtext>PC</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mtext>corr</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo> <mml:mtext>.</mml:mtext></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Synaptic weights are kept fixed during the population coupling measurement, while external input is as in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. We measured population coupling using 250 s of activity.</p></sec><sec id="s4-5"><title>Receptive-field based network model</title><p>For <xref ref-type="fig" rid="fig2">Figure 2</xref>, we adapt a previously developed model of receptive field properties in mouse visual cortex (<xref ref-type="bibr" rid="bib51">Watanabe et al., 2016</xref>). We add neuronal dynamics and, beginning with uniform connectivity, simulate synaptic plasticity as visual stimuli are presented to the network. This model is constructed by assigning receptive fields to each excitatory neuron from a 2D Gabor function,<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>RF</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mtext>A exp</mml:mtext><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mtext>cos</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>f</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mtext> cos</mml:mtext><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mtext> sin</mml:mtext><mml:mi>θ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mtext> sin</mml:mtext><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:mtext> cos</mml:mtext><mml:mi>θ</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where A is the amplitude, <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf153"><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula> are the standard deviations of the Gaussian, <inline-formula><mml:math id="inf154"><mml:mi>θ</mml:mi></mml:math></inline-formula> is the orientation, <inline-formula><mml:math id="inf155"><mml:mi>f</mml:mi></mml:math></inline-formula> is the frequency and <inline-formula><mml:math id="inf156"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> is the phase of the receptive field. A network of 250 excitatory neurons with receptive fields is randomly generated from <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, with <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf158"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf159"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf160"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. As in the previous network, there is a single inhibitory neuron which all excitatory neurons project to, and receive inhibition from.</p><p>Neurons are rate-based and have similar dynamics as in the simple network model (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). Synaptic plasticity is also governed by the same learning rules (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). Inputs are presented to the network in the form of 2D images, and the input to each neuron <inline-formula><mml:math id="inf161"><mml:mi>i</mml:mi></mml:math></inline-formula> for a given image <inline-formula><mml:math id="inf162"><mml:msub><mml:mi>I</mml:mi><mml:mtext>ext</mml:mtext></mml:msub></mml:math></inline-formula> is determined by the pixel-wise dot product of that image with the neurons’ receptive field <inline-formula><mml:math id="inf163"><mml:msub><mml:mtext>RF</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, in addition to an independent noise term for each neuron given by an Ornstein-Uhlenbeck process;<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext>ext</mml:mtext></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mtext>RF</mml:mtext><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mtext>OU</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo> <mml:mtext>.</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>All excitatory-to-inhibitory synapses are uniformly initialised with weights <inline-formula><mml:math id="inf164"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init-RF</mml:mtext><mml:mtext>EE</mml:mtext></mml:msubsup></mml:math></inline-formula> and inhibitory-to-excitatory synapses with weights <inline-formula><mml:math id="inf165"><mml:msubsup><mml:mi>W</mml:mi><mml:mtext>init-RF</mml:mtext><mml:mtext>IE</mml:mtext></mml:msubsup></mml:math></inline-formula>. We simulate the evolution of synaptic weights during visually-evoked activity by sequentially presenting the network with randomly chosen bars of different orientations. Each image is presented for 500 ms. The total simulation time is 500 s, and synaptic weights are updated at each timestep. All results in <xref ref-type="fig" rid="fig2">Figure 2</xref> are pooled from 15 independent network instances, with 250 excitatory neurons in each network instance.</p><p>We define the selectivity of each neuron as <inline-formula><mml:math id="inf166"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>specific</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>non-specific</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf167"><mml:msub><mml:mi>w</mml:mi><mml:mtext>specific</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from neurons which share the same receptive field orientation and <inline-formula><mml:math id="inf168"><mml:msub><mml:mi>w</mml:mi><mml:mtext>non-specific</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from neurons which have a different receptive field orientation.</p></sec><sec id="s4-6"><title>The allen brain observatory: 2-photon calcium imaging of visual responses in vivo</title><p>We use data from the Allen Brain Observatory, a publicly available and curated survey of neural activity in adult mouse visual cortex. A comprehensive description of the experimental methods, data acquisition and data analyses are available as white papers published by the Allen Institute for Brain Science (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>). A list of the experiment IDs used in our analysis is available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.11837406">10.6084/m9.figshare.11837406</ext-link>.</p><p>Briefly, GCaMP6F was expressed in primary visual area neurons of transgenic mice line Ai93. Cranial surgery was performed to insert a window between p37-p63, followed by 2 weeks of habituation to the experiment setting. Mice were head-fixed on top of a rotating disk and could walk freely. 2-photon imaging experiments were conducted as the mouse passively viewed the stimulus protocol on a screen. The stimulus protocols included in our analysis consisted of either i) 10 min of drifting gratings, followed by 42 min of interleaved natural movies, drifting gratings and spontaneous activity, followed by another 10 min of drifting gratings, or ii) 8 min of static gratings, followed by 45 min of interleaved natural movies, static gratings and spontaneous activity, followed by 9 min of static gratings (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, see white paper for further details). Drifting gratings were presented at eight uniformly separated directions and at five different temporal frequencies. Static gratings were presented at six uniformly separated orientations separated, five different spatial frequencies and four different phases. 112 imaging experiments were initially included in our analysis.</p></sec><sec id="s4-7"><title>Measuring population coupling and stimulus response variability in vivo</title><p>The Allen Brain Atlas API provides functions which allow us to extract fluorescence traces and measure average stimulus response properties of individual cells during an experiment (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>). Motion correction, ROI detection and segmentation, and the removal of neuropil fluorescence artefacts are automatically performed using the API. We customised scripts within this API so that we could measure population coupling and stimulus response properties under specific conditions and timeframes.</p><p>We measure population coupling similarly to the network model analysis (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), but where a neuron’s activity is represented by calcium fluorescence dF/F. To ensure a reliable estimate of the population activity when calculating population coupling, we exclude any experiments in which less than 50 neurons were recorded. We also exclude any experiments in which the population couplings are not sufficiently consistent when using either half (randomly chosen) of the neurons to estimate population activity (<inline-formula><mml:math id="inf169"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>, linear regression). This reduces the number of experiments in our analysis from 112 to 64, for a total of 15,281 neurons. In addition, we only include neurons with a response reliability that is above the median reliability. The response reliability is defined as the trial-to-trial correlation of the dF/F traces during the neuron’s preferred stimulus presentation (<xref ref-type="bibr" rid="bib2">Allen Brain Atlases and Data, 2016</xref>) . <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> shows a similar analysis, but where we include neurons with the top 75% most reliable neurons, or include all neurons, regardless of their response reliability.</p><p>We measure the preferred orientation of each neuron during both the first presentation of static or drifting gratings (<inline-formula><mml:math id="inf170"><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref-1</mml:mtext></mml:msub></mml:math></inline-formula>), and the final presentation of static or drifting gratings (<inline-formula><mml:math id="inf171"><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref-2</mml:mtext></mml:msub></mml:math></inline-formula>) (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The preferred orientation is defined as the grating that evoked the largest mean response across all trials. Note that each experiment contains only either static or drifting gratings, so there is no overlap between these two conditions. The absolute difference in preferred orientation is calculated as: <inline-formula><mml:math id="inf172"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref-1</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mtext>ORI</mml:mtext><mml:mtext>pref-2</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Similarly, the absolute difference in preferred direction is calculated as: <inline-formula><mml:math id="inf173"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref</mml:mtext></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref-1</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mtext>DIR</mml:mtext><mml:mtext>pref-2</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-8"><title>Simulating perceptual learning</title><p>For the perceptual learning simulation in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, the input <inline-formula><mml:math id="inf174"><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> to each neuron is simulated as before, but with an additional term which is active whenever the stimulus associated with the additional external input is present (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref>). We first simulate synaptic plasticity without any stimulus associations for 300 s (i.e. with <inline-formula><mml:math id="inf175"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mtext>associated</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), and then simulate perceptual learning (with <inline-formula><mml:math id="inf176"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mtext>associated</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>). The identity of the associated stimulus is changed every 25 s to simulate continual learning.<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mtext>i</mml:mtext><mml:mtext>pref</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mtext>input</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mtext>stim</mml:mtext></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mtext>associated</mml:mtext></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mtext>input</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mtext>associated</mml:mtext></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mtext>OU</mml:mtext><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo> <mml:mtext>, </mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf177"><mml:mi>δ</mml:mi></mml:math></inline-formula> is the Kronecker delta function. Feedforward stimulus selectivity is defined as <inline-formula><mml:math id="inf178"><mml:mrow><mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>specific</mml:mtext></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>non-specific</mml:mtext></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf179"><mml:msub><mml:mi>w</mml:mi><mml:mtext>specific</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from neurons which share the same feedforward stimulus preference and <inline-formula><mml:math id="inf180"><mml:msub><mml:mi>w</mml:mi><mml:mtext>non-specific</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from neurons which have a different feedforward stimulus preference. Likewise, associated stimulus selectivity is defined as <inline-formula><mml:math id="inf181"><mml:mrow><mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>associated</mml:mtext></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>non-associated</mml:mtext></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf182"><mml:msub><mml:mi>w</mml:mi><mml:mtext>associated</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from neurons whose feedforward stimulus preference is the associated stimulus, and <inline-formula><mml:math id="inf183"><mml:msub><mml:mi>w</mml:mi><mml:mtext>non-associated</mml:mtext></mml:msub></mml:math></inline-formula> are the synaptic weights from other neurons.</p></sec><sec id="s4-9"><title>Single plastic neuron embedded in a static network</title><p>In order to systematically investigate the effect of population coupling on perceptual learning, we must keep the population coupling of both the static and plastic population fixed throughout the experiment. Since changes in the synaptic weights connecting both these populations will alter their population coupling, we overcome this by making these particular synapses functionally silent. That is, while their synaptic weight is updated depending on pre- and post-synaptic activity as before (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>), these synapses do not contribute when calculating the activity of the static and plastic neurons. The activities of the static and plastic neurons (<inline-formula><mml:math id="inf184"><mml:msup><mml:mi>y</mml:mi><mml:mtext>static</mml:mtext></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf185"><mml:msup><mml:mi>y</mml:mi><mml:mtext>plastic</mml:mtext></mml:msup></mml:math></inline-formula>) are therefore only determined by their external input and the activities of the population (<inline-formula><mml:math id="inf186"><mml:msup><mml:mi>y</mml:mi><mml:mtext>pop</mml:mtext></mml:msup></mml:math></inline-formula>, <xref ref-type="fig" rid="fig4">Figure 4C</xref>), meaning that their population coupling can be systematically varied:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> ,</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>plastic</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>plastic</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mtext>PC</mml:mtext><mml:mrow><mml:mtext>plastic</mml:mtext></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> ,</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>static</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mtext>static</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mtext>PC</mml:mtext><mml:mrow><mml:mtext>static</mml:mtext></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>pop</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> .</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf187"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is fixed for the duration of the simulation, while the synaptic weights from the static to the plastic population are updated as below;<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mtext>static</mml:mtext></mml:msubsup><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mtext>plastic</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:mi>ζ</mml:mi><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msub><mml:mi/><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi/><mml:msub><mml:mi>N</mml:mi><mml:mtext>plastic</mml:mtext></mml:msub></mml:msup><mml:mi>W</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi/><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>W</mml:mi><mml:msup><mml:mi/><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi/><mml:mtext>total</mml:mtext></mml:msub><mml:mo maxsize="120%" minsize="120%">)</mml:mo> <mml:mtext>.</mml:mtext></mml:mrow></mml:math></disp-formula></p><p>As before, the input <inline-formula><mml:math id="inf188"><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> has an additional term which is active whenever the stimulus associated with the additional external input is present (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, that is whenever the red stimulus is being presented). We first simulate synaptic plasticity without any stimulus associations for 500 s (i.e. with <inline-formula><mml:math id="inf189"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mtext>associated</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), and then simulate perceptual learning (with <inline-formula><mml:math id="inf190"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mtext>associated</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>) for 100 s. Perceptual learning is quantified by the ratio of the red synaptic weight (associated stimulus) to the blue synaptic weight (original preferred stimulus of the plastic neuron) after plasticity.</p></sec><sec id="s4-10"><title>Measuring stimulus decoding performance</title><p>We train a perceptron to decode the stimulus identity from the individual activity of all neurons in the network, using the scikit-learn python package. The average activity of each neuron across a 500 ms sampling period are used as inputs during training. For <xref ref-type="fig" rid="fig4">Figure 4E</xref>, performance at decoding pairs of stimuli simultaneously presented to the network is shown. Relative deviation from the average performance of a perceptron trained to decode pairs of stimuli (28 possible pairs from eight stimuli) over all three network types is calculated. The relative deviations for each network type from the average across all networks types are shown (<xref ref-type="fig" rid="fig4">Figure 4E</xref>).</p></sec><sec id="s4-11"><title>Code availability</title><p>Code is publicly available on GitHub on <ext-link ext-link-type="uri" xlink:href="https://github.com/yannaodh/sweeney_clopath_2020">https://github.com/yannaodh/sweeney_clopath_2020</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/sweeney_clopath_2020">https://github.com/elifesciences-publications/sweeney_clopath_2020</ext-link>; <xref ref-type="bibr" rid="bib46">Sweeney, 2020</xref>). </p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Tobias Rose and Alex Cayco-Gajic for their invaluable scientific feedback and comments on the manuscript. This work was funded by BBSRC BB/N013956/1, BB/N019008/1, Wellcome Trust 200790/Z/16/Z, Simons Foundation 564408 and EPSRC EP/R035806/1. We are also grateful to the Allen Institute for Brain Science for making freely available their data and tools.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-56053-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All calcium imaging data came from the Allen Institute for Brain Science, Allen Brain Observatory. Available from: <ext-link ext-link-type="uri" xlink:href="http://observatory.brain-map.org/visualcoding/">http://observatory.brain-map.org/visualcoding/</ext-link>. A list of experiment IDs can be found on FigShare, under the doi 10.6084/m9.figshare.11837406. Code is publicly available on GitHub on <ext-link ext-link-type="uri" xlink:href="https://github.com/yannaodh/sweeney_clopath_2020">https://github.com/yannaodh/sweeney_clopath_2020</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/sweeney_clopath_2020">https://github.com/elifesciences-publications/sweeney_clopath_2020</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset4" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Sweeney</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Supplementary table 1 (List of ABI experiment IDs)</data-title><source>figshare</source><pub-id assigning-authority="figshare" pub-id-type="doi">10.6084/m9.figshare.11837406</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ajemian</surname> <given-names>R</given-names></name><name><surname>D'Ausilio</surname> <given-names>A</given-names></name><name><surname>Moorman</surname> <given-names>H</given-names></name><name><surname>Bizzi</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A theory for how sensorimotor skills are learned and retained in noisy and nonstationary neural circuits</article-title><source>PNAS</source><volume>110</volume><fpage>E5078</fpage><lpage>E5087</lpage><pub-id pub-id-type="doi">10.1073/pnas.1320116110</pub-id><pub-id pub-id-type="pmid">24324147</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Allen Brain Atlases and Data</collab></person-group><year iso-8601-date="2016">2016</year><source>Allen Brain Observatory</source><ext-link ext-link-type="uri" xlink:href="http://observatory.brain-map.org/visualcoding/">http://observatory.brain-map.org/visualcoding/</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andermann</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Chronic cellular imaging of mouse visual cortex during operant behavior and passive viewing</article-title><source>Frontiers in Cellullar Neuroscience</source><volume>4</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.3389/fncel.2010.00003</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ba</surname> <given-names>J</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name><name><surname>Mnih</surname> <given-names>V</given-names></name><name><surname>Leibo</surname> <given-names>JZ</given-names></name><name><surname>Ionescu</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Using fast weights to attend to the recent past</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benna</surname> <given-names>MK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational principles of synaptic memory consolidation</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1697</fpage><lpage>1706</lpage><pub-id pub-id-type="doi">10.1038/nn.4401</pub-id><pub-id pub-id-type="pmid">27694992</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caras</surname> <given-names>ML</given-names></name><name><surname>Sanes</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Top-down modulation of sensory cortex gates perceptual learning</article-title><source>PNAS</source><volume>114</volume><fpage>9972</fpage><lpage>9977</lpage><pub-id pub-id-type="doi">10.1073/pnas.1712305114</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname> <given-names>GA</given-names></name><name><surname>Grossberg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Discovering order in Chaos: stable self-organization of neural recognition codes</article-title><source>Annals of the New York Academy of Sciences</source><volume>504</volume><fpage>33</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1987.tb48724.x</pub-id><pub-id pub-id-type="pmid">3477121</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Büsing</surname> <given-names>L</given-names></name><name><surname>Vasilaki</surname> <given-names>E</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Connectivity reflects coding: a model of voltage-based STDP with homeostasis</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>344</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1038/nn.2479</pub-id><pub-id pub-id-type="pmid">20098420</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Froemke</surname> <given-names>RC</given-names></name><name><surname>Sprekeler</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Receptive field formation by interacting excitatory and inhibitory synaptic plasticity</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/066589</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name><name><surname>Rose</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Variance and invariance of neuronal long-term representations</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>372</volume><elocation-id>20160161</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0161</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cossell</surname> <given-names>L</given-names></name><name><surname>Iacaruso</surname> <given-names>MF</given-names></name><name><surname>Muir</surname> <given-names>DR</given-names></name><name><surname>Houlton</surname> <given-names>R</given-names></name><name><surname>Sader</surname> <given-names>EN</given-names></name><name><surname>Ko</surname> <given-names>H</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional organization of excitatory synaptic strength in primary visual cortex</article-title><source>Nature</source><volume>518</volume><fpage>399</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1038/nature14182</pub-id><pub-id pub-id-type="pmid">25652823</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname> <given-names>LN</given-names></name><name><surname>Pettit</surname> <given-names>NL</given-names></name><name><surname>Minderer</surname> <given-names>M</given-names></name><name><surname>Chettih</surname> <given-names>SN</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic reorganization of neuronal activity patterns in parietal cortex</article-title><source>Cell</source><volume>170</volume><fpage>986</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.07.021</pub-id><pub-id pub-id-type="pmid">28823559</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname> <given-names>S</given-names></name><name><surname>Drew</surname> <given-names>PJ</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cascade models of synaptically stored memories</article-title><source>Neuron</source><volume>45</volume><fpage>599</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.02.001</pub-id><pub-id pub-id-type="pmid">15721245</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname> <given-names>JA</given-names></name><name><surname>Perich</surname> <given-names>MG</given-names></name><name><surname>Chowdhury</surname> <given-names>RH</given-names></name><name><surname>Solla</surname> <given-names>SA</given-names></name><name><surname>Miller</surname> <given-names>LE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Long-term stability of cortical population dynamics underlying consistent behavior</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>260</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0555-4</pub-id><pub-id pub-id-type="pmid">31907438</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gerstner</surname> <given-names>W</given-names></name><name><surname>Kistler</surname> <given-names>WM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Mathematical formulations of hebbian learning</article-title><source>Biological Cybernetics</source><volume>87</volume><fpage>404</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1007/s00422-002-0353-y</pub-id><pub-id pub-id-type="pmid">12461630</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goltstein</surname> <given-names>PM</given-names></name><name><surname>Coffey</surname> <given-names>EB</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>Pennartz</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>In vivo two-photon Ca2+ imaging reveals selective reward effects on stimulus-specific assemblies in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>11540</fpage><lpage>11555</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1341-12.2013</pub-id><pub-id pub-id-type="pmid">23843524</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grosmark</surname> <given-names>AD</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences</article-title><source>Science</source><volume>351</volume><fpage>1440</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1126/science.aad1935</pub-id><pub-id pub-id-type="pmid">27013730</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Processing of expected and unexpected events during conditioning and attention: a psychophysiological theory</article-title><source>Advances in Psychology</source><volume>42</volume><fpage>181</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1016/S0166-4115(08)60909-7</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal control of transient dynamics in balanced networks supports generation of complex movements</article-title><source>Neuron</source><volume>82</volume><fpage>1394</fpage><lpage>1406</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id><pub-id pub-id-type="pmid">24945778</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname> <given-names>D</given-names></name><name><surname>Habenschuss</surname> <given-names>S</given-names></name><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Network plasticity as bayesian inference</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004485</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004485</pub-id><pub-id pub-id-type="pmid">26545099</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kappel</surname> <given-names>D</given-names></name><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Habenschuss</surname> <given-names>S</given-names></name><name><surname>Hsieh</surname> <given-names>M</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reward-based stochastic self-configuration of neural circuits</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://www.arxiv-vanity.com/papers/1704.04238/">https://www.arxiv-vanity.com/papers/1704.04238/</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname> <given-names>H</given-names></name><name><surname>Cossell</surname> <given-names>L</given-names></name><name><surname>Baragli</surname> <given-names>C</given-names></name><name><surname>Antolik</surname> <given-names>J</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The emergence of functional microcircuits in visual cortex</article-title><source>Nature</source><volume>496</volume><fpage>96</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1038/nature12015</pub-id><pub-id pub-id-type="pmid">23552948</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Letzkus</surname> <given-names>JJ</given-names></name><name><surname>Wolff</surname> <given-names>SB</given-names></name><name><surname>Lüthi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Disinhibition, a circuit mechanism for associative learning and memory</article-title><source>Neuron</source><volume>88</volume><fpage>264</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.024</pub-id><pub-id pub-id-type="pmid">26494276</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>IC</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The nature of shared cortical variability</article-title><source>Neuron</source><volume>87</volume><fpage>644</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212710</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litwin-Kumar</surname> <given-names>A</given-names></name><name><surname>Doiron</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5319</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id><pub-id pub-id-type="pmid">25395015</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lütcke</surname> <given-names>H</given-names></name><name><surname>Margolis</surname> <given-names>DJ</given-names></name><name><surname>Helmchen</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Steady or changing? Long-term monitoring of neuronal population activity</article-title><source>Trends in Neurosciences</source><volume>36</volume><fpage>375</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2013.03.008</pub-id><pub-id pub-id-type="pmid">23608298</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mank</surname> <given-names>M</given-names></name><name><surname>Santos</surname> <given-names>AF</given-names></name><name><surname>Direnberger</surname> <given-names>S</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name><name><surname>Stein</surname> <given-names>V</given-names></name><name><surname>Hendel</surname> <given-names>T</given-names></name><name><surname>Reiff</surname> <given-names>DF</given-names></name><name><surname>Levelt</surname> <given-names>C</given-names></name><name><surname>Borst</surname> <given-names>A</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name><name><surname>Griesbeck</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A genetically encoded calcium Indicator for chronic in vivo two-photon imaging</article-title><source>Nature Methods</source><volume>5</volume><fpage>805</fpage><lpage>811</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1243</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname> <given-names>JL</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>O'Reilly</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the Hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>D</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Scheuss</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Balance and stability of synaptic structures during synaptic plasticity</article-title><source>Neuron</source><volume>82</volume><fpage>430</fpage><lpage>443</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.031</pub-id><pub-id pub-id-type="pmid">24742464</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Cossell</surname> <given-names>L</given-names></name><name><surname>Iacaruso</surname> <given-names>MF</given-names></name><name><surname>Ko</surname> <given-names>H</given-names></name><name><surname>Barthó</surname> <given-names>P</given-names></name><name><surname>Moore</surname> <given-names>T</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Diverse coupling of neurons to populations in sensory cortex</article-title><source>Nature</source><volume>521</volume><fpage>511</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1038/nature14273</pub-id><pub-id pub-id-type="pmid">25849776</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pakan</surname> <given-names>JM</given-names></name><name><surname>Francioni</surname> <given-names>V</given-names></name><name><surname>Rochefort</surname> <given-names>NL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Action and learning shape the activity of neuronal circuits in the visual cortex</article-title><source>Current Opinion in Neurobiology</source><volume>52</volume><fpage>88</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2018.04.020</pub-id><pub-id pub-id-type="pmid">29727859</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panas</surname> <given-names>D</given-names></name><name><surname>Amin</surname> <given-names>H</given-names></name><name><surname>Maccione</surname> <given-names>A</given-names></name><name><surname>Muthmann</surname> <given-names>O</given-names></name><name><surname>van Rossum</surname> <given-names>M</given-names></name><name><surname>Berdondini</surname> <given-names>L</given-names></name><name><surname>Hennig</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sloppiness in spontaneously active neuronal networks</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>8480</fpage><lpage>8492</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4421-14.2015</pub-id><pub-id pub-id-type="pmid">26041916</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname> <given-names>Y</given-names></name><name><surname>Choi</surname> <given-names>W</given-names></name><name><surname>Paik</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Symmetry of learning rate in synaptic plasticity modulates formation of flexible and stable memories</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>5671</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-05929-2</pub-id><pub-id pub-id-type="pmid">28720795</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peron</surname> <given-names>SP</given-names></name><name><surname>Freeman</surname> <given-names>J</given-names></name><name><surname>Iyer</surname> <given-names>V</given-names></name><name><surname>Guo</surname> <given-names>C</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A cellular resolution map of barrel cortex activity during tactile behavior</article-title><source>Neuron</source><volume>86</volume><fpage>783</fpage><lpage>799</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.027</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname> <given-names>J</given-names></name><name><surname>Khan</surname> <given-names>AG</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Nemri</surname> <given-names>A</given-names></name><name><surname>Orsolic</surname> <given-names>I</given-names></name><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Keller</surname> <given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning enhances sensory and multiple Non-sensory representations in primary visual cortex</article-title><source>Neuron</source><volume>86</volume><fpage>1478</fpage><lpage>1490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.037</pub-id><pub-id pub-id-type="pmid">26051421</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus-dependent suppression of Chaos in recurrent neural networks</article-title><source>Physical Review E</source><volume>82</volume><elocation-id>011903</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.82.011903</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranson</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stability and plasticity of contextual modulation in the mouse visual cortex</article-title><source>Cell Reports</source><volume>18</volume><fpage>840</fpage><lpage>848</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2016.12.080</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rokni</surname> <given-names>U</given-names></name><name><surname>Richardson</surname> <given-names>AG</given-names></name><name><surname>Bizzi</surname> <given-names>E</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Motor learning with unstable neural representations</article-title><source>Neuron</source><volume>54</volume><fpage>653</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.04.030</pub-id><pub-id pub-id-type="pmid">17521576</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname> <given-names>T</given-names></name><name><surname>Jaepel</surname> <given-names>J</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cell-specific restoration of stimulus preference after monocular deprivation in the visual cortex</article-title><source>Science</source><volume>352</volume><fpage>1319</fpage><lpage>1322</lpage><pub-id pub-id-type="doi">10.1126/science.aad3358</pub-id><pub-id pub-id-type="pmid">27284193</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roxin</surname> <given-names>A</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Efficient partitioning of memory systems and its importance for memory consolidation</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003146</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003146</pub-id><pub-id pub-id-type="pmid">23935470</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rule</surname> <given-names>ME</given-names></name><name><surname>O'Leary</surname> <given-names>T</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Causes and consequences of representational drift</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>141</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.08.005</pub-id><pub-id pub-id-type="pmid">31569062</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoups</surname> <given-names>A</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name><name><surname>Qian</surname> <given-names>N</given-names></name><name><surname>Orban</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Practising orientation identification improves orientation coding in V1 neurons</article-title><source>Nature</source><volume>412</volume><fpage>549</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1038/35087601</pub-id><pub-id pub-id-type="pmid">11484056</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sedigh-Sarvestani</surname> <given-names>M</given-names></name><name><surname>Nolte</surname> <given-names>M</given-names></name><name><surname>Mardoum</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Population coupling in the mouse visual cortex</article-title><conf-name>In Computational and Systems Neuroscience (Cosyne)</conf-name><fpage>1</fpage><lpage>44</lpage></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengpiel</surname> <given-names>F</given-names></name><name><surname>Stawinski</surname> <given-names>P</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Influence of experience on orientation maps in cat visual cortex</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>727</fpage><lpage>732</lpage><pub-id pub-id-type="doi">10.1038/11192</pub-id><pub-id pub-id-type="pmid">10412062</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Singh</surname> <given-names>A</given-names></name><name><surname>Peyrache</surname> <given-names>A</given-names></name><name><surname>Humphries</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Plasticity of a neural dictionary in prefrontal cortex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/027102</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sweeney</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>sweeney_clopath_2020</data-title><source>GitHub</source><version designator="4f1c8dd">4f1c8dd</version><ext-link ext-link-type="uri" xlink:href="https://github.com/yannaodh/sweeney_clopath_2020">https://github.com/yannaodh/sweeney_clopath_2020</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tremblay</surname> <given-names>R</given-names></name><name><surname>Lee</surname> <given-names>S</given-names></name><name><surname>Rudy</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>GABAergic interneurons in the neocortex: from cellular properties to circuits</article-title><source>Neuron</source><volume>91</volume><fpage>260</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.033</pub-id><pub-id pub-id-type="pmid">27477017</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Triesch</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Synergies between intrinsic and synaptic plasticity mechanisms</article-title><source>Neural Computation</source><volume>19</volume><fpage>885</fpage><lpage>909</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.4.885</pub-id><pub-id pub-id-type="pmid">17348766</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turrigiano</surname> <given-names>GG</given-names></name><name><surname>Leslie</surname> <given-names>KR</given-names></name><name><surname>Desai</surname> <given-names>NS</given-names></name><name><surname>Rutherford</surname> <given-names>LC</given-names></name><name><surname>Nelson</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons</article-title><source>Nature</source><volume>391</volume><fpage>892</fpage><lpage>896</lpage><pub-id pub-id-type="doi">10.1038/36103</pub-id><pub-id pub-id-type="pmid">9495341</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Sprekeler</surname> <given-names>H</given-names></name><name><surname>Zenke</surname> <given-names>F</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title><source>Science</source><volume>334</volume><fpage>1569</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1126/science.1211095</pub-id><pub-id pub-id-type="pmid">22075724</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Watanabe</surname> <given-names>K</given-names></name><name><surname>Teramae</surname> <given-names>J-n</given-names></name><name><surname>Wakamiya</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Inferred Duality of Synaptic Connectivity in Local Cortical Circuit with Receptive Field Correlation</source><publisher-name>Springer International Publishing</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-319-46687-3_12</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zenke</surname> <given-names>F</given-names></name><name><surname>Agnes</surname> <given-names>EJ</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6922</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7922</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zylberberg</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Untuned but not irrelevant: a role for untuned neurons in sensory information coding</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/134379</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Supplementary materials</title><boxed-text><sec id="s9"><title>Methods for Figure S1</title><p>We simulate a network of 1 postsynaptic neuron and 10 presynaptic neurons. 3 of the presynaptic neurons share the same stimulus preference as the postsynaptic neuron and the remaining have different preferred stimuli. We then identify the parameter regime in which the coupling of the single plastic neuron to the rest of the population is correlated to its learning rate. To do so, we measure the population coupling of the postsynaptic neuron for a range of different learning rates from <inline-formula><mml:math id="inf191"><mml:mrow><mml:mn mathsize="90%">0.5</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="90%">α</mml:mi><mml:mtext mathsize="90%">s</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf192"><mml:mrow><mml:mn mathsize="90%">10</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathsize="90%">α</mml:mi><mml:mtext mathsize="90%">s</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>, using a separate network instantiation for each value of <inline-formula><mml:math id="inf193"><mml:mi mathsize="90%">α</mml:mi></mml:math></inline-formula>. We then estimate the slope of the relationship between population coupling and <inline-formula><mml:math id="inf194"><mml:mi mathsize="90%">α</mml:mi></mml:math></inline-formula> using linear regression, across a range of values for the synaptic scaling rate (<inline-formula><mml:math id="inf195"><mml:mi mathsize="90%">ζ</mml:mi></mml:math></inline-formula>) and noise magnitude (<inline-formula><mml:math id="inf196"><mml:msub><mml:mi mathsize="90%">σ</mml:mi><mml:mtext mathsize="90%">OU</mml:mtext></mml:msub></mml:math></inline-formula>).</p><p>This can be expressed by the terms in (<xref ref-type="disp-formula" rid="equ12">Equation 12</xref>), below, which describe a synaptic weight update dW under Hebbian plasticity with learning rate <inline-formula><mml:math id="inf197"><mml:mi mathsize="90%">α</mml:mi></mml:math></inline-formula> and synaptic scaling with rate <inline-formula><mml:math id="inf198"><mml:mi mathsize="90%">ζ</mml:mi></mml:math></inline-formula>. For specific weights, the correlation with the input, corr(stim), is high, meaning that these weights tend to be large. For non-specific weights, corr(stim) is close to 0 and so does not contribute to the update dW. From the terms in (<xref ref-type="disp-formula" rid="equ12">Equation 12</xref>), we can see that a large <inline-formula><mml:math id="inf199"><mml:mi mathsize="90%">α</mml:mi></mml:math></inline-formula>, the presence of noise, and a small <inline-formula><mml:math id="inf200"><mml:mi mathsize="90%">η</mml:mi></mml:math></inline-formula>, can all contribute to large non-specific weights.<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mi mathsize="90%">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathsize="90%">W</mml:mi></mml:mrow><mml:mo mathsize="90%" stretchy="false">=</mml:mo><mml:mrow><mml:mrow><mml:mi mathsize="90%">α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="90%" minsize="90%">(</mml:mo><mml:mrow> <mml:mtext mathsize="90%">corr(stim)</mml:mtext><mml:mo mathsize="90%" stretchy="false">+</mml:mo><mml:mtext mathsize="90%">corr(noise)</mml:mtext></mml:mrow><mml:mo maxsize="90%" minsize="90%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="90%" stretchy="false">-</mml:mo><mml:mrow><mml:mi mathsize="90%">ζ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="90%" minsize="90%">(</mml:mo><mml:mrow><mml:msub><mml:mi mathsize="90%">W</mml:mi><mml:mtext mathsize="90%">total</mml:mtext></mml:msub><mml:mo mathsize="90%" stretchy="false">-</mml:mo><mml:msub><mml:mi mathsize="90%">W</mml:mi><mml:mtext mathsize="90%">target</mml:mtext></mml:msub></mml:mrow><mml:mo maxsize="90%" minsize="90%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.56053.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Richards</surname><given-names>Blake A</given-names></name><role>Reviewer</role><aff><institution>McGill University</institution><country>Canada</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Doiron</surname><given-names>Brent</given-names> </name><role>Reviewer</role><aff><institution>University of Pittsburgh</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Many brain models work with just the mean activity across a population, ignoring the wide diversity of response properties that is characteristic of many neuronal population recordings. The authors provide modelling results which point to an intriguing link between the diversities of response variability and synaptic learning rates. A signature of this diversity link is seen in a relation between how malleable a neuron's tuning is over time and how coupled a neuron's activity is to the whole population. This prediction was validated with population recordings in mouse V1, giving support for their modelling work. Building models that explore the inherent diversity of neuronal response, in its various forms, is an important avenue of study and this work provides a critical step in this direction.</p><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;Population coupling predicts the plasticity of stimulus responses in cortical circuits&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and a Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Blake A Richards (Reviewer #3).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>There was considerable enthusiasm for the approach and for the novel hypothesis that, in a network with diverse learning rates, neurons with fast rates are more coupled to population activity than neurons with slow rates. The attempt to substantiate this hypothesis by using recordings from the Allen Brain Observatory was considered a considerable strength. However as amply stated in the original reviews, the strength/shape/significance of the relationships in Figures 3E,F are not firmly established and some more compelling insight into the diversity of timescales in the actual data is definitely needed.</p><p>A new submission of a thoroughly reworked paper that addresses these concerns and additional concerns in original reviews could be viewed favorably at <italic>eLife</italic>. The Reviewing Editor would particularly refer the authors to concerns by reviewer #1 &quot;I would have expected an associated Figure 3E and F from the model so that a better comparison could be made and we could understanding how much the α's need to vary.&quot; and &quot;The relation between learning diversity and population coupling is interesting – but outside of the initial observation in the model there is no real theory/understanding for this relation being offered&quot;, and from reviewer #3 &quot;They begin with diverse learning rates and then examine the effect on population coupling. But, what if, functionally, population coupling should determine learning rate, as stipulated by gradient descent?&quot;</p><p><italic>Reviewer #1:</italic></p><p>The paper by Sweeny and Clopath investigates how a diversity of plasticity timescales allows for a diversity of neuronal coupling to population activity. Overall, the paper investigates an interesting effect. However, I feel that the paper falls short in several areas. I explain these below.</p><p>1) While the comparison to the Allen dataset is inspired, the end result is somewhat disappointing. The relation between change in preferred orientation and population coupling shown in Figure 3E and F are quite weak (I realize that it is statistically significant). Further, there is no attempt to relate the weak trend in the data to the distribution of learning timescales that would be required to produce it. This is likely because the model is simplified and there is not a real sense of continuous tuning (only four orientations were shown). In this way the model prediction is not really tight. I would have expected an associated Figure 3E and F from the model so that a better comparison could be made and we could understanding how much the α's need to vary.</p><p>2) The relation between learning diversity and population coupling is interesting – but outside of the initial observation in the model there is no real theory/understanding for this relation being offered. Is there a simple mean field style theory that can be put forth? Can other sources of heterogeneity (say single neuron baseline firing rate r<sub>0</sub>) create a similar relation? Why is there a spread of population coupling in the uniform α case? Answers to these questions could help build a deeper understanding of the key result. As it stands the paper simply shows simulation results and gives a loose connection between synaptic variability, population coupling, and response tuning. I expect more in a high profile publication.</p><p><italic>Reviewer #2:</italic></p><p>Sweeney and Clopath report simulations and analysis of in vivo calcium imaging data suggesting that neurons with faster learning rates will exhibit higher population coupling, consistent with the idea of functional network architecture composed of slowly-changing connectivity between stably tuned neurons and quickly changing connectivity between unstably tuned neurons.</p><p>The authors begin by studying networks where they train a low-dimensional structure into the excitatory weights (four-dimensional in Figure 1, and I would guess 8-dimensional in Figure 2 due to the 8 orientations of receptive field), with one global inhibitory neuron. Population coupling describes a one-dimensional correlation structure – is this an appropriate description for these network, or are the activity four or eight dimensional? How do the correlations within- and between the trained structures relate to the population coupling, and how does the timescale of a neuron's plasticity relate to its coupling to co-stimulated neurons vs non-co-stimulated neurons?</p><p>What is the relationship between the timescale of the associations trained in Figure 4, and do the results depend on the relationship between that timescale of stimulation and the fast/slow timescales of plasticity?</p><p>I applaud the authors for seeking a direct experimental test of their model's results. The results of that test (Figure 3E) seem, however, fairly weak. More importantly, it seems that the basic characterization of tuning stability in this data has been skipped over, which makes it difficult to interpret these results.</p><p>The trial-by-trial responses to gratings (at least in the Allen Brain Observatory dataset) exhibit significant variability, and the tuning curve is often a poor predictor of the responses. This requires, I think, a stronger analysis to test the authors' prediction.</p><p>a) First off, how stable is the tuning? Is orientation selectivity stable? If there are neurons that are tuned only in the early or the late epoch, how does that match with the model?</p><p>b)In Figure 3B, it seems that the neurons with the largest responses are the most population coupled, which makes sense given the definition of population coupling. How does this contribute to the neurons' orientation selectivity and relate to tuning stability?</p><p>c) In neurons that are significantly tuned at the early and late epochs, is their tuning different? This is close to what the authors asked, but I think it could be made more rigorous – one idea is by a statistical test asking whether the distribution of responses to the initially preferred stimulus is distinguishable between the early and late grating epochs. (And correspondingly for the preferred stimulus of the late epoch.)</p><p>d)In Figure 3B, it seems that the neurons with the largest responses are the most population coupled, which makes sense given the definition of population coupling. Does this hold up with extracted events? How does this contribute to the neurons' orientation selectivity and relate to tuning stability?</p><p>e) How do these results relate to the degree of neurons' tuning and the reliability of their responses? Do strongly tuned neurons have more stable stimulus preferences? Do neurons with lower trial-to-trial variability have more stable stimulus preferences?</p><p>f) The authors refer only to orientation tuning. For the drifting gratings, what about direction? (And what about spatial or temporal frequencies?)</p><p>g) The description of which data from the Allen Brain Observatory were used seems incomplete. How were experiments chosen to include; which Cre lines, layers, and areas were the data used from? Do the results differ across those dimensions? That dataset currently includes a lot more than the 112 experiments with gratings included.</p><p>h) The observatory API also included extracted events, to account for the autocorrelation time of the fluorescence. Do the results depend on the use of df/f compared to events?</p><p><italic>Reviewer #3:</italic></p><p>In this paper, Sweeney and Clopath examine the relationship between &quot;population coupling&quot; and synaptic plasticity, both in a series of computational models and experimental data from the Allen Brain Institute (2-photon calcium imaging in mouse primary visual cortex). The metric used for population coupling here is the same one introduced by Okun et al., 2015, namely, the extent to which a given neuron correlates with the average activity of the entire population.</p><p>In their first model, the authors examine the impact of diverse learning rates on excitatory synapses in a fully connected model of rate-based, leaky neurons. The excitatory synapses are updated using a Hebbian rule (with some competition for stabilization). The Hebbian updates are controlled with learning rates \α<sub>i</sub>, where i is the index of the neuron. Thus, each neuron can have its own learning rate. The authors demonstrate that neurons with fast learning rates tend to have less specificity in their connections, and more fluctuations in that specificity as well. Furthermore, they show that there is a relationship between learning rate and population coupling, with higher population coupling for neurons with larger learning rates. They also show that diverse population coupling is a natural consequence of diverse learning rates. Thus, their model predicts that if cortical neurons possess a diverse set of learning rates, then there should be a high degree of variability in population coupling, and neurons with greater population coupling should be those that are most plastic.</p><p>The authors then examine whether these predictions from their model are borne out in the Allen data. They demonstrate that there is indeed a high diversity in population coupling of excitatory neurons (as observed by Okun et al.). As well, they show that neurons whose preferred stimulus orientation changes most over the course of the recording session are those with the greatest degree of population coupling, as predicted by their model.</p><p>Finally, the authors examine the functional implications of diverse learning rates in networks with sensory inputs and potential for learned associations. They show that diverse learning rates in their model helps to maintain the ability of the neurons to carry information about stimulus identity while permitting continual learning of new stimulus associations.</p><p>Overall, I think this is an excellent paper. I really enjoyed it. The introduction of a computational model that makes clear experimental predictions, followed by an explicit test of those predictions in available large datasets is exactly how computational neuroscience should proceed, and I applaud the authors for this. I also appreciated the attempt to show the functional importance of diverse learning rates at the end of the paper.</p><p>I have two related concerns about the findings in the paper, though, which I would encourage the authors to consider. The root of my concerns is the lack of a normative framework for understanding learning in both the models and the data. The authors begin with diverse learning rates as a potential phenomenon, then attempt to make predictions and explore functional implications. I wonder whether flipping this might not have been a more fruitful approach for explaining the experimental data. That is, the authors could have started with a question of what functional problem is to be solved, then showed that diverse learning rates could solve it, and then confirmed the phenomenon in the data. There are two reasons why this more normative approach may be better at explaining the data:</p><p>1) An alternative account for the phenomenon the authors observe in the Allen data can be found in normative models. Consider a recurrent neural network trained with gradient descent to perform some function. Regardless of the function being learned, on average, neurons with greater impact on the rest of the network will have larger synaptic updates than other neurons. This is because the gradient of any function with respect to a neuron will depend on its ability to influence future activity, and neurons that contribute more to the gradient will be updated more. Now, neurons with a strong tendency to activate other neurons will have high levels of population coupling, while neurons with a tendency to inhibit other neurons (disynaptically, since these are excitatory neurons) will have low levels of population coding. Neurons with limited impact will have middle levels of population coupling. Thus, a gradient based account would predict that there should be a U-shaped curve relating population coupling to plasticity. To my eye, that is precisely what the Allen data actually shows (Figure 3E). Thus, I worry that the authors have it backwards. They begin with diverse learning rates and then examine the effect on population coupling. But, what if, functionally, population coupling should determine learning rate, as stipulated by gradient descent? Now, to be clear, I do not think the authors have to actually address this hypothesis I put forward with new simulations. Per the <italic>eLife</italic> philosophy, I would like to improve this paper, not demand the paper I may have been inclined to write myself. So, I don't think new simulations are needed. However, given the slightly questionable fit of their model hypothesis to the data shown in Figure 3E, I think that this alternative hypothesis should at least be mentioned in the Discussion.</p><p>2) The purpose of the simulations in Figure 4 were a bit mysterious to me. The authors appeared to make fairly strong assumptions about what would be useful to a network, e.g. that it would be good to show increased selectivity to some external stimulus, or that information should be as preserved as possible. But, why not start with the more obvious normative framework for multiple learning rates, and one which the authors identify in the Discussion, i.e. the need to avoid catastrophic forgetting? This is sort of demonstrated in Figure 4, but in an indirect fashion that relies on the assumption that selectivity is a good performance metric. Why not actually use the networks to perform various tasks, and show that the networks are better at avoiding catastrophic forgetting of the tasks when diverse learning rates are present? Even a simple task would be easier to understand the implications, than the selectivity measurements provided by the authors, in my opinion. But, again, I don't actually think new simulations would be required, per se (though they could help). Nonetheless, I think a more intuitive account for why selectivity is the right metric to use would be helpful.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Population coupling predicts the plasticity of stimulus responses in cortical circuits&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Ronald Calabrese (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>Please make the following very minor but important edits directed by the reviewer comments provided. These should be accomplished rapidly so as not to hold-up publication and will require only the Reviewing Editor to review.</p><p><italic>Reviewer #1:</italic></p><p>Figure 1—figure supplement 1 discussion: Why change the parameter for the synaptic scaling rate from zeta to eta? Does zeta refer to something else?</p><p>Figure 3E: missing x axis ticks for static gratings.</p><p>Throughout, the figures have a variety of font sizes for the tick labels, axis labels, and legends. Making these uniform, within and across figures, would make them easier to read.</p><p><italic>Reviewer #2:</italic></p><p>In their revised paper, Sweeney and Clopath have addressed most of the concerns raised by myself and the other reviewers quite well. In my opinion, the paper is very close to being ready for publication. I have one final quibble related to the first major concern I raised in my initial review.</p><p>In my initial review, I noted that there is an alternative hypothesis based on normative models which posits that neurons with strong population coupling should be more plastic because they have a greater impact on the network, and thus are more important for any performance gradients. But. this hypothesis also posits that neurons that inhibit other neurons a lot, thus which may have extremely low population coupling, would also be more plastic.</p><p>The authors have almost satisfied my concerns with their response. I appreciate their attempt at testing whether this prediction holds in the data. However, their test is ill-formed. They test this hypothesis by assigning a semi-arbitrary threshold for low (&lt; 0.2) vs. medium (&gt;=0.2, &lt;=0.4) vs. high (&gt;0.4) population coupling, and then testing whether neurons in the Allen data with low population coupling show bigger orientation changes than neurons with medium orientation changes. They report that the tests were non-significant, and conclude that the data doesn't support this hypothesis.</p><p>This test rests on the idea that we can group the neurons into these three bins and hope to test this alternative hypothesis. Yet, we do not really know how the scale of the population coupling metric used here relates to real impact on network activity in the brain. For example, it could be that neurons with a population coupling metric of 0.3 actually have a fairly big impact on the network, so they should be in the high group. Essentially, we have no principled way to judge what the threshold for these groups should be. Indeed, I am not surprised that the tests came out as non-significant, because it is clear that the Δ ORI pref begins to increase after a level of around 0.25 in population coupling.</p><p>As it stands, by my eye, the data in Figure 3E still suggests that there is an initial decrease in Δ ORI pref as we move from really low population coupling, then an increase again as we move further out. The test given does not convince me otherwise. Really, if the goal were to convince me that this alternative hypothesis cannot account for the data as well as their model, the authors would need to determine whether a linear model with nothing but a monotonic increase in Δ ORI pref accounts for the data better than a non-linear or bi-linear model that include an initial decrease. My bet is that the latter model would be better at fitting the data, even after consideration of increased parameters (e.g. via the AIC or something).</p><p>However, I don't need to see this analysis per se, and I don't intend to hold up publication of this paper based on my personal interpretation of the data. What I would like to see is simply a change in the text that is now given in the Discussion. The authors write:</p><p>&quot;Thus, a gradient-based account would predict that there should be a U-shaped curve relating population coupling to plasticity. Although we did not observe such a relationship, this may be a fruitful avenue of enquiry for future experiments.&quot;</p><p>I think that, to be more honest, this should read something more like:</p><p>&quot;Thus, a gradient-based account would predict that there should be a U-shaped curve relating population coupling to plasticity. Our data showed may show some initial decrease in plasticity as population coupling increases (Figure 3F), but these questions outstrip the focus of this work. Consideration of whether alternative models based on gradients could explain this data may nonetheless be a fruitful avenue of enquiry for future experiments.&quot;</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.56053.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>A new submission of a thoroughly reworked paper that addresses these concerns and additional concerns in original reviews could be viewed favorably at eLife. The Reviewing Editor would particularly refer the authors to concerns by reviewer #1 &quot;I would have expected an associated Figure 3E and F from the model so that a better comparison could be made and we could understanding how much the α's need to vary.&quot;</p></disp-quote><p>We have now included a more direct comparison between the data and our model, by including data from the network simulations within Figure 3F. Both the network simulation and experimental data are consistent with a link between population coupling and fluctuations in selectivity.</p><disp-quote content-type="editor-comment"><p>and &quot;The relation between learning diversity and population coupling is interesting – but outside of the initial observation in the model there is no real theory/understanding for this relation being offered&quot;,</p></disp-quote><p>We have also included an exploration of how much the α’s (learning rate) need to vary in order to match the distribution of population coupling observed experimentally (Figure 3—figure supplement 2, distribution shown in Figure 3C).</p><disp-quote content-type="editor-comment"><p>and from reviewer #3 &quot;They begin with diverse learning rates and then examine the effect on population coupling. But, what if, functionally, population coupling should determine learning rate, as stipulated by gradient descent?&quot;</p></disp-quote><p>We thought that this was a very interesting hypothesis, and tested it further in the data (described below). We found no strong statistical evidence for this in the current data, but now discuss it in the manuscript.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The paper by Sweeny and Clopath investigates how a diversity of plasticity timescales allows for a diversity of neuronal coupling to population activity. Overall, the paper investigates an interesting effect. However, I feel that the paper falls short in several areas. I explain these below.</p><p>1) While the comparison to the Allen dataset is inspired, the end result is somewhat disappointing. The relation between change in preferred orientation and population coupling shown in Figure 3E and F are quite weak (I realize that it is statistically significant). Further, there is no attempt to relate the weak trend in the data to the distribution of learning timescales that would be required to produce it. This is likely because the model is simplified and there is not a real sense of continuous tuning (only four orientations were shown). In this way the model prediction is not really tight. I would have expected an associated Figure 3E and F from the model so that a better comparison could be made and we could understanding how much the α's need to vary.</p></disp-quote><p>We also now calculate the population coupling ratio for neurons with low/high fluctuations in the model, and show them alongside the data in Figure 3F. The trend is similar to that seen in the data, i.e. the ratio &gt; 1 across 15 network simulations. Neurons with high fluctuations in their selectivity have a higher population coupling than neurons with low fluctuations. We define low/high fluctuations by whether there are &lt; or &gt; the median fluctuation.</p><p>Although there are indeed 4 orientations in the Figure 1 model, there are 8 orientations in the Figure 2 models, which is a more detailed model. While conducting our initial network simulations we also explored a wider range of orientations (up to 32), and simulations in which orientation tuning is randomly generated from a continuous distribution. We found that the trend between population coupling and change in selectivity was conserved across these simulations, but chose to use simulations with 8 orientations in our extended analysis, as this number of orientations are more consistent with the Brain Observatory data. In addition, we found that we need a large number of neurons per orientation to gather enough observations about changes in selectivity to use in our analyses (i.e. if we used 32 orientations we would need to simulate with 4x as many neurons, which was infeasible given our computational resources).</p><disp-quote content-type="editor-comment"><p>2) The relation between learning diversity and population coupling is interesting – but outside of the initial observation in the model there is no real theory/understanding for this relation being offered. Is there a simple mean field style theory that can be put forth? Can other sources of heterogeneity (say single neuron baseline firing rate r<sub>0</sub>) create a similar relation? Why is there a spread of population coupling in the uniform α case? Answers to these questions could help build a deeper understanding of the key result. As it stands the paper simply shows simulation results and gives a loose connection between synaptic variability, population coupling, and response tuning. I expect more in a high profile publication.</p></disp-quote><p>The theory for understanding the link between population coupling and synaptic input diversity has already been proposed by Okun et al., which theoretically and empirically link population coupling to specific versus non-specific synaptic connections (and discuss how factors such as baseline firing rate doesn’t contribute to this effect). We build upon this, proposing a mechanism that gives rise to the diverse ratios of specific/non-specific connections. Of course, there are many different plasticity rules which could achieve this, but a key factor is that – assuming some form of Hebbian plasticity – some neurons are more sensitive to transiently correlated ‘population’ activity than others, and develop stronger coupling to it. For us, this is expressed as the learning rate (see Figure 1—figure supplement 1).</p><p>This can be expressed by the terms in equation 1, below. For specific weights (W<sub>spec</sub>), corr(stim) is high, meaning that the W<sub>spec</sub> tends to be large. For non-specific weights, corr(stim) is ~ 0. From the terms in equation 1, we can see that a large α, large corr(noise), and small eta, can all contribute to a large W<sub>nonspec</sub></p><p>dW = α*(corr(stim)+corr(noise)) – eta*(W<sub>total</sub>-W<sub>target</sub>) Equation 1</p><p>This is now discussed alongside Figure 1—figure supplement 1.</p><p>We also investigated how other forms of heterogeneity affects the distribution of population coupling, e.g. the single neuron baseline firing rate r<sub>0</sub>, as suggested by the reviewer. We found that introducing a uniform distribution of r<sub>0</sub>, along a range which we also varied, did not introduce substantial changes in the distribution of population coupling (shown in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>).</p><fig id="respfig1"><label>Author response image 1.</label><caption><title>Distribution of population coupling in network simulations as we vary the range of the uniform baseline firing rate distribution, from 1 to 15.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-resp-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>Sweeney and Clopath report simulations and analysis of in vivo calcium imaging data suggesting that neurons with faster learning rates will exhibit higher population coupling, consistent with the idea of functional network architecture composed of slowly-changing connectivity between stably tuned neurons and quickly changing connectivity between unstably tuned neurons.</p><p>The authors begin by studying networks where they train a low-dimensional structure into the excitatory weights (four-dimensional in Figure 1, and I would guess 8-dimensional in Figure 2 due to the 8 orientations of receptive field), with one global inhibitory neuron. Population coupling describes a one-dimensional correlation structure – is this an appropriate description for these network, or are the activity four or eight dimensional? How do the correlations within- and between the trained structures relate to the population coupling, and how does the timescale of a neuron's plasticity relate to its coupling to co-stimulated neurons vs non-co-stimulated neurons?</p></disp-quote><p>Due to the relatively high amount of injected noise and recurrent connections within the network, the network activity does not tend to be low-dimensional. This is demonstrated in the plots in <xref ref-type="fig" rid="respfig2">Author response image 2</xref> showing the pairwise correlation matrix (left) of the activity of neurons in a network with 8 orientations, and where there is no discernible correlation structure. The distribution of pairwise correlation coefficients is also a broad and unimodal (right). The relation between the timescale of a neurons’ plasticity and its coupling to co-stimulated vs non-co-stimulated neurons is shown in Figure 1E (the co-stimulated neurons are ‘specific connections’ and the non co-stimulated neurons are ‘non-specific).</p><fig id="respfig2"><label>Author response image 2.</label><caption><title>Pairwise correlations.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-resp-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>What is the relationship between the timescale of the associations trained in Figure 4, and do the results depend on the relationship between that timescale of stimulation and the fast/slow timescales of plasticity?</p></disp-quote><p>The timescale of the change in stimulation is 25 seconds, and is slower than the timescale of both slow and fast plasticity. The change in stimulation needs to be slow enough so that learning the associated stimulus occurs, so that we can demonstrate that neurons with fast plasticity exhibit earlier and stronger associative learning. Although the associated stimulus switches before the neurons with slow plasticity complete learning, we can still see the cumulative effect of the associative learning paradigm in Figure 4A.</p><disp-quote content-type="editor-comment"><p>I applaud the authors for seeking a direct experimental test of their model's results. The results of that test (Figure 3E) seem, however, fairly weak. More importantly, it seems that the basic characterization of tuning stability in this data has been skipped over, which makes it difficult to interpret these results.</p><p>The trial-by-trial responses to gratings (at least in the Allen Brain Observatory dataset) exhibit significant variability, and the tuning curve is often a poor predictor of the responses. This requires, I think, a stronger analysis to test the authors' prediction.</p><p>a) First off, how stable is the tuning? Is orientation selectivity stable? If there are neurons that are tuned only in the early or the late epoch, how does that match with the model?</p></disp-quote><p>We quantify the stability of tuning by looking at the reliability of orientation responses (Figure 3, Figure 3—figure supplement 1). The reliability is a measure provided in the Allen Brain Observatory API, and is the mean trial-to-trial correlation of the dF/F calcium fluorescence traces during the neurons preferred stimulus presentation. This seemed to us a good measure for assessing the stability of tuning. There is a relatively broad distribution of reliabilities across neurons, and the distribution differs somewhat for the drifting grating and static grating experiments, with neurons having more reliable responses in the drifting grating experiments. This is encouraging, as it is also the stimulus set in which we see the strongest link between population coupling and plasticity of stimulus selectivity. So, we don’t think we are seeing these effects because the neurons are simply very unreliable. To test this further, we reanalyse the effects using only neurons with high reliability across the experiment, and find that the correlation between population coupling and plasticity is in fact stronger for these neurons, across both static and drifting grating stimulus sets.</p><disp-quote content-type="editor-comment"><p>b)In Figure 3B, it seems that the neurons with the largest responses are the most population coupled, which makes sense given the definition of population coupling. How does this contribute to the neurons' orientation selectivity and relate to tuning stability?</p></disp-quote><p>We explore this relationship – and other relevant measures – in Figure 3—figure supplement 4. We found that there is no statistically significant relationship between mean response and tuning stability (Figure 3—figure supplement 1B), but that peak response and tuning stability are correlated (Figure 3—figure supplement 4C). We found that the relationship between the plasticity of tuning and population coupling remained when controlling for peak responses as a potential confounding factor (Figure 3—figure supplement 4F).</p><disp-quote content-type="editor-comment"><p>c) In neurons that are significantly tuned at the early and late epochs, is their tuning different? This is close to what the authors asked, but I think it could be made more rigorous – one idea is by a statistical test asking whether the distribution of responses to the initially preferred stimulus is distinguishable between the early and late grating epochs. (And correspondingly for the preferred stimulus of the late epoch.)</p></disp-quote><p>While the Brain Observatory API does not provide a way to easily extract the full distribution of responses divided between early and late epochs, we can measure the distributions of the change in mean and variance of the responses to the initially preferred stimulus across the early and late grating epochs. We plot the distribution of signal to noise ratio (SNR), define as |mean(early)-mean(late)|/mean(std(early)+std(late)). In the plot in <xref ref-type="fig" rid="respfig3">Author response image 3</xref>, the changes in early and late responses are either for responses to the initially preferred stimulus (early), the preferred stimulus of the late epoch (late) if there is a change in preferred stimulus, or to a random non-preferred stimulus (random). As may be expected from previous observations about the distribution of fluctuations in stimulus selectivity (Figure 3D), there is a relatively broad range of changes in the response distribution. The SRN distribution of response changes does not seem dependent on whether they are responses to a preferred stimulus or not, although the SNR distribution is more similar for responses to either of the preferred stimuli (KS statistic =.035), compared with responses to a non-preferred stimulus (KS statistic =0.11 (late) and 0.14 (early)).</p><fig id="respfig3"><label>Author response image 3.</label><caption><title>Distribution of SNR.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-resp-fig3-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>d)In Figure 3B, it seems that the neurons with the largest responses are the most population coupled, which makes sense given the definition of population coupling. Does this hold up with extracted events? How does this contribute to the neurons' orientation selectivity and relate to tuning stability?</p></disp-quote><p>The extracted events detected by the brain observatory API doesn’t give us much information, as there aren’t enough events per recording to get good estimates of the population coupling. Recall that it is difficult even to get a decent measure of population coupling even with the df/F fluorescence traces, and we had to discard a substantial number of experiments that didn’t meet our criteria. The number of events is anti-correlated with population coupling, and with orientation preference stability, and uncorrelated with OSI (see <xref ref-type="fig" rid="respfig4">Author response image 4</xref>).</p><fig id="respfig4"><label>Author response image 4.</label><caption><title>Population Coupling.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56053-resp-fig4-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>e) How do these results relate to the degree of neurons' tuning and the reliability of their responses? Do strongly tuned neurons have more stable stimulus preferences? Do neurons with lower trial-to-trial variability have more stable stimulus preferences?</p></disp-quote><p>See above – We measure the reliability of responses across neurons, and find that the results hold, and are stronger, in neurons with high reliability. This is shown in now in Figure 3 and in Figure 3—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>f) The authors refer only to orientation tuning. For the drifting gratings, what about direction? (And what about spatial or temporal frequencies?)</p></disp-quote><p>The direction tuning of drifting grating is also included in our analysis (black versus gray stacks in the histograms). The original Figure 3 considered both orientation and direction tuning together, we now show the analysis and results separately.</p><p>We have now investigated spatial and temporal frequencies. The same effect is present in both these case (Figure 3—figure supplement 3). Note also that orientation tuning exhibits a weaker effect than direction tuning, consistent with a static/drifting grating difference. It’s possible that this is just due to them being different experiments, or due to there being more plasticity evoked by drifting gratings versus static gratings.</p><disp-quote content-type="editor-comment"><p>g) The description of which data from the Allen Brain Observatory were used seems incomplete. How were experiments chosen to include; which Cre lines, layers, and areas were the data used from? Do the results differ across those dimensions? That dataset currently includes a lot more than the 112 experiments with gratings included.</p></disp-quote><p>We now include a list of the ids of the experiments we used to perform the analysis, as a table available at 10.6084/m9.figshare.11837406. Note also that the analysis was conducted with the first round of datasets released, there have been further releases of datasets since then. We selected datasets from primary visual area (visp) and with line Ai93. The details and list of experiments is now included in our Materials and methods section. Conducting an analysis of how the results differ across layer/areas/Cre lines is beyond the scope of our study, but can be performed using the analysis scripts that we will provide.</p><disp-quote content-type="editor-comment"><p>h) The observatory API also included extracted events, to account for the autocorrelation time of the fluorescence. Do the results depend on the use of df/f compared to events?</p></disp-quote><p>As above, extracted events aren’t useful for us in this analysis – there are not enough samples per recording session.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…]</p><p>I have two related concerns about the findings in the paper, though, which I would encourage the authors to consider. The root of my concerns is the lack of a normative framework for understanding learning in both the models and the data. The authors begin with diverse learning rates as a potential phenomenon, then attempt to make predictions and explore functional implications. I wonder whether flipping this might not have been a more fruitful approach for explaining the experimental data. That is, the authors could have started with a question of what functional problem is to be solved, then showed that diverse learning rates could solve it, and then confirmed the phenomenon in the data. There are two reasons why this more normative approach may be better at explaining the data:</p><p>1) An alternative account for the phenomenon the authors observe in the Allen data can be found in normative models. Consider a recurrent neural network trained with gradient descent to perform some function. Regardless of the function being learned, on average, neurons with greater impact on the rest of the network will have larger synaptic updates than other neurons. This is because the gradient of any function with respect to a neuron will depend on its ability to influence future activity, and neurons that contribute more to the gradient will be updated more. Now, neurons with a strong tendency to activate other neurons will have high levels of population coupling, while neurons with a tendency to inhibit other neurons (disynaptically, since these are excitatory neurons) will have low levels of population coding. Neurons with limited impact will have middle levels of population coupling. Thus, a gradient based account would predict that there should be a U-shaped curve relating population coupling to plasticity. To my eye, that is precisely what the Allen data actually shows (Figure 3E). Thus, I worry that the authors have it backwards. They begin with diverse learning rates and then examine the effect on population coupling. But, what if, functionally, population coupling should determine learning rate, as stipulated by gradient descent? Now, to be clear, I do not think the authors have to actually address this hypothesis I put forward with new simulations. Per the eLife philosophy, I would like to improve this paper, not demand the paper I may have been inclined to write myself. So, I don't think new simulations are needed. However, given the slightly questionable fit of their model hypothesis to the data shown in Figure 3E, I think that this alternative hypothesis should at least be mentioned in the Discussion.</p></disp-quote><p>This is certainly an interesting hypothesis, and we tested this out on the Allen Brain Institute data. Specifically, we tested whether neurons with low population coupling were also more plastic than neurons with average population coupling (i.e. similarly to neurons with high population coupling). To do this, we split the neurons in three groups (low, moderate, high) according to their population coupling. We then tested whether the change in stimulus selectivity was significantly different across neurons in these low/moderate/high groups. The hypothesis – that neurons with low population coupling have higher plasticity of stimulus selectivity than neurons with moderate population coupling, was rejected in all four stimulus types (orientation, direction, spatial frequency, and temporal frequency). We discuss this in the text.</p><p>We did not find such a relationship, finding that (for orientation, direction, and spatial frequency) the plasticity of stimulus selectivity was higher amongst neurons with high population coupling versus low population coupling, and amongst neurons with high population coupling versus moderate population coupling, but not in any other pairwise comparison (Tukey’s multiple comparison test, results below). There were no statistically significant differences for temporal frequency.</p><p>Population coupling is defined as low if &lt; 0.2 (n=230[DG], 602 [SG]), high if &gt; 0.4 (n=193 [DG], 2643 [SG]), and moderate otherwise (n = 717 [DG], 514 [SG]). DG=drifting gratings, SG=static gratings.</p><p>Spatial frequency tuning:</p><p>Multiple Comparison of Means – Tukey HSD,FWER=0.05</p><p><table-wrap id="inlinetable5" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">group1</td><td valign="top">group2</td><td valign="top">meandiff</td><td valign="top">lower</td><td valign="top">upper</td><td valign="top">reject</td></tr><tr><td valign="top">Low</td><td valign="top">Medium</td><td valign="top">-0.0305</td><td valign="top">-0.1391</td><td valign="top">0.078</td><td valign="top">False</td></tr><tr><td valign="top">Low</td><td valign="top">High</td><td valign="top">0.215</td><td valign="top">0.0717</td><td valign="top">0.3584</td><td valign="top">True</td></tr><tr><td valign="top">Medium</td><td valign="top">High</td><td valign="top">0.2456</td><td valign="top">0.1298</td><td valign="top">0.3613</td><td valign="top">True</td></tr></tbody></table></table-wrap></p><p>Orientation tuning:</p><p>Multiple Comparison of Means – Tukey HSD,FWER=0.05</p><p><table-wrap id="inlinetable6" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">group1</td><td valign="top">group2</td><td valign="top">meandiff</td><td valign="top">lower</td><td valign="top">upper</td><td valign="top">reject</td></tr><tr><td valign="top">Low</td><td valign="top">Medium</td><td valign="top">1.5271</td><td valign="top">-4.5566</td><td valign="top">7.6108</td><td valign="top">False</td></tr><tr><td valign="top">Low</td><td valign="top">High</td><td valign="top">11.2159</td><td valign="top">2.5317</td><td valign="top">19.9</td><td valign="top">True</td></tr><tr><td valign="top">Medium</td><td valign="top">High</td><td valign="top">9.6888</td><td valign="top">2.3278</td><td valign="top">17.0499</td><td valign="top">True</td></tr></tbody></table></table-wrap></p><p>Temporal frequency tuning:</p><p>Multiple Comparison of Means – Tukey HSD,FWER=0.05</p><p><table-wrap id="inlinetable7" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">group1</td><td valign="top">group2</td><td valign="top">meandiff</td><td valign="top">lower</td><td valign="top">upper</td><td valign="top">reject</td></tr><tr><td valign="top">Low</td><td valign="top">Medium</td><td valign="top">-0.0335</td><td valign="top">-0.1688</td><td valign="top">0.1019</td><td valign="top">False</td></tr><tr><td valign="top">Low</td><td valign="top">High</td><td valign="top">0.0578</td><td valign="top">-0.1268</td><td valign="top">0.2425</td><td valign="top">False</td></tr><tr><td valign="top">Medium</td><td valign="top">High</td><td valign="top">0.0913</td><td valign="top">-0.0682</td><td valign="top">0.2508</td><td valign="top">False</td></tr></tbody></table></table-wrap></p><p>Direction tuning:</p><p>Multiple Comparison of Means – Tukey HSD,FWER=0.05</p><p><table-wrap id="inlinetable8" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">group1</td><td valign="top">group2</td><td valign="top">meandiff</td><td valign="top">lower</td><td valign="top">upper</td><td valign="top">reject</td></tr><tr><td valign="top">Low</td><td valign="top">Medium</td><td valign="top">8.9885</td><td valign="top">-4.956</td><td valign="top">22.9331</td><td valign="top">False</td></tr><tr><td valign="top">Low</td><td valign="top">High</td><td valign="top">35.6128</td><td valign="top">17.6497</td><td valign="top">53.5758</td><td valign="top">True</td></tr><tr><td valign="top">Medium</td><td valign="top">High</td><td valign="top">26.6242</td><td valign="top">11.702</td><td valign="top">41.5465</td><td valign="top">True</td></tr></tbody></table></table-wrap></p><p>It is possible that further experiments could uncover such a relationship however, so we have included a discussion of this hypothesis in the manuscript.</p><disp-quote content-type="editor-comment"><p>2) The purpose of the simulations in Figure 4 were a bit mysterious to me. The authors appeared to make fairly strong assumptions about what would be useful to a network, e.g. that it would be good to show increased selectivity to some external stimulus, or that information should be as preserved as possible. But, why not start with the more obvious normative framework for multiple learning rates, and one which the authors identify in the Discussion, i.e. the need to avoid catastrophic forgetting? This is sort of demonstrated in Figure 4, but in an indirect fashion that relies on the assumption that selectivity is a good performance metric. Why not actually use the networks to perform various tasks, and show that the networks are better at avoiding catastrophic forgetting of the tasks when diverse learning rates are present? Even a simple task would be easier to understand the implications, than the selectivity measurements provided by the authors, in my opinion. But, again, I don't actually think new simulations would be required, per se (though they could help). Nonetheless, I think a more intuitive account for why selectivity is the right metric to use would be helpful.</p></disp-quote><p>The choice of selectivity as a metric was primarily so that we could perform a like-for-like comparison with what could be measured from the empirical data, i.e. stimulus selectivity. We fully agree with the reviewer that selectivity as a metric doesn’t capture everything, and that there are alternative approaches which may capture more complex stimulus representations, and the plasticity of these representations. Indeed, it would be fascinating to conduct an analysis of how plasticity rate relates to neurons involvement in low-dimensional latent dynamics, similar to that found by Gallego et al. recently, but this is beyond the scope of our current study. We now discuss this in the manuscript in subsection “A plasticity-coupling link in vivo”. Note also that we do measure task performance in Figure 4E, where the task is to decode the identity of pairs of stimuli presented simultaneously to the network. As the reviewer hints at, this task can already be thought of as an indirect test of overcoming catastrophic forgetting, since the stimulus protocol throughout development involves the continual presentation of stimuli throughout synaptic plasticity. Hence the network composed entirely of neurons with fast learning rates performs poorly in this task.</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>Please make the following very minor but important edits directed by the reviewer comments provided. These should be accomplished rapidly so as not to hold-up publication and will require only the Reviewing Editor to review.</p><p>Reviewer #1:</p><p>Figure 1—figure supplement 1 discussion: Why change the parameter for the synaptic scaling rate from zeta to eta? Does zeta refer to something else?</p></disp-quote><p>We corrected the typo.</p><disp-quote content-type="editor-comment"><p>Figure 3E: missing x axis ticks for static gratings.</p></disp-quote><p>We added that.</p><disp-quote content-type="editor-comment"><p>Throughout, the figures have a variety of font sizes for the tick labels, axis labels, and legends. Making these uniform, within and across figures, would make them easier to read.</p></disp-quote><p>We tried our best to uniform the figures.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…]</p><p>However, I don't need to see this analysis per se, and I don't intend to hold up publication of this paper based on my personal interpretation of the data. What I would like to see is simply a change in the text that is now given in the Discussion. The authors write:</p><p>&quot;Thus, a gradient-based account would predict that there should be a U-shaped curve relating population coupling to plasticity. Although we did not observe such a relationship, this may be a fruitful avenue of enquiry for future experiments.&quot;</p><p>I think that, to be more honest, this should read something more like:</p><p>&quot;Thus, a gradient-based account would predict that there should be a U-shaped curve relating population coupling to plasticity. Our data showed may show some initial decrease in plasticity as population coupling increases (Figure 3F), but these questions outstrip the focus of this work. Consideration of whether alternative models based on gradients could explain this data may nonetheless be a fruitful avenue of enquiry for future experiments.&quot;</p></disp-quote><p>We did change the paragraph as suggested.</p></body></sub-article></article>