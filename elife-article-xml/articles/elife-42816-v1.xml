<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">42816</article-id><article-id pub-id-type="doi">10.7554/eLife.42816</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural structure mapping in human probabilistic reward learning</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-110985"><name><surname>Luyckx</surname><given-names>Fabrice</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0656-538X</contrib-id><email>fabrice.luyckx@psy.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-101065"><name><surname>Nili</surname><given-names>Hamed</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-124000"><name><surname>Spitzer</surname><given-names>Bernhard</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-16084"><name><surname>Summerfield</surname><given-names>Christopher</given-names></name><email>christopher.summerfield@psy.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Experimental Psychology</institution><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Wellcome Centre for Integrative Neuroimaging</institution><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Adaptive Rationality</institution><institution>Max Planck Institute for Human Development</institution><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Lee</surname><given-names>Daeyeol</given-names></name><role>Reviewing Editor</role><aff><institution>Yale School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>07</day><month>03</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e42816</elocation-id><history><date date-type="received" iso-8601-date="2018-10-12"><day>12</day><month>10</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-02-21"><day>21</day><month>02</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Luyckx et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Luyckx et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-42816-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.42816.001</object-id><p>Humans can learn abstract concepts that describe invariances over relational patterns in data. One such concept, known as magnitude, allows stimuli to be compactly represented on a single dimension (i.e. on a mental line). Here, we measured representations of magnitude in humans by recording neural signals whilst they viewed symbolic numbers. During a subsequent reward-guided learning task, the neural patterns elicited by novel complex visual images reflected their payout probability in a way that suggested they were encoded onto the same mental number line, with 'bad' bandits sharing neural representation with 'small' numbers and 'good' bandits with 'large' numbers. Using neural network simulations, we provide a mechanistic model that explains our findings and shows how structural alignment can promote transfer learning. Our findings suggest that in humans, learning about reward probability is accompanied by structural alignment of value representations with neural codes for the abstract concept of magnitude.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.42816.002</object-id><title>eLife digest</title><p>Many things in the world have a certain structure to them, which we can use to organize our thinking. To mentally represent your family, for example, you could group your family members into men and women, or group them based on where they live. But a more intuitive approach for most people is to organize family members by generation: child, sibling, parent, grandparent. It is as though we instinctively place each family member along a mental line, from young to old.</p><p>We use mental lines to organize other types of information too, most notably numbers. But can we also use them to represent new information? Luyckx et al. trained healthy volunteers to associate pictures of six different colored donkeys with six different reward probabilities. One donkey was followed by reward 5% of the time, another was followed by reward 95% of the time, and so on. Through trial and error, the volunteers learned to rank the donkeys in terms of how likely they were to precede a reward. Luyckx et al. then compared the volunteers’ brain activity while viewing the donkeys to their brain activity while viewing the numbers 1 to 6.</p><p>The donkeys evoked patterns of electrical brain activity corresponding to the number that signaled their place on a mental line. Thus, donkey 1, with the lowest reward probability, produced a pattern of brain activity similar to that of the number 1, and so on for the others. This suggests that rather than learning in an unstructured way, we use past knowledge of relations among stimuli to organize new information. This phenomenon is called structural alignment.</p><p>The results of Luyckx et al. provide the first evidence from brain activity to support structural alignment. They suggest that we use a general understanding of how the world is structured to learn new things. This could be relevant to both education and artificial intelligence. People, and computers, may learn more effectively if taught about the relations between items, rather than just the items in isolation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>structure learning</kwd><kwd>value-based decision-making</kwd><kwd>neural network</kwd><kwd>numerical cognition</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Consolidator Grant CQR01290.CQ001</award-id><principal-award-recipient><name><surname>Summerfield</surname><given-names>Christopher</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>SP 1510/2-1</award-id><principal-award-recipient><name><surname>Spitzer</surname><given-names>Bernhard</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>During learning, human neural codes for experienced reward probability map onto the same mental number line for symbolic numbers.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ability to learn rapidly from limited data is a key ingredient of human intelligence. For example, on moving to a new city, you will rapidly discover which restaurants offer good food and which neighbors provide enjoyable company. Current models of learning propose that appetitive actions toward novel stimuli are learned <italic>tabula rasa</italic> via reinforcement (<xref ref-type="bibr" rid="bib35">Sutton and Barto, 2018</xref>), and these models explain the amplitude of neural signals in diverse brain regions during reward-guided choices in humans and other animals (<xref ref-type="bibr" rid="bib7">Dolan and Dayan, 2013</xref>; <xref ref-type="bibr" rid="bib28">O'Doherty et al., 2003</xref>; <xref ref-type="bibr" rid="bib33">Schultz et al., 1997</xref>). However, reinforcement learning models learn only gradually, and even when coupled with powerful function approximation methods, exhibit limited generalization beyond their training domain (<xref ref-type="bibr" rid="bib24">Mnih et al., 2015</xref>). This has led to the suggestion they are ill-equipped to fully describe human learning (<xref ref-type="bibr" rid="bib19">Lake et al., 2017</xref>).</p><p>By contrast, cognitive scientists have ascribed human intelligence to the formation of abstract knowledge representations (or ‘concepts’) that delimit the structural forms that new data is likely to take (<xref ref-type="bibr" rid="bib12">Gentner, 2010</xref>; <xref ref-type="bibr" rid="bib15">Kemp and Tenenbaum, 2008</xref>; <xref ref-type="bibr" rid="bib37">Tenenbaum et al., 2011</xref>). Indeed, real-world data can often be described by simple relational structures, such as a tree, a grid or a ring (<xref ref-type="bibr" rid="bib37">Tenenbaum et al., 2011</xref>). Humans may infer relational structure through probabilistic computation (<xref ref-type="bibr" rid="bib14">Kemp et al., 2010</xref>) and a long-standing theory proposes that humans understand new domains by their alignment with existing relational structures (<xref ref-type="bibr" rid="bib11">Gentner, 1983</xref>). However, these models are often criticized for failing to specify how concepts might be plausibly encoded or computed in neural circuits (<xref ref-type="bibr" rid="bib23">McClelland et al., 2010</xref>). A pressing concern, thus, is to provide a mechanistic account of how relational knowledge is encoded and generalized in the human brain (<xref ref-type="bibr" rid="bib38">Tervo et al., 2016</xref>).</p><p>The current project was inspired by recent observations that the representational geometry of human neural signals evoked by symbolic numbers respects their relative cardinality. In scalp M/EEG signals, neural patterns evoked by Arabic digits vary continuously with numerical distance, such that multivariate signals for ‘3’ are more similar to those for ‘4’ than ‘5’. (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Teichmann et al., 2018</xref>). In scalp M/EEG signals, neural patterns evoked by Arabic digits vary continuously with numerical distance, such that multivariate signals for ‘3’ are more similar to those for ‘4’ than ‘5’. Number is a symbolic system that expresses magnitude in abstract form (<xref ref-type="bibr" rid="bib4">Bueti and Walsh, 2009</xref>; <xref ref-type="bibr" rid="bib8">Fischer and Shaki, 2018</xref>; <xref ref-type="bibr" rid="bib40">Walsh, 2003</xref>) and so we reasoned that continuously varying neural signals evoked by numbers might be indexing a conceptual basis set that supports one-dimensional encoding of novel stimuli. In the domain of reward-guided learning, a compact description of the stimulus space projects data into a single dimension that runs from ‘bad’ to ‘good’. Here, thus, we asked humans to learn the reward probabilities associated with novel, high-dimensional visual images, and measured whether the stimuli come to elicit neural patterns that map onto one-dimensional neural codes for numerical magnitude.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Whilst undergoing scalp EEG recordings, human participants (n = 46) completed two tasks: a numerical decision task and a probabilistic reward-guided learning task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, see Materials and methods). In the numerical task, participants viewed rapid streams of 10 Arabic digits (1 to 6) and reported whether numbers in orange or blue font had the higher (Experiment 1a, n = 22) or lower (Experiment 1b, n = 24) average. The reward-learning task was based on the multi-armed bandit paradigm that has been used ubiquitously to study value-guided decision-making (<xref ref-type="bibr" rid="bib7">Dolan and Dayan, 2013</xref>). Participants learned the reward probabilities associated with six unique novel images (colored donkeys), which paid out a fixed reward with a stationary probability (range 0.05–0.95). These probability values were never signaled to the participant but instead acquired by trial and error in an initial learning phase. In the test phase, we asked participants to decide between two successive donkeys to obtain a reward, and estimated trial-wise subjective probability estimates for each bandit by fitting a delta rule model to choices (<xref ref-type="bibr" rid="bib35">Sutton and Barto, 2018</xref>). Throughout these phases, the bandits were never associated with numbers in any way.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.003</object-id><label>Figure 1.</label><caption><title>Task design and RSA results.</title><p>(<bold>A</bold>) Humans performed two tasks during a single EEG recording session. In the numerical decision task, participants viewed a stream of ten digits between 1 and 6, deciding whether the blue or orange numbers had the highest/lowest average. In the bandit task, participants learned about the reward probabilities of six images (bandits) and were asked to choose between two successive bandits to obtain a fixed reward. Numbers below each frame show time duration of the frame in ms. (<bold>B</bold>) RSA revealed a numerical and value distance effect from ~100 ms after stimulus onset (bottom colored lines, P<sub>cluster</sub> &lt;0.005). Inset shows magnitude model RDM. Shaded area represents SEM. Repeating the same analyses with correlation distance (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) or splitting the data per task framing group (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) provided highly similar results. <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> shows the patterns do not differ between bandits presented first or second. (<bold>C</bold>) Averaged neural RDMs between 200–700 ms for the numerical (top) and bandit (bottom) task show a clear correspondence with the magnitude model.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>RSA results with Pearson correlation distance.</title><p>We repeated all main analyses using correlation distance, a measure that is scale invariant and removes any univariate effects, showing that our results are consistent over different distance measures. (<bold>A</bold>) RSA revealed a magnitude effect arising around 100 ms for both tasks (bottom colored lines, P<sub>cluster</sub> &lt;0.005). Shaded area represents SEM. (<bold>B</bold>) Averaged RDMs between 200–700 ms for both tasks. (<sc><bold>C</bold></sc>) Averaged neural RDM between 350 and 600 ms across the two tasks. Upper left and lower right quadrant represent within-task dissimilarities for the numerical and bandit task respectively, lower right and upper left quadrant contain the cross-validated dissimilarities between tasks. (<bold>D</bold>) Cross-temporal cross-validation revealed a stable magnitude representation shared over the two tasks between approximately 350 and 600 ms (P<sub>cluster</sub> &lt;0.005).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>RSA results split per task framing.</title><p>Approximately half of the participants performed the numerical task indicating the color with the lowest average (n = 24) and the other half indicating the highest average (n = 22). (<bold>A-B</bold>) Within-task RSA showed magnitude representations were reliably decodable for the two tasks under either task framing, albeit with slightly later/smaller clusters than the aggregated data (bottom colored lines, P<sub>cluster</sub> &lt;0.005). Shaded area represents SEM. (<bold>C-D</bold>) Cross-temporal cross-validation showed a shared magnitude representation under either task framing, with a slightly larger cluster for the higher frame (P<sub>cluster</sub> &lt;0.005).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.006</object-id><label>Figure 1—figure supplement 3.</label><caption><title>RSA results split for first and second bandit.</title><p>To test for the possibility that our magnitude decoding was not merely driven by a ‘value comparison’ signal, whereby the value of the second bandit is assessed relative to the value of the first, RDMs were calculated separately for the first and second presented bandit. (<bold>A</bold>) Although the identified cluster was greater for the second bandit, magnitude was decodable for both bandits reliably from approximately 350 ms onwards (bottom colored lines, P<sub>cluster</sub> &lt;0.005). (<bold>B</bold>) Averaged neural RDMs between 200 and 700 ms for the first (top) and second (bottom) bandit were highly similar.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig1-figsupp3-v1.tif"/></fig></fig-group><sec id="s2-1"><title>Shared magnitude representation for numbers and probabilistic rewards</title><p>Using representational similarity analysis (RSA) (<xref ref-type="bibr" rid="bib18">Kriegeskorte and Kievit, 2013</xref>), we replicated the previous finding (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Teichmann et al., 2018</xref>) that patterns of neural activity across the scalp from ~100 ms onwards were increasingly dissimilar for numbers with more divergent magnitude, that is codes for ‘3’ and ‘5’ were more dissimilar than those for ‘3’ and ‘4’ (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, green line). This occurred irrespective of task framing (report higher vs. lower average) and category (orange vs. blue numbers), suggesting that neural signals encoded an abstract representation of magnitude and not solely a decision-related quantity such as choice certainty (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>). Next, we used RSA to examine the neural patterns evoked by bandits. We found that multivariate EEG signals varied with subjective bandit ranks, with bandits that paid out with nearby probabilities eliciting more similar neural patterns (from ~100 ms onwards; <xref ref-type="fig" rid="fig1">Figure 1B</xref>, blue line).</p><p>Our key question was whether there was a shared neural code for numerical magnitude and reward probability. We found that EEG signals elicited by digit ‘6’ were more similar to those evoked by the most valuable bandit, and digit one predicted the bandit least likely to pay out, with a similar convergence for intermediate numbers and bandits (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Cross-validation of neural signals elicited by all numbers (1 to 6) and bandits (inverse ranks 1–6) was stable and reliable from 300 to 650 ms post-stimulus, as demonstrated by cross-temporal RSA (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). We conducted several control analyses to further explore the nature of this effect. The cross-validation effect was not driven by patterns within a single number/bandit pair, as it remained robust to the removal of any one of the six number/bandit pairs (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In particular, although the largest number/most valuable bandit cross-validation appeared more dissimilar to other numbers/bandits, the effect persisted when only numbers/bandits 1–5 were included in the analysis (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We then asked whether each number was more similar to its equivalent bandit than to other bandits (e.g. number 3 and bandit 3, the ‘on-diagonal’ information in <xref ref-type="fig" rid="fig3">Figure 3A</xref>), by computing an ‘Exemplar Discriminability Index’ (EDI) (<xref ref-type="bibr" rid="bib26">Nili et al., 2016</xref>). Additionally, we asked whether numbers showed a gradually increasing dissimilarity to non-identical bandits (e.g. whether number three was more similar to bandit 2/4 than bandit 1/5, the ‘off-diagonal’ information in <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Both of these effects were independently reliable, suggesting not only that each number shares a representation with its corresponding bandit, but that the transitive patterns of encoding numbers and bandits are in a common register in neural signals.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.007</object-id><label>Figure 2.</label><caption><title>Cross-temporal cross-validation RSA.</title><p>(<bold>A</bold>) Averaged neural RDM from 350 to 600 ms across the numerical (1-6) and bandit (b1–b6) task. Upper left and lower right quadrants show representational dissimilarity for numbers (‘N’) and bandits (‘B’), respectively, that is within-task RDM; lower left/upper right quadrants show cross-validated dissimilarity between numbers and bandits (‘N-B’), that is between-task RDM. (<bold>B</bold>) Cross-temporal cross-validated RSA revealed a stable magnitude representation that was shared between the two tasks (P<sub>cluster</sub> &lt;0.005) around 350–600 ms. (<bold>C</bold>) To ensure that our cross-validation was not driven by a single number/bandit pair, we systematically removed each number/bandit pair and repeated the cross-temporal cross-validated RSA on the subset data. Each pixel can range from 0 (no significant cross-validation for any number/bandit pair) to 6 (cross-validation always reached significance). Between 400 and 600 ms our cross-validation was robust to the removal of any number/bandit pair (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> shows the results isolated when excluding number/bandit pair 6).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.008</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Cross-validation after removal of number 6/subjectively highest valued bandit (subset of <xref ref-type="fig" rid="fig2">Figure 2C</xref>).</title><p>The most distinct pattern of numerical/value distance was present for the highest number and most valued bandit. After removing this pair from the cross-validated RDM and repeating the cross-temporal cross-validation RSA, magnitude was still decodable from the remaining numbers and bandits (P<sub>cluster</sub> &lt;0.05).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.009</object-id><label>Figure 2—figure supplement 2.</label><caption><title>We compared the strength of within-subject cross-validation to the between-participants cross-validation, asking whether variations in multivariate neural signals existed that were idiosyncratic within participants.</title><p>For each participant, we combined EEG responses per stimulus from the numerical task iteratively with the EEG responses of another participant from the bandit task, repeating our cross-validation protocol for the newly created between-subject data. This allowed us to ask how well a participant’s neural patterns correlated with those of other participants, resulting in a distribution of correlation estimates at each time point. We then calculated a z-value at each time point, indicating how far the within-participant correlation diverged from the between-participant distribution of correlations. Non-parametric cluster-based permutation tests were then used to identify clusters in time where participants’ neural patterns in the bandit task were significantly better predicted by their own neural patterns compared to the population (P<sub>cluster</sub> &lt;0.05). The effect was noisier but arose around the same time as the original cross-validation pattern, suggesting the effect was not purely driven by shared noise from the same recording session.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig2-figsupp2-v1.tif"/></fig></fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.010</object-id><label>Figure 3.</label><caption><title>Detailed examination of the magnitude pattern in cross-validation.</title><p>(<bold>A</bold>) The presence of a one-to-one mapping along the number line (i.e. number one to least valued bandit) was tested using the ‘Exemplar Discriminability Index’ (EDI), a measure that indicates how much better items on average map onto iterations of the same item compared to different items. The EDI is calculated by subtracting the mean on-diagonal distances from the mean off-diagonal distances (top illustration). Significant exemplar discriminability, where numbers most closely resembled their equivalent bandit, arose at the same time as our main findings. (<bold>B</bold>) Removing the diagonal from the lower rectangle in the cross-validation RDM (i.e. the dissimilarity between distributed responses to corresponding stimuli in the two tasks) reproduced the results from our main analysis, suggesting the effect was not mainly driven by matching stimulus pairs (e.g. number six and most valuable bandit), but by a gradual distance effect (P<sub>cluster</sub> &lt;0.005).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig3-v1.tif"/></fig></sec><sec id="s2-2"><title>Relating numerical magnitude representation to choice behavior</title><p>Past work has identified overlapping choice biases in numerical cognition and economic decisions (<xref ref-type="bibr" rid="bib13">Kanayet et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Schley and Peters, 2014</xref>). Next thus, we asked how patterns of behavior in the numerical and bandit tasks were related to one another by creating choice matrices encoding the difference in relative weight given to each number or bandit in the choices made by participants. For the numerical task, we computed decision weights for each number in the choice using an averaging approach (see Materials and methods) and plotted the relative difference in these weights for each combination of numbers (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). For the bandit task, this was simply the probability of choosing the subjectively highest valued bandit for each combination of bandits (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Although choice matrices for numbers and bandits were on average correlated across participants (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msub><mml:mi>r</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula>= 0.32, Z = 5.65, p &lt; 0.0001, Wilcoxon signed rank test), this correlation disappeared when subtracting the group average choice matrices and correlating the residual matrices (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msub><mml:mi>r</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula>= -0.02, Z = -0.49, p = 0.63). In other words, we were not able to identify shared variation in individual weighting of numbers 1-6 and bandits 1-6 in behavior alone, perhaps because of the different nature of the decision required in each task.</p><p>Subsequently, we asked how these choice matrices explained variance in patterns of neural similarity, that is whether the behavior explained shared variation in the neural structure alignment for numbers and bandits. To this end, we substituted the linear representational distance matrix used for earlier analyses (i.e. one that assumes equal spacing among adjacent numbers and bandits) with the subject-specific choice matrices computed from behavior and repeated the analyses above. This allowed us to ask how patterns of neural similarity among both numbers and bandits were explained by variance in subject-specific choice matrices. For each neural pattern, we used a regression-based approach in which choice matrices from numbers and bandits were entered as competing regressors. Interestingly, we found that choice patterns from the numerical task explained variance in the neural patterns for both numbers and bandits, but choice patterns from the bandit task only explained variance in the neural patterns of the bandit task (<xref ref-type="fig" rid="fig4">Figure 4C–D</xref>) (P<sub>cluster</sub> &lt;0.005). One interpretation of this finding is that humans used their intrinsic sense of magnitude when forming neural representations of the bandits, but not vice versa. We note in passing that this asymmetry is not secondary to the ordering of the two tasks, which was fully counterbalanced across participants.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.011</object-id><label>Figure 4.</label><caption><title>Behavioral analyses.</title><p>(<bold>A</bold>) Group-averaged difference RDM of decision weights in the numerical task. We calculated the weight of each number on participant’s choice, independent of color, and created a choice RDM through pairwise differences of weights. (<bold>B</bold>) Group-averaged choice RDM in the bandit task. Each cell contains the probability of choosing the highest valued bandit on trials where bandit <italic>x</italic> and bandit <italic>y</italic> were presented together. Participants never encountered trials where the same bandit was presented twice. (<bold>C</bold>) Both choice matrices were inserted in a multiple regression explaining EEG patterns to establish a potential link between behavior and neural patterns in either task. Only the numerical choice RDM explained neural patterns of the numerical task. (<bold>D</bold>) In contrast, both choice RDMs significantly explained neural patterns in the bandit task, possibly indicating that participants relied on a more general understanding of numbers in both tasks (bottom colored lines, P<sub>cluster</sub> &lt; 0.005). Shaded area represents SEM. (<bold>E</bold>) Distributions of <inline-formula><mml:math id="inf3"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> after fitting a power-law model of the form <inline-formula><mml:math id="inf4"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> to the decision weights in the numerical task (yellow) and the average neural patterns in the numerical (green) and bandit task (blue) between 350 and 600 ms (see Materials and methods). In all cases, the best fitting parameter <inline-formula><mml:math id="inf5"><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> was significantly greater than 0 (linear), indicating an overweighting/increasing dissimilarity for larger quantities (numbers 5-6 or highest valued bandits). (<bold>F</bold>) Decision weights under the median estimated <inline-formula><mml:math id="inf6"><mml:mi>k</mml:mi></mml:math></inline-formula> for psychometric (yellow) and neurometric (green/blue) fits, compared to the median true human decision weights in the numerical task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig4-v1.tif"/></fig><p>In previous work, we observed that participants tended to give relatively greater weight to larger magnitudes during the numerical decision task, for example numbers '5' and '6' had disproportionate impact on averaging judgments (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>). This finding was replicated in the current data (<xref ref-type="fig" rid="fig4">Figure 4E-F</xref>). Human choices were best fit by a power-law model in which participants averaged and compared distorted numerical values <inline-formula><mml:math id="inf7"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> with <inline-formula><mml:math id="inf8"><mml:mi>k</mml:mi></mml:math></inline-formula>= 2.04 ± 1.11 (<inline-formula><mml:math id="inf9"><mml:mi>k</mml:mi></mml:math></inline-formula>&gt; 1: t(45) = 12.47, p &lt; 0.001). This prompted us to ask whether any shared variance between behavioral choice matrices and neural signals for the two tasks could be explained by subject-specific differences in the pattern of compression or anti-compression in the mental number line, as characterized by this model. Turning to the neural data, we thus generated candidate representational dissimilarity matrices (RDMs) under the assumption that distance in neural space can likewise be non-linear and best described by a distortion given by the same power-law model, that is of the form <inline-formula><mml:math id="inf10"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. We found that in both numerical and bandit tasks the best fitting RDM was parameterized by <inline-formula><mml:math id="inf11"><mml:mi>k</mml:mi></mml:math></inline-formula>&gt; 1 [numerical: <inline-formula><mml:math id="inf12"><mml:mi>k</mml:mi></mml:math></inline-formula>= 1.73 ± 0.82, t(45) = 14.34, p &lt; 0.001; bandit: <inline-formula><mml:math id="inf13"><mml:mi>k</mml:mi></mml:math></inline-formula>= 1.72 ± 0.85, t(45) = 13.65, p &lt; 0.001]. In other words, we observed that the anti-compressed number line estimated from behavior was reflected, on average, in both the neural representation of numbers and bandits. However, when we correlated the subject-specific model parameter <inline-formula><mml:math id="inf14"><mml:mi>k</mml:mi></mml:math></inline-formula> from behavior with estimates obtained from the neural data from either task, we found that although the degree of behavioral anti-compression strongly predicted the neural anti-compression for the numerical task (<inline-formula><mml:math id="inf15"><mml:mi>ρ</mml:mi></mml:math></inline-formula>= 0.57, p = 0.0004), it did not for the bandit task (<inline-formula><mml:math id="inf16"><mml:mi>ρ</mml:mi></mml:math></inline-formula>= -0.13, p = 0.39). One interpretation of this result is that the variance linking the mental number line to the representation of bandits (i.e. from <xref ref-type="fig" rid="fig4">Figure 4D</xref>) is not simply due to individual differences in compression or anti-compression of the mental representations of numbers and bandits but must lie in a subspace not captured by this simple unidimensional model.</p></sec><sec id="s2-3"><title>Dimensionality of magnitude representation</title><p>Recent work has suggested that during categorization, posterior parietal neurons in the monkeys are strikingly low-dimensional, as if the parietal cortex were engaging in a gain control process that projected stimulus features or timings on a single axis (<xref ref-type="bibr" rid="bib9">Fitzgerald et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Ganguli et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Platt and Glimcher, 1999</xref>; <xref ref-type="bibr" rid="bib41">Wang et al., 2018</xref>). Indeed, we observed a centro-parietal positivity (CPP) that varied with the magnitude of both numbers and reward probabilities (<xref ref-type="fig" rid="fig5">Figure 5A–B</xref>). This signal resembles a previously described EEG signal, that has been found to scale with the choice certainty in perceptual (<xref ref-type="bibr" rid="bib27">O'Connell et al., 2012</xref>) and economic tasks (<xref ref-type="bibr" rid="bib30">Pisauro et al., 2017</xref>). However, in our numerical task the CPP followed an approximately ascending pattern from lower to higher numbers regardless of task framing (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) or color category. The cross-validation effect persisted even after the CPP had been regressed out of the data (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). This suggests that (a) the CPP in our task may represent a notion of magnitude, not a certainty signal alone; and (b) that this signal is not the sole driver of our multivariate findings.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.012</object-id><label>Figure 5.</label><caption><title>Dimensionality of magnitude representation.</title><p>(<bold>A</bold>) Average normalized amplitudes associated with numbers 1–6, independent of task framing (report highest/lowest) or category (blue/orange) at highlighted centro-parietal electrodes. Grey shaded area shows time of greatest disparity between signals (Kruskal-Wallis, P<sub>FDR</sub> &lt;0.01). Scalp map inset shows response amplitude for number six during identified time window. Colored shading represents SEM. The ascending direction of the univariate responses was independent of task framing (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) (<bold>B</bold>) Equivalent analysis for bandits b1 (lowest value) to b6 (highest value) in the bandit task. Scalp map shows response amplitude for highest subjectively valued bandit b6. (<bold>C</bold>) Dimensionality of the data was iteratively reduced using SVD and the strength of cross-validation under each new dimensionality was assessed by comparing the mean cross-validation in the 350–600 ms time window (bottom plot). Each cell in the grid contains the t- and p-value of a pairwise comparison of mean CV under different dimensionalities of the data. Reduction to one (and to a lesser degree two) dimension(s) significantly reduced the size of the effect. (<bold>D</bold>) Multidimensional scaling (MDS) revealed two principal axes that describe the data: a magnitude axis approximately following the number/bandit order and a certainty axis distinguishing inlying (e.g. 3,4) from outlying (e.g. 1,6) numbers or bandits.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.013</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Univariate centro-parietal signals separated by task and task framing.</title><p>Grey-shaded areas show time of greatest disparity between signals (Kruskal-Wallis, P<sub>FDR</sub> &lt;0.01). (<bold>A-B</bold>) Centro-parietal responses for numbers followed an ascending pattern from low to high numbers, independent of whether the task instructions asked to indicate the color with the lowest or highest average. Scalp maps show response amplitude for number six at the identified time window. (<bold>C-D</bold>) Centro-parietal responses for bandits followed the same ascending pattern, going from subjectively lowest valued bandit to the highest valued bandit. The bandit task was identical for both framing groups. Scalp maps show response amplitude for the highest valued bandit b6 at the identified time window.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.014</object-id><label>Figure 5—figure supplement 2.</label><caption><title>We tested whether the univariate CPP amplitude modulations could explain our multivariate findings.</title><p>The magnitude model was compared to a model RDM constructed from univariate CPP amplitude differences in a multiple regression. (<bold>A-B</bold>) CPP amplitudes were obtained by averaging the univariate centro-parietal response to each stimulus (digit or bandit) within the individually identified time windows from <xref ref-type="fig" rid="fig5">Figure 5A–B</xref>. CPP RDMs (inset) were constructed based on the differences between average amplitudes. Error bars represent SEM. (<bold>C</bold>) Average Euclidean distances of CPP amplitudes from both tasks combined (numerical: 1–6, bandit: b1-b6). The lower left quadrant, containing the between-task distances in CPP amplitudes, served as the CPP model RDM for the cross-validation analysis. (<bold>D-F</bold>) For each control analysis, the magnitude model significantly explained variance in the multivariate neural patterns even after entering the univariate CPP as a second regressor in a multiple regression (within-task comparison: P<sub>cluster</sub> &lt;0.005, bottom colored lines; cross-validation: P<sub>cluster</sub> &lt;0.05). Shaded colored area represents SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.42816.015</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Cross-validation after excluding the first principal dimension.</title><p>A more stringent test to control for univariate effects is to exclude the first dimension identified by SVD. Cross-temporal cross-validation on the reduced data revealed a smaller but significant cluster at the same time points as our main result and a previously unobserved later cluster (P<sub>cluster</sub> &lt;0.05). Consistent with our previous analyses (<xref ref-type="fig" rid="fig5">Figure 5A–C</xref>), this suggests there is a major univariate component to our multivariate findings, but the shared pattern also exists in higher dimensions of the data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig5-figsupp3-v1.tif"/></fig></fig-group><p>Nevertheless, to understand the dimensionality of the number and bandit representations (and the subspace in which they aligned), we used two dimensionality reduction techniques, singular value decomposition (SVD) and multidimensional scaling (MDS). First, using SVD, we systematically removed dimensions from the EEG data and recomputed our number-bandit cross-validation scores (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). We found that probabilistic reward learning was supported by a low-dimensional neural magnitude code, with reliable effects persisting when all but two eigenvectors were removed from the data but significantly attenuated when only a single dimension was retained in the EEG data. Indeed, 3D and full (high-dimensional) solutions led to statistically equivalent cross-validation, with some attenuation of the effect when two dimensions were retained and a more dramatic decrease with only a single dimension. To further establish that the cross-validation effect was not solely driven by the observed univariate activity, we again used SVD to remove the first dimension and re-computed the cross-validation statistics (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). A significant cluster of cross-validation emerged at the same time as the originally observed effect together with a previously unobserved cluster later in time (P<sub>cluster</sub> &lt;0.05). In summary, aside from a major univariate component to our cross-validation effect, there remains a shared pattern that lies in higher dimensions of the data.</p><p>Secondly, we used MDS to visualize the first dimensions of the concatenated number/bandit data. This disclosed an axis pertaining to magnitude and another approximately corresponding to certainty along which, especially for the bandits, the large (or best) and small (or worst) items diverged from the others (<xref ref-type="fig" rid="fig5">Figure 5D</xref> and <xref ref-type="video" rid="video1">Video 1</xref>). In other words, the numbers and bandits align principally along a single magnitude axis but with an additional contribution from a second factor potentially encoding choice certainty.</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-42816-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.42816.016</object-id><label>Video 1.</label><caption><title>The neural geometry of the first two dimensions of both tasks in shared space over time, identified through multidimensional scaling (MSD).</title></caption></media></sec><sec id="s2-4"><title>Neural network simulations</title><p>What are the potential benefits of the shared coding scheme we observed in neural signals? One possibility is that shared structure can promote generalization, such that new relational structures (i.e. the transitive relations among bandits as a function of their reward probability) are learned faster and more effectively when an existing scaffold (such as a transitive representation of number) has been previously learned. We are unable to test for this benefit directly in our human data, because all participants were numerate adult humans, denying us an appropriate control condition. However, to demonstrate the theoretical benefit of shared coding at the mechanistic level, we turned to a simple computational tool, a feedforward neural network (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Neural networks are not constrained to make inferences over structure, but structured representations may emerge naturally in the weights during training (<xref ref-type="bibr" rid="bib23">McClelland et al., 2010</xref>). Here, we confronted the network with two diffeent stimulus sets in turn that (like our numbers and bandits) shared the same similarity structure. We then asked if the shared structure facilitates retraining on the second set after learning the first. The network was first trained on inputs <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow/></mml:msub></mml:math></inline-formula><sub>a</sub> arriving at input units <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and after convergence, retrained on inputs <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> fed into units <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (where <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are separate input modules that project to a common hidden layer H). Inputs <inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were 6 random vectors constructed to have the same continuously varying similarity structure as the bandits, whereas inputs <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> consisted of either a different set of six random vectors with the same second-order structure, or a shuffled control lacking the second-order structure. Relearning on <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> proceeded faster when inputs shared a common structure with <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6B-D</xref>). In a second control, we shuffled the weights <inline-formula><mml:math id="inf27"><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:math></inline-formula> connecting the hidden layer to the output layer after convergence on inputs <inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, destroying the mapping of activity patterns in the hidden layer to the output layer. RSA conducted after retraining revealed reliable cross-validated patterns of activity in the hidden units only for the condition where <inline-formula><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> shared an underlying structure and weights <inline-formula><mml:math id="inf31"><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:math></inline-formula> were kept intact (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), mirroring the result from the human neural data.</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.42816.017</object-id><label>Figure 6.</label><caption><title>Neural network simulations.</title><p>(<bold>A</bold>) Schematic depiction of network structure and training. The network was first trained to classify inputs <inline-formula><mml:math id="inf32"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> fed into units <inline-formula><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (lower green circles). Inputs <inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> consisted of six stimuli that either exhibited gradual increasing dissimilarity or were shuffled as a control (stimulus RDMs shown next to examples of <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). After convergence, the model was trained on new input <inline-formula><mml:math id="inf37"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that were fed into a separate input stream <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (lower blue circles). Inputs <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were different to <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> but exhibited the same similarity structure. (<bold>B</bold>) Loss plotted over the course of training (left panel) and retraining (right panel) for the test (red) and shuffled control (blue) conditions. Learning was faster during training for control stimuli, but retraining was faster when <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> exhibited shared similarity structure. (<bold>C</bold>) Loss for control simulations where hidden-to-output weights W2 were shuffled between training and retraining, suggesting successful transfer depends on structure encoded in W2. (<sc><bold>D</bold></sc>) Mean loss for first 1000 cycles after retraining. (<bold>E</bold>) Cross-validation RSA on hidden unit activation for all stimuli in <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> after retraining. Hidden unit activations exhibit shared similarity structure only when W2 remains unshuffled and <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> share structure. Inset shows cross-validation RDM from hidden units for the test condition. Error bars show SEM over 100 network simulations with different initialization.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-42816-fig6-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We report that during a probabilistic reward-guided learning task involving arbitrary images (‘bandits’), stimuli with high payout probability shared a neural code with larger numbers, and those with lower value shared a neural code with lower numbers. We interpret these data as indicating that an abstract neural code for magnitude forms a conceptual basis set or ‘scaffold’ for learning new information, such as the reward probabilities associated with novel stimuli. Rather than encoding stimulus value in an unstructured value function or lookup table (as is common in RL models), our data suggest that humans project available stimuli onto a low-dimensional axis that runs from ‘bad’ to ‘good’. This neural axis is aligned with the mental number line, suggesting that humans recycle an abstract concept of magnitude to encode reward probabilities.</p><p>Learning a structured representation of value will have the benefit of allowing new inductive inferences, such as inferring transitive preferences among economic goods without exhaustive pairwise comparison (<xref ref-type="bibr" rid="bib1">Alfred et al., 2018</xref>), and facilitate read-out in downstream brain areas, related perhaps to the notion of a ‘common currency’ for reward (<xref ref-type="bibr" rid="bib20">Levy and Glimcher, 2012</xref>).</p><p>Our neural network simulations provide a demonstration of how shared structure can promote generalization and thus faster learning, even for stimuli with different physical input features. However, our design was not suited to directly test a benefit of learning between tasks, since our participants were numerate adults when they entered the experiment. In further work, it would be of particular interest to teach participants two new transitive structures, each associated with a different stimulus set, and test whether the extent to which the neural codes align predicts learning rates for the second stimulus set – a direct prediction that emerges from our computational simulations.</p><p>We did, however, find a link between the transitive neural codes and participants’ behavior. Choice patterns in the two tasks were positively correlated, and how participants treated numbers in the numerical task was reflected in the neural patterns of both tasks. Furthermore, we found that participants tended to overweight larger numbers and this non-linear weighting correlated highly with non-linear representations at the neural level, at least in the numerical task. Why we did not find a correlation with non-linearities in the neural patterns of the bandit task is unclear. One speculation is that the non-linearity arises at a later stage in the processing of stimuli and is specific to the task at hand.</p><p>One major limitation of our approach is the limited spatial resolution of EEG. This leaves open the question of the true dimensionality of the shared neural code. Our investigations using dimensionality reduction techniques indicate that the code in EEG signals is low-dimensional but not simply univariate. Thus, whilst our work is consistent with previous studies showing that the amplitude of centro-parietal EEG signals scales with number (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>) and the value of economic prospects, such as food items (<xref ref-type="bibr" rid="bib30">Pisauro et al., 2017</xref>), it also suggests a more complex pattern encoding the shared structure among stimuli defined by transitive relations. However, it would be instructive to measure the effect using techniques that potentially afford higher spatial resolution, such as MEG or fMRI. More generally, however, our work is consistent with theories that have suggested that neural signals for magnitude in the parietal cortex may provide a conceptual bridge between different metrics such as space, time and number (<xref ref-type="bibr" rid="bib4">Bueti and Walsh, 2009</xref>; <xref ref-type="bibr" rid="bib5">Chafee, 2013</xref>; <xref ref-type="bibr" rid="bib9">Fitzgerald et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Parkinson et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Walsh, 2003</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Forty-nine healthy participants (Experiment 1a = 24, Experiment 1b = 25) participated in behavioral and EEG testing at the University of Oxford. Sample size for Experiment 1a was determined based on common sample sizes in the field and a similar size was used in Experiment 1b for the replication. Two participants from Experiment 1a were excluded from all analyses due to failure to learn in the bandit task (chance level performance) and one participant from Experiment 1b due to excessive movement artefacts in the recorded EEG data. All analyses were performed on the remaining 46 participants (n female = 24, n right-handed = 43, age = 24.7 ± 4.5). All participants had normal or corrected-to-normal vision, with no history of neurological or psychiatric illness. Participants were compensated for their time at a rate of £10/hr plus additional bonuses based on their performance (max. £2.50 in the numerical task and £5 in the bandit task). Informed consent was given before the start of the experiment. The study was approved by the Medical Science Inter-Divisional Research Ethics Committee (R49578/RE001).</p></sec><sec id="s4-2"><title>Experimental procedure</title><p>Both tasks (numerical and bandit) were run within a single recording session, with the order of tasks counterbalanced between participants. Stimuli were created and presented using the Psychophysics Toolbox-3 (<xref ref-type="bibr" rid="bib3">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib17">Kleiner et al., 2007</xref>) for Matlab (MathWorks) and additional custom scripts. The tasks were presented on a 20’’ screen with a resolution of 1600 × 900, at a refresh rate of 60 Hz and on a grey background. Viewing distance was fixed at approximately 62 cm. The F and J key on a standard QWERTY keyboard served as response keys for left- and right-hand responses, respectively.</p><sec id="s4-2-1"><title>Numerical task</title><p>A trial started with a central dark grey fixation dot lasting 500 ms, followed by 10 Arabic digits at a rate of ~3 Hz (each digit was shown for 283 ms per stimulus with an inter-stimulus interval (ISI) of 67 ms). Numbers were drawn uniformly random from 1 to 6, with half of the stimuli randomly colored in orange and the other half in blue. Sequence generation was unconstrained, except that the blue/orange means could not be identical. After sequence offset, participants could respond by choosing one of two response boxes on screen containing the options ‘O’ (orange) and ‘B’ (blue). Location of response options (left or right box) was fixed within the task but counterbalanced between participants. Left- and right-hand responses were used to select the left and right boxes respectively. When a response was given, the corresponding box would change to the chosen color 100 ms before feedback. In the case of a correct answer, both letters within the boxes were replaced by a dollar sign (‘$’) accompanied by a high-pitch tone for 350 ms. Conversely, if the response was incorrect or no response was given within 2 s, the boxes would show a dash (‘/’) and a low-pitch tone was played. The chosen response box remained colored during feedback. The next trial started after an inter-trial interval (ITI) sampled uniformly between 500 and 1500 ms.</p><p>Task framing was inverted after testing the first group of participants. In Experiment 1a, participants chose the color associated with the highest average, while in Experiment 1b they chose the color with the lowest average. After 10 (Experiment 1a) or 20 (Experiment 1b) practice trials (excluded from analysis) each participant performed 300 trials in 6 blocks of 50 trials. Participants could take a self-timed break in between blocks.</p></sec><sec id="s4-2-2"><title>Bandit task</title><p>Bandits were represented by six unique colored drawings of donkeys, freely available on the internet, and each donkey was colored differently (green, purple, orange, yellow, red and blue) using GIMP (<ext-link ext-link-type="uri" xlink:href="https://www.gimp.org">https://www.gimp.org</ext-link>) and superimposed on a light grey background. Each image was associated with one of six stationary reward probabilities, linearly spaced between 0.05 and 0.95 [0.05, 0.23, 0.41, 0.59, 0.77, 0.95], and these were assigned randomly to donkeys for each participant.</p><p>The experiment consisted of two learning phases and one test phase. In the first learning phase (L1), all six bandits were presented on screen simultaneously, in a 2 × 3 configuration. Participants could click on each bandit 36 times, in any order they preferred. Every time a bandit was selected, the image was replaced by a feedback sign and the surrounding frame adopted the color of the chosen bandit. Feedback in a successful trial consisted of a centrally presented dollar sign and a high-pitch tone, otherwise a dash appeared paired with a low-pitch tone. Feedback was not drawn probabilistically in this phase: the number of successful trials was determined based on the maximum number of clicks per bandit and its associated reward probability. After a bandit was chosen 36 times, it was masked and remained unavailable until the end of the phase.</p><p>In the second learning phase (L2), participants were presented with two random bandits sequentially, identical to the test phase (see below). Phase L2 only differed from the test phase in that it included 50% pseudo-choice trials, where the computer determined which bandit had to be chosen, in order to encourage exploration of all bandits. During these trials, the computer-chosen bandit and corresponding response key were highlighted with a brown frame. All pseudo-choice bandits were assigned equally often and balanced over presentation order. It was emphasized to participants that the pseudo-choice bandits were selected randomly and did not signal the optimal choice. Phase L2 lasted for 2 blocks of 60 trials with a short break in between blocks.</p><p>Each trial in phase L2 and in the test phase started with the presentation of a white fixation dot for 500 ms. The fixation dot would disappear 250 ms before presentation of the first bandit. Two bandits were then presented sequentially, each for 500 ms with an ISI of 250 ms. Afterwards, participants had to choose which bandit they preferred. Two response boxes on screen indicated the choice options: ‘A’ referring to the first bandit presented and ‘B’ to the second. The location of ‘A’ and ‘B’ (left or right box) alternated randomly from trial to trial. The chosen box would then change to the color of the chosen bandit 200 ms before feedback was given. Reward was determined randomly according to the reward probability of the chosen bandit. If the choice was successful, both response boxes would contain a dollar sign and a high-pitch tone played for 500 ms. If the choice entailed no reward or no response was given within 2 s, both boxes would show a dash and a low-pitch tone was played. The fixation dot also turned red when no response was given. No feedback was provided for the unchosen option. A new trial started after an ITI of 500 ms. The test phase consisted of 10 blocks of 60 trials. By the probabilistic nature of the bandit outcomes, the subjective ranking of the bandits could potentially vary over the course of the experiment. It was therefore emphasized to participants before the test phase that the actual reward probabilities of the bandits would never change.</p></sec></sec><sec id="s4-3"><title>EEG acquisition</title><p>The EEG signal was recorded using 61 Ag/AgCl sintered surface electrodes (EasyCap, Herrsching, German), a NeuroScan SynAmps RT amplifier, and Curry 7 software (Compumedics NeuroScan, Charlotte, NC). Electrodes were placed according to the extended international 10–20 system, with the right mastoid as recording reference and channel AFz as ground. Additional bipolar electrooculography (EOG) was recorded, with two electrodes placed on either temple for recording horizontal EOG and two electrodes above and below the right eye for vertical EOG. All data was recorded at 1 kHz and low-pass filtered online at 200 Hz. All impedances were kept below 10–15 kΩ during the experiment.</p></sec><sec id="s4-4"><title>EEG pre-processing</title><p>The data from both tasks were pre-processed following the same pipeline, using functions from the EEGLAB toolbox (<xref ref-type="bibr" rid="bib6">Delorme and Makeig, 2004</xref>) for Matlab and custom scripts. First the data were down-sampled to 250 Hz, low-pass filtered at 40 Hz and then high-pass filtered at 1 Hz. The continuous recording was visually screened for excessively noisy channels and these were interpolated by the weighted average of the surrounding electrodes. The data was then offline re-referenced to average reference. In the numerical task, epochs were extracted from 1 s before fixation dot onset to 5.5 s after. In the bandit task, epochs were extracted from 0.5 s before fixation dot onset to 3 s after. Epochs were baselined relative to the full pre-fixation time window. Epochs containing atypical noise (such as muscle activity) were rejected after visual inspection. We then performed Independent Component Analysis (ICA) and removed components related to eye blink activity and other artefacts (manually selected for each participant). Lastly, the trial epochs were split into smaller stimulus epochs for each digit/bandit and re-baselined based on the pre-stimulus onset time window. For the numerical task, these epochs spanned −65 ms to 850 ms relative to stimulus onset. For the bandit task, they spanned −250 ms to 750 ms. Final analyses focused on the overlapping time window of −65 to 750 ms in both tasks.</p></sec><sec id="s4-5"><title>Statistical procedure</title><p>Experiment 1b was pre-registered as a control experiment (DOI 10.17605/osf.io/ym3gu), directly replicating the bandit task and inverting the task framing for the numerical task. We confirmed our proposed hypothesis that task framing would not affect either the direction of the univariate parietal effects (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) or the multivariate patterns (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). To increase the power of our analyses, we collapsed the two data sets. All analyses were conducted on the subject level and statistics are reported for the group level.</p></sec><sec id="s4-6"><title>Delta-rule model</title><p>We estimated subjective probabilities for each bandit using a delta-rule model. On every trial, the model compares the (subjective) values of the two offered bandits and updates the value of the chosen bandit based on the observed reward during the task:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo mathvariant="bold">+</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo mathvariant="bold">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo mathvariant="bold">+</mml:mo><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo mathvariant="bold">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the value of the bandit chosen by the participant on trial <inline-formula><mml:math id="inf48"><mml:mi>t</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf49"><mml:mi>α</mml:mi></mml:math></inline-formula> the learning rate and <inline-formula><mml:math id="inf50"><mml:mi>R</mml:mi></mml:math></inline-formula> the received reward (either 0 or 1). Value of the chosen bandit is updated for the next trial <inline-formula><mml:math id="inf51"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, by taking the difference between the observed reward <inline-formula><mml:math id="inf52"><mml:mi>R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> and the expected reward <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> modulated by the size of the learning rate. To obtain estimates of the model’s choices, the values of the two bandits are passed through a sigmoidal response function:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf54"><mml:mi>Δ</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, that is the difference in value between the first (A) and second (B) bandit. The policy parameters <inline-formula><mml:math id="inf55"><mml:mi>s</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf56"><mml:mi>λ</mml:mi></mml:math></inline-formula> indicate the slope and termination point (lapse rate) of the logistic choice function. The latter was fixed to 0.05, equivalent to the bounds of the reward probabilities in the task, and the parameters α and <inline-formula><mml:math id="inf57"><mml:mi>s</mml:mi></mml:math></inline-formula> (learning rate and slope) were fit to the data. Best-fitting parameter estimates were obtained by minimizing the negative log-likelihood function using optimization tools in Matlab. Bandit probabilities in the test phase were initialized according to the estimates of subjective reward probability obtained from free-choice trials from phase L2. Search space was restricted for both parameters between 0.0001 and 0.5. Best fitting parameters were then used to estimate trial-by-trial subjective ranks for all bandits per participant by classifying the bandits according to their subjective values.</p></sec><sec id="s4-7"><title>Representational similarity analysis (RSA)</title><p>The pre-processed EEG data was first z-scored over all trials, per electrode and time point. To obtain the condition-specific activations at each time point and electrode, we constructed a design matrix using dummy coding for each condition within a task (numbers 1 to 6 and the six bandits) and subsequently estimated beta coefficients using a linear regression model for each number or (ranked) bandit. These beta coefficients then reflected the trial-average response per condition at each time point and electrode. We then calculated the Euclidean (or correlation) distance between the whole-scalp neural signals of each condition pair (e.g. bandit 1 and bandit 2), resulting in a 6 × 6 representational dissimilarity matrix (neural RDM) at each time point for both tasks separately (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Neural RDMs were smoothed over time through convolution with a 60 ms uniform kernel. To test for patterns of numerical distance in the neural RDMs, we created a 6 × 6 magnitude model RDM in which the predicted dissimilarity linearly increased from 0 to 1 as a function of the numerical difference between two numbers. The upper triangles of the model and neural RDM were subsequently correlated using Kendall Tau-a rank correlation (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) (<xref ref-type="bibr" rid="bib25">Nili et al., 2014</xref>).</p><p>In the cross-validation analyses, we followed a similar pipeline as the within-task RSA described above, except that beta estimates of condition activation from both tasks were concatenated before calculating the Euclidean distance between all 12 conditions, resulting in a 12 × 12 RDM containing both <italic>within-task</italic> (e.g number-number) and <italic>between-task</italic> (e.g. number-bandit) dissimilarities (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). To account for potential differences in the time at which a magnitude code was decodable, we conducted this analysis for all possible combinations of time points (cross-temporal RSA) (<xref ref-type="bibr" rid="bib16">King and Dehaene, 2014</xref>). Neural RDMs were smoothed over time through convolution with a 60 x 60 ms uniform kernel. In cross-validation, model RDMs were correlated with the lower rectangle of the neural RDM, containing the between-task dissimilarities. The diagonal of the rectangle was included, since on-diagonal information is non-redundant in cross-validation. Correlations were baseline corrected by subtracting the average correlation in the pre-stimulus period to not bias our cluster-identifying algorithm. Significant clusters were identified using cluster-corrected nonparametric permutation tests (iterations = 1000, cluster-defining and cluster-level thresholds at p&lt;0.005, unless stated otherwise) (<xref ref-type="bibr" rid="bib22">Maris and Oostenveld, 2007</xref>).</p><p>We tested to what extent the choice behavior of a task was reflected in the neural patterns through multiple regression (<xref ref-type="fig" rid="fig4">Figure 4A–D</xref>). For the numerical task, a model RDM was calculated for each participant based on the differences in choice probability for each number pair (see below). The bandit model RDM was constructed by taking the average probability of choosing the most valuable bandit (according to the delta-rule model estimates) for any bandit pair. Both models were vectorized and z-scored and entered as two regressors in a model explaining variance in the neural RDM of either the numerical task (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) or the bandit task (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). Similarly, for the CPP control analyses (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2D–E</xref>), a model RDM was constructed based on the differences in average peak activity per condition (see below). The CPP model was then entered in a multiple regression together with the magnitude model, to determine whether the variance in neural patterns could be explained by a magnitude code over and above the univariate findings.</p></sec><sec id="s4-8"><title>CPP analysis</title><p>Normalized EEG epochs were averaged for each digit (independent of color category) or for each subjective bandit rank. Based on previous research (<xref ref-type="bibr" rid="bib34">Spitzer et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Twomey et al., 2015</xref>), we selected seven centro-parietal electrodes (CP1, P1, POz, CPz, CP2 and P2) and averaged the event-related potentials (ERP) over these electrodes for each stimulus. Next, we sought to identify for each task the time window where the disparity in ERP signals was greatest between stimulus types, using a non-parametric omnibus test (Kruskal-Wallis test) at every time point. To avoid circular inference, the test was performed in a leave-one-out fashion, determining significance based on the remaining 45 participants. The largest cluster of adjacent significant time points (p&lt;0.01) was then determined using FDR correction for multiple comparisons (<xref ref-type="bibr" rid="bib2">Benjamini and Hochberg, 2009</xref>). Activity within each individual’s time window was then averaged for each condition and differences in the ERP averages were taken to construct RDMs that were used as control models for RSA (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p></sec><sec id="s4-9"><title>Dimensionality reduction</title><p>We assessed the dimensionality of the neural data through Singular Value Decomposition (SVD), a method that allows to efficiently obtain principal components in the data through linear transformation. After estimating beta coefficients for each condition, we used SVD at each time point to obtain the diagonal matrix <inline-formula><mml:math id="inf58"><mml:mi>Σ</mml:mi></mml:math></inline-formula> that contained the six singular values. We then systematically reduced the dimensionality of the data by removing the last column of <inline-formula><mml:math id="inf59"><mml:mi>Σ</mml:mi></mml:math></inline-formula>, reconstructed the data under the reduced dimensionality and followed the rest of the cross-validation pipeline as described above. Changes in the strength of the cross-validation were tested by comparing the model – EEG RDM correlations averaged over the 350-600 ms time window, under the different dimensionalities of the data (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p></sec><sec id="s4-10"><title>Psychometric model</title><p>To estimate numerical magnitude distortion in the numerical task, we fitted a psychometric model to the choice data (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). The model is adapted from that described in <xref ref-type="bibr" rid="bib34">Spitzer et al. (2017)</xref>. First, input values (numbers 1 – 6 in the task) are normalized between 0 and 1 in six equidistant steps. These normalized values <inline-formula><mml:math id="inf60"><mml:mi>n</mml:mi><mml:mi>X</mml:mi></mml:math></inline-formula> are then transformed into a subjective decisional value <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> by exponentiating them with free parameter <inline-formula><mml:math id="inf62"><mml:mi>k</mml:mi></mml:math></inline-formula>.<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mover accent="true"><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></disp-formula></p><p>When <italic>k = 1</italic>, <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is equal to <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. When <italic>k &gt; 1</italic>, decision values are exponential, giving relatively higher weights to larger numbers and being more indifferent to smaller numbers. Conversely, when <italic>k &lt; 1</italic>, decision values are compressed, giving lower weight to the larger numbers. Next, we model the trial-level decision-value as the sum over all samples <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold">=</mml:mo><mml:munderover><mml:mo mathvariant="bold">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo mathvariant="bold">=</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="bold">10</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">⋅</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">⋅</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mrow><mml:mn mathvariant="bold">10</mml:mn><mml:mo mathvariant="bold">−</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is an indicator variable that codes for stimulus category (<italic>orange</italic> = -1<italic>, blue</italic> = 1) and <inline-formula><mml:math id="inf67"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a leakage term that exponentially discounts earlier samples in the stream. Finally, the model uses a logistic function for computing choice probabilities:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo mathvariant="bold">=</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo mathvariant="bold">−</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mn mathvariant="bold">1</mml:mn><mml:mo mathvariant="bold">+</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow><mml:mo mathvariant="bold">−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo mathvariant="bold">+</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the probability of choosing the blue category. <inline-formula><mml:math id="inf69"><mml:mi>s</mml:mi></mml:math></inline-formula> is the inverse slope of the logistic choice function and <inline-formula><mml:math id="inf70"><mml:mi>B</mml:mi></mml:math></inline-formula> captures a simple response bias toward one of the two categories. Finally, <inline-formula><mml:math id="inf71"><mml:mi>f</mml:mi></mml:math></inline-formula> is an indicator variable that codes for the framing of the task, inverting the choice probability for the low frame (<italic>f</italic> = 1) compared to the high frame (<inline-formula><mml:math id="inf72"><mml:mi>f</mml:mi></mml:math></inline-formula>= 0). Best fitting parameters for <inline-formula><mml:math id="inf73"><mml:mi>k</mml:mi></mml:math></inline-formula>[0.01 – 10], <inline-formula><mml:math id="inf74"><mml:mi>l</mml:mi></mml:math></inline-formula>[0 – 1], <inline-formula><mml:math id="inf75"><mml:mi>m</mml:mi></mml:math></inline-formula>[unconstrained] and <inline-formula><mml:math id="inf76"><mml:mi>s</mml:mi></mml:math></inline-formula> [0.001 – 8] were obtained using standard optimization tools in Matlab.</p><p>Model-free decision weights were estimated for each participant using an averaging approach to compare to the model predictions. Choice probabilities for each digit were calculated by averaging over all responses to trials where that digit was present.</p></sec><sec id="s4-11"><title>Neurometric mapping</title><p>In order to obtain an estimate of the distortion in neural representational geometry, we generated a range of candidate model RDMs computed from features that were distorted by a parameter <inline-formula><mml:math id="inf77"><mml:mi>k</mml:mi></mml:math></inline-formula>, analogous to the psychometric model. Six equidistant values between 0 and 1 were raised to the power of <inline-formula><mml:math id="inf78"><mml:mi>k</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) and model RDMs were constructed based on the Euclidean distances after distortion. Parameters that fitted the neural data best were found through exhaustive search through values of <inline-formula><mml:math id="inf79"><mml:mi>k</mml:mi></mml:math></inline-formula> from 0.35 – 3 in steps of 0.01, iteratively computing the Kendall Tau-a correlation between the upper triangle of the model RDM and the neural RDM averaged over a time window between 350 and 600 ms. The distortion <inline-formula><mml:math id="inf80"><mml:mi>k</mml:mi></mml:math></inline-formula> associated with the highest correlation was determined in each participant individually and subjected to group-level analysis. Representational geometries for the two tasks were stable in this time window based on the analysis depicted in <xref ref-type="fig" rid="fig2">Figure 2B</xref>.</p></sec><sec id="s4-12"><title>Neural network</title><p>We constructed a simple feedforward neural network with 21 input units (1 bias unit and two input modules of 20 units, <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), 10 hidden units <italic>H</italic> and 10 output units <italic>Y</italic> (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). The network was trained (learning rate = 0.001) to map inputs <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, both consisting of 6 stimuli with 20 features each, onto 6 random vectors. Both inputs were generated by drawing random values from a standard normal distribution. In the crucial test condition, both <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> shared a second-order structure of gradually increasing dissimilarity. This was achieved by successively flipping the sign of two more features for each adjacent stimulus. The network learned to minimize the cost-function (cross-entropy) with respect to the supervision signal and via backpropagation, first on inputs <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> arriving at input units <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and after 10<sup>6</sup> iterations it was then retrained on inputs <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> fed into units <inline-formula><mml:math id="inf90"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p>Two control conditions were included to assess the contribution of shared structure to retraining performance. In one control, the model was initially trained on an input <inline-formula><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that was entirely random, that is not constructed using the sign-flipping method. In the second control, hidden-to-output weights <italic>W2</italic> were shuffled before retraining on <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Simulations were run 100 times for each of the conditions (<inline-formula><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf94"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> shared structure vs. <inline-formula><mml:math id="inf95"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was random; <italic>W2</italic> unshuffled vs. shuffled).</p><p>Next, RSA was performed on the hidden unit activations, after convergence had been achieved on retraining, to test for shared representational structure in the hidden units. Each stimulus from <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was fed into <inline-formula><mml:math id="inf97"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf98"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> into <inline-formula><mml:math id="inf99"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to obtain hidden unit activations for each stimulus. A cross-validation RDM was then constructed based on the differences in activations between <inline-formula><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for each stimulus and correlated with a magnitude model RDM (<xref ref-type="fig" rid="fig6">Figure 6E</xref>).</p></sec><sec id="s4-13"><title>Data and code availability</title><p>All code and materials to reproduce the analyses and experiments are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/summerfieldlab/Luyckx_etal_2019">https://github.com/summerfieldlab/Luyckx_etal_2019</ext-link>. (<xref ref-type="bibr" rid="bib21">Luyckx, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/Luyckx_etal_2019">https://github.com/elifesciences-publications/Luyckx_etal_2019</ext-link>). Data to reproduce the results available from the Dryad Digital Repository: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.7k7s800">https://doi.org/10.5061/dryad.7k7s800</ext-link>. Raw EEG data files are available upon request.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank Zeb Kurth-Nelson, Laurence Hunt and Gaia Scerif for their insightful comments and Mark Stokes for providing access to EEG equipment.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Software, Supervision, Funding acquisition, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: Informed consent was given before the start of the experiment. The study was approved by the Medical Science Inter-Divisional Research Ethics Committee at Oxford University (R49578/RE001).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.42816.018</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-42816-transrepform-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data necessary to reproduce the results are available on <ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.5061/dryad.7k7s800">https://dx.doi.org/10.5061/dryad.7k7s800</ext-link>. All code and materials to reproduce the analyses and experiments are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/summerfieldlab/Luyckx_etal_2019">https://github.com/summerfieldlab/Luyckx_etal_2019</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/Luyckx_etal_2019">https://github.com/elifesciences-publications/Luyckx_etal_2019</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Data from: Neural structure mapping in human probabilistic reward learning</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.7k7s800</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alfred</surname> <given-names>KL</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Kraemer</surname> <given-names>DJM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Putting the pieces together: generating a novel representational space through deductive reasoning</article-title><source>NeuroImage</source><volume>183</volume><fpage>99</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.07.062</pub-id><pub-id pub-id-type="pmid">30081195</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Hochberg</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Controlling the false discovery rate : a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society Series B</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.2307/2346101</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bueti</surname> <given-names>D</given-names></name><name><surname>Walsh</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The parietal cortex and the representation of time, space, number and other magnitudes</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>364</volume><fpage>1831</fpage><lpage>1840</lpage><pub-id pub-id-type="doi">10.1098/rstb.2009.0028</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chafee</surname> <given-names>MV</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A scalar neural code for categories in parietal cortex: representing cognitive variables as &quot;more&quot; or &quot;less&quot;</article-title><source>Neuron</source><volume>77</volume><fpage>7</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.025</pub-id><pub-id pub-id-type="pmid">23312511</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname> <given-names>A</given-names></name><name><surname>Makeig</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname> <given-names>RJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Goals and habits in the brain</article-title><source>Neuron</source><volume>80</volume><fpage>312</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.007</pub-id><pub-id pub-id-type="pmid">24139036</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname> <given-names>MH</given-names></name><name><surname>Shaki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Number concepts: abstract and embodied</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>373</volume><elocation-id>20170125</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0125</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fitzgerald</surname> <given-names>JK</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Fanini</surname> <given-names>A</given-names></name><name><surname>Bennur</surname> <given-names>S</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Assad</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Biased associative representations in parietal cortex</article-title><source>Neuron</source><volume>77</volume><fpage>180</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.014</pub-id><pub-id pub-id-type="pmid">23312525</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Bisley</surname> <given-names>JW</given-names></name><name><surname>Roitman</surname> <given-names>JD</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name><name><surname>Miller</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>One-dimensional dynamics of attention and decision making in LIP</article-title><source>Neuron</source><volume>58</volume><fpage>15</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.01.038</pub-id><pub-id pub-id-type="pmid">18400159</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gentner</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Structure-Mapping: a theoretical framework for analogy*</article-title><source>Cognitive Science</source><volume>7</volume><fpage>155</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog0702_3</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gentner</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Bootstrapping the mind: analogical processes and symbol systems</article-title><source>Cognitive Science</source><volume>34</volume><fpage>752</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1111/j.1551-6709.2010.01114.x</pub-id><pub-id pub-id-type="pmid">21564235</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanayet</surname> <given-names>FJ</given-names></name><name><surname>Opfer</surname> <given-names>JE</given-names></name><name><surname>Cunningham</surname> <given-names>WA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The value of numbers in economic rewards</article-title><source>Psychological Science</source><volume>25</volume><fpage>1534</fpage><lpage>1545</lpage><pub-id pub-id-type="doi">10.1177/0956797614533969</pub-id><pub-id pub-id-type="pmid">24958687</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kemp</surname> <given-names>C</given-names></name><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name><name><surname>Niyogi</surname> <given-names>S</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A probabilistic model of theory formation</article-title><source>Cognition</source><volume>114</volume><fpage>165</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2009.09.003</pub-id><pub-id pub-id-type="pmid">19892328</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kemp</surname> <given-names>C</given-names></name><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The discovery of structural form</article-title><source>PNAS</source><volume>105</volume><fpage>10687</fpage><lpage>10692</lpage><pub-id pub-id-type="doi">10.1073/pnas.0802631105</pub-id><pub-id pub-id-type="pmid">18669663</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname> <given-names>JR</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname> <given-names>M</given-names></name><name><surname>Brainard</surname> <given-names>D</given-names></name><name><surname>Pelli</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What’s new in Psychtoolbox-3?</article-title><source>Perception</source><volume>36</volume><pub-id pub-id-type="doi">10.1068/v070821</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Kievit</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational geometry: integrating cognition, computation, and the brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id><pub-id pub-id-type="pmid">23876494</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lake</surname> <given-names>BM</given-names></name><name><surname>Ullman</surname> <given-names>TD</given-names></name><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Building machines that learn and think like people</article-title><source>Behavioral and Brain Sciences</source><volume>40</volume><pub-id pub-id-type="doi">10.1017/S0140525X16001837</pub-id><pub-id pub-id-type="pmid">27881212</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname> <given-names>DJ</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The root of all value: a neural common currency for choice</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>1027</fpage><lpage>1038</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.06.001</pub-id><pub-id pub-id-type="pmid">22766486</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Luyckx</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Luyckx_etal_2019</data-title><source>GitHub</source><version designator="612b219">612b219</version><ext-link ext-link-type="uri" xlink:href="https://github.com/summerfieldlab/Luyckx_etal_2019">https://github.com/summerfieldlab/Luyckx_etal_2019</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname> <given-names>JL</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Noelle</surname> <given-names>DC</given-names></name><name><surname>Plaut</surname> <given-names>DC</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name><name><surname>Seidenberg</surname> <given-names>MS</given-names></name><name><surname>Smith</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Letting structure emerge: connectionist and dynamical systems approaches to cognition</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>348</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.06.002</pub-id><pub-id pub-id-type="pmid">20598626</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mnih</surname> <given-names>V</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name><name><surname>Silver</surname> <given-names>D</given-names></name><name><surname>Rusu</surname> <given-names>AA</given-names></name><name><surname>Veness</surname> <given-names>J</given-names></name><name><surname>Bellemare</surname> <given-names>MG</given-names></name><name><surname>Graves</surname> <given-names>A</given-names></name><name><surname>Riedmiller</surname> <given-names>M</given-names></name><name><surname>Fidjeland</surname> <given-names>AK</given-names></name><name><surname>Ostrovski</surname> <given-names>G</given-names></name><name><surname>Petersen</surname> <given-names>S</given-names></name><name><surname>Beattie</surname> <given-names>C</given-names></name><name><surname>Sadik</surname> <given-names>A</given-names></name><name><surname>Antonoglou</surname> <given-names>I</given-names></name><name><surname>King</surname> <given-names>H</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name><name><surname>Wierstra</surname> <given-names>D</given-names></name><name><surname>Legg</surname> <given-names>S</given-names></name><name><surname>Hassabis</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human-level control through deep reinforcement learning</article-title><source>Nature</source><volume>518</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/nature14236</pub-id><pub-id pub-id-type="pmid">25719670</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nili</surname> <given-names>H</given-names></name><name><surname>Wingfield</surname> <given-names>C</given-names></name><name><surname>Walther</surname> <given-names>A</given-names></name><name><surname>Su</surname> <given-names>L</given-names></name><name><surname>Marslen-Wilson</surname> <given-names>W</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A toolbox for representational similarity analysis</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003553</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003553</pub-id><pub-id pub-id-type="pmid">24743308</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nili</surname> <given-names>H</given-names></name><name><surname>Walther</surname> <given-names>A</given-names></name><name><surname>Alink</surname> <given-names>A</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inferring exemplar discriminability in brain representations</article-title><source>BioRxiv</source><pub-id pub-id-type="doi">10.1101/080580</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connell</surname> <given-names>RG</given-names></name><name><surname>Dockree</surname> <given-names>PM</given-names></name><name><surname>Kelly</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A supramodal accumulation-to-bound signal that determines perceptual decisions in humans</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1729</fpage><lpage>1735</lpage><pub-id pub-id-type="doi">10.1038/nn.3248</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Critchley</surname> <given-names>H</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Temporal difference models and reward-related learning in the human brain</article-title><source>Neuron</source><volume>38</volume><fpage>329</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00169-7</pub-id><pub-id pub-id-type="pmid">12718865</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>S</given-names></name><name><surname>Wheatley</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A common cortical metric for spatial, temporal, and social distance</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>1979</fpage><lpage>1987</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2159-13.2014</pub-id><pub-id pub-id-type="pmid">24478377</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pisauro</surname> <given-names>MA</given-names></name><name><surname>Fouragnan</surname> <given-names>E</given-names></name><name><surname>Retzler</surname> <given-names>C</given-names></name><name><surname>Philiastides</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural correlates of evidence accumulation during value-based decisions revealed via simultaneous EEG-fMRI</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>15808</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms15808</pub-id><pub-id pub-id-type="pmid">28598432</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platt</surname> <given-names>ML</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of decision variables in parietal cortex</article-title><source>Nature</source><volume>400</volume><fpage>233</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1038/22268</pub-id><pub-id pub-id-type="pmid">10421364</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schley</surname> <given-names>DR</given-names></name><name><surname>Peters</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Assessing &quot;economic value&quot;: symbolic-number mappings predict risky and riskless valuations</article-title><source>Psychological Science</source><volume>25</volume><fpage>753</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1177/0956797613515485</pub-id><pub-id pub-id-type="pmid">24452604</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname> <given-names>W</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitzer</surname> <given-names>B</given-names></name><name><surname>Waschke</surname> <given-names>L</given-names></name><name><surname>Summerfield</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Selective overweighting of larger magnitudes during noisy numerical comparison</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>0145</fpage><lpage>0148</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0145</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><edition>Second Edition</edition><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teichmann</surname> <given-names>L</given-names></name><name><surname>Grootswagers</surname> <given-names>T</given-names></name><name><surname>Carlson</surname> <given-names>T</given-names></name><name><surname>Rich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decoding digits and dice with magnetoencephalography: evidence for a shared representation of magnitude</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>999</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01257</pub-id><pub-id pub-id-type="pmid">29561240</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name><name><surname>Kemp</surname> <given-names>C</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name><name><surname>Goodman</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How to grow a mind: statistics, structure, and abstraction</article-title><source>Science</source><volume>331</volume><fpage>1279</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1126/science.1192788</pub-id><pub-id pub-id-type="pmid">21393536</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tervo</surname> <given-names>DGR</given-names></name><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Toward the neural implementation of structure learning</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>99</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.014</pub-id><pub-id pub-id-type="pmid">26874471</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Twomey</surname> <given-names>DM</given-names></name><name><surname>Murphy</surname> <given-names>PR</given-names></name><name><surname>Kelly</surname> <given-names>SP</given-names></name><name><surname>O'Connell</surname> <given-names>RG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The classic P300 encodes a build-to-threshold decision variable</article-title><source>European Journal of Neuroscience</source><volume>42</volume><fpage>1636</fpage><lpage>1643</lpage><pub-id pub-id-type="doi">10.1111/ejn.12936</pub-id><pub-id pub-id-type="pmid">25925534</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walsh</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A theory of magnitude: common cortical metrics of time, space and quantity</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>483</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2003.09.002</pub-id><pub-id pub-id-type="pmid">14585444</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Hosseini</surname> <given-names>EA</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Flexible timing by temporal scaling of cortical responses</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>102</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0028-6</pub-id><pub-id pub-id-type="pmid">29203897</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42816.022</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Lee</surname><given-names>Daeyeol</given-names></name><role>Reviewing Editor</role><aff><institution>Yale School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Lee</surname><given-names>Daeyeol</given-names> </name><role>Reviewer</role><aff><institution>Yale School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Chafee</surname><given-names>Matthew</given-names> </name><role>Reviewer</role><aff><institution>University of Minnesota</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Neural structure mapping in human probabilistic reward learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Daeyeol Lee as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Matthew Chafee (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Neural activity recorded with EEG display similar responses associated with two different types of magnitude information when the subjects process a series of rapidly presented numbers and when the subjects learned a set of reward probabilities associated with arbitrary visual. This suggests that the brain uses the dimension of magnitude as a scaffolding to incorporate new information.</p><p>Essential revisions:</p><p>1) Results do not convincingly demonstrate that the similarity in the neural activity induced by numbers and probability is reflected in the pattern, rather than in a univariate activity.</p><p>The authors use representational similarity analysis (RSA), based on a Euclidean distance measure, to compare patterns of activation. Previous research has shown univariate monotonic representations of value in several brain areas, including posterior parietal cortex (e.g. encoding of both magnitude and probability of expected juice, Platt and Glimcher 1999). If I understand correctly, a crucial aspect of the results here is that they hold after accounting for a univariate effect, so that the similarity is indeed in the <italic>pattern</italic> of activation. The univariate effect was estimated based on the mean response of seven centro-parietal electrodes. It is not clear that this is enough to rule out the possibility that the results still reflect a univariate effect – for example, there may be additional univariate effects in other electrodes, which were not accounted for. Why did the authors choose to use a Euclidean distance measure, which by definition will also pick up univariate effects? How about using the Pearson correlation (or 1-Pearson correlation) instead? This measure will not reflect any univariate effects.</p><p>2) The main result shown in Figure 1C needs clarifications.</p><p>Figure 1C shows the similarity of within-task and cross-task decoding. Although the results from the within-task coding look clean, the results from the cross-task decoding provide only limited support to the shared magnitude representation. Namely, the activity associated with the maximum quantity (6) looks distinct from the remaining 5 values, although it looks more similar to larger values (4 and 5) than the smaller ones. This is also very different from the results from the simulation of network model (Figure 2E). In addition, there is not a strong tendency for EEG feature vectors to be more similar along the diagonal within the upper right and lower left blocks themselves (representing the same magnitudes across the two tasks) versus off the diagonal (representing different magnitudes in the two tasks) within these blocks. It seems as if the neural encoding of individual magnitudes was lost between the two conditions. The authors performed additional tests in Figure 1E by removing individual quantities, but the results show the average of all those control analyses. The authors should test the similarity after removing just the maximum value and see whether the remaining values show cross-task similarity. If not, they should provide some explanation as to why their findings might be entirely driven by the maximum value.</p><p>Is it possible that the similarity reflected the brain being in a “magnitude evaluation” state rather than “representing magnitude 6” state between the two tasks (as one example)? If the neural encoding of specific magnitudes does not generalize across tasks, to what extent can it be said that the two tasks share a single underlying “mental number line”? Figure 3A (bottom panel), Figure 2—figure supplement 2, and associated analysis seem to get at this point but the link here was not entirely clear. Figure 3A (bottom panel) shows that removing the diagonal from the cross-validation across tasks did not remove the cross validation between tasks over time (that is, EEG feature vectors at one time point in the bandit task were similar to EEG feature vectors at multiple time points in the number task and vice versa). This result is interpreted to indicate that the cross-temporal similarity did not depend on shared single-quantity coding across tasks (“but by a gradual distance effect”). Could it also reflect a shared state change across tasks related to the cognitive process of quantitative comparison, rather than magnitude encoding as suggested by a shared number line? It could be useful to consider more extensively the limit to which the EEG data indicate that the neural representation of specific magnitudes generalizes across tasks.</p><p>Another interesting aspect of the dissimilarity data across tasks is that there seems to be greater EEG vector similarity (“confusion”) off-diagonal in the number task (Figure 1C, upper left quadrant) relative to the bandit task (lower right quadrant). Does this imply different “width” of neural tuning for magnitude in the two tasks? Although it is difficult to extrapolate from single neuron to EEG studies, single neuron recording in prefrontal and parietal cortex of monkeys performing quantity evaluation tasks such as those conducted by A Nieder, EK Miller, and colleagues demonstrated that single prefrontal and parietal neurons have tuning functions for magnitude that are centered on different “preferred” quantities but are broadly tuned. This seems at least conceptually consistent with the similarity between EEG feature vectors seen off-diagonal in the upper left quadrant of Figure 1C. Conversely, similarity between EEG feature vectors seems much more concentrated along the diagonal in the bandit task (lower right quadrant, Figure 1C). This could potentially imply a neural code that is more like a look-up table in the bandit task in which a specific EEG feature vector was only seen for bandit 5 and no other bandit for example). That could suggest two magnitude representations in the two tasks, one tuned for magnitude (number task), one implementing a lookup table for magnitude (bandit task). Some comment about this potential different in magnitude representations could be useful. This would not invalidate the idea of a shared magnitude representation, but it might identify more clearly aspects in which the magnitude representation was modulated across contexts.</p><p>3) Behaviors need to be documented more carefully.</p><p>The behavioral in both tasks seems very important for the research question, yet the behavior is hardly reported. The actual choices, as a function of the digits/bandits presented are not reported. In the supplementary material, Figure S3 presents some results, but these were not completely clear to me. The authors replicate the distortion in weighting numbers in the numerical task, which they have reported previously, and also provide convincing evidence that this distortion is associated with the neural signal. However, they do not show whether the behavioral distortions in the two tasks are correlated across subjects, and they do show that the neural distortions are not correlated (Figure 3B). I did not follow the logic of Figure 3C – how exactly were choice distortions in the numerical task used? Why were the distortions estimated from the bandit task regressed out? Isn't the idea that the same system is responsible for distortions in both tasks? Or do you assume separate sources for distortions, only some of which are shared across tasks?</p><p>The main thrust of the argument was that forming generalized representations of the structure of input data (such as the concept of magnitude) in one context accelerates learning in new contexts. The network model examined this question, but the behavioral data in human subjects was not interrogated to show that learning in the second task was accelerated relative to the first (unless I missed it). It is impressive that distortions in magnitude representation (biased encoding of larger magnitudes) were shared across task contexts, suggesting a shared magnitude representation. However, the behavioral or computational benefits of the underlying generalized representation in terms of accelerating learning in new contexts did not appear to be explicitly addressed. If that is the case it could be useful to consider this limitation (and potentially how it could be addressed in future studies).</p><p>4) Some methods need to be described in more details so that the manuscript is more accessible to non-expert readers.</p><p>What aspect of neural activity comprised the feature vector entered in the RSA? The Material and methods states “linear regression (GLM) was used to estimate beta coefficients for each number or (ranked) bandit for each electrode and time point.” I was puzzled what data went into the regression model and how the model was specified. Am I right that there were separate regressors for each individual number and bandit, each coded by a dummy variable, and that the regression coefficient associated with each variable (at each electrode and time point) quantified the proportion of variance in z-scored EEG signal amplitude explained by the presence (absence) of that specific quantity over stimulus repetitions (trials)? One critical piece of information missing for me was the source of the variance the model was trying to explain (variability over stimulus presentations?) It would be important in addition to clarify whether, rather than the dummy coding above, the GLM model included numerical quantity and reward (bandit) probability as scalar independent variables (which would test a linear relation between neural activity and magnitude). Some additional explanation about the steps in the analysis, specification of the model, whether the model explained variance over stimulus repetitions (or trials) or some other source, and what the meaning of the resulting beta coefficients was in neural terms would help increase the clarity of the main finding.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.42816.023</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Results do not convincingly demonstrate that the similarity in the neural activity induced by numbers and probability is reflected in the pattern, rather than in a univariate activity.</p><p>The authors use representational similarity analysis (RSA), based on a Euclidean distance measure, to compare patterns of activation. Previous research has shown univariate monotonic representations of value in several brain areas, including posterior parietal cortex (e.g. encoding of both magnitude and probability of expected juice, Platt and Glimcher 1999). If I understand correctly, a crucial aspect of the results here is that they hold after accounting for a univariate effect, so that the similarity is indeed in the pattern of activation. The univariate effect was estimated based on the mean response of seven centro-parietal electrodes. It is not clear that this is enough to rule out the possibility that the results still reflect a univariate effect – for example, there may be additional univariate effects in other electrodes, which were not accounted for. Why did the authors choose to use a Euclidean distance measure, which by definition will also pick up univariate effects?. How about using the Pearson correlation (or 1-Pearson correlation) instead? This measure will not reflect any univariate effects.</p></disp-quote><p>Thanks for this point. The reviewers are right that previous studies have demonstrated univariate encoding of probability and value in the parietal cortex. The Platt and Glimcher study cited of course involves recording from single cells sampled to have response fields at specific locations (i.e. congruent with one of the targets), and thus one might not expect it to translate directly to macroscopic signals measured in human scalp EEG. It is also true that we have previously shown monotonic univariate encoding of number in EEG (Spitzer et al., 2017) and others have shown that the subjective value of economic prospects, such as food items, is encoded in the CPP (Pisauro et al., 2017). Importantly however, our study is the first to demonstrate such signals in human EEG during a probabilistic reward learning task, involving completely arbitrary visual stimuli. This advance notwithstanding, we agree that our empirical results would be less novel if all effects were simply attributable to a common univariate CPP signal (although our theoretical account would still stand). However, our control analysis and in particular the careful consideration of the dimensionality of the signal patterns (SVD analyses) seem to suggest that this is not the case.</p><p>The reviewer points out that correlation distance, which is scale invariant and thus removes the univariate effect, would be an appropriate way to test this. We agree. In fact, we tried both measures (Euclidean and correlation distances) during our original analysis and they yielded similar results. We chose to display the Euclidean distance because it is (arguably) a more interpretable measure. However, in response to the reviewers’ suggestions, we have now added a supplementary figure that presents the same results using (Pearson) correlation distance (Figure 1—figure supplement 1). As the reviewer will see, correlation distance yields very similar results to Euclidean distance.</p><p>We agree with the reviewers that activity from other electrodes not included in our subset of 7 electrodes could contain residual univariate effects. Since our EEG data is referenced to the mean of all electrodes, the sum of all recorded activity across the scalp is zero. This makes it more challenging to deal with this issue (i.e. one inevitably has to sub-select electrode clusters to plot a univariate effect, or else it will simply average out across the scalp). However, another way to test whether our effects are univariate or multivariate is to remove dimensions from the data, for example using singular value decomposition (SVD), and test whether our effect persists after removal of the first dimension. We have now added a supplementary analysis (Figure 5—figure supplement 3) using this approach and recomputing the cross-validation statistics. If the effect were purely univariate, removing the first dimension would eliminate it in cross-validation. However, with the first dimension removed, still, a significant cluster of cross-validation emerges at the same time as the originally observed effect, and a previously unobserved cluster also emerges later in time. Our best interpretation of these findings aligns with that proposed in the initial manuscript: that there is a major univariate component to our cross-validation effect (as would be expected from previous studies), but that the shared pattern is also observed in higher dimensions of the data.</p><disp-quote content-type="editor-comment"><p>2) The main result shown in Figure 1C needs clarifications.</p><p>Figure 1C shows the similarity of within-task and cross-task decoding. Although the results from the within-task coding look clean, the results from the cross-task decoding provide only limited support to the shared magnitude representation. Namely, the activity associated with the maximum quantity (6) looks distinct from the remaining 5 values, although it looks more similar to larger values (4 and 5) than the smaller ones.</p></disp-quote><p>Thanks for this. In part, the reviewer is right; the greatest distance is between quantity 6 and the other 5 quantities. We think this is due to the “anti-compression” in the number line in this task, an effect we have reported previously (Spitzer et al., 2017) and replicate here (Figure 4E-F). In part, this effect appears somewhat visually exaggerated due to the scaling of the 12 x 12 cross-validation RDM and nonlinearities in the colormap (the “hot” map in Matlab). However, the reviewer is right to ask whether the effect persists when number 6 is excluded. Indeed, it does. In Figure 2C, we excluded each of the numbers in turn and recalculated the cross-validation effect, plotting for each pixel the number of times for which our cross-validation reached significance (i.e. zero to 6, the maximum number of possible folds of the data). Now, additionally, in Figure 2—figure supplement 1, we show the data specifically excluding number 6. As can be seen, the cross-validation effect is still present, albeit reduced in magnitude as one might expect.</p><disp-quote content-type="editor-comment"><p>This is also very different from the results from the simulation of network model (Figure 2E).</p></disp-quote><p>This is a good point. We could have been clearer that our network simulations were not intended to explicitly simulate the human data from this task, but rather to show (as a proof of concept) that prior learning of data with comparable similarity structure can facilitate relearning. This is because in the simulations, the level of prior experience is under our control (we either expose the network to a different dataset with shared structure, or do not). Clearly, this control is unavailable for the human data, because our participants (healthy adults) are all numerate and thus have substantial prior learning of magnitude structure. Instead, the goal of our simulations was different – to show why learning (or having learned) such a representation might be beneficial for new learning, i.e. to provide a normative motivation for the coding scheme that our data reveal. We now acknowledge these limitations more explicitly both when describing the neural network and in the Discussion.</p><p>In newer work building on the present findings, which is ongoing in the lab, we are conducting experiments that resemble far more closely the neural network simulations (i.e. testing for learning and generalisation in wholly novel domains with shared or unshared structure). We hope that this work will be ready for dissemination soon.</p><disp-quote content-type="editor-comment"><p>In addition, there is not a strong tendency for EEG feature vectors to be more similar along the diagonal within the upper right and lower left blocks themselves (representing the same magnitudes across the two tasks) versus off the diagonal (representing different magnitudes in the two tasks) within these blocks. It seems as if the neural encoding of individual magnitudes was lost between the two conditions.</p></disp-quote><p>We agree that, at least visually, it might seem as if on-diagonal elements in the between-task cross-validations (lower left and upper right) do not appear very strong. In part, greater on-diagonal similarities <italic>within</italic> tasks (upper left and lower right) probably follow naturally from the additional boost to decoding given by shared perceptual features (i.e. Arabic numeral 3 is more similar to itself than to any of the donkey images). This exaggerates the scaling of the figure which may obscure more subtle differences in similarity in the between-task cross-validation. To test this explicitly, we examined the on- and off-diagonal information separately. We included new control analyses and a new figure (Figure 3) specifically tackling this question. We describe the ‘Exemplar Discriminability Index’ (EDI; Nili et al., 2016), a measure that indexes the similarity of stimuli of equivalent magnitudes (on-diagonal) compared the other stimuli (off-diagonal) (Figure 3A). In a second control analysis, we excluded the on-diagonal information to probe whether our cross-validation was not solely driven by one-to-one mapping of magnitudes, but also by the pattern of gradually increasing dissimilarity (Figure 3B). Both effects were independently reliable. In other words, number 3 is more similar to bandit 3 than to other bandits (on-diagonal or exemplar cross-validation effect) and number 3 is also more similar to bandits 2 and 4 than to other bandits (off-diagonal distance effect, statistics computed after excluding the diagonal). This seems to support the claims we make in the paper.</p><disp-quote content-type="editor-comment"><p>The authors performed additional tests in Figure 1E by removing individual quantities, but the results show the average of all those control analyses. The authors should test the similarity after removing just the maximum value and see whether the remaining values show cross-task similarity. If not, they should provide some explanation as to why their findings might be entirely driven by the maximum value.</p></disp-quote><p>Thank you – we believe we have answered this point above – conducting exactly the analysis requested by the reviewer. The results still hold when the maximum quantity (number or bandit 6) is excluded (Figure 2—figure supplement 1).</p><disp-quote content-type="editor-comment"><p><italic>Is it possible that the similarity reflected the brain being in a “magnitude evaluation” state rather than “representing magnitude 6” state between the two tasks (as one example)? If the neural encoding of specific magnitudes does not generalize across tasks, to what extent can it be said that the two tasks share a single underlying “mental number line”? Figure 3A (bottom panel), Figure 2</italic>—figure supplement 2, <italic>and associated analysis seem to get at this point but the link here was not entirely clear. Figure 3A (bottom panel) shows that removing the diagonal from the cross-validation across tasks did not remove the cross validation between tasks over time (that is, EEG feature vectors at one time point in the bandit task were similar to EEG feature vectors at multiple time points in the number task and vice versa). This result is interpreted to indicate that the cross-temporal similarity did not depend on shared single-quantity coding across tasks (“but by a gradual distance effect”). Could it also reflect a shared state change across tasks related to the cognitive process of quantitative comparison, rather than magnitude encoding as suggested by a shared number line? It could be useful to consider more extensively the limit to which the EEG data indicate that the neural representation of specific magnitudes generalizes across tasks.</italic> </p></disp-quote><p>The reviewer makes a good point that our data could reflect in part a neural signal associated with value comparison, rather than value encoding/evaluation. However, a value comparison signal would depend on the distance between the two bandits presented on a given trial (or perhaps between successive numbers) and should mostly be observed for the second bandit, and not the first. However, we observe the magnitude signal independently and with equal strength for the first-presented and second-presented bandit (Figure 1—figure supplement 3), so we think it is unlikely to be a comparison signal. A related suggestion is that the neural signal encodes uncertainty about the choice. For example, participants may be more certain how to respond when a stimulus is 6 or 1 than when it is 3 or 4. However, we found that the strongest component of the RSA cross-validation effect placed numbers/bandits 1 and 6 at opposite ends of a neural continuum, which is at odds with this suggestion. Thus, we think the neural data we observed are more likely to be related to magnitude evaluation, rather than magnitude comparison.</p><disp-quote content-type="editor-comment"><p>Another interesting aspect of the dissimilarity data across tasks is that there seems to be greater EEG vector similarity (“confusion”) off-diagonal in the number task (Figure 1C, upper left quadrant) relative to the bandit task (lower right quadrant). Does this imply different “width” of neural tuning for magnitude in the two tasks? Although it is difficult to extrapolate from single neuron to EEG studies, single neuron recording in prefrontal and parietal cortex of monkeys performing quantity evaluation tasks such as those conducted by A Nieder, EK Miller and colleagues demonstrated that single prefrontal and parietal neurons have tuning functions for magnitude that are centered on different “preferred” quantities but are broadly tuned. This seems at least conceptually consistent with the similarity between EEG feature vectors seen off-diagonal in the upper left quadrant of Figure 1C. Conversely, similarity between EEG feature vectors seems much more concentrated along the diagonal in the bandit task (lower right quadrant, Figure 1C). This could potentially imply a neural code that is more like a look-up table in the bandit task in which a specific EEG feature vector was only seen for bandit 5 and no other bandit for example). That could suggest two magnitude representations in the two tasks, one tuned for magnitude (number task), one implementing a lookup table for magnitude (bandit task). Some comment about this potential different in magnitude representations could be useful. This would not invalidate the idea of a shared magnitude representation, but it might identify more clearly aspects in which the magnitude representation was modulated across contexts.</p></disp-quote><p>The reviewer is right that overall neural similarity for the numbers is greater than for the bandits. This could imply something fundamental about numerical magnitude and reward probability, but another possibility is that it has to do with differences among the way the two tasks were implemented – our numbers occurred in a rapid stream, whereas the donkeys were presented in just 2 wider-spaced intervals. This choice might seem curious but was motivated by a desire for consistency with a previous paper from our lab (Spitzer et al., 2017) where we had seen the numerical distance effect emerge strongly. Thus we are somewhat wary of trying to read too much into this difference on the basis of the current data alone. In future experiments, we plan to use more comparable tasks for numbers and bandits.</p><p>The fact that the similarity between EEG feature vectors appears much more concentrated along the diagonal in the bandit task is related to this issue. The numbers are overall more similar to each other than to the bandits, such that when a common scale is used for the 12 x 12 matrix, it appears that the EDI is stronger for the bandit task. In fact, when the data are plotted with different scales for the two quadrants, it can be seen that this is largely an artefact of the way we plotted the data. We now include a new plot that makes this clear (Figure 1C).</p><disp-quote content-type="editor-comment"><p>3) Behaviors need to be documented more carefully.</p><p>The behavioral in both tasks seems very important for the research question, yet the behavior is hardly reported. The actual choices, as a function of the digits/bandits presented are not reported. In the supplementary material, Figure S3 presents some results, but these were not completely clear to me. The authors replicate the distortion in weighting numbers in the numerical task, which they have reported previously, and also provide convincing evidence that this distortion is associated with the neural signal. However, they do not show whether the behavioral distortions in the two tasks are correlated across subjects, and they do show that the neural distortions are not correlated (Figure 3B). I did not follow the logic of Figure 3C – how exactly were choice distortions in the numerical task used? Why were the distortions estimated from the bandit task regressed out? Isn't the idea that the same system is responsible for distortions in both tasks? Or do you assume separate sources for distortions, only some of which are shared across tasks?</p></disp-quote><p>We agree that there could have been more emphasis on the behaviour in the main text. We did in fact analyse our behaviour in some detail, but many of these analyses were relegated to the supplementary materials in order to save space (under the original “Short Report” submission). Here, in the revised paper, we have opted to return some material to the main text, and also conducted further behavioural analyses that we hope will address the reviewers’ comments. We now show the choice probabilities for both number and bandit tasks in comparable form (Figure 4A-B). The reviewer’s comments also prompted us to relate behaviour to brain activity in a new way that we find particularly revealing, by asking how differences in choice probabilities for numbers and bandits predict neural activity on each task. Interestingly, behavioural patterns for the numbers jointly explain neural distance effects in both bandit and number tasks, whereas behavioural patterns for the bandits only explain neural distances in the bandit, but not the number task (Figure 4C-D). One interpretation of this finding is that the mental number line is “primary” in that it scaffolds probabilistic reward learning, but the converse is not true. We briefly discuss why for the estimated non-linearities (Figure 4E-F), we could not find a correlation between behaviour in the numerical task and neural signals of the bandit task. It is possible our estimation method for neural RDM (‘neurometric fit’), albeit capturing certain key features, is too simple to describe the full space of the data in which there is a shared pattern.</p><disp-quote content-type="editor-comment"><p>The main thrust of the argument was that forming generalized representations of the structure of input data (such as the concept of magnitude) in one context accelerates learning in new contexts. The network model examined this question, but the behavioral data in human subjects was not interrogated to show that learning in the second task was accelerated relative to the first (unless I missed it). It is impressive that distortions in magnitude representation (biased encoding of larger magnitudes) were shared across task contexts, suggesting a shared magnitude representation. However, the behavioral or computational benefits of the underlying generalized representation in terms of accelerating learning in new contexts did not appear to be explicitly addressed. If that is the case it could be useful to consider this limitation (and potentially how it could be addressed in future studies).</p></disp-quote><p>Thanks for this. As discussed above, it is indeed true that our experiments do not allow us to directly assess the benefits of learning in humans. This is because we are not able to “teach” our participants the orderly/magnitude structure of symbolic numbers – they know it already. However, building on the present findings, we are conducting new experiments where we teach participants two new transitive systems, with a view to measuring exactly the transfer that is demonstrated in our simulations.</p><disp-quote content-type="editor-comment"><p>4) Some methods need to be described in more details so that the manuscript is more accessible to non-expert readers.</p><p>What aspect of neural activity comprised the feature vector entered in the RSA. The Material and methods states “linear regression (GLM) was used to estimate beta coefficients for each number or (ranked) bandit for each electrode and time point.” I was puzzled what data went into the regression model and how the model was specified. Am I right that there were separate regressors for each individual number and bandit, each coded by a dummy variable, and that the regression coefficient associated with each variable (at each electrode and time point) quantified the proportion of variance in z-scored EEG signal amplitude explained by the presence (absence) of that specific quantity over stimulus repetitions (trials)?</p></disp-quote><p>We could have been clearer here. However, the reviewer’s description of our methods is entirely accurate. The dummy coding is a convenient way to obtain the average activation over all trials within a condition, at each electrode and time point. We have amended the Materials and methods section to make our analysis pipeline clearer.</p><disp-quote content-type="editor-comment"><p>One critical piece of information missing for me was the source of the variance the model was trying to explain (variability over stimulus presentations?) It would be important in addition to clarify whether, rather than the dummy coding above, the GLM model included numerical quantity and reward (bandit) probability as scalar independent variables (which would test a linear relation between neural activity and magnitude). Some additional explanation about the steps in the analysis, specification of the model, whether the model explained variance over stimulus repetitions (or trials) or some other source, and what the meaning of the resulting beta coefficients was in neural terms would help increase the clarity of the main finding.</p></disp-quote><p>Our regression-based approach tests for similarities among summary measures for each condition (e.g. bandit or number), as is standard in RSA analysis (we note in passing that this differs somewhat from classifier-based pattern similarity measures where predictions about class labels are often made at the level of individual trials). Neural summary statistics are computed condition-wise using the regression model (with dummy coding) as discussed above. It is only in the final step, when we correlate model RDMs with the neural RDMs, that we test the presence of representational patterns in the neural data. We have gone through our Materials and methods section to make sure that all of these points are clear, in particular bearing in mind that not all readers may be familiar with the standard analysis pipeline for RSA analysis.</p></body></sub-article></article>