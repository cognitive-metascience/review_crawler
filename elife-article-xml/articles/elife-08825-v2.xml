<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">08825</article-id><article-id pub-id-type="doi">10.7554/eLife.08825</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Normative evidence accumulation in unpredictable environments</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-33729"><name><surname>Glaze</surname><given-names>Christopher M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-34495"><name><surname>Kable</surname><given-names>Joseph W</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-17965"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Neuroscience</institution>, <institution>University of Pennsylvania</institution>, <addr-line><named-content content-type="city">Philadelphia</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Psychology</institution>, <institution>University of Pennsylvania</institution>, <addr-line><named-content content-type="city">Philadelphia</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-1044"><name><surname>Behrens</surname><given-names>Timothy</given-names></name><role>Reviewing editor</role><aff><institution>Oxford University</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>cglaze@sas.upenn.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>31</day><month>08</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e08825</elocation-id><history><date date-type="received"><day>19</day><month>05</month><year>2015</year></date><date date-type="accepted"><day>30</day><month>08</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Glaze et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Glaze et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-08825-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.08825.001</object-id><p>In our dynamic world, decisions about noisy stimuli can require temporal accumulation of evidence to identify steady signals, differentiation to detect unpredictable changes in those signals, or both. Normative models can account for learning in these environments but have not yet been applied to faster decision processes. We present a novel, normative formulation of adaptive learning models that forms decisions by acting as a leaky accumulator with non-absorbing bounds. These dynamics, derived for both discrete and continuous cases, depend on the expected rate of change of the statistics of the evidence and balance signal identification and change detection. We found that, for two different tasks, human subjects learned these expectations, albeit imperfectly, then used them to make decisions in accordance with the normative model. The results represent a unified, empirically supported account of decision-making in unpredictable environments that provides new insights into the expectation-driven dynamics of the underlying neural signals.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.001">http://dx.doi.org/10.7554/eLife.08825.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.08825.002</object-id><title>eLife digest</title><p>Organisms gather information from their surroundings to make decisions. Traditionally, neuroscientists have investigated decision-making by first asking what would be optimal for the animal, and then seeing whether and how the brain implements the optimal process. This approach has assumed that the environment consists of noisy, but stable, signals that the brain must decipher by accumulating information over time and ‘averaging out’ the noise.</p><p>Previous research had suggested that most animals can accumulate information. However, these studies also showed that animals, including humans, often fall short of the optimal solution by being overly sensitive to noise and failing to completely average it out. Of course, in real life, the signals themselves can change abruptly and unpredictably, challenging us to distinguish noise from changes in the underlying signals. If a moving target suddenly jolts to the right, is that change part of the normal jitter that should be ignored, or does it predict where the target will be next? How do we know when to keep old information that is still relevant to the decision, and when to discard the old information because a change might have occurred that renders it irrelevant?</p><p>Glaze et al. have addressed this question by building optimal change detection into the traditional ‘information-accumulation’ framework. The model suggests that what researchers previously thought was an over-sensitivity to noise might actually be optimal for the real-life challenge of detecting change. In two different tasks, Glaze et al. tested human volunteers to see if they could make decisions in ways predicted by the model. One task involved the volunteers making decisions about which one of two possible sources of noisy signals generated a given piece of information, with the correct answer changing unpredictably every 1–20 trials. The other task involved looking at a crowd of moving dots, which jolted and wobbled as they changed direction, and the volunteers had to decide which direction the dots were moving at the end of each trial.</p><p>Both experiments showed that the volunteers were remarkably good at making decisions in the ways predicted by the new model, and incorporated learned expectations about the rate of change in underlying signals. The results suggest that humans, and potentially other organisms, are capable of detecting changes in the optimal ways suggested by the decision-making model. The study also makes predictions about what kinds of neural patterns neuroscientists might find when measuring brain activity while organisms do similar tasks.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.002">http://dx.doi.org/10.7554/eLife.08825.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>decision-making</kwd><kwd>change detection</kwd><kwd>drift-diffusion model</kwd><kwd>neuroscience</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health (NIH)</institution></institution-wrap></funding-source><award-id>OppNet Grant R01 MH098899</award-id><principal-award-recipient><name><surname>Glaze</surname><given-names>Christopher M</given-names></name><name><surname>Kable</surname><given-names>Joseph W</given-names></name><name><surname>Gold</surname><given-names>Joshua I</given-names></name></principal-award-recipient></award-group><funding-statement>The funder had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Theoretically optimal dynamics for making decisions in unpredictable environments provide a broadly applicable framework for understanding choice behavior and underlying neural signals.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Even the simplest perceptual judgments, like detecting the presence of a dim light, take time for the brain to process (<xref ref-type="bibr" rid="bib39">Luce, 1986</xref>). Some of this time reflects sensory and motor processing, but a considerable fraction is dedicated to the decision process that converts the incoming sensory information into a categorical judgment that guides behavior (<xref ref-type="bibr" rid="bib60">Sternberg, 2001</xref>). Under certain conditions, this temporally unfolding process serves a normative purpose: improving the accuracy of the decision by reducing uncertainty about the source or identity of noisy inputs. The sequential probability ratio test (SPRT), drift-diffusion model, and related sequential-sampling models are forms of ‘belief-updating’ rules for this normative process, based on perfect integration over time of the logarithm of the likelihood ratio (<italic>LLR</italic>) associated with each data point (<xref ref-type="bibr" rid="bib2">Barnard, 1946</xref>; <xref ref-type="bibr" rid="bib66">Wald, 1947</xref>; <xref ref-type="bibr" rid="bib26">Good, 1979</xref>; <xref ref-type="bibr" rid="bib37">Link, 1992</xref>; <xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2001</xref>; <xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). These models have been useful for studying neural mechanisms of decision-making (<xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>) but are normative for only a restricted set of conditions in which: (1) the ideal starting time-point for accumulation is known (e.g., given by the onset of an experimental trial); and (2) the statistics of the incoming information are perfectly stable throughout the entire sequence, with no change in the underlying signal and all noise coming from the same probability distribution.</p><p>Perfect integration can be particularly problematic for tasks that require the detection of signal changes (<xref ref-type="bibr" rid="bib12">Clifford and Ibbotson, 2002</xref>). When there is certainty about when the change might occur, integrated signals from before vs after that time can be compared to detect the change (<xref ref-type="bibr" rid="bib27">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib42">Macmillan and Creelman, 2004</xref>). However, when there is temporal uncertainty about the change, integrating evidence at the wrong time might miss the signal or add unnecessary noise, resulting in a loss of sensitivity to the change (<xref ref-type="bibr" rid="bib36">Lasley and Cohn, 1981</xref>). Several possible solutions to this problem have been proposed, including using a leaky integrator, taking a time derivative of the evidence to identify changes, or using knowledge of the spatial and temporal structure of the stimulus to guide a more directed search for the evidence (<xref ref-type="bibr" rid="bib30">Henning et al., 1975</xref>; <xref ref-type="bibr" rid="bib44">Nachmias and Rogowitz, 1983</xref>; <xref ref-type="bibr" rid="bib57">Smith, 1995</xref>, <xref ref-type="bibr" rid="bib58">1998</xref>; <xref ref-type="bibr" rid="bib65">Verghese et al., 1999</xref>; <xref ref-type="bibr" rid="bib55">Schrater et al., 2000</xref>). However, none of these solutions provide more general insights into how to balance the operations used to identify both steady, noisy, signals and unpredictable changes in those signals.</p><p>Here we present a normative model of decisions between two alternatives that provides such an account. In a variety of learning and other tasks, the tradeoff between signal identification and change detection has been related to inference algorithms in hidden Markov models and other Bayesian algorithms. These algorithms estimate statistical parameters in the presence of abrupt and unpredictable change-points in the otherwise stable statistics of a data-generating process (<xref ref-type="bibr" rid="bib70">Zakai, 1965</xref>; <xref ref-type="bibr" rid="bib38">Liptser and Shiryaev, 1977</xref>; <xref ref-type="bibr" rid="bib50">Rabiner, 1989</xref>; <xref ref-type="bibr" rid="bib69">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib1">Adams and MacKay, 2007</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib20">Fearnhead and Liu, 2007</xref>; <xref ref-type="bibr" rid="bib68">Wilson et al., 2010</xref>; <xref ref-type="bibr" rid="bib43">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Sato and Kording, 2014</xref>). Here we express these algorithms in a novel form that, unlike previous change-point models, is based on the <italic>LLR</italic> and thus can be compared directly to standard decision models based on evidence accumulation (<xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2001</xref>; <xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). The form thus yields quantitative predictions of both choice behavior and the underlying neural signals for decisions about unstable, noisy stimuli (<xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>). A key feature of the model is that the expected amount of instability in the environment governs the temporal dynamics of the decision process. When perfect stability is expected, evidence is accumulated perfectly. Otherwise, evidence is accumulated with a leak (<xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>) to a non-absorbing boundary that expedites the identification of unexpected changes that should re-start the accumulation process, where both the leak and the boundary depend on the level of expected instability in the environment. These expectation-dependent dynamics represent a novel view of leaky, saturating, or otherwise imperfect evidence accumulation, which here may be understood as facilitating, rather than hindering, statistical inference. We show that human decision-makers can use these dynamics to solve two different tasks on different timescales (tens of seconds vs hundreds of milliseconds) that each requires information accumulation in the presence of unpredictable change-points occurring at different rates.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Model</title><p>Consider a decision about which of two alternatives is the present source of a sequence of noisy data arriving over time. We derived a belief-update rule for these kinds of decisions based on Bayesian principles that have typically been used to understand learning processes in dynamic environments on relatively slow timescales (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) (<xref ref-type="bibr" rid="bib69">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib1">Adams and MacKay, 2007</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib20">Fearnhead and Liu, 2007</xref>; <xref ref-type="bibr" rid="bib68">Wilson et al., 2010</xref>; <xref ref-type="bibr" rid="bib43">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Sato and Kording, 2014</xref>). This rule both accounts for environmental instability and relates directly to models of perfect, leaky, and bounded accumulation that have been used to understand decision processes in stable environments (<xref ref-type="bibr" rid="bib37">Link, 1992</xref>; <xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2001</xref>; <xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). We define belief as the logarithm of the posterior odds of the alternative sources of information (<italic>L</italic>) given all information collected until a given time point. The sign of <italic>L</italic> indicates which source is currently believed to be generating the information, and the magnitude of <italic>L</italic> indicates how certain that belief is. The update rule is optimal when there is a fixed probability that the source could switch to the alternative at any time (i.e., according to a Bernoulli process). Specifically,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>L</italic><sub><italic>n</italic></sub> is the belief at time step <italic>n</italic>, <italic>LLR</italic><sub><italic>n</italic></sub> is the sensory evidence (the log likelihood ratio) at step <italic>n</italic>, <italic>H</italic> (the ‘hazard rate’) is the expected probability at each time step that the source will switch from one alternative to the other, and <italic>ψ</italic> is the time-varying prior expectation (the logarithm of the prior odds) about the source before observing the new evidence:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.003</object-id><label>Figure 1.</label><caption><title>Normative model.</title><p>(<bold>A</bold>) Illustration of the belief-updating process. (<bold>B</bold>) Discrete-time log-prior odds at a given moment as a function of the belief at the prior moment, plotted as <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> for different values of <italic>H</italic>. (<bold>C</bold>) Continuous-time version of the model, with log-prior odds plotted as a function of belief, computed by numerically integrating <xref ref-type="disp-formula" rid="equ7">Equation 4</xref> with d<italic>x</italic>(<italic>t</italic>) = 0 over a 16 ms interval. Here expected instability (<italic>λ</italic>) has units of number of changes per s. Thus, <italic>λ</italic> → ∞ is analogous to discrete-time <italic>H</italic> → 0.5. (<bold>D</bold>–<bold>F</bold>) Examples of how the normative model (solid lines) and perfect accumulation (dashed gray lines) process a time-dependent stimulus (light vs dark grey for the two alternatives, shown at the top) for different hazard rates (<italic>H</italic>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.003">http://dx.doi.org/10.7554/eLife.08825.003</ext-link></p></caption><graphic xlink:href="elife-08825-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.08825.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Dynamics of the continuous-time model.</title><p>(<bold>A</bold>) Example of the temporal derivative of belief magnitude plotted as a function of belief magnitude (<xref ref-type="disp-formula" rid="equ7">Equation 4</xref>), given an average sensory evidence of 7 units of <italic>LLR</italic> per unit time. The point of intersection with the dotted line (i.e., derivative = 0) corresponds to the approximate steady-state value of the belief (the mode of the probability distribution). (<bold>B</bold>) Histogram of belief values at steady state for hazard rate λ = 0.1 Hz from panel <bold>A</bold>, with the approximated solution in <xref ref-type="disp-formula" rid="equ30">Equation 14a</xref> shown in magenta. Note the heavy tail, which is typical for moderate-to-strong input to the model. (<bold>C</bold>) Asymmetric effects of transient ‘perturbations’ of evidence of equal magnitude (35 units of <italic>LLR</italic> per s) but opposite signs. Belief magnitude re-converges to steady state faster after the positive perturbation (i.e., favoring the current belief) than the negative perturbation (i.e., opposing the current belief), which accounts for the heavy tail pointed towards zero in <bold>B</bold>. (<bold>D</bold>–<bold>I</bold>) Simulated temporal evolution of the probability distribution of belief value, given an average sensory evidence of 7 units of <italic>LLR</italic> per s, with an abrupt sign reversal at <italic>t</italic> = 5 s. (<bold>D</bold>–<bold>F</bold>) Histograms of belief at the time-points indicated by arrows. (<bold>G</bold>) Pseudocolor plot of the full probability distributions normalized by the peak probability over the entire time series. Hot/cold colors indicate high/low probabilities. (<bold>H</bold>) Expected value of the belief variable. (<bold>I</bold>) Standard deviation of the belief variable. Note that after a change-point, leaky integration is re-started and beliefs pass through the ‘low-confidence’ regime of the model, resulting in a transient increase of variability that is approximately Gaussian. All simulations used 10,000 iterations.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.004">http://dx.doi.org/10.7554/eLife.08825.004</ext-link></p></caption><graphic xlink:href="elife-08825-fig1-figsupp1-v2.tif"/></fig></fig-group></p><p>The prior expectation <italic>ψ</italic> is the key feature of the model, balancing integration to identify steady signals and differentiation to detect changes by dynamically filtering sensory information in a way that depends on both <italic>L</italic> and <italic>H</italic> (<xref ref-type="fig" rid="fig1 fig2">Figures 1, 2</xref>). For the special case of <italic>H</italic> = 0 (perfect stability), the two rightmost terms in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> cancel. In this case, the update <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> reduces to perfect accumulation as in random-walk and related decision models used to identify steady, but noisy, signals (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) (<xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). In contrast, when <italic>H</italic> is high and changes are expected, accumulation over time is severely limited to facilitate change detection (<xref ref-type="fig" rid="fig1 fig2">Figures 1F, 2G</xref>). For intermediate values of <italic>H</italic>, these operations trade-off to emphasize change detection at the expense of steady signal identification (for higher <italic>H</italic>) or vice versa (for lower <italic>H</italic>; <xref ref-type="fig" rid="fig1 fig2">Figures 1E, 2G</xref>). Finally, in the special case of <italic>H</italic> = 0.5, the history of evidence is irrelevant at all times and all three terms in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> cancel, so <italic>ψ</italic> = 0 and <italic>L</italic><sub><italic>n</italic></sub> = <italic>LLR</italic><sub><italic>n</italic></sub>.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.005</object-id><label>Figure 2.</label><caption><title>Features of the discrete-time (<bold>A</bold>, <bold>C</bold>, <bold>E</bold>, <bold>G</bold>) and continuous-time (<bold>B</bold>, <bold>D</bold>, <bold>F</bold>) normative models.</title><p>(<bold>A</bold>, <bold>B</bold>) Leak rate as a function belief state and hazard rate. Blues are the least leaky and correspond to longer temporal accumulation; reds are the most leaky and correspond to a sign reversal in the change in current belief, resulting in damped oscillations in choice behavior. For the continuous-time model (<bold>B</bold>), there are no leak rates analogous to discrete-time <italic>H</italic> &gt; 0.5. (<bold>C</bold>, <bold>D</bold>) Bias as a function belief state and hazard rate. Dark greens are the most biased in favor of the alternative associated with negative log-odds; yellows are the most biased in favor of the other alternative. (<bold>E</bold>, <bold>F</bold>) Predicted choice accuracy one sample (<bold>E</bold>) or &lt;300 ms (<bold>F</bold>) after a change-point vs during steady-state conditions, at different expected hazard rates, as shown, for two difference strengths of evidence (<bold>E</bold>: |<italic>LLR</italic>| = 0.5 for leftmost curves and 5 for rightmost; <bold>F</bold>: |<italic>LLR</italic>| = 4/s for leftmost curves and 80/s for rightmost). (<bold>G</bold>) Average belief from the discrete-time model over 1000 simulations for each condition shown, each with a single change-point at trial 20.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.005">http://dx.doi.org/10.7554/eLife.08825.005</ext-link></p></caption><graphic xlink:href="elife-08825-fig2-v2.tif"/></fig></p><p>To gain further insight into the dynamics of the model and how it controls this trade-off, we made approximations of the nonlinearity in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><label>(3a)</label><mml:math id="m4"><mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mtext> when </mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(3b)</label><mml:math id="m5"><mml:mrow><mml:mo>≈</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>when </mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ6"><label>(3c)</label><mml:math id="m6"><mml:mrow><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext> when </mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≪</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here <italic>K</italic><sub><italic>n</italic></sub> governs the leakiness of the accumulation process, and <italic>θ</italic><sub><italic>n</italic></sub>, governs a bias. Both parameters are adaptive, depending on both <italic>H</italic> and <italic>L</italic><sub><italic>n</italic></sub>, with dynamics that jointly establish a boundary on the prior and thus limit subsequent belief strength. The dynamics include two regimes, as follows.</p><p>First, when beliefs are uncertain (i.e., regimes around <italic>L</italic><sub><italic>n − 1</italic></sub> = 0 in <xref ref-type="fig" rid="fig1 fig2">Figures 1B, 2A,C</xref>; <xref ref-type="disp-formula" rid="equ4">Equation 3a</xref>, in which <italic>K</italic><sub><italic>n</italic></sub> predominates over <italic>θ</italic><sub><italic>n</italic></sub>), the model acts like a leaky accumulator, in which the prior expectation is a fraction of the previous belief (<xref ref-type="bibr" rid="bib10">Busemeyer and Townsend, 1993</xref>; <xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib62">Tsetsos et al., 2012</xref>). Thus, the dynamics of a leaky accumulator can, in principle, act like the normative model, but only in the low-certainty regime (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In this regime, the normative leak is adaptive, which has been demonstrated previously (<xref ref-type="bibr" rid="bib48">Ossmy et al., 2013</xref>), and is directly dependent on <italic>H</italic>, which has not been described previously. For low <italic>H</italic> and thus relative stability, a small leak provides long integration times. For <italic>H</italic> ≈ 0.5 (the correct answer is equally likely to stay or switch after each sample), the model discards all historical information and <italic>L</italic> depends only on <italic>LLR</italic>. For <italic>H</italic> &gt; 0.5 (the correct answer is more likely to switch after each sample), the prior expectation undergoes damped oscillations (<xref ref-type="fig" rid="fig2">Figure 2G</xref>), even when the source of evidence is transiently stable. These oscillations repeatedly switch the direction of existing beliefs because of the high expected probability of change on each discrete time step.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.006</object-id><label>Figure 3.</label><caption><title>Two ways of approximating the discrete-time normative model, accounting separately for its dynamics when the sensory evidence is consistently weak (<bold>A</bold>, average |<italic>LLR</italic>| ≈ 0.25) or strong (<bold>B</bold>, average |<italic>LLR</italic>| ≈ 10).</title><p>As in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, each panel has discrete-time log-prior odds as a function of the belief at the previous moment. Dark blue lines correspond to the normative model for <italic>H</italic> = 0.1. Light blue lines correspond to a leaky accumulator with no bias, related to the linear approximation in <xref ref-type="disp-formula" rid="equ4">Equation 3a</xref> but optimized to best approximate the normative model separately for each average evidence strength in <bold>A</bold> and <bold>B</bold>. Magenta lines correspond to perfect accumulation (no leak) to a stabilizing boundary related to <xref ref-type="disp-formula" rid="equ5 equ6">Equation 3b,c</xref>, also optimized for each evidence strength. In general, the leaky accumulator is better at approximating the normative solution for weak sensory evidence (<bold>A</bold>), whereas the bounded accumulator is better at approximating the solution for strong sensory evidence (<bold>B</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.006">http://dx.doi.org/10.7554/eLife.08825.006</ext-link></p></caption><graphic xlink:href="elife-08825-fig3-v2.tif"/></fig></p><p>Second, as the magnitude of <italic>L</italic><sub><italic>n − 1</italic></sub> increases and belief certainty becomes high (i.e., regimes around <italic>L</italic><sub><italic>n − 1</italic></sub> far from zero in <xref ref-type="fig" rid="fig1 fig2">Figures 1B, 2A,C</xref>; <xref ref-type="disp-formula" rid="equ5 equ6">Equation 3b,c</xref>, in which <italic>θ</italic><sub><italic>n</italic></sub> predominates over <italic>K</italic><sub><italic>n</italic></sub>), such as when the incoming evidence is strong or during periods of stability in the source, the prior expectation approaches a ‘stabilizing boundary’ whose height directly depends on <italic>H</italic>. Thus, the dynamics of a model that stabilizes the decision process at a hazard-dependent value can, in principle, act like the normative model, but only in the high-certainty regime (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This boundary represents a suspension of the accumulation process but, unlike the decision bound in the SPRT and related models (<xref ref-type="bibr" rid="bib2">Barnard, 1946</xref>; <xref ref-type="bibr" rid="bib66">Wald, 1947</xref>; <xref ref-type="bibr" rid="bib26">Good, 1979</xref>; <xref ref-type="bibr" rid="bib37">Link, 1992</xref>; <xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>), does not terminate the decision process. Instead, it stabilizes <italic>L</italic><sub><italic>n</italic></sub> when no changes occur (i.e., temporarily ending further evidence accumulation) while still allowing for the sampling of new evidence that might lead to changes in belief and a re-start of the accumulation process (<xref ref-type="bibr" rid="bib52">Resulaj et al., 2009</xref>). The stabilizing boundary is also in contrast to the asymptote in leaky accumulation, which increases linearly with the strength of evidence (<xref ref-type="bibr" rid="bib10">Busemeyer and Townsend, 1993</xref>; <xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib62">Tsetsos et al., 2012</xref>).</p><p>Together these properties navigate an inherent trade-off between identification of steady signals and change detection. This trade-off depends on both evidence strength and expected <italic>H</italic> (<xref ref-type="fig" rid="fig2">Figure 2E,G</xref>). For weak evidence, the trade-off is most severe, as the model uses expected <italic>H</italic> to err on the side of either detecting changes quickly when <italic>H</italic> is high or identifying stable signals when <italic>H</italic> is low. As the strength of evidence increases, performance improves steadily for both conditions and the trade-off diminishes.</p><sec id="s2-1-1"><title>Continuous-time version</title><p>We also developed a continuous-time version of the model (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) that allowed for a more direct comparison to drift-diffusion and other continuous-time models of decision-making (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) (<xref ref-type="bibr" rid="bib59">Smith and Ratcliff, 2004</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>). The model is based on the optimal filter for a Markov jump process with two states and stationary white-noise emissions (<xref ref-type="bibr" rid="bib70">Zakai, 1965</xref>; <xref ref-type="bibr" rid="bib38">Liptser and Shiryaev, 1977</xref>; <xref ref-type="bibr" rid="bib13">Crisan and Rozovskii, 2011</xref>). Here we write the incoming evidence as a continuous-time sequence of noisy observations: d<italic>x</italic>(<italic>t</italic>) = <italic>h</italic>(<italic>t</italic>)d(<italic>t</italic>) + <italic>σ</italic>d<italic>W</italic>, where <italic>h</italic>(<italic>t</italic>) = ±<italic>μ</italic>, with the sign depending on which source is generating data at time <italic>t</italic>, and <italic>σ</italic> is the standard deviation of the noise in a standard Wiener process d<italic>W</italic>. The source <italic>h</italic>(<italic>t</italic>) jumps between states at an average rate <italic>λ</italic>, with jumps occurring as a Poisson process. Letting <italic>A</italic> = 2<italic>μ</italic>/<italic>σ</italic><sup>2</sup>:<disp-formula id="equ7"><label>(4)</label><mml:math id="m7"><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The result can be viewed as a nonlinear filter for the incoming evidence that is more general than the perfect or leaky integration central to previous models of decision-making between two alternatives (<xref ref-type="bibr" rid="bib10">Busemeyer and Townsend, 1993</xref>; <xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). In the special case that <italic>λ</italic> = 0, d<italic>L</italic>(<italic>t</italic>) = <italic>A</italic>d<italic>x</italic>(<italic>t</italic>), which is perfect integration of the noisy observations d<italic>x</italic>(<italic>t</italic>). Approximations of this model are similar to those for the discrete-time model (<xref ref-type="fig" rid="fig2">Figure 2B,D</xref>). When beliefs are uncertain (<italic>L</italic> ≈ 0), d<italic>L</italic> ≈ −2<italic>λL</italic>d<italic>t</italic> + <italic>A</italic>d<italic>x</italic>(<italic>t</italic>), which results in an Ornstein-Uhlenbeck process over periods in which the source is perfectly stable (<xref ref-type="bibr" rid="bib10">Busemeyer and Townsend, 1993</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>). As certainty increases (|<italic>L</italic>| &gt; 0), a simultaneous increase in leak rate and bias drives the decision variable to a stabilizing boundary (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) with a probability distribution that has a heavy tail, reflecting dynamics that facilitate the detection of subsequent changes (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). As with the discrete-time model, these dynamics navigate the trade-off between identification of steady signals and change detection in a way that depends on both evidence strength and expected <italic>λ</italic> (<xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p></sec></sec><sec id="s2-2"><title>Psychophysics</title><p>We used two separate tasks to investigate if and how human subjects could use these dynamics to adapt to different rates of change and find the optimal trade-off between stable signal identification and change detection. For both tasks, we found that: (1) subjects adapted, albeit imperfectly, to different hazard rates (via comparisons to a suboptimal model, which ignored block-wise changes in <italic>H</italic>) and used their subjective estimates of hazard rate in a manner consistent with the normative model; and (2) their choice dynamics were better described by the normative model than two other adaptive, but suboptimal, alternatives inspired by the approximations to the normative model (one was an accumulator with a leak that could vary as a free parameter for each hazard-specific block of trials but no stabilizing boundary; the other was a perfect accumulator with a stabilizing boundary that could vary as a free parameter for each hazard-specific block of trials; see <xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><sec id="s2-2-1"><title>‘Triangles’ task</title><p>This task required subjects to make trial-by-trial choices about which of two spatially separated triangles on a computer screen was the source of a single data point presented on that trial, represented as the position of a star on the screen (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>). Subjects could thus make choices based on accumulated evidence after each new sample of data, with the <italic>LLR</italic> for each star corresponding to its position relative to each triangle. The correct source changed at a hazard rate that was constant within a block of trials but varied across blocks (0.05–0.95). In a subset of sessions (65 of 111), learning was facilitated by beginning and ending each block of trials with stretches of trial-by-trial feedback about the correct answer. However, subjects were never instructed on what the hazard rates were or when they would change.<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.007</object-id><label>Figure 4.</label><caption><title>Triangles task and normative model fits.</title><p>(<bold>A</bold>) Example task screen. Triangles and surrounding greenish clouds represent the means and variances of the two generative processes; red star is a single sample (in this case generated by the left process). (<bold>B</bold>) Sample trials, with actual star position indicated by blue circles and subject choices indicated by red ‘x’. Star positions close to the center represent weak evidence for either of the alternatives because the respective probabilities of either source generating the star position are close. Star positions towards the edge of the screen represent strong evidence for the triangle to which the star is closest. (<bold>C</bold>) Block-wise subjective (fit) <italic>H</italic> vs objective <italic>H</italic>. Dotted line is unity; solid line is a least-squares fit. (<bold>D</bold>) Histogram of slope coefficients from least-squares fits as in <bold>C</bold>, calculated for individual subjects.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.007">http://dx.doi.org/10.7554/eLife.08825.007</ext-link></p></caption><graphic xlink:href="elife-08825-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.08825.008</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Two examples of subjects adapting to objective hazard rate across an entire experimental session.</title><p>(<bold>A</bold>, <bold>B</bold>) Star position in arbitrary units plotted as a function of trial number. (<bold>C</bold>, <bold>D</bold>) Fit subjective hazard rate (black line with circles) in 400-trial bins slid forward in 50-bin steps, plotted against the median trial number for that bin. Also plotted are the objective hazard rates, unbinned (gray dashed lines) and binned like for the subjective values (black dashed line with hash marks).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.008">http://dx.doi.org/10.7554/eLife.08825.008</ext-link></p></caption><graphic xlink:href="elife-08825-fig4-figsupp1-v2.tif"/></fig></fig-group></p><p>The subjects were able to adapt their decision-making to these different hazard rates, as assessed by direct fits of their choice data by the normative model. Specifically, models that allowed subjective <italic>H</italic> to freely vary by block provided better fits to the data than a suboptimal model that ignored the block-wise changes in objective <italic>H</italic> (median ± bootstrapped SEM difference of Bayesian Information Criterion, or BIC, from normative vs block-independent <italic>H</italic> fits was −23.721 ± 9.671, Wilcoxon signed-rank test, p &lt; 0.0001; per subject, the normative fits were better in 43 of 48 subjects using a signed-rank test, Bonferroni corrected p &lt; 0.05). Overall, the normative model performed well, with choice residuals centered around zero (mean ± std deviance residual = 0.003 ± 0.458) and a reasonably close match to the choice data (median ± bootstrapped SEM McFadden's <italic>r</italic><sup><italic>2</italic></sup> of 0.895 ± 0.016 across subjects). Moreover, the estimated values of subjective <italic>H</italic> from these fits were strongly correlated with objective <italic>H</italic> across all subjects (Pearson's <italic>r</italic> = 0.721, p &lt; 0.0001; <xref ref-type="fig" rid="fig4">Figure 4C</xref>), with 47 of 48 individual subjects showing a regression slope of subjective on objective <italic>H</italic> that was &gt;0 and in 46 of those cases was also &lt;1 (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, median ± bootstrapped SEM regression slope = 0.402 ± 0.042). However, although the subjects adapted their decision-making behavior appropriately for different values of <italic>H</italic>, their subjective estimates of <italic>H</italic> tended towards <italic>H</italic> ∼ 0.5, for which the history of evidence is irrelevant. This tendency to mis-estimate extreme hazard rates did not appear to reflect insufficient learning opportunities, because these trends persisted even when restricting fits to the last 200 trials of each block (across subjects and blocks, bootstrapped regression slope of subjective on objective <italic>H</italic> = 0.373 ± 0.044; see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) or to blocks beginning with explicit, trial-to-trial feedback (regression slope = 0.562 ± 0.038).</p><p>The subjects appeared to be using these learned, subjective estimates of hazard rate in a manner consistent with the normative model, for several reasons. First, their choice dynamics directly reflected biases predicted by the two regimes of the normative model (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, <xref ref-type="fig" rid="fig5">Figure 5A–F</xref>). When certainty was high (i.e., choices just following a trial in which the star position was far to the left or right), the subjects consistently showed hazard-dependent biases that were predicted by the stabilizing boundary of the model: weak evidence interpreted as stability for low <italic>H</italic> and change for high <italic>H</italic> (Spearman's <italic>r</italic> = 0.890, p &lt; 0.0001, comparing predicted and actual biases from individual blocks; <xref ref-type="fig" rid="fig5">Figure 5A,B</xref>). When weak evidence persisted without change-points for a run of trials following a change-point, choice dynamics consistently reflected the hazard-dependent leak predicted by the model (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, <xref ref-type="fig" rid="fig5">Figure 5D,E</xref>): gradual updates for low subjective <italic>H</italic>, immediate updates for subjective <italic>H</italic> ≈ 0.5, and damped oscillations for high subjective <italic>H</italic> (including lower accuracy on two vs one trial following the change-point). Fits to the block-independent model did not show these <italic>H</italic>-dependent choice dynamics, confirming that the choice dynamics did not result from any differences in how the randomly generated stars were sampled under the different conditions used for these analyses (<xref ref-type="fig" rid="fig5">Figure 5C,F</xref>).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.009</object-id><label>Figure 5.</label><caption><title>Triangles task choice data pooled across all 48 subjects (top row), plus predictions from fits to the normative model allowing a different subjective hazard rate to be assigned to each block (middle row) and from fits to a model with subjective hazard rates randomly assigned across trials (bottom row).</title><p>Colors are different ranges of objective <italic>H</italic>, as shown in panel <bold>D</bold>. Errorbars are bootstrapped sem. (<bold>A</bold>–<bold>C</bold>) Probability of switching choices as a function of the <italic>LLR</italic> for a change in the correct answer. Data were restricted to trials following strong evidence (|<italic>LLR</italic>| &gt; 4) to directly investigate the ‘strong belief’ regime of the model predictions. (<bold>D</bold>–<bold>F</bold>) Probability of switching sides in which a strong <italic>LLR</italic> (|<italic>LLR</italic>| &gt; 4) for the original side was followed by a change-point and weak (|<italic>LLR</italic>| &lt; 2) evidence for the opposite side. Significant differences by <italic>H</italic> in subject data are indicated by asterisks (Bonferroni corrected p &lt; 0.05, χ<sup>2</sup> test). (<bold>G</bold>–<bold>L</bold>) Block-by-block choice accuracy on change-point vs non-change-point trials when the evidence (magnitude of <italic>LLR</italic>, as indicated) was relatively weak (<bold>G</bold>–<bold>I</bold>) or strong (<bold>J</bold>–<bold>L</bold>). Points are individual blocks that included ≥5 trials with the indicated conditions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.009">http://dx.doi.org/10.7554/eLife.08825.009</ext-link></p></caption><graphic xlink:href="elife-08825-fig5-v2.tif"/></fig></p><p>Second, the subjects' decision processes reflected a strong, hazard- and evidence-strength-dependent trade-off between detecting changes and identifying steady signals, as predicted by the normative model (<xref ref-type="fig" rid="fig5">Figure 5G–L</xref>). When the evidence was weak (star positions close to the midline), accuracy following a change-point was highest for high <italic>H</italic> (mean ± bootstrapped SEM across blocks = 73.7 ± 2.4% correct) then declined steadily for intermediate (66.4 ± 1.2%) and low <italic>H</italic> (50.0 ± 7.3%; Spearman's correlation between change-point accuracy and <italic>H</italic> was 0.559, p &lt; 0.0001, vs a predicted correlation from the normative model of 0.651). In contrast, accuracy on non change-point trials with the same strength of evidence was lowest for high <italic>H</italic> (57.1 ± 4.1%) then improved steadily for intermediate (71.4 ± 1.2%) and low <italic>H</italic> (81.1 ± 2.2%; Spearman's correlation between non change-point accuracy and <italic>H</italic> was −0.502, p &lt; 0.0001, vs a normative prediction of −0.625; <xref ref-type="fig" rid="fig5">Figure 5G,H</xref>). When the evidence was strong, the trade-off was much smaller, as predicted by the normative model (Spearman's correlation between change-point accuracy and <italic>H</italic> was −0.040, p = 0.557 and between non change-point accuracy and <italic>H</italic> was −0.005, p = 0.945; normative predictions were 0.027 and 0.010, respectively; <xref ref-type="fig" rid="fig5">Figure 5J,K</xref>). Fits to the block-independent model did not show these <italic>H</italic>-dependent trade-offs, for either weak or strong evidence (<xref ref-type="fig" rid="fig5">Figure 5I,L</xref>).</p><p>Third, we used choice data to directly estimate the mapping of subjective beliefs to priors (<italic>L</italic><sub><italic>n − 1</italic></sub> to <italic>Ψ</italic><sub><italic>n</italic></sub>, <xref ref-type="fig" rid="fig6">Figure 6</xref>; compare to <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Like for the normative model, the estimated mappings depended on subjective <italic>H</italic> (one-way MANOVA for the groups shown in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, p &lt; 0.0001). Moreover, for each <italic>H</italic>-group, these mappings matched predictions of the normative model (<xref ref-type="fig" rid="fig6">Figure 6B,E</xref>; Hotelling's <italic>t</italic>-test comparing data and model, p = 0.189, 0.321, and 0.086 for low, medium, and high values of objective <italic>H</italic>, respectively).<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.010</object-id><label>Figure 6.</label><caption><title>Belief dynamics estimated directly from the data and compared to predictions from the normative model and two suboptimal approximations (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</title><p>(<bold>A</bold>–<bold>D</bold>) Estimates of the log prior-odds on a given trial as a function of belief on the previous trial (compare to <xref ref-type="fig" rid="fig1">Figure 1B</xref>) computed for each experimental block, grouped by objective <italic>H</italic>, as indicated in the legend below panel <bold>A</bold>. Solid lines are across-block means, and dashed lines are sem. (<bold>A</bold>) Data. (<bold>B</bold>) Fit normative model. (<bold>C</bold>) Fit hazard-dependent leaky accumulator. (<bold>D</bold>) Fit model with perfect accumulation to a hazard-dependent stabilizing boundary. Asterisks in panels <bold>C</bold> and <bold>D</bold> indicate hazard-rate regimes in which estimates from the corresponding model prediction differed significantly from data estimates using Hotelling's <italic>t</italic>-test with a Bonferroni corrected p &lt; 0.05. (<bold>E</bold>–<bold>G</bold>) Hazard-specific differences between the data estimates and model predictions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.010">http://dx.doi.org/10.7554/eLife.08825.010</ext-link></p></caption><graphic xlink:href="elife-08825-fig6-v2.tif"/></fig></p><p>In contrast, the choice data from the triangles task were not as well matched by either of the two adaptive, suboptimal models we considered (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig6">6</xref>). The leaky-accumulator model had worse overall fits to the choice data than the normative model for 34 of 48 subjects (median ± SEM difference in BIC = −5.179 ± 1.967, Wilcoxon signed-rank test, p &lt; 0.0001) and predicted mappings of subjective beliefs to priors that matched the pooled data only for medium and high values of <italic>H</italic> but not for low values of <italic>H</italic>, which lacked the asymptotic regime prescribed by the normative model when beliefs were more certain (<xref ref-type="fig" rid="fig6">Figure 6C,F</xref>; Hotelling's t-test, p &lt; 0.0001 for low objective <italic>H</italic>, and p = 0.312 and 0.545 for medium and high objective <italic>H</italic>, respectively). Likewise, the model with perfect accumulation to a hazard-specific stabilizing boundary had worse overall fits to the choice data than the normative model for 34 of 48 subjects (−0.942 ± 0.487, p = 0.007), reflecting the lack of a leaky-accumulation regime prescribed by the normative model when beliefs were uncertain and <italic>H</italic> was high (<xref ref-type="fig" rid="fig6">Figure 6D,G</xref>; Hotelling's t-test, p = 0.228, 0.463, and 0.017, respectively). This relatively modest, but reliable, difference in BIC reflected an inherent difficulty in distinguishing these models with the particular task conditions we used (fitting simulated data from either model yielded similarly small BIC differences: −1.448 ± 0.900 for simulations based on the normative fits and 1.393 ± 1.054 for simulations using the stabilizing-boundary fits). Both suboptimal models had best-fitting, subjective hazard rates that, even more than for the normative fits, tended to overestimate small objective values and underestimate large objective values, further supporting the idea that the subjects were using mis-estimated hazard rates to make their decisions (regression slope of subjective vs objective <italic>H</italic> = 0.115 ± 0.023 for the leaky accumulator and 0.290 ± 0.044 for the perfect accumulator to a stabilizing boundary, p &lt; 0.0001 when compared to slopes from the normative fits in both cases).</p></sec><sec id="s2-2-2"><title>Dots-reversal task</title><p>This task was a novel version of a commonly used random-dot motion task (<xref ref-type="bibr" rid="bib7">Britten et al., 1992</xref>). For this ‘dots-reversal’ task, the direction of coherent motion underwent sudden changes within trials. Each subject participated in two separate sessions, one in which changes occurred at a relatively slow rate (0.1 Hz), and one in which changes occurred at a fast rate (2.0 Hz) rate (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="other" rid="media1 media2 media3 media4">Videos 1–4</xref>). Motion strength (coherence) was fixed to either a high or low value within each trial, and subjects were instructed to pay attention to the stimulus throughout the trial and then indicate its final direction, after which they received feedback on the correct answer.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.011</object-id><label>Figure 7.</label><caption><title>Dots-reversal task and normative model fits.</title><p>(<bold>A</bold>) Representation of a reversing-dots stimulus for a single trial. The subject was instructed to indicate the final, perceived direction of motion. (<bold>B</bold>) Subjective hazard rate, estimated from direct fits of choice data by the normative model with hazard rate as a free parameter, plotted as a function of objective hazard rate. Each pair of connected points represents data from an individual subject.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.011">http://dx.doi.org/10.7554/eLife.08825.011</ext-link></p></caption><graphic xlink:href="elife-08825-fig7-v2.tif"/></fig><media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="mov" mimetype="video" xlink:href="elife-08825-media1.mov"><object-id pub-id-type="doi">10.7554/eLife.08825.012</object-id><label>Video 1.</label><caption><title>Example random dot motion stimulus with 0.1 Hz changes, at 80% (‘high’) coherence.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.012">http://dx.doi.org/10.7554/eLife.08825.012</ext-link></p></caption></media><media content-type="glencoe play-in-place height-250 width-310" id="media2" mime-subtype="mov" mimetype="video" xlink:href="elife-08825-media2.mov"><object-id pub-id-type="doi">10.7554/eLife.08825.013</object-id><label>Video 2.</label><caption><title>Example random dot motion stimulus with 0.1 Hz changes, at 20% (‘low’) coherence.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.013">http://dx.doi.org/10.7554/eLife.08825.013</ext-link></p></caption></media><media content-type="glencoe play-in-place height-250 width-310" id="media3" mime-subtype="mov" mimetype="video" xlink:href="elife-08825-media3.mov"><object-id pub-id-type="doi">10.7554/eLife.08825.014</object-id><label>Video 3.</label><caption><title>Example random dot motion stimulus with 2 Hz changes, at 80% (‘high’) coherence.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.014">http://dx.doi.org/10.7554/eLife.08825.014</ext-link></p></caption></media><media content-type="glencoe play-in-place height-250 width-310" id="media4" mime-subtype="mov" mimetype="video" xlink:href="elife-08825-media4.mov"><object-id pub-id-type="doi">10.7554/eLife.08825.015</object-id><label>Video 4.</label><caption><title>Example random dot motion stimulus with 2 Hz changes, at 20% (‘low’) coherence.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.015">http://dx.doi.org/10.7554/eLife.08825.015</ext-link></p></caption></media></p><p>As with the triangles task, the subjects were able to adapt their decision-making to these different hazard rates. Models that allowed subjective <italic>λ</italic> (change-point rate, here treated as a continuous-time variable) to vary with objective <italic>λ</italic> provided better fits to the data than a model that ignored the session-specific changes in <italic>λ</italic> (median ± SEM difference in BIC from the normative vs block-independent model fits was −4.790 ± 1.216, p &lt; 0.0005; per subject, normative BIC values were significantly lower in 9 of 13 subjects with a Bonferroni corrected p &lt; 0.05, Wilcoxon signed-rank test). The normative model performed well overall, with choice residuals centered around zero (mean ± std deviance residual = 0.053 ± 0.897) and a reasonably close match to the choice data (median ± bootstrapped SEM McFadden <italic>r</italic><sup><italic>2</italic></sup> of 0.385 ± 0.055 across subjects). Of the 13 subjects, 12 had best-fitting values of adaptive, subjective <italic>λ</italic> that showed appropriate sensitivity to objective <italic>λ</italic>, with estimated subjective <italic>λ</italic> lower on 0.1 vs 2.0 Hz trials (<xref ref-type="fig" rid="fig7">Figure 7B</xref>; Wilcoxon signed-rank p &lt; 0.05). However, like for the triangles task, the subjects tended to overestimate low values and underestimate high values of <italic>λ</italic> (median ± bootstrapped SEM estimated subjective <italic>λ</italic> = 0.365 ± 0.109 and 1.129 ± 0.168 Hz for the 0.1-Hz and 2-Hz conditions respectively), with a similar tendency even when restricting model fits to the last 50 trials of each session to account for learning (subjective <italic>λ</italic> = 0.291 ± 0.122 and 0.968 ± 0.207 Hz for the 0.1-Hz and 2-Hz conditions, respectively).</p><p>Also consistent with our results from the triangles task, the subjects appeared to be using their adaptive estimates of <italic>λ</italic> in a manner consistent with the normative model, based on several lines of evidence. First, the choice data exhibited dynamics predicted by the normative model (<xref ref-type="fig" rid="fig8">Figure 8</xref>). For high-coherence trials, the strong sensory evidence dominated the decision process, yielding &gt;90% accuracy within 500 ms following the final change in direction irrespective of the rate of preceding direction changes (<xref ref-type="fig" rid="fig8">Figure 8D,E</xref>). In contrast, for low-coherence trials, integration times were strongly dependent on hazard rate (i.e., greater effects of <italic>ψ</italic> in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) Specifically, accuracy improved more steeply as a function of viewing duration for the low- vs high-hazard condition: performance was worse for the 0.1-Hz condition for durations &lt;500 ms, reflecting persistence of the perceived direction of motion just prior to the final change-point (i.e., direction reversal), but rose as viewing duration increased and exceeded performance for the 2-Hz condition at long durations (<xref ref-type="fig" rid="fig8">Figure 8A,B</xref>). These dynamics, particularly at low coherences, were not predicted by the block-independent model and thus did not reflect uneven sampling of the data under the different coherence and hazard conditions (<xref ref-type="fig" rid="fig8">Figure 8C,F</xref>).<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.016</object-id><label>Figure 8.</label><caption><title>Dots-reversal task choice dynamics comparing the pooled data from 13 subjects (top row) with predictions from fits to the normative model (middle row) and to the normative model with the subjective hazard rates shuffled across trials and blocks for each subject and session (bottom row).</title><p>(<bold>A</bold>–<bold>F</bold>) accuracy (±bootstrapped sem) as a function of viewing time following the final direction change within a trial for low- (<bold>A</bold>–<bold>C</bold>) and high- (<bold>D</bold>–<bold>F</bold>) coherence stimuli for the two hazard-rate conditions (indicated in panel <bold>A</bold>). Asterisks in panels <bold>A</bold> and <bold>D</bold> indicate a significant difference between the two hazard-rate conditions (bootstrapped t-test, Bonferroni corrected p &lt; 0.05). (<bold>G</bold>–<bold>L</bold>) Dots-reversal task trade-off between accuracy on trials in which the final viewing duration was &lt;300 ms vs &gt;300 ms for different hazard rates (indicated in panel <bold>J</bold>), when the motion coherence was low (<bold>G</bold>–<bold>I</bold>) or high (<bold>J</bold>–<bold>L</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.016">http://dx.doi.org/10.7554/eLife.08825.016</ext-link></p></caption><graphic xlink:href="elife-08825-fig8-v2.tif"/></fig></p><p>Second, as with the triangles task, this decision process reflected a strong hazard- and evidence-strength-dependent trade-off between detecting changes and identifying steady signals, as predicted by the normative model (<xref ref-type="fig" rid="fig8">Figure 8G–K</xref>). For low-coherence trials, choice accuracy was lower for the low-hazard condition just following a change-point (median ± bootstrapped SEM 7.1 ± 11.1% and 40.3 ± 2.8%, for low- and high-hazard sessions respectively, when the stimulus was shown for &lt;300 ms following the final change-point, Wilcoxon signed rank, p &lt; 0.01, vs predicted accuracies of 34.6 ± 4.7% and 44.9 ± 3.1%, respectively) but was greater for the low-hazard condition thereafter (83.6 ± 3.6% and 69.9 ± 8.3%, respectively, p &lt; 0.0005, vs predicted 86.2 ± 2.3% and 74.2 ± 2.9%, respectively). For high-coherence trials, choice accuracy was much higher overall and, consistent with the normative model, showed a weaker trade-off, with no difference by hazard-rate condition for short viewing durations following the final change point (66.7 ± 14.6% and 66.1 ± 7.3% for 0.1-Hz and 2-Hz sessions respectively, p = 0.831, vs predicted 46.9 ± 9.4% and 59.7 ± 3.7%, respectively) and only a slight difference for longer post-change durations (100 ± 0% and 93.5 ± 1.4%, respectively, p = 0.004, vs predicted 97.8 ± 0.4% and 92.1 ± 2.0%, respectively). In contrast, the block-independent model did not predict these hazard-dependent trade-offs (<xref ref-type="fig" rid="fig8">Figure 8I,L</xref>).</p><p>Third, we directly measured the dependence of choice dynamics on both the hazard rate and the strength of the sensory evidence by fitting choice data to integrating models with separate leaks for each hazard-specific session and coherence level (<xref ref-type="fig" rid="fig9">Figure 9</xref>). As predicted by the normative model (<xref ref-type="fig" rid="fig3 fig8">Figures 3A, 8B,E</xref>), the best-fitting leak depended on both (Friedman test, p &lt; 0.0005 for the effect of hazard rate and p &lt; 0.0001 for the effect of motion coherence; <xref ref-type="fig" rid="fig9">Figure 9A</xref>). The per-subject, pairwise differences between best-fitting leak, computed with respect to either coherence or hazard rate, did not differ from predictions of the normative model (median ± bootstrapped SEM normalized data–model difference by hazard rate = −0.003 ± 0.021, by coherence = −0.001 ± 0.050, Wilcoxon signed rank p = 0.501 and 0.292, respectively).<fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.08825.017</object-id><label>Figure 9.</label><caption><title>Comparison of predictions from normative model vs from the suboptimal approximations (<xref ref-type="fig" rid="fig3">Figure 3</xref>) for the dots-reversal task.</title><p>(<bold>A</bold>–<bold>D</bold>) Parameter fits from a leaky-accumulator model with separate leak–rate parameters per hazard rate (as indicated in panel <bold>B</bold>) and coherence (yielding four leaks per subject). (<bold>A</bold>) Leaks fit to choice data. (<bold>B</bold>) Leaks fit to predicted choices from the normative model using best-fitting parameters from subject data. (<bold>C</bold>) Leaks fit to predicted choices from the leaky-accumulator model using leaks that depended on the session-specific hazard rate but not coherence. (<bold>D</bold>) Leaks fit to predicted choices from the bounded-accumulator model using boundaries that depended on the session-specific hazard rate but not coherence. (<bold>E</bold>–<bold>G</bold>) Difference in the best-fitting leak to the two coherences predicted by each of the models above plotted against the difference in leaks from the direct fits to the choice data, separated by hazard rate (see panel <bold>B</bold>). Differences are normalized by sum of leaks from each of the coherences. In <bold>A</bold>–<bold>G</bold>, each point represents a single subject and hazard-rate condition. (<bold>H</bold>–<bold>K</bold>) Predicted accuracy (±bootstrapped sem) as a function of viewing time following the final direction change within a trial for low- (<bold>H</bold>, <bold>J</bold>) and high- (<bold>I</bold>, <bold>K</bold>) coherence stimuli for the two hazard-rate conditions (indicated in panel <bold>I</bold>), calculated as in <xref ref-type="fig" rid="fig8">Figure 8</xref> but for predictions by fits to the leaky- (<bold>H</bold>, <bold>I</bold>) and bounded- (<bold>J</bold>, <bold>K</bold>) accumulator models.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.08825.017">http://dx.doi.org/10.7554/eLife.08825.017</ext-link></p></caption><graphic xlink:href="elife-08825-fig9-v2.tif"/></fig></p><p>In contrast, the choice data from the dots-reversal task were not as well matched by either of the two adaptive, suboptimal models we considered (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The leaky-integrator model, in which the leak depended on hazard rate but not coherence level, had worse overall fits to the choice data than the normative model for 10 of 13 subjects (median ± bootstrapped SEM difference in BIC = −4.066 ± 3.078, Wilcoxon signed rank, p &lt; 0.05), failing in particular to capture the strongly coherence-dependent leak of the data and the normative model (<xref ref-type="fig" rid="fig9">Figure 9C,F,H,I</xref>; normalized data–model median ± bootstrapped SEM difference between change in leak by coherence = 0.241 ± 0.067, Wilcoxon signed rank p &lt; 0.0005). The normative model also outperformed the model with perfect integration to a stabilizing boundary that freely varied by objective hazard rate (BIC was lower for 9 of 13 subjects, −4.305 ± 2.662, p &lt; 0.05). This suboptimal model had a more subtle deviation from the data, consisting primarily of an exaggerated dependence of leak on coherence (<xref ref-type="fig" rid="fig9">Figure 9D,G,J,K</xref>; per-subject, normalized data–model difference between change in leak by coherence = −0.189 ± 0.059, Wilcoxon signed rank p &lt; 0.0001). Like for the normative fits, both suboptimal models also had best-fitting subjective hazard rates that were imperfectly adapted to the objective values, further supporting the idea that the subjects were using imperfect estimates to make their decisions (best-fitting <italic>λ</italic> = 0.789 ± 0.084 and 1.697 ± 0.227 Hz for the 0.1-Hz and 2-Hz conditions, respectively, for the leaky integrator and 4.378 ± 0.998 and 8.803 ± 1.159 Hz, respectively, for the perfect integrator to a stabilizing boundary).</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We derived a normative model of evidence accumulation for decision tasks that is based on Bayesian principles for inferring changes in the statistics of a generative process (<xref ref-type="bibr" rid="bib50">Rabiner, 1989</xref>; <xref ref-type="bibr" rid="bib1">Adams and MacKay, 2007</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib20">Fearnhead and Liu, 2007</xref>; <xref ref-type="bibr" rid="bib8">Brown and Steyvers, 2009</xref>; <xref ref-type="bibr" rid="bib67a">Wilson and Finkel, 2009</xref>; <xref ref-type="bibr" rid="bib46">Nassar et al., 2010</xref>, <xref ref-type="bibr" rid="bib45">2012</xref>; <xref ref-type="bibr" rid="bib68">Wilson et al., 2010</xref>; <xref ref-type="bibr" rid="bib4a">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib68a">Wilson et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Gonzalez Castro et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Sato and Kording, 2014</xref>). Our model incorporates change detection into sequential-sampling decision models and is related to other, modified versions of these models that have been used to combine multiple sensory cues of different but known reliabilities or infer unknown sensory reliability assumed to be stable during the course of decision-making (<xref ref-type="bibr" rid="bib29">Hanks et al., 2011</xref>; <xref ref-type="bibr" rid="bib14">Deneve, 2012</xref>; <xref ref-type="bibr" rid="bib17">Drugowitsch et al., 2014</xref>). However, unlike those models, which invoked a separate learning-rate term or had other, more complex forms, our model casts adaptation directly in the context of the evidence-accumulation process that is a key focus of studies of decision-making (<xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib53">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib31">Huk and Shadlen, 2005</xref>; <xref ref-type="bibr" rid="bib63">Uchida et al., 2006</xref>; <xref ref-type="bibr" rid="bib9">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Hanks et al., 2015</xref>). This formulation allowed us to identify, for the first time, features of evidence accumulation that can underlie normative, adaptive decision-making, including expectation-dependent changes in leaky accumulation when beliefs are weak and saturating accumulation when beliefs are stronger. We showed that human subjects made decisions on two separate tasks, requiring evidence accumulation either across or within trials, that were consistent with the adaptive, hazard-dependent accumulation process prescribed by the model.</p><p>Our findings substantially extend previous studies that similarly suggested that human decision-making behavior can reflect adaptations to the rate of environmental changes (<xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib8">Brown and Steyvers, 2009</xref>; <xref ref-type="bibr" rid="bib25">Gonzalez Castro et al., 2014</xref>). Specifically, we showed that subjects could both learn a range of hazard rates and then use those learned rates in a normative manner to interpret sequences of evidence to make decisions. However, they tended to learn imperfectly, over-estimating low hazard rates and under-estimating high hazard rates. Thus, although their use of these imperfectly learned hazard rates was consistent with the normative model, their overall decisions in some cases fell short of the ideal observer. Our framework provides a new way to interpret these deviations from optimality: not simply as poor performance, but rather as different, hazard-dependent set-points of an inherent trade-off. This tradeoff balances sensitivity to change during periods of expected instability, and sensitivity to steady-state signals during periods of expected stability. These different set points may have reflected certain prior expectations about the improbability of either perfect stability or excessive instability that could constrain performance when those conditions occur.</p><p>Such prior expectations about a lack of perfect environmental stability interpreted in the context of our framework might also provide new insights into previous studies of the temporal dynamics of evidence accumulation. In some cases, decisions about perfectly stable stimuli appear to involve perfect accumulation, as described by drift-diffusion and related models (<xref ref-type="bibr" rid="bib21">Gold and Shadlen, 2000</xref>; <xref ref-type="bibr" rid="bib53">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib9">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Hanks et al., 2015</xref>). Under those conditions, deviations from perfect accumulation in the brain may be considered as inefficient, operating under other constraints (e.g., computational costs), or of uncertain relevance to decision-making (<xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib18">Drugowitsch et al., 2012</xref>). In contrast, our results imply that at least some deviations from perfect accumulation might reflect normative adjustments to expected instabilities, even under the nominally stable conditions used for many tasks. For example, leaky accumulation that places more emphasis on recent vs past information or rates of accumulation that vary as a function of time, which can account for the temporal dynamics of certain decisions about stimuli that are presented with stable statistics for 100's of ms or more, might reflect prior expectations that instabilities are likely to occur within that time frame (<xref ref-type="bibr" rid="bib64">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib19">Eckhoff et al., 2008</xref>). Likewise, reports of an ‘urgency’ signal that limits temporal integration based on a drive to respond quickly might reflect similar expectations of impending instabilities (<xref ref-type="bibr" rid="bib51">Reddi and Carpenter, 2000</xref>; <xref ref-type="bibr" rid="bib16">Ditterich, 2006</xref>; <xref ref-type="bibr" rid="bib11">Cisek et al., 2009</xref>; <xref ref-type="bibr" rid="bib18">Drugowitsch et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Thura et al., 2012</xref>). More extreme expectations of instabilities might relate to other tasks that appear not to require temporal integration at all and instead show little dependence of performance on stimulus duration beyond what is needed to activate the sensory detectors (<xref ref-type="bibr" rid="bib40">Ludwig et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Uchida et al., 2006</xref>). These interpretations are consistent with the idea that the temporal integration window for many kinds of decisions might be highly flexible and adapt to the temporal dynamics of the environment (<xref ref-type="bibr" rid="bib48">Ossmy et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Gonzalez Castro et al., 2014</xref>). Insofar as the accumulated evidence that serves as the decision variable governing choice behavior can also be thought of as a confidence signal, such adaptive dynamics might also pertain to confidence judgments associated with certain decision tasks (<xref ref-type="bibr" rid="bib32">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib33">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="bib41">Ma and Jazayeri, 2014</xref>). Further work is needed to understand if and how these findings can be understood in the context of a common set of normative principles that balance the identification of steady signals with change detection.</p><p>Our results might also have implications for understanding the trade-off between speed and accuracy inherent to many tasks (<xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib6">Bogacz et al., 2010</xref>). Sequential-sampling models like drift-diffusion typically account for this trade-off in terms of an absorbing decision boundary. This boundary can be set to a pre-defined value to terminate the decision process while emphasizing either speed or accuracy at the expense of the other, or possibly balancing the two in the service of maximizing related quantities like reward rate (<xref ref-type="bibr" rid="bib23">Gold and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib49">Palmer et al., 2005</xref>; <xref ref-type="bibr" rid="bib5">Bogacz et al., 2006</xref>, <xref ref-type="bibr" rid="bib6">2010</xref>; <xref ref-type="bibr" rid="bib56">Simen et al., 2009</xref>). Alternatively, in our model the adaptive accumulation process can be suspended, at least temporarily, not by an extrinsically imposed decision rule like an absorbing decision boundary but rather by the non-linear dynamics of the accumulation process itself. In principle, certain decisions might be made by committing to an alternative once this asymptotic regime is reached. This regime represents an upper limit on the expected level of confidence and thus precludes the need for either additional data for that alternative or for an additional boundary. In this case, the resulting speed-accuracy trade-off would not necessarily reflect a pre-defined attempt to control those factors explicitly but rather expectations about the rate at which the evidence-generating process is changing.</p><p>Future work is needed to investigate how key features of our model might be implemented in the nervous system for different tasks and different timescales. Previous studies using tasks that required information accumulation on the timescale of the triangles task (e.g., over many seconds to minutes) have similarly suggested that humans can approximate optimal change detection, which in some cases includes a sensitivity to different hazard rates (<xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib8">Brown and Steyvers, 2009</xref>; <xref ref-type="bibr" rid="bib46">Nassar et al., 2010</xref>). The neural mechanisms of these abilities are not yet known, but fMRI and pupillometry data suggest possible roles for the arousal system including the anterior cingulate cortex and the noradrenergic system, and genotype data imply possible contributions of the dopamine system (<xref ref-type="bibr" rid="bib69">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib45">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib35">Krugel et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">O'Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib43">McGuire et al., 2014</xref>). Conversely, evidence-accumulation processes that operate over shorter timescales, like for various versions of the random-dot motion task, have focused on dynamic neural signals in other parts of cortex, the basal ganglia, and the superior colliculus that can reflect the rapid build-up of evidence to select a particular motor response (in these cases involving eye movements) (<xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib15">Ding and Gold, 2013</xref>). There are some suggestions that these systems may interact under certain conditions (<xref ref-type="bibr" rid="bib47">O'Reilly et al., 2013</xref>), but much more work is needed to understand the brain mechanisms responsible for the kinds of normative, scale-invariant dynamics of evidence accumulation we characterized in this study. Extending our framework to more than two alternatives and to conditions in which the statistics of the evidence changes gradually, as opposed to abruptly, would also be an important step towards better understanding how the brain accumulates and interprets dynamic evidence to solve complex, real-world problems.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Discrete-time model</title><p>The normative model is based on the posterior probability each of option (<italic>z</italic><sub><italic>1</italic></sub> or <italic>z</italic><sub><italic>2</italic></sub>) given all of the evidence collected so far (<italic>x</italic><sub><italic>1:n</italic></sub>), <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We assume that at each time step, there is a probability (<italic>H</italic>, for ‘hazard rate’) that there will be a switch in the correct option. Beginning with Bayes' Rule, and using the sum and product rules of probability, it can be shown that:<disp-formula id="equ8"><label>(5)</label><mml:math id="m8"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>p</italic>(<italic>x</italic><sub><italic>n</italic></sub>|<italic>z</italic><sub><italic>i</italic></sub>) is the likelihood of observing the evidence from source <italic>i</italic>. This relationship is the forward recursion for the Baum-Welch algorithm in Hidden Markov Models and has been proven elsewhere (<xref ref-type="bibr" rid="bib4">Bishop, 2006</xref>). We derived the model (<xref ref-type="disp-formula" rid="equ1 equ2">Equations 1, 2</xref>) by taking the logarithm of the ratio of the two equations; that is, defining <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and expanding the logarithm, giving:<disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the first term of the RHS is the <italic>LLR</italic> in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> by definition. The second term of the RHS can be manipulated to yield <italic>ψ</italic> (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>) first by dividing both the numerator and denominator by <italic>Hq</italic>(<italic>z</italic><sub>2,<italic>n</italic> − 1</sub>), then expanding the expression while using <inline-formula><mml:math id="inf3"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by definition, giving <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Factoring out exp(<italic>L</italic><sub><italic>n</italic> − 1</sub>) from the first term of the RHS yields <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>.</p><p>The special cases of <italic>H</italic> = 0 and <italic>H</italic> = 0.5 are most straightforward to see from <xref ref-type="disp-formula" rid="equ8">Equation 5</xref>. When <italic>H</italic> = 0:<disp-formula id="equ10"><mml:math id="m10"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which is perfect integration of the log likelihood ratios. When <italic>H</italic> = 0.5:<disp-formula id="equ12"><mml:math id="m12"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2"><title>Continuous-time model</title><p>Akin to the discrete-time model, the continuous-time version is based on the posterior probabilities of each option given all evidence collected until a given time point <italic>t</italic>. It has been shown previously that the non-normalized posterior probabilities of each of two states in a Markov jump process d<italic>x</italic>(<italic>t</italic>), with average values ±<italic>μ</italic> and noise magnitude <italic>σ</italic>, can be written as a system of stochastic differential equations (<xref ref-type="bibr" rid="bib70">Zakai, 1965</xref>; <xref ref-type="bibr" rid="bib38">Liptser and Shiryaev, 1977</xref>):<disp-formula id="equ14"><label>(6)</label><mml:math id="m14"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>d</mml:mtext><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>d</mml:mtext><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>We used this result to write the log-odds ratio signal as <italic>L</italic>(<italic>t</italic>), seeking the derivative <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>d</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mi>d</mml:mi><mml:mo>⁡</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, by beginning with <xref ref-type="disp-formula" rid="equ14">Equation 6</xref>, separating out the deterministic and stochastic components of the incoming evidence, and rewriting <xref ref-type="disp-formula" rid="equ14">Equation 6</xref> in vector form:<disp-formula id="equ15"><label>(7)</label><mml:math id="m15"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>d</mml:mtext><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">L</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>W</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="bold">L</mml:mi><mml:mo>≡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>λ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>λ</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mo>≡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>.</disp-formula></p><p>Applying Itō's Lemma:<disp-formula id="equ16"><label>(8)</label><mml:math id="m16"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>d</mml:mtext><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>d</mml:mtext><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">L</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>Tr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>...</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>W</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>We now expand each component of <xref ref-type="disp-formula" rid="equ16">Equation 8</xref>, beginning with those in the deterministic expression:<disp-formula id="equ17"><label>(9)</label><mml:math id="m17"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">L</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mi>λ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>λ</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mi>λ</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>...</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mi>λ</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>and<disp-formula id="equ18"><label>(10)</label><mml:math id="m18"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>Tr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mo>∇</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Turning to the stochastic component:<disp-formula id="equ19"><label>(11)</label><mml:math id="m19"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Substituting <xref ref-type="disp-formula" rid="equ17">Equations 9</xref>–<xref ref-type="disp-formula" rid="equ19">11</xref> into <xref ref-type="disp-formula" rid="equ16">Equation 8</xref> yields:<disp-formula id="equ20"><label>(12)</label><mml:math id="m20"><mml:mrow><mml:mi>d</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>−</mml:mi><mml:mi>λ</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>−</mml:mi><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mi>μ</mml:mi><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mi>μ</mml:mi><mml:mi>σ</mml:mi></mml:mfrac><mml:mtext>d</mml:mtext><mml:mi>W</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Letting <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>μ</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, and using the hyperbolic sine function, we have <inline-formula><mml:math id="inf6"><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mi>sinh</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>σ</mml:mi><mml:mtext>d</mml:mtext><mml:mi>W</mml:mi></mml:mrow></mml:math></inline-formula>, which can be rewritten as <xref ref-type="disp-formula" rid="equ7">Equation 4</xref> using <inline-formula><mml:math id="inf7"><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:mtext>d</mml:mtext><mml:mi>W</mml:mi></mml:mrow></mml:math></inline-formula>. Simulations in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> show examples of time-evolution of the belief variable by approximating <xref ref-type="disp-formula" rid="equ7">Equation 4</xref> with the Euler-Maruyama method.</p></sec><sec id="s4-3"><title>First-order approximations</title><p>We made first-order Taylor approximations of the deterministic terms in each model (<xref ref-type="fig" rid="fig2">Figure 2A–D</xref>, <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>).</p><sec id="s4-3-1"><title>Discrete-time model</title><p>For the discrete-time model, we based the approximations on the log prior odds in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>: <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>L</italic><sub><italic>n − 1</italic></sub><italic>′</italic> is the value of the previous belief around which the approximation was made, and<disp-formula id="equ21"><mml:math id="m21"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Writing this equation with leak rate <italic>K</italic> and bias <italic>θ</italic> as in <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>K</mml:mi><mml:mo>≡</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>≡</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>When previous beliefs are weak; that is, <italic>L′</italic> = 0,<disp-formula id="equ22"><mml:math id="m22"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>H</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and<disp-formula id="equ23"><mml:math id="m23"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Expressing the approximation in terms of <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, leak rate <italic>K</italic> = 2<italic>H</italic> and bias <italic>θ</italic> = 0, as in <xref ref-type="disp-formula" rid="equ4">Equation 3a</xref>.</p><p>When previous beliefs are strongly in favor of the first alternative; that is, <italic>L</italic><sub><italic>n − 1</italic></sub> → ∞,<disp-formula id="equ24"><mml:math id="m24"><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>lim</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>so the leak rate <italic>K</italic> = 1, and the bias is determined entirely by the value of the log-prior odds evaluated as:<disp-formula id="equ25"><mml:math id="m25"><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>lim</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>as in <xref ref-type="disp-formula" rid="equ5">Equation 3b</xref>.</p><p>Similarly, when previous beliefs are strongly in favor of the second alternative; i.e., <italic>L</italic><sub><italic>n − 1</italic></sub> → −∞,<disp-formula id="equ26"><mml:math id="m26"><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>lim</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>so the leak rate <italic>K</italic> = 1 here as well, and the bias is determined entirely by the value of the log-prior odds evaluated as:<disp-formula id="equ27"><mml:math id="m27"><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mrow><mml:mi>lim</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>as in <xref ref-type="disp-formula" rid="equ6">Equation 3c</xref>.</p></sec><sec id="s4-3-2"><title>Continuous-time model</title><p>We approximated continuous-time model in <xref ref-type="disp-formula" rid="equ7">Equation 4</xref> by taking the first-order Taylor approximation of the deterministic term, which we write here as <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Specifically, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>k</mml:mi><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula>, where <italic>k</italic> represents the time-varying leak rate as in the discrete-time model (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), and <italic>b</italic> represents a bias in the derivative of the belief variable (<xref ref-type="disp-formula" rid="equ7">Equation 4</xref>; <xref ref-type="fig" rid="fig2">Figure 2D</xref>) that, along with the changing leak rate, effects a stabilizing boundary like in the discrete-time version. We calculated <italic>k</italic> as the slope of <italic>g</italic>(<italic>L</italic>), which is given as <inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>/</mml:mo><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>L′</italic> is the belief state around which the approximation was made. We computed bias as: <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Analogous to the discrete-time case, when <italic>L′</italic> = 0 (certainty is low and beliefs are weak), <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>×</mml:mo><mml:mn>0</mml:mn><mml:mo>×</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and the approximation is linear, resulting in an Ornstein-Uhlenbeck process during periods of stability in the data. However, as <italic>L′</italic> → ±∞, <italic>k</italic> → ∞, analogous to the leak rate approaching one in the discrete-time case, and<disp-formula id="equ28"><mml:math id="m28"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>lim</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>±</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>lim</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>±</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mi>lim</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>±</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>+</mml:mo></mml:mrow></mml:mrow><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>lim</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mo>±</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁡</mml:mo><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>→</mml:mo><mml:mo>±</mml:mo><mml:mi>∞</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Whereas discrete-time approximations of the model give log-priors that are qualitatively similar to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> for strong beliefs (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), this regime in general is not as well approximated as a linear-Gaussian process, with steady-state solutions over stable periods that are shifted, extreme-value distributions (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, panel D). These distributions can be approximated by first solving for the general steady-state probability distribution of <italic>L</italic>, as follows. Beginning with the corresponding Fokker-Planck equation and letting p(<italic>L, t</italic>) denote the time-dependent probability distribution of <italic>L</italic> and γ = <italic>Ah</italic>(<italic>t</italic>), the average of the sensory evidence during the stable period, we want the solution to <italic>p</italic>(<italic>L, t</italic>) such that: <inline-formula><mml:math id="inf17"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Therefore, <inline-formula><mml:math id="inf18"><mml:mrow><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which we solved as <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>⁡</mml:mo><mml:mi>sinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mtext>d</mml:mtext><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>C</italic><sub><italic>0</italic></sub> is a normalizing constant and <italic>L</italic><sub><italic>a</italic></sub> is a reflecting boundary condition. So <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and letting <italic>C</italic> be another normalizing constant that absorbs the constant terms inside the exponential:<disp-formula id="equ29"><label>(13)</label><mml:math id="m29"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mi>cosh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In the high-certainty regime (the expected value of the belief variable is very positive or negative, either because of strong sensory evidence or a very low hazard rate, or both), this expression can be well approximated as<disp-formula id="equ30"><label>(14a)</label><mml:math id="m30"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> when </mml:mtext><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ31"><label>(14b)</label><mml:math id="m31"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>when </mml:mtext><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≪</mml:mo><mml:mtext>0</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p><xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, panel B shows an example of this approximation along with simulations. <xref ref-type="disp-formula" rid="equ30 equ30">Equation 14</xref> can be rewritten as extreme value distributions with location parameters ±log(γ/λ) with the sign depending on the sign of the sensory evidence, and scale parameter = 1. For example, taking <xref ref-type="disp-formula" rid="equ30">Equation 14a</xref>,<disp-formula id="equ32"><mml:math id="m32"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>λ</mml:mi><mml:mi>γ</mml:mi></mml:mfrac><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>C</mml:mi><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>C</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁡</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>C′</italic> = <italic>C</italic>γ/λ.</p></sec></sec><sec id="s4-4"><title>Tasks</title><p>48 subjects (29 female, 19 male; age range = 19–45 years) participated in the triangles task, and 13 subjects (7 female, 6 male; age range = 19–38 years) participated in the dots-reversal task after providing informed consent. Human subject protocols were approved by the University of Pennsylvania Internal Review Board. Both tasks were performed on an iMac with a 27′′ (68.5 cm) screen.</p><sec id="s4-4-1"><title>Triangles task</title><p>Triangles were separated by 16 cm and represented the centers of a pair of two-dimensional Gaussian distributions. On each trial, one triangle was chosen as the true source of the generated star, and that source's associated two-dimensional distribution was sampled to determine the position of the star. Distributions were directly represented on the screen by scaling the color axis by screen position between blue and green according to the probability that a star would be generated in the given position (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>). Because the triangles were separated along the horizontal axis, only this dimension was relevant for determining which triangle represented the true source on that trial. For each trial, the star blinked on and off for ∼1.5 s before the subject could choose the inferred source of that star, to minimize fast guesses. For each session, one of three different variances of the pair of two-dimensional distributions was randomly chosen without replacement (the ratio of the standard deviation of the generative process to the distance between the triangles was 0.24, 0.33, or 0.41). These three conditions corresponded to mean values of log-likelihood ratios of 9, 4.5, or 3.33, respectively, of generated stars.</p><p>Each subject performed two 1000-trial blocks per session in 1–4 total sessions. Each block used a hazard rate that governed the rate of switching between the two sources (triangles) and was chosen randomly from a set of seven possible values (0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 0.95). Hazard rates were chosen without replacement within sessions to ensure a change across blocks. In a subset of sessions, each block began with 400 trials in which subjects received feedback on the correct choice, followed by another 400 trials without feedback and ending with 200 feedback-based trials so that changes in hazard rate did not coincide with the onset of feedback.</p><p>Before each session, subjects were instructed that the triangles generated stars into overlapping neighborhoods and shown representations of the spatial distributions. They were then instructed that triangles would ‘take turns’ generating stars, with switches in the turn-taking that would occasionally be fast or slow. After receiving these instructions, subjects were shown an animation illustrating the generative process (i.e., a sample sequence of trials).</p><p>Subjects were paid a minimum $8 per session and an additional amount based on performance: at the beginning of each session, the subject had $5, and over the trials was penalized by 20 cents for each incorrect choice and rewarded with either 1 or 2 cents for correct choices. Total cash reward was continuously updated on feedback trials but not on non-feedback trials so subjects could not infer the previous correct choice. On average, subjects received a total additional cash reward of $8 (range $0–27).</p></sec><sec id="s4-4-2"><title>Dots-reversal task</title><p>This task was based on decisions about the coherent direction of motion of a set of stochastic dots (density = 70 dots/deg<sup>2</sup>/s) presented in a 10°-diameter circular aperture at the center of the computer screen with three interleaved frames of motion. Each trial involved a stimulus 5–10 s in duration, determined as min(10, 5 + τ), where τ was an exponentially distributed random variable, making trial terminations unpredictable within the given time frame. Within each trial, the direction of movement alternated between leftward and rightward at an average hazard rate of either 0.1 Hz or 2 Hz. Subjects participated in two sessions each, with 200 trials per session and a hazard rate that was constant throughout the session. The order of the two hazard rate sessions was chosen at random.</p><p>Each session began with 20 practice trials in which coherence was set to 60–85%, relatively high values that were considered easy for all subjects. For the remaining 180 trials, coherence was randomly chosen as either this ‘high coherence’ value (25% of trials) or a ‘low-coherence’ value (75% of trials). The value used for ‘low coherence’ was determined separately for each subject (mean ± SEM = 14.85 ± 1.53%, range 6–38%), corresponding to the coherence for which the participant could correctly decide the direction of a 500-ms long stable stimulus (i.e., no direction changes) 65% of the time. We assessed this threshold using a modified version of the adaptive QUEST procedure in which coherence was set to the mean of the threshold probability distribution (<xref ref-type="bibr" rid="bib67">Watson and Pelli, 1983</xref>; <xref ref-type="bibr" rid="bib34">King-Smith et al., 1994</xref>). We ran the QUEST procedure before each session and did not end the procedure until stable performance was achieved, defined as an estimated threshold log-likelihood ≥ −2.5 under the assumption that unstable performance would shift the corresponding threshold and keep log-likelihoods lower (direct estimates of threshold across consecutive 20-trial blocks verified this assumption). We also ensured that the measured threshold from this procedure was consistent across sessions for individual subjects. We based ‘high’ coherence on the low-coherence threshold: subjects with thresholds &gt;15% received 85% high coherence, those with thresholds between 7–15% received 80% high coherence, and one subject with a remarkably low (∼4–5%) threshold received 60% high coherence. All stimuli in this range are fairly easy to judge.</p><p>Before the session, subjects were instructed to do their best to follow motion direction throughout a given trial and indicate the direction they believed dots were moving in at the ‘very end’ of the trial. Subjects received feedback after each trial on the correct answer but were not given additional monetary reward for performance as in the triangles task.</p></sec></sec><sec id="s4-5"><title>Model fitting</title><p>All models were fit to choice data using Matlab's optimization toolbox by minimizing the cross-entropy error function (<xref ref-type="bibr" rid="bib4">Bishop, 2006</xref>):<disp-formula id="equ33"><label>(15)</label><mml:math id="m33"><mml:mrow><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>ρ</italic><sub><italic>n</italic></sub> is a binary variable indicating which alternative was chosen on trial <italic>n</italic> (arbitrarily defined as 0 for the right and 1 for the left) and <inline-formula><mml:math id="inf21"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the choice probability predicted by the given model. All models assumed the choices were based on the sign of the subjective log-odds.</p><sec id="s4-5-1"><title>Triangles task</title><p>We fit choices from the triangles task for each block of trials and each session by computing estimated <italic>L</italic><sub><italic>n</italic></sub> on each iteration of the fitting algorithm using <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>; the current best estimate of subjective hazard rate for that iteration and block of trials (<inline-formula><mml:math id="inf22"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>); and a gain term on star position (<italic>β</italic>) that was applied across blocks but was specific to each session, which accounted for a subjective estimate of the generative variance (<xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2001</xref>): <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Unless otherwise indicated, all fits were made to trials without any feedback on the correct answer to confirm that learned hazard rates were used during this period. We omitted from further analyses the first 200 trials of each block for sessions in which no trial-by-trial feedback was given at all, allowing for stabilization of learned, subjective estimates of the current generative <italic>H</italic> and resulting in a total of 800–6400 trials per subject for analysis. We assumed choices were based on the subjective log-odds and Gaussian noise: <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>sign</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ζ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <italic>ς</italic><sub><italic>n</italic></sub> is the Gaussian noise variable. We also assumed a fixed magnitude of noise <italic>υ</italic> across sessions but specific to each subject. Model fits thus computed the cumulative probability of choosing the left triangle for subject <italic>i</italic>, in session <italic>s</italic>, block <italic>b</italic>, and trial <italic>n</italic> as:<disp-formula id="equ34"><label>(16)</label><mml:math id="m34"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>erf</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msub><mml:mi>υ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Thus, this model had 4–16 free parameters for each subject, depending on the number of sessions. Because of the large number of parameters for some subjects, we used a maximum a posteriori (MAP) fitting procedure that placed conjugate priors on each parameter that were fixed across subjects and conditions, subtracting off log(<italic>p</italic>[<italic>parameter estimate</italic>|<italic>conjugate prior distribution of parameters</italic>]) from the error term in <xref ref-type="disp-formula" rid="equ33">Equation 15</xref>.</p></sec><sec id="s4-5-2"><title>Dots-reversal task</title><p>We fit the continuous-time model to data from the dots-reversal task using <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, which is the most efficient discrete-time approximation of <xref ref-type="disp-formula" rid="equ7">Equation 4</xref> and faster than the Euler-Maruyama approximation with small time-steps. However, unlike the triangles task, here all choices were made after observing an entire sequence of stimuli over the trial. We thus fit the model using <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> with <italic>n</italic> indexing trial rather than time and <italic>m</italic> indexing time-step within a trial, <italic>i</italic> indexing subject and <italic>s</italic> indexing session, as follows:<disp-formula id="equ35"><label>(17)</label><mml:math id="m35"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>k</italic><sub><italic>i</italic></sub> is a gain term for that subject on signed coherence <italic>C</italic><sub><italic>ismn</italic></sub> (negative for rightward motion, positive for leftward motion; because coherence was determined probabilistically, its magnitude could vary step-by-step within a trial); <inline-formula><mml:math id="inf25"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> indicates the expected coherence magnitude for that trial, determined experimentally as described above; <italic>η</italic><sub><italic>ismn</italic></sub> is zero-mean, unit variance Gaussian noise; and <inline-formula><mml:math id="inf26"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is subjective hazard rate specific to each session. To convert to a continuous-time subjective hazard rate <italic>λ</italic>, we multiplied <inline-formula><mml:math id="inf27"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> by the monitor refresh rate (60 Hz), which determines the time-steps between dot drawings.</p><p>The last two terms of <xref ref-type="disp-formula" rid="equ35">Equation 17</xref> represent the subjective <italic>LLR</italic>, which we assume reflects a coherence-dependent signal (the second-to-last term) plus internal (neural), signal-dependent noise (the last term). Because we could not directly observe this noisy quantity, we fit the model by numerically deriving the time-evolution of the log-odds probability distribution over each trial and each step of the fitting iteration. Specifically, we determined the probability of each log-odds (<italic>L</italic><sub><italic>isomn</italic></sub>) at each time step by marginalizing over the probability of each log-odds from the previous time-step (<italic>L</italic><sub><italic>isj, m − 1, n</italic></sub>):<disp-formula id="equ36"><label>(18)</label><mml:math id="m36"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:msubsup><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes a Gaussian probability distribution function of variable <italic>x</italic> with mean <italic>μ</italic> and standard deviation <italic>σ</italic> and is the conditional probability distribution of the log-odds on each time-step given the coherence, model parameters, and log-odds on the previous time-step. Probability distributions were initialized on each trial as a Dirac delta function. For the model fits, we discretized the log-odds space between −10 and 10 over steps of 0.4 log-odds, which we determined via simulations to be a sufficient range and resolution for accurate parameter estimates. Estimated choice probabilities were then computed as the cumulative probability of choosing the leftward direction: <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>M</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mtext>d</mml:mtext><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Model fits were thus based on three parameters per subject, a single gain term <italic>k</italic><sub><italic>i</italic></sub> and two hazard rate terms <inline-formula><mml:math id="inf30"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, one for each session.</p></sec><sec id="s4-5-3"><title>Sub-optimal model <sup>#</sup>1: block-independent model</title><p>For both tasks, we fit to choice data a version of the normative model that ignored the block-wise changes in objective hazard rate. To ensure a fair model comparison with the block-dependent normative model, we constructed the null model using the same number of hazard-rate parameters but randomly shuffled across blocks. Specifically, for the triangles task the main model equation (<xref ref-type="disp-formula" rid="equ34">Equation 16</xref>) was written as <inline-formula><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>b</italic>(<italic>n</italic>) denotes the hazard-specific block to which this trial was randomly assigned. Randomization was performed before each fit, and this shuffle-and-fit procedure was repeated 50 times to generate a distribution of model log-likelihoods and BIC values against which the normative model could be compared across subjects. For the dots-reversal task, the main model equations (<xref ref-type="disp-formula" rid="equ35 equ37">Equations 17, 18</xref>) were written as <inline-formula><mml:math id="inf32"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>k</mml:mi><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>s</italic> was a vector indicating the randomized session, with the shuffle-and-fit procedure repeated 20 times per subject.</p></sec><sec id="s4-5-4"><title>Sub-optimal model <sup>#</sup>2: block-dependent leaky accumulator</title><p>For both tasks, we also fit an alternative model based on the linear approximation in <xref ref-type="disp-formula" rid="equ4">Equation 3a</xref>. For the triangles task this model was written as <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>K</italic> was the leak specific to subject <italic>i</italic> in session <italic>s</italic> and block <italic>b</italic>, and the other parameters were as described above. For the dots-reversal task we fit the same model, only here treating noise as a latent variable like we did for fitting the normative model and deriving the time-evolution of the log-odds probability distribution over each trial and each step of the fitting iteration: <inline-formula><mml:math id="inf34"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Unlike the normative model, these fits were greatly simplified by an analytic solution for the stationary standard derivation of the log-odds, given the current coherence and model parameters: <inline-formula><mml:math id="inf35"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. This quantity is the standard deviation for the stationary probability distribution of the discrete-time analogue of an Ornstein-Uhlenbeck process in which coherence is perfectly stable over a trial. Thus, for each step of the fitting procedure, we solved for the average log-odds at the end of the trial by: (1) running the deterministic portion of the leaky-accumulation over the time-dependent coherence for the trial, and (2) writing the probability distribution of the log-odds at the end of the trial as a Gaussian with the final mean determined in step 1 and a standard deviation as described above, giving <inline-formula><mml:math id="inf36"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>erf</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>M</italic> indicates the final sample of trial <italic>n</italic>.</p></sec><sec id="s4-5-5"><title>Sub-optimal model <sup>#</sup>3: perfect accumulation with block-dependent stabilizing boundaries</title><p>For both tasks, we also fit an alternative model assuming perfect integration to a stabilizing boundary as in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> with the boundary in <xref ref-type="disp-formula" rid="equ5 equ6">Equation 3b,c</xref> as a free parameter; that is, rewriting <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> as:<disp-formula id="equ37"><label>(19)</label><mml:math id="m37"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>θ</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>For the triangles task, these fits were made as for the normative model, only using the re-written expression in <xref ref-type="disp-formula" rid="equ37">Equation 19</xref> for log-prior odds above; that is, <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. For the dots-reversal task, we similarly made fits as for the normative model, substituting the expression for <italic>ψ</italic> in <xref ref-type="disp-formula" rid="equ37">Equation 19</xref> into <xref ref-type="disp-formula" rid="equ35 equ36">Equations 17, 18</xref>.</p></sec></sec><sec id="s4-6"><title>Analysis details</title><p>Choice data shown in <xref ref-type="fig" rid="fig5">Figure 5A</xref> were fit by a two-parameter logistic function: <inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>ϕ</italic> represents the <italic>LLR</italic> for which subjects have a 50% chance of choosing either side, and <italic>β</italic> is the slope of the function around that point. Average differences in parameter <italic>ϕ</italic> by hazard-rate condition are reflected in the horizontal shift of the psychometric function, representing a bias towards (leftward shift) or away from (rightward shift) repeating the same choice. Like for the fits of the main normative model, here the first 200–400 trials of each block were excluded to allow for a period of learning. We report the correlation between <italic>ϕ</italic> and the prediction from the asymptotic approximation of the fit normative model: <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The subjective mappings of <italic>ψ</italic><sub><italic>n</italic></sub> to <italic>L</italic><sub><italic>n − 1</italic></sub> in <xref ref-type="fig" rid="fig6">Figure 6</xref> were estimated as a non-parametric function, fit to choice data based on <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ψ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> where here the <italic>LLR</italic> was based on the generative variance used for the task. We expressed <italic>ψ</italic><sub><italic>n</italic></sub> as an interpolated function of <italic>L</italic><sub><italic>n</italic> − 1</sub>, with values spread evenly between −10 and 10 in steps of one log-odds ratio and interpolation performed with cubic splines. We fit the mapping with the same objective function as for the parametric models (<xref ref-type="disp-formula" rid="equ18">Equation 10</xref>), using the entire data set within a given block to estimate the <italic>ψ</italic> that best fit choice data. We used Tikhonov regularization of the derivative (for smoothness) using the added penalty term: <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi>γ</mml:mi><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Δ</mml:mi><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, where <italic>i</italic> indexes the value of <italic>L</italic> for which <italic>ψ</italic> was estimated and <italic>γ</italic> = 1/20 was determined through ad hoc methods.</p><p>Standard errors and statistical tests on performance measured as a function of viewing duration following the final change-point on the dots-reversal task were based on bootstrapped samples of the behavioral data or model predictions (<xref ref-type="fig" rid="fig8">Figure 8A–F</xref>, <xref ref-type="fig" rid="fig9">Figure 9H–K</xref>). Viewing duration bins were 0–200, 200–500, 500–1000, 1000–1500 and 1500–3000 ms. These analyses only included trials for which there was at least one change-point and the duration of the second-to-last direction was at least 300 ms to avoid immediately sequential change-points. The mean ± SEM durations of the second-to-last direction for trials used in this analysis were 2945 ± 55 ms for 0.1 Hz and 789 ± 13 ms for 2 Hz. At these durations, discrimination accuracy was likely to be at nearly asymptotic levels at the time of the final change-point. For a given duration bin specific to coherence and condition (indexed jointly as <italic>k</italic>), a single bootstrapped sample <italic>m</italic> of performance was calculated as <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>m</italic> indexes subject, generated as a random integer between zero and 14; <italic>n</italic> indexes trial; and <italic>N</italic><sub><italic>km</italic></sub> is the total number of trials within the duration bin for that subject and trial type (e.g., 0.1 Hz, low coherence). Means and standard errors were calculated as means and standard deviations of all bootstrapped samples (1000 samples per comparison). Statistical tests between condition-by-coherence trials <italic>i</italic> and <italic>j</italic> were based on paired differences between the same bootstrapped samples. The probability that <inline-formula><mml:math id="inf43"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> was calculated as <inline-formula><mml:math id="inf44"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></inline-formula>, (where <italic>M</italic> was the total number of bootstrapped samples for that comparison), likewise for <inline-formula><mml:math id="inf45"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and statistical significance indicated when one of these was less than the desired confidence level (0.05).</p><p>Fit leaks for the dots-reversal task (<xref ref-type="fig" rid="fig9">Figure 9</xref>) used the same algorithm as in the leaky-accumulator model described above but with separate leak terms for both hazard rate and low vs high coherence. Specifically, for subject <italic>i</italic>, session <italic>s</italic>, time-step <italic>m</italic>, trial <italic>n</italic>, and coherence level <italic>c</italic>, we defined the leak <inline-formula><mml:math id="inf46"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The noise was based on the stationary standard derivation of the log-odds, given the current coherence and model parameters: <inline-formula><mml:math id="inf47"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. We then fit the choice data to the predicted probability of a given choice for each trial, <inline-formula><mml:math id="inf48"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>erf</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>M</italic> indicates the final sample of trial <italic>n</italic>. We used a beta distribution prior on leak rate, letting the maximized model log probability for each subject be based on the sum of log likelihoods and this log prior probability, similar to what we did for the triangles task. We were interested in the dependence of leak on coherence level and comparing these dependencies between the choice data and model predictions. To control for overall level of leak by session (and subject), we computed the dependence as a normalized quantity: <inline-formula><mml:math id="inf49"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where the ‘high’ and ‘low’ subscripts denote leaks for high and low coherences. The comparison between the data and normative model prediction of the dependence on hazard rate (session) used an analogous normalized measure: <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where ‘fast’ and ‘slow’ indicate the 2 Hz and 0.1 Hz sessions respectively. Statistics reported were based on these difference measures.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Gabriel Kroch and Timothy Kim for help with data collection and Joe McGuire, Yin Li, Matt Nassar, and Bob Wilson for comments.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>CMG, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>JWK, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>JIG, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent, and consent to publish, was obtained from each subject prior to each experiment. Human subject protocols were approved by the University of Pennsylvania Internal Review Board.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>MacKay</surname><given-names>DJ</given-names></name></person-group><year>2007</year><article-title>Bayesian online changepoint detection</article-title><comment>University of Cambridge Technical report</comment></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnard</surname><given-names>GA</given-names></name></person-group><year>1946</year><article-title>Sequential tests in industrial statistics</article-title><source>Journal of the Royal Statistical Society</source><volume>8</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.2307/2983610</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year>2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year>2006</year><source>Pattern recognition and machine learning</source><publisher-loc>New York</publisher-loc><source>Springer</source></element-citation></ref><ref id="bib4a"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Boerlin</surname><given-names>M</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year>2013</year><article-title>Predictive coding of dynamical variables in balanced spiking networks</article-title><source>PLoS computational biology</source><volume>9</volume><issue>11</issue><fpage>e1003258</fpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year>2010</year><article-title>The neural basis of the speed-accuracy tradeoff</article-title><source>Trends in Neurosciences</source><volume>33</volume><fpage>10</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2009.09.002</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year>1992</year><article-title>The analysis of visual motion: a comparison of neuronal and psychophysical performance</article-title><source>The Journal of Neuroscience</source><volume>12</volume><fpage>4745</fpage><lpage>4765</lpage></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name></person-group><year>2009</year><article-title>Detecting and predicting changes</article-title><source>Cognitive Psychology</source><volume>58</volume><fpage>49</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2008.09.002</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year>2013</year><article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title><source>Science</source><volume>340</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1233912</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Townsend</surname><given-names>JT</given-names></name></person-group><year>1993</year><article-title>Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment</article-title><source>Psychological Review</source><volume>100</volume><fpage>432</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.100.3.432</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Puskas</surname><given-names>GA</given-names></name><name><surname>El-Murr</surname><given-names>S</given-names></name></person-group><year>2009</year><article-title>Decisions in changing conditions: the urgency-gating model</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>11560</fpage><lpage>11571</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1844-09.2009</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clifford</surname><given-names>CW</given-names></name><name><surname>Ibbotson</surname><given-names>MR</given-names></name></person-group><year>2002</year><article-title>Fundamental mechanisms of visual motion detection: models, cells and functions</article-title><source>Progress in Neurobiology</source><volume>68</volume><fpage>409</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1016/S0301-0082(02)00154-5</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Crisan</surname><given-names>D</given-names></name><name><surname>Rozovskii</surname><given-names>B</given-names></name></person-group><year>2011</year><source>The Oxford handbook of nonlinear filtering</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year>2012</year><article-title>Making decisions with unknown sensory reliability</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><fpage>75</fpage><pub-id pub-id-type="doi">10.3389/fnins.2012.00075</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2013</year><article-title>The basal ganglia's contributions to perceptual decision making</article-title><source>Neuron</source><volume>79</volume><fpage>640</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.042</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditterich</surname><given-names>J</given-names></name></person-group><year>2006</year><article-title>Evidence for time-variant decision making</article-title><source>The European Journal of Neuroscience</source><volume>24</volume><fpage>3628</fpage><lpage>3641</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.05221.x</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Klier</surname><given-names>EM</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year>2014</year><article-title>Optimal multisensory decision-making in a reaction-time task</article-title><source>eLife</source><volume>3</volume><fpage>e03005</fpage><pub-id pub-id-type="doi">10.7554/eLife.03005</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year>2012</year><article-title>The cost of accumulating evidence in perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3612</fpage><lpage>3628</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4010-11.2012</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckhoff</surname><given-names>P</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Law</surname><given-names>C</given-names></name><name><surname>Connolly</surname><given-names>PM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2008</year><article-title>On diffusion processes with variable drift rates as models for decision making during learning</article-title><source>New Journal of Physics</source><volume>10</volume><fpage>nihpa49499</fpage><pub-id pub-id-type="doi">10.1088/1367-2630/10/1/015006</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fearnhead</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name></person-group><year>2007</year><article-title>On-line inference for multiple changepoint problems</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>69</volume><fpage>589</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2007.00601.x</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2000</year><article-title>Representation of a perceptual decision in developing oculomotor commands</article-title><source>Nature</source><volume>404</volume><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1038/35006062</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2001</year><article-title>Neural computations that underlie decisions about sensory stimuli</article-title><source>Trends in Cognitive Sciences</source><volume>5</volume><fpage>10</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01567-9</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2002</year><article-title>Banburismus and the brain: decoding the relationship between sensory stimuli, decisions, and reward</article-title><source>Neuron</source><volume>36</volume><fpage>299</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)00971-6</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Castro</surname><given-names>LN</given-names></name><name><surname>Hadjiosif</surname><given-names>AM</given-names></name><name><surname>Hemphill</surname><given-names>MA</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name></person-group><year>2014</year><article-title>Environmental consistency determines the rate of motor adaptation</article-title><source>Current Biology</source><volume>24</volume><fpage>1050</fpage><lpage>1061</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.03.049</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Good</surname><given-names>IJ</given-names></name></person-group><year>1979</year><article-title>Studies in the history of probability and statistics. XXXVI. AM Turing's statistical work in World War II</article-title><source>Biometrika</source><volume>66</volume><fpage>393</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1093/biomet/66.2.393</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year>1966</year><source>Signal detection theory and psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Duan</surname><given-names>CA</given-names></name><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year>2015</year><article-title>Distinct relationships of parietal and prefrontal cortices to evidence accumulation</article-title><source>Nature</source><volume>520</volume><fpage>220</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature14066</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Mazurek</surname><given-names>ME</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hopp</surname><given-names>E</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2011</year><article-title>Elapsed decision time affects the weighting of prior probability in a perceptual decision task</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>6339</fpage><lpage>6352</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5613-10.2011</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henning</surname><given-names>GB</given-names></name><name><surname>Hertz</surname><given-names>BG</given-names></name><name><surname>Broadbent</surname><given-names>DE</given-names></name></person-group><year>1975</year><article-title>Some experiments bearing on the hypothesis that the visual system analyses spatial patterns in independent bands of spatial frequency</article-title><source>Vision Research</source><volume>15</volume><fpage>887</fpage><lpage>897</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(75)90228-X</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2005</year><article-title>Neural activity in macaque parietal cortex reflects temporal integration of visual motion signals during perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10420</fpage><lpage>10436</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4684-04.2005</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Zariwala</surname><given-names>HA</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year>2008</year><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><volume>455</volume><fpage>227</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature07200</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2009</year><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King-Smith</surname><given-names>PE</given-names></name><name><surname>Grigsby</surname><given-names>SS</given-names></name><name><surname>Vingrys</surname><given-names>AJ</given-names></name><name><surname>Benes</surname><given-names>SC</given-names></name><name><surname>Supowit</surname><given-names>A</given-names></name></person-group><year>1994</year><article-title>Efficient and unbiased modifications of the QUEST threshold method: theory, simulations, experimental evaluation and practical implementation</article-title><source>Vision Research</source><volume>34</volume><fpage>885</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(94)90039-6</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krugel</surname><given-names>LK</given-names></name><name><surname>Biele</surname><given-names>G</given-names></name><name><surname>Mohr</surname><given-names>PN</given-names></name><name><surname>Li</surname><given-names>SC</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name></person-group><year>2009</year><article-title>Genetic variation in dopaminergic neuromodulation influences the ability to rapidly and flexibly adapt decisions</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>106</volume><fpage>17951</fpage><lpage>17956</lpage><pub-id pub-id-type="doi">10.1073/pnas.0905191106</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lasley</surname><given-names>DJ</given-names></name><name><surname>Cohn</surname><given-names>T</given-names></name></person-group><year>1981</year><article-title>Detection of a luminance increment: effect of temporal uncertainty</article-title><source>Journal of the Optical Society of America</source><volume>71</volume><fpage>845</fpage><lpage>850</lpage><pub-id pub-id-type="doi">10.1364/JOSA.71.000845</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Link</surname><given-names>SW</given-names></name></person-group><year>1992</year><source>The wave theory of difference and similarity</source><publisher-loc>Hillsdale, NJ</publisher-loc><publisher-name>Erlbaum</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liptser</surname><given-names>RS</given-names></name><name><surname>Shiryaev</surname><given-names>AN</given-names></name></person-group><year>1977</year><source>Statistics of random processes: 1. General theory</source><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Luce</surname><given-names>RD</given-names></name></person-group><year>1986</year><source>Response times: their role in inferring elementary mental organization</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludwig</surname><given-names>CJ</given-names></name><name><surname>Gilchrist</surname><given-names>ID</given-names></name><name><surname>McSorley</surname><given-names>E</given-names></name><name><surname>Baddeley</surname><given-names>RJ</given-names></name></person-group><year>2005</year><article-title>The temporal impulse response underlying saccadic decisions</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>9907</fpage><lpage>9912</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2197-05.2005</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year>2014</year><article-title>Neural coding of uncertainty and probability</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>205</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014017</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name><name><surname>Creelman</surname><given-names>CD</given-names></name></person-group><year>2004</year><source>Detection theory: a user's guide</source><publisher-loc>Mahwah, NJ</publisher-loc><publisher-name>Lawrence Erlbaum</publisher-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><year>2014</year><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><volume>84</volume><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nachmias</surname><given-names>J</given-names></name><name><surname>Rogowitz</surname><given-names>BE</given-names></name></person-group><year>1983</year><article-title>Masking by spatially-modulated gratings</article-title><source>Vision Research</source><volume>23</volume><fpage>1621</fpage><lpage>1629</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(83)90176-1</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname><given-names>JX</given-names></name><name><surname>Schüffelgen</surname><given-names>U</given-names></name><name><surname>Cuell</surname><given-names>SF</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year>2013</year><article-title>Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>110</volume><fpage>E3660</fpage><lpage>E3669</lpage><pub-id pub-id-type="doi">10.1073/pnas.1305373110</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ossmy</surname><given-names>O</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year>2013</year><article-title>The timescale of perceptual evidence integration can be adapted to the environment</article-title><source>Current Biology</source><volume>23</volume><fpage>981</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.04.039</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>J</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2005</year><article-title>The effect of stimulus strength on the speed and accuracy of a perceptual decision</article-title><source>Journal of Vision</source><volume>5</volume><fpage>376</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1167/5.5.1</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabiner</surname><given-names>L</given-names></name></person-group><year>1989</year><article-title>A tutorial on hidden Markov models and selected applications in speech recognition</article-title><source>Proceedings of the IEEE</source><volume>77</volume><fpage>257</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1109/5.18626</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddi</surname><given-names>BA</given-names></name><name><surname>Carpenter</surname><given-names>RH</given-names></name></person-group><year>2000</year><article-title>The influence of urgency on decision time</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>827</fpage><lpage>830</lpage><pub-id pub-id-type="doi">10.1038/77739</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname><given-names>A</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2009</year><article-title>Changes of mind in decision-making</article-title><source>Nature</source><volume>461</volume><fpage>263</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nature08275</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>Y</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year>2014</year><article-title>How much to trust the senses: likelihood learning</article-title><source>Journal of Vision</source><volume>14</volume><fpage>13</fpage><pub-id pub-id-type="doi">10.1167/14.13.13</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schrater</surname><given-names>PR</given-names></name><name><surname>Knill</surname><given-names>DC</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year>2000</year><article-title>Mechanisms of visual motion detection</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>64</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/71134</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname><given-names>P</given-names></name><name><surname>Contreras</surname><given-names>D</given-names></name><name><surname>Buck</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>P</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>2009</year><article-title>Reward rate optimization in two-alternative decision making: empirical tests of theoretical predictions</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>35</volume><fpage>1865</fpage><lpage>1897</lpage><pub-id pub-id-type="doi">10.1037/a0016926</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name></person-group><year>1995</year><article-title>Psychophysically principled models of visual simple reaction time</article-title><source>Psychological Review</source><volume>102</volume><fpage>567</fpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.567</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name></person-group><year>1998</year><article-title>Bloch's law predictions from diffusion process models of detection</article-title><source>Australian Journal of Psychology</source><volume>50</volume><fpage>139</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1080/00049539808258790</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Ratcliff</surname><given-names>R</given-names></name></person-group><year>2004</year><article-title>Psychology and neurobiology of simple decisions</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>161</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.01.006</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sternberg</surname><given-names>S</given-names></name></person-group><year>2001</year><article-title>Separate modifiability, mental modules, and the use of pure and composite measures to reveal them</article-title><source>Acta Psychologica</source><volume>106</volume><fpage>147</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1016/S0001-6918(00)00045-7</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thura</surname><given-names>D</given-names></name><name><surname>Beauregard-Racine</surname><given-names>J</given-names></name><name><surname>Fradet</surname><given-names>CW</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year>2012</year><article-title>Decision making by urgency gating: theory and experimental support</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>2912</fpage><lpage>2930</lpage><pub-id pub-id-type="doi">10.1152/jn.01071.2011</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year>2012</year><article-title>Using time-varying evidence to test models of decision dynamics: bounded diffusion vs. the leaky competing accumulator model</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><fpage>79</fpage><pub-id pub-id-type="doi">10.3389/fnins.2012.00079</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year>2006</year><article-title>Seeing at a glance, smelling in a whiff: rapid forms of perceptual decision making</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>485</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1038/nrn1933</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year>2001</year><article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.108.3.550</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verghese</surname><given-names>P</given-names></name><name><surname>Watamaniuk</surname><given-names>SN</given-names></name><name><surname>McKee</surname><given-names>SP</given-names></name><name><surname>Grzywacz</surname><given-names>NM</given-names></name></person-group><year>1999</year><article-title>Local motion detectors cannot account for the detectability of an extended trajectory in noise</article-title><source>Vision Research</source><volume>39</volume><fpage>19</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(98)00033-9</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wald</surname><given-names>A</given-names></name></person-group><year>1947</year><source>Sequential analysis</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year>1983</year><article-title>QUEST: a Bayesian adaptive psychometric method</article-title><source>Percept Psychophys</source><volume>33</volume><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.3758/BF03202828</pub-id></element-citation></ref><ref id="bib67a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>R</given-names></name><name><surname>Finkel</surname><given-names>L</given-names></name></person-group><year>2009</year><article-title>Advances in neural information processing systems 22</article-title><source>A neural implementation of the Kalman filter</source><fpage>p. 2062</fpage><lpage>p. 2070</lpage></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2010</year><article-title>Bayesian online learning of the hazard rate in change-point problems</article-title><source>Neural Computation</source><volume>22</volume><fpage>2452</fpage><lpage>2476</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00007</pub-id></element-citation></ref><ref id="bib68a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year>2013</year><article-title>A mixture of delta-rules approximation to bayesian inference in change-point problems</article-title><source>PLoS computational biology</source><volume>9</volume><issue>7</issue><fpage>p. e1003150</fpage></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year>2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zakai</surname><given-names>M</given-names></name></person-group><year>1965</year><article-title>The optimal filtering of Markov jump processes in additive white noise</article-title><comment>Research Note No. 563, Sylvania Electronic System</comment></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.08825.018</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Behrens</surname><given-names>Timothy</given-names></name><role>Reviewing editor</role><aff><institution>Oxford University</institution>, <country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for submitting your work entitled “Normative evidence accumulation in unpredictable environments” for peer review at <italic>eLife</italic>. Your submission has been favorably evaluated by Timothy Behrens (Senior and Reviewing Editor) and three peer reviewers.</p><p>The reviewers have discussed the reviews with one another and the editor has drafted this decision to help you prepare a revised submission.</p><p>The study of how the brain integrates a history of evidence into a single expectation has been a remarkably profitable avenue of research in forming quantitative understandings of neural mechanisms over recent years and decades. However, two largely distinct literatures have tackled this problem from very different perspectives. One set of researchers have considered the mathematics and neurophysiology of integrating continuous streams of evidence using approaches such as the drift diffusion model and the sequential probability ratio test. Another set of researchers have considered the integration of discrete events or trials using Bayesian models that can, for example, optimally determine when to integrate evidence together, and when to separate new evidence because the world has changed.</p><p>The current paper presents an important step towards a unification of these two literatures, by presenting an elegant mathematical analysis of the Bayesian change-point models to demonstrate that they can be viewed as modified sequential probability ratio tests, and are therefore directly applicable to the large set of researchers who are interested in continuous evidence integration. It makes new and interesting predictions about the stream integration case in situations when the evidence is non-stationary and it tests these predictions in behaviour. All three reviewers considered this to be a very interesting and potentially important step.</p><p>As you will see below, the reviewers did not have major criticisms of the model that is presented or data, which they broadly found to be convincing. Most important in terms of solidifying the conclusions, however, are Reviewer 1's and 3's similar points about the demonstration of the qualitative reason for the improvement of the current model (Reviewer 1) and the absence of a reasonable analysis of other (sub-optimal) models (Reviewer 3).</p><p>In the discussion, the reviewers and editor were also clear that the manuscript is really written for a technical audience. <italic>eLife</italic> readership is broad and the reviewers and editor would appreciate a reframing of the paper that makes the central points clearer to this broad audience.</p><p>One suggestion that emerged during the discussion was a clearer framing of the manuscript as follows:</p><p>a) The same Bayesian learning framework, that has been used in other contexts (work by Behrens, Adams, Kording and also Nassar and Gold) is here derived for evidence accumulation in perceptual decision-making tasks like RDM;</p><p>b) This normative framework can be described, in both discrete and continuous cases, as a leaky accumulator with non-absorbing bounds, with the leak rate and the height of the bounds being explicit functions of the environmental change rate;</p><p>c) Show that this is the case in their data (their paradigm with variable hazard rate is a good test even if atypical of RDM experiments);</p><p>d) Provide some justification why this model helps our understanding of perceptual decision-making (can the relationship with change point detection explain or offer insight into previously unexplained data?);</p><p>e) Provide some clear commentary on the relationship to previous models of change point detection (can the relationship with RDMs explain or offer insight into previously unexplained data?).</p><p>We urge you to consider this, or other possible reframings in which the strong message can be understood clearly without an understanding of the technical details.</p><p><italic>Reviewer #1:</italic></p><p>In this study, Glaze, Kable and Gold present a model of evidence integration over time in which the relative weighting given to new and past observations can be adjusted to reflect the hazard rate for change in the environment. They show that this model can be generalized to both discrete and continuous time cases and that it fits human performance better than a model without adjustable hazard rate, in two very different decision-making tasks – a random dot motion task with within-trial reversals, and a task in which evidence is accumulated over many discrete trials.</p><p>This is a good quality paper which I think will be of interest to people across the field of perceptual decision-making, since it presents a clear framework that is applicable in diverse tasks. It could be an influential and highly cited paper in the field.</p><p>If I were to make a case why the manuscript should be published in <italic>eLife</italic>, I would point out that the adaptation of the Bayesian framework to the random dot motion case does represent a major conceptual advance over the more typical approaches in that field (SPRT models with fixed leak rates or the drift diffusion model), and the model does better at explaining participants' performance than those more typical models. However, I would then suggest that the paper could be strengthened by exploring in more detail why the current model outperforms others (especially, the leaky accumulator with hazard rate as a free parameter by block). Is this because the leaky accumulator down weights past beliefs about the correct response without taking into account evidence strength? If so the reason for the current model's superiority is not really to do with estimating the hazard rate, although the text implies that it is. Furthermore, to what extent does the current model address burning questions in that field, such as how confidence judgements are made or when the evidence accumulation process should terminate?</p><p><italic>Reviewer #2:</italic></p><p>In this manuscript by Glaze et al., the authors present a normative model for evidence accumulation in a non-stationary environment in which the successive simples are drawn from one of two alternative distributions for an unknown and variable duration. The main part of the manuscript is to compare the performance of human subjects in two different behavioral tasks with the predictions of this normative model and a simpler alternative model based on leaky integration. The results show that human subjects differ significantly from the predictions of normative model, in that subjective estimate of the rate of change (hazard rate) is close to 0.5, suggesting that they tend to give insufficient weight to the history of evidence. Although the manuscript is quite technical in nature, it is written clearly, and the findings would be of high value to many researchers in the field. There are only a few, relatively minor, comments:</p><p>1) The overall conclusion of the authors is that the subjective estimates of hazard rate are biased, but this quantity is used in a normative way. However, this might be misleading. Namely, is it fair to refer to an algorithm as “normative” if the quantity used in this algorithm is biased? Does such an algorithm behave differently, for example, from a model that uses the accurate estimate of hazard rate in non-normative way? Unless the authors can clarify how these two different scenarios can be distinguished, how the word “normative” is used in this manuscript might need to be improved.</p><p>2) In the subsection “Psychophysics”, the authors should indicate for how many sessions, trial-by-trial feedback was provided in the beginning and end of each block.</p><p>3) What do green and blue colors in <xref ref-type="fig" rid="fig7">Figure 7A</xref> indicate?</p><p><italic>Reviewer #3:</italic></p><p>This is an interesting paper that provides a significant contribution through the clear derivation of a normative approach for accumulation of evidence under conditions where the evidence is not stationary. The derivation and the description of how changes in the rate of change of environments correspond to leakiness in accumulation was very appealing.</p><p>I found the experimental section convincing in terms of showing that humans do indeed try to estimate the rate of change of the environment, and that this estimate affects how they make decisions. But the further claim made in the paper that humans behave according to the normative model was harder to be convinced by – it seemed that other (suboptimal) models that use an estimate of the hazard rate might also be consistent with the data, but this wasn't much explored in the paper. Instead, the straw man such as a model where the estimated hazard rate is a single value fixed for all time was used, but it seemed rather a weak straw man.</p><p>In addition, much greater clarity in the exposition would be desirable.</p><p>Despite these concerns, the nice derivation of the normative results under changes in environments makes me see the paper positively.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.08825.019</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>[…] As you will see below, the reviewers did not have major criticisms of the model that is presented or data, which they broadly found to be convincing. Most important in terms of solidifying the conclusions, however, are Reviewer 1's and 3's similar points about the demonstration of the qualitative reason for the improvement of the current model (Reviewer 1) and the absence of a reasonable analysis of other (sub-optimal) models (Reviewer 3)</italic>.</p><p>Our original submission included direct comparisons of the normative model with two suboptimal models: 1) subjective hazard rate was randomly shuffled across conditions, meant to mimic choices under the assumption of a single subjective hazard rate, but with the same parameter structure; and 2) a leaky accumulator, which was inspired by both the approximation to the normative model in the weak-belief regime (<xref ref-type="disp-formula" rid="equ4">Equation 3a</xref> in the manuscript) as well as the many neural models that assume (linear) leaky integration. We now include a comparison to a third, suboptimal model, in this case assuming perfect integration to a stabilizing boundary (“bounded accumulation”), inspired by the approximation to the normative model in the strong-belief regime (<xref ref-type="disp-formula" rid="equ5 equ6">Equation 3b, c</xref>). We also now provide for each experimental task a consolidated discussion of how the fits compare between the normative model versus the leaky and bounded accumulator approximations and highlight key differences between models in <xref ref-type="fig" rid="fig3 fig6 fig9">Figures 3, 6, and 9</xref>.</p><p><italic>In the discussion, the reviewers and editor were also clear that the manuscript is really written for a technical audience.</italic> eLife <italic>readership is broad and the reviewers and editor would appreciate a reframing of the paper that makes the central points clearer to this broad audience</italic>.</p><p><italic>One suggestion that emerged during the discussion was a clearer framing of the manuscript as follows:</italic></p><p><italic>a) The same Bayesian learning framework, that has been used in other contexts (work by Behrens, Adams, Kording and also Nassar and Gold) is here derived for evidence accumulation in perceptual decision-making tasks like RDM;</italic></p><p><italic>b) This normative framework can be described, in both discrete and continuous cases, as a leaky accumulator with non-absorbing bounds, with the leak rate and the height of the bounds being explicit functions of the environmental change rate</italic>;</p><p><italic>c) Show that this is the case in their data (their paradigm with variable hazard rate is a good test even if atypical of RDM experiments)</italic>;</p><p><italic>d) Provide some justification why this model helps our understanding of perceptual decision-making (can the relationship with change point detection explain or offer insight into previously unexplained data?)</italic>;</p><p><italic>e) Provide some clear commentary on the relationship to previous models of change point detection (can the relationship with RDMs explain or offer insight into previously unexplained data?)</italic>.</p><p><italic>We urge you to consider this, or other possible reframings in which the strong message can be understood clearly without an understanding of the technical details</italic>.</p><p>We very much appreciate the thoughtful suggestions, which we have incorporated throughout the manuscript, including the Abstract, Introduction, Results, and Discussion sections.</p><p>Reviewer #1:</p><p><italic>[…] However, I would then suggest that the paper could be strengthened by exploring in more detail why the current model outperforms others (especially, the leaky accumulator with hazard rate as a free parameter by block). Is this because the leaky accumulator down weights past beliefs about the correct response without taking into account evidence strength?</italic></p><p>Yes, and this failure to account for evidence strength will lead to, for example, confidence that is allowed to grow to a much higher asymptote that hinders change detection when the leaky accumulator has been optimized to process weak evidence, as in <xref ref-type="disp-formula" rid="equ4">Equation 3a</xref>. In contrast, the normative model limits confidence at any given moment to the logarithmic terms in <xref ref-type="disp-formula" rid="equ5 equ6">Equation 3b, c</xref>. We now provide these intuitions, along with complementary limitations of the suboptimal model with perfect accumulation to a stabilizing boundary, in the new <xref ref-type="fig" rid="fig3">Figure 3</xref> and associated text.</p><p><italic>If so the reason for the current model's superiority is not really to do with estimating the hazard rate, although the text implies that it is</italic>.</p><p>We respectfully disagree: the value of the limit in confidence mentioned above depends entirely on estimated hazard rate as in <xref ref-type="disp-formula" rid="equ5 equ6">Equations 3b, c</xref>. In other words, the normative model accounts for evidence strength in a way that depends on hazard rate.</p><p><italic>Furthermore, to what extent does the current model address burning questions in that field, such as how confidence judgements are made or when the evidence accumulation process should terminate?</italic></p><p>We agree that these are very interesting issues that are closely related to evidence accumulation and therefore are pertinent to our model. We have an entire paragraph in the Discussion about how our model provides new insights into the speed-accuracy trade-off and decision termination. We thank the reviewer for pointing out the link to confidence judgments, which we now also include in that paragraph.</p><p>Reviewer #2:</p><p><italic>[…] There are only a few, relatively minor, comments</italic>.</p><p><italic>1) The overall conclusion of the authors is that the subjective estimates of hazard rate are biased, but this quantity is used in a normative way. However, this might be misleading. Namely, is it fair to refer to an algorithm as “normative” if the quantity used in this algorithm is biased?</italic></p><p>We would argue that the algorithm is normative while the subjective parameter estimates are not. We now explain our perspective on this important point more clearly in the Discussion, as follows:</p><p>“[W]e showed that subjects could both learn a range of hazard rates and then use those learned rates in a normative manner to interpret sequences of evidence to make decisions. However, they tended to learn imperfectly, over-estimating low hazard rates and under-estimating high hazard rates. […] These different set points may have reflected certain prior expectations about the improbability of either perfect stability or excessive instability that could constrain performance when those conditions occur.”</p><p><italic>Does such an algorithm behave differently</italic>, <italic>for example, from a model that uses the accurate estimate of hazard rate in non-normative way?</italic></p><p>We agree that this is a very interesting question. We have provided several lines of evidence that support the idea that the subjects are using their subjective estimates of hazard rate in a normative fashion. First, we used choice data to directly estimate the mapping of subjective beliefs to priors (new <xref ref-type="fig" rid="fig6">Figure 6</xref>) and showed that subjects exhibited leaky/asymptotic integration in ways that closely matched predictions of the normative model using imperfect estimates of hazard rate. Second, their behavior exhibited the trade-off between change detection and steady-state signal identification predicted by the model, based on their subjective estimates of hazard (<xref ref-type="fig" rid="fig5 fig8">Figures 5 and 8</xref>). Third, their behavior also reflected the signal-strength-dependent biases predicted by the model, in a manner also dependent on their subjective estimates of hazard.</p><p>In addition, we now include in the manuscript estimated subjective hazard rates from both the leaky and bounded accumulator models for both tasks. These parameters also deviate from objective values, “further supporting the idea that the subjects were using imperfect estimates [of hazard rate] to make their decisions.”</p><p>We of course cannot fully rule out the possibility that there are some other models that can better explain our choice data using objective hazard rates. However, given the relatively few parameters per block in our model, plus its ability to capture many aspects of the behavioral data, we believe that we have presented a compelling case that, to a very large degree, our subjects’ behavior is consistent with a normative process using imperfect estimates of hazard rate.</p><p><italic>Unless the authors can clarify how these two different scenarios can be distinguished, how the word “normative” is used in this manuscript might need to be improved</italic>.</p><p>We hope that we have addressed this important point sufficiently thoroughly and clearly in the revised manuscript.</p><p><italic>2) In the subsection “Psychophysics”, the authors should indicate for how many sessions, trial-by-trial feedback was provided in the beginning and end of each block</italic>.</p><p>We apologize for the lack of detail, which we now provide.</p><p><italic>3) What do green and blue colors in</italic> <xref ref-type="fig" rid="fig7"><italic>Figure 7A</italic></xref> <italic>indicate?</italic></p><p>We apologize for the confusion and have now ensured that all figures have appropriate legends.</p><p>Reviewer #3:</p><p><italic>[…] I found the experimental section convincing in terms of showing that humans do indeed try to estimate the rate of change of the environment, and that this estimate affects how they make decisions. But the further claim made in the paper that humans behave according to the normative model was harder to be convinced by – it seemed that other (suboptimal) models that use an estimate of the hazard rate might also be consistent with the data, but this wasn't much explored in the paper. Instead, the straw man such as a model where the estimated hazard rate is a single value fixed for all time was used, but it seemed rather a weak straw man</italic>.</p><p>We strongly agree for the need to compare normative model fits with other likely candidate models. We had originally focused on comparison with a leaky integrator that had the leak vary freely by blocks of trials, because this alternative model seemed to be the most viable form of information accumulation examined in prior studies that could solve these tasks. We apologize for any confusion about what forms of this model we used (it was not the case that we used the true straw man of a single fixed hazard rate for all conditions). We have clarified and expanded upon these issues substantially and include for each task model comparisons to both leaky integration (allowing the leak to vary by hazard-specific block) and bounded, perfect, accumulation (allowing the bound to vary by hazard-specific block). The models are described in detail in separate sub-sections of Methods.</p><p><italic>In addition, much greater clarity in the exposition would be desirable</italic>.</p><p>We have implemented the suggested changes described in the summary comments, above, and hope that we have substantially clarified the exposition.</p></body></sub-article></article>