<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">36395</article-id><article-id pub-id-type="doi">10.7554/eLife.36395</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Model-based fMRI reveals dissimilarity processes underlying base rate neglect</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-84270"><name><surname>O'Bryan</surname><given-names>Sean R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0562-8211</contrib-id><email>sean.r.obryan@ttu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-109305"><name><surname>Worthy</surname><given-names>Darrell A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-109306"><name><surname>Livesey</surname><given-names>Evan J</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-61168"><name><surname>Davis</surname><given-names>Tyler</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Psychological Sciences</institution><institution>Texas Tech University</institution><addr-line><named-content content-type="city">Lubbock</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Psychology</institution><institution>Texas A&amp;M University</institution><addr-line><named-content content-type="city">College Station</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">School of Psychology</institution><institution>University of Sydney</institution><addr-line><named-content content-type="city">Sydney</named-content></addr-line><country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Verstynen</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff><institution>Carnegie Mellon University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>03</day><month>08</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e36395</elocation-id><history><date date-type="received" iso-8601-date="2018-03-05"><day>05</day><month>03</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-08-01"><day>01</day><month>08</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, O'Bryan et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>O'Bryan et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-36395-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.36395.001</object-id><p>Extensive evidence suggests that people use base rate information inconsistently in decision making. A classic example is the inverse base rate effect (IBRE), whereby participants classify ambiguous stimuli sharing features of both common and rare categories as members of the rare category. Computational models of the IBRE have posited that it arises either from associative similarity-based mechanisms or from dissimilarity-based processes that may depend on higher-level inference. Here we develop a hybrid model, which posits that similarity- and dissimilarity-based evidence both contribute to the IBRE, and test it using functional magnetic resonance imaging data collected from human subjects completing an IBRE task. Consistent with our model, multivoxel pattern analysis reveals that activation patterns on ambiguous test trials contain information consistent with dissimilarity-based processing. Further, trial-by-trial activation in left rostrolateral prefrontal cortex tracks model-based predictions for dissimilarity-based processing, consistent with theories positing a role for higher-level symbolic processing in the IBRE.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.36395.002</object-id><title>eLife digest</title><p>Is a patient with muscle aches, headache and fever more likely to have influenza or Ebola? Most people correctly choose ‘influenza’ because it is the more common of the two diseases. But what about someone with a cough and unexplained bleeding? Coughing is a symptom of influenza but not of Ebola. Unexplained bleeding is a symptom of Ebola but not of influenza. Faced with ambiguous symptoms such as these, many people would diagnose ‘Ebola’ despite knowing that influenza is more common. Indeed, when a situation shares characteristics with both a common and a rare category, we often tend to predict that it belongs to the rare group. This phenomenon is known as base rate neglect, but why does it occur?</p><p>One theory is that we pay more attention to features that belong to rare categories (such as unexplained bleeding) because they are distinctive and unusual. But another possibility is that we use our knowledge of the common category to rule out examples that do not conform to our expectations. Of the many cases of influenza that you have heard about or experienced, probably none of them featured unexplained bleeding.</p><p>To distinguish between these possibilities, O’Bryan et al. trained healthy volunteers on a categorization task that included ambiguous stimuli. The participants performed the task inside a brain scanner. O’Bryan et al. then programmed a computer to solve the same problems. The simulation either used similarity-based judgments (how similar is this to the rare category?), dissimilarity-based judgments (how dissimilar is this from the common category?), or both. The results suggested that when people show base rate neglect, they rely more on dissimilarity-based evidence than on similarity-based evidence. In other words, they focus more on how a test item differs from the common category. Consistent with this, whenever the volunteers chose the rare category, their brains were processing information about the common category. The imaging results also revealed that when the volunteers used dissimilarity-based evidence, they activated a brain region involved in abstract thinking and reasoning.</p><p>How people use information about likelihoods is relevant to all aspects of decision-making. Beyond helping us to understand how we assign items to categories, the work by O’Bryan et al. could also inform future research in areas such as learning and memory.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>categorization</kwd><kwd>fMRI</kwd><kwd>base rates</kwd><kwd>multivoxel analysis</kwd><kwd>rostrolateral prefrontal cortex</kwd><kwd>exemplar model</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007131</institution-id><institution>Texas Tech University</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Davis</surname><given-names>Tyler</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Model-based imaging shows that the rostrolateral prefrontal cortex supports dissimilarity-based heuristics that people may use when they are confronted with ambiguous scenarios.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Does this patient have influenza or Ebola virus? Categorization is a fundamental process that underlies many important decisions. Categories, such as viruses, often have different relative frequencies or base rates. Influenza, for example, is very common and infects millions of people worldwide each year, whereas Ebola virus tends to have infection rates that are orders of magnitude lower.</p><p>One critical question is how people use such base rate information when making categorization decisions. Research so far has suggested that people tend to be, at best, inconsistent in their use of base rate information. In both realistic studies with medical professionals and artificial categorization tasks in the lab, when confronted with examples that share characteristics with both rare and common categories, people show a tendency to predict the rare category much more often than the base rates would suggest (<xref ref-type="bibr" rid="bib55">Tversky and Kahneman, 1974</xref>; <xref ref-type="bibr" rid="bib14">Casscells et al., 1978</xref>; <xref ref-type="bibr" rid="bib7">Bravata, 2000</xref>). In an extreme case, known as the inverse base rate effect (IBRE), people may even predict rare categories as more likely than common ones (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>). For example, in an IBRE context, a patient presenting with cough (a characteristic feature of influenza) and unexplained bleeding (a characteristic feature of Ebola), may be more likely to be diagnosed with Ebola than influenza.</p><p>The mechanisms that lead to base rate neglect are currently undetermined at both the cognitive and neural levels. Computationally, according to influential work with similarity-based categorization models (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>, <xref ref-type="bibr" rid="bib32">Kruschke, 2001</xref>), the IBRE arises from differential selective attention to features for common and rare categories. Specifically, participants learn to attend more strongly to features of rare categories, making ambiguous cases seem more similar to rare categories and thus more likely to be rare category members. In terms of the flu example, participants may attend more to the unexplained bleeding feature of the rarer Ebola virus category, and thus predict Ebola when confronted with a patient with both features.</p><p>Similarity-based category learning models have strong support in the neurobiological category learning literature. Model-based predictions for how similar items are to stored category representations have been shown to correlate with activation in the medial temporal lobes (MTL; <xref ref-type="bibr" rid="bib17">Davis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib18">Davis et al., 2012b</xref>). Moreover, at a finer-grained level, multivoxel activation patterns in the MTL have been shown to contain information associated with higher-order similarity relationships between category members anticipated by similarity-based models (<xref ref-type="bibr" rid="bib19">Davis and Poldrack, 2014</xref>), including those predicted by differences in selective attention (<xref ref-type="bibr" rid="bib37">Mack et al., 2016</xref>). The dorsolateral prefrontal cortex (dlPFC) tends to track predictions of choice uncertainty from similarity-based models, whereas ventromedial PFC (vmPFC) tends to track estimates of high choice accuracy or model-confidence (<xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>).</p><p>Despite the strong cognitive and neural evidence for similarity-based models, it remains an open question whether they provide a complete account of IBRE-like phenomena. One alternative proposition is that people’s choice of rare categories when confronted with conflicting information may stem from reliance on dissimilarity processes, either solely, or in addition to similarity-based processes. According to theories that focus on dissimilarity-based processes, people build strong expectations of the common category; thus they view items containing features inconsistent with these expectations as more likely to be members of the rare category (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Winman et al., 2005</xref>). For example, a doctor may have seen thousands of cases of flu, none with unexplained bleeding, and thus rule out influenza and choose Ebola virus based on these expectations. In these cases, it is <italic>dissimilarity</italic> to members of the common (unchosen) category that drives choice, rather than the similarity to rare (chosen) category members per se.</p><p>Formal models positing dissimilarity processes have so far been explicitly dual-process oriented. For example, ELMO, a computational model that incorporates a choice elimination decision based on dissimilarity, argues that such elimination depends on explicit reasoning processes that are separate from similarity-based processes that arise in other trials (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>). In the present study, we propose a new account based on a recently proposed dissimilarity-based extension of the generalized context model, the dissGCM (<xref ref-type="bibr" rid="bib54">Stewart and Morin, 2007</xref>). This account uses the same basic similarity computations as standard similarity-based models (e.g. <xref ref-type="bibr" rid="bib44">Nosofsky, 1986</xref>), but allows similarities and dissimilarities to stored exemplars to be used as evidence for a category. In terms of the above example, dissimilarity to influenza can be used as evidence for Ebola (and vice versa).</p><p>As specified computationally, the dissGCM is agnostic about whether using dissimilarity-based evidence constitutes a different cognitive or neurobiological mechanism from using similarity-based evidence. On one hand, the dissGCM has no fundamentally different computations from a basic similarity process; as detailed below, dissimilarity is a simple transformation of similarity. On the other hand, it is possible that dissimilarity processes require manipulation of similarity relationships between category representations in a more symbolic or abstract manner, as anticipated by previous dissimilarity theories. Given that the dissGCM makes separable estimates for the relative contributions of similarity- and dissimilarity-based evidence to choice in a given trial, these model predictions can be used to explicitly test whether employing dissimilarity-based evidence against unchosen categories engages brain regions beyond those associated with the use of similarity-based evidence, consistent with dual-process accounts of IBRE. Specifically, we can test whether regions that are known to be critical for using higher-level abstract rules track dissGCM’s predicted trial-by-trial used of dissimilarity-based evidence, and whether these regions diverge from those typically found to track estimates of similarity-based evidence.</p><p>Higher-level cognitive control mechanisms are thought to depend on a hierarchy of abstraction in the lateral PFC along the rostral-caudal axis (<xref ref-type="bibr" rid="bib1">Badre and D'Esposito, 2007</xref>; <xref ref-type="bibr" rid="bib2">Badre and D'Esposito, 2009</xref>). At the apex of this hierarchy is the rostrolateral PFC (rlPFC), a region often implicated in tasks that require people to generalize across abstract, symbolic representations. For example, relational reasoning tasks such as Raven’s progressive matrices and rule-based tasks involving abstract relations are thought to depend on left rlPFC (<xref ref-type="bibr" rid="bib15">Christoff et al., 2001</xref>; <xref ref-type="bibr" rid="bib9">Bunge et al., 2005</xref>, <xref ref-type="bibr" rid="bib8">Bunge et al., 2009</xref>; <xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>). In addition to its role in generalizing abstract, relational rules, we have recently found left rlPFC to be involved in rule evaluation and novel generalization processes for simpler feature-based rules in categorization tasks (<xref ref-type="bibr" rid="bib46">Paniukov and Davis, 2018</xref>). In the present study, dissimilarity-based generalization to novel feature pairings may depend on rule evaluation processes in the rlPFC more so than simple similarity-based processing, if studies anticipating that dissimilarity-based processes depend more upon higher-level symbolic rules are correct (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Winman et al., 2005</xref>). Alternatively, pure similarity-based accounts suggest that generalization patterns in an IBRE task do not depend on the existence of a separate, higher-level mechanism (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>, <xref ref-type="bibr" rid="bib32">Kruschke, 2001</xref>), and would thus expect a single neurobiological network associated with similarity-based processing to be engaged for choice across trials.</p><p>Here we test the dissGCM by incorporating its predictions into an analysis of fMRI data collected from participants completing a standard IBRE task (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>). We first examine whether multivoxel activation patterns elicited during conflicting trials in the IBRE task are consistent with participants activating information associated with the rare category, as predicted by pure similarity-based accounts, or activating information associated with (dissimilarity to) the common category, as predicted by the dissGCM. To this end, we use representational similarity analysis (RSA; <xref ref-type="bibr" rid="bib30">Kriegeskorte et al., 2008</xref>) to decode which features of the stimuli are most strongly activated while participants are categorizing the conflicting items. This analysis is based on recent work in the broader memory literature establishing that it is possible to decode whether participants are retrieving particular object categories from memory based on their activation patterns in ventral temporal cortex (<xref ref-type="bibr" rid="bib48">Rissman and Wagner, 2012</xref>; <xref ref-type="bibr" rid="bib26">Haxby et al., 2014</xref>).</p><p>To facilitate the multivoxel analysis, here we use the real world visual categories faces, scenes, and objects as stimulus features. These visual categories have a well-defined representational topography across the cortex (<xref ref-type="bibr" rid="bib27">Haxby et al., 2001</xref>; <xref ref-type="bibr" rid="bib24">Grill-Spector and Weiner, 2014</xref>), allowing us to predict whether participants are differentially activating particular stimulus features (faces, scenes, or objects) by computing similarities between activation patterns elicited for the key IBRE trials and feature-specific patterns from an independent localizer scan. By crossing the visual stimulus features with our category structure (<xref ref-type="fig" rid="fig1">Figure 1</xref>), we create situations where a rare category is associated with one feature type (e.g. a scene) and a common category is associated with another feature type (e.g. an object). The extent to which each type of information is active can then be compared to determine whether participants are representing stimulus features associated with the common or rare category on a trial, and thus answer whether their BOLD activation patterns are more consistent with pure similarity or dissGCM’s combined dissimilarity and similarity processes. In this context, we anticipate that the multivoxel pattern analysis will index an interactive process between feature-based attention and memory retrieval: the dissGCM, pure similarity-based GCM, and previous dissimilarity-based inference models all predict that categorization decisions are driven by an attention-weighted memory process whereby a stimulus is compared with the contents of memory (<xref ref-type="bibr" rid="bib44">Nosofsky, 1986</xref>; <xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib54">Stewart and Morin, 2007</xref>). This prediction suggests that during categorization, the multivoxel patterns activated for a particular stimulus will reflect both direct perceptual processing and retrieval of information from memory. Because the dissGCM predicts greater contributions from the common, unchosen category during this retrieval process, we expect multivoxel patterns during ambiguous trials to reveal greater activation of information associated with the common, unchosen category.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.003</object-id><label>Figure 1.</label><caption><title>Abstract task design and an example trial.</title><p>In the headings, I = imperfect predictor, PC = common perfect predictor, PR = rare perfect predictor. The second row refers to the visual category used for each stimulus feature: F = face, S = scene, O = object. Each following row corresponds to a learning trial, with a ‘1’ indicating the presence of the feature and ‘0’ indicating its absence.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig1-v2"/></fig><p>In addition to our multivoxel analysis, we also test whether using dissimilarity-based evidence against unchosen categories may tap distinct brain regions, such as the rlPFC, beyond those involved with similarity-based computations. To this end, we take trial-by-trial predictions for how much similarity- and dissimilarity-based evidence contribute to the winning category and use these predictions as regressors in fMRI analysis. We anticipated that the MTL and vmPFC would be positively associated with similarity-based evidence, whereas dlPFC would be negatively associated with similarity-based evidence for the winning category. Contrastingly, we expected rlPFC to track estimates of dissimilarity-based evidence against alternative options.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral results and model fit</title><p>Learning curves over the 12 learning blocks for common and rare disease item pairs are shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. All subjects reached greater than 90% accuracy over the last four blocks (M = 98.1%, SD = 2.4%, range = 93.5–100%). Mean choice performance in the first block was above chance (25%) for both common (M = 63.6%) and rare (M = 43.2%) feature pairs. Consistent with previous IBRE studies, a linear mixed effects model revealed a significant block by trial type interaction (<italic>F</italic> (1, 262)=20.7, p&lt;0.001), suggesting that the common diseases were learned more quickly than the rare diseases. Paired <italic>t</italic>-tests revealed that participants were significantly more accurate on common compared with rare disease trials in the first (<italic>t</italic> (21)=2.26, p=0.034), second (<italic>t</italic> (21)=2.85, p=0.010), third (<italic>t</italic> (21)=2.72, p=0.013), fourth (<italic>t</italic> (21)=2.46, p=0.023), and 12th blocks (<italic>t</italic> (21)=2.23, p=0.037).</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.004</object-id><label>Figure 2.</label><caption><title>Learning curves.</title><p>Points depict proportions correct for common and rare disease predictions over the 12 blocks of the training phase (mean ± SEM). *p &lt; 0.05.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig2-v2"/></fig><p>For the test phase, participants were asked to categorize the original category exemplars in addition to a number of other novel feature combinations in the absence of feedback. We then fit the dissGCM to the group choice probabilities for each test item. The dissGCM is based on the original generalized context model (<xref ref-type="bibr" rid="bib44">Nosofsky, 1986</xref>), but allows for dissimilarity to be used as evidence for a decision (<xref ref-type="bibr" rid="bib54">Stewart and Morin, 2007</xref>). The model posits that people represent stimuli as points in a multidimensional feature space, and that categorization judgments are based on distances between probe stimuli and stored exemplars. As for the standard GCM, similarities to all exemplars of each category are summed into evidence for each category. However, in the dissGCM, evidence that an item is dissimilar to <italic>other</italic> categories is also used as evidence for a category. For example, evidence for Disease 1 includes not only an item’s similarity to members of Disease 1, but also its dissimilarity to other diseases.</p><p>Choice probabilities and dissGCM-derived predictions for each of the test items are summarized in <xref ref-type="table" rid="table1">Table 1</xref>. Consistent with an inverse base rate effect, participants were numerically more likely to classify ambiguous test stimuli (combinations of rare and common features) as members of the relevant rare category (M = 49.8%) than the relevant common category (M = 43.5%) combined across object-scene, scene-scene, and object-object pairs. A one-sample t-test revealed that the percentage of rare responding on ambiguous trials was significantly higher than the 1/4 base rate for the rare category (<italic>t</italic> (21)=8.11, p&lt;0.001). Likewise, participants chose the rare category for ambiguous pairs significantly more often than for the imperfect predictors (faces: M = 30.0%), (<italic>t</italic> (21)=3.85, p&lt;0.001).</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.005</object-id><label>Table 1.</label><caption><title>Observed and dissGCM-predicted response probabilities for the test phase.</title><p>The feature combinations presented at test are listed in the leftmost column: F = face, S = scene, O = object. In the headings, D1–D4 correspond to the four possible category responses (diseases). Bold, italicized values indicate results for the key ambiguous stimuli in which a scene was paired with an object.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="4">Behavior</th><th align="center" colspan="4">dissGCM</th></tr><tr><th valign="bottom">Test item</th><th valign="bottom"><italic>D1</italic></th><th valign="bottom"><italic>D2</italic></th><th valign="bottom"><italic>D3</italic></th><th valign="bottom"><italic>D4</italic></th><th valign="bottom"><italic>D1</italic></th><th valign="bottom"><italic>D2</italic></th><th valign="bottom"><italic>D3</italic></th><th valign="bottom"><italic>D4</italic></th></tr></thead><tbody><tr><td>F1 + S1</td><td>.972</td><td>.018</td><td>.008</td><td>.003</td><td>.971</td><td>.014</td><td>.008</td><td>.008</td></tr><tr><td>F1 + O1</td><td>.031</td><td>.962</td><td>.008</td><td>0.</td><td>.063</td><td>.901</td><td>.018</td><td>.018</td></tr><tr><td>F2 + O2</td><td>.005</td><td>0.</td><td>.987</td><td>.008</td><td>.008</td><td>.008</td><td>.972</td><td>.013</td></tr><tr><td>F2 + S2</td><td>.023</td><td>.008</td><td>.069</td><td>.901</td><td>.018</td><td>.018</td><td>.059</td><td>.905</td></tr><tr><td>F1</td><td>.667</td><td>.295</td><td>.023</td><td>.015</td><td>.667</td><td>.283</td><td>.025</td><td>.025</td></tr><tr><td>F2</td><td>.107</td><td>.038</td><td>.550</td><td>.305</td><td>.027</td><td>.027</td><td>.640</td><td>.307</td></tr><tr><td>S1</td><td>.848</td><td>.061</td><td>.008</td><td>.083</td><td>.955</td><td>.015</td><td>.015</td><td>.015</td></tr><tr><td>O1</td><td>.008</td><td>.908</td><td>.069</td><td>.015</td><td>.040</td><td>.880</td><td>.040</td><td>.040</td></tr><tr><td>O2</td><td>.008</td><td>.069</td><td>.908</td><td>.015</td><td>.012</td><td>.012</td><td>.965</td><td>.012</td></tr><tr><td>S2</td><td>.023</td><td>.053</td><td>.008</td><td>.916</td><td>.032</td><td>.032</td><td>.032</td><td>.904</td></tr><tr><td><bold><italic>S1 + O</italic><italic>1</italic></bold></td><td><bold>.<italic>414</italic></bold></td><td><bold>.<italic>487</italic></bold></td><td><bold>.<italic>073</italic></bold></td><td><bold>.<italic>027</italic></bold></td><td><bold>.<italic>419</italic></bold></td><td><bold>.<italic>496</italic></bold></td><td><bold>.<italic>042</italic></bold></td><td><bold>.<italic>042</italic></bold></td></tr><tr><td><bold><italic>O2 + S</italic><italic>2</italic></bold></td><td><bold>.<italic>035</italic></bold></td><td><bold>.<italic>047</italic></bold></td><td><bold>.<italic>453</italic></bold></td><td><bold>.<italic>465</italic></bold></td><td><bold>.<italic>038</italic></bold></td><td><bold>.<italic>038</italic></bold></td><td><bold>.<italic>460</italic></bold></td><td><bold>.<italic>464</italic></bold></td></tr><tr><td>F1 + O2</td><td>.131</td><td>.238</td><td>.631</td><td>0.</td><td>.156</td><td>.174</td><td>.658</td><td>.013</td></tr><tr><td>F1 + S2</td><td>.264</td><td>.062</td><td>.008</td><td>.667</td><td>.178</td><td>.237</td><td>.023</td><td>.563</td></tr><tr><td>F2 + S1</td><td>.608</td><td>.031</td><td>.138</td><td>.223</td><td>.657</td><td>.013</td><td>.155</td><td>.175</td></tr><tr><td>F2 + O1</td><td>.008</td><td>.674</td><td>.302</td><td>.016</td><td>.024</td><td>.567</td><td>.170</td><td>.239</td></tr><tr><td>O1 + O2</td><td>.008</td><td>.514</td><td>.475</td><td>.004</td><td>.040</td><td>.444</td><td>.477</td><td>.040</td></tr><tr><td>S1 + S2</td><td>.397</td><td>.065</td><td>.011</td><td>.527</td><td>.400</td><td>.040</td><td>.040</td><td>.520</td></tr></tbody></table></table-wrap><p>In addition to response probabilities, we tested whether reaction times differed on the ambiguous test trials depending on whether a rare or common response was made. On these trials of interest, a linear mixed effects model revealed that RTs were slower when participants made rare responses (M = 1.47 s) than common responses (M = 1.27 s), (<italic>t</italic> (21)=10.48, p&lt;0.001). The observation of slowed RTs on ambiguous trials receiving rare responses suggests that rare selections may be more cognitively demanding relative to common selections, consistent with previous dissimilarity-based theories of IBRE that posit a role of higher-level, inferential reasoning in base rate neglect.</p></sec><sec id="s2-2"><title>Multivoxel results</title><sec id="s2-2-1"><title>Test phase</title><p>The primary goal of the multivoxel analysis was to decode, for the ambiguous stimuli, whether participants were activating information consistent with the common or rare category when they make the choice to classify the stimulus as rare. Specifically, for the bold italicized stimuli listed in <xref ref-type="table" rid="table1">Table 1</xref>, we tested whether participants’ activation patterns were more similar to localizer activation patterns associated with scenes when a scene was the common feature (and object was rare) and more similar to those of objects when an object was the common feature (and scene was rare). Participants encountered 24 examples of these key object-scene pairings over the course test phase, and the choice patterns for each subject are detailed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p><p>The prediction that information associated with the common category should be more active on ambiguous trials is derived from the dissGCM. When examining how much each category’s exemplars (common and rare) contributed to the rare response for ambiguous items, the model posits that rare choices are more probable because of the contribution that dissimilarity to the common category makes to the evidence for the rare category relative to the contribution of similarity to the rare category. Formally, similarity-based evidence is given as the summed attention-weighted similarity of a stimulus to the winning category (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref> in Materials and methods), and dissimilarity-based evidence is the summed attention-weighted dissimilarity to the non-winning categories (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref> in Materials and methods). For example, using these formulas, in the fitted version of the model, the proportion of the overall evidence for rare contributed by similarity to the rare category exemplar was nearly half the evidence contributed by dissimilarity to the common category exemplar (rare = 0.088; common = 0.153, in the dissGCM’s attention weighted similarity units).</p><p>For this analysis, multivoxel pattern estimates were anatomically restricted to ROIs in ventral temporal cortex associated with each visual stimulus category (objects: left inferior posterior temporal gyrus; scenes: bilateral parahippocampal gyrus; and faces: right temporal occipital fusiform gyrus). Within these respective regions, subject-level ROIs were then functionally selected by creating 6 mm spheres around subjects’ peak activation to each category during the localizer phase. Pattern estimates were found to discriminate between information associated with control items during test: pattern similarity estimates for objects were significantly greater on object-only trials (O1, O2, and O1+O2) than scene-only trials (S1, S2, and S1+S2), (<italic>t</italic> (21)=2.83, p=0.010), and vice versa (<italic>t</italic> (21)=5.60, p&lt;0.001). Likewise, estimates for faces on face-only control trials were found to be significantly greater than on object-only trials (<italic>t</italic> (21)=2.54, p=0.019), and scene-only trials (<italic>t</italic> (21)=2.92, p=0.008).</p><p>Multivoxel pattern similarity results for the ambiguous test trials are depicted in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Consistent with the dissGCM’s predictions, a linear mixed effects model with BOLD pattern similarity as the outcome variable and categorical predictors for response, stimulus dimension (common vs. rare), and visual stimulus category (objects vs. scenes) revealed a significant interaction between response and pattern similarity to common and rare features, whereby participants tended to more strongly activate patterns associated with common features only when they made a rare response (<italic>F</italic> (1, 42)=4.92, p=0.032). Specifically, when participants chose the rare category, their activation patterns were most similar to whichever visual stimulus category (scenes or objects) was associated with the common category (<italic>t</italic> (21)=2.78, p=0.011). Interestingly, there was no significant difference between pattern similarity for rare and common features when participants made a common response (<italic>t</italic> (21)=0.45, p=0.653). Visual stimulus category was not found to interact with response (<italic>F</italic> (1, 72)=0.229, p=0.634), or whether an item was rare or common (<italic>F</italic> (1, 72)=0.241, p=0.625), in the pattern similarity model, and thus the results in <xref ref-type="fig" rid="fig3">Figure 3</xref> are collapsed across objects and scenes. A depiction of the test phase results including means for each distinct item in the model can be found in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.006</object-id><label>Figure 3.</label><caption><title>Multivoxel pattern similarity to common and rare stimulus features for ambiguous trials in which participants made common (left) and rare (right) responses (mean ± SEM).</title><p>Purple squares correspond to the objects/scenes associated with the common category, while green squares correspond to the objects/scenes associated with the rare category in a given trial. Gray squares depict mean pattern similarity to the non-present face dimension for both response types. *p &lt; 0.05. No error bars are included for the gray bars because face dimensions were not included in the overall mixed effects model.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36395.007</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Multivoxel pattern similarity to common and rare objects, scenes, and faces for ambiguous trials in which participants made common (left) and rare (right) responses (mean ± SEM).</title><p>Purple corresponds to objects/scenes associated with the common category, while green corresponds to the objects/scenes associated with the rare category on a given trial. Triangles indicate objects, and circles indicate scenes. Gray squares depict mean pattern similarity to the non-present face dimension for both response types. *p &lt; 0.05. No error bars are included for the gray bars because face dimensions were not included in the overall mixed effects model.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig3-figsupp1-v2"/></fig></fig-group><p>Because faces were off-screen for the key test trials and pattern similarity to the face dimension could represent information associated with either common or rare exemplars, no a priori predictions were made regarding pattern similarity to faces on ambiguous trials. However, a one-sample t-test revealed no significant differences in pattern similarity to the face dimension across responses (<italic>t</italic> (21)=0.22, p=0.828). Mean pattern similarity to faces on the ambiguous test trials is depicted by the gray squares in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p><p>To summarize, our multivoxel findings for the test phase suggest that people more strongly activate information associated with common categories when engaging in base rate neglect, consistent with dissGCM’s prediction that dissimilarity to the common category exemplar contributes more to rare decisions than similarity to the rare category exemplar. Although the model’s evidence weighting predictions and our multivoxel results provide a reasonable account for why participants tend to choose rare categories for ambiguous stimuli, the dissGCM does not address the question of whether a separate mechanism or strategy may contribute to trials in which the common category is chosen. Like the dissGCM, previous dual-process theories of IBRE (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Winman et al., 2005</xref>) propose that rare responses tend to be a byproduct of dissimilarity-based processing, but hypothesize that common responses are more likely a result of a ‘strategic guessing’ strategy that is engaged when a probe fails to elicit a strong match with learned category rules.</p><p>To more explicitly test whether our multivoxel results on the ambiguous trials support the representational assumptions of distinct mechanisms that contribute to common versus rare responses, we computed Bayes factors to evaluate the strength of evidence for and against the null hypothesis in both cases. According to the predictions of dual-process accounts, no differences in mean pattern similarity to rare versus common stimulus dimensions would be expected for common responses, as participants are expected to retrieve weak or competing representations of the category exemplars in these cases and thus respond in a way consistent with the category base rates. Alternatively, enhanced pattern similarity to common stimulus dimensions would be expected in the case of rare responses, in line with dissGCM’s explanation of the IBRE. Bayes factors for each of these hypotheses were tested using the BIC approximation method, computing exp(ΔBIC/2) between the null and alternative models (<xref ref-type="bibr" rid="bib56">Wagenmakers, 2007</xref>). The resulting Bayes factors suggested positive evidence in favor of the null hypothesis for pattern similarity on common response trials (BF<sub>01</sub> = 7.54), and conversely, positive evidence in favor of the alternative hypothesis that common features would be more strongly represented on rare response trials (BF<sub>10</sub> = 4.36). Accordingly, beyond revealing that a dissimilarity-based process contributes to rare responding in an IBRE task, our multivoxel results point to the existence of a distinct process for common responses that is, on average, less dependent on the activation of common or rare category exemplars. Our behavioral findings provide additional evidence for such a dissociation, as reaction times were found to be significantly slower for rare relative to common responses.</p></sec><sec id="s2-2-2"><title>Learning phase</title><p>Beyond our primary questions about test phase activation, multivoxel analysis of the learning phase can provide additional information about how participants processed stimuli in the present task. Generally, both similarity-based models and dissimilarity-based models such as the dissGCM predict that features which are most informative about the correct category will contribute more to categorization decisions during learning. With respect to multivoxel predictions, this means that activation patterns elicited during learning should contain more information about the predictive features (objects or scenes) than non-predictive features (faces), and both of these types of information should be activated more strongly than non-present features. <xref ref-type="fig" rid="fig4">Figure 4</xref> depicts mean pattern similarities for predictive, non-predictive, and non-present visual stimulus categories during the learning phase for both common and rare disease trials. As anticipated, a linear mixed effects model collapsed across trial type revealed that pattern similarity to the visual category was the strongest for perfectly predictive features (M <italic>= </italic>.065), followed by the non-predictive but present features (M = −0.050) and the non-present features (M = −0.145), (<italic>F</italic> (2, 42)=54.8, p&lt;0.001). This finding, whereby activation patterns elicited for stimuli during learning are most similar to predictive features, is consistent with recent studies using MVPA to measure dimensional selective attention in categorization and reinforcement learning (<xref ref-type="bibr" rid="bib38">Mack et al., 2013</xref>, <xref ref-type="bibr" rid="bib37">Mack et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Leong et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">O'Bryan et al., 2018</xref>). For common trials, pairwise comparisons revealed significant differences between pattern similarity to perfect and imperfect predictors (<italic>t</italic> (21)=3.38, p=0.003), perfect predictors and non-present features (<italic>t</italic> (21)=5.71, p&lt;0.001), and between imperfect predictors and non-present features (<italic>t</italic> (21)=4.27, p&lt;0.001). Likewise, for rare trials we found significant differences between pattern similarity to perfect and imperfect predictors (<italic>t</italic> (21)=5.69, p&lt;0.001), perfect predictors and non-present features (<italic>t</italic> (21)=9.11, p&lt;0.001), and between imperfect predictors and non-present features in the expected directions (<italic>t</italic> (21)=3.11, p=0.005) (see <xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.008</object-id><label>Figure 4.</label><caption><title>Multivoxel pattern similarity to each feature type during the learning phase (mean ± SEM).</title><p>The left panel is for trials predictive of a common disease, and the right for trials predictive of a rare disease. Red points represent perfect predictors, purple points represent imperfect predictors (faces), and blue points represent non-present features. **p &lt; 0.01, ***p &lt; 0.001.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig4-v2"/></fig><p>Although the greater contribution of predictive features to multivoxel activation patterns during learning is a straightforward prediction that is consistent with any model, a further question is how such activation patterns during learning contribute to later test performance. As with the test phase, dissimilarity-based theories make the somewhat counterintuitive prediction that it is specifically what people learn about the common category that is driving later choices of the rare category. Mechanistically, dissimilarity-based generalization is thought to involve a comparison process whereby memory-based representations of learned category exemplars are retrieved and then contrasted with the stimulus currently under consideration. Because of the base rate manipulation in an IBRE task, people are expected to retrieve information about the common category more readily when faced with ambiguous transfer stimuli, thus making them more likely to choose the rare category in such cases via elimination (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Winman et al., 2005</xref>).</p><p>Because the dissGCM is designed to explain group-level generalization patterns rather than individual differences per se, the model incorporates base rate information using exemplar-specific memory strength parameters (<italic>t</italic><sub>j</sub>), which we fix at the true 3:1 category base rates across subjects. However, a realistic expectation is that subjects will differ in the extent to which they learn (and eventually recall) the predictive values associated with common and rare exemplars. Here, our pattern similarity measure provides an opportunity to investigate whether individuals who more strongly represent information associated with the common category over the course of learning neglect the category base rates more frequently at test, as predicted by dissimilarity-based theories of IBRE. This prediction is in direct contrast to the dominant similarity-based explanation of IBRE, which posits that it is specifically a stronger learned association between rare perfect predictors and their category that drives later rare category selections for the ambiguous test probes (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>, <xref ref-type="bibr" rid="bib32">Kruschke, 2001</xref>). Accordingly, we tested these hypotheses by computing Pearson correlations between mean pattern similarity to each stimulus dimension during the learning phase and subjects’ choice behavior on the critical ambiguous trials.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref> depicts the associations between BOLD pattern similarity to common and rare stimulus dimensions during learning and base rate neglect. Consistent with dissimilarity-based accounts, we found that greater activation of multivoxel patterns associated with common perfect predictors during learning was correlated with a higher proportion of rare choices on the ambiguous test trials (<italic>r</italic> = 0.590, <italic>t</italic> (20)=3.27, p=0.004). Alternatively, we found no significant relationship between activation of multivoxel patterns during learning and choice proportions on IBRE trials for rare perfect predictors (<italic>r</italic> = 0.114, <italic>t</italic> (20)=0.512, p=0.614), common faces (<italic>r</italic> = −0.163, <italic>t</italic> (20)=−0.737, p=0.470), or rare faces (<italic>r</italic> = −0.039, <italic>t</italic> (20)=−0.173, p=0.865). A linear mixed effects model including factors for each item and participants’ rare choice proportions was used to test for significant differences in slope among the above associations. The model revealed an interaction between pattern similarity to different learning phase items and base rate neglect (<italic>F</italic> (3, 60)=2.97, p=0.039). Specifically, the relationship between pattern similarity to common perfect predictors and base rate neglect was stronger, in the positive direction, than those for common faces (<italic>t</italic> (60)=2.72, p=0.009), and rare faces (<italic>t</italic> (60)=2.40, p=0.020). Likewise, the difference in positive slope between pattern similarity and base rate neglect for common versus rare perfect predictors was marginally significant (<italic>t</italic> (60)=1.88, p=0.065).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.009</object-id><label>Figure 5.</label><caption><title>Associations between multivoxel pattern similarity to stimulus dimensions during the learning phase and individual differences in base rate neglect.</title><p>For each graph, the y-axis depicts the proportion of rare responses made by each subject on ambiguous test trials, while the x-axis depicts subjects’ mean BOLD pattern similarity to a respective stimulus dimension over the course of learning. **p &lt; 0.01.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig5-v2"/></fig></sec></sec><sec id="s2-3"><title>Model-based univariate results</title><p>By revealing a link between activation of common feature patterns and the IBRE, our multivoxel results suggest that dissimilarity-based evidence against unchosen categories contributes to choice behavior in the present task. However, it remains an open question whether such dissimilarity processes involve distinct neural or cognitive mechanisms beyond those thought to underlie basic similarity processes. Importantly, similarity-based theories propose that a single, non-inferential cognitive process is responsible for generalization patterns across trials in the IBRE task (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>, <xref ref-type="bibr" rid="bib32">Kruschke, 2001</xref>), and thus it is anticipated that a network of brain regions associated with similarity-based generalization underlies choice across task contexts in the present study. Although the dissGCM is agnostic as to whether using dissimilarity as evidence is more cognitively demanding than relying on similarity alone, previous theories of IBRE positing dissimilarity processes propose that the use of contrastive evidence is inherently inferential (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Winman et al., 2005</xref>). Accordingly, the latter account would predict a unique neural topography associated with dissimilarity-based evidence, including regions known to be involved in higher-level, symbolic reasoning.</p><p>To test whether similarity- and dissimilarity-based evidence rely on different brain regions, we modeled univariate voxel-wise activation using trial-by-trial estimates of similarity- and dissimilarity-based evidence derived from the dissGCM. Specifically, the overall evidence <italic>v</italic> for the winning category on each test trial was decomposed into two separate regressors: one for summed similarity to the winning category, and the other for summed dissimilarity to the non-winning categories. The regions associated with dissimilarity-based evidence in this analysis are thus distinct from those negatively associated with similarity-based evidence because they are derived from evidence against the alternative, non-winning category.</p><p>Our analysis showed that greater similarity-based contributions to the winning category were associated with activation in the MTL (left hippocampus) vmPFC, and primary motor cortex (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, depicted in red; <xref ref-type="table" rid="table2">Table 2</xref>). These results are consistent with findings from other model-based fMRI studies suggesting that the MTL is involved in similarity-based retrieval (<xref ref-type="bibr" rid="bib17">Davis et al., 2012a</xref>, <xref ref-type="bibr" rid="bib18">Davis et al., 2012b</xref>). Likewise, the engagement of vmPFC corroborates recent studies suggesting that this region tracks higher relative evidence for categorization decisions (<xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">O'Bryan et al., 2018</xref>). The positive relationship between vmPFC and similarity processes may also be reflective of attention to strong predictors (<xref ref-type="bibr" rid="bib51">Sharpe and Killcross, 2015</xref>; <xref ref-type="bibr" rid="bib43">Nasser et al., 2017</xref>) or the application of familiar category rules (<xref ref-type="bibr" rid="bib5">Boettiger and D'Esposito, 2005</xref>; <xref ref-type="bibr" rid="bib36">Liu et al., 2015</xref>), both of which are consistent with similarity-based accounts of IBRE that attribute choice to a well-established association between perfect predictors and their outcomes that is driven by attention (e.g. <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>). We also found that greater contributions of similarity-based evidence were positively associated with activation in the primary motor cortex. While more anterior motor-planning regions such as pre-SMA and SMA tend to be associated with rule acquisition processes (e.g. <xref ref-type="bibr" rid="bib5">Boettiger and D'Esposito, 2005</xref>), primary motor cortex has been found to track increasing levels of response automaticity in categorization tasks (<xref ref-type="bibr" rid="bib57">Waldschmidt and Ashby, 2011</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.010</object-id><label>Figure 6.</label><caption><title>Results from the model-based univariate analysis.</title><p>(<bold>A</bold>) Depicts activation that tracks similarity-based contributions to choice (summed similarity to the winning category). Red depicts activation positively correlated with similarity-based contributions and blue depicts negatively correlated activation. (<bold>B</bold>) Depicts brain regions that are positively correlated with dissimilarity-based contributions to choice (summed dissimilarity to the non-winning category).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36395-fig6-v2"/></fig><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.36395.011</object-id><label>Table 2.</label><caption><title>Activated clusters and peaks for the fMRI results in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Contrast</th><th valign="top">Regions</th><th valign="top">Peak <italic>t</italic>-value</th><th valign="top">Peak MNI coordinates (x,y,z)</th><th valign="top">Number of voxels</th><th valign="top">Cluster <italic>P</italic></th></tr></thead><tbody><tr><td valign="top">Similarity &gt; 0</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top"/><td valign="top">Rostral and ventral medial <break/>prefrontal cortex</td><td valign="top">7.76</td><td valign="top">0, 54, –2</td><td valign="top">2268</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Middle temporal gyrus</td><td valign="top">5.74</td><td valign="top">64, –6, −14</td><td valign="top">1050</td><td valign="top">p=0.016</td></tr><tr><td valign="top"/><td valign="top">Precentral gyrus</td><td valign="top">7.65</td><td valign="top">42, –16, 62</td><td valign="top">1031</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Precentral gyrus</td><td valign="top">4.81</td><td valign="top">0, –30, 58</td><td valign="top">463</td><td valign="top">p=0.008</td></tr><tr><td valign="top"/><td valign="top">Middle temporal gyrus</td><td valign="top">4.98</td><td valign="top">−62, –2, −16</td><td valign="top">322</td><td valign="top">p=0.016</td></tr><tr><td valign="top"/><td valign="top">Parietal operculum cortex</td><td valign="top">5.74</td><td valign="top">−34, –30, 18</td><td valign="top">282</td><td valign="top">p=0.027</td></tr><tr><td valign="top"/><td valign="top">Hippocampus</td><td valign="top">5.25</td><td valign="top">−22, –18, −16</td><td valign="top">271</td><td valign="top">p=0.019</td></tr><tr><td valign="top"/><td valign="top">Lateral occipital cortex (inferior)</td><td valign="top">4.68</td><td valign="top">50, –72, 12</td><td valign="top">157</td><td valign="top">p=0.039</td></tr><tr><td valign="top">Similarity &lt; 0</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top"/><td valign="top">Superior parietal and lateral <break/>occipital cortex (superior)</td><td valign="top">8.43</td><td valign="top">−44, –46, 58</td><td valign="top">5123</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Middle frontal gyrus</td><td valign="top">7.01</td><td valign="top">−52, 12, 36</td><td valign="top">2491</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Dorsal medial PFC</td><td valign="top">9.00</td><td valign="top">−2, 18, 46</td><td valign="top">917</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Cerebellum</td><td valign="top">6.11</td><td valign="top">28, –64, −28</td><td valign="top">769</td><td valign="top">p=0.002</td></tr><tr><td valign="top"/><td valign="top">Middle frontal gyrus</td><td valign="top">6.23</td><td valign="top">32, 2, 62</td><td valign="top">730</td><td valign="top">p=0.002</td></tr><tr><td valign="top"/><td valign="top">Middle frontal gyrus</td><td valign="top">5.89</td><td valign="top">44, 36, 30</td><td valign="top">391</td><td valign="top">p=0.009</td></tr><tr><td valign="top"/><td valign="top">Inferior temporal gyrus</td><td valign="top">6.09</td><td valign="top">−54, –52, −12</td><td valign="top">375</td><td valign="top">p=0.009</td></tr><tr><td valign="top"/><td valign="top">Inferior temporal gyrus</td><td valign="top">6.53</td><td valign="top">60, –52, −10</td><td valign="top">271</td><td valign="top">p=0.016</td></tr><tr><td valign="top"/><td valign="top">Cerebellum</td><td valign="top">6.08</td><td valign="top">−28, –60, −32</td><td valign="top">186</td><td valign="top">p=0.031</td></tr><tr><td valign="top"/><td valign="top">Thalamus</td><td valign="top">4.88</td><td valign="top">−10, –18, 10</td><td valign="top">175</td><td valign="top">p=0.038</td></tr><tr><td valign="top">Dissimilarity &gt; 0</td><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/></tr><tr><td valign="top"/><td valign="top">Occipital cortex</td><td valign="top">7.55</td><td valign="top">12, –78, 12</td><td valign="top">1372</td><td valign="top">p&lt;0.001</td></tr><tr><td valign="top"/><td valign="top">Fusiform and lateral occipital <break/>cortex (inferior)</td><td valign="top">6.82</td><td valign="top">42, –60, −18</td><td valign="top">865</td><td valign="top">p=0.002</td></tr><tr><td valign="top"/><td valign="top">Fusiform and lateral occipital <break/>cortex (inferior)</td><td valign="top">5.97</td><td valign="top">−36, –52, −18</td><td valign="top">575</td><td valign="top">p=0.003</td></tr><tr><td valign="top"/><td valign="top">Middle frontal gyrus</td><td valign="top">5.00</td><td valign="top">54, 16, 34</td><td valign="top">255</td><td valign="top">p=0.020</td></tr><tr><td valign="top"/><td valign="top">Frontal pole (rostrolateral PFC)</td><td valign="top">5.93</td><td valign="top">−42, 52, –6</td><td valign="top">130</td><td valign="top">p=0.047</td></tr></tbody></table></table-wrap><p>The dlPFC, dorsomedial PFC, and posterior parietal cortex were found to be negatively correlated with similarity-based evidence for the chosen category (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, depicted in blue; <xref ref-type="table" rid="table2">Table 2</xref>). This fronto-parietal network is generally associated with rule-based category learning (<xref ref-type="bibr" rid="bib22">Filoteo et al., 2005</xref>; <xref ref-type="bibr" rid="bib50">Seger and Cincotta, 2006</xref>; <xref ref-type="bibr" rid="bib53">Soto et al., 2013</xref>), and is thought to play a critical role in representing the uncertainty associated with categorization decisions (<xref ref-type="bibr" rid="bib21">DeGutis and D'Esposito, 2007</xref>; <xref ref-type="bibr" rid="bib49">Seger et al., 2015</xref>; <xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>). Thus, our results are consistent with these findings, and moreover, suggest that dlPFC and functionally related fronto-parietal regions may be engaged in cases where probes fail to elicit a strong similarity-based match with stored category exemplars.</p><p>Contrastingly, dissimilarity-based evidence was positively correlated with activation in the left rlPFC (<xref ref-type="fig" rid="fig6">Figure 6B</xref>; <xref ref-type="table" rid="table2">Table 2</xref>), consistent with our hypothesis that this type of evidence might encourage more symbolic processes believed to underlie the rlPFC’s contribution to category learning (<xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Paniukov and Davis, 2018</xref>). No clusters were significantly negatively associated with dissimilarity-based evidence. Comparing the statistical maps in <xref ref-type="fig" rid="fig6">Figure 6A and B</xref>, it is apparent that greater relative contributions of dissimilarity-based evidence do not necessitate smaller contributions of similarity-based evidence in the dissGCM: if these regressors were anticorrelated, one would expect the regions associated with dissimilarity processes to resemble the fronto-parietal network we found to be negatively associated with similarity. Instead, our results show that using contrastive evidence uniquely engages the rlPFC, in line with dual-process theories that suggest dissimilarity-based processing may distinctly depend on higher-level, abstract reasoning. Despite obvious differences between the activation patterns elicited for each contrast, it is notable that all three maps (positive similarity, negative similarity, and positive dissimilarity) revealed significant activation in portions of ventral occipitotemporal cortex. These regions (lateral occipital cortex, inferior temporal gyrus, and fusiform gyrus) have well-established roles in representing visual object categories, including those used as stimulus dimensions in the present study (<xref ref-type="bibr" rid="bib24">Grill-Spector and Weiner, 2014</xref>). Accordingly, it is possible that the engagement of these regions in our study reflects feature-based attention, exemplar retrieval, or a combination of both processes that occurs regardless of the respective contributions that similarity- and dissimilarity-based evidence make to a decision.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The present study employed model-based fMRI to test how similarity and dissimilarity contribute to the inverse base rate effect (IBRE) and how these types of evidence relate to neural mechanisms that support category learning. The dominant theory behind the IBRE suggests that it arises from attentional processes that make ambiguous items containing features of rare and common categories seem more similar to members of the rare category. Here we find support for the hypothesis that dissimilarity-based evidence also contributes to the IBRE: people may categorize the ambiguous stimuli as members of the rare category not only because of their similarity to the rare category, but also because of their dissimilarity to members of the common category.</p><p>The dissGCM, an extension of the GCM that allows for the use of dissimilarity-based evidence in categorization behavior, predicted two novel observations in the neuroimaging data. First, as predicted by the dissGCM’s relative contribution of similarity- and dissimilarity-based evidence during the ambiguous trials, multivoxel analysis suggested stronger activation of patterns associated with features of the common category when participants classified ambiguous stimuli as rare. Second, model-based univariate analysis revealed that measures of similarity- and dissimilarity-based evidence had unique neural topographies. Similarity-based evidence for the winning category was positively correlated with regions of the hippocampus, vmPFC, and primary motor cortex. In contrast, dlPFC, dorsomedial PFC, and posterior parietal cortex were negatively correlated with similarity-based contributions. Dissimilarity-based evidence against non-winning categories was positively correlated with the left rlPFC.</p><p>The present results raise several important questions about the cognitive and neural mechanisms underlying people’s use of base rate information. Previous theories arguing for dissimilarity-like processes as explanations of IBRE have argued that they arise from mechanisms rooted in higher-level propositional logic that fundamentally differ from the similarity-based mechanisms posited by dominant theories (<xref ref-type="bibr" rid="bib29">Juslin et al., 2001</xref>). As illustrated by the dissGCM, such dissimilarity-based processes can be viewed as simple extensions of similarity-based processing and need not depend on the existence of a functionally separate categorization system. At the same time, our neuroimaging results suggest that dissimilarity, but not similarity-based evidence may arise from processing in rlPFC regions that are known to be involved with higher-level reasoning and problem solving (<xref ref-type="bibr" rid="bib15">Christoff et al., 2001</xref>; <xref ref-type="bibr" rid="bib9">Bunge et al., 2005</xref>, <xref ref-type="bibr" rid="bib8">Bunge et al., 2009</xref>). One possibility for reconciling these theories is that the dissimilarity-based evidence involves more abstract or symbolic feature processing than pure similarity processes, and this additional processing taps rlPFC regions. This is consistent with our recent model-based fMRI results, which demonstrate that rlPFC tracks measures of relational encoding in category learning, but otherwise this type of category learning may rely on the same basic similarity-based mechanisms as simpler feature-based learning (<xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>).</p><p>By establishing that the rlPFC is engaged when participants incorporate dissimilarity-based evidence into categorization decisions, our research adds to a growing literature aiming to pinpoint a domain-general computational role for this region. A common thread among tasks shown to engage the rlPFC is that they tend to involve combining across disparate representations to form the basis for a decision – whether those representations comprise confidence estimates and subjective value (<xref ref-type="bibr" rid="bib20">De Martino et al., 2013</xref>), visual features and their relations (<xref ref-type="bibr" rid="bib10">Bunge, 2004</xref>; <xref ref-type="bibr" rid="bib8">Bunge et al., 2009</xref>; <xref ref-type="bibr" rid="bib16">Davis et al., 2017</xref>), or expected rewards and their relative uncertainties (<xref ref-type="bibr" rid="bib6">Boorman et al., 2009</xref>; <xref ref-type="bibr" rid="bib3">Badre et al., 2012</xref>). Likewise, in the case of the current study, the evidence that an ambiguous stimulus is similar to a given category must be combined with the evidence that the stimulus is dissimilar to the other possible categories. Although the dissGCM instantiates dissimilarity as a simple transformation of similarity, the involvement of rlPFC when participants place more reliance on dissimilarity-based evidence may be attributable to increasing demands for integrating evidence across several abstract representations. A decision made on pure similarity-based evidence would require no such integration. This hypothesis accords with recent findings implicating the rlPFC in evaluative processes for categorization tasks that require candidate rules to be weighed over the course of several trials, relative to matching tasks where a rule can be known with certainty following a single correct trial (<xref ref-type="bibr" rid="bib46">Paniukov and Davis, 2018</xref>).</p><p>One question that has arisen repeatedly in the literature on the IBRE is whether it reflects an inherent irrationality in decision making. When viewed through the lens of basic similarity-based attentional processes (e.g. <xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>, <xref ref-type="bibr" rid="bib32">Kruschke, 2001</xref>), the IBRE appears to arise from very simple learning mechanisms that are not particularly tied to higher-level rationality, and rare choices seem to indicate a lack of knowledge of the base rates. Indeed, in a separate model fit, we attempted to fit the standard similarity-based GCM to the key pattern on the ambiguous trials. However, the standard GCM was only able to predict a greater proportion of rare choices if accurate knowledge of the exemplar base rates was eliminated (all values of <italic>t<sub>j</sub></italic> = 1 or fit as free parameters). In contrast, accurate knowledge of the category base rates directly contributes to the greater dissimilarity-based evidence against the common category. Thus from the dissGCM perspective, participants are perfectly knowledgeable about the base rates in the present task, but they use this knowledge in a way not anticipated by pure similarity-based models. However, whether or not this use of dissimilarity-based evidence constitutes irrationality is a deeper question that cannot be answered based purely on the present results.</p><p>How or whether the use of dissimilarity is encouraged by the standard IBRE design, compared with other types of categorization problems, is an open question. The dissGCM was originally developed to explain sequential effects in categorization (<xref ref-type="bibr" rid="bib54">Stewart and Morin, 2007</xref>), and its success in this domain suggests that dissimilarity processes, such as those revealed here, may be present in many categorization tasks that are more familiar in the neuroimaging literature. However, how much a task encourages dissimilarity-based processing may vary considerably and depend on a number of factors. For example, purely attentional accounts posit that strong initial learning of the common category leads people to learn the rare category by the features that distinguish it from the common (<xref ref-type="bibr" rid="bib39">Markman, 1989</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>). Learning-order effects do appear to play a role in the IBRE: previous studies have shown that using blocked or unequally distributed category frequencies during training leads participants to favor later-learned categories on ambiguous test probes, even when overall base rates are held constant (<xref ref-type="bibr" rid="bib40">Medin and Bettger, 1991</xref>; <xref ref-type="bibr" rid="bib31">Kruschke, 1996</xref>).</p><p>Early studies on the role of order and blocking on IBRE are similar to current work on blocked versus interleaved learning in the broader categorization literature (<xref ref-type="bibr" rid="bib4">Birnbaum et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Carvalho and Goldstone, 2014</xref>, <xref ref-type="bibr" rid="bib12">Carvalho and Goldstone, 2015</xref>; <xref ref-type="bibr" rid="bib23">Goldwater et al., 2018</xref>). In blocked learning, categories are learned by viewing a number of items from the same category before switching to other categories. For example, in the present case, if we had used blocked learning, participants may see an entire block of Disease 1 examples, and then blocks of Disease 2, 3, and 4, but the examples of the Diseases would not be intermixed. In interleaved learning, the standard for category learning, items from all categories are presented in a random order such that the examples of the different categories are intermixed. Blocked learning tends to lead participants to focus more on stimulus features that are shared with members of the same category, whereas interleaved learning tends to lead participants to focus more on features that differentiate categories. Interestingly, while not an interleaved versus blocked manipulation per se, frequency manipulations such as those used in the present study have an effect of creating more blocking within common categories – common categories are more likely to follow examples of the same category, and interleaving within rare categories. Although discovered long after the initial IBRE studies, blocked versus interleaved learning theories may offer a concurring explanation of the IBRE that does not depend on differences in the rate at which common and rare categories are learned. However, formal computational models of blocked versus interleaved learning have thus far focused on how these scenarios produce differences in selective attention to stimulus features that are characteristic (blocked) or diagnostic (interleaved) of a category, and are pure similarity-based models such as the original GCM (<xref ref-type="bibr" rid="bib13">Carvalho and Goldstone, 2017</xref>). Contrastingly, our MVPA and univariate fMRI results show that pure similarity-based processing cannot fully explain the IBRE, and thus strongly suggest that dissimilarity processes contribute to the IBRE.</p><p>To investigate how learning manipulations, such as blocked versus interleaved, or individual differences in learning influence the mechanisms we propose here, it will be critical for future research to build full learning models of the dissGCM. The dissGCM, like the standard GCM, is a model of asymptotic categorization performance and generalization, and thus is not well-equipped to account for learning dynamics or individual differences. For these reasons, our individual difference analysis focused on using MVPA estimates from individual stimuli rather than formal model-based analysis. Nonetheless, these analyses reveal important individual differences that are consistent with dissimilarity-based theories more broadly. Dissimilarity-based theories posit that one of the reasons IBRE arises is because the common category becomes more thoroughly established in memory during learning, which leads participants to retrieve this information more readily at test. From this perspective, participants who learn the common category more strongly should consequently exhibit base rate neglect more frequently. Consistent with these predictions of dissimilarity-based theories, pattern similarity analyses revealed that participants who more strongly activated information associated with common categories during learning engaged in base rate neglect more often at test. While these results suggest that individual differences in learning contribute to IBRE, they nonetheless point to a critical need to develop a full learning-based version of the dissGCM that can be applied at the individual level to capture these differences. For example, one possibility is that participants’ weighting of similarity and dissimilarity (the <italic>s</italic> parameter) changes over learning based on the participants’ learning rates and factors related to blocking versus interleaved presentation (<xref ref-type="bibr" rid="bib13">Carvalho and Goldstone, 2017</xref>). However, such a model would require extensive additional data to validate, and thus is beyond the scope of the present study.</p><p>The IBRE exemplifies a case in cognitive neuroscience where independent models that predict essentially the same behavioral patterns make very different assumptions about the cognitive processes, and accordingly, brain states, involved in producing the behavior. Our findings from the test phase represent a critical step forward in an emerging area of research using multivariate fMRI to reveal that qualitatively distinct brain states may reflect the use of multiple response strategies in the face of identical stimuli (e.g. <xref ref-type="bibr" rid="bib38">Mack et al., 2013</xref>). Consistent with past research using MVPA to decode learned selective attention (<xref ref-type="bibr" rid="bib38">Mack et al., 2013</xref>, <xref ref-type="bibr" rid="bib37">Mack et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Leong et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">O'Bryan et al., 2018</xref>), multivoxel patterns associated with predictive features were more strongly activated than imperfectly predictive features during the learning phase. Using the same approach to decode which information participants were focusing on during ambiguous test trials, we found stronger activation of patterns associated with common compared with rare stimulus features, but importantly, this pattern only emerged in cases where participants chose the rare category. Moreover, rare category selections were accompanied by slower RTs relative to common selections. These results are consistent with a higher-level, dissimilarity-based process where activating information associated with common exemplars provides contrastive evidence against the well-established common category. Alternatively, it is possible that participants are more likely to respond according to the base rates when the ambiguous stimuli elicit a strong similarity-based match: given our RT results along with the correlation between similarity-based evidence and motor cortex engagement, in these cases subjects may revert to habitual response patterns from the learning phase and simply choose the more well-established (common) category. However, understanding the precise cognitive mechanisms that contribute to these response-dependent activation patterns remains a direction for future research.</p><p>Interestingly, while our findings argue against the prediction from similarity-based models that the IBRE arises because rare features become more similar to their associated category, the observed attention weight parameters <italic>w</italic><sub>k</sub> from the model fits are consistent with a key part of similarity theory – that there is greater selective attention allocated to the rare feature dimension. Indeed, the rare feature dimensions outweighed the common features for both sets of categories in our data. However, these larger attention weights did not seem to drive greater pattern similarity to the rare feature dimension in our multivoxel results. We predict that our multivoxel results are not driven directly by simple feature-based attention, but instead indicate some combination of attention and memory-based retrieval of the category exemplars. Pattern similarity measures in ventral temporal cortex have been shown to effectively index both dimensional selective attention (<xref ref-type="bibr" rid="bib33">Leong et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">O'Bryan et al., 2018</xref>) and the retrieval of non-present, associated stimuli (e.g. <xref ref-type="bibr" rid="bib59">Zeithamova et al., 2012</xref>; for review, see <xref ref-type="bibr" rid="bib48">Rissman and Wagner, 2012</xref>). Rather than adjudicating between whether the multivoxel patterns in the current study are more likely to indicate attention or memory, a possibility that accords with both potential explanations is that these pattern similarity indices reflect information that is actively represented in working memory, either by way of visual cueing or reinstated long-term memories (<xref ref-type="bibr" rid="bib35">Lewis-Peacock and Postle, 2008</xref>). In cases in which multiple or competing stimulus representations are present in WM, as may be expected for the ambiguous IBRE trials, multivoxel patterns should be most similar to whichever representation is consciously attended (<xref ref-type="bibr" rid="bib34">Lewis-Peacock et al., 2012</xref>). However, given the design of the current study we are unable to rule out the possibility that implicitly activated or post-decisional feature representations contribute to our pattern similarity results. Future studies may wish to combine multivoxel pattern analysis with eye-tracking (e.g. <xref ref-type="bibr" rid="bib33">Leong et al., 2017</xref>) to better understand the unique contributions that attention and memory make to the present results.</p><p>In conclusion, using model-based fMRI analysis, we found evidence that extreme cases of base rate neglect such as the IBRE may arise from a combination of similarity- and dissimilarity-based processes. Accordingly, measures of neural activation suggest that people may be more strongly relying on evidence about how dissimilar an item is to common categories when faced with ambiguous stimuli. Furthermore, dissimilarity processes have a unique cortical topography that includes the rostrolateral PFC, a region believed to be involved with more symbolic feature processing.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Twenty-four healthy right-handed volunteers (age range 18–58; 13 women) participated in the study for $35. All protocols were approved by the Texas Tech University IRB. Two participants were excluded, one for falling asleep and the other for registration failures in the first five scanning runs.</p><sec id="s4-1"><title>Behavioral protocol</title><p>The study consisted of three phases: localizer, learning, and test. The localizer phase consisted of two scanning runs (run length = 5 min 10 s) in which participants classified images based on whether they contained a face, an object, or a scene. Each image was presented for 2.5 s during which participants were asked to respond ‘Scene (1), Face (2), or Object (3)?' Each trial was separated with random fixation drawn from a truncated exponential distribution with mean = 3 s. Over the duration of the localizer phase, subjects categorized 38 examples of each stimulus type. The face, object, and scene images used were black-and-white squares presented on a white background with black text. The stimuli used during the localizer runs were presented in a random order, and did not include any of the images used for the experimental task.</p><p>In the learning phase, participants learned a classic IBRE category structure (<xref ref-type="bibr" rid="bib41">Medin and Edelson, 1988</xref>; see <xref ref-type="fig" rid="fig1">Figure 1</xref>). The features used for the stimuli included examples of faces, objects, and scenes not shown in the localizer phase. Participants were given an epidemiological cover story asking them to predict whether hypothetical patients would contract a disease based on the people they have been in contact with (faces), the objects they have used (objects), and the places they have been (scenes). On each trial of the learning phase, participants would see a stimulus for 3 s and were asked to answer ‘Disease 1, 2, 3, or 4?’ This was followed by random fixation, feedback (1.75 s) in which they were told whether they were right or wrong and the correct answer, and additional fixation. The same distribution was used to generate fixations as in the localizer phase. Faces were always assigned to the imperfectly predictive feature dimensions, whereas objects and scenes were perfectly predictive and associated with only one disease (<xref ref-type="fig" rid="fig1">Figure 1</xref>). To ensure that no visual stimulus category differed in overall frequency, one common disease was always associated with objects and the other scenes, and likewise for rare diseases. Participants were randomly assigned to one of two conditions to balance which images were presented together during learning and test, and disease labels were randomized across participants. Within-pair stimulus position (left or right) was randomized on each trial, and the presentation order of feature pairs was randomized within each block for every participant. The learning phase was spread over three scanning runs (run length = 5 min 10 s), and four blocks of the stimulus set were presented per run, resulting in a total of 12 blocks and 96 trials for the learning phase. The progression of a learning trial is depicted in the bottom panel of <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><p>During the test phase, participants completed trials with both new and old exemplars and classified them as ‘Disease 1, 2, 3, or 4?', but no longer received feedback. New items included all possible single and two-feature combinations of the perfectly predictive features (see <xref ref-type="table" rid="table1">Table 1</xref>, Results). Trials were 3 s and separated by random fixation as described above. Like the learning phase, the test phase occurred over three consecutive scanning runs (run length = 5 min 10 s). Each item in the stimulus set was encountered twice per run, with the exception of the ambiguous perfect predictor pairs which were repeated four times per run. This resulted in 24 instances of ambiguous scene-object pairs, and 48 instances of the ambiguous trials overall for each participant. Presentation order of the test items was randomized for each of the three runs, with participants rating two test sets per run, resulting in a total of 156 test trials.</p></sec><sec id="s4-2"><title>Model</title><p>The dissimilarity generalized context model (dissGCM; <xref ref-type="bibr" rid="bib54">Stewart and Morin, 2007</xref>) is an extension of the generalized context model (<xref ref-type="bibr" rid="bib44">Nosofsky, 1986</xref>) that accounts for choice using a combination of similarity- and dissimilarity-based evidence. Like the original GCM, stimuli are represented as points in a multidimensional feature space. The model computes distances in this space between probe stimuli <italic>Si</italic> and stored exemplars <italic>Sj</italic> along each dimension <italic>k</italic>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>r</italic> defines the metric of the space, here assumed to be one (city-block). The <italic>w<sub>k</sub></italic> indicates dimensional attention weights, which have the function of stretching the distance along strongly attended dimensions, and are constrained to sum to one.</p><p>Distances are converted to similarities via an exponential transform:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>c</italic> is a specificity parameter that controls the rate at which similarity decays as a function of distance.</p><p>The first contribution of evidence for a given category comes from the summed similarity between a probe and all stored exemplars for that category, consistent with the original GCM. DissGCM then combines this similarity-based contribution with the summed <italic>dissimilarity</italic> between a probe and the exemplars from all other categories. The overall evidence, <italic>v</italic>, for a category <italic>C<sub>A</sub></italic>, given stimulus <italic>S<sub>i</sub></italic> is:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">¬</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>s</italic> is a free parameter that determines how much the model weights similarity versus dissimilarity. The parameter <italic>t<sub>j</sub></italic> reflects exemplar-specific memory strength, which we fix at each exemplar’s true base rate during learning (1 for rare category exemplars, 3 for common category exemplars). Here, we also make the assumption that exemplars only contribute evidence (similarity or dissimilarity) if they have at least one positive feature match with a probe stimulus.</p><p>The model makes a prediction for how likely an item is to be classified as a member of a given category <italic>C<sub>A</sub></italic> by:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>b</italic> is a free parameter that reflects the baseline level of similarity for a category that has 0 positive feature matches. More generally, this parameter ensures that no predicted probabilities are 0 or 1, which interferes with the maximum likelihood-based model fits.</p><p>The model was fit to the group response frequencies for each option by minimizing the −2 * Log Likelihood using a differential evolution function optimizer. The overall fit was 4,314.588. The best fitting parameters for each of the dimension weights were <italic>w</italic><sub>1</sub> (face 1)=0.277, <italic>w</italic><sub>2</sub> (common scene)=0.665, <italic>w</italic><sub>3</sub> (rare object)=0.887, <italic>w</italic><sub>4</sub> (face 2)=0.170, <italic>w</italic><sub>5</sub> (common object)=0.712, and <italic>w</italic><sub>6</sub> (rare scene)=0.879); <italic>c</italic> = 9.05; <italic>s</italic> = 0.946; <italic>b</italic> = 0.023.</p></sec><sec id="s4-3"><title>Image acquisition</title><p>Imaging data were acquired on a 3.0 T Siemens Skyra MRI scanner at the Texas Tech Neuroimaging Institute. Structural images were acquired in the sagittal plane using MPRAGE whole-brain anatomical scans (TR = 1.9 s; TE = 2.44 ms; <italic>θ</italic> = 9°; FOV = 250 × 250 mm; matrix = 256 × 256 mm; slice thickness = 1.0 mm, slices = 192). Functional images were acquired using a single-shot T2*-weighted gradient echo EPI sequence (TR = 2.5 s; TE = 25 ms; <italic>θ</italic> = 75°; FOV = 192 × 192 mm; matrix = 64 × 64; slice thickness = 3 mm).</p></sec><sec id="s4-4"><title>fMRI analysis and preprocessing</title><p>Functional data were preprocessed and analyzed using FSL (<ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl">www.fmrib.ox.ac.uk/fsl</ext-link>). Anatomical images were preprocessed using Freesurfer (autorecon1). Functional images were skull stripped, motion corrected, prewhitened, and high-pass filtered (cutoff: 60 s). For the model-based univariate analysis, functional images were spatially smoothed using a 6 mm FWHM Gaussian kernel. No smoothing was performed on functional data used for the multivoxel analysis. First-level statistical maps were registered to the Montreal Neurological Institute (MNI)−152 template using 6-DOF boundary-based registration to align the functional image to the Freesurfer-processed high-resolution anatomical image, and 12-DOF affine registration to the MNI-152 brain.</p></sec><sec id="s4-5"><title>Model-based univariate analysis</title><p>The model-based univariate analysis employed a standard three-level mixed effects model carried out in FSL’s FEAT program. The first-level model included an EV for stimulus presentation and two model-based parametric modulators: similarity- and dissimilarity-based evidence, computed from the dissGCM. Specifically, these regressors were obtained on a trial-by trial basis using <xref ref-type="disp-formula" rid="equ3">equation 3</xref> (see Model section), where the evidence contribution of summed similarity to the winning category (<italic>C<sub>A</sub></italic>; most probable category according to the model) is calculated as:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>and the evidence contribution of summed dissimilarity to non-winning categories with a positive feature match is calculated as:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">¬</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Both parametric modulators were centered and scaled (z-scored) within run. Additional explanatory variables (EVs) of no interest included motion parameters, their temporal derivatives, EVs to censor volumes exceeding a framewise displacement of 0.9 mm (<xref ref-type="bibr" rid="bib52">Siegel et al., 2014</xref>), and an EV to account for trials in which participants failed to make a behavioral response. Final statistical maps were corrected for multiple comparisons using a non-parametric cluster-mass-based correction with a cluster-forming threshold of <italic>t</italic> (21)=3.52 (p&lt;0.001, one-tailed).</p></sec><sec id="s4-6"><title>Multivoxel pattern analysis</title><p>RSA was conducted using the PyMVPA toolbox (<xref ref-type="bibr" rid="bib25">Hanke et al., 2009</xref>) and custom Python routines. To obtain trial-by-trial estimates of the hemodynamic response, we computed a β-map (<xref ref-type="bibr" rid="bib47">Rissman et al., 2004</xref>) for each stimulus onset using an LS-A procedure (<xref ref-type="bibr" rid="bib42">Mumford et al., 2012</xref>), simultaneously modeling the trials of interest as separate regressors in a GLM. These estimates were anatomically restricted to three ventral temporal ROIs that were maximally responsive to scene, object, and face information in the localizer data. Specifically, pattern estimates were spatially localized in visual stimulus category-specific ROIs by creating 6 mm spheres around subjects’ peak activation within anatomically defined regions in the Harvard-Oxford Atlas associated with category selectivity (objects: left inferior posterior temporal gyrus; scenes: bilateral parahippocampal gyrus; faces: right temporal occipital fusiform gyrus; <xref ref-type="bibr" rid="bib28">Ishai et al., 1999</xref>; <xref ref-type="bibr" rid="bib35">Lewis-Peacock and Postle, 2008</xref>; <xref ref-type="bibr" rid="bib34">Lewis-Peacock et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Grill-Spector and Weiner, 2014</xref>). The last trial of each run was automatically discarded from the multivoxel analysis to ensure stable estimation of the activation patterns for all trials. Additional explanatory variables (EVs) of no interest included motion parameters, their temporal derivatives, and EVs to censor volumes exceeding a framewise displacement of 0.9 mm.</p><p>For the primary pattern similarity analyses, we measured how much participants were activating scene, object, and face information on individual test phase trials by calculating mean correlation distance (1 – Pearson’s <italic>r</italic>) between activation patterns on each test trial and those elicited for each visual category during the localizer phase. For interpretative ease, the distances were converted to similarities using exp(- distance), and then standardized (<italic>z</italic>-scored) within participants. Source data and scripts used to create all figures and tables (e.g. R code, PyMVPA scripts, statistical maps for the model-based fMRI analysis) are freely available online at <ext-link ext-link-type="uri" xlink:href="https://osf.io/atbz7/">https://osf.io/atbz7/</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by start-up funds to TD from Texas Tech University. The authors declare no conflicts of interest.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Subjects provided written informed consent before taking part in the study, and all procedures involving human subjects were approved by the Texas Tech University Institutional Review Board.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.36395.012</object-id><label>Supplementary file 1.</label><caption><title>Number of trials where common and rare responses were made for each participant over the 24 ambiguous scene-object test trials.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-36395-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.36395.013</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-36395-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Source data and scripts used to create all figures and tables (e.g. R code, PyMVPA scripts, statistical maps for the model-based fMRI analysis) are posted to a publicly available online repository (Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://osf.io/atbz7/">https://osf.io/atbz7/</ext-link>). Raw fMRI data for the study organized according to Brain Imaging Data Structure (BIDS) guidelines are available at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds001302">https://openneuro.org/datasets/ds001302</ext-link>.</p><p>The following datasets were generated:</p><p><related-object content-type="generated-dataset" id="dataset1" source-id="https://osf.io/atbz7/" source-id-type="uri"><collab collab-type="author">Sean R O'Bryan</collab><year>2018</year><source>Model-based fMRI reveals dissimilarity processes underlying base rate neglect</source><ext-link ext-link-type="uri" xlink:href="https://osf.io/atbz7/">https://osf.io/atbz7/</ext-link><comment>Publicly available at the Open Science Framework</comment></related-object></p><p><related-object content-type="generated-dataset" id="dataset2" source-id="https://openneuro.org/datasets/ds001302" source-id-type="uri"><collab collab-type="author">Sean R O'Bryan</collab><collab collab-type="author">Darrell A Worthy</collab><collab collab-type="author">Evan J Livesey</collab><collab collab-type="author">Tyler Davis</collab><year>2018</year><source>Inverse Base Rate</source><ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds001302">https://openneuro.org/datasets/ds001302</ext-link><comment>Publicly available at the Open Neuro website (accession no. ds001302)</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Functional magnetic resonance imaging evidence for a hierarchical organization of the prefrontal cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>19</volume><fpage>2082</fpage><lpage>2099</lpage><pub-id pub-id-type="doi">10.1162/jocn.2007.19.12.2082</pub-id><pub-id pub-id-type="pmid">17892391</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Is the rostro-caudal axis of the frontal lobe hierarchical?</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>659</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1038/nrn2667</pub-id><pub-id pub-id-type="pmid">19672274</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Long</surname> <given-names>NM</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration</article-title><source>Neuron</source><volume>73</volume><fpage>595</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.025</pub-id><pub-id pub-id-type="pmid">22325209</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birnbaum</surname> <given-names>MS</given-names></name><name><surname>Kornell</surname> <given-names>N</given-names></name><name><surname>Bjork</surname> <given-names>EL</given-names></name><name><surname>Bjork</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Why interleaving enhances inductive learning: the roles of discrimination and retrieval</article-title><source>Memory &amp; Cognition</source><volume>41</volume><fpage>392</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.3758/s13421-012-0272-7</pub-id><pub-id pub-id-type="pmid">23138567</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boettiger</surname> <given-names>CA</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Frontal networks for learning and executing arbitrary stimulus-response associations</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>2723</fpage><lpage>2732</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3697-04.2005</pub-id><pub-id pub-id-type="pmid">15758182</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action</article-title><source>Neuron</source><volume>62</volume><fpage>733</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.05.014</pub-id><pub-id pub-id-type="pmid">19524531</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bravata</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Making medical decisions under uncertainty</article-title><source>Seminars in Medical Practice</source><volume>3</volume><fpage>6</fpage><lpage>13</lpage></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunge</surname> <given-names>SA</given-names></name><name><surname>Helskog</surname> <given-names>EH</given-names></name><name><surname>Wendelken</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Left, but not right, rostrolateral prefrontal cortex meets a stringent test of the relational integration hypothesis</article-title><source>NeuroImage</source><volume>46</volume><fpage>338</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.01.064</pub-id><pub-id pub-id-type="pmid">19457362</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunge</surname> <given-names>SA</given-names></name><name><surname>Wendelken</surname> <given-names>C</given-names></name><name><surname>Badre</surname> <given-names>D</given-names></name><name><surname>Wagner</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Analogical reasoning and prefrontal cortex: evidence for separable retrieval and integration mechanisms</article-title><source>Cerebral Cortex</source><volume>15</volume><fpage>239</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh126</pub-id><pub-id pub-id-type="pmid">15238433</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunge</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>How we use rules to select actions: a review of evidence from cognitive neuroscience</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>4</volume><fpage>564</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.3758/CABN.4.4.564</pub-id><pub-id pub-id-type="pmid">15849898</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname> <given-names>PF</given-names></name><name><surname>Goldstone</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Putting category learning in order: category structure and temporal arrangement affect the benefit of interleaved over blocked study</article-title><source>Memory &amp; Cognition</source><volume>42</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.3758/s13421-013-0371-0</pub-id><pub-id pub-id-type="pmid">24092426</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname> <given-names>PF</given-names></name><name><surname>Goldstone</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The benefits of interleaved and blocked study: different tasks benefit from different schedules of study</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>22</volume><fpage>281</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.3758/s13423-014-0676-4</pub-id><pub-id pub-id-type="pmid">24984923</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname> <given-names>PF</given-names></name><name><surname>Goldstone</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The sequence of study changes what information is attended to, encoded, and remembered during category learning</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>43</volume><fpage>1699</fpage><lpage>1719</lpage><pub-id pub-id-type="doi">10.1037/xlm0000406</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casscells</surname> <given-names>W</given-names></name><name><surname>Schoenberger</surname> <given-names>A</given-names></name><name><surname>Graboys</surname> <given-names>TB</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Interpretation by physicians of clinical laboratory results</article-title><source>New England Journal of Medicine</source><volume>299</volume><fpage>999</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1056/NEJM197811022991808</pub-id><pub-id pub-id-type="pmid">692627</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname> <given-names>K</given-names></name><name><surname>Prabhakaran</surname> <given-names>V</given-names></name><name><surname>Dorfman</surname> <given-names>J</given-names></name><name><surname>Zhao</surname> <given-names>Z</given-names></name><name><surname>Kroger</surname> <given-names>JK</given-names></name><name><surname>Holyoak</surname> <given-names>KJ</given-names></name><name><surname>Gabrieli</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Rostrolateral prefrontal cortex involvement in relational integration during reasoning</article-title><source>NeuroImage</source><volume>14</volume><fpage>1136</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0922</pub-id><pub-id pub-id-type="pmid">11697945</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>T</given-names></name><name><surname>Goldwater</surname> <given-names>M</given-names></name><name><surname>Giron</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>From concrete examples to abstract relations: the rostrolateral prefrontal cortex integrates novel examples into relational categories</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>2652</fpage><lpage>2670</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw099</pub-id><pub-id pub-id-type="pmid">27130661</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>T</given-names></name><name><surname>Love</surname> <given-names>BC</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Learning the exception to the rule: model-based FMRI reveals specialized representations for surprising category members</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>260</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr036</pub-id><pub-id pub-id-type="pmid">21666132</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>T</given-names></name><name><surname>Love</surname> <given-names>BC</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Striatal and hippocampal entropy and recognition signals in category learning: simultaneous processes revealed by model-based fMRI</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>38</volume><fpage>821</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1037/a0027865</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>T</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Quantifying the internal structure of categories using a neural typicality measure</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>1720</fpage><lpage>1737</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht014</pub-id><pub-id pub-id-type="pmid">23442348</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>Garrett</surname> <given-names>N</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Confidence in value-based choice</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/nn.3279</pub-id><pub-id pub-id-type="pmid">23222911</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeGutis</surname> <given-names>J</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Distinct mechanisms in visual category learning</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>7</volume><fpage>251</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.3758/CABN.7.3.251</pub-id><pub-id pub-id-type="pmid">17993211</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filoteo</surname> <given-names>JV</given-names></name><name><surname>Maddox</surname> <given-names>WT</given-names></name><name><surname>Simmons</surname> <given-names>AN</given-names></name><name><surname>Ing</surname> <given-names>AD</given-names></name><name><surname>Cagigas</surname> <given-names>XE</given-names></name><name><surname>Matthews</surname> <given-names>S</given-names></name><name><surname>Paulus</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cortical and subcortical brain regions involved in rule-based category learning</article-title><source>NeuroReport</source><volume>16</volume><fpage>111</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1097/00001756-200502080-00007</pub-id><pub-id pub-id-type="pmid">15671857</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldwater</surname> <given-names>MB</given-names></name><name><surname>Don</surname> <given-names>HJ</given-names></name><name><surname>Krusche</surname> <given-names>MJF</given-names></name><name><surname>Livesey</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Relational discovery in category learning</article-title><source>Journal of Experimental Psychology: General</source><volume>147</volume><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1037/xge0000387</pub-id><pub-id pub-id-type="pmid">29309195</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname> <given-names>K</given-names></name><name><surname>Weiner</surname> <given-names>KS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional architecture of the ventral temporal cortex and its role in categorization</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>536</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1038/nrn3747</pub-id><pub-id pub-id-type="pmid">24962370</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname> <given-names>M</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Sederberg</surname> <given-names>PB</given-names></name><name><surname>Hanson</surname> <given-names>SJ</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Pollmann</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>PyMVPA: A python toolbox for multivariate pattern analysis of fMRI data</article-title><source>Neuroinformatics</source><volume>7</volume><fpage>37</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1007/s12021-008-9041-y</pub-id><pub-id pub-id-type="pmid">19184561</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>435</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170325</pub-id><pub-id pub-id-type="pmid">25002277</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Furey</surname> <given-names>ML</given-names></name><name><surname>Ishai</surname> <given-names>A</given-names></name><name><surname>Schouten</surname> <given-names>JL</given-names></name><name><surname>Pietrini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title><source>Science</source><volume>293</volume><fpage>2425</fpage><lpage>2430</lpage><pub-id pub-id-type="doi">10.1126/science.1063736</pub-id><pub-id pub-id-type="pmid">11577229</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishai</surname> <given-names>A</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name><name><surname>Martin</surname> <given-names>A</given-names></name><name><surname>Schouten</surname> <given-names>JL</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Distributed representation of objects in the human ventral visual pathway</article-title><source>PNAS</source><volume>96</volume><fpage>9379</fpage><lpage>9384</lpage><pub-id pub-id-type="doi">10.1073/pnas.96.16.9379</pub-id><pub-id pub-id-type="pmid">10430951</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juslin</surname> <given-names>P</given-names></name><name><surname>Wennerholm</surname> <given-names>P</given-names></name><name><surname>Winman</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>High-level reasoning and base-rate use: do we need cue-competition to explain the inverse base-rate effect?</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>27</volume><fpage>849</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.27.3.849</pub-id><pub-id pub-id-type="pmid">11394684</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruschke</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Base rates in category learning</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>22</volume><fpage>3</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.22.1.3</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruschke</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Toward a unified model of attention in associative learning</article-title><source>Journal of Mathematical Psychology</source><volume>45</volume><fpage>812</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1006/jmps.2000.1354</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leong</surname> <given-names>YC</given-names></name><name><surname>Radulescu</surname> <given-names>A</given-names></name><name><surname>Daniel</surname> <given-names>R</given-names></name><name><surname>DeWoskin</surname> <given-names>V</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic interaction between reinforcement learning and attention in multidimensional environments</article-title><source>Neuron</source><volume>93</volume><fpage>451</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.040</pub-id><pub-id pub-id-type="pmid">28103483</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name><name><surname>Drysdale</surname> <given-names>AT</given-names></name><name><surname>Oberauer</surname> <given-names>K</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural evidence for a distinction between short-term memory and the focus of attention</article-title><source>Journal of Cognitive Neuroscience</source><volume>24</volume><fpage>61</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00140</pub-id><pub-id pub-id-type="pmid">21955164</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Peacock</surname> <given-names>JA</given-names></name><name><surname>Postle</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Temporary activation of long-term memory supports working memory</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>8765</fpage><lpage>8771</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1953-08.2008</pub-id><pub-id pub-id-type="pmid">18753378</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Z</given-names></name><name><surname>Braunlich</surname> <given-names>K</given-names></name><name><surname>Wehe</surname> <given-names>HS</given-names></name><name><surname>Seger</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural networks supporting switching, hypothesis testing, and rule application</article-title><source>Neuropsychologia</source><volume>77</volume><fpage>19</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.07.019</pub-id><pub-id pub-id-type="pmid">26197092</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mack</surname> <given-names>ML</given-names></name><name><surname>Love</surname> <given-names>BC</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic updating of hippocampal object representations reflects new conceptual knowledge</article-title><source>PNAS</source><volume>113</volume><fpage>13203</fpage><lpage>13208</lpage><pub-id pub-id-type="doi">10.1073/pnas.1614048113</pub-id><pub-id pub-id-type="pmid">27803320</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mack</surname> <given-names>ML</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name><name><surname>Love</surname> <given-names>BC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decoding the brain's algorithm for categorization from its neural implementation</article-title><source>Current Biology</source><volume>23</volume><fpage>2023</fpage><lpage>2027</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.08.035</pub-id><pub-id pub-id-type="pmid">24094852</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markman</surname> <given-names>AB</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>LMS rules and the inverse base-rate effect: comment on Gluck and Bower (1988)</article-title><source>Journal of Experimental Psychology: General</source><volume>118</volume><fpage>417</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.118.4.417</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medin</surname> <given-names>DL</given-names></name><name><surname>Bettger</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Sensitivity to changes in Base-Rate information</article-title><source>The American Journal of Psychology</source><volume>104</volume><fpage>311</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.2307/1423242</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medin</surname> <given-names>DL</given-names></name><name><surname>Edelson</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Problem structure and the use of base-rate information from experience</article-title><source>Journal of Experimental Psychology: General</source><volume>117</volume><fpage>68</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.117.1.68</pub-id><pub-id pub-id-type="pmid">2966231</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname> <given-names>JA</given-names></name><name><surname>Turner</surname> <given-names>BO</given-names></name><name><surname>Ashby</surname> <given-names>FG</given-names></name><name><surname>Poldrack</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>NeuroImage</source><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id><pub-id pub-id-type="pmid">21924359</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nasser</surname> <given-names>HM</given-names></name><name><surname>Calu</surname> <given-names>DJ</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Sharpe</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The dopamine prediction error: contributions to associative models of reward learning</article-title><source>Frontiers in Psychology</source><volume>8</volume><elocation-id>244</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.00244</pub-id><pub-id pub-id-type="pmid">28275359</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosofsky</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Attention, similarity, and the identification-categorization relationship</article-title><source>Journal of Experimental Psychology: General</source><volume>115</volume><fpage>39</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.115.1.39</pub-id><pub-id pub-id-type="pmid">2937873</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Bryan</surname> <given-names>SR</given-names></name><name><surname>Walden</surname> <given-names>E</given-names></name><name><surname>Serra</surname> <given-names>MJ</given-names></name><name><surname>Davis</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rule activation and ventromedial prefrontal engagement support accurate stopping in self-paced learning</article-title><source>NeuroImage</source><volume>172</volume><fpage>415</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.084</pub-id><pub-id pub-id-type="pmid">29410293</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paniukov</surname> <given-names>D</given-names></name><name><surname>Davis</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The evaluative role of rostrolateral prefrontal cortex in rule-based category learning</article-title><source>NeuroImage</source><volume>166</volume><fpage>19</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.057</pub-id><pub-id pub-id-type="pmid">29107769</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rissman</surname> <given-names>J</given-names></name><name><surname>Gazzaley</surname> <given-names>A</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Measuring functional connectivity during distinct stages of a cognitive task</article-title><source>NeuroImage</source><volume>23</volume><fpage>752</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.06.035</pub-id><pub-id pub-id-type="pmid">15488425</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rissman</surname> <given-names>J</given-names></name><name><surname>Wagner</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distributed representations in memory: insights from functional brain imaging</article-title><source>Annual Review of Psychology</source><volume>63</volume><fpage>101</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-120710-100344</pub-id><pub-id pub-id-type="pmid">21943171</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seger</surname> <given-names>CA</given-names></name><name><surname>Braunlich</surname> <given-names>K</given-names></name><name><surname>Wehe</surname> <given-names>HS</given-names></name><name><surname>Liu</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Generalization in category learning: the roles of representational and decisional uncertainty</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>8802</fpage><lpage>8812</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0654-15.2015</pub-id><pub-id pub-id-type="pmid">26063914</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seger</surname> <given-names>CA</given-names></name><name><surname>Cincotta</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dynamics of frontal, striatal, and hippocampal systems during rule learning</article-title><source>Cerebral Cortex</source><volume>16</volume><fpage>1546</fpage><lpage>1555</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj092</pub-id><pub-id pub-id-type="pmid">16373455</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharpe</surname> <given-names>MJ</given-names></name><name><surname>Killcross</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The prelimbic cortex directs attention toward predictive cues during fear learning</article-title><source>Learning &amp; Memory</source><volume>22</volume><fpage>289</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1101/lm.038273.115</pub-id><pub-id pub-id-type="pmid">25979990</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname> <given-names>JS</given-names></name><name><surname>Power</surname> <given-names>JD</given-names></name><name><surname>Dubis</surname> <given-names>JW</given-names></name><name><surname>Vogel</surname> <given-names>AC</given-names></name><name><surname>Church</surname> <given-names>JA</given-names></name><name><surname>Schlaggar</surname> <given-names>BL</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Statistical improvements in functional magnetic resonance imaging analyses produced by censoring high-motion data points</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>1981</fpage><lpage>1996</lpage><pub-id pub-id-type="doi">10.1002/hbm.22307</pub-id><pub-id pub-id-type="pmid">23861343</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soto</surname> <given-names>FA</given-names></name><name><surname>Waldschmidt</surname> <given-names>JG</given-names></name><name><surname>Helie</surname> <given-names>S</given-names></name><name><surname>Ashby</surname> <given-names>FG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain activity across the development of automatic categorization: a comparison of categorization tasks using multi-voxel pattern analysis</article-title><source>NeuroImage</source><volume>71</volume><fpage>284</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.01.008</pub-id><pub-id pub-id-type="pmid">23333700</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname> <given-names>N</given-names></name><name><surname>Morin</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dissimilarity is used as evidence of category membership in multidimensional perceptual categorization: a test of the similarity-dissimilarity generalized context model</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>60</volume><fpage>1337</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1080/17470210701480444</pub-id><pub-id pub-id-type="pmid">17853242</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname> <given-names>A</given-names></name><name><surname>Kahneman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Judgment under uncertainty: heuristics and biases</article-title><source>Science</source><volume>185</volume><fpage>1124</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1126/science.185.4157.1124</pub-id><pub-id pub-id-type="pmid">17835457</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A practical solution to the pervasive problems of <italic>p</italic> values</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>14</volume><fpage>779</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.3758/BF03194105</pub-id><pub-id pub-id-type="pmid">18087943</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waldschmidt</surname> <given-names>JG</given-names></name><name><surname>Ashby</surname> <given-names>FG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical and striatal contributions to automaticity in information-integration categorization</article-title><source>NeuroImage</source><volume>56</volume><fpage>1791</fpage><lpage>1802</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.02.011</pub-id><pub-id pub-id-type="pmid">21316475</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winman</surname> <given-names>A</given-names></name><name><surname>Wennerholm</surname> <given-names>P</given-names></name><name><surname>Juslin</surname> <given-names>P</given-names></name><name><surname>Shanks</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Evidence for rule-based processes in the inverse base-rate effect</article-title><source>The Quarterly Journal of Experimental Psychology Section A</source><volume>58</volume><fpage>789</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1080/02724980443000331</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeithamova</surname> <given-names>D</given-names></name><name><surname>Dominick</surname> <given-names>AL</given-names></name><name><surname>Preston</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Hippocampal and ventral medial prefrontal activation during retrieval-mediated learning supports novel inference</article-title><source>Neuron</source><volume>75</volume><fpage>168</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.05.010</pub-id><pub-id pub-id-type="pmid">22794270</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36395.019</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Verstynen</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff><institution>Carnegie Mellon University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Verstynen</surname><given-names>Timothy</given-names> </name><role>Reviewer</role><aff><institution>Carnegie Mellon University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Seger</surname><given-names>Carol</given-names> </name><role>Reviewer</role><aff><institution>Colorado State University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Model-based fMRI reveals dissimilarity processes underlying base rate neglect&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Timothy Verstynen as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Carol Seger (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The reviewers all agreed that this was an important and creative study. The use of MVPA to test explicit psychological models of a cognitive phenomenon was innovative. However, all of the reviewers found the presentation of the theoretical and methodological aspects of the study to be opaque. This resulted in substantial difficulty in being able to accurately judge whether the key findings were veridical or not (or in some cases what the key findings are). Given the overall positive opinion on the scope and aims of the study, the article will require substantial revisions in order to be able to adequately evaluate the conclusions and interpretations put forth.</p><p>Below is a consolidated review of the comments from all reviewers. The major points are organized by topic.</p><p>Essential revisions:</p><p>1) Inferential concerns:</p><p>The authors are often imprecise when writing about the cognitive functions that might underlie the differences in neural activation in the MVPA analyses. They often refer to the subjects &quot;thinking about&quot; the common or rare category, but this is unclear. The subjects could consciously be thinking about the category. The representations could be activated implicitly, and indirectly and unconsciously bias the subjects' responses. The subjects could simply be paying more attention to the certain features, and this attention could precede (attending to a feature associated with a rare disease could bias the decision) or even follow the decision (deciding it is the rare disease heightens attention to features of the rare disease). The authors do briefly discuss alternatives in the Discussion section, but a more systematic analysis of the different options and which are ruled out by the present results versus which are still open questions would be helpful.</p><p>2) Ambiguity in the MVPA models:</p><p>What parameters from the dissGCM model were used?</p><p>It is unclear how the pattern similarity measures during trials when the low base rate outcome is selected is consistent with the authors' theory. However, it seems that the increased similarity to rare features on trials when the high base rate outcome is selected (for objects only) would be counter to the authors' dissGCM model.</p><p>Finally, the authors have a clear model-based definition of similarity and dissimilarity in the Model description section, similarity as the summed similarity to the winning category exemplars, and dissimilarity as the summed similarity to other categories, so that the two measures are relative to different sets of stimuli. They didn't clearly establish this difference in the Introduction and didn't always clearly interpret results clearly. Many readers will come to the paper assuming that dissimilarity is just the opposite of similarity and need to clearly understand when and how each term is being used. Perhaps using terms like Dissimilarity-Other Category and Similarity-Same category would make it clearer. Some of the most exciting results of the paper are the different neural correlates of similarity and dissimilarity (Figure 5), but it is easy to get confused as to why the negative similarity regressor (blue in Figure 5) differs from the dissimilarity regressor.</p><p>3) Logical Flow:</p><p>The authors rely heavily on assuming that the reader will not read the paper in a linear order, instead assuming the reader will be familiar with much of the Materials and methods when reading the Results. For example, information regarding the regions that the representational distance scores are drawn from is buried at the end of the Materials and methods. In addition, there are not clear details in the Materials and methods regarding the calculation of the similarity score itself. Thus, it is almost impossible for the reader to know how to interpret the key findings (Figures 3-5) without going back and forth or making some assumptions about the approach. This needs to be overhauled given the format of <italic>eLife</italic>.</p><p>The one place this isn't a concern is the presentation of the dissGCM model. While the details are appreciated, they are also out of place. This needs to be in the Results and Materials and methods, not the Introduction, and disambiguated so that conceptual information necessary for understanding the model and its fit to behavior is provided in Results, while the model itself is formally defined in the Materials and methods.</p><p>4) Neural Similarity analysis:</p><p>In many cases, it's not clear that the correct statistics were used. For example, in Figure 3, the interaction and main effects are reported as post-hoc t-tests. How was the interaction actually calculated (i.e., can't assess an interaction with a t-test)? What linear model was used? There is also a concern that the key analysis reported in Figure 3 may be based on very few trials. How many trials were actually included for each subject? Was there sufficient statistical power for the analysis?</p><p>5) Parameterization of behavior for brain-behavior correlations:</p><p>It is not immediately clear what the value is in showing the brain-behavior predictions based on the probability of selecting the low base rate outcome and the pattern similarity scores in Figure 5. This needs to be motivated and explained in more detail.</p><p>There is a specific model parameter, (<italic>s</italic> in Equation 3), that defines the degree to which a subject relies on similarity vs. dissimilarity. Wouldn't correlating individual differences in pattern similarities with this variable be a much more direct measure of the dissGCM hypothesis?</p><p>6) Value and clarity of univariate BOLD analysis:</p><p>The description of how these results are obtained is a bit opaque in the Materials and methods.</p><p>This analysis is asking a tangential question than the primary hypothesis of the paper (i.e., it's not supporting or adding nuance to the key findings from the multivariate analysis).</p><p>The interpretations from these maps is subjective and somewhat vague.</p><p>7) Analysis of face regions with face stimuli:</p><p>Why didn't the authors look at face activation in a face region (e.g., FFA) at all? Faces are the imperfect predictor here, which means they are the stimulus with the most flexibility in terms of associating with the outcome. Wouldn't a key prediction of the dissGCM model be that faces be more similar to object and scene area activity on trials when the common outcome is selected and vice versa for trials where the rare outcome is selected? It seems odd that the analysis is restricted to objects and scenes given the unique position face stimuli are given in the task.</p><p>8) Behavioral analysis:</p><p>For the behavioral analysis (Figure 2), was the interaction formally decomposed? Please report the relevant statistics in detail. It is also puzzling why reaction time was not reported. Reaction time could shed light on the mechanisms underlying choices. For example, if replying based on similarity is due to habitual responding, one would predict faster RTs in that case. One would also expect longer RTs for more deliberative choices.</p><p>9) Presentation of consecutive rare stimuli:</p><p>Are there any trials where the authors present two consecutive rare stimuli? Carvalho and Goldstone (2015) suggest that participants make decision by comparing the stimulus at time t with the stimulus at time t-1. In the current article, the stimulus at time t-1 is more likely to be from the same category as the stimulus at time t for common categories than for rare categories. Same category stimuli focus on within-category information (similarity) while different category stimuli focus on between-category information (dissimilarity). This alternative explanation does not rely on base rate and should be discussed.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36395.020</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions</p><p>1) Inferential concerns:</p><p>The authors are often imprecise when writing about the cognitive functions that might underlie the differences in neural activation in the MVPA analyses. They often refer to the subjects &quot;thinking about&quot; the common or rare category, but this is unclear. The subjects could consciously be thinking about the category. The representations could be activated implicitly, and indirectly and unconsciously bias the subjects' responses. The subjects could simply be paying more attention to the certain features, and this attention could precede (attending to a feature associated with a rare disease could bias the decision) or even follow the decision (deciding it is the rare disease heightens attention to features of the rare disease). The authors do briefly discuss alternatives in the Discussion section, but a more systematic analysis of the different options and which are ruled out by the present results versus which are still open questions would be helpful.</p></disp-quote><p>Throughout the paper, we no longer refer to subjects thinking about the categories, and instead use more precise terms relating to what the MVPA analysis is objectively measuring (e.g., participants are activating patterns associated with the common category exemplar).</p><p>We have also revised the manuscript to more thoroughly discuss the cognitive processes that we believe the pattern similarity measure is capturing, and justify these predictions based on prior research using similar methods in concert with the representational assumptions made by both similarity- and dissimilarity-based theories of the IBRE. For instance, in the Introduction:</p><p>“In this context, we anticipate that the multivoxel pattern analysis will index an interactive process between feature-based attention and memory retrieval: both the dissGCM, pure similarity-based GCM, and previous dissimilarity-based inference models predict that categorization decisions are driven by an attention-weighted memory process whereby a stimulus is compared to the contents of memory. […] Because the dissGCM predicts greater contributions from the common, unchosen category during this retrieval process, we expect multivoxel patterns during ambiguous trials to reveal greater activation of information associated with the common, unchosen category.”</p><p>We then more thoroughly address the types of representations that may be contributing to our findings in the Discussion:</p><p>“We predict that our multivoxel results are not driven directly by simple feature-based attention, but instead indicate some combination of attention and memory-based retrieval of the category exemplars. […] Future studies may wish to combine multivoxel pattern analysis with eye-tracking (e.g., Leong et al., 2017) to better understand the unique contributions that attention and memory make to the present results.”</p><disp-quote content-type="editor-comment"><p>2) Ambiguity in the MVPA models:</p><p>What parameters from the dissGCM model were used?</p></disp-quote><p>For both the multivoxel results and the model-based univariate results, our focus is on the predicted similarity- and dissimilarity-based contributions to the overall decision evidence <italic>v</italic>. We now thoroughly describe how the parameters for the multivoxel analysis (and the model-based imaging analysis) are obtained where appropriate in the Results text. For example:</p><p>“The prediction that information associated with the common category should be more active on ambiguous trials is derived from the dissGCM. […] For example, using these formulas, in the fitted version of the model, the proportion of the overall evidence for rare contributed by similarity to the rare category exemplar was nearly half the evidence contributed by dissimilarity to the common category exemplar (rare = 0.088; common = 0.153, in the dissGCM’s attention weighted similarity units).”</p><disp-quote content-type="editor-comment"><p>It is unclear how the pattern similarity measures during trials when the low base rate outcome is selected is consistent with the authors' theory. However, it seems that the increased similarity to rare features on trials when the high base rate outcome is selected (for objects only) would be counter to the authors' dissGCM model.</p></disp-quote><p>Greater neural similarity to the common features is consistent with the theory that people more heavily rely on (dissimilarity to) the common category to infer that the ambiguous cases must be rare, consistent with dissGCM’s predictions for the contribution of dissimilarity-based evidence to common category exemplars relative to similarity-based evidence for the rare exemplars (see above). We now clarify this result and offer a more thorough interpretation following the details of the statistical test in the Results section:</p><p>“To summarize, our multivoxel findings for the test phase suggest that people more strongly activate information associated with common categories when engaging in base rate neglect, consistent with dissGCM’s prediction that dissimilarity to the common category exemplar contributes more to rare decisions than similarity to the rare category exemplar. […] Our behavioral findings provide additional evidence for such a dissociation, as reaction times were found to be significantly slower for rare relative to common responses.”</p><p>Regarding the reviewers’ second point, we found that the difference between representational similarity to the rare and common objects when subjects chose the common category was not statistically significant, <italic>t</italic> (16) =. 869, p =. 398. Figure 3 is now collapsed across visual stimulus categories to more clearly illustrate the interaction effect between activation of rare/common stimulus features and whether the rare/common category was chosen. We believe that presenting the data in this manner will be more straightforward for readers to interpret, given that we now display the means for imperfect face predictors in the graph (see comment #6) and that no interactions or main effects of whether the stimulus was a scene or object were observed across cells. In addition to Figure 3 which is collapsed across objects/scenes, we now include a figure supplement (Figure 3—figure supplement 1) which depicts the means associated with each distinct stimulus (e.g., rare object) in the model. Increased neural similarity to the rare object category for common responses would indeed run counter to the predictions of dissGCM – as we now discuss in this section (see the paragraph above), dissGCM does not suggest an alternative process that leads to common responses, and instead is designed to account for participants’ overall tendency to choose the rare category in ambiguous cases.</p><disp-quote content-type="editor-comment"><p>Finally, the authors have a clear model-based definition of similarity and dissimilarity in the Model description section, similarity as the summed similarity to the winning category exemplars, and dissimilarity as the summed similarity to other categories, so that the two measures are relative to different sets of stimuli. They didn't clearly establish this difference in the Introduction and didn't always clearly interpret results clearly. Many readers will come to the paper assuming that dissimilarity is just the opposite of similarity and need to clearly understand when and how each term is being used. Perhaps using terms like Dissimilarity-Other Category and Similarity-Same category would make it clearer. Some of the most exciting results of the paper are the different neural correlates of similarity and dissimilarity (Figure 5), but it is easy to get confused as to why the negative similarity regressor (blue in Figure 5) differs from the dissimilarity regressor.</p></disp-quote><p>We agree that more clarity in our references to similarity/negative similarity vs. dissimilarity (and establishing what each represents in more detail) was necessary. The revised manuscript now sets up this distinction in the Introduction. For example:</p><p>“In addition to our multivoxel analysis, we also test whether using dissimilarity-based evidence against unchosen categories may tap distinct brain regions, such as the rlPFC, beyond those involved with similarity-based computations. […] We anticipated that the MTL and vmPFC would be positively associated with similarity-based evidence, whereas dlPFC would be negatively associated with similarity-based evidence for the winning category. Contrastingly, we expected rlPFC to track estimates of dissimilarity-based evidence against alternative options.”</p><p>Beyond introducing the point that similarity- and dissimilarity-based evidence are taken relative to the chosen and unchosen categories early in the paper, we now remind readers of this point in several relevant sections of the manuscript. In particular, we emphasize this distinction in the model-based univariate Results section where it is critical to differentiate between regions associated with dissimilarity-based evidence versus those negatively associated with similarity-based evidence. For example:</p><p>“To test whether similarity- and dissimilarity-based evidence rely on different brain regions, we modeled univariate voxel-wise activation using trial-by-trial estimates of similarity- and dissimilarity-based evidence derived from the dissGCM. […] The regions associated with dissimilarity-based evidence in this analysis are thus distinct from those negatively associated with similarity-based evidence because they are derived from evidence against the alternative, non-winning category.”</p><disp-quote content-type="editor-comment"><p>3) Logical Flow:</p><p>The authors rely heavily on assuming that the reader will not read the paper in a linear order, instead assuming the reader will be familiar with much of the Materials and methods when reading the Results. For example, information regarding the regions that the representational distance scores are drawn from is buried at the end of the Materials and methods. In addition, there are not clear details in the Materials and methods regarding the calculation of the similarity score itself. Thus, it is almost impossible for the reader to know how to interpret the key findings (Figures 3-5) without going back and forth or making some assumptions about the approach. This needs to be overhauled given the format of eLife.</p></disp-quote><p>We now include detailed information about our multivoxel analysis in the Results section, including a description of how the ROIs were selected. Along with these details, we describe how the RSA measure was found to successfully differentiate control items during the test phase:</p><p>“For this analysis, multivoxel pattern estimates were anatomically restricted to ROIs in ventral temporal cortex associated with each visual stimulus category (objects: left inferior posterior temporal gyrus; scenes: bilateral parahippocampal gyrus; and faces: right temporal occipital fusiform gyrus). […] Likewise, estimates for faces on face-only control trials were found to be significantly greater than on object-only trials, t (21) = 2.54, p =. 019, and scene-only trials, t (21) = 2.92, p =. 008.”</p><p>We believe that in the previous version of the manuscript, it was not always clear whether we were referring to the pattern similarity measure or model-based predictions of similarity-based evidence, which may have been a point of confusion. The revised manuscript is now more precise with these terms by clearly establishing when we are referring to model-based predictions of similarity-based evidence to a given category or exemplar, versus BOLD pattern similarity in the multivoxel analysis.</p><p>The multivoxel pattern analysis section in the Materials and methods now follows a more logical organization, and additional details about the BOLD pattern similarity calculations were added:</p><p>“RSA was conducted using the PyMVPA toolbox (Hanke et al., 2009) and custom Python routines. […] For interpretative ease, the distances were converted to similarities using exp(- distance), and then standardized (z-scored) within participants.”</p><disp-quote content-type="editor-comment"><p>The one place this isn't a concern is the presentation of the dissGCM model. While the details are appreciated, they are also out of place. This needs to be in the Results and Materials and methods, not the Introduction, and disambiguated so that conceptual information necessary for understanding the model and its fit to behavior is provided in Results, while the model itself is formally defined in the Materials and methods.</p></disp-quote><p>We now include the formal model definition in the Materials and methods section, while including relevant conceptual information and details regarding the key model parameters where appropriate in the Results.</p><disp-quote content-type="editor-comment"><p>4) Neural Similarity analysis:</p><p>In many cases, it's not clear that the correct statistics were used. For example, in Figure 3, the interaction and main effects are reported as post-hoc t-tests. How was the interaction actually calculated (i.e., can't assess an interaction with a t-test)? What linear model was used? There is also a concern that concerned that the key analysis reported in Figure 3 may be based on very few trials. How many trials were actually included for each subject? Was there sufficient statistical power for the analysis?</p></disp-quote><p>The multivoxel results for the test phase (Figure 3) were calculated using a linear mixed effects model with random intercepts for each participant. The interaction was previously reported as a <italic>t</italic>-value corresponding to the γ-weight for the interaction term, which by default are accompanied by a <italic>t</italic>-statistic in R’s “nlme” package. However, we agree that this may be a point of confusion for readers and as such now report the equivalent <italic>F-</italic>testfor the interaction:</p><p>“Multivoxel pattern similarity results for the ambiguous test trials are depicted in Figure 3. […] Interestingly, there was no significant difference between pattern similarity for rare and common features when participants made a common response, t (21) = 0.45, p =. 653.”</p><p>Based on this comment, we have also made it clear throughout the manuscript where linear mixed effects modeling was used and report the <italic>F</italic> statistic associated with the resulting interaction terms where applicable.</p><p>Regarding the statistical power of the results displayed in Figure 3, we anticipate that there was sufficient power for the test. The number of ambiguous test trials was doubled relative to the other trial types during the test phase with this analysis in mind, and each participant was given 24 ambiguous scene-object pairings to categorize over three scanning runs. In the Materials and methods, we now detail the number of trials allocated to each test stimulus, and a new supplementary file (Supplementary File 1) depicts the number of rare and common responses made on the key scene-object trials for each subject. Moreover, we now show that the pattern similarity measure accurately discriminates between faces, objects, and scenes within each functional localizer ROI for control (face-, object-, or scene-only) trials in the Results section, which we believe further alleviates concerns about the power of the analysis.</p><disp-quote content-type="editor-comment"><p>5) Parameterization of behavior for brain-behavior correlations:</p><p>It is not immediately clear what the value is in showing the brain-behavior predictions based on the probability of selecting the low base rate outcome and the pattern similarity scores in Figure 5. This needs to be motivated and explained in more detail.</p></disp-quote><p>We now thoroughly discuss the motivation for this analysis in terms of its relationship to previous similarity- versus dissimilarity-based explanations of IBRE behavior (Results section):</p><p>“As with the test phase, dissimilarity-based theories make the somewhat counterintuitive prediction that it is specifically what people learn about the common category that is driving later choices of the rare category. […] This prediction is in direct contrast to the dominant similarity-based explanation of IBRE, which posits that it is specifically a stronger learned association between rare perfect predictors and their category that drives later rare category selections for the ambiguous test probes (Medin and Edelson, 1988; Kruschke, 1996, 2001).”</p><disp-quote content-type="editor-comment"><p>There is a specific model parameter, (s in Equation 3), that defines the degree to which a subject relies on similarity vs. dissimilarity. Wouldn't correlating individual differences in pattern similarities with this variable be a much more direct measure of the dissGCM hypothesis?</p></disp-quote><p>The dissGCM, like the GCM, is made to be a model of asymptotic categorization performance and is not well-equipped to capture individual differences. One reason for this is that the model is constrained to fit all trials, not just the key ambiguous trials. Similarity is critical for responses on many trials, and highly weighting dissimilarity leads the <italic>s</italic> parameter to be highly skewed in fits to individual subject data. Further, because there are three times more common items, the raw dissimilarity-based evidence is much higher for the common category than the similarity-based evidence for rare, and thus almost any amount of dissimilarity weighting produces the predicted rare responding. Thus, there is little pressure on the model to modulate the weighting of dissimilarity to fit the IBRE trials, and the model is very underidentified if fit to only the key IBRE trials.</p><p>We did fit an individual subject version nonetheless, finding a correlation between the weight to dissimilarity and slowed RTs. This may suggest that more deliberation is required to process dissimilarity, consistent with our MVPA results and the observed association between rlPFC and dissimilarity-based contributions to choice. No other relevant correlations were observed with the <italic>s</italic> parameter, but this is likely to due to the issues described above as its values were highly skewed when fit to individual subjects.</p><p>Importantly, because the <italic>s</italic> parameter is a scalar multiple of the similarity- and dissimilarity-based evidence, our model-based predictions for the univariate analysis are not affected by the <italic>s</italic> parameter value. For these reasons, we have decided not to include this analysis in the present study, but would be willing to do so if it was deemed critical by reviewers. We have included a discussion paragraph addressing this subject:</p><p>“The dissGCM, like the standard GCM, is a model of asymptotic categorization performance and generalization, and thus is not well-equipped to account for learning dynamics or individual differences. […] However, such a model would require extensive additional data to validate, and thus is beyond the scope of the present study.”</p><disp-quote content-type="editor-comment"><p>6) Value and clarity of univariate BOLD analysis:</p><p>The description of how these results are obtained is a bit opaque in the Materials and methods.</p></disp-quote><p>We now detail the calculation of the trial level similarity- and dissimilarity-based evidence estimates and how they were used as regressors in the model-based univariate section of the Materials and methods:</p><p>“The first-level model included an EV for stimulus presentation and two model-based parametric modulators: Similarity- and dissimilarity-based evidence, computed from the dissGCM. Specifically, these regressors were obtained on a trial-by trial basis using Equation 3 (see Model section), where the evidence contribution of summed similarity to the winning category (C<sub>A</sub>; Most probable category according to the model) is calculated as:</p><p>s∑Sj∈CAtjsimij,(5)</p><p>and the evidence contribution of summed dissimilarity to non-winning categories with a positive feature match is calculated as:</p><p>1-s∑Sj∈¬CAtj(1-simij)(6)</p><p>Both parametric modulators were centered and scaled (z-scored) within run.”</p><disp-quote content-type="editor-comment"><p>This analysis is asking a tangential question than the primary hypothesis of the paper (i.e., it's not supporting or adding nuance to the key findings from the multivariate analysis).</p></disp-quote><p>We believe that the model-based imaging analysis provides critical support for the overall conclusions of the paper in that dissimilarity-based evidence not only contributes to base rate neglect, but that this type of processing is cognitively and neurobiologically distinct from pure similarity-based processing. While the neurobiological systems involved in similarity-based categorization are well understood, this is the first study to investigate whether incorporating contrastive evidence into categorization decisions recruits brain regions beyond those typically correlated with evidence in rule-based category learning (e.g., vmPFC and dlPFC). In the revised manuscript, we more thoroughly explain the rationale for this analysis in the Introduction. For example:</p><p>“It is possible that dissimilarity processes require manipulating similarity relationships between category representations in a more symbolic or abstract manner, as anticipated by previous dissimilarity theories. […] Specifically, we can test whether regions that are known to be critical for using higher-level abstract rules track dissGCM’s predicted trial-by-trial used of dissimilarity-based evidence and whether these regions diverge from those typically found to track estimates of similarity-based evidence.</p><p>Likewise:</p><p>“In the present study, dissimilarity-based generalization to novel feature pairings may depend on rule evaluation processes in the rlPFC more so than simple similarity-based processing, if studies anticipating that dissimilarity-based processes depend more upon higher-level symbolic rules are correct (Juslin, Wennerholm and Winman, 2001; Winman et al., 2005). Alternatively, pure similarity-based accounts suggest that generalization patterns in an IBRE task do not depend on the existence of a separate, higher-level mechanism (Medin and Edelson, 1988; Kruschke, 1996, 2001), and would thus expect a single neurobiological network associated with similarity-based processing to be engaged for choice across trials.”</p><p>We also re-emphasize these points when reporting our model-based univariate findings in the Results:</p><p>“Comparing the statistical maps in Figure 6A and 6B, it is apparent that greater relative contributions of dissimilarity-based evidence do not necessitate smaller contributions of similarity-based evidence in the dissGCM: if these regressors were anticorrelated, one would expect the regions associated with dissimilarity processes to resemble the fronto-parietal network we found to be negatively associated with similarity. Instead, our results show that using contrastive evidence uniquely engages the rlPFC, in line with dual-process theories that suggest dissimilarity-based processing may distinctly depend upon higher-level, abstract reasoning.”</p><disp-quote content-type="editor-comment"><p>The interpretations from these maps is subjective and somewhat vague.</p></disp-quote><p>We agree with the reviewers that the paper would benefit from making more connections between our univariate findings and the broader literature on categorization, rather than focusing somewhat exclusively on our a priori regions of interest. In line with this comment, we now present a considerably more detailed univariate Results section with paragraphs dedicated to each of the three contrasts. For example, where we discuss the positive correlates of similarity:</p><p>“Our analysis showed that greater similarity-based contributions to the winning category choice were associated with activation in the MTL (left hippocampus) vmPFC, and primary motor cortex (Figure 6A, depicted in red). […] While more anterior motor-planning regions such as pre-SMA and SMA tend to be associated with rule acquisition processes (e.g., Boettiger and D’Esposito, 2005), primary motor cortex has been found to track increasing levels of response automaticity in categorization tasks (Walschmidt and Ashby, 2011).”</p><disp-quote content-type="editor-comment"><p>7) Analysis of face regions with face stimuli:</p><p>Why didn't the authors look at face activation in a face region (e.g., FFA) at all? Faces are the imperfect predictor here, which means they are the stimulus with the most flexibility in terms of associating with the outcome. Wouldn't a key prediction of the dissGCM model be that faces be more similar to object and scene area activity on trials when the common outcome is selected and vice versa for trials where the rare outcome is selected? It seems odd that the analysis is restricted to objects and scenes given the unique position face stimuli are given in the task.</p></disp-quote><p>Consistent with the reviewers’ suggestion, we analyzed BOLD pattern similarity to faces using the same ROI-selection technique as was used for objects and scenes (6 mm spheres around subject-specific activation peaks within right temporal occipital fusiform gyrus). For the test analysis, we now report and depict mean pattern similarity to faces for the ambiguous test trials alongside the object/scene patterns in Figure 3 and Figure 3—figure supplement 1. Pattern similarity to faces was not found to differ between trials where a common or rare response was made. We did not include the face dimension in the primary mixed effects model, with the following rationale now included in the manuscript:</p><p>“Because faces were off-screen for the key test trials and pattern similarity to the face dimension could represent information associated with either common or rare exemplars, no a priori predictions were made regarding pattern similarity to faces on ambiguous trials. However, a one-sample t-test revealed no significant differences in pattern similarity to the face dimension across responses, t (21) = 0.22, p =. 828. Mean pattern similarity to faces on the ambiguous test trials is depicted by the grey squares in Figure 3, with error bars absent to indicate that these values did not contribute to the main statistical model.”</p><p>Additionally, we now analyze pattern similarity to the imperfectly predictive faces during the learning phase in relation to subjects’ IBRE tendencies, as was previously done for the perfect common and rare predictors. Unlike the ambiguous test trials, faces were an on-screen stimulus dimension throughout the learning phase, and accordingly, serve as excellent controls for the perfect predictor correlations in this analysis. We now depict the respective relationships between pattern similarity to faces on common/rare disease trials and test behavior in Figure 5. The results of the brain-behavior correlations are also detailed in the text:</p><p>“Figure 5 depicts the associations between BOLD pattern similarity to common and rare stimulus dimensions during learning and base rate neglect. […] Likewise, the difference in positive slope between pattern similarity and base rate neglect for common versus rare perfect predictors was marginally significant, t (60) = 1.88, p =. 065.”</p><p>Please note that for the results above, the correlations for pattern similarity to the common and rare features have changed slightly. This is because the previous correlations were calculated using rare response probabilities obtained from our MVPA output files, which discard the final trial of each scanning run to ensure stable estimates. We now correctly include the final trial from the behavioral data in this analysis. The inclusion (or previous omission) of this final trial did not affect the interpretation or statistical significance of the previously reported correlations compared to what we find here.</p><disp-quote content-type="editor-comment"><p>8) Behavioral analysis:</p></disp-quote><p><italic>For the behavioral analysis (Figure 2), was the interaction formally decomposed? Please report the relevant statistics in detail. It is also puzzling why reaction time was not reported. Reaction time could shed light on the mechanisms underlying choices. For example, if replying based on similarity is due to habitual responding, one would predict faster RTs in that case. One would also expect longer RTs for more deliberative choices.</italic></p><p>For the learning curves presented in Figure 2, we now decompose the interaction effect using a linear mixed effects model to appropriately account for the nesting structure in the data (trials within participants) and report where categorization accuracy was significantly higher for the common disease during the learning phase. Blocks where significant differences were observed are now indicated in the figure as well.</p><p>We appreciate the reviewers’ suggestion to examine reaction time patterns in the data. Consistent with the idea that rare responses may involve a more cognitively demanding (dissimilarity-based) process, analyzing RTs for the different responses on ambiguous test trials revealed that rare responses were indeed made more slowly than common responses. These findings are now detailed in the behavioral Results section:</p><p>“In addition to response probabilities, we tested whether reaction times differed on the ambiguous test trials depending on whether a rare or common response was made. On these trials of interest, a linear mixed effects model revealed that RTs were considerably slower when participants made rare responses (M = 1.47 s) in comparison to common responses (M = 1.27 s), t (21) = 10.48, p &lt;.001. The observation of slowed RTs on ambiguous trials receiving rare responses suggests that rare selections may be more cognitively demanding relative to common selections, consistent with previous dissimilarity-based theories of IBRE that posit a role of higher-level, inferential reasoning in base rate neglect.”</p><disp-quote content-type="editor-comment"><p>9) Presentation of consecutive rare stimuli:</p><p>Are there any trials where the authors present two consecutive rare stimuli? Carvalho and Goldstone (2015) suggest that participants make decision by comparing the stimulus at time t with the stimulus at time t-1. In the current article, the stimulus at time t-1 is more likely to be from the same category as the stimulus at time t for common categories than for rare categories. Same category stimuli focus on within-category information (similarity) while different category stimuli focus on between-category information (dissimilarity). This alternative explanation does not rely on base rate and should be discussed.</p></disp-quote><p>We now include a Discussion section explaining how interleaved versus blocked designs (and how they create runs of same- vs. different-category trials) lead to differences in selective attention that emphasize features that are characteristic of a category (blocked, emphasizing within category) versus distinguishing between category differences (interleaved), and connect these findings to the interpretation of the present study. For example:</p><p>“Early studies on the role of order and blocking on IBRE are similar to current work on blocked versus interleaved learning in the broader categorization literature (Birnbaum et al., 2013; Carvalho and Goldstone, 2014, 2015; Goldwater et al., 2018). […] Contrastingly, our MVPA and univariate fMRI results show that pure similarity-based processing cannot fully explain the IBRE, and thus strongly suggest that dissimilarity processes contribute to the IBRE.”</p></body></sub-article></article>