<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">43625</article-id><article-id pub-id-type="doi">10.7554/eLife.43625</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Representational untangling by the firing rate nonlinearity in V1 simple cells</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-126900"><name><surname>Gáspár</surname><given-names>Merse E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-65214"><name><surname>Polack</surname><given-names>Pierre-Olivier</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1716-6595</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-40842"><name><surname>Golshani</surname><given-names>Peyman</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-31486"><name><surname>Lengyel</surname><given-names>Máté</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7266-0049</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-125665"><name><surname>Orbán</surname><given-names>Gergő</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2406-5912</contrib-id><email>orban.gergo@wigner.mta.hu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>MTA Wigner Research Center for Physics</institution><addr-line><named-content content-type="city">Budapest</named-content></addr-line><country>Hungary</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Cognitive Science</institution><institution>Central European University</institution><addr-line><named-content content-type="city">Budapest</named-content></addr-line><country>Hungary</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Center for Molecular and Behavioral Neuroscience</institution><institution>Rutgers University</institution><addr-line><named-content content-type="city">Newark</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Integrative Center for Learning and Memory, Brain Research Institute</institution><institution>University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Department of Neurology</institution><institution>David Geffen School of Medicine, University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution>West Los Angeles VA Medical Center</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution content-type="dept">Department of Engineering, Computational and Biological Learning Lab</institution><institution>University of Cambridge</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Rust</surname><given-names>Nicole</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>10</day><month>09</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e43625</elocation-id><history><date date-type="received" iso-8601-date="2018-11-14"><day>14</day><month>11</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-08-13"><day>13</day><month>08</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Gáspár et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Gáspár et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-43625-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.43625.001</object-id><p>An important computational goal of the visual system is ‘representational untangling’ (RU): representing increasingly complex features of visual scenes in an easily decodable format. RU is typically assumed to be achieved in high-level visual cortices via several stages of cortical processing. Here we show, using a canonical population coding model, that RU of low-level orientation information is already performed at the first cortical stage of visual processing, but not before that, by a fundamental cellular-level property: the thresholded firing rate nonlinearity of simple cells in the primary visual cortex (V1). We identified specific, experimentally measurable parameters that determined the optimal firing threshold for RU and found that the thresholds of V1 simple cells extracted from in vivo recordings in awake behaving mice were near optimal. These results suggest that information re-formatting, rather than maximisation, may already be a relevant computational goal for the early visual system.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>vision</kwd><kwd>linear decoding</kwd><kwd>intracellular</kwd><kwd>mixed selectivity</kwd><kwd>firing rate nonlinearity</kwd><kwd>membrane potential</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003825</institution-id><institution>Hungarian Academy of Sciences</institution></institution-wrap></funding-source><award-id>Lendulet Fellowship</award-id><principal-award-recipient><name><surname>Gáspár</surname><given-names>Merse E</given-names></name><name><surname>Orban</surname><given-names>Gergo</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Gáspár</surname><given-names>Merse E</given-names></name><name><surname>Lengyel</surname><given-names>Máté</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000854</institution-id><institution>Human Frontier Science Program</institution></institution-wrap></funding-source><award-id>RGP0044/2018</award-id><principal-award-recipient><name><surname>Golshani</surname><given-names>Peyman</given-names></name><name><surname>Lengyel</surname><given-names>Máté</given-names></name><name><surname>Orban</surname><given-names>Gergo</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 MH105427</award-id><principal-award-recipient><name><surname>Golshani</surname><given-names>Peyman</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Golshani</surname><given-names>Peyman</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>National Brain Research Program of Hungary</institution></institution-wrap></funding-source><award-id>2017-1.2.1-NKP-2017-00002</award-id><principal-award-recipient><name><surname>Orban</surname><given-names>Gergo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Firing rate nonlinearity recovers linear decodability of orientation information from simple cells of the primary visual cortex under uncertainty of nuisance parameters phase and spatial frequency.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The visual cortex relies on a series of hierarchically organised processing stages to construct increasingly complex representations of the visual environment (<xref ref-type="bibr" rid="bib37">Orban, 2008</xref>; <xref ref-type="bibr" rid="bib50">Tafazoli et al., 2017</xref>; <xref ref-type="bibr" rid="bib52">Ungerleider and Haxby, 1994</xref>). An important goal of this processing hierarchy in the ventral visual stream is to represent information about stimuli in a format that facilitates behaviourally relevant tasks, such as object recognition, identification, or classification. This reformatting of information has been called ‘representational untangling’ (RU; <xref ref-type="bibr" rid="bib19">DiCarlo and Cox, 2007</xref>; <xref ref-type="bibr" rid="bib9">Bengio et al., 2013</xref>) and it is often formalised via the concept of linear decodability. Linear decoding measures the extent to which a particular stimulus feature (such as the identity of an object) is explicitly encoded in a representation such that it can be accurately estimated based on a simple weighted sum of the activation of representational units (<xref ref-type="bibr" rid="bib11">Bishop, 2006</xref>). For example, classification boundaries for different objects appear highly non-linear and ‘tangled’ in the space of pixel intensities, or the space of retinal or primary visual cortical (V1) activities, thus preventing efficient linear decoding of object identity information. In contrast, in inferior temporal cortex (IT), these boundaries become untangled, making object identity information linearly decodable (<xref ref-type="bibr" rid="bib18">DiCarlo et al., 2012</xref>). Critically, linear decodability of a stimulus feature does not only require that neural responses are modulated by this feature, but also that at the same time they remain tolerant to, that is depend only weakly or trivially on other, ‘nuisance’ stimulus features that can also change across stimuli. For example, while neural responses across the whole visual system, from the retina and V1 to IT, will change when different objects are presented, the activation of select IT cells shows tolerance to changes in 'nuisance’ parameters, such as illumination, location or scale (<xref ref-type="bibr" rid="bib12">Brincat and Connor, 2004</xref>; <xref ref-type="bibr" rid="bib19">DiCarlo and Cox, 2007</xref>; <xref ref-type="bibr" rid="bib28">Ito et al., 1995</xref>; <xref ref-type="bibr" rid="bib33">Logothetis et al., 1994</xref>; <xref ref-type="bibr" rid="bib51">Tanaka, 1996</xref>; <xref ref-type="bibr" rid="bib53">Vogels and Biederman, 2002</xref>).</p><p>The neural mechanisms underlying RU are largely unknown, with most previous work focussing on RU of object category information in IT, and how the cascaded nonlinear input-output transformations of the early stages of the visual hierarchy contribute to it (<xref ref-type="bibr" rid="bib27">Hung et al., 2005</xref>; <xref ref-type="bibr" rid="bib38">Pagan et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Yamins and DiCarlo, 2016</xref>). In contrast, we study an elementary form of RU that is already taking place at the first stage of visual cortical processing, in V1, and uses a simple and ubiquitous property of single neurons: the firing rate nonlinearity (FRNL), that is the nonlinear transformation between a cell’s membrane potential and its instantaneous firing rate. In V1, there is broad agreement that an image feature that is explicitly represented is local orientation. Indeed, several studies investigated linear decodability of stimulus orientation directly from V1 firing rates (or spike counts) as a function of tuning curve properties (<xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Seriès et al., 2004</xref>; <xref ref-type="bibr" rid="bib46">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib48">Shamir and Sompolinsky, 2006</xref>), noise correlations (<xref ref-type="bibr" rid="bib10">Berens et al., 2012</xref>; <xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>), or the internal dynamics of V1 (<xref ref-type="bibr" rid="bib24">Gutnisky et al., 2017</xref>). However, previous work did not examine membrane potential responses, and was thus not suitable for studying the specific contribution of the FRNL to linear decodability. Moreover, these studies only considered at most a single nuisance parameter (contrast), thus requiring only minimal RU to be carried out in neural responses.</p><p>In order to study the contribution of the FRNL to RU in V1, we directly compared the linear decodability of stimulus orientation from membrane potentials and firing rates, and considered some of the most prevalent nuisance parameters of visual stimuli: contrast (an elementary aspect of illumination), phase (location), and spatial period (scale). We found that nuisance parameters made the linear decodability of orientation information non-trivial: once this richer set of nuisance parameters was considered, membrane potential responses of a population of orientation-selective cells remained highly tangled, and linearly undecodable. However, despite the obvious loss of <italic>total</italic> information caused by the rectifying aspect of the FRNL, which is due to all membrane potential values below the firing threshold being mapped to zero firing rate, the <italic>format</italic> of information in firing rates was more amenable to the linear decoding of orientation. This trade-off between total information and linear decodability resulted in a clear optimum for the value of the firing threshold. In particular, the optimal firing threshold depended on a few key experimentally measurable parameters, and we confirmed in <italic>in vivo</italic> intracellular recordings that mouse V1 simple cells had their thresholds near the optimal value. These results suggest that RU may be a universal principle of organisation throughout the visual system, and it involves cellular as well as circuit-level mechanisms.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>In order to study the RU of information about stimulus orientation in V1 responses, we adapted a canonical population coding model (<xref ref-type="bibr" rid="bib29">Jones and Palmer, 1987</xref>) (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We chose this model as it had the minimal complexity necessary for systematically studying the effects of specific single-neuron (e.g. FRNL threshold, membrane potential variability) and network parameters (e.g. population size, noise correlations) on the encoding of stimulus orientation in the face of other (nuisance) stimulus features affecting neural responses. More specifically, the membrane potential response of each model neuron was determined by the linear response of the neuron-specific oriented Gabor filter to the stimulus. These Gabor filters approximated the receptive field properties of simple cells, resulting in response characteristics that were modulated by the orientation, frequency, and phase of a static, full field sinusoidal grating stimulus (<xref ref-type="bibr" rid="bib17">Dayan and Abbott, 2005</xref>). To model the <italic>in vivo</italic> variability of V1 membrane potential responses in awake animals (<xref ref-type="bibr" rid="bib25">Haider et al., 2013</xref>), these membrane potentials were then subject to additive Gaussian noise independently sampled in time windows whose length (20 ms) was approximately matched to the decay time of the autocorrelation function of simple cells (<xref ref-type="bibr" rid="bib4">Azouz and Gray, 1999</xref>). The firing rate of each cell was obtained using a rectifying nonlinearity that has been shown to capture the FRNL of simple cells (<xref ref-type="bibr" rid="bib14">Carandini and Ferster, 2000</xref>; <xref ref-type="bibr" rid="bib20">Dorn and Ringach, 2003</xref>; <xref ref-type="bibr" rid="bib42">Priebe and Ferster, 2008</xref>). RU was quantified by the performance of a linear decoder which decoded stimulus orientation from membrane potentials or firing rates in the face of noise and variability in other (nuisance) parameters of the stimulus: phase, contrast, and spatial frequency (<xref ref-type="fig" rid="fig1">Figure 1</xref>, blue).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.002</object-id><label>Figure 1.</label><caption><title>Model schematic.</title><p>Left: sine wave grating stimulus used as input to the model population. The stimulus is parametrised by orientation (<inline-formula><mml:math id="inf1"><mml:mi>ϑ</mml:mi></mml:math></inline-formula>) and nuisance parameters phase (<italic>φ</italic>), spatial period (λ), and contrast (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). Middle: simple cell membrane potential (MP) responses (grey boxes) are obtained using localised, oriented Gabor filters and temporally correlated additive noise (Gaussian, with standard deviation σ). The mean response varies sinusoidally (with amplitude <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) around the baseline (<inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) as the phase of the grating stimulus is changing. The stochastic component of the MP response of each neuron is variable in time (black line) and across trials (gray lines). Firing rate is obtained by transforming the MP through a threshold-power-law firing rate nonlinearity (FRNL), characterised by threshold <italic>u</italic><sub>th</sub> and exponent κ. Right: linear decoding of orientation from the population response of <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> simple cells yields the estimated orientation (<inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>ϑ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig1-v1.tif"/></fig><p>We studied RU as a function of parameters describing the stimulus distribution as well as parameters describing the neural population. As the complete parameter space of the model (including the detailed stimulus filter of every neuron) was vast, it was unfeasible to explore it fully. Thus, we focussed on a few key characteristics of our model neurons (<xref ref-type="fig" rid="fig1">Figure 1</xref>, red): the mean membrane potential (<inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and depth of modulation (<inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), which were defined based on the membrane potential response to a drifting full-field grating at 100% contrast, preferred orientation and preferred spatial period; noise variability (<inline-formula><mml:math id="inf9"><mml:mi>σ</mml:mi></mml:math></inline-formula>), which determined the magnitude of the noise injected into membrane potentials; and the threshold (<inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and exponent (<inline-formula><mml:math id="inf11"><mml:mi>κ</mml:mi></mml:math></inline-formula>) of the single neuron FRNL. At the population level, we studied the effects of population size (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>); decoding resolution (<inline-formula><mml:math id="inf13"><mml:mi>K</mml:mi></mml:math></inline-formula>), defined as the number of different orientation categories to be decoded; and the magnitude of noise correlations (<inline-formula><mml:math id="inf14"><mml:mi>ρ</mml:mi></mml:math></inline-formula>) with a given structure, that is the correlation between the membrane potential noise of different cells in the population.</p><sec id="s2-1"><title>The effect of response rectification on representational untangling</title><p>The effects of noise and nuisance parameters on linear decodability can be understood by considering the binary discrimination of two orientations in a pair of neurons responding to stimuli with variable orientation (to be decoded) and phase (to which the decoder is required to be invariant) (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This binary classification task (discrimination) generalises for multiclass cases that can be regarded as combinations of pairwise comparisons. In the model, filter responses depend both on the orientation and phase of the stimulus: at any particular orientation, variability in phase induces a manifold of responses (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, coloured ellipses). Membrane potential responses are derived from filter responses but are contaminated by noise (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, coloured dots), which introduces uncertainty even when phase is fixed and known. Nevertheless, as long as the phase of the stimulus is fixed (and the noise is not overwhelmingly large), all membrane potential values scatter around the same value for each orientation, creating well separated sets of joint responses so that orientation remains linearly decodable (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, green line shows optimal classification boundary). However, variability in phase introduces a substantial amount of additional variability in responses along the corresponding manifolds which intersect multiple times. This causes the sets of membrane potential responses to become strongly overlapping (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, coloured dots) and the optimal decision boundary to become highly nonlinear (‘entangled’, <xref ref-type="fig" rid="fig2">Figure 2C</xref>, green line), such that no linear decision boundary can approximate it efficiently. Thus, even the representation of orientation information by orientation-tuned cells can become highly entangled in the presence of nuisance parameters.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.003</object-id><label>Figure 2.</label><caption><title>Effect of phase variability on the linear separability of the responses of a pair of simple cells.</title><p>(<bold>A</bold>) Filter responses of a pair of model simple cells to gratings with various orientations (different colours) and phases (position along ellipses). Circles mark a pair of example stimulus phases at two different orientations. (<bold>B</bold>) Stochastic membrane potential responses of the pair of cells (dots) at the reference pair of stimulus orientations and phases (gray circles with black contour). Gray lines show average responses at other phases and orientations for reference. The optimal decision boundary (green line) constructed for membrane potential responses is a straight line and it is thus achievable by a linear decoder. (<bold>C</bold>) Membrane potential responses (coloured dots) to stimuli with the same pair of orientations as in B but for variable stimulus phase (gray ellipses with black contour). Phase variability abolishes the linear separability of responses given to different orientations: the decision boundary of the optimal decoder (green line) is highly nonlinear. (<bold>D</bold>) Filter responses as in A but truncated due to the threshold linear transformation of the FRNL. (<bold>E–F</bold>) Same as B-C, but for firing rate responses. Note that the decision boundary of the optimal decoder of firing rate responses (F, green line) can be well approximated by a linear decoder (F, dark green line).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig2-v1.tif"/></fig><p>Nonlinear transformations of variables can render even complex representations linearly decodable – an insight that underlies many pattern recognition algorithms (<xref ref-type="bibr" rid="bib11">Bishop, 2006</xref>). Specifically, in our case, we focus on the rectifying aspect of the firing rate nonlinearity of neurons. This rectification effectively ‘removes’ a large part of the membrane potential response space thus letting the decoder operate only on the quadrant of super-threshold responses (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). While this drastic removal of a large fraction of responses can clearly lead to severe total information loss (<xref ref-type="bibr" rid="bib6">Barak et al., 2013</xref>), responses in the remaining quadrant may also become more linearly separable. This is because the density of manifold intersections generally decreases towards higher membrane potential values. In other words, the rectification only allows strongly responding cells to contribute to decoding, and the resulting sparsification of the representation will generally render it more linearly separable (<xref ref-type="bibr" rid="bib6">Barak et al., 2013</xref>). This explains why the optimal decision boundary for firing rates remains well approximated by a line (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), even with variability in stimulus phase (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, the decision boundary of the optimal decoder is shown in light green while that of the best linear decoder in dark green). Thus, there is a trade-off for RU between total information loss and sparsification controlled by the firing threshold, and this trade-off becomes particularly acute in the face of nuisance parameter variations.</p></sec><sec id="s2-2"><title>Orientation decoding from a population under phase variability</title><p>In order to study the trade-off between total information loss and sparsification quantitatively, we parametrically varied the firing threshold in a population of <inline-formula><mml:math id="inf15"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:math></inline-formula> neurons, each characterised by identical firing thresholds and noise but random receptive field parameters (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). To simplify our analysis, we assumed a rectified linear FRNL (see below for FRNLs with exponents greater than one). At each threshold level, we compared the performance of two decoders: a linear decoder, and an optimal Bayesian decoder (see Materials and methods). The linear decoder was trained and tested on different subsets of data differing in the membrane potential noise added to the linear filter responses of model neurons. The training data set was sufficiently large that asymptotic test performance was achieved, therefore the performance of the linear decoder was limited solely by the properties of the stimuli and not by the amount of data. The optimal decoder was constructed with perfect knowledge of the process generating neural responses and thus did not need to be separately trained. As it used the optimal decision boundaries, the performance of the Bayesian decoder represented a theoretical upper bound on the performance of <italic>any</italic> decoder, and could also be used to quantify the total information content of responses (Materials and methods; <xref ref-type="bibr" rid="bib39">Panzeri et al., 1999</xref>). Each decoder was tested with the phase of the stimulus kept fixed (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, black: linear decoder, gray: optimal decoder) or being varied (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, dark blue: linear decoder, light blue: optimal decoder).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.004</object-id><label>Figure 3.</label><caption><title>Effect of phase variability on decoding performance.</title><p>Orientation decoding from firing rates (FR) was performed for grating stimuli with fixed (black and grey) or unknown phase (dark and light blue) using an optimal (lighter colours) or linear decoder (darker colours). (<bold>A</bold>) Decoding performance as a function of the FRNL threshold (solid lines). Black dotted line shows chance performance. Green shaded area shows the distribution of membrane potentials for reference. Red line shows sparseness of responses as a function of the FRNL threshold. Inset shows the performance of the linear decoder against the performance predicted by the normalised optimal decoder (the combined effect of total information and sparseness) at different values of the FRNL threshold under variable phase (blue dots). Note that decoding from firing rates with FRNL threshold values below the membrane potential distribution is equivalent to decoding from membrane potentials. (<bold>B</bold>) Performance of the linear decoder using firing rates (FR) obtained with the optimal FRNL thresholds (diamonds on A) and membrane potentials (MP). Horizontal lines show the performance of the optimal decoder at the corresponding FRNL threshold values. (<bold>C</bold>) Performance of linear decoder with fixed (black bars) and unknown phase (blue bars) for a neuron population with pixel-like receptive fields. As no optimal threshold existed with this population, the firing rate decoder was evaluated at the optimal FRNL threshold of the Gabor population. (<bold>D</bold>) Same as panel C but for a population with center-surround receptive fields.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.005</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Properties of the model neuron population.</title><p>(<bold>A</bold>) Gabor filters characterising the model neurons. A fixed set of Gabor filters was used throughout the simulations (but see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) that characterise the receptive field properties of the model neuron population. Receptive field locations were randomly sampled on a 90 degree circle (approximating the visual field), with random orientations and phase but fixed spatial frequency and receptive field size (see Materials and methods and <xref ref-type="table" rid="table1">Table 1</xref>). (<bold>B</bold>) Representation of the linear decoder parameters trained for membrane potential decoding (top panel) and firing rate decoding (lower panel). Colour code shows the strength of the connection between model neurons and the orientations the decoder distinguishes. There is no clear pattern in the connection strengths of the membrane potential decoder. In the case of the firing rate decoder, however, stronger weights are characteristic of neurons with preferred orientations matching the orientations represented by the decoder. Note the different colour scales in B and C.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.006</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Alternative measures for the characterisation of decoding performance.</title><p>(<bold>A</bold>) Linear decoding performance as a function of the FRNL threshold for fraction correct (blue), probabilistic faction correct (black), and cosine error (yellow). For fraction correct, in any given trial the class with the maximal class probability is chosen and the fraction of correct choices across trial is plotted. For the probabilistic fraction correct, class probabilities are normalised and the mean normalised class probability of the correct choice is calculated. The cosine error measure (yellow) is based on a weighted sum of the orientations characterising the classes and the cosine of the angular deviation of the resulting orientation from the true orientation is measured. While the performance of the performance measures is not equal, the optimal threshold (diamonds and ticks on the horizontal axis) is only marginally affected by the choice of measure. (<bold>B</bold>) Optimal decoding performance as measured by fraction correct (blue) and probabilistic fraction correct (black), similar to panel A. Mutual information between the population responses and the stimulus orientation (yellow) is a shifted and exponentiated version of the probabilistic fraction correct (see text). At low threshold levels, the mutual information equals the logarithm of the number of decoded orientations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.007</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Linear decoding performance with variable phase for narrow and wide field of view.</title><p>Receptive fields are distributed either on a 90-degree circle (blue) or a 3-degree circle (red). Shaded area shows the full range of variance (between maximal and minimal decoding performance in 25 simulations). Representational untangling is not affected by assessing local orientation instead of global orientation. The blue line is identical to the one shown on <xref ref-type="fig" rid="fig3">Figure 3A</xref> of the main text.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig3-figsupp3-v1.tif"/></fig></fig-group><p>The performance of the optimal decoder simply decreased monotonically as the threshold was increased (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, gray and light blue). This was expected because the thresholding effect of the FRNL loses information in the subthreshold range (as in this range all membrane potential values are mapped to the same zero firing rate) while the super-threshold part of the FRNL (even if it is nonlinear) represents a one-to-one mapping which does not change information content. This means that the net effect of the FRNL can only be information loss, with higher thresholds leading to larger information loss (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref>). Therefore, as long as the functional objective of V1 was the maximisation of total orientation information transmitted to downstream areas (the so-called 'infomax' principle; <xref ref-type="bibr" rid="bib32">Linsker, 1988</xref>; <xref ref-type="bibr" rid="bib8">Bell and Sejnowski, 1997</xref>), one would expect to see low values of the firing threshold, clipping the membrane potential distribution as little as possible (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, green shaded area).</p><p>In contrast to the simple monotonic decrease in total information, linear decoding performance showed a more complex, non-monotonic dependence on the firing threshold. At the lowest values of the threshold, all membrane potential responses were super-threshold (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, green histogram shows the distribution of membrane potential responses across all stimuli), and so decoding from firing rates was essentially equivalent to decoding from membrane potentials. Thus, as expected (<xref ref-type="fig" rid="fig2">Figure 2</xref>), linear decoding with variable stimulus phase was at chance (10%) at this extreme, that is it was unable to extract any information about orientation from the membrane potential responses of the population (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, left blue bar). Correspondingly, the coefficients of the linear decoder did not bear any systematic relationship with the preferred orientations of neurons and the decoded orientations (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). The failure of linear decoding was due to membrane potential responses fully reverting for stimuli with anti-preferred phases. This meant that depending on stimulus phase, responses for the preferred orientation of a cell could be well above or below responses to non-preferred orientations, thus violating the monotonic relationship that linear decoding requires between responses and the match of stimulus orientation to the preferred orientation of cells. For fixed stimulus phase, linear decodability was well above chance (~87%) even at low threshold values (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, left black bar). Note that, unlike the case suggested in <xref ref-type="fig" rid="fig2">Figure 2</xref>, it did not reach the performance of the optimal decoder because we allowed orientation itself to vary within each <inline-formula><mml:math id="inf16"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> discrete decoded orientation categories, making the optimal decision boundaries slightly nonlinear even at a fixed stimulus phase.</p><p>At extremely high values of the firing threshold, membrane potential responses always remained sub-threshold, keeping firing rates zero at all times. Thus, all decoders performed at chance due to this total loss of information. Between the two extremes, as the threshold increased, there was a trade-off between two opposing effects: the total information in responses decreased, as shown by the monotonically decreasing performance of the optimal decoder (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, gray and light blue; see also above), while responses became increasingly sparser (see Materials and methods, <xref ref-type="fig" rid="fig3">Figure 3A</xref>, red), increasing the linear decodability of the remaining information (see <xref ref-type="fig" rid="fig2">Figure 2F</xref>). As a result of this trade-off, linear decoding had a pronounced peak with an optimum at intermediate firing thresholds values, around <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo> <mml:mi/><mml:mo>-</mml:mo><mml:mn>57</mml:mn></mml:math></inline-formula> mV in this case (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, dark blue diamond; <xref ref-type="fig" rid="fig3">Figure 3B</xref> right blue bar), that is ~3 mV above the average membrane potential (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). This optimal firing threshold was largely independent of the precise measure used to quantify performance, whether it was simply the fraction of correct responses used here and in the following, a statistically more appropriate probabilistic fraction correct measure, or a measure that also depended on the magnitude of the (circular) error between true and decoded orientation (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref>). The success of linear decoding at the optimal threshold was also reflected in the patterns of decoding coefficients: as expected, they scaled with the difference between a neuron’s preferred orientation and the decoded orientation (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>). To assess the extent to which the FRNL threshold threshold was effective in helping RU using local image patches instead of grating stimuli covering a large portion of the visual field, we also performed the same analysis with a 500-neuron population resembling a V1 hypercolumn, with receptive fields covering only a 3° circle, produced results similar to those obtained with full-field stimuli. (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><p>In order to see how much the trade-off between total information loss and population sparseness could account for linear decodability, we computed the correlation between the actual performance of the linear decoder and the performance that could be predicted based on scaling the performance of the optimal decoder (FC<sub>opt</sub>, indicative of total information, see above) by population sparseness: (FC<sub>opt</sub> - chance) × sparseness + chance. We found a strong correlation across different values of the firing threshold between the actual and predicted performance of the linear decoder (<inline-formula><mml:math id="inf18"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.98</mml:mn></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3A</xref>, inset). For fixed stimulus phase, decision boundaries were generally more linear, thus the reduction of overall information dominated, which resulted in only a smaller peak in performance at around the same threshold value (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, black diamond; <xref ref-type="fig" rid="fig3">Figure 3B</xref> right black bar).</p></sec><sec id="s2-3"><title>Representational untangling of orientation is specific to V1</title><p>To show that the RU of orientation information is specific to V1 and does not occur at earlier stages of visual processing, we performed simulations with two other model neuron populations in which selectivities of individual neurons resembled that of neurons in the retina and the lateral geniculate nucleus (LGN). For this we used neurons that were sensitive to a single pixel in the stimulus (as a simple model of photoreceptor activations in the retina; <xref ref-type="fig" rid="fig3">Figure 3C</xref>, inset) or neurons characterised by center-surround receptive fields (modelling retinal ganglion and LGN cells; <xref ref-type="fig" rid="fig3">Figure 3D</xref> inset). For a fair comparison with our V1 population, we used the same number of cells, with the same set of receptive field locations, and the same amount of overall signal and noise variability in their membrane potentials.</p><p>While linear decodability was similarly high as from V1 responses without phase nuisance (<xref ref-type="fig" rid="fig3">Figure 3C–D</xref>, black bars; cf. <xref ref-type="fig" rid="fig3">Figure 3B</xref>, black bars), it was markedly different once phase nuisance was introduced (<xref ref-type="fig" rid="fig3">Figure 3C–D</xref>, blue bars; cf. <xref ref-type="fig" rid="fig3">Figure 3B</xref>, blue bars). Not only was orientation linearly undecodable from the membrane potentials of our model retinal and LGN populations (<xref ref-type="fig" rid="fig3">Figure 3C–D</xref>, MP blue bars) but, in contrast to the V1 population, it also remained undecodable from their firing rates, even with the best possible choice of the firing threshold (<xref ref-type="fig" rid="fig3">Figure 3C–D</xref>, FR blue bars; see Appendix 1 for an intuition).</p></sec><sec id="s2-4"><title>Decoding with multiple nuisance features</title><p>Simple cells in V1 show mixed selectivity to a number of stimulus features beside orientation and phase. Thus, we extended our analyses to include two more nuisance features, spatial frequency (or its inverse, spatial period) and contrast, that are among the two strongest modulators of V1 responses (<xref ref-type="bibr" rid="bib26">Hubel and Wiesel, 1968</xref>) and, in addition, they are analogous to size and illumination, which are in turn among the most commonly considered nuisance features for high-level RU (<xref ref-type="bibr" rid="bib12">Brincat and Connor, 2004</xref>; <xref ref-type="bibr" rid="bib28">Ito et al., 1995</xref>; <xref ref-type="bibr" rid="bib53">Vogels and Biederman, 2002</xref>). We tested linear decoding performance with all eight possible combinations of these nuisance features varying or being fixed. When varied, each feature was sampled from a probability density that was chosen to reflect the main characteristics of natural stimulus statistics (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, Materials and methods). When fixing a nuisance feature, we chose a value that was near the mean of the natural distribution (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, ticks on the x-axis).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.008</object-id><label>Figure 4.</label><caption><title>Effect of nuisance parameter variability on decoding performance.</title><p>Nuisance parameters were varied individually (blue: phase; green: spatial period; red: contrast) or in combination (mixture colours). (<bold>A</bold>) Parameter distributions used for varying nuisance parameters: uniform for stimulus phase (left), lognormal for spatial period (middle), and beta distribution for contrast (right). Ticks on x-axes show parameter values used when the corresponding parameter was fixed. (<bold>B</bold>) Linear decoding performance as a function of the FRNL threshold for different combinations of variable nuisance parameters (colours, see legend for details: ‘v’ denotes variable, ‘.’ denotes fixed parameter). Coloured ticks on x-axis show optimal thresholds for the corresponding combinations of variable nuisance parameters (i.e. the locations of peaks on the corresponding performance curves). Note that even when all nuisance parameters are variable, a linear decoder performs above chance around the optimal threshold. (<bold>C</bold>) Linear decoding performance for firing rates obtained with optimal FRNL threshold values under different nuisance parameter uncertainties (bars, colours as in B) and for membrane potentials (white lines). Note that the only nuisance parameter that shows membrane potential decoding performance considerably above chance is contrast (red). Simulations without nuisance parameter variability (black) and with only phase variability (blue) are replotted from <xref ref-type="fig" rid="fig3">Figure 3A</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.009</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Variance in decoding performance as a result of variations in receptive field parameters of model neurons.</title><p>Randomness was introduced by resampling the positions and phases of the Gabor filters that characterise the receptive fields of the model neurons. Means (bars) and 2 s.D. (error bars) are calculated from 25 random settings of the population. Sensitivity of the optimal performance of firing rate (filled bars) and membrane potential decoders (white horizontal lines on the bars) to variations in encoding population parameters for different nuisance parameter combinations. All of the membrane potential decoders where nuisance parameters are present (white lines on coloured bars) are significantly lower than that of the no-nuisace membrane potential decoder (white line on black bar), unpaired t-test: p=1.5e-33, t[22.1]=−132.5; p=4.0e-39, t[27.7]=−119.3; p=5.0e-27, t[43.3]=−24.5; p=1.9e-33, t[22]=−132.3; p=1.8e-33, t[22.1]=−131.5; p=2.2e-36, t[25]=−124.7; p=1.8e-33, t[22]=−132.4 for the seven bars, respectively. Firing rate decoders (coloured bars) were consistently outperforming membrane potential decoders for all conditions except for the case where contrast was the only nuisance parameter, consistent with the fact that contrast introduces variations that do not directly affect linear decoding boundaries (unpaired t-test: p=1.9e-33, t[22]=132.6; p=0.58, t[24]=−0.6; p=3.3e-14, t[24]=15.8; p=1.1e-33, t[23]=120.0; p=1.6e-12, t[24]=13.2; p=3.9e-17, t[24]=21.3; p=1.0e-13, t[24]=15.1; p=5.8e-06, t[23]=5.8543 for the eight conditions, respectively). Colours match those at <xref ref-type="fig" rid="fig4">Figure 4</xref>. Notice that the variance of optimal performance of the FR decoder is almost negligible, except for the no nuisance (black) and contrast nuisance (red) cases, where variance of membrane potential decoder performances are also high.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.010</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Orientation, spatial period, and contrast decoding from firing rate responses.</title><p>(<bold>A</bold>) Decoding performance for orientation, spatial period, and contrast from firing rate responses as a function of FRNL threshold. Of the four investigated variables (phase, orientation, spatial period, contrast) one was selected as a target for the linear decoder while the other three were treated as nuisance parameters for the decoder. The number of decoding classes were ten in every case. FRNL threshold-dependence showed a peak similar to orientation decoding, with slight variation in the optimal FRNL threshold (coloured ticks). (<bold>B</bold>) Linear decoding performance for firing rates at the optimal FRNL threshold (colours as in <bold>A</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig4-figsupp2-v1.tif"/></fig></fig-group><p>Overall, the pattern of results was similar to that obtained with variability in phase only (<xref ref-type="fig" rid="fig4">Figure 4</xref>, black and blue for no variability in nuisance features, and variability in phase only, respectively, repeated from <xref ref-type="fig" rid="fig3">Figure 3A,B</xref>): more nuisance variability decreased performance (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), and the trade-off between total information and sparseness resulted in a peak in performance at intermediate threshold levels (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, coloured lines). Interestingly, we found the most often studied nuisance parameter to cause the least amount of representational entanglement: variability in contrast affected linear decodability of membrane potentials the least (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, red) because the response manifolds corresponding to changes in contrast were radial lines (as membrane potential responses simply scaled with contrast) which all intersected only at one point and thus created little additional ambiguity (not shown). Importantly, while there was a slight variation in the optimal firing threshold values that allowed maximal decoding performance (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, coloured ticks), this variation was relatively small across the eight combinations of nuisance features we tested and remained largely unchanged when the receptive field parameters of the neurons were perturbed (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p>To test the robustness of these results to variations in stimulus statistics, we also varied the distributions of spatial frequency and contrast (<xref ref-type="fig" rid="fig5">Figure 5A–B</xref>). (We left the uniform phase distribution unchanged as it is unlikely that any realistic stimulus manipulation would lead to particular phases to be overrepresented.) By using the original parameter distributions (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) to construct training stimuli for the decoder and different parameter distributions to test performance, this analysis provided a test of how well the optimal thresholds generalised across different stimulus distributions. We found that the firing thresholds that were optimal for the original stimulus distributions remained near optimal with these changed distributions: there was no discernible loss of performance compared to a decoder which was trained with the modified stimulus distributions (<xref ref-type="fig" rid="fig5">Figure 5C–D</xref>, bars vs. horizontal lines).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.011</object-id><label>Figure 5.</label><caption><title>Robustness of the optimal FRNL threshold to changes in nuisance parameter statistics.</title><p>(<bold>A</bold>) Distributions of spatial period. Grey-shaded distribution is the reference distribution used in other figures where spatial period was a nuisance parameter. (<bold>B</bold>) Performance of the linear decoder under different period distributions (colours as in A) with the ‘default’ FRNL threshold which was optimised to the reference spatial period distribution (bars). As an upper bound, performance with the FRNL threshold re-optimised for each spatial period distribution is also shown (horizontal lines). Note that bars reach horizontal lines in all cases, indicating that performance with the default FRNL threshold is indistinguishable from that achieved with the re-optimised FRNL threshold. (<bold>C–D</bold>) Same as (<bold>A–B</bold>) but for changes in the distribution of stimulus contrast.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig5-v1.tif"/></fig><p>While it is orientation coding that is most often associated with simple cell activity in V1, all other stimulus parameters to which simple cells show selectivity can be regarded as targets for decoding. Thus, to further test the robustness of our findings, we also studied the linear decodability of the spatial period or contrast of stimuli, while letting all other (nuisance) stimulus parameters (including orientation) vary (see Materials and methods). We found that the linear decodability of both stimulus parameters had a similar firing threshold-dependence as that of orientation, with a distinct peak performance close to the optimal threshold for orientation decoding (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>; cf. <xref ref-type="fig" rid="fig4">Figure 4</xref>, grey).</p></sec><sec id="s2-5"><title>Parameter-dependence of the optimal firing threshold</title><p>We noted that for most model settings we studied so far (identity and distribution of fixed vs. variable nuisance stimulus features) there was a clear optimum for the firing threshold which remained roughly constant across all conditions (<xref ref-type="fig" rid="fig4">Figure 4</xref>). In contrast, simple scaling arguments predicted (Materials and methods) that performance should fundamentally depend on specific combinations of single cell parameters (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). In particular, it should depend on how much of the noise variability (<inline-formula><mml:math id="inf19"><mml:mi>σ</mml:mi></mml:math></inline-formula>) versus signal variability (controlled by the depth of modulation, <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) in membrane potentials is 'removed’ (i.e. mapped to zero firing rate) by the thresholding of the FRNL. In turn, the optimal threshold (<inline-formula><mml:math id="inf21"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>) should shift with the mean membrane potential (<inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), and scale when noise and signal variance are jointly scaled. We tested these predictions by varying either the depth of modulation (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, × symbols) or the noise variance of membrane potentials (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, + symbols) and confirmed that in all these cases the appropriately normalised optimal threshold, <inline-formula><mml:math id="inf23"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, showed the same, approximately linear, relationship with the noise-to-signal ratio, <inline-formula><mml:math id="inf24"><mml:mi>σ</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6A</xref>).</p><p>To further test the robustness of this result, we systematically varied a number of other model parameters: the number of neurons in the population (<inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6B</xref>), the number of orientation categories to be decoded (<inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6C</xref>), the magnitude of noise correlations in the population (<inline-formula><mml:math id="inf27"><mml:mi>ρ</mml:mi></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6D</xref>), the super-threshold shape (exponent) of the FRNL of neurons (<inline-formula><mml:math id="inf28"><mml:mi>κ</mml:mi></mml:math></inline-formula>, <xref ref-type="fig" rid="fig6">Figure 6E</xref>). Wherever possible, we varied these parameters around experimentally found values. For example, average noise correlations measured in spike counts in awake V1 are typically reported to be less than 0.1 (<xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>) which imply average membrane potential correlations (which we are modelling here) in the range of 0.06–﻿0.15 (<xref ref-type="bibr" rid="bib5">Bányai et al., 2017</xref>) (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). The average exponent of the suprathreshold part of the FRNL of V1 simple cells was found to be ~1.2 (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). For other parameters, those controlling the size of the population (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), and the resolution of the estimation task (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), experimentally validated data was not available and so we varied them several-fold to ensure our results remained robust to them. In all cases, we measured linear decoding performance while varying phase as the nuisance stimulus feature (as in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, blue).</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.012</object-id><label>Figure 6.</label><caption><title>Dependence of the optimal threshold on model parameters.</title><p>(<bold>A</bold>) Dependence of the normalised optimal threshold (y-axis) on the noise-to-signal ratio (x-axis). The normalised optimal threshold is the deviation of the optimal threshold from the baseline membrane potential, normalised by the magnitude of membrane potential noise: <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (see text for details). Noise-to-signal ratio is the ratio between the magnitude of noise and the strength of the signal: <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Note the same linear dependence irrespective of whether signal strength (×) or noise magnitude is varied (+). (<bold>B–E</bold>) Same as (<bold>A</bold>) for different population sizes (<bold>B</bold>), decoder resolutions (<bold>C</bold>), correlation strengths (<bold>D</bold>) and exponents of the FRNL nonlinearity (<bold>E</bold>). Asterisks mark the default values of the parameters used in other figures. Scaling of the optimal threshold with noise-to-signal ratio is largely independent from changes in these network and cellular parameters except for the exponent of the FRNL nonlinearity which substantially changes the noise-dependence of the optimal threshold.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.013</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Parameter-dependence of optimal FRNL threshold.</title><p>Linear decoding performance was assessed for the linear firing rate decoder under phase uncertainty as a function of FRNL threshold. Stars indicate the default values of the parameters used in other figures. Ticks on the horizontal axis show the optimal FRNL threshold. (<bold>A</bold>) Population size. (<bold>B</bold>) Resolution of the decoder. (<bold>C</bold>) Level of correlation in the noise corrupting membrane potential responses (correlations are homogeneous across all the pairs in the population). (<bold>D</bold>) Exponent of the FRNL. Parameter values match those shown on <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.014</object-id><label>Figure 6—figure supplement 2.</label><caption><title>Effect of information-limiting correlations on decoding performance.</title><p>Information-limiting correlations were induced in the population by introducing random rotations in the orientation of the stimulus. Standard deviation of the noise was five degrees (inset). Average standard deviation of the membrane potential resulting from such stimulus orientation noise was 1.5 mV. So that marginal noise variance on individual neurons is matched with that of the non-correlated case (green shaded area), private noise was introduced with 2.59 mV standard deviation. Information limiting correlations reduce the performance of the Bayesian decoder (light blue). The linear decoder (dark blue) shows a maximum performance close to the optimal FRNL threshold characterising the non-correlated case.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig6-figsupp2-v1.tif"/></fig></fig-group><p>We found that a clear optimum existed for the firing threshold in all cases (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Although peak performance could depend strongly on some model parameters (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), the value of the optimal threshold at which it was achieved was largely independent of these parameters (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Specifically, as expected, peak performance increased with the number of cells in the population (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref>) and decreased with the number of orientation categories to be decoded (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>), but, the scaling of the optimal threshold with the noise-to-signal ratio remained invariant to either parameter (<xref ref-type="fig" rid="fig6">Figure 6B–C</xref>). Both peak performance (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>) and the optimal threshold (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) were only weakly affected by increasing correlations among the responses of the neurons (either uniformly across the population, or such that they had a specific ‘information limiting’ structure; <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>, see also <xref ref-type="bibr" rid="bib35">Moreno-Bote et al. (2014)</xref> and the Appendix 1). The only other parameter that had a substantial effect on the optimal threshold (but not on peak performance, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1D</xref>) was the exponent of the FRNL (<xref ref-type="fig" rid="fig6">Figure 6E</xref>).</p></sec><sec id="s2-6"><title>V1 simple cells have near optimal firing thresholds</title><p>The finding that the optimal firing threshold depended on only a handful, mostly directly measurable parameters of cellular responses allowed us to test experimentally whether the FRNL of simple cells supports RU in V1. For this, we studied the example of linear decoding of orientation with phase as a nuisance parameter. First, we estimated the mean, the modulation depth (both in mV) and the noise variance (in mV<sup>2</sup>) of membrane potential responses, as well as the threshold of the FRNL (in mV) from intracellular recordings of V1 simple cells in awake mice viewing drifting full-field sinusoidal grating stimuli (i.e. with phase changing systematically; Materials and methods, <xref ref-type="fig" rid="fig7">Figure 7A–B</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). We then constructed model neuron populations with matching membrane potential response properties (using the experimentally measured mean, modulation depth and noise variance parameters) and for each model population computed the optimal threshold. Given our results on the parameter dependence of the optimal threshold (<xref ref-type="fig" rid="fig6">Figure 6</xref>), in order to compare experimentally measured and optimal threshold values, we expressed both in normalised units (subtracting the mean membrane potential and dividing by modulation depth) and plotted them as functions of the noise-to-signal ratio (the standard deviation of noise divided by modulation depth). As our data did not allow the reliable estimation of the precise value of the exponent of the FRNL (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), we expressed our predictions for each value of the noise-to-signal ratio as the set of normalised threshold values that would result in at least 90% peak performance at any value of the exponent within the range of exponents (between 1 and 2) that earlier reports considered realistic (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplements 2</xref>–<xref ref-type="fig" rid="fig7s3">3</xref>). We found that the firing thresholds determined experimentally were in this near-optimal robust performance regime in all cases despite large differences in individual parameters across the cells we recorded (<xref ref-type="fig" rid="fig7">Figure 7C</xref>; blue circles). Randomly swapping parameters across cells revealed that the incidence of measured thresholds in the robust performance regime was significant (<xref ref-type="fig" rid="fig7">Figure 7C</xref> inset, black dots; permutation test, p=0.01), suggesting that the near-optimal thresholds we found in the actual cells required specific co-tuning of these parameters.</p><fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.015</object-id><label>Figure 7.</label><caption><title>Comparison of optimal firing thresholds derived from the model and firing thresholds of V1 simple cells.</title><p>(<bold>A</bold>) Intracellularly recorded ‘generator’ membrane potential trace of a V1 simple cell (black) with spikes clipped off (see Materials and methods). Orange vertical lines show spike times, orange horizontal line shows estimated firing threshold (<inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). Red marks show response baseline (<inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), signal variance (<inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), and noise magnitude (σ) estimated from the generator potential responses to multiple cycles of the moving grating stimulus. (<bold>B</bold>) Illustration of estimating the FRNL from electrophysiological data. The firing rate of a cell as a function of the membrane potential (top panel, black line, gray shaded area shows s.e.m.) is obtained as the normalised ratio of the probability distributions of the generator potential at spike times and at all times (bottom panel, orange and gray histograms, respectively). A threshold-power-law function was fitted to the firing rate function and the threshold linear fit was used to estimate the firing threshold (vertical orange line). Threshold-power-law fits with different levels of the FRNL exponent (red traces, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>κ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>κ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) were largely consistent with the firing rate estimated from the data. (<bold>C</bold>) Normalised thresholds of four V1 simple cells as a function of the noise-to-signal ratio of their membrane potential responses (blue circles). Normalised thresholds and noise-to-signal ratios were computed from the original cellular parameters (panels A-B) as in <xref ref-type="fig" rid="fig6">Figure 6</xref>. Shaded area shows robust decodability regime of RU (range of normalised thresholds within which &gt; 90% of maximal linear decoding performance is achieved across all <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> values between 1 and 2, cf. <xref ref-type="fig" rid="fig6">Figure 6E</xref>, <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). Inset: same as main panel but black dots correspond to normalised threshold values and noise-to-signal ratios obtained by shuffling the experimentally measured parameters across recorded neurons (<inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = −46.8, –42.4, –47.3, –36.9 mV; <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = 7.15, 9.1, 4.48, 7.83 mV; <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 1.7, 2.83, 2.39, 3.21; and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = −44.9, –38.6, –44.9, –35.1 mV). (<bold>D</bold>) Same as panel (<bold>C</bold>) but recorded data is compared with the prediction of maximal information transmission on the normalised threshold.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.016</object-id><label>Figure 7—figure supplement 1.</label><caption><title>Spike fitting.</title><p>(<bold>A</bold>) Location of a spike is determined by searching a local maximum (time axis aligned to this point for illustration purposes) in the raw membrane potential data (corresponding to peaks with steepness exceeding a given threshold). Inflection points before (right circle) and after (blue circle) the peak are determined. Initiation time of the spike (vertical thin red line), and the spike threshold (horizontal thin red line) are determined by a piecewise linear fit on the membrane potential in a time window preceding the left inflection point. The tail of the spike is fitted by an exponential (blue curve) on the time window between 2.5 ms succeeding the peak and the right inflection point. The fitted exponential is used for removing the spike tail in a 6 ms window. Between the starting point of the spike and the right inflection point the generator potential is taken to be equal to the spiking threshold. (<bold>B</bold>) Illustration of a high firing rate segment of the intracellular recording (red line) and the estimated generator potential (blue line). The spike fitting method is capable of estimating generator potentials for spikes separated by not less than 5 ms. The high firing rate shown here is not typical and was chosen to demonstrate the performance under circumstances that are challenging for spike fitting.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.017</object-id><label>Figure 7—figure supplement 2.</label><caption><title>Dependence of the optimal threshold on the level of membrane potential noise.</title><p>Linear decoding performance is measured at various FRNL threshold levels with a threshold-linear nonlinearity (κ = 1, (<bold>A</bold>) and with a threshold quadratic nonlinearity (κ = 2, (<bold>B</bold>). As the amplitude of membrane potential noise increases, the optimal threshold progressively shifts to higher values (red diamonds and corresponding ticks on the x axis). Black dots indicate the minimum and maximum of the FRNL threshold range in which decoding performance exceeds the 9% of the performance measured at the optimal threshold.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig7-figsupp2-v1.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43625.018</object-id><label>Figure 7—figure supplement 3.</label><caption><title>Robust decodability of population responses.</title><p>Relationship between the normalised optimal threshold on the signal-to-noise ratio at two FRNL exponents (see <xref ref-type="fig" rid="fig6">Figure 6E</xref>) considered to be the extremes of feasible values of FRNLs characterising neuronal responses: at threshold linear nonlinearity, corresponding to κ = 1 (thick blue line), and threshold quadratic nonlinearity, corresponding to κ = 2 (thick orange line). Shaded areas represent the range of normalised thresholds where the performance of the linear decoder exceeds the 90% of the performance measured at the optimal normalised threshold (see <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). Robust decodability is defined by the regime where linear decoding performance is close to the performance measured at the optimal threshold irrespective of the exact value of the FRNL exponent (overlap between shaded areas).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig7-figsupp3-v1.tif"/></fig></fig-group><p>These analyses also offered a way to directly compare our hypothesis that V1 is optimised for RU to the classical infomax hypothesis that V1 is optimised for total information transmission. Recall that infomax predicts that the optimal firing threshold is as low as possible. In principle, this optimum is well below the average membrane potential, which appears to be in contradiction with our experimental data that showed firing thresholds clearly above the average membrane potential (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, normalised thresholds are all above 0). However, we also found that total information remained at ceiling for substantially higher values of the firing thresholds (<xref ref-type="fig" rid="fig3">Figure 3</xref>, optimal decoder), raising the possibility that infomax may also be able to account for our data. Thus, we followed the same approach as for RU, and rather than concentrating on the unique optimal threshold, which was difficult to define without knowing the precise value of the FRNL exponent, we identified the robust performance regime as the set of normalised threshold values that would result in at least 90% maximal total information at each value of the noise-to-signal ratio, and across the whole regime of realistic FRNL exponents (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, grey region). Only 3 out of 4 of our recorded cells were in this regime (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, blue circles), and given the breadth of the robust performance regime extending to infinitely low thresholds, this was not significant by using the same permutation test as in the case of RU (p=0.54). Thus, in contrast to RU, the specificity of the infomax hypothesis was too limited to be able to convincingly account for the data.</p></sec><sec id="s2-7"><title>The effect of population heterogeneity</title><p>The results above were obtained assuming a homogeneous population of neurons which only differed in their receptive field locations, preferred orientations and phases, but had otherwise identical parameters. As population heterogeneity can have an important influence on neural coding (<xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Shamir and Sompolinsky, 2006</xref>), we also studied heterogeneous populations. In particular, we were wondering whether our finding of near-optimal thresholds in individual cells (<xref ref-type="fig" rid="fig7">Figure 7</xref>) would be representative even if those cells were part of a heterogeneous population. Therefore, we constructed a population in which noise variance (<inline-formula><mml:math id="inf41"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>) and FRNL exponent (<inline-formula><mml:math id="inf42"><mml:mi>κ</mml:mi></mml:math></inline-formula>) were varied across cells in experimentally found ranges (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>). The FRNL threshold of each individual cell was then set to a value that would have been optimal in a homogeneous population in which all cells had the same parameters (<inline-formula><mml:math id="inf43"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf44"><mml:mi>κ</mml:mi></mml:math></inline-formula>) as that single cell. (That is, we only optimised thresholds ‘locally’ for each neuron, rather than attempting to find the globally optimal combination of thresholds for the population of cells). We then randomly varied the thresholds of all cells around their respective locally optimal values and asked whether there were parameter combinations which yielded better performance. We found that modifying the thresholds generally resulted in deteriorating performance, such that decoding performance was highest near the original locally optimal thresholds (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Thus, the thresholds found to be optimal based on the assumption of a homogeneous population still provided high performance in more realistic, heterogeneous populations. This result also suggests that overall (‘global’) optimality of population decoding performance might be achieved by some optimization rule acting locally on the firing threshold of each neuron separately, without needing information about the cellular parameters of other neurons, which would be difficult to obtain by biologically plausible mechanisms.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.019</object-id><label>Figure 8.</label><caption><title>Representational untangling in a heterogeneous population.</title><p>Orientation decoding performance from a population (N = 500) of neurons with heterogeneous properties as a function of the magnitude of deviation (Euclidean distance) from the optimal firing thresholds determined based on the assumption of a homogeneous population. Both the exponent of the FRNL and the level of membrane potential noise were chosen from a set of five possible values (1, 1.2, 1.4, 1.6, 1.8, and 2, 2.5, 3, 3.5, 4 mV, respectively), yielding 25 different parameter combinations. Thus, twenty neurons with different receptive fields were assigned to each parameter combination. For each of the 25 parameter combinations, the optimal firing threshold was established by simulating a homogeneous population with those parameters. In the heterogeneous population, the threshold for each cell was set to the value optimised for the corresponding homogeneous population. Decoding performance was measured after perturbing these thresholds (black dots). Grey line shows decoding performance with the unperturbed thresholds, black line is a quadratic fit to the perturbed performance levels.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43625-fig8-v1.tif"/></fig><p>We also studied the effect of additional forms of heterogeneity in individual receptive field properties (size, non-circularity or inclination, preferred spatial frequency) by adjusting these parameters to approximately match those found in experiments (<xref ref-type="bibr" rid="bib29">Jones and Palmer, 1987</xref>) and found that this also had only a small influence on performance, or the optimal threshold (data not shown).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have shown that the firing rate nonlinearity (FRNL) of V1 simple cells contributes to the representational untangling (RU) of orientation and other low-level visual information. While decoding performance is traditionally considered to be limited by the ‘noise’ variability in neural responses (<xref ref-type="bibr" rid="bib10">Berens et al., 2012</xref>; <xref ref-type="bibr" rid="bib15">Chen et al., 2006</xref>), our focus on RU warranted that we explicitly took into account another, oft-neglected source of response variability: that due to variability in nuisance parameters of the stimulus, such as phase, contrast, and spatial period. We have quantified RU by the linear decodability of membrane potentials or firing rates, and found that despite the obvious (and substantial) information loss entailed by the FRNL, sparsification of responses made the format of information in firing rates more amenable to linear decoding. Our analyses suggested this effect to be specific to V1 as it did not arise in model populations of retinal or LGN cells with non-oriented receptive fields. We also found that the value of the FRNL threshold that struck the optimal balance between sparsifying responses and preserving information was robust to variations in the identity of decoded and nuisance features, and in fact most other model parameters, and depended only on a few, experimentally well-defined local (as opposed to population-wide) quantities characterising the responses of individual cells. An analysis of intracellular recordings of mouse V1 simple cells showed that the thresholds of these cells were near optimal for RU despite substantial variability in their cellular parameters. In comparison, an alternative computational objective that is often considered to be relevant for V1, information maximisation, was unable to specifically account for these data. These results suggest that the FRNL of V1 simple cells may be specifically adapted to support the RU of orientation information.</p><sec id="s3-1"><title>Visual processing in ecologically relevant regimes</title><p>Although the evolutionary objective of the visual system is to maximise performance on natural images, we used highly simplified, full-field sinusoidal gratings as stimuli (but note that natural image statistics were taken into account in the choice of the distribution of nuisance parameters; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). Our choice for artificial stimuli was motivated by a number of factors. First, it allowed our results to be directly compared to a large swathe of the theoretical and experimental literature that used the same stimuli (<xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>; <xref ref-type="bibr" rid="bib46">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib48">Shamir and Sompolinsky, 2006</xref>; <xref ref-type="bibr" rid="bib10">Berens et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Gutnisky et al., 2017</xref>). Second, it also allowed us to show that nuisance parameters, rather than the traditionally studied factors of single-neuron variability or noise correlations, are the main bottleneck for decoding (and that this bottleneck is at least partially alleviated by the firing rate nonlinearity) even for the same simple stimuli that previous studies have used, without considering the whole complexity of natural images. Third, more complex stimuli will recruit mechanisms based on lateral and feed-back connections (eg. those responsible for extra-classical receptive field effects) that the network architecture we used here cannot capture. However, our main results remained essentially unchanged when we considered a ‘hypercolumnar’ population representing <italic>local</italic> rather than <italic>global</italic> orientation (ie. such that all cells had their receptive fields in the same location; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Importantly, inasmuch as our model represents an appropriate approximation of at least such a hypercolumnar population, the content of natural images outside this (classical) receptive field location will not affect the decoding of the content at this location, and thus these results should generalise to natural stimuli.</p><p>In general, the performance of any (but the optimal) decoder depends on the amount of data used to train it. Indeed, we often need to make decisions based on only a few training examples -- something that biological learning systems excel at (<xref ref-type="bibr" rid="bib30">Lake et al., 2015</xref>). However, in contrast to high-level cognitive tasks requiring flexible decision making, it is reasonable to expect that the decoding of low-level visual features in an early visual area, such as V1, has been optimised on evolutionary time scales and would thus not be limited by the amount of data experienced over the lifetime of an individual. Therefore, in all cases, we trained our linear decoders with sufficient amounts of data so that to achieve asymptotic performance. This meant that we mostly tested generalisation performance only for new instances of membrane potential noise, not for new stimuli (but see <xref ref-type="fig" rid="fig5">Figure 5</xref> for generalisation to new distributions of stimuli.) Nevertheless, this approach also allowed us to demonstrate that even in the limit of infinite training data, nuisance parameters represent a fundamental challenge for RU that can be mitigated by the appropriate firing rate nonlinearity.</p></sec><sec id="s3-2"><title>Decoding from firing rates versus spike counts</title><p>In previous work, decoding was often performed from spike counts rather than firing rates (<xref ref-type="bibr" rid="bib10">Berens et al., 2012</xref>; <xref ref-type="bibr" rid="bib40">Pitkow and Meister, 2012</xref>; <xref ref-type="bibr" rid="bib46">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib47">Shamir, 2014</xref>; but see <xref ref-type="bibr" rid="bib1">Abbott and Dayan, 1999</xref>; <xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>; <xref ref-type="bibr" rid="bib48">Shamir and Sompolinsky, 2006</xref>). The transformation between the two entails further information loss due to the discrete nature of spike counts and potential additional (Poisson) stochasticity in them, with the magnitude of this information loss depending on the time window used for counting spikes. However, in the limit of large time windows or large populations, variability in firing rates due to nuisance parameter variability dominates over the effects of spiking variability. While the relevant time window for decoding may depend on the ecological situation and the specific task an animal is facing, the size of the population is likely large enough to allow the effective averaging out of spiking variability. Importantly, we have also shown that population size only scales overall performance but does not affect the value for the optimal threshold (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Moreover, the Gaussian variability in membrane potentials with deterministic conversion to firing rates we assumed, combined with a deterministic spike generation process, has been shown to result in spike count variability that is phenomenologically similar to classical Poisson spike count models (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) and in fact matches experimentally observed stimulus (orientation and contrast) dependent changes in spike count (co-)variability better (<xref ref-type="bibr" rid="bib5">Bányai et al., 2017</xref>). Thus, we expect our results to generalise to spike count decoding from large experimentally recorded populations.</p></sec><sec id="s3-3"><title>Noise correlations</title><p>We found an increase, albeit relatively small, in decoding performance with an increase in noise correlations (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, showing results for uniform noise correlations – similar results, not shown, were obtained with other correlation structures). Although this may at first seem counterintuitive (correlations imply redundancy), it is well known that the effects of noise correlations depend on their relation to the tuning of cells (<xref ref-type="bibr" rid="bib3">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib31">Lin et al., 2015</xref>) and they generally increase linear Fisher information for the particular (tuning-independent) pattern of correlations we studied (<xref ref-type="bibr" rid="bib1">Abbott and Dayan, 1999</xref>). As expected, information limiting correlations decreased the performance of both the optimal Bayesian decoder and of the linear decoder, such that the efficiency of the linear decoder relative to the optimal decoder became higher -- that is the resulting code was relatively more linearly decodable. While other patterns of correlations may result in a decrease of performance, noise correlations in V1 tend to be small overall (<xref ref-type="bibr" rid="bib21">Ecker et al., 2011</xref>). Moreover, as we argued above, <italic>effective</italic> noise correlations will be dominated by correlations induced by nuisance parameter variability in the settings we studied, and so the effects of ‘standard’ noise correlations are likely to be diminishing.</p></sec><sec id="s3-4"><title>Complex cells in V1</title><p>Orientation selectivity is a central feature of V1 neurons (<xref ref-type="bibr" rid="bib26">Hubel and Wiesel, 1968</xref>). We argued that the mixed selectivity of neurons affects the linear decodability of stimulus information adversely: if neurons are selective to additional stimulus features then variations in these will likely cause representational entanglement. Stimulus phase is particularly prone to causing representational entanglement of orientation information if neuronal responses are jointly modulated by both phase and orientation. Importantly, the level of phase selectivity greatly varies across neurons (<xref ref-type="bibr" rid="bib36">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="bib49">Skottun et al., 1991</xref>). For a neuron that is sensitive to orientation but not to phase, a so-called complex cell, variability in stimulus phase is not detrimental and decodability remains intact. It is unclear if the FRNL-based mechanism of RU contributes to the emergence of such complex cells, but there is a suggestive correspondence between the canonical model of complex cells and the architecture we studied. According to the canonical model of complex cell responses, these responses are brought about by a specific pooling of simple cell responses. Intriguingly, the mathematical form of this pooling is essentially isomorphic to the linear decoder we studied here: it takes a linear combination of the non-linearly (typically quadratically) transformed responses of a number of simple cells differing in their preferred phases (<xref ref-type="bibr" rid="bib26">Hubel and Wiesel, 1968</xref>) and potentially other receptive field properties (<xref ref-type="bibr" rid="bib44">Rust et al., 2005</xref>). This suggests that the same principles that we found determine the optimal firing threshold of simple cells for an abstract linear decoder may also determine the optimal firing threshold of simple cells for the efficient operation of complex cells. Furthermore, our simulations show similar detrimental effects for nuisance parameters other than phase, including spatial period. For these other nuisance parameters, complex cell properties have limited capacity to prevent the detrimental effect of entanglement. We argue that the FRNL provides a surprisingly effective solution for the more general problem of decoding under nuisance parameter uncertainty.</p></sec><sec id="s3-5"><title>The computational role of the FRNL</title><p>We have shown that the FRNL has an important computational role in RU. Previous work implicated the FRNL of V1 cells in achieving contrast-invariant orientation tuning curves in V1 simple cells (<xref ref-type="bibr" rid="bib22">Finn et al., 2007</xref>). This effect can also be understood as a spacial case of a mechanism promoting RU: contrast-invariant tuning curves contribute to more efficient contrast-invariant decoding of firing rates by ensuring that firing rates are simply scaled by contrast and so decision boundaries for orientation decoding (<xref ref-type="fig" rid="fig2">Figure 2</xref>) remain radial and thus linear when contrast varies (<xref ref-type="bibr" rid="bib34">Ma et al., 2006</xref>). However, contrast is but one of several nuisance parameters whose variability makes RU of orientation information challenging in V1, and as we have shown, other nuisance parameters (phase and spatial period) have even more dramatic effects (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Our results thus extend previous work by placing contrast invariant tuning curves in the wider context of RU and showing that the FRNL of simple cells plays a general role in keeping orientation information linearly decodable in the face of variability in a number of nuisance parameters.</p><p>The FRNL has been shown to contribute to performing linear classification on arbitrary mappings of a set of variables (<xref ref-type="bibr" rid="bib6">Barak et al., 2013</xref>). In such tasks, no single input feature alone can be used for solving the task by linear read-out. Thus, mixed selectivity (i.e. the property that neuronal responses depend on multiple stimulus attributes, <xref ref-type="bibr" rid="bib2">Asaad et al., 1998</xref>; <xref ref-type="bibr" rid="bib16">Churchland and Shenoy, 2007</xref>; <xref ref-type="bibr" rid="bib54">Warden and Miller, 2010</xref>) was shown to be advantageous and even necessary (e.g. in higher-order association cortices during tasks requiring cognitive flexibility, <xref ref-type="bibr" rid="bib43">Rigotti et al., 2013</xref>). In contrast, in the standard task of orientation decoding in V1 considered here, an ‘orderly’ input-output mapping is required, in which one input feature needs to be mapped to the output monotonically. For this task, the mixed selectivity of neurons is less of a blessing: if neurons had pure selectivities for orientation such that their responses did not depend on any other stimulus parameters then variation in nuisance parameters would not lead to representational entanglement. Moreover, earlier work on the effects of response sparsification on linear decodability studied a network of abstract binary neurons (<xref ref-type="bibr" rid="bib6">Barak et al., 2013</xref>) and thus could not relate sparseness to a biophysically well-defined firing threshold as we did. Our results generalise the utility of the FRNL, showing that it pertains even to an elementary sensory decoding task.</p><p>Given that the main direct effect of the FRNL is the sparsification of neural responses (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, red), one might then intuitively reason that setting the FRNL threshold to very high values to achieve ultra-sparse codes could increase linearly separability even more. In this limit, each image would be coded as a one-hot population response vector. Although one-hot population coding achieved by ultra-sparse codes has appealing theoretical properties, it fundamentally relies on assuming no noise, and requires an exponential number of neurons (in the number of nuisance parameters). In fact, in the (unrealistic) limit of no noise, the question of an optimal threshold even becomes somewhat moot as essentially all thresholds above a minimum will perform equally well (essentially perfectly) -- as the broadening of the robust performance regime towards low values of the noise-to-signal ratio in <xref ref-type="fig" rid="fig7">Figure 7C</xref> (and <xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3</xref>) also suggests. Moreover, we expect ultra sparse coding to be particularly sensitive to contrast as a nuisance parameter (as the correct threshold for achieving a one-hot code will critically depend on the overall scaling of responses which in turn depends monotonically on contrast, such that selecting a single optimal threshold is impossible). Importantly, the conditions for ultra-sparse codes are also unlikely to be met in real V1, for example the experimentally measured levels of noise-to-signal ratio in our V1 data were well above 0 (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Indeed, at these realistic noise levels, we found that increasing the number of neurons in the population did not favour higher thresholds which could have potentially led to such ultra sparse codes (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><p>The FRNL-induced increase in sparseness has also been shown to contribute to increasing mutual information between visual stimuli and the responses of retinal ganglion cells (<xref ref-type="bibr" rid="bib40">Pitkow and Meister, 2012</xref>), such that there was an optimum for the FRNL threshold at intermediate values. Although our results may superficially suggest a similar interpretation, they are in fact orthogonal. It is important to note that, in our case, the performance of the optimal decoder (the analogue of mutual information measured by <xref ref-type="bibr" rid="bib40">Pitkow and Meister, 2012</xref>) was a monotonically decreasing function of the FRNL threshold, without an optimum at intermediate values. The difference is due to the fact that <xref ref-type="bibr" rid="bib40">Pitkow and Meister (2012)</xref> modeled the effects of the FRNL threshold in a regime in which spiking noise dominated. Specifically, they studied small populations of neurons (<inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> ≤ 8) and kept the average firing rate of neurons constant (by adjusting their peak firing rate) as the FRNL threshold was varied. This meant that a decrease in the threshold in their setting led to sustained firing with low spike counts, which were associated with high relative variability, thus diminishing information in the low threshold regime. In contrast, we considered a large population of neurons in which spiking noise is less relevant (and thus decoding performance does not depend on the overall scaling of firing rates) and instead the effects of nuisance parameters dominate (see above). Indeed, in line with our results, <xref ref-type="bibr" rid="bib40">Pitkow and Meister (2012)</xref> also found that increasing population size shifted the value of the FRNL threshold at which total (mutual) information was maximised towards smaller values, such that the dominant effect was now a decrease in total information for higher thresholds. Thus, the optimal intermediate value for the FRNL threshold we found emerged for a fundamentally different reason: because we measured linearly decodable information rather than total information, which is brought about by a trade-off between total information and sparseness. Taken together, these results suggest that the FRNL threshold may play an important role in neural computations at different stages of sensory processing via different mechanisms: by maximising total information transmission in the retina, and by achieving RU in the visual cortex.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Population model of MP responses</title><p>The default population model for encoding stimuli consisted of <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 500 simple cells whose membrane potential responses were established by calculating circular Gabor filter responses plus Gaussian noise (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Each circular Gabor filter (indexed by n) is described by six parameters: the coordinates of the center of the filter measured from the line of sight (<inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>,<inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), the spatial period of the plane wave component of the Gabor filter (<inline-formula><mml:math id="inf49"><mml:mi>λ</mml:mi></mml:math></inline-formula>), the orientation of the sinusoidal component (<inline-formula><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>180</mml:mn></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></inline-formula>), the phase offset of the sinusoidal component relative to the center of the filter (<inline-formula><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>360</mml:mn></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></inline-formula>), standard deviation of the circular Gaussian envelope (<inline-formula><mml:math id="inf52"><mml:mi>δ</mml:mi></mml:math></inline-formula>). All angles are measured in degrees, retinal distances (coordinates, spatial period, envelope width) are measured in degrees of visual angle. Numerical values of the above filter parameters were chosen according to <xref ref-type="table" rid="table1">Table 1</xref>. In the default model, spatial period and envelope width were identical across the population and identical parameters were defined to be approximately equal to the empirical average from <xref ref-type="bibr" rid="bib29">Jones and Palmer (1987)</xref>. Filter locations were uniformly sampled in the whole visual field (90 degrees), which ensured that not only local stimulus effects were considered. Preferred orientations and phases of Gabor filter were uniformly sampled from the entire range of possible values (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). Code used for simulation is available on GitHub (<xref ref-type="bibr" rid="bib23">Gáspár, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/representational_untangling">https://github.com/elifesciences-publications/representational_untangling</ext-link>).</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.43625.020</object-id><label>Table 1.</label><caption><title>Parameters of the decoding model under phase uncertainty and their default values are shown or their generator methods are indicated (first column).</title><p>Description of the parameters and methods are expounded (second column). The performance curve of the above described standard model is shown by the thick blue curve on <xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="fig4">Figure 4B</xref> and used as a reference simulation on <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref> where parameters of the model are varied.</p></caption><table frame="hsides" rules="groups"><tbody><tr><th colspan="2" valign="top">Parameters of the encoder Gabor population</th></tr><tr><td valign="top"><p><inline-formula><mml:math id="inf53"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:math></inline-formula></p></td><td valign="top">Number of Gabor cells in the encoder population (with the exception of <xref ref-type="fig" rid="fig6">Figure 6B</xref>)</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:msup><mml:mn>90</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">coordinates of the center of Gabor filter n measured from the line of sight; randomly chosen from a uniform distribution over a disk with radius R (with the exception of <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>)</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">period of the plane wave component of Gabor filters; identical for all cells (with the exception of <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>)</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>180</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>180</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">preferred orientation of cell n; evenly distributed on the entire range</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mi/><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>]</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>360</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">phase offset of the sinusoidal wave component of the Gabor filter relative to the center; evenly distributed on the entire range, but the order is randomly permuted to avoid correlation with the preferred orientation (with the exception of no-nuisance simulations where <inline-formula><mml:math id="inf59"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo> <mml:mi/><mml:mn>180</mml:mn></mml:math></inline-formula>)</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">standard deviation of the circular Gaussian envelope of Gabor filters; identical for all cells</td></tr><tr><th colspan="2" valign="top">Parameters of the rescaling of filter responses to membrane potential values</th></tr><tr><td valign="top"><inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mn>60</mml:mn><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">mean value of phase modulated filter responses</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>12</mml:mn><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">peak amplitude of maximally modulated filter responses; numeric value is chosen as a typical value (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) (but varied on <xref ref-type="fig" rid="fig6">Figure 6A</xref>)</td></tr><tr><th colspan="2" valign="top">Variability and covariability of membrane potential responses</th></tr><tr><td valign="top"><inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mi>ξ</mml:mi><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>=</mml:mo><mml:mn>25</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="bold">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">std of Gaussian membrane potential noise is measured relative to the signal amplitude; identical for all cells (but varied on <xref ref-type="fig" rid="fig6">Figures 6</xref>, <xref ref-type="fig" rid="fig7">7C</xref> and <xref ref-type="fig" rid="fig8">8</xref>)</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">off-diagonal elements of the <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> covariance matrix; no correlation structure is assumed (with the exception of <xref ref-type="fig" rid="fig6">Figure 6</xref>)</td></tr><tr><th colspan="2" valign="top">Firing rate nonlinearity</th></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf67"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula></p></td><td valign="top">power-law exponent of the FRNL (but varied on <xref ref-type="fig" rid="fig6">Figures 6E</xref>, <xref ref-type="fig" rid="fig7">7C</xref> and <xref ref-type="fig" rid="fig8">8</xref>)</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">threshold of the FRNL; this is always a running variable in the simulations</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo>=</mml:mo><mml:mn>16.7</mml:mn><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">H</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">prefactor of the FRNL of Gabor cells</td></tr><tr><th colspan="2" valign="top">Parameters of the categorisation task</th></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf70"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula></p></td><td valign="top">number of discrete orientation categories (varied only on <xref ref-type="fig" rid="fig6">Figure 6C</xref>)</td></tr><tr><th colspan="2" valign="top">Parameters of the stimulus set used for training the decoder</th></tr><tr><td valign="top"> <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">number of bins for stimulus orientation, <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, within an orientation category (represents orientation uncertainty)</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">number of bins for stimulus phase, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>(represents phase uncertainty)</td></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></p></td><td valign="top">number of stimulus repetitions at a given (<inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) with independent noise</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">total number of stimuli used for training the decoder</td></tr><tr><td valign="top"> <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Spatial period of sine wave stimuli; matched to the spatial period of the Gabor filters (but see <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref> and respective captions)</td></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf79"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula></p></td><td valign="top">contrast of the sine wave stimuli; chosen to be the mean value of the natural distribution used later in <xref ref-type="fig" rid="fig4">Figure 4</xref> or <xref ref-type="fig" rid="fig6">Figure 6</xref> (but see <xref ref-type="fig" rid="fig5">Figure 5</xref>)</td></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>180</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></p></td><td valign="top">orientation of the grating stimulus <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), 0 being the horizontal direction</td></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>360</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></p></td><td valign="top">phase of grating stimulus m relative to line of sight; generated such that (<inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) pairs come from the <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> rectangular grid covering uniformly the <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>–<inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> parameter space</td></tr><tr><th colspan="2" valign="top">Parameters of the stimulus set used for testing the decoder</th></tr><tr><td valign="top"><p> <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:math></inline-formula></p></td><td valign="top">number of stimulus repetitions with given (<inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>); other parameters of the testing stimulus bank is the same as the training parameters above</td></tr></tbody></table></table-wrap><p>In order to limit simulation time and eliminate discretisation noise, analytical filter responses are calculated in response to sine wave stimuli. A strictly finite size realistic receptive field requires truncation of the receptive field but such a truncation would prevent the analytical calculation of filter responses, therefore only the standard exponentially decaying Gaussian envelope of the Gabor-filter is supposed to keep the filter localised. Filter response of a circular Gabor filter with infinite domain to an infinite sine wave stimulus when spatial period of the filter and the stimulus are supposed to be identical is given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>δ</mml:mi></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>ϑ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ψ</mml:mi><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mo>−</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>δ</mml:mi></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>ϑ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here response is shifted and scaled such that the predefined value <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> matches the phase averaged DC component and <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> matches the amplitude of the phase modulated AC component at the preferred orientation at 100% contrast level (for derivations in the case of unequal spatial periods see the Appendix 1). In the above expression <inline-formula><mml:math id="inf92"><mml:mi>λ</mml:mi></mml:math></inline-formula> is the common spatial periods; <inline-formula><mml:math id="inf93"><mml:mi>ϑ</mml:mi></mml:math></inline-formula>: grating stimulus orientation; <inline-formula><mml:math id="inf94"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>: stimulus phase relative to the line of sight;<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>ψ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:mfenced><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:math></disp-formula>a phase term belonging to the filter location. A similar expression can be obtained for more general settings of a grating stimulus (not shown). Deviation of the above analytical response from the response of a truncated Gabor filter (to a local stimulus) is not substantial. Subscript indices of filter parameters, identifying a particular filter of the population are not shown for clarity.</p><p>Parameters of the Gabor filters determine the mean response characteristics of a model neuron: the mean membrane potential was assumed to be equal to the linear filter response to a stimulus. As a consequence, mean responses of individual neurons to oriented grating stimuli can be characterised by a tuning curve with peak response corresponding to the preferred orientation of the neuron. The response of a neuron was the sum of the mean response and a Gaussian noise. The noise, however, was not necessarily independent: in some experiments (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) correlation between membrane potential responses was introduced by using multivariate Gaussian noise to determine the responses of the complete population. Noise was assumed to have no temporal structure beyond a limited time window, therefore samples were considered to be iid samples in 20 ms time bins. Amplitude and contrast parameters of stimuli are kept constant throughout the simulations, filter responses are scaled and shifted to match empirical neural responses, here characterised by <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="table" rid="table1">Table 1</xref>). Noise level was set to be 25% relative to the signal variance (matched to <xref ref-type="bibr" rid="bib13">Carandini, 2004</xref> example simple cell).</p></sec><sec id="s4-2"><title>Population models for LGN and retina responses</title><p>To study the potential contribution of FRNL to RU at earlier stages of the visual processing hierarchy, we defined LGN and retina models by altering the filter properties of the encoding population. Retina receptive fields were approximated by pixel responses, while LGN receptive fields were approximated by difference of Gaussian filters (DoG, <xref ref-type="bibr" rid="bib17">Dayan and Abbott, 2005</xref>). In order to be able to use analytic calculations derived for Gabor filters, we approximated DoG responses as the difference of two constrained Gabor filters. The sinusoidal component of the Gabor filter was modified such that the phase relative to the Gabor center (<inline-formula><mml:math id="inf97"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) was zero and the spatial period was increased so that within the Gaussian envelope there was no practical modulation. The sizes of the central ON-region and peripheral OFF-region were set to 1.5° and 4°, respectively. To be able to contrast retina, LGN and V1 analyses, filter positions were matched to those of the V1 population and retina/LGN filter responses were calibrated such that stimulus variance of the model neurons were equal to their corresponding neurons in V1.</p></sec><sec id="s4-3"><title>Mapping of membrane potentials to firing rates</title><p>The nonlinear transformation from membrane potential to firing rate is described by the firing rate nonlinearity (FRNL). A general threshold-power-law function, <inline-formula><mml:math id="inf98"><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo> <mml:mi/><mml:mo>=</mml:mo> <mml:mi/><mml:mi>Φ</mml:mi><mml:msubsup><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, is used to simulate simple cell firing responses that has empirically been found to fit simple cell responses well (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>). In this expression <inline-formula><mml:math id="inf99"><mml:msub><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> indicates rectification. The specific value of the scaling factor <inline-formula><mml:math id="inf100"><mml:mi>Φ</mml:mi></mml:math></inline-formula> does not affect results. The value of the power-law exponent for the simulations was <inline-formula><mml:math id="inf101"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> (except <xref ref-type="fig" rid="fig6">Figure 6</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>) and the range of possible physiological values (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) was explored when fitting membrane potential recordings (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Parameters of the FRNL are assumed to be identical across cells (but see <xref ref-type="fig" rid="fig8">Figure 8</xref>). Since nonlinearity is central to our analysis FRNL threshold was varied in the simulations in order to study its effect on decoding performance.</p></sec><sec id="s4-4"><title>Linear decoder</title><p>A single-layer decoder was used to perform probabilistic linear decoding of orientation information from the stimulus. The decoder represented <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> classes and was performing multinomial logistic regression by assigning probabilities to the represented classes. Weights, which could take both positive and negative values, were tuned to be optimal by supervised learning on a set of static training stimuli (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B,C</xref>). In the training data set multiple values of the decoded parameter belonged to any given class (<inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the case of orientation). Training and testing was performed on different stimulus sets, and training and testing samples differed in membrane potential noise. Wherever nuisance parameters were present, parameters of training images were sampled from the distribution characteristic of the nuisance parameter(s). Parameters of individual test images were sampled from the same distribution, except for <xref ref-type="fig" rid="fig5">Figure 5</xref> where a different parameter distribution was used for one of the nuisance parameters. Stimulus parameter distributions were constructed such that these approximated the characteristics of natural images. Fitting of the weight parameters of the decoder was performed in MATLAB using a custom code that uses the Barzalai-Borwein method to perform gradient descent (<xref ref-type="bibr" rid="bib7">Barzilai and Borwein, 1988</xref>; <xref ref-type="bibr" rid="bib23">Gáspár, 2019</xref>). Training stimulus parameter space is uniformly covered by a 2D grid in case of phase uncertainty, and the same grid is used to test the decoder. <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (and <inline-formula><mml:math id="inf105"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>'</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) describes the number of repetitions with newly generated noise to generate the whole training (or testing) stimulus data set (<xref ref-type="table" rid="table1">Table 1</xref>). For any given nuisance parameter that is characterised by non-uniform prior (see <xref ref-type="fig" rid="fig4">Figure 4</xref>) a distorted multidimensional grid is used to generate the stimulus bank. For spatial period, a lognormal distribution with parameters <inline-formula><mml:math id="inf106"><mml:mi>μ</mml:mi></mml:math></inline-formula> = 0.95, <inline-formula><mml:math id="inf107"><mml:mi>σ</mml:mi></mml:math></inline-formula> = 0.55 was used. For contrast, a beta-distribution was fitted to local contrast distribution based on a small dataset containing 24-hour time-lapse images, resulting in parameters <inline-formula><mml:math id="inf108"><mml:mi>α</mml:mi></mml:math></inline-formula> = 2.4, <inline-formula><mml:math id="inf109"><mml:mi>β</mml:mi></mml:math></inline-formula> = 3.6.</p><p>The resulting decoder provided class probabilities, and the maximum class probability was used to indicate the decision. We tested the robustness of our claims by using alternative methods for decision. These analyses revealed variations in the measured level of decoding performance but the optimal threshold was invariant to the choice of performance measure (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref>). The efficiency of the decoding is measured by fraction correct.</p></sec><sec id="s4-5"><title>Optimal decoder</title><p>The optimal decoder was constructed by inferring class labels from data by explicitly inverting the process of the generation of output from the population of neurons. Membrane potential responses of individual neurons for a grating stimulus with a particular orientation and phase was described by normal distribution<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf110"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the Gabor-filter response and <inline-formula><mml:math id="inf111"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> is the level of membrane potential noise. Likelihood of observing a particular firing rate response is<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf112"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the baseline probability of zero firing rate response, <inline-formula><mml:math id="inf113"><mml:mi>H</mml:mi><mml:mo>(</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> is the Heaviside function and <inline-formula><mml:math id="inf114"><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mfenced close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mo>/</mml:mo><mml:mi>d</mml:mi><mml:mi>u</mml:mi><mml:msup><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. Assuming a discrete set of stimulus phases, the posterior probability of orientation <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:munderover><mml:munder><mml:mo>∏</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Priors, <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, were chosen to be uniform.</p><p>An optimal decoder was derived when ILC was assumed to contribute to the membrane potential noise. We constructed the decoder by explicitly modelling how ILC is introduced: ILC can be modelled by assuming that the value of the decoded variable (the orientation in our case) is not constant but changes stochastically. We assumed that the orientation of stimuli, <inline-formula><mml:math id="inf118"><mml:mi>ϑ</mml:mi></mml:math></inline-formula>, are sampled from a normal distribution around the true value, <inline-formula><mml:math id="inf119"><mml:mi>Θ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In order to obtain the posterior probability for the true orientation, a marginalisation over the stochastically sampled orientations beyond the marginalisation over phases is required:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>ϑ</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>ϑ</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-6"><title>Contrast and spatial period decoding</title><p>Orientation decoding is a standard measure of stimulus encoding in V1 simple cells but the joint selectivity to a number of other variables, including contrast and spatial period means that the contribution of FRNL to decoding these variables can also be directly tested. Diversity of the filter properties of the encoding population is crucial for efficient decoding. When studying orientation decoding properties of the population we ensured diversity in filter orientation and phases but used identical spatial period sensitivities across the population. When studying spatial period and contrast decoding, we constructed a population which represented the spatial period characteristics of the stimuli by matching the distribution of period of the filters by sampling the spatial periods from the period distribution of the stimuli. Such an encoding population was used in all of the analyses in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>. Here, after choosing a particular parameter for decoding, all other stimulus parameters were regarded as nuisance parameters. Classes for the decoded stimuli were established by partitioning the decoded parameters according to the cumulative distribution of the stimuli: stimulus classes were defined as the centers of the partitions containing equal probability mass.</p></sec><sec id="s4-7"><title>Infomax model</title><p>The objective of the infomax model is the optimisation of information transmission with respect to the decoding variable, which is formulated through the mutual information:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">ϑ</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the first term on the right hand side is the conditional entropy of the class label given possible responses and the second term is the entropy of the category distribution, the index <italic>k</italic> runs through the different orientation classes. Note that the conditional probability under the logarithm in the first term is the posterior of the class label. The second term in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> does not depend on the response distribution therefore it is not affected by changes in firing properties of the neurons, including the firing threshold.</p><p>The probabilistic fraction correct (PFC) performance measure,<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>m</italic> runs through the trials of the experiment, is in an intimate relationship with the mutual information (<xref ref-type="disp-formula" rid="equ8">Equation 8</xref>). This can be seen by taking the logarithm of PFC is<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>P</mml:mi><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>which corresponds to a Monte Carlo approximation to the integral in the conditional entropy in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> since in individual trials stimuli and population responses to the particular stimulus can be regarded as samples:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>_</mml:mo></mml:munder><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This indicates that the PFC performance measure is an approximation to exponent of the mutual information, up to a scaling constant that is determined by the entropy of the stimuli (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref>).</p></sec><sec id="s4-8"><title>Experimental subjects and surgical procedures</title><p>All experimental procedures were approved by the University of California Los Angeles Office for Protection of Research Subjects and the Chancellor’s Animal Research Committee. 1–12 month old C57Bl6/J mice underwent implantation of head-bars, surgery recovery, acclimation to the spherical treadmill and craniotomy over V1 as described in <xref ref-type="bibr" rid="bib41">Polack et al. (2013)</xref>. A 3 mm diameter coverslip drilled with a 500 μm diameter hole was placed over the dura such that the coverslip fit entirely in the craniotomy and was flush with the skull surface.. The coverslip was maintained in place using Vetbond and dental cement and the recording chamber was filled with cortex buffer containing 135 mM NaCl, 5 mM KCl, 5 mM HEPES, 1.8 mM CaCl2 and 1 mM MgCl2. The head-bar was fixed to a post and the mouse was placed on the spherical treadmill to recover from anesthesia. All recordings were performed at least 2 hr after the end of anesthesia.</p></sec><sec id="s4-9"><title>Electrophysiological recordings</title><p> Two-photon guided in-vivo whole-cell recordings were performed as described in <xref ref-type="bibr" rid="bib41">Polack et al. (2013)</xref>. Long-tapered micropipettes made of borosilicate glass (1.5 mm outer diameter, 0.86 mm inner diameter, Sutter Instrument) were pulled on Sutter Instruments P-97 pipette puller to a resistance of 3–7 MΩ, and filled with an internal solution containing 115 mM potassium gluconate, 20 mM KCl, 10 mM HEPES, 10 mM phosphocreatine, 14 mM ATP-Mg, 0.3 mM GTP, and 0.01–0.05 mM Alexa-594. Whole-cell current-clamp recordings were performed using the bridge mode of an Axoclamp 2A amplifier (Molecular Devices), further amplified and low-pass filtered at 5 kHz using a Warner Instruments amplifier (LPF 202A). Series of current pulses of small intensity (typically −100 pA) were used to balance the bridge and compensate the pipette capacitance. The membrane potential was not corrected for liquid junction potentials (estimated to be about 10 mV).</p></sec><sec id="s4-10"><title>Visual presentation</title><p>Visual stimuli were presented as described in <xref ref-type="bibr" rid="bib41">Polack et al. (2013)</xref>. A 40 cm diagonal LCD monitor was placed in the monocular visual field of the mouse at a distance of 30 cm, contralateral to the craniotomy. Custom-made software developed with Psychtoolbox in MATLAB was used to display drifting sine wave gratings (single orientations at the preferred orientation, temporal frequency = 2 Hz, spatial frequency = 0.04 cycle per degree, contrast = 100%). The presentation of each orientation lasted 3 s, which was preceded by the presentation of a gray isoluminant screen for an additional 3 s.</p></sec><sec id="s4-11"><title>Data processing of intracellular measurements</title><p>MP changes of V1 simple cells induced by drifting grating stimulus were fitted with three parameters: MP DC level (<inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), signal variance (<inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">C</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), level of noise (<inline-formula><mml:math id="inf122"><mml:mi>σ</mml:mi></mml:math></inline-formula>). Further, FRNL threshold was also extracted from MP recordings for each neuron individually. First, a spike removal algorithm is applied on the raw MP data to obtain the generator potential (<xref ref-type="bibr" rid="bib13">Carandini, 2004</xref>) and the time of action potentials. Our spike removal algorithm used composite analytical fits (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>) to accurately subtract spikes from raw MP data. This allowed precise estimation of residual MP levels at the location of spikes, which was required for FRNL calculation. Since the phase of periodic membrane potential modulation shows some variance across trials, and there are trials in which the phasic modulation of the membrane potential is difficult to determine, we performed the analysis in such a way that individual cycles of the periodic modulation are extracted from the 3-sec duration of stimulus presentation (6 cycles). The three parameters of the membrane potential response were calculated individually for these trials from the corresponding data segments. To do so, multiple cycles from a given trial were overlaid. The DC level (in mV) was established by averaging across cycles and time; AC level (in mV) was established by averaging across the overlaid cycles and measuring the amplitude of the average modulation; noise level (in mV<sup>2</sup>) was measured by calculating variance across overlaid cycles.</p><p>For the estimation of the parameters of FRNL, the method described by <xref ref-type="bibr" rid="bib13">Carandini (2004)</xref> was used (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). The trial-averaged generator potential was segmented using 20 msec windows, and mean membrane potential levels in these bins were used to construct a histogram with 1 mV bin size. Another histogram was constructed for the number of spikes generated at any given membrane potential level. To obtain the mean firing rate corresponding to a membrane potential level, spike counts were normalised with the total duration of membrane potential segments in that bin. A threshold-linear function was fitted to the above determined FRNL to estimate the FRNL threshold.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a Lendület Award of the Hungarian Academy of Sciences (GO), an award from the National Brain Research Program of Hungary (NAP-B, KTIA_NAP_12-2-201, GO), and the Wellcome Trust (ML), the Whitehall Foundation (PG) and NIH R01 grant MH105427 (PG) and the Human Frontier Science Program (RGP0044/2018, PG,ML,GO,). We would like to thank Michael Einstein for assistance with electrophysiological recordings. The authors declare no competing financial interests.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Software, Validation, Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Supervision, Funding acquisition, Methodology, Project administration</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All animal experiments were approved by University of California Los Angeles IACUC and Animal Research Committee (Protocol #06-066).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.43625.021</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-43625-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data is available along with code at the GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/CSNLWigner/representational_untangling">https://github.com/CSNLWigner/representational_untangling</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/representational_untangling">https://github.com/elifesciences-publications/representational_untangling</ext-link>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The effect of correlated variability on the accuracy of a population code</article-title><source>Neural Computation</source><volume>11</volume><fpage>91</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1162/089976699300016827</pub-id><pub-id pub-id-type="pmid">9950724</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asaad</surname> <given-names>WF</given-names></name><name><surname>Rainer</surname> <given-names>G</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Neural activity in the primate prefrontal cortex during associative learning</article-title><source>Neuron</source><volume>21</volume><fpage>1399</fpage><lpage>1407</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80658-3</pub-id><pub-id pub-id-type="pmid">9883732</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname> <given-names>BB</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azouz</surname> <given-names>R</given-names></name><name><surname>Gray</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cellular mechanisms contributing to response variability of cortical neurons <italic>in</italic> vivo</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>2209</fpage><lpage>2223</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-02209.1999</pub-id><pub-id pub-id-type="pmid">10066274</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bányai</surname> <given-names>M</given-names></name><name><surname>Koman</surname> <given-names>Z</given-names></name><name><surname>Orbán</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Population activity statistics dissect subthreshold and spiking variability in V1</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>29</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1152/jn.00931.2016</pub-id><pub-id pub-id-type="pmid">28298305</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The sparseness of mixed selectivity neurons controls the generalization-discrimination trade-off</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>3844</fpage><lpage>3856</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2753-12.2013</pub-id><pub-id pub-id-type="pmid">23447596</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barzilai</surname> <given-names>J</given-names></name><name><surname>Borwein</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Two-point step size gradient methods</article-title><source>IMA Journal of Numerical Analysis</source><volume>8</volume><fpage>141</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1093/imanum/8.1.141</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname> <given-names>AJ</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The &quot;independent components&quot; of natural scenes are edge filters</article-title><source>Vision Research</source><volume>37</volume><fpage>3327</fpage><lpage>3338</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00121-1</pub-id><pub-id pub-id-type="pmid">9425547</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Courville</surname> <given-names>A</given-names></name><name><surname>Vincent</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representation learning: a review and new perspectives</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>35</volume><fpage>1798</fpage><lpage>1828</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2013.50</pub-id><pub-id pub-id-type="pmid">23787338</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Ecker</surname> <given-names>AS</given-names></name><name><surname>Cotton</surname> <given-names>RJ</given-names></name><name><surname>Ma</surname> <given-names>WJ</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A fast and simple population code for orientation in primate V1</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>10618</fpage><lpage>10626</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1335-12.2012</pub-id><pub-id pub-id-type="pmid">22855811</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer Verlag</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brincat</surname> <given-names>SL</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Underlying principles of visual shape selectivity in posterior inferotemporal cortex</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>880</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1038/nn1278</pub-id><pub-id pub-id-type="pmid">15235606</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Amplification of trial-to-trial response variability by neurons in visual cortex</article-title><source>PLOS Biology</source><volume>2</volume><elocation-id>e264</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0020264</pub-id><pub-id pub-id-type="pmid">15328535</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Ferster</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Membrane potential and firing rate in cat primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>470</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-01-00470.2000</pub-id><pub-id pub-id-type="pmid">10627623</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Geisler</surname> <given-names>WS</given-names></name><name><surname>Seidemann</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal decoding of correlated neural population responses in the primate visual cortex</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1412</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1038/nn1792</pub-id><pub-id pub-id-type="pmid">17057706</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4235</fpage><lpage>4257</lpage><pub-id pub-id-type="doi">10.1152/jn.00095.2007</pub-id><pub-id pub-id-type="pmid">17376854</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Theoretical Neuroscience</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name><name><surname>Zoccolan</surname> <given-names>D</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How does the brain solve visual object recognition?</article-title><source>Neuron</source><volume>73</volume><fpage>415</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.010</pub-id><pub-id pub-id-type="pmid">22325196</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name><name><surname>Cox</surname> <given-names>DD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Untangling invariant object recognition</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>333</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.06.010</pub-id><pub-id pub-id-type="pmid">17631409</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorn</surname> <given-names>JD</given-names></name><name><surname>Ringach</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Estimating membrane voltage correlations from extracellular spike trains</article-title><source>Journal of Neurophysiology</source><volume>89</volume><fpage>2271</fpage><lpage>2278</lpage><pub-id pub-id-type="doi">10.1152/jn.000889.2002</pub-id><pub-id pub-id-type="pmid">12686584</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname> <given-names>AS</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The effect of noise correlations in populations of diversely tuned neurons</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>14272</fpage><lpage>14283</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2539-11.2011</pub-id><pub-id pub-id-type="pmid">21976512</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname> <given-names>IM</given-names></name><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>Ferster</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The emergence of contrast-invariant orientation tuning in simple cells of cat visual cortex</article-title><source>Neuron</source><volume>54</volume><fpage>137</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.02.029</pub-id><pub-id pub-id-type="pmid">17408583</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Gáspár</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Representational_Untangling</data-title><source>GitHub</source><version designator="b74cc1b">b74cc1b</version><ext-link ext-link-type="uri" xlink:href="https://github.com/CSNLWigner/representational_untangling">https://github.com/CSNLWigner/representational_untangling</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Beaman</surname> <given-names>CB</given-names></name><name><surname>Lew</surname> <given-names>SE</given-names></name><name><surname>Dragoi</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spontaneous fluctuations in visual cortical responses influence population coding accuracy</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>1409</fpage><lpage>1427</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv312</pub-id><pub-id pub-id-type="pmid">26744543</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haider</surname> <given-names>B</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition dominates sensory responses in the awake cortex</article-title><source>Nature</source><volume>493</volume><fpage>97</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1038/nature11665</pub-id><pub-id pub-id-type="pmid">23172139</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hung</surname> <given-names>CP</given-names></name><name><surname>Kreiman</surname> <given-names>G</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Fast readout of object identity from macaque inferior temporal cortex</article-title><source>Science</source><volume>310</volume><fpage>863</fpage><lpage>866</lpage><pub-id pub-id-type="doi">10.1126/science.1117593</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Tamura</surname> <given-names>H</given-names></name><name><surname>Fujita</surname> <given-names>I</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Size and position invariance of neuronal responses in monkey inferotemporal cortex</article-title><source>Journal of Neurophysiology</source><volume>73</volume><fpage>218</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1152/jn.1995.73.1.218</pub-id><pub-id pub-id-type="pmid">7714567</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>JP</given-names></name><name><surname>Palmer</surname> <given-names>LA</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</article-title><source>Journal of Neurophysiology</source><volume>58</volume><fpage>1233</fpage><lpage>1258</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.58.6.1233</pub-id><pub-id pub-id-type="pmid">3437332</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lake</surname> <given-names>BM</given-names></name><name><surname>Salakhutdinov</surname> <given-names>R</given-names></name><name><surname>Tenenbaum</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human-level concept learning through probabilistic program induction</article-title><source>Science</source><volume>350</volume><fpage>1332</fpage><lpage>1338</lpage><pub-id pub-id-type="doi">10.1126/science.aab3050</pub-id><pub-id pub-id-type="pmid">26659050</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>IC</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The nature of shared cortical variability</article-title><source>Neuron</source><volume>87</volume><fpage>644</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212710</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linsker</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Self-organization in a perceptual network</article-title><source>Computer</source><volume>21</volume><fpage>105</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1109/2.36</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname> <given-names>NK</given-names></name><name><surname>Pauls</surname> <given-names>J</given-names></name><name><surname>Bülthoff</surname> <given-names>HH</given-names></name><name><surname>Poggio</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>View-dependent object recognition by monkeys</article-title><source>Current Biology</source><volume>4</volume><fpage>401</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(00)00089-0</pub-id><pub-id pub-id-type="pmid">7922354</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname> <given-names>WJ</given-names></name><name><surname>Beck</surname> <given-names>JM</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name><name><surname>Beck</surname> <given-names>J</given-names></name><name><surname>Kanitscheider</surname> <given-names>I</given-names></name><name><surname>Pitkow</surname> <given-names>X</given-names></name><name><surname>Latham</surname> <given-names>P</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Information-limiting correlations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1410</fpage><lpage>1417</lpage><pub-id pub-id-type="doi">10.1038/nn.3807</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Higher order visual processing in macaque extrastriate cortex</article-title><source>Physiological Reviews</source><volume>88</volume><fpage>59</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1152/physrev.00008.2007</pub-id><pub-id pub-id-type="pmid">18195083</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pagan</surname> <given-names>M</given-names></name><name><surname>Urban</surname> <given-names>LS</given-names></name><name><surname>Wohl</surname> <given-names>MP</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Signals in inferotemporal and perirhinal cortex suggest an untangling of visual target information</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1132</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1038/nn.3433</pub-id><pub-id pub-id-type="pmid">23792943</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name><name><surname>Schultz</surname> <given-names>S</given-names></name><name><surname>Rolls</surname> <given-names>ET</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>On decoding the responses of a population of neurons from short time windows</article-title><source>Neural Computation</source><volume>11</volume><fpage>1553</fpage><lpage>1577</lpage><pub-id pub-id-type="doi">10.1162/089976699300016142</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitkow</surname> <given-names>X</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decorrelation and efficient coding by retinal ganglion cells</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>628</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1038/nn.3064</pub-id><pub-id pub-id-type="pmid">22406548</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polack</surname> <given-names>PO</given-names></name><name><surname>Friedman</surname> <given-names>J</given-names></name><name><surname>Golshani</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of brain state-dependent gain modulation in visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1331</fpage><lpage>1339</lpage><pub-id pub-id-type="doi">10.1038/nn.3464</pub-id><pub-id pub-id-type="pmid">23872595</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>Ferster</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Inhibition, spike threshold, and stimulus selectivity in primary visual cortex</article-title><source>Neuron</source><volume>57</volume><fpage>482</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.02.005</pub-id><pub-id pub-id-type="pmid">18304479</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname> <given-names>M</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name><name><surname>Fusi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname> <given-names>NC</given-names></name><name><surname>Schwartz</surname> <given-names>O</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Spatiotemporal elements of macaque V1 receptive fields</article-title><source>Neuron</source><volume>46</volume><fpage>945</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.021</pub-id><pub-id pub-id-type="pmid">15953422</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seriès</surname> <given-names>P</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Tuning curve sharpening for orientation selectivity: coding efficiency and the impact of correlations</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1129</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1038/nn1321</pub-id><pub-id pub-id-type="pmid">15452579</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Simple models for reading neuronal population codes</article-title><source>PNAS</source><volume>90</volume><fpage>10749</fpage><lpage>10753</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamir</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emerging principles of population coding: in search for the neural code</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>140</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.002</pub-id><pub-id pub-id-type="pmid">24487341</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamir</surname> <given-names>M</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Implications of neuronal diversity on population coding</article-title><source>Neural Computation</source><volume>18</volume><fpage>1951</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.8.1951</pub-id><pub-id pub-id-type="pmid">16771659</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skottun</surname> <given-names>BC</given-names></name><name><surname>De Valois</surname> <given-names>RL</given-names></name><name><surname>Grosof</surname> <given-names>DH</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name><name><surname>Albrecht</surname> <given-names>DG</given-names></name><name><surname>Bonds</surname> <given-names>AB</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Classifying simple and complex cells on the basis of response modulation</article-title><source>Vision Research</source><volume>31</volume><fpage>1078</fpage><lpage>1086</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(91)90033-2</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tafazoli</surname> <given-names>S</given-names></name><name><surname>Safaai</surname> <given-names>H</given-names></name><name><surname>De Franceschi</surname> <given-names>G</given-names></name><name><surname>Rosselli</surname> <given-names>FB</given-names></name><name><surname>Vanzella</surname> <given-names>W</given-names></name><name><surname>Riggi</surname> <given-names>M</given-names></name><name><surname>Buffolo</surname> <given-names>F</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Zoccolan</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Emergence of transformation-tolerant representations of visual objects in rat lateral extrastriate cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e22794</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22794</pub-id><pub-id pub-id-type="pmid">28395730</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Inferotemporal cortex and object vision</article-title><source>Annual Review of Neuroscience</source><volume>19</volume><fpage>109</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.19.030196.000545</pub-id><pub-id pub-id-type="pmid">8833438</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungerleider</surname> <given-names>LG</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>'What' and 'where' in the human brain</article-title><source>Current Opinion in Neurobiology</source><volume>4</volume><fpage>157</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(94)90066-3</pub-id><pub-id pub-id-type="pmid">8038571</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname> <given-names>R</given-names></name><name><surname>Biederman</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Effects of illumination intensity and direction on object coding in macaque inferior temporal cortex</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>756</fpage><lpage>766</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.7.756</pub-id><pub-id pub-id-type="pmid">12050087</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warden</surname> <given-names>MR</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Task-dependent changes in short-term memory in the prefrontal cortex</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>15801</fpage><lpage>15810</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1569-10.2010</pub-id><pub-id pub-id-type="pmid">21106819</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamins</surname> <given-names>DL</given-names></name><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Using goal-driven deep learning models to understand sensory cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>356</fpage><lpage>365</lpage><pub-id pub-id-type="doi">10.1038/nn.4244</pub-id><pub-id pub-id-type="pmid">26906502</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.43625.022</object-id><sec id="s8" sec-type="appendix"><title>1 Intuition for the specificity of representational untangling of orientation decoding to V1</title><p>The reason for the difference between V1 and these upstream areas in the ability of the FRNL to help linear decodability can be understood through a simple intuition. The main effect of the FRNL is distinguishing between stimuli based on whether the corresponding neural responses exceed the firing threshold or not. This is useful for orientation decoding with phase nuisance when cells can attain different maximal membrane potential values depending on stimulus orientation even when pooling across all possible stimulus phases. For Gabor filter receptive fields this is clearly the case: at the preferred orientation of a cell, it will be deeply modulated by phase, and will attain a high maximal membrane potential value at its preferred phase, while at the orthogonal orientation it will be unmodulated by stimulus phase and will thus only attain intermediate values of the membrane potential. If the firing threshold is between these intermediate and maximal values, the FRNL can contribute to decoding. In contrast, cells with non-oriented receptive fields, such as those we used to model upstream areas, will show the same amount of membrane potential modulation at any stimulus orientation, and thus the attained maximal membrane potentials will not differ between stimulus orientations. As a result, no firing threshold will be able to distinguish between different orientations, and linear decoding performance remains at chance, just as we found.</p></sec><sec id="s9" sec-type="appendix"><title>2 Information-limiting correlations</title><p>Imposing a flat correlation structure on the membrane potential responses had a small effect on peak performance (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>) and on optimal threshold (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). The effect of correlations, however, depends not only on magnitude but also on its specific structure: Information Limiting Correlation (ILC) (<xref ref-type="bibr" rid="bib35">Moreno-Bote et al., 2014</xref>) imply covariations on neuron populations responses that are indistinguishable from those caused by changes in the decoded stimulus, stimulus orientation in our case and are known to have detrimental effects on coding. We investigated the effect of ILC by introducing orientation noise in the stimulus: the orientation of input stimulus was randomly sampled from a five degree mormal distribution. The 'private' noise added to the linear filter responses (<xref ref-type="fig" rid="fig1">Figure 1</xref>) was rescaled so that the total variance, the joint effect caused by the variance in stimulus drive and that of the 'private' noise, remained the same as in earlier simulations (3 mV). ILC limits decoding performance by introducing uncertainty about the identity of the stimulus orientation, which can be seen in decreased Bayesian decoder performance too (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Importantly, while ILC also affected linear decoding by reducing overall performance, the qualitative properties of the firing rate decoder remained intact: the decoder was characterised by a clear optimal threshold and the location of the optimum was similar to the independent noise case. Interestingly, the magnitude of decline in linear decoding performance relative to the performance of the optimal decoder is smaller when variance is partly caused by ILC than in the case of a network where noise is independent across neurons (90% vs. 78%, respectively).</p></sec><sec id="s10" sec-type="appendix"><title>3 Analytical calculation of Gabor filter responses to sine grating stimuli</title><p>Gabor filter response (<inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) to general sine wave stimulus,<disp-formula id="equ12"><label>(S1)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>is calculated in a coordinate system aligned to the two cardinal axes of the Gabor filter. In this coordinate system the general form of a Gabor filter is given by<disp-formula id="equ13"><label>(S2)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo rspace="7.5pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>and the response of the filter is<disp-formula id="equ14"><label>(S3)</label><mml:math id="m14"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:munderover><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>x</mml:mi></mml:mpadded></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The integral is broken down into two terms according to the two terms of <xref ref-type="disp-formula" rid="equ12">Equation S1</xref><disp-formula id="equ15"><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We introduce <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> such that <inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where we omitted the variables <inline-formula><mml:math id="inf128"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf129"><mml:mi>y</mml:mi></mml:math></inline-formula> for the clarity of the notation. We focus on the calculation of <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> since <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> can be obtained by substituting of <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Expansion of trigonometric functions results in sixteen terms, only four of which yield non-zero double integrals:<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mo>+</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Using the addition and subtraction formulae for trigonometric functions,<disp-formula id="equ17"><label>(S4)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>x</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Using <inline-formula><mml:math id="inf134"><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msqrt><mml:mfrac><mml:mi>π</mml:mi><mml:mi>a</mml:mi></mml:mfrac></mml:msqrt></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, all the integrals can be be expressed in a closed form:<disp-formula id="equ18"><label>(S5)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mo>+</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>−</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>After expansion and simplification the above equation results in<disp-formula id="equ19"><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Finally this can be rewritten in a compact form<disp-formula id="equ20"><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Substituting <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, we can obtain a closed form expression for <inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ21"><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msqrt><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msqrt></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:mi>b</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Up to this point, for mathematical convenience, sine and cosine waves were parametrised with the wave vectors <inline-formula><mml:math id="inf138"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf139"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> together with the phases <inline-formula><mml:math id="inf140"><mml:mi>w</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf141"><mml:mi>r</mml:mi></mml:math></inline-formula>. In general, wave vectors <inline-formula><mml:math id="inf142"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be mapped onto the more commonly used spatial period (<inline-formula><mml:math id="inf143"><mml:mi>λ</mml:mi></mml:math></inline-formula>) and orientation (<inline-formula><mml:math id="inf144"><mml:mi>ϑ</mml:mi></mml:math></inline-formula>) parameters through<disp-formula id="equ22"><mml:math id="m22"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ϑ</mml:mi><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="6.9pt">,</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ϑ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In the above derivation we assumed the coordinate system to be centred on the centre of the Gabor filter. Since in a population of Gabor filters this simplifying assumption cannot hold for most of the filters, we relax the assumptions to have arbitrary centre for the Gabor filter. Under these conditions, a Gabor filter is characterised by eight parameters: <inline-formula><mml:math id="inf145"><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf146"><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf148"><mml:mi>σ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf149"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf150"><mml:mi>δ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>λ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>φ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf153"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the centre of the Gaussian envelope, <inline-formula><mml:math id="inf154"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the orientation of its major axis measured from the horizontal axis of the reference coordinate system, <inline-formula><mml:math id="inf155"><mml:mi>σ</mml:mi></mml:math></inline-formula> is the largest variance of the Gaussian in the direction of the major axes, <inline-formula><mml:math id="inf156"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> defines the ratio of the minor and major axes, <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the relative orientation of the cosine wave component measured from the major axes, <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>λ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula> is the period of the cosine, and <inline-formula><mml:math id="inf159"><mml:msub><mml:mi>φ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula> is its phase at the centre of the Gaussian. This set of parameters can be mapped to our original set of six parameters (<inline-formula><mml:math id="inf160"><mml:msub><mml:mi>G</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf161"><mml:mi>a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf162"><mml:mi>b</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf163"><mml:mi>u</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf164"><mml:mi>v</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf165"><mml:mi>w</mml:mi></mml:math></inline-formula>) by<disp-formula id="equ23"><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>ϵ</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:mi>u</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Analogously, <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> can be also expressed in this coordinate system, using the parameters spatial period (<inline-formula><mml:math id="inf167"><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>), orientation (<inline-formula><mml:math id="inf168"><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>), phase (<inline-formula><mml:math id="inf169"><mml:msub><mml:mi>φ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>), and amplitude (<inline-formula><mml:math id="inf170"><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>). The spatial period and the amplitude are independent of the coordinate system but orientation (<inline-formula><mml:math id="inf171"><mml:msup><mml:mi>ϑ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>) and phase (<inline-formula><mml:math id="inf172"><mml:msup><mml:mi>φ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula>) undergo a transformation upon change in the coordinate system:<disp-formula id="equ24"><label>(S6)</label><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ25"><label>(S7)</label><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Taken together, the Gabor filter response with parameters <inline-formula><mml:math id="inf173"><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf174"><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf175"><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf176"><mml:mi>σ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf177"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf178"><mml:mi>δ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf179"><mml:msub><mml:mi>λ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf180"><mml:msub><mml:mi>φ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math></inline-formula>, to a sinusoidal grating stimulus, parametrised by <inline-formula><mml:math id="inf181"><mml:msub><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf182"><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf183"><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf184"><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf185"><mml:msub><mml:mi>φ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>, is<disp-formula id="equ26"><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mphantom><mml:mi>m</mml:mi></mml:mphantom></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mi>σ</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>δ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>cos</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>δ</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf186"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43625.024</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Rust</surname><given-names>Nicole</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>DiCarlo</surname><given-names>Jim</given-names> </name><role>Reviewer</role><aff><institution>Massachusetts Institute of Technology</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Representational untangling by the firing rate nonlinearity in V1 simple cells&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Jim DiCarlo (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this study, the authors examine the role of threshold nonlinearities (a model of the mechanisms that intervene between membrane potential and firing rate) in neurons in cortical area V1. They use a combination of simulations and a bit of experimental data to argue that those thresholds appear to be set to maximize the (population) linear decodability of stimulus orientation in the face of nuisance parameters (phase, contrast, and spatial frequency). This hypothesis is referred to as representational untangling (RU). While untangling is an essential component of the visual form processing pathway, the mechanisms that support it are incompletely described, and in that context, this paper addresses an important and interesting set of issues. The reviewers have identified a number of issues that need to be addressed but they believe that they can be addressed via further analyses and some re-writing.</p><p>Essential revisions:</p><p>1) What is/are the main alternative hypotheses (to RU) and which figures/results reject those alternatives?</p><p>The main setup of this study is that the &quot;designer&quot; of V1 has followed a particular optimization goal (= a particular RU variant). (I mean &quot;designer&quot; here in the general sense of evolution, development, etc.) I kept wishing that the authors would more directly pose and test at least one serious alternative optimization goal. The main one they seem to entertain is preservation of total information:</p><p>&quot;These results suggest that information re-formatting, rather than maximisation, may already be a relevant computational goal for the early visual system.&quot;</p><p>But that alternative is dismissed as almost trivial (and some versions are), which leaves one wondering why a study is even needed. As the authors point out, thresholds can only remove information. The more interesting alternative optimizations have to do with preserving information in the face of energy costs or other forms of compression (e.g. sparseness).</p><p>Here is a first attempt at stating an alternative:</p><p>&quot;However, despite the obvious loss of total information caused by the rectifying aspect of the FRNL, which is due to all membrane potential values below the firing threshold being mapped to zero firing rate…&quot; But this is not at all obvious at the population level.</p><p>And then &quot;While this drastic removal of a large fraction of responses can clearly lead to severe total information loss (Barak et al., 2013),&quot; The key word here is &quot;can.&quot; But does it?</p><p>For example, the total information from the population of retinal ganglion cells might be spread out across an overcomplete set of V1 neurons, such that, even with thresholds, the V1 population maintains the total information (i.e. no loss). Of course, even if that were true (which I don't believe), then one would still have to suggest what the reason for doing that overcomplete spread out might be (e.g. preservation of information about natural images (not total information), energy costs, etc.).</p><p>To be more concrete and constructive: The most interesting testable experimental question here is how the thresholds are set (i.e. under what possible optimization goal.) The main setup seems to go like this: the population of V1 encoders is fixed, the noise in the membrane potentials of those encoders is irreducible, and the parameter under (optimization) control of this system is the threshold. Under these assumptions, the question posed is, what optimization goal is the system using to set the u<sub>th</sub> parameter for each neuron? The authors claim that it is the particular RU goal they setup (Figure 7). It would be stronger if they could show that it is not (or less) consistent with some other optimization goal. In both cases, the simulations would assume the same fixed number of neuron and irreducible noise. This would make the paper much stronger. Alternatively, perhaps the authors could consider a range of RU optimization hypotheses (e.g. separability of orientation, separability of contrast, etc.)? Or, similarly, optimization for RU under limited training examples for the decoders? (see point 3 below).</p><p>Similarly, the authors focused solely on RU of the orientation of sinusoidal gratings from the responses of model simple cells. Optimality of the firing rate threshold is defined in the context of untangling information about the orientation of sinusoidal gratings, absent any reference to why posing the problem this way makes sense, given that these neurons presumably evolved to process natural images.</p><p>2) Try to strengthen the presented evidence for RU from the image input to this level of V1 (spiking outputs of V1 simple cells).</p><p>Previous experimental results advocating for RU along the ventral stream have made comparisons at two points of processing (e.g. V4 population spike rates and IT population spike rates). It would strengthen the claims if the authors would do something similar across the key stage of processing they are focused on here. E.g. compare with pixels, center-surround (e.g. difference of gaussians (DOG) to approx. RGC and LGN responses).</p><p>We understand that some decodes were attempted on the simulated intracellular potential population and compared with the spiking outputs. That is good, but this seems a bit like comparing apples and oranges.</p><p>3) Better define the RU hypothesis (or alternative variants of it). In particular, the operational definition of linear separability is not agreed upon in the field, and different definitions tend to test different things. We suggest would be to explore these different operational variants (below) and decide if the results are robust to that, or if they point in an even more interesting direction.</p><p>Most notably: It appears that the linear decoder test that was applied was only a test of generalization to new noise samples (subsection “Linear decoder”), rather than generalization to unseen values of the stimulus parameters. Is this correct? But then the manuscript reads: &quot;RU was quantified by the performance of a linear decoder which decoded stimulus orientation from membrane potentials or firing rates in the face of noise and variability in other (nuisance) parameters of the stimulus: phase, contrast, and spatial frequency (Figure 1, blue).&quot; This might imply tests of generalization to new stimulus values, but it is unclear. (Side point, the paper must be significantly clarified around this issue, regardless of what was done.)</p><p>Assuming that the training data completely cover all the test data (i.e. generalization only to new noise samples), then it is surprising to see that this linear decodability test would not be partially successful with decoders on the pixel (+noise) input representation. (Note that the two dimensional examples such as Figure 2 provide useful intuition, but tend to hide the possibilities of successful linear separability that is possible in high dimensional population spaces.) But the intuition might be wrong here because the chosen nuisance variables might strongly push against this possibility. Clarification around this issue would strengthen the paper. That is, one RU possibility is that NO separating hyperplane exists in the population state space. Another RU possibility is that multiple separating hyperplanes exists, but that they require a very large number of training examples to discover – thus, in practice, they appear not to exist. The difference in these two variants of RU depends on the amount of training data and the amount of required generalization.</p><p>To summarize: the improved linear decodabilty of the V1 population relative to a pixel or DOG representation should be shown directly and the dependence on training sample size should be explored in some way. The key result might be: for limited number of training examples, the properly thresholded V1 decoding performance is higher than the pixel and DOG representations, but that result is not true in the limit of infinite training data. To be clear, either of the possibilities above are interesting and publishable, but they are impossible to disentangle right now.</p><p>Related: an intuitive solution to increase linearly separability is to set RELU thresholds very high such that the representation of each image is ultra-sparse. In the limit, each image would be coded as one-hot population response vector. Under some operational definitions of linear separability, this solution is perfectly fine (e.g. test only at the training images). However, it is not a real world solution because it has little to no generalization power and it requires a very large number of neurons to maintain information and corresponding large numbers of training examples. Thus, the trick for real world tests of linear separability in the setting explored in this paper is to set the thresholds high enough to enable linear separability in the context of limited training data and test generalization to new nuisance values of the stimulus parameters – what that limit should be and how &quot;far&quot; the &quot;new&quot; stimuli should be are admittedly unclear, but both could be considered and explored to firm up the arguments. Perhaps this has already been done and it was missed it in the presentation.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43625.025</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) What is/are the main alternative hypotheses (to RU) and which figures/results reject those alternatives?</p><p>[…] To be more concrete and constructive: The most interesting testable experimental question here is how the thresholds are set (i.e. under what possible optimization goal.) The main setup seems to go like this: the population of V1 encoders is fixed, the noise in the membrane potentials of those encoders is irreducible, and the parameter under (optimization) control of this system is the threshold. Under these assumptions, the question posed is, what optimization goal is the system using to set the u<sub>th</sub> parameter for each neuron? The authors claim that it is the particular RU goal they setup (Figure 7). It would be stronger if they could show that it is not (or less) consistent with some other optimization goal. In both cases, the simulations would assume the same fixed number of neuron and irreducible noise. This would make the paper much stronger. Alternatively, perhaps the authors could consider a range of RU optimization hypotheses (e.g. separability of orientation, separability of contrast, etc.)? Or, similarly, optimization for RU under limited training examples for the decoders? (see point 3 below).</p></disp-quote><p>Thank you for the very constructive suggestion. Although, as the reviewer points out, we already referred to a specific alternative non-RU-related optimisation goal (information maximisation) in the previous version of the manuscript, and we thought it was clearly ruled out by the data, we did not unpack why we thought this was the case and, thus, this indeed remained way too implicit in our presentation. In order to address the reviewer’s criticism, we have now explicitly included this alternative and explain why it cannot account for the data. We chose (Shannon) information maximisation (infomax) as a relevant alternative because it is a widely investigated and accepted optimisation goal for sensory systems (Dayan and Abbott, 2000; Rieke et al., 1997, Spike: Exploring the Neural Code). We have now formulated infomax in the context of our network and built on a well-known relationship between the performance of the Bayesian decoder and mutual information, the objective function for infomax (Materials and methods). We have included an analysis of information transmission in the context of changing firing thresholds under phase nuisance parameter uncertainty in the Results section, included an additional panel on this analysis (Figure 3—figure supplement 2B), expanded the analysis of experimental data to the infomax principle, and discuss this alternative hypothesis in the Discussion. We have included the description of the infomax model in the Materials and methods. In short, our results indicate that infomax does not account for the experimentally found firing thresholds of V1 cells.</p><p>As for robustness to the choice of a specific RU-related objective, we have conducted another set of novel analyses to investigate RU performance when the goal was decoding spatial period or contrast rather than orientation. We performed the experiment by keeping other nuisance parameters unknown but swapping spatial period (or contrast) and orientation: orientation became a nuisance while spatial period (or contrast) became the variable of interest (Figure 4—figure supplement 2). Our analyses showed that while there were quantitative differences in performance from the original (orientation decoding) case, our main results carried over to these scenarios: the firing rate nonlinearity could increase (linear) decodability, and there was an optimal value for the threshold of this nonlinearity very near (within 1-2 mV) of the optimal threshold we originally found. A new figure which summarises these results has been added to the Appendix 1 (Figure 4—figure supplement 2). We refer to these results in the Results, discuss them in the Discussion, and have extended the Materials and methods with the description of this alternative decoding paradigm.</p><disp-quote content-type="editor-comment"><p>Similarly, the authors focused solely on RU of the orientation of sinusoidal gratings from the responses of model simple cells. Optimality of the firing rate threshold is defined in the context of untangling information about the orientation of sinusoidal gratings, absent any reference to why posing the problem this way makes sense, given that these neurons presumably evolved to process natural images.</p></disp-quote><p>While we agree that the evolutionary goal of the system must be to achieve maximal performance on natural images, rather than the highly simplified full field gratings we used in our study, our choice for these stimuli was motivated by a number of factors. First, as a large swathe of the theoretical and experimental literature has used such full-field grating stimuli, we thought it was important to use a paradigm which was as similar to previous work as possible in order to make our results easily comparable to those previous results. Indeed, we think that the point that nuisance parameters, rather than single-neuron variability or the exact structure of noise correlations, are the main bottleneck for decoding (and that this bottleneck is at least partially alleviated by the firing rate nonlinearity) is stronger when we show that it is even true for the same simple stimuli that others have used (but largely ignored the effects of nuisance parameters), even without considering the whole complexity of natural images.</p><p>Second, the relatively simple feed-forward architecture of our model population is probably sufficient and has been widely used to account for responses to such simple stimuli. However, more complex stimuli will recruit mechanisms (eg. those responsible for extra-classical receptive field effects) that this architecture cannot capture, we leave the effects of these mechanisms on RU for later studies. We now dedicate a section in the Discussion to cover this point (“Visual processing in ecologically relevant regimes”). In addition, as we explain it in the text, natural image statistics were at least taken into account in the choice of the distribution of nuisance parameters (Figure 5A).</p><p>Third, as we now show in Figure 3—figure supplement 3 (and discuss in the Results), our main results remain essentially unchanged when we consider a “hypercolumnar” population representing <italic>local</italic> rather than <italic>global</italic> orientation (ie. such that all cells have their receptive fields in the same location). Importantly, inasmuch as our model represents an appropriate approximation of hypercolumnar responses (see above), the content of natural images outside this (classical) receptive field location will not affect the decoding of the content at this location, and thus these results should generalise to natural stimuli.</p><disp-quote content-type="editor-comment"><p>2) Try to strengthen the presented evidence for RU from the image input to this level of V1 (spiking outputs of V1 simple cells).</p><p>Previous experimental results advocating for RU along the ventral stream have made comparisons at two points of processing (e.g. V4 population spike rates and IT population spike rates). It would strengthen the claims if the authors would do something similar across the key stage of processing they are focused on here. E.g. compare with pixels, center-surround (e.g. difference of gaussians (DOG) to approx. RGC and LGN responses).</p><p>We understand that some decodes were attempted on the simulated intracellular potential population and compared with the spiking outputs. That is good, but this seems a bit like comparing apples and oranges.</p></disp-quote><p>Thank you for this other excellent suggestion. We have taken it on board and now devote a whole new section (Representational untangling of orientation is specific to V1 and a section in the Appendix 1 (Section 1) and corresponding section in the Materials and methods) and new figure panels (Figure 3C,D) to showing that RU of orientation information cannot be achieved with retinal- (ie. single-pixel) or LGN-like (ie. DoG) receptive fields.</p><disp-quote content-type="editor-comment"><p>3) Better define the RU hypothesis (or alternative variants of it). In particular, the operational definition of linear separability is not agreed upon in the field, and different definitions tend to test different things. […]</p><p>To summarize: the improved linear decodabilty of the V1 population relative to a pixel or DOG representation should be shown directly and the dependence on training sample size should be explored in some way. The key result might be: for limited number of training examples, the properly thresholded V1 decoding performance is higher than the pixel and DOG representations, but that result is not true in the limit of infinite training data. To be clear, either of the possibilities above are interesting and publishable, but they are impossible to disentangle (;) right now.</p></disp-quote><p>We trained our linear decoders with sufficient amounts of data so that to achieve asymptotic performance. This was true for <italic>all</italic> cases, including those using pixel or DoG (center-surround) receptive fields. (Thus, as the reviewer suggests, we mostly only test generalisation performance for new noise samples, not new stimuli, but see below.) The reason for this was twofold. First, we wanted to be able to make what we believe is the stronger statement: that <italic>even in the limit of infinite training data</italic> RU is non-trivial in the presence of nuisance parameters (and that the appropriate firing rate nonlinearity can help with it). Second, as we are studying the representation of low-level visual features in an early visual area, there is good reason to believe that the decoding of this information could have been optimised on evolutionary time scales (as the reviewer also notes elsewhere) and would thus not be limited by the amount of data experienced over the lifetime of an individual.</p><p>We have now clarified what we mean by generalisation in the Results, discuss our choice of asymptotic performance in the Discussion, and explain the details of cross validation in the Materials and methods and Table 1.</p><p>Furthermore, note that in Figure 5, we test a specific (and we believe ecologically relevant) form of generalisation: generalisation to new <italic>distributions</italic> of stimuli(rather than to new <italic>individual</italic> stimuli) which can occur when transitioning between different environments. Nevertheless, we also tested cross-validated performance with phase as nuisance parameter such that the distribution from which training and test stimuli were sampled were the same but the actual set of training and test stimuli were different and found that the performance vs. threshold curves (not shown) were near-identical to those we obtained originally (Figure 3).</p><disp-quote content-type="editor-comment"><p>Related: an intuitive solution to increase linearly separability is to set RELU thresholds very high such that the representation of each image is ultra-sparse. In the limit, each image would be coded as one-hot population response vector. Under some operational definitions of linear separability, this solution is perfectly fine (e.g. test only at the training images). However, it is not a real world solution because it has little to no generalization power and it requires a very large number of neurons to maintain information and corresponding large numbers of training examples. Thus, the trick for real world tests of linear separability in the setting explored in this paper is to set the thresholds high enough to enable linear separability in the context of limited training data and test generalization to new nuisance values of the stimulus parameters – what that limit should be and how &quot;far&quot; the &quot;new&quot; stimuli should be are admittedly unclear, but both could be considered and explored to firm up the arguments. Perhaps this has already been done and it was missed it in the presentation.</p></disp-quote><p>This is an intriguing possibility, thank you for bringing it up. As the reviewer anticipates, the one-hot population coding solution achieved by ultra-sparse codes fundamentally relies on assuming no noise, and requires an exponential number of neurons (in the number of nuisance parameters). In fact, in the (unrealistic) limit of no noise, the question of an optimal threshold even becomes somewhat moot as essentially <italic>all</italic> thresholds above a minimum will perform equally well (essentially perfectly), as the broadening of the robust performance interval towards low values of the noise-to-signal ratio in Figure 7C (and Figure 7—figure supplement 3) also suggests. Moreover, ultra sparse coding will be particularly sensitive to contrast as a nuisance parameter (as the correct threshold for achieving a one-hot code will critically depend on the overall scaling of responses which in turn depends monotonically on contrast, such that selecting a single optimal thresholdis impossible). All-in-all, ultra sparse codes were not relevant for our study because these conditions (especially no noise) were not met in our simulations. Indeed, note that we found that increasing the number of neurons in the population did not favour higher thresholds which could have potentially led to such ultra sparse codes (Figure 6B). More importantly, we expect these conditions also not to apply to real V1, e.g. the experimentally measured levels of noise-to-signal ratio in our V1 data were well above 0 (Figure 7). In sum, the pathological solution of ultra-sparse codes is already ruled out under the realistic conditions we studied. Note that this did not even require us to measure generalisation to new stimuli (but see Figure 5 and our previous response), only to new noise samples. (See our previous response for the justification of why we focussed on this form of generalisation.) We now discuss this in the text (subsection “The computational role of the FRNL”).</p></body></sub-article></article>