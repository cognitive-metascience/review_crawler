<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">30762</article-id><article-id pub-id-type="doi">10.7554/eLife.30762</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A spatial memory signal shows that the parietal cortex has access to a craniotopic representation of space</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-93724"><name><surname>Semework</surname><given-names>Mulugeta</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6070-0119</contrib-id><email>mulugetas@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-94397"><name><surname>Steenrod</surname><given-names>Sara C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7932-7385</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" id="author-94398"><name><surname>Goldberg</surname><given-names>Michael E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0728-2464</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="other" rid="fund12"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Mahoney-Keck Center for Brain and Behavior Research, Department of Neuroscience</institution><institution>Columbia University College of Physicians and Surgeons</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Neuroscience</institution><institution>Columbia University College of Physicians and Surgeons</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Division of Neurobiology and Behavior</institution><institution>New York State Psychiatric Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Neurology</institution><institution>Columbia University College of Physicians and Surgeons</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Department of Psychiatry</institution><institution>Columbia University College of Physicians and Surgeons</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Department of Ophthalmology</institution><institution>Columbia University College of Physicians and Surgeons</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution content-type="dept">Kavli Institute for Neuroscience</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-17965"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing Editor</role><aff id="aff8"><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Institute of Clinical and Translational Sciences, Washington University School of Medicine, St Louis, United States</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>16</day><month>02</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e30762</elocation-id><history><date date-type="received" iso-8601-date="2017-07-26"><day>26</day><month>07</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2018-02-15"><day>15</day><month>02</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Semework et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Semework et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-30762-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.30762.001</object-id><p>Humans effortlessly establish a gist-like memory of their environment whenever they enter a new place, a memory that can guide action even in the absence of vision. Neurons in the lateral intraparietal area (LIP) of the monkey exhibit a form of this environmental memory. These neurons respond when a monkey makes a saccade that brings the spatial location of a stimulus that appeared on a number of prior trials, but not on the present trial, into their receptive fields (RFs). The stimulus need never have appeared in the neuron’s RF. This memory response is usually weaker, with a longer latency than the neuron’s visual response. We suggest that these results demonstrate that LIP has access to a supraretinal memory of space, which is activated when the spatial location of the vanished stimulus can be described by a retinotopic vector from the center of gaze to the remembered spatial location.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>memory</kwd><kwd>lateral intraparietal</kwd><kwd>spatial vision</kwd><kwd>environmental memory</kwd><kwd>monkey</kwd><kwd>vision</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R24 EY-015634</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>2T32MH015174-35</award-id><principal-award-recipient><name><surname>Semework</surname><given-names>Mulugeta</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000888</institution-id><institution>W. M. Keck Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100002089</institution-id><institution>Fight for Sight</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001068</institution-id><institution>Dana Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001201</institution-id><institution>Kavli Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R21 EY-017938</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R21 EY-020631</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01 EY-017039</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>P30 EY-019007</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><award-group id="fund12"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01 EY-014978</award-id><principal-award-recipient><name><surname>Goldberg</surname><given-names>Michael E</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neural recordings and analyses illustrate a unique lateral intraparietal area (LIP) response that may contribute to how primates can establish a memory of the environment in a useful coordinate frame, and maintain this representation of the environment over time.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans, and presumably monkeys, effortlessly establish a gist-like memory of their environment whenever they enter a new place. They can then use this memory to guide action even in the absence of vision. The hallmark of this environmental memory is that the objects remembered need not be relevant to the subject’s current behavior. For example, although you may never be asked to point to the door with your eyes closed, you establish a memory of the door’s location automatically. Although normally humans have no trouble pointing to objects in the room with their eyes closed, patients with bilateral parietal lesions cannot do this even though they can easily locate and point to objects in the room with their eyes open (<xref ref-type="bibr" rid="bib22">Levine et al., 1985</xref>), suggesting an environmental memory impairment.</p><p>Visually responsive neurons in the frontal eye field (FEF) exhibit a signal that could represent environmental memory (<xref ref-type="bibr" rid="bib35">Umeno and Goldberg, 2001</xref>). After monkeys make a number of saccades that bring a task-irrelevant probe stimulus into the receptive field of a visually responsive FEF neuron, many neurons respond on trials when a saccade brings the spatial location of the stimulus into the receptive field, even though the probe stimulus did not appear on the current trial. However, because the investigators always used the same saccade both to establish and evaluate the memory response, it is not clear if the effect is a true spatial memory or merely a memory of receptive field stimulation associated with a saccade.</p><p>Here, we asked if neurons in the lateral intraparietal area (LIP), an area with visual, oculomotor, and mnemonic connections that serves as a priority map of the environment (<xref ref-type="bibr" rid="bib5">Bisley and Goldberg, 2010</xref>), also exhibits an environmental memory signal. Indeed, we found that neurons in LIP did convey an environmental memory signal. Further, we found that the memory signal could be established even when the probe stimulus never appeared in the receptive field of the neuron, and occurred despite the fact that the monkey made a different saccade to bring the spatial location of the vanished probe stimulus into the receptive field. These results suggest that LIP has access to a representation of the visual world in at least supraretinal coordinates. Because saccades and reaching movements are coded in the parietal cortex in retinotopic coordinates (<xref ref-type="bibr" rid="bib11">Duhamel et al., 1992</xref>; <xref ref-type="bibr" rid="bib1">Andersen et al., 1998</xref>), these results suggest that one role of LIP is to transform a supraretinal representation of the remembered environment into a retinotopic representation more useful for the generation of action.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Dataset</title><p>We recorded the activity of 131 neurons in three monkeys: 79 in Monkey A, 15 in Monkey B, and 37 in Monkey C. Because we had only a small number of cells in each monkey and the results from Monkeys B and C were comparable, these two data sets were combined for several analyses.</p><p>All neurons in our sample had visual responses to the onset of a saccade target in their receptive fields, and exhibited delay-period and/or presaccadic activity in a memory-guided delayed saccade task. Furthermore, we only studied the memory-related activity of neurons whose postsaccadic responses were not contaminated by the phasic and tonic components of an eye position signal often found in parietal neurons (<xref ref-type="bibr" rid="bib1">Andersen et al., 1998</xref>). All neurons were situated in the lateral bank of the intraparietal sulcus, as determined by structural MRI (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.002</object-id><label>Figure 1.</label><caption><title>Location of LIP recordings.</title><p>(<bold>A</bold>) A tungsten microelectrode (250 µm thick, straight shadow) located in the target area based on known LIP activity and the commonly used atlas-defined coordinates (<xref ref-type="bibr" rid="bib27">Paxinos et al., 1999</xref>; <xref ref-type="bibr" rid="bib31">Saleem and Logothetis, 2012</xref>) within the given coronal slice of the brain. This electrode location was at −2 AP and +10 ML.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig1-v2"/></fig></sec><sec id="s2-2"><title>Task 1: Basic memory task</title><p>We studied 72 LIP neurons using a task based on that used to demonstrate environmental memory in the frontal eye field (<xref ref-type="bibr" rid="bib35">Umeno and Goldberg, 2001</xref>) (<xref ref-type="fig" rid="fig2">Figure 2</xref>). After determining the spatial tuning properties of the neuron being recorded, the monkey performed the basic memory task which is comprised of four blocks. We customized the arrangement of the stimuli (fixation point, saccade target, and probe stimulus) according to the spatial properties of each neuron’s receptive field. In the first block, we asked the monkey to perform 20 visually guided saccade trials in which no probe stimuli appeared on the screen (<xref ref-type="fig" rid="fig2">Figure 2</xref>, Block 1). In these trials, no stimulus, including the saccade target, encroached on the receptive field of the neuron. Next, we asked the monkey to perform a block of 30 visually guided saccade trials in which a task-irrelevant probe stimulus appeared at a location that would be brought into the receptive field by the required saccade (i.e. the future receptive field of the neuron) (<xref ref-type="fig" rid="fig2">Figure 2</xref>, Block 2). Then, we pseudorandomly interleaved trials in which the probe stimulus appeared on the screen with those in which no probe stimulus appeared (<xref ref-type="fig" rid="fig2">Figure 2</xref>, Block 3). Finally, we presented the monkey with a block of 100 trials in which, again, the probe stimulus never appeared (<xref ref-type="fig" rid="fig2">Figure 2</xref>, Block 4).</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.003</object-id><label>Figure 2.</label><caption><title>The basic memory task.</title><p>The different trials types were performed in blocks. In Block 1 (baseline), the monkey made a visually guided saccade to a point outside the neuron’s response field, to show that the saccade itself does not evoke neural activity. In the cartoon, the fixation point is a white square, the saccade target a red square, the presaccadic spatial location of the receptive field a white circle, the postsaccadic receptive field a magenta circle. The presentation times of the fixation point, saccade target and, when appropriate, probe stimuli are shown in the traces below. In Block 2 (visual max), the monkey made the same saccade, but now the saccade brought the probe stimulus into the receptive field. If the monkey made a saccade to the probe stimulus, the trial was terminated. In Block 3 (form and recall memory), for half of the trials, the probe stimulus appeared on the screen and was brought into the RF by the saccade. These trials were pseudorandomly intermixed with trials in which no probe stimulus appeared and the monkey made the same saccade. In block 4 (forget), the monkey made the same saccade but, as in Block 1, the probe stimulus never appeared.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig2-v2"/></fig><p>22/49 of neurons in Monkey A (45%), and 11/23 (48%) exhibited environmental memory in the basic task: There was a significant difference (p &lt; 0.05 by Wilcoxon rank sum) in the post saccadic response in Block 1 and the probe stimulus-absent trials in Block 3 (<xref ref-type="fig" rid="fig3">Figure 3</xref> for single cell and <xref ref-type="fig" rid="fig4">Figure 4</xref> for the population of all cells (p&lt;0.001 Wilcoxon signed ran), black traces and raster symbols versus magenta traces and raster symbols). There was no significant post-saccadic response in Block 1 (<xref ref-type="fig" rid="fig3">Figure 3</xref>, for a single cell and <xref ref-type="fig" rid="fig4">Figure 4</xref> for the population of all cells black traces and raster symbols). There was a response to the probe stimulus in Block 2 when the saccade brought the probe stimulus into the receptive field (<xref ref-type="fig" rid="fig3">Figure 3</xref>, for a single cell and <xref ref-type="fig" rid="fig4">Figure 4</xref> for the population of all cells green traces and raster symbols). Neurons responded similarly in Block 3 as they did in Block 2 on the half of trials in which the probe stimulus appeared in the future receptive field (<xref ref-type="fig" rid="fig3">Figure 3</xref> for a single cell and <xref ref-type="fig" rid="fig4">Figure 4</xref> for the population of all cells, red traces and raster symbols). However, on the interleaved half of the trials in Block 3 in which a probe stimulus did not appear, the cells responded when the monkey made a saccade bringing the vanished probe location into the receptive field (<xref ref-type="fig" rid="fig3">Figure 3</xref> for a single cell and <xref ref-type="fig" rid="fig4">Figure 4</xref> for the population of memory cells, magenta traces and raster symbols). This response, which occurred after the saccade brought the spatial location of the probe stimulus into the receptive field even though no probe appeared on that trial, is the environmental memory response. Finally, after a block of forgetting trials in which the probe stimulus never appeared (Block 4 trials, identical to Block 1 trials for a single cell), the environmental memory response waned and, in some cases, disappeared entirely. The peristimulus time histogram (PSTH) figures do not include an average forgetting trace because the wide variation of forgetting traces made such an average uninformative</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.004</object-id><label>Figure 3.</label><caption><title>Single-cell responses in the basic memory task: from Monkey A (left panel) and Monkeys B and C (right panel).</title><p>Neural activity aligned to the beginning of the saccade. Shaded regions in the peristimulus time histograms (PSTHs) are standard errors of means calculated using all the trials in the given block. Black traces and raster dots: activity in Block 1, stimulus absent. Green traces and raster dots: activity in Block 2, 100% stimulus present. Red (broken) traces and raster dots: activity in stimulus-present trials in Block 3. Magenta traces and raster dots: activity in probe stimulus-absent trials in Block 3. Here, there is a brisk response that shows the expected latency advance evoked by predictive remapping (<xref ref-type="bibr" rid="bib11">Duhamel et al., 1992</xref>). Note that the latency of the memory response is nearly 100 ms longer after the saccade than the predictive response. The memory decays after many (up to 100) trials. H and V are horizontal and vertical eye movements smoothed using a 10 ms sliding causal filter.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig3-v2"/></fig><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.005</object-id><label>Figure 4.</label><caption><title>Population responses in the basic memory task: from Monkey A (left panel) and Monkeys B and C (right panel).</title><p>Block descriptions are as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig4-v2"/></fig><p>Both populations of neurons, including the statistically significant and the statistically non-significant neurons showed statistically significant memory responses (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). The population showed a significant environmental memory response comparing the responses in Block one and the memory trials of Block 3 (Monkey A, p=0.0002 by Wilcoxon signed rank). Monkeys B and C (p=0.0003, Wilcoxon signed rank). (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, Monkey A in blue and Monkeys B and C in red, significant cells filled symbols). The environmental memory response was weaker than the visual response evoked when the monkey made a saccade that brought the stimulus into the receptive field (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, p&lt;0.001 by Wilcoxon Signed rank). The latency of the environmental memory response was greater than the visual response evoked when a saccade brought the stimulus into the receptive field (<xref ref-type="fig" rid="fig5">Figure 5c</xref>) (Wilcoxon signed rank p=0.02 for Monkey A and B, and 0.0005 for Monkey C; mean visual/memory latency: 36/77 ms for Monkey A, 9/116 ms for Monkeys B and C). Of note some, but not all, of the cells exhibiting environmental memory had a shorter visual latency than one would expect given the minimal latency to a stimulus flashed in the receptive field. This latency advance is characteristic of the remapping response (<xref ref-type="bibr" rid="bib10">Duhamel et al., 1991</xref>). However, because the memory responses for some neurons increased gradually, we were unable to establish memory latencies for all neurons using our latency method (for these neurons, we used other approaches, as described in the Materials and methods section).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.006</object-id><label>Figure 5.</label><caption><title>Population data for the basic memory task: For all recorded units (open circles and triangles) and for units which showed significant differences between baseline and memory blocks (filled circles and triangles, trial per trial peak comparisons, Wilcoxon signed rank, population p&lt;0.001, within-cell Wilcoxon rank sum &lt;0.05).</title><p>(<bold>A</bold>) Comparison of peak activity in the baseline and memory conditions (Block 1 vs Block 3, no probe stimulus trials). Each point represents a single cell. Cells with memory activity lie above the x = y line (diagonal). Monkey A: blue circles; Monkeys B and C: red triangles (*=Monkeys B and C). Insets: index (Block 3 versus Block 1) histograms for the whole population, out of which the statistically significant units are shown in shaded circles and triangles on the scatter plot. A median (numbers above index histograms) and rank sum and KS test confirmed memory activity as they both showed that the index distribution for the parent population was positively skewed. (<bold>B</bold>) Peak memory activity plotted against visual activity. Blue and red lines in the scatter plots (<bold>B and C</bold>) are polynomial fits to each population data. They both indicate a positive shift of neural responses towards memory activity. (<bold>C</bold>) Latency of memory response versus the latency of visual response for cells. (<bold>D</bold>) Normalized decay activity. The memory response gradually decays after the last trial in which the probe appeared. The regression lines are data fits using a first order exponential. As indicated in ‘D’ legend, open squares and triangles are neural activities during decay trials compared to (normalized by) the mean of the last five trials with the probe stimulus (left y-axis).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig5-v2"/></fig><p>During Block 4, in which the probe stimulus no longer appeared, the memory response gradually decayed (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). On an individual cell basis, this decay (measured in the memory window as described in the Materials and methods section) was quite noisy and variable among cells. As a population, the normalized decay activity could be fit to a first-order exponential. To control for fast memory buildups and/or in-between block fluctuations, we normalized the decay activity with stimulus presentation block. Monkey A had a decay rate constant of 0.3 trials (i.e. versus stimulus/block-one trials, first-order exponential) (R<sup>2</sup> = 0.7). Monkeys B and C had similar results (decay rate constant = 0.13; R<sup>2</sup> = 0.6). For both monkeys and comparisons, the first and last 10 trials in the 50-trial forgetting block (Block 4) are statistically different (Wilcoxon signed rank, p&lt;0001).</p><p>The memory cells were not just the expected tail of a population distribution. To investigate the population median shift, we used a classical median approach. We analyzed the distribution of index histograms and found that memory activity significantly increased the median (medians &gt; 0.1 and compared with the index histograms with a mean-deducted version of the same distribution Wilcoxon signed rank p=3.7034e-12 for Monkey A and 1.4923e-06 for Monkeys B and C). We also used a non-parametric and robust skewness estimator called the medcouple (medc) measure (<xref ref-type="bibr" rid="bib6">Brys et al., 2004</xref>). Unlike classical histogram descriptors such as skewness and kurtosis, this approach finds the scaled median difference between the left and right sides of a distribution. Its values range from −1 to 1 (left to right skewed, respectively). Analysis using this method for mixed trials in Block 3 (memory) versus Block 1 (baseline) indices (<xref ref-type="fig" rid="fig5">Figure 5a</xref> inserts) revealed that the population data was skewed toward a memory response (positive medc, ~1). The positive skewness of the memory responses (compared to baseline) is also indicated by an increased slope of a polynomial fit line (red and blue lines in <xref ref-type="fig" rid="fig5">Figure 5a</xref>) which is shifted to left of the identity line (black dashed line).</p></sec><sec id="s2-3"><title>Task 2: No-RF task</title><p>This task tested whether environmental memory could be evoked in the absence of receptive field stimulation. The basic memory task demonstrated that LIP neurons respond when a saccade brings the spatial location of a previously presented (now vanished) probe stimulus into their receptive field. However, because we established memory by having the monkey make a saccade that brought a stimulus into the receptive field, and then demonstrated the memory by having the monkey make the same saccade without a stimulus present, we could not know whether the memory response was independent of receptive field stimulation, or if it required visual stimulation or the receptive field to be established. Furthermore, we also could not determine whether the memory response was independent of the saccade used to establish it. To answer these questions, we used a modified version of the basic memory task, the No-RF task, in which the probe stimulus never appeared in the receptive field of the neuron and the monkey was required to make two different saccades on different trials (<xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.007</object-id><label>Figure 6.</label><caption><title>The No-RF task.</title><p>Trials occurred in blocks. The first block (block 1, baseline) was used to establish the baseline activity of the neuron for saccade 1, prior to introduction to the probe stimulus. Block 2 (mixed, form and recall memory) introduced a task-irrelevant probe stimulus in half of the trials. In the half of trials where the probe stimulus appeared, the monkey was instructed to make a different saccade (saccade 2), which relocated the cell’s receptive field away from the probe location (Block 2, orange). In the other half of trials, no probe stimulus was presented and the monkey made saccade 1, bringing the location of the (previously presented) probe stimulus into the cell’s receptive field (Block 2, magenta). In Block 3 (forget, identical to Block 1), to measure the decay of the memory response, the monkey was instructed to make saccade one and no probe was presented. Finally, in Block 4 (visual max), to measure the visual response of the cell to the probe, the monkey was instructed to make saccade 1, and the probe stimulus was presented in the cell’s receptive field.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig6-v2"/></fig><p>Trials in the first block of the No-RF task were identical to those in Block 1 of the basic memory task. In Block 1, the monkey made a visually guided saccade (saccade 1) to a target outside of the neuron’s receptive field and no probe stimulus appeared (<xref ref-type="fig" rid="fig6">Figure 6</xref>, Block 1). In Block 2, two trial types were pseudorandomly interleaved: no-probe trials identical to those in Block 1 (requiring saccade 1), and trials in which the probe stimulus appeared, but the monkey had to make a different saccade (saccade 2). In the latter trials, the probe stimulus appeared in the location corresponding the neuron’s receptive field after saccade 1. However, instead of making saccade 1, monkeys were instructed to make saccade 2, which relocated the neuron’s receptive field away from the probe stimulus location, thus preventing it from ever visually stimulating the cell. Block 3 was identical to Block 1, allowing us to measure the decay rate of the memory response. In Block 4, the monkey was instructed to make saccade one and the probe stimulus was presented in the receptive field, visually stimulating the cell. This enabled us to compare the memory and visual responses (<xref ref-type="fig" rid="fig6">Figure 6</xref>, block 4 and <xref ref-type="fig" rid="fig7">Figure 7</xref>, green trace), and ensure that we had not lost the neuron during Block 3 while we observed the memory response decay.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.008</object-id><label>Figure 7.</label><caption><title>Single-cell responses in the No-RF memory task: from Monkey A (left panel) and Monkeys C (right panel).</title><p>Block descriptions are as in <xref ref-type="fig" rid="fig6">Figure 6</xref>. Black traces and raster dots: activity in Block 1, stimulus absent. Red (broken) traces and raster dots: activity in stimulus-present trials in Block 2. Magenta traces and raster dots: activity in probe stimulus-absent trials in Block 2. The memory decays after many (up to 100) trials. Green traces and raster dots: activity in Block 4, 100% stimulus present. H and V are horizontal and vertical eye movements smoothed using a 10 ms sliding causal filter.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig7-v2"/></fig><p>We studied 44 neurons (30 in Monkey A, 14 in Monkey C) in the No-RF task, in which the stimulus never appeared in the cell’s receptive field before and during the establishment of the memory. Some LIP neurons have a brief postsaccadic response to eye movements in all directions, including those away from their receptive fields (Wang and Goldberg, in preparation). Therefore, rather than excluding neurons with postsaccadic responses, we included neurons with small postsaccadic responses that did not differ between blocks 1 (saccades that will, in block 2, bring the spatial location of the vanished stimulus into the receptive field, but in which no stimulus ever appeared on the screen) and block 2 (different saccades that brought the receptive field away from the stimulus whose memory is being established, Wilcoxon signed rank: Monkey A p-value=0.4; Monkey C p-value=0.3). Although the stimulus never appeared in the neuron’s receptive field, the cells responded when the saccade brought the spatial location of the vanished stimulus into the receptive field (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The population exhibited a robust memory response (<xref ref-type="fig" rid="fig8">Figure 8</xref>, poststimulus histogram for all cells we studied). The population histogram shows, for one monkey, a small postsaccadic burst in the stimulus appearing trials of block 2. One could argue, by looking at the postsaccadic response in the trials where the monkey made the saccade that brought the visual stimulus to a location outside of our estimate of the cell’s receptive field, that this postsaccadic response was a visual response. However, we saw the same postsaccadic response in block 1, where the monkey made a different saccade and no visual stimulus had ever appeared in the receptive field. Thus, the identical postsaccadic response in block two cannot be a visual response.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.009</object-id><label>Figure 8.</label><caption><title>Population responses in the No-RF memory task: from Monkey A (left panel) and Monkeys B and C (right panel).</title><p>Block descriptions are as in <xref ref-type="fig" rid="fig7">Figure 7</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig8-v2"/></fig><p>26% (8/30) of Monkey A neurons and 57% of monkey C neurons (8/14) exhibited environmental memory in the No-RF task. (<xref ref-type="fig" rid="fig7">Figure 7</xref> for a single cell and <xref ref-type="fig" rid="fig8">Figure 8</xref> for the entire population of cells that we studied). The neurons showed a significant difference (p&lt;0.05 by Wilcoxon rank sum) in the post saccadic response in Block 1 and the probe stimulus-absent trials in Block 2 (black traces and raster symbols versus magenta traces and raster symbols). They had a visual response in Block 4 when the saccade brought the stimulus into the receptive field. As in the basic task, this visual response was larger and had a longer shorter latency than the memory response. There was no significant difference in the postsaccadic responses in Block 1, when no stimulus appeared on the screen, and the memory forming trials in Block 2, when a stimulus appeared on the screen but did not appear in the receptive field of the neuron (<xref ref-type="fig" rid="fig7">Figure 7</xref>, for a single cell and <xref ref-type="fig" rid="fig8">Figure 8</xref> for the population of memory cells black traces and raster symbols) (Monkey A, p=0.4; Monkey C, p=0.3, Wilcoxon signed rank). Because the postsaccadic responses in Block 1 and the memory-forming trials in block to were not different, the much larger postsaccadic response in the memory trials of Block 2 could not have been a visual response.</p><p>Each population of neurons, including the statistically significant and the statistically non-significant neurons, taken as a whole, showed a statistically significant memory response (<xref ref-type="fig" rid="fig9">Figure 9a</xref>). The population showed a significant environmental memory response comparing the responses in Block 1 and the memory trials of Block 3 (Monkey A, p=0.006, Monkey B, p=0,007, Wilcoxon signed rank).</p><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.30762.010</object-id><label>Figure 9.</label><caption><title>Population data in the No-RF memory task: All recorded units (open circles and triangles) and units which showed significant differences between baseline and memory blocks (filled symbols, trial per trial peak comparisons, Wilcoxon signed rank, population p&lt;0.001, within-cell Wilcoxon rank sum &lt;0.05).</title><p>(<bold>A</bold>) Comparison of peak activity in the baseline and memory conditions (Block 1 vs Block 2, no probe stimulus trials). Each point represents a single cell. Cells with memory activity lie above the x = y line (diagonal). Monkey A: blue circles; Monkey C: red triangles. Insets: index (Block 2 versus Block 1) histograms for the whole population, out of which the statistically significant units are shown in shaded circles and triangles on the scatter plot. A median (numbers above index histograms) and rank sum and KS test confirmed memory activity as they both showed that the index distribution for the parent population was positively skewed. (<bold>B</bold>) Peak memory activity plotted against visual activity. Blue and red lines in the scatter plots are polynomial fits to each population data. They both indicate positive shift of neural responses towards memory activity. (<bold>C</bold>) Latency of memory response versus the latency of visual response for cells. (<bold>D</bold>) Normalized decay activity. Memory response gradually decays after the last trial in which the probe appeared. The regression lines are data fits using a first order exponential. As indicated in ‘D’ legend, open squares and triangles are neural activities during decay trials compared to (normalized by) the mean of the last five trials with the probe stimulus (left y-axis).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-30762-fig9-v2"/></fig><p>Similar to the basic memory task, the memory cells were not just the expected tail of a population distribution. The No-RF task population indices (mixed trials in Block 2 versus Block 1, <xref ref-type="fig" rid="fig9">Figure 9a</xref> inserts) were shifted to positive median values (median &gt;= 0.1 and medc of 0.2 for both monkeys; Wilcoxon signed rank p=2.3087e-08 for Monkey A; and 0.007 for Monkey C). Here also, leftward shift (increased slope vs identity line) of a polynomial fit line (red and blue lines in <xref ref-type="fig" rid="fig9">Figure 9a</xref>) signified positive skewness of the memory responses (compared to baseline).</p><p>As in the basic task, the larger visual response in Block 4 was larger than the memory response in Block 2 (Monkey A, p&lt;0.0001, Monkey C p=0.03 Wilcoxon signed rank). This shows that whatever decay we saw in Block 3 was not due to our losing the cell over this rather long experiment. The memory response had a longer latency than the neuron’s visual response (<xref ref-type="fig" rid="fig9">Figure 9c</xref>) (Wilcoxon signed rank p=0.008 for Monkey A, and 0.006 for Monkey C; mean visual/memory latency: 39/101 ms for Monkey A, 25/106 ms for Monkey C).</p><p>As with data from the basic memory task, the normalized decay activity of the population (<xref ref-type="fig" rid="fig9">Figure 9d</xref>) could be fit to a first-order exponential. Monkey A had a decay rate constant of 0.09 trials and R<sup>2</sup> of −0.06; Monkey C, decay 0.07 trials, R<sup>2</sup> = 0.12. Significant p-values were found using a Wilcoxon signed rank test between trial mean comparisons of the first and the last 10 trials in the 50-trial decay epoch considered (Wilcoxon signed rank for Monkey A: p=0.0002, p=0.01 for Monkey C). The negative R<sup>2</sup> in Monkey A demonstrates the slowness of the decay and that a first-order exponential is not the best fit (it caused non-optimal line fit). This fit is used in the figures for consistency and visual clarity.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this set of experiments, we demonstrate that LIP neurons exhibit an environmental memory signal, which lasts over a duration of multiple trials, decays slowly, and updates with eye movements. In addition, we demonstrate that a neuron does not require visual stimulation or a particular training saccade to establish memory activity. There is a similar signal in the frontal eye field (<xref ref-type="bibr" rid="bib35">Umeno and Goldberg, 2001</xref>), in visual and visuomovement cells, but not movement cells. Those preliminary experiments, however, had two confounds. First, the memory was always established by stimulating the receptive field. Second, the saccade that evoked the memory was identical to the saccade used to establish it, so the memory could have been related to the saccadic process. In our experiments, we show that memory can be evoked by a stimulus that never appeared in the neuron’s receptive field, and that the memory response manifested even when the saccade used to evoke it differed from the saccade used to establish it. Furthermore, as in the FEF (<xref ref-type="bibr" rid="bib35">Umeno and Goldberg, 2001</xref>), memory activity occurred both in neurons which did exhibit saccadic remapping as well as those that did not. In sum, these results suggest that LIP has access to a supraretinal representation of the visual world despite the fact that all of its explicit responses are retinotopic, and that this memory response cannot be simply ascribed to saccadic remapping or saccade planning.</p><p>Our results can explain previous clinical observations regarding the role of parietal cortex in spatial memory. Patients with bilateral parietal lesions cannot point to an object in their room with their eyes closed, although they can easily do it with their eyes open (<xref ref-type="bibr" rid="bib22">Levine et al., 1985</xref>). This suggests that these patients do not have access to a remembered spatial representation of their environment. More importantly, patients with right parietal lesions report their spatial memory in a retinotopic frame. <xref ref-type="bibr" rid="bib4">Bisiach and Luzzatti (1978)</xref> asked two Milanese patients with right parietal damage to describe their memory of the Piazza del Duomo in Milan. They found that these patients could only describe the recalled environmental landmarks that would fall in their unaffected (right) hemifield, which depended on their (imagined) vantage point. For example, when they described Piazza del Duomo as if they were standing with their back to the cathedral they remembered only the landmarks to the right of the cathedral. However, when they described the Piazza del Duomo as if they were facing the cathedral they only remembered the landmarks on the other side of the square, which were now to the right of their imagined vantage point. This experiment demonstrates two key ideas; (1) The brain stores long-term memory of environments in supraretinal coordinates in an area unaffected by a parietal lesion, since the patients could, under certain circumstances, remember the entire Piazza del Duomo. (2) Retrieving that memory requires the parietal cortex, but the right parietal patients could only report (and therefore mentally represent) objects on the right side of their imagined vantage point. They had a mnemonic left hemianopia for a remembered environment. If their memory were reportable in a supraretinal frame they should have been able to report the entire scene. Because they could not do so, and could only report objects in the non-neglected hemifield, the report of their environmental memory must be processed by the retinotopic map of the parietal cortex. Our results are consistent with this result. The memory of an environment can be stored a supraretinal frame, but must be reported by neurons with retinotopic receptive fields. The neurons that we have reported here fit that description. They have access to a supraretinal representation of the visual field, because environmental memory does not require stimulating their receptive fields, but they only report that memory when the spatial location of the remembered stimuli lies in their receptive field.</p><p>The memory response has both a longer latency and a lesser intensity than a simple reafferent visual response. This suggests that it does not arise from a feedforward mechanism, just as task-related pattern selectivity in V4 requires a late, presumably feedback, mechanism (<xref ref-type="bibr" rid="bib15">Ipata et al., 2012</xref>). There are two known mechanisms by which LIP can create a spatially accurate representation of space despite a constantly moving eye. The first is through remapping, in which a neuron will respond immediately after a saccade brings the spatial location of a recently vanished stimulus into its receptive field (<xref ref-type="bibr" rid="bib10">Duhamel et al., 1991</xref>; <xref ref-type="bibr" rid="bib33">Sun and Goldberg, 2016</xref>). This effectively changes the spatial origin of the retinotopic coordinate system from the presaccadic fixation point to the saccade target. The next saccade could just as easily remap the current retinotopic representation into a coordinate system centered on the next saccade target, and so on, through a number of saccades. This is unlikely to be the basis of our results, however, because many cells that show environmental memory do not show pre-saccadic remapping when a saccade brings a stimulus into its receptive field.</p><p>The second mechanism creates a spatially accurate retinotopic representation from a supraretinal representation. There is excellent human psychophysical evidence that the saccadic system has access to a supraretinal representation of space that does not involve remapping. <xref ref-type="bibr" rid="bib21">Karn et al. (1997)</xref> showed that there is little difference in the inaccuracy of memory-guided saccades after two or six intervening visually-guided saccades. Reliance on a remapping mechanism for accuracy would entail the concatenation of errors from saccade to saccade, whereas access to a supraretinal coordinate frame would enable a more stable representation of space across multiple saccades. In a similar experiment, <xref ref-type="bibr" rid="bib28">Poletti et al. (2013)</xref> asked humans to make different numbers of intervening saccades between the presentation of a target for a memory-guided saccade and executing the actual saccade. For the first few intervening saccades, the variability of the memory-guided saccade increased linearly, as expected if the error of each remapping process would concatenate. However, after the first few saccades, the increase in variability decreased with each subsequent saccade, as if the representation of the saccade target had shifted to a supraretinal frame which would not increase its error with each saccade. To explain this phenomenon, they proposed a model that entails a shift from an early remapping mechanisms to a subsequent supraretinal mechanism. This late supraretinal representation could arise from a gain-field mechanism. Visual responses in LIP are linearly modulated by the position of the eye in the orbit, the gain field. The eye position signal that modulates the gain fields in LIP could come from the representation of eye position in area 3a (<xref ref-type="bibr" rid="bib39">Zhang et al., 2008</xref>). It is mathematically trivial to calculate target position in supraretinal coordinates from retinotopic gain fields (<xref ref-type="bibr" rid="bib40">Zipser and Andersen, 1988</xref>; <xref ref-type="bibr" rid="bib32">Salinas and Abbott, 1997</xref>; <xref ref-type="bibr" rid="bib29">Pouget and Sejnowski, 1994</xref>). Although gain fields are inaccurate immediately after a saccade (<xref ref-type="bibr" rid="bib37">Xu et al., 2012</xref>), they could contribute to a late, accurate, supraretinal representation that develops when the eye position signal is accurate, as one would expect if the eye position signal arose from proprioception. The neurons that we studied did not have eye position modulation of their visual responses – such neurons often have a phasic and tonic postsaccadic response that arises from the eye position signal itself (Wang et al.). Indeed, because the memory of the stimulus was established well before the saccade that evoked the memory, the supraretinal representation of the remembered stimulus could easily be implicitly encoded in the gain-field responses of LIP neurons (<xref ref-type="bibr" rid="bib40">Zipser and Andersen, 1988</xref>).</p><p>Data from patients with parietal lesions, such as the previously described results from Bisiach and Luzzatti, suggest that although LIP might calculate target position in retinotopic coordinates, the parietal cortex does not store the results of that calculation. Instead, a supraretinal representation of space could be stored elsewhere, possibly in the medial temporal lobe. O’Keefe discovered that neurons in the rat hippocampus (the ‘place cells’) discharge when rats enter spatial location that they have seen before (<xref ref-type="bibr" rid="bib24">O'Keefe and Dostrovsky, 1971</xref>). Other studies have duplicated this result in the monkey hippocampus (<xref ref-type="bibr" rid="bib25">Ono et al., 1993</xref>; <xref ref-type="bibr" rid="bib30">Rolls et al., 1989</xref>). Grid cells in entorhinal cortex are thought to be the precursors of hippocampal place cells (<xref ref-type="bibr" rid="bib23">Moser et al., 2008</xref>) and these have been found in the monkey (<xref ref-type="bibr" rid="bib7">Buffalo, 2015</xref>) as well as in humans (<xref ref-type="bibr" rid="bib16">Jacobs et al., 2013</xref>). It is known that there is a direct, reciprocal connection between the parahippocampal gyrus and LIP (<xref ref-type="bibr" rid="bib34">Suzuki and Amaral, 1994</xref>; <xref ref-type="bibr" rid="bib2">Baizer et al., 1991</xref>). Thus, LIP could send an eye-position modulated visual signal to the medial temporal lobe, which could serve as a building block for a supraretinal memory. The medial temporal lobe could then use this activity to generate the supraretinal component of place cell activity and send this supraretinal signal back to LIP. LIP itself would only be activated when the spatial location of the vanished stimulus can be described by a retinotopic vector from the center of gaze to the receptive field of the neuron. Thus, LIP has access to a supraretinal representation, but expresses only a retinotopic representation. It is important to emphasize that LIP is part of a spatial network that includes the FEF and the superior colliculus. Although neuropsychological studies suggest that parietal damage affects spatial memory, we do not know if damage to other parts of the network has a similar effect.</p><p>Although early models posited that the oculomotor system uses a supraretinal representation (<xref ref-type="bibr" rid="bib38">Zee et al., 1976</xref>), it is clear that the parietal cortex sends a spatially accurate retinotopic signal to the oculomotor (<xref ref-type="bibr" rid="bib26">Pare and Wurtz, 1997</xref>) and skeletomotor (<xref ref-type="bibr" rid="bib3">Batista et al., 1999</xref>) systems. Even auditory stimuli, which are initially coded in craniotopic coordinates, are converted to retinotopic coordinates for the oculomotor (<xref ref-type="bibr" rid="bib19">Jay and Sparks, 1987b</xref>; <xref ref-type="bibr" rid="bib18">Jay and Sparks, 1987a</xref>) and skeletal motor system (<xref ref-type="bibr" rid="bib12">Grunewald et al., 1999</xref>; <xref ref-type="bibr" rid="bib8">Cohen and Andersen, 2000</xref>) in parietal cortex, and the oculomotor system of the superior colliculus (<xref ref-type="bibr" rid="bib17">Jay and Sparks, 1984</xref>). We suggest that the environmental memory signal in LIP is an example of the conversion of a supraretinal signal to a retinotopic signal for memory and spatial attention as well as for motor control.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>The Animal Care and Use Committees at Columbia University and the New York State Psychiatric Institute approved all of the animal protocols in this study as complying with the guidelines established in the United States Public Health Service Guide for the Care and Use of Laboratory Animals (protocol NYSPI-1225-C). We used one female and two male rhesus monkeys (Macaca mulatta) with weights between 6 and 13 kg.</p><p>We first trained monkeys to sit in a primate chair using a pole and collar technique. After chair training, we surgically fitted the monkeys with acrylic implants, anchored with titanium or ceramic screws, outfitted with a headpost which stabilized the monkeys head while sitting in a primate chair. During the same surgery, we implanted scleral search coils around both eyes (<xref ref-type="bibr" rid="bib20">Judge et al., 1980</xref>) and brought the coil wire out to a plug on the acrylic. After basic behavioral training, we performed a craniotomy to expose the intraparietal sulcus (using coordinates determined from a structural MRI), over which we affixed a recording chamber in the acrylic.</p><p>We located the actual recording sites in each monkey by performing MRIs with the recording electrode in place (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). We tranquilized the monkey in the vivarium with ketamine and atropine for transport to the MRI lab. We then anesthetized the monkey using endotracheal isoflurane, and positioned it in a Kopf MRI-compatible stereotaxic instrument. To create the images, we used a custom-made rigid and flexible RF array coils using GE MR750(3T) and GE Signa(1.5 T) scanners. We used custom Matlab software, Osirix, GE’s MediaViewer, and DicomWorks to analyze the data.</p><p>We performed all surgeries using ketamine/isoflurane general anesthesia using aseptic surgical technique. The monkey recovered fully before testing restarted. During testing, monkeys worked for their daily water intake and were supplemented with dried and fresh fruits. We monitored monkeys’ weights and general health on every recording day, and at least once a week.</p><p>We controlled all experiments using the REX (downloadable from: <ext-link ext-link-type="uri" xlink:href="https://nei.nih.gov/intramural/software">https://nei.nih.gov/intramural/software</ext-link>) system (<xref ref-type="bibr" rid="bib13">Hays et al., 1982</xref>) and recorded single-unit activity with glass-insulated tungsten electrodes introduced through a guide tube positioned plastic grid with 1 mm spacing between possible penetrations (<xref ref-type="bibr" rid="bib9">Crist et al., 1988</xref>). In general, recording sessions lasted between 5 and 8 hr depending on the stability of the cell and the monkey’s willingness to continue to work. We took care to avoid making penetrations with the electrode in adjacent grid holes from the previous day’s penetration in order to reduce tissue damage. We kept careful logs regarding the location and depth of each penetration, an estimate describing cell types encountered, and the quality of the monkey’s behavior. During every testing and training session, we monitored monkeys using a closed-circuit camera and monitor.</p><p>We verified stimulus timing using a photoprobe affixed to the screen, which emitted a pulse for each event. We monitored the monkey’s eye movements using a CNC phase detector (Crist Instruments, Hagerstown, MD) to decode the search coil signal (<xref ref-type="bibr" rid="bib20">Judge et al., 1980</xref>) and sampled the signal at 1 kHz. During testing, monkeys sat in a primate chair in a sound-attenuated Faraday room. We performed these experiments in two experimental setups. In one set up, the monkeys sat 57 cm away from a CRT monitor (ViewSonic Professional Series P225F) with a refresh rate of 120 Hz. In the second setup, we presented stimuli with a Hitachi CPX275 LCD projector with a refresh rate of 60 Hz, on a screen 72 cm from the monkey.</p><p>Once we isolated an LIP neuron and confirmed that it displayed canonical visual, delay, and perisaccadic responses, we probed the boundaries of LIP neuron receptive fields by having monkeys make memory-guided saccades (<xref ref-type="bibr" rid="bib14">Hikosaka and Wurtz, 1983</xref>) to targets appearing in locations which were inside and outside of the cell’s receptive field. In some cases, we used a fixation task to characterize the cell’s receptive field by having the monkey fixate a point while stimuli briefly flashed (50 ms) pseudo-randomly on the screen, generating a map of locations that evoked visual responses (measured 50–150 ms after the flash). We ensured that saccade target and probe stimuli locations were positioned correctly with respect to future and current receptive field locations to avoid unintentional contamination by a visual response.</p><p>We transformed the REX data into a form analyzable by MATLAB (MathWorks, Natick, MA) using the REXTOOLS software (downloadable from <ext-link ext-link-type="uri" xlink:href="https://nei.nih.gov/intramural/software">https://nei.nih.gov/intramural/software</ext-link>). Although the REX system provides an estimate of activity using the MEX (downloadable from <ext-link ext-link-type="uri" xlink:href="https://nei.nih.gov/intramural/software">https://nei.nih.gov/intramural/software</ext-link>) spike sorter, for the analyses in this paper we used the MEX system to digitize the neural data and sorted the spikes offline using the MEX offline analysis program. The custom codes, and raw data from every cell analyzed in this paper are provided as. m, and. csv files.</p><p>Before performing detailed statistical analysis, we first investigated if the data came from standard normal distributions, using two-sample Kolmogorov-Smirnov (KS) test. When we tested the mean neural activity in the response windows (intervals described below), all of our data sets were found to be distributed non-normally (non-parametric).</p><p>To show that the statistically significant cells in both experiments were not just one side of a symmetric distribution we calculated a memory index to quantify the degree to which each cell manifested memory activity, comparing postsaccadic activity in Block 1 (R<sub>pre</sub>) with postsaccadic activity in Block 3 (R<sub>mem</sub>):<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>All index distributions were not normally distributed (by KS test), and we showed that the population median was significantly different from zero by using median values for the distribution of the memory indices and a Wilcoxon signed rank test to compare each sample with a test sample identical to the measured sample with the measured mean subtracted from each value. In addition, we calculated medcouple, a non-parametric histogram skewness measure (<xref ref-type="bibr" rid="bib6">Brys et al., 2004</xref>). This tool is not affected by unsymmetrical tails and outliers, and is also not based on classical skewness represented by the third moment. Since this measure does not depend on mean or standard deviation, it gives an accurate description of a skewed distribution. Its results are bound between values: −1 (left skewed), 0 (symmetric), and 1 (right skewed).</p><p>All cells reported here had both statistically significant visual and memory responses (Wilcoxon signed rank p-value for median activity between baseline and response window &lt;0.001) (<xref ref-type="bibr" rid="bib36">Whitley and Ball, 2002</xref>). We have excluded units with memory activity if median activity in Block 1 (baseline recording block) pre- and post-saccadic were statistically different (indicating eye-position modulation). In other words, even if we could find significant memory activity well beyond what can be described by either eye position or saccadic activity effect, we are not presenting them here.</p><p>To quantify the magnitude of the memory and visual responses, we did a comparison of the peristimulus time histograms (PSTHs) during baseline, visual, and memory trials, for identical epochs aligned on saccade onset. All PSTHs were normalized to baseline activity (block 1) and were constructed from 2 ms spike bins, smoothed using a 10 ms sliding causal filter. Baseline calculations were made in the −426 to −226 ms (pre-saccade onset) window. To quantify the decay, perisaccadic memory and visual responses, we selected the time point of peak activity in the window from 125 ms before the saccade onset (to include any predictive remapping) to 500 ms after. We then looked at the median of raw spike count over a window extending 100 ms before and after this point to calculate response latencies, as described next.</p><p>To obtain a latency value of the memory response, we used a median threshold-crossing and sustained response method. In short, this analysis compared the median activity in the baseline and response windows. We derived a ‘cut off’ value by determining the spike count values which would fall above at least the 75% percentile of the baseline median. By comparing the median spike counts in the response window to this ‘cut off’ value, we could determine when a minimum of five bins (of 2 ms each) contained a greater spike count than the ‘cut off’ value. We took the first of these bins as the response latency, and verified visually by looking at the corresponding time on the PSTH. Since the baseline activity can vary between different trials in the same experiment, we first chose a window within the time from fixation to −226 ms before saccade onset. Within this wide window, we made 200 ms wide sliding windows, in 1 ms steps. By finding the median spike count within these smaller windows, we picked the window closest to the start of the response window (but still had the same median as the population of these several 200 ms wide windows). This median was chosen to look at the response window in which a threshold crossing for at least 20 ms was picked as the response latency.</p><p>We could not calculate latencies for a few neurons using this method, because the baseline (pre-saccadic) memory block response was as high as post-saccadic activity. There were also a few other units whose latencies were automatically picked by the aforementioned median method but a more precise time point could be picked by doing yet another median-based analysis. For these units, we implemented Wilcoxon rank sum comparison with the baseline median and a sliding 50 ms window, stepped 1 ms, in the response epoch. The first such 20 ms window, where there was a statistical difference was observed was picked as the latency point.</p><p>We observed that the memory response continued to manifest for almost up to 100 trials after the last probe stimulus trial, and so we analyzed the ‘forgetting’ or ‘decay trials’. While individual cell results were noisy and there were differences between cells, we normalized each cell’s decay activity to its peak memory activity and fit the population data to a first order exponential (shown in figures) and quantified it using comparisons of the first and last 10-trials in a 50-trial epoch. We fit the population data similarly.</p></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank, Moshe Shalev and Girma Asfaw for veterinary care, Yana Pavlova and Vincent Sanchez for technical assistance, John Caban and Matthew Hasday for machining, Glen Duncan for electronic and computer assistance, and Latoya Palmer, Cherise Washington, and Lisa Kennelly for facilitating everything. This research was supported, in part, by grants from the Keck, Gatsby, Kavli, Zegar, and Dana Foundations and the National Eye Institute (R24 EY-015634, R21 EY-017938, R21 EY-020631, R01 EY-017039, P30 EY-019007, and R01 EY-014978 to MG, principal investigator; SS was also supported by training grant T32-EY-13933. MS was supported by NINDS training grant from 2T32MH015174-35, Brain and Behavior Research Foundation (NARSAD) 2013 Young Investigator Award.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: The Animal Care and Use Committees at Columbia University and the New York State Psychiatric Institute approved all of the animal protocols in this study as complying with the guidelines established in the United States Public Health Service Guide for the Care and Use of Laboratory Animals. protocol NYSPI-1225-C</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.30762.011</object-id><label>Source Code 1.</label><caption><title>All Matlab Scripts for data analysis and preparation</title><p>The zip file contains all Matlab scripts used in converting raw spike and analog data from NIH’s REX files to Matlab, analyzing neural activities such as firing rates, decay activities etc. and creating spreadsheets and figures.</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-30762-code1-v2.zip"/></supplementary-material><supplementary-material id="sdata1"><object-id pub-id-type="doi">10.7554/eLife.30762.012</object-id><label>Source data 1.</label><caption><title>Table describing response attributes for all neurons included in the analyzed population</title><p>The table provides all measured response attributes for the neurons which showed statistically significant memory activity. The first row (headers) contains the particular measure used to quantify activity such as mean, median, etc. It also includes other descriptors such as, the file name, block type, p-values for various comparisons, etc.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-30762-data1-v2.csv"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.30762.013</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-30762-transrepform-v2.pdf"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Snyder</surname> <given-names>LH</given-names></name><name><surname>Batista</surname> <given-names>AP</given-names></name><name><surname>Buneo</surname> <given-names>CA</given-names></name><name><surname>Cohen</surname> <given-names>YE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Posterior parietal areas specialized for eye movements (LIP) and reach (PRR) using a common coordinate frame</article-title><source>Novartis Foundation Symposium</source><volume>218</volume><fpage>109</fpage><lpage>122</lpage><pub-id pub-id-type="pmid">9949818</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baizer</surname> <given-names>JS</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Organization of visual inputs to the inferior temporal and posterior parietal cortex in macaques</article-title><source>Journal of Neuroscience</source><volume>11</volume><fpage>168</fpage><lpage>190</lpage><pub-id pub-id-type="pmid">1702462</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batista</surname> <given-names>AP</given-names></name><name><surname>Buneo</surname> <given-names>CA</given-names></name><name><surname>Snyder</surname> <given-names>LH</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Reach plans in eye-centered coordinates</article-title><source>Science</source><volume>285</volume><fpage>257</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1126/science.285.5425.257</pub-id><pub-id pub-id-type="pmid">10398603</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisiach</surname> <given-names>E</given-names></name><name><surname>Luzzatti</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Unilateral neglect of representational space</article-title><source>Cortex</source><volume>14</volume><fpage>129</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/S0010-9452(78)80016-1</pub-id><pub-id pub-id-type="pmid">16295118</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisley</surname> <given-names>JW</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Attention, intention, and priority in the parietal lobe</article-title><source>Annual Review of Neuroscience</source><volume>33</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-060909-152823</pub-id><pub-id pub-id-type="pmid">20192813</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brys</surname> <given-names>G</given-names></name><name><surname>Hubert</surname> <given-names>M</given-names></name><name><surname>Struyf</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A robust measure of skewness</article-title><source>Journal of Computational and Graphical Statistics</source><volume>13</volume><fpage>996</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1198/106186004X12632</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buffalo</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Bridging the gap between spatial and mnemonic views of the hippocampal formation</article-title><source>Hippocampus</source><volume>25</volume><fpage>713</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.1002/hipo.22444</pub-id><pub-id pub-id-type="pmid">25787704</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>YE</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Reaches to sounds encoded in an eye-centered reference frame</article-title><source>Neuron</source><volume>27</volume><fpage>647</fpage><lpage>652</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)00073-8</pub-id><pub-id pub-id-type="pmid">11055445</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crist</surname> <given-names>CF</given-names></name><name><surname>Yamasaki</surname> <given-names>DS</given-names></name><name><surname>Komatsu</surname> <given-names>H</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A grid system and a microsyringe for single cell recording</article-title><source>Journal of Neuroscience Methods</source><volume>26</volume><fpage>117</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/0165-0270(88)90160-4</pub-id><pub-id pub-id-type="pmid">3146006</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duhamel</surname> <given-names>J-R</given-names></name><name><surname>Colby</surname> <given-names>CL</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Neurons in the lateral intraparietal area of the monkey remap visual space in conjunction with saccadic eye movements. I. Presaccadic events</article-title><source>Soc. Neurosci. Abs</source><volume>17</volume><fpage>1282</fpage></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duhamel</surname> <given-names>JR</given-names></name><name><surname>Colby</surname> <given-names>CL</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The updating of the representation of visual space in parietal cortex by intended eye movements</article-title><source>Science</source><volume>255</volume><fpage>90</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1126/science.1553535</pub-id><pub-id pub-id-type="pmid">1553535</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grunewald</surname> <given-names>A</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Responses to auditory stimuli in macaque lateral intraparietal area. I. Effects of training</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>330</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.1.330</pub-id><pub-id pub-id-type="pmid">10400962</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hays</surname> <given-names>AV</given-names></name><name><surname>Richmond</surname> <given-names>BJ</given-names></name><name><surname>Optican</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>A UNIX- based multiple process system for real-time data acquisition and control</article-title><conf-name>Conf Proc</conf-name><publisher-loc>Anaheim, Ca</publisher-loc></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hikosaka</surname> <given-names>O</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Visual and oculomotor functions of monkey substantia nigra pars reticulata. III. Memory-contingent visual and saccade responses</article-title><source>Journal of Neurophysiology</source><volume>49</volume><fpage>1268</fpage><lpage>1284</lpage><pub-id pub-id-type="doi">10.1152/jn.1983.49.5.1268</pub-id><pub-id pub-id-type="pmid">6864250</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ipata</surname> <given-names>AE</given-names></name><name><surname>Gee</surname> <given-names>AL</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Feature attention evokes task-specific pattern selectivity in V4 neurons</article-title><source>Proceedings of the National Academy of Sciences</source><volume>109</volume><fpage>16778</fpage><lpage>16785</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215402109</pub-id><pub-id pub-id-type="pmid">23043119</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname> <given-names>J</given-names></name><name><surname>Weidemann</surname> <given-names>CT</given-names></name><name><surname>Miller</surname> <given-names>JF</given-names></name><name><surname>Solway</surname> <given-names>A</given-names></name><name><surname>Burke</surname> <given-names>JF</given-names></name><name><surname>Wei</surname> <given-names>XX</given-names></name><name><surname>Suthana</surname> <given-names>N</given-names></name><name><surname>Sperling</surname> <given-names>MR</given-names></name><name><surname>Sharan</surname> <given-names>AD</given-names></name><name><surname>Fried</surname> <given-names>I</given-names></name><name><surname>Kahana</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Direct recordings of grid-like neuronal activity in human spatial navigation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1188</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1038/nn.3466</pub-id><pub-id pub-id-type="pmid">23912946</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jay</surname> <given-names>MF</given-names></name><name><surname>Sparks</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Auditory receptive fields in primate superior colliculus shift with changes in eye position</article-title><source>Nature</source><volume>309</volume><fpage>345</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1038/309345a0</pub-id><pub-id pub-id-type="pmid">6727988</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jay</surname> <given-names>MF</given-names></name><name><surname>Sparks</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1987">1987a</year><article-title>Sensorimotor integration in the primate superior colliculus. I. Motor convergence</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>22</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.1.22</pub-id><pub-id pub-id-type="pmid">3559673</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jay</surname> <given-names>MF</given-names></name><name><surname>Sparks</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1987">1987b</year><article-title>Sensorimotor integration in the primate superior colliculus. II. Coordinates of auditory signals</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>35</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.1.35</pub-id><pub-id pub-id-type="pmid">3559680</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Judge</surname> <given-names>SJ</given-names></name><name><surname>Richmond</surname> <given-names>BJ</given-names></name><name><surname>Chu</surname> <given-names>FC</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Implantation of magnetic search coils for measurement of eye position: an improved method</article-title><source>Vision Research</source><volume>20</volume><fpage>535</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(80)90128-5</pub-id><pub-id pub-id-type="pmid">6776685</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karn</surname> <given-names>KS</given-names></name><name><surname>Møller</surname> <given-names>P</given-names></name><name><surname>Hayhoe</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Reference frames in saccadic targeting</article-title><source>Experimental Brain Research</source><volume>115</volume><fpage>267</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1007/PL00005696</pub-id><pub-id pub-id-type="pmid">9224855</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname> <given-names>DN</given-names></name><name><surname>Warach</surname> <given-names>J</given-names></name><name><surname>Farah</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Two visual systems in mental imagery: dissociation of &quot;what&quot; and &quot;where&quot; in imagery disorders due to bilateral posterior cerebral lesions</article-title><source>Neurology</source><volume>35</volume><fpage>1010</fpage><pub-id pub-id-type="doi">10.1212/WNL.35.7.1010</pub-id><pub-id pub-id-type="pmid">4010939</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Place cells, grid cells, and the brain's spatial representation system</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>69</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id><pub-id pub-id-type="pmid">18284371</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Dostrovsky</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ono</surname> <given-names>T</given-names></name><name><surname>Nakamura</surname> <given-names>K</given-names></name><name><surname>Nishijo</surname> <given-names>H</given-names></name><name><surname>Eifuku</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Monkey hippocampal neurons related to spatial and nonspatial functions</article-title><source>Journal of Neurophysiology</source><volume>70</volume><fpage>1516</fpage><lpage>1529</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.70.4.1516</pub-id><pub-id pub-id-type="pmid">8283212</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pare</surname> <given-names>M</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Monkey posterior parietal cortex neurons antidromically activated from superior colliculus Modulation of neuronal activity by target uncertainty Shared motor error for multiple eye movements</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>3493</fpage><lpage>3497</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.78.6.3493</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paxinos</surname> <given-names>G</given-names></name><name><surname>Huang</surname> <given-names>X-F</given-names></name><name><surname>Toga</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>The Rhesus Monkey Brain in Stereotaxic Coordinates</source><publisher-loc>New York</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poletti</surname> <given-names>M</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name><name><surname>Rucci</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Optimal multimodal integration in spatial localization</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>14259</fpage><lpage>14268</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0523-13.2013</pub-id><pub-id pub-id-type="pmid">23986259</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname> <given-names>A</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>A neural model of the cortical representation of egocentric distance</article-title><source>Cerebral Cortex</source><volume>4</volume><fpage>314</fpage><lpage>329</lpage><pub-id pub-id-type="doi">10.1093/cercor/4.3.314</pub-id><pub-id pub-id-type="pmid">8075535</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname> <given-names>ET</given-names></name><name><surname>Miyashita</surname> <given-names>Y</given-names></name><name><surname>Cahusac</surname> <given-names>PM</given-names></name><name><surname>Kesner</surname> <given-names>RP</given-names></name><name><surname>Niki</surname> <given-names>H</given-names></name><name><surname>Feigenbaum</surname> <given-names>JD</given-names></name><name><surname>Bach</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Hippocampal neurons in the monkey with activity related to the place in which a stimulus is shown</article-title><source>Journal of Neuroscience</source><volume>9</volume><fpage>1835</fpage><lpage>1845</lpage><pub-id pub-id-type="pmid">2723752</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Saleem</surname> <given-names>KS</given-names></name></person-group><person-group person-group-type="author"><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>A Combined MRI and Histology Atlas of the Rhesus Monkey Brain in Stereotaxic Coordinates</source><edition>2nd Edition</edition><publisher-loc>San Diego</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname> <given-names>E</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Invariant visual responses from attentional gain fields</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>3267</fpage><lpage>3272</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.6.3267</pub-id><pub-id pub-id-type="pmid">9212273</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname> <given-names>LD</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Corollary discharge and oculomotor proprioception: cortical mechanisms for spatially accurate vision</article-title><source>Annual Review of Vision Science</source><volume>2</volume><fpage>61</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-082114-035407</pub-id><pub-id pub-id-type="pmid">28532350</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname> <given-names>WA</given-names></name><name><surname>Amaral</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Perirhinal and parahippocampal cortices of the macaque monkey: cortical afferents</article-title><source>The Journal of Comparative Neurology</source><volume>350</volume><fpage>497</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1002/cne.903500402</pub-id><pub-id pub-id-type="pmid">7890828</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umeno</surname> <given-names>MM</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spatial processing in the monkey frontal eye field. II. Memory responses</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>2344</fpage><lpage>2352</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.5.2344</pub-id><pub-id pub-id-type="pmid">11698524</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitley</surname> <given-names>E</given-names></name><name><surname>Ball</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Statistics review 6: Nonparametric methods</article-title><source>Critical Care</source><volume>6</volume><fpage>509</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1186/cc1820</pub-id><pub-id pub-id-type="pmid">12493072</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>BY</given-names></name><name><surname>Karachi</surname> <given-names>C</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The postsaccadic unreliability of gain fields renders it unlikely that the motor system can use them to calculate target position in space</article-title><source>Neuron</source><volume>76</volume><fpage>1201</fpage><lpage>1209</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.034</pub-id><pub-id pub-id-type="pmid">23259954</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zee</surname> <given-names>DS</given-names></name><name><surname>Optican</surname> <given-names>LM</given-names></name><name><surname>Cook</surname> <given-names>JD</given-names></name><name><surname>Robinson</surname> <given-names>DA</given-names></name><name><surname>Engel</surname> <given-names>WK</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Slow saccades in spinocerebellar degeneration</article-title><source>Archives of Neurology</source><volume>33</volume><fpage>243</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1001/archneur.1976.00500040027004</pub-id><pub-id pub-id-type="pmid">1083233</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Monkey primary somatosensory cortex has a proprioceptive representation of eye position</article-title><source>Progress in Brain Research</source><volume>171</volume><fpage>37</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(08)00606-7</pub-id><pub-id pub-id-type="pmid">18718280</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zipser</surname> <given-names>D</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons</article-title><source>Nature</source><volume>331</volume><fpage>679</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1038/331679a0</pub-id><pub-id pub-id-type="pmid">3344044</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.30762.015</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Reviewing Editor</role><aff id="aff9"><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;A spatial memory signal shows that the parietal cortex has access to a craniotopic representation of space&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors and the evaluation has been overseen by Sabine Kastner as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study examined the ability of neurons in area LIP of monkeys to encode the memorized location of visual stimuli. The basic result is similar to previous findings from the senior author showing that visually responsive neurons in the frontal eye field (FEF) can respond to manipulations that relate to &quot;environmental memory&quot; (Umeno and Goldberg, 2001). Specifically, the neurons respond to the remembered location of a previously presented visual probe following a saccadic eye movement that aligns a given neuron's spatial receptive field to the probe location, even when the probe is now absent. However, here the authors note that the task design from the previous study made it impossible to determine if &quot;the effect is a true spatial memory or a merely a memory of receptive field stimulation by a saccade.&quot; They therefore use new task designs, including one that dissociates saccade vectors and probe stimulation location, to distinguish these alternatives. They also focus on a different brain area (LIP vs. FEF).</p><p>The reviewers had much to praise about this study, including its clever tasks that improve upon the design of the earlier study, interesting and novel results, and a thorough discussion. However, the enthusiasm of all three reviewers for this study and its potential impact were substantially limited by several major concerns, detailed below.</p><p>Essential revisions:</p><p>1) By far the biggest concern is that the data are in many cases not presented in a manner that allows them to be evaluated effectively. Other than an initial pair of PSTH and raster plots for example responses from Task 1, the remaining results are presented primarily using scatter plots, which does not give any sense of the time course of neural responses in the context of fairly involved sensory/memory/motor sequences. Among the issues raised that should be addressed are:</p><p>a) Show time courses of responses for all three tasks, for single neurons and population averages. These plots could help to show, for example, whether there were any visually evoked responses in Task 2, Block 2; what is the time course of the responses relative to the saccade, and when the &quot;peak activity in the baseline and memory blocks of trials&quot; occurred in Task 3.</p><p>b) Account for some very high spike rates – some were as high as 400+ sp/sec. Could this reflect multi-unit activity?</p><p>c) A better justification for using the medc metric, as opposed to more straightforward tests comparing distributions.</p><p>2) Much of the data from this paper comes from a single monkey, leading to two issues. First, tasks 1 and 2 have data from two other monkeys that appropriately and effectively confirm the more extensive results from the first monkey. However, it is unusual to treat data from monkey B and C as if from a single monkey. At the very least, it would be useful to use different symbols for the two monkeys (e.g., red triangle &amp; red square) in the scatterplots, to demonstrate that the results are similar for the two. Second, results from Task 3 are only from one monkey, which does not meet the acknowledged standard in this field. It therefore is important to make it clear that this is an unconfirmed, preliminary finding that is not critical to the overall message of the study. Alternatively, confirmatory data from a second monkey is needed.</p><p>3) The writing and figures should be revised carefully for clarity. For example, in the current manuscript it is difficult to understand the details of the tasks, in particular key timing issues. The way the figures are organized does not help. For example, it is not clear whether probe stimulus is ON when the monkey makes the saccades (1 or 2) during PROBE ON trials of block 3 and 2 of task 1 and 2, respectively. It would be easy to add under each task figure the time course of each block/trials. Other figures have errors and/or other issues that should be fixed. For example, <xref ref-type="fig" rid="fig5">Figure 5</xref>, block 2 probe ON, the position of the fixation point and target are moved to the right compared to other figures. <xref ref-type="fig" rid="fig7">Figure 7</xref> block 1, an arrow says the fovea is at the center of the screen.</p><p>4) The interpretation of the results could also use further clarification, particularly with respect to a &quot;craniotopic reference frame.&quot; In particular, it is not clear that the results allow for this claim. This study did not involve manipulations of the orientation of the head, and the information about the position of the probe could be encoded in any other reference frame (hand, body). As the authors certainly know, it could also be &quot;an absolute, world-based frame of reference&quot; (Colby &amp; Duhamel, 1996). Moreover, the relationship to lesion findings should also be clarified. For example, what is basis for the claim that the study by Bisiach and Luzzatti shows that &quot;retrieving that memory goes through a retinotopic process that requires the parietal cortex&quot;? Finally, it would be useful to clarify what these and other data say about the specific role of LIP in generating spatial representations, as distinguished from other parts of the oculomotor network including the FEF.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A spatial memory signal shows that the parietal cortex has access to a craniotopic representation of space&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Sabine Kastner (Senior editor) and a Reviewing editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>1) The most major point is that it is not clear that the results from Task 2 justify the claim that the environmental memory signal &quot;does not require visual stimulation.&quot; Inspection of <xref ref-type="fig" rid="fig8">Figure 8</xref> suggests the presence of a visual response in the &quot;Form memory&quot; condition, at least for Monkeys B and C. Neural responses for the Block 2, stimulus vs no-stimulus condition should be compared directly if this claim is to be supported.</p><p>2) The additional transparency about data from Monkeys B and C in the figures is appreciated. However, I would suggest not using the statement: 'Since the results from Monkeys B and C were comparable and we had only a small number of cells in each monkey, we combined them into &quot;Monkey B&quot;.' Instead, perhaps say something like 'Because the results from Monkeys B and C were comparable and we had only a small number of cells in each monkey, several analyses combine these two data sets.'</p><p>Then for the text and figures (e.g., <xref ref-type="fig" rid="fig4">Figure 4</xref>), use &quot;Monkeys B and C&quot; instead of &quot;Monkey B&quot;</p><p>3) <xref ref-type="fig" rid="fig5">Figure 5D</xref> and <xref ref-type="fig" rid="fig9">Figure 9D</xref> are pretty hard to parse, and it is not clear what the normalization to Block 1 adds. Perhaps consider: (1) removing those points if they are not necessary, or (2) using a supplemental figure if they are, along with a stronger justification for including them. Also, is a cubic polynomial justified for fitting the open symbols in 5d?</p><p>4) How should the lack of decay in Monkeys B and C for Task 2 be interpreted?</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A spatial memory signal shows that the parietal cortex has access to a craniotopic representation of space&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Sabine Kastner (Senior editor) and a Reviewing editor.</p><p>The manuscript has been improved but there still is one remaining issue that needs to be addressed before acceptance, as outlined below:</p><p>The added information describing the neural responses to Task 2 is welcome but awfully cryptic, and I'm not sure it clearly indicates that the environmental memory signal &quot;does not require visual stimulation.&quot; Specifically:</p><p>1) Identifying a statistically significant difference between Block 2 with stimulus and Block 4 does not seem either surprising or interesting: in Block 4, the stimulus was placed in the RF and so by definition should produce a bigger response.</p><p>2) The comparison of memory recall versus memory formation is key, as noted previously, but here treated in a cursory manner: p-values for population analyses do not give any intuition for size and/or timing of spike-rate differences for each neuron (and p-values of 0.02 and 0.03 should not be considered as evidence for a &quot;highly statistical difference&quot;), nor does this analysis rule out that there were visual responses in the probe-on trials.</p><p>3) For the population baseline-vs-memory block analysis, a p-value of 0.05 is not considered significant, even with outliers, and so this should not be considered the &quot;same&quot; result.</p><p>Can the authors provide more clear and definitive evidence that the environmental memory signal &quot;does not require visual stimulation&quot;?</p><p>Please note that we strongly expect you to provide conclusive and convincing evidence to resolve these concerns satisfactorily, since we are unlikely to grant another round of revisions after this one.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.30762.016</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>Essential revisions:</p><disp-quote content-type="editor-comment"><p>1) By far the biggest concern is that the data are in many cases not presented in a manner that allows them to be evaluated effectively. Other than an initial pair of PSTH and raster plots for example responses from Task 1, the remaining results are presented primarily using scatter plots, which does not give any sense of the time course of neural responses in the context of fairly involved sensory/memory/motor sequences. Among the issues raised that should be addressed are:</p></disp-quote><p>We now show time courses of responses for two tasks, for single neurons and population averages. The third task been entirely removed to address the concern that the data came from a single monkey.</p><disp-quote content-type="editor-comment"><p>a) Show time courses of responses for all three tasks, for single neurons and population averages. These plots could help to show, for example, whether there were any visually evoked responses in Task 2, Block 2; what is the time course of the responses relative to the saccade, and when the &quot;peak activity in the baseline and memory blocks of trials&quot; occurred in Task 3.</p></disp-quote><p>Corrected, as described above. There are visually-evoked responses in Task 2 only in the last block and the time course of the responses around the saccade resemble those from Task 1.</p><disp-quote content-type="editor-comment"><p>b) Account for some very high spike rates – some were as high as 400+ sp/sec. Could this reflect multi-unit activity?</p></disp-quote><p>These are not multi-unit activities but actual peak spiking rates calculated from PSTHs in the response window. These rates are high because they are maximums and are calculated from PSTHs which are constructed from narrow bins (2 ms) using a smoothing window (10 ms). In the current version, we have normalized the spiking activity to that of Block 1 (baseline) pre-saccadic activity and there are no longer such extreme peak firing rates.</p><disp-quote content-type="editor-comment"><p>c) A better justification for using the medc metric, as opposed to more straightforward tests comparing distributions.</p></disp-quote><p>Medc is used for non-Gaussian distributions. For the sake of simplicity, and to provide extra confirmation we now have added a straightforward median calculation. We left medc in for the benefit of readers who wish to have extra validation of the result.</p><disp-quote content-type="editor-comment"><p>2) Much of the data from this paper comes from a single monkey, leading to two issues. First, tasks 1 and 2 have data from two other monkeys that appropriately and effectively confirm the more extensive results from the first monkey. However, it is unusual to treat data from monkey B and C as if from a single monkey. At the very least, it would be useful to use different symbols for the two monkeys (e.g., red triangle &amp; red square) in the scatterplots, to demonstrate that the results are similar for the two. Second, results from Task 3 are only from one monkey, which does not meet the acknowledged standard in this field. It therefore is important to make it clear that this is an unconfirmed, preliminary finding that is not critical to the overall message of the study. Alternatively, confirmatory data from a second monkey is needed.</p></disp-quote><p>These are also valid points. Therefore: (1) we have clearly identified monkey B differently from monkey C by adding ‘*’ on top of the red triangles in the scatter plots. 2) Task 3, being from only one monkey, has been completely removed. It will be used in future publications when a second monkey is recorded from.</p><disp-quote content-type="editor-comment"><p>3) The writing and figures should be revised carefully for clarity. For example, in the current manuscript it is difficult to understand the details of the tasks, in particular key timing issues. The way the figures are organized does not help. For example, it is not clear whether probe stimulus is ON when the monkey makes the saccades (1 or 2) during PROBE ON trials of block 3 and 2 of task 1 and 2, respectively. It would be easy to add under each task figure the time course of each block/trials. Other figures have errors and/or other issues that should be fixed. For example, <xref ref-type="fig" rid="fig5">Figure 5</xref>, block 2 probe ON, the position of the fixation point and target are moved to the right compared to other figures. <xref ref-type="fig" rid="fig7">Figure 7</xref> block 1, an arrow says the fovea is at the center of the screen.</p></disp-quote><p>All of these issues have been addressed by replacing the task figures with completely new ones. The new versions include cartoons illustrating task timing, associated eye-positions, and text defining the role of each block of trials, such as “baseline”, “form memory”, “recall”, etc.</p><disp-quote content-type="editor-comment"><p>4) The interpretation of the results could also use further clarification, particularly with respect to a &quot;craniotopic reference frame.&quot; In particular, it is not clear that the results allow for this claim. This study did not involve manipulations of the orientation of the head, and the information about the position of the probe could be encoded in any other reference frame (hand, body). As the authors certainly know, it could also be &quot;an absolute, world-based frame of reference&quot; (Colby &amp; Duhamel, 1996).</p></disp-quote><p>The reviewers are correct that from the evidence in this paper we cannot assert that LIP has access to a craniotopic representation. However, our data clearly argue that LIP has access to a more general representation of visual space than a retinotopic one. To eliminate the unwarranted specificity of “craniotopic” we have substituted “supraretinal” for “craniotopic” throughout the paper.</p><disp-quote content-type="editor-comment"><p>Moreover, the relationship to lesion findings should also be clarified. For example, what is basis for the claim that the study by Bisiach and Luzzatti shows that &quot;retrieving that memory goes through a retinotopic process that requires the parietal cortex&quot;?</p></disp-quote><p>We now write,</p><p>“Our results can explain previous clinical observations regarding the role of parietal cortex in spatial memory. Patients with bilateral parietal lesions cannot point to an object in their room with their eyes closed, although they can easily do it with their eyes open (Farah et al., 1985). This suggests that these patients do not have access to a remembered spatial representation of their environment. More importantly, patients with right parietal lesions report their spatial memory in a retinotopic frame. Bisiach and Luzzatti (1978) asked two Milanese patients with right parietal damage to describe their memory of the Piazza del Duomo in Milan. When they described it as if they were standing with their back to the cathedral they remembered only the landmarks to the right of the cathedral. When they described it as if they were facing the cathedral they only remembered the landmarks on the other side of the square, which were now to the right of their imagined vantage point. This experiment demonstrates two key ideas; 1. The brain stores long-term memory of environments in supraretinal coordinates in an area unaffected by a parietal lesion, since the patients could, under certain circumstances, remember the entire Piazza del Duomo. 2. Retrieving that memory requires the parietal cortex, but the right parietal patients could only report (and therefore image) objects on the right side of their imagined vantage point. They had a mnemonic left hemianopia for a remembered environment. If their memory were reportable in a supraretinal frame they should have been able to report the entire scene. Because they could not do so, but could only report objects in the non-neglected field, the report of their environmental memory must be processed by the retinotopic map of the parietal cortex. Our results are consistent with this result. The memory of an environment can be stored a supraretinal frame, but must be reported by neurons with retinotopic receptive fields. The neurons that we have reported here fit that description.”</p><disp-quote content-type="editor-comment"><p>Finally, it would be useful to clarify what these and other data say about the specific role of LIP in generating spatial representations, as distinguished from other parts of the oculomotor network including the FEF.</p></disp-quote><p>We now write,</p><p>“It is important to emphasize that LIP is part of a spatial network that includes the FEF and the superior colliculus. Although the neuropsychological studies suggest that parietal damage affects spatial memory, we do not know if damage to other parts of the network has a similar effect.”</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>1) The most major point is that it is not clear that the results from Task 2 justify the claim that the environmental memory signal &quot;does not require visual stimulation.&quot; Inspection of <xref ref-type="fig" rid="fig8">Figure 8</xref> suggests the presence of a visual response in the &quot;Form memory&quot; condition, at least for Monkeys B and C. Neural responses for the Block 2, stimulus vs no-stimulus condition should be compared directly if this claim is to be supported.</p></disp-quote><p>Another great observation to which we provide the following answers:</p><p>It is true that <xref ref-type="fig" rid="fig8">Figure 8</xref> shows a perisaccadic burst in the memory trials of block 3. However, it also shows a perisaccadic burst in block 1, when no stimulus had ever appeared in the receptive field of the neuron and the saccade did not bring the stimulus into the receptive field. LIP neurons often have a small perisaccadic burst when monkeys make any saccade (Wang and Goldberg, in preparation), and the perisaccadic burst.</p><p>We now write (Results section):</p><p>&quot;We studied 54 neurons (30 in Monkey A, 14 in Monkey C) in the No-RF task. We used the same criteria as for the neurons studied in the basic task, with one major difference: some LIP neurons have a brief perisaccadic response to eye movements in all directions, including those away from their receptive fields. Rather than excluding neurons with perisaccadic responses, we included neurons with perisaccadic responses that did not differ between blocks 1 (saccades that will, in block 3, bring the spatial location of the vanished stimulus into the receptive field) and block 3 (saccades made away from the receptive field).&quot;And:</p><p>&quot;To investigate whether, as a population, the groups showed statistically significant memory responses, we utilized two approaches. First, we compared population PSTHs for the different blocks. [...] We observed the environmental memory response (<xref ref-type="fig" rid="fig9">Figure 9A</xref>) despite the facts that 1) the probe stimulus never appeared in the neuron's receptive field, and 2) the saccade used to establish the memory response (saccade 1).&quot;</p><disp-quote content-type="editor-comment"><p>2) The additional transparency about data from Monkeys B and C in the figures is appreciated. However, I would suggest not using the statement: 'Since the results from Monkeys B and C were comparable and we had only a small number of cells in each monkey, we combined them into &quot;Monkey B&quot;.' Instead, perhaps say something like 'Because the results from Monkeys B and C were comparable and we had only a small number of cells in each monkey, several analyses combine these two data sets.'</p><p>Then for the text and figures (e.g., <xref ref-type="fig" rid="fig4">Figure 4</xref>), use &quot;Monkeys B and C&quot; instead of &quot;Monkey B&quot;</p></disp-quote><p>Corrected and figure legends and text references.</p><p>Now, the data for second task (Task 2) comes from only Monkey C. This helped in creating a population that is consistent and representative.</p><disp-quote content-type="editor-comment"><p>3) <xref ref-type="fig" rid="fig5">Figure 5D</xref> and <xref ref-type="fig" rid="fig9">Figure 9D</xref> are pretty hard to parse, and it is not clear what the normalization to Block 1 adds. Perhaps consider: 1) removing those points if they are not necessary, or 2) using a supplemental figure if they are, along with a stronger justification for including them. Also, is a cubic polynomial justified for fitting the open symbols in 5d?</p></disp-quote><p>In the spirit of full disclosure about the history of these panels, the main idea behind adding block 1 normalization and showing both came mainly from questions from one specific researcher in our floor. We do accept that this approach complicated the message, and thus have simplified them by:</p><p>1) Removing the extra plots and axis i.e. we now show only the decay vs last few memory forming trials.</p><p>2) Using only a first order exponential fit. Cubic polynomial was used to help readers follow the modulation and also get a better fit to the data (r-square). It is worth noting here that our main criteria for measuring decay is statistical comparison between the first and last 10-trials in a given epoch. As such, using the wrong fit can cause non-optimal line fits as is evidenced by a negative r-square for Monkey A Task 2 fit. We can take out the r-square value references if the editor feels it will confuse readers.</p><p>3) We have expanded our decay epoch to 50 trials (instead of 40) to show better (comparably sharper) decay at least for one of the monkeys(groups).</p><disp-quote content-type="editor-comment"><p>4) How should the lack of decay in Monkeys B and C for Task 2 be interpreted?</p></disp-quote><p>We found that most of our units “forget” in about 40 trials, meaning, the lack of decay for the specific data set and task is only for the 40-trial epoch, not for the whole “forgetting” block. As mentioned above, we now show 50-trial epoch confirming decay, albeit slow. There are units that can keep their memory even for up to 100 trials. To explain this further showing up to 100 trials is not practical as:</p><p>1) Not all neurons keep their memory that long.</p><p>2) Not all recordings have 100 such trial.</p><p>These two points mean that we will have enough units for 100 trials to average over.</p><p>We now say (Subsection “Task 2: No – RF Task.”):</p><p>“For this task, Monkey A showed no decay within the 50-trial epoch. This is common for some units in the population which can keep their memory even for up to 100 trials. Since not all recordings have a large number of ‘forgetting’ trials, it is not possible to have enough units for 100 trials to average over. The negative R2 demonstrates the slowness of the decay and that a first-order exponential is not the best fit (it caused non-optimal line fit). This fit is used in the figures for consistency and visual clarity.”</p><p>On a previous and somewhat unclear statement we made about latencies: we now show latencies for all units using different approaches. We now say (Subsection “Task 1 – Basic Memory Task”):</p><p>“However, because the memory responses for some neurons increased gradually, we were unable to establish memory latencies for all neurons using our latency method (for these neurons, we used other approaches, as described in the Materials and methods section).”</p><p>This refers to what we say (Materials and methods section):</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The added information describing the neural responses to Task 2 is welcome but awfully cryptic, and I'm not sure it clearly indicates that the environmental memory signal &quot;does not require visual stimulation.&quot; Specifically:</p><p>1) Identifying a statistically significant difference between Block 2 with stimulus and Block 4 does not seem either surprising or interesting: in Block 4, the stimulus was placed in the RF and so by definition should produce a bigger response.</p></disp-quote><p>We respectfully disagree – this result just shows that the memory response is weaker (and has a longer latency) than the pure visual response. Although not a main point of the paper it does say something about the memory phenomenon and is worth including in the paper. Furthermore, the larger visual response in Block 4 than in Block 2 shows that whatever decay we saw in Block 3 was not due to our losing the cell over this rather long experiment. Finally, we do not use the Block 2-Block 4 comparison to establish that the memory response was not a visual response. We now write (Subsection “Task 2: No-RE task.”).</p><p>“As in the basic task, the larger visual response in Block 4 was larger than the memory response in Block 2 (Monkey A, p &lt; 0.0001, Monkey C p = 0.03 Wilcoxon signed rank). This shows that whatever decay we saw in Block 3 was not due to our losing the cell over this rather long experiment. The memory response had a longer latency than the neuron’s visual response (<xref ref-type="fig" rid="fig9">Figure 9C</xref>) (Wilcoxon signed rank p = 0.008 for Monkey A, and 0.006 for Monkey C; mean visual/memory latency: 39/101 ms for Monkey A, 25/106 ms for Monkey C).”</p><disp-quote content-type="editor-comment"><p>2) The comparison of memory recall versus memory formation is key, as noted previously, but here treated in a cursory manner: p-values for population analyses do not give any intuition for size and/or timing of spike-rate differences for each neuron (and p-values of 0.02 and 0.03 should not be considered as evidence for a &quot;highly statistical difference&quot;).</p></disp-quote><p>The scatter plots (<xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig9">Figure 9</xref>) give a precise measure of the differences in peak spike rates for each cell, and the latency of the cell’s response. The population histograms give an estimate of timing across the population.</p><disp-quote content-type="editor-comment"><p>Nor does this analysis rule out that there were visual responses in the probe-on trials.</p></disp-quote><p>The data that show we do not have a visual response in the no-RF experiment is the comparison between Block 1 and Block 2. There is no visual stimulus in Block 1, nor has there ever been a visual stimulus in the RF at that point in the experiment. There is a visual stimulus outside the RF in Block 2 trials with the stimulus. This stimulus has no effect on the cell’s activity, because there is no difference between the small postsaccadic response in Block 1, and the small postaccadic response in Block 2 when the monkey makes a saccade in the different direction that does not bring the stimulus into the receptive field. Therefore. the response in block 2 cannot be a visual response. We now write, (Subsection “Task 2: No-RE task.”)</p><p>“Therefore, rather than excluding neurons with postsaccadic responses, we included neurons with small postsaccadic responses that did not differ between blocks 1 (saccades that will, in block 2, bring the spatial location of the vanished stimulus into the receptive field, but in which no stimulus ever appeared on the screen) and block 2 (different saccades that brought the receptive field away from the stimulus whose memory is being established, Wilcoxon signed rank: Monkey A p-value = 0.4; Monkey C p-value = 0.3). Although the stimulus never appeared in the neuron’s receptive field, the cells responded when the saccade brought the spatial location of the vanished stimulus into the receptive field (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The population exhibited a robust memory response (<xref ref-type="fig" rid="fig8">Figure 8</xref>, poststimulus histogram for all cells we studied). The population histogram shows, for one monkey, a small postsaccadic burst in the stimulus appearing trials of block 2. One could argue, by looking at the postsaccadic response in the trials where the monkey made the saccade that brought the visual stimulus to a location outside of our estimate of the cell’s receptive field, that this postsaccadic response was a visual response.”</p><disp-quote content-type="editor-comment"><p>3) For the population baseline-vs-memory block analysis, a p-value of 0.05 is not considered significant, even with outliers, and so this should not be considered the &quot;same&quot; result.</p></disp-quote><p>We realized that we had been using the wrong nonparametric test for most of our analysis. We are now using the Wilcoxon Signed Rank test, the non-parametric equivalent of the paired t-test, for the population analyses. Using this test, we have much lower p values for the population studies. The only p &lt; 0.05 value we used was to establish memory in single neurons, by showing differences in median activity in the postsaccadic epoch for Block 1 trials trials, before the memory had been established, and the stimulus-absent trials of Block 2, which had the memory response even though the task was identical in in the two blocks, the monkey making a saccade that brings the receptive field into a specific location where there is no stimulus. For a single cell to show environmental memory, the difference in the response had to be significant, p &lt; 0.05 by Wilcoxon Rank Sum, which is identical to the Mann Whitney U test, the nonparametric t test. The use of p &lt; 0.05 for single cells is pretty standard across the literature, for example Joshi et al., (2016).</p><disp-quote content-type="editor-comment"><p>Can the authors provide more clear and definitive evidence that the environmental memory signal &quot;does not require visual stimulation&quot;?</p></disp-quote><p>Please see our reply to point 2 above.</p></body></sub-article></article>