<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">06564</article-id><article-id pub-id-type="doi">10.7554/eLife.06564</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Rapid categorization of natural face images in the infant right hemisphere</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-28144"><name><surname>de Heering</surname><given-names>Adélaïde</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataro1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-27413"><name><surname>Rossion</surname><given-names>Bruno</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataro1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Psychological Sciences Research Institute</institution>, <institution>University of Louvain</institution>, <addr-line><named-content content-type="city">Louvain-la-Neuve</named-content></addr-line>, <country>Belgium</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Institute of Neuroscience</institution>, <institution>University of Louvain</institution>, <addr-line><named-content content-type="city">Louvain-la-Neuve</named-content></addr-line>, <country>Belgium</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-1066"><name><surname>Culham</surname><given-names>Jody C</given-names></name><role>Reviewing editor</role><aff><institution>University of Western Ontario</institution>, <country>Canada</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>bruno.rossion@uclouvain.be</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>02</day><month>06</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e06564</elocation-id><history><date date-type="received"><day>18</day><month>01</month><year>2015</year></date><date date-type="accepted"><day>16</day><month>04</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, de Heering and Rossion</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>de Heering and Rossion</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-06564-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.06564.001</object-id><p>Human performance at categorizing natural visual images surpasses automatic algorithms, but how and when this function arises and develops remain unanswered. We recorded scalp electrical brain activity in 4–6 months infants viewing images of objects in their natural background at a rapid rate of 6 images/second (6 Hz). Widely variable face images appearing every 5 stimuli generate an electrophysiological response over the right hemisphere exactly at 1.2 Hz (6 Hz/5). This face-selective response is absent for phase-scrambled images and therefore not due to low-level information. These findings indicate that right lateralized face-selective processes emerge well before reading acquisition in the infant brain, which can perform figure-ground segregation and generalize face-selective responses across changes in size, viewpoint, illumination as well as expression, age and gender. These observations made with a highly sensitive and objective approach open an avenue for clarifying the developmental course of natural image categorization in the human brain.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.001">http://dx.doi.org/10.7554/eLife.06564.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.06564.002</object-id><title>eLife digest</title><p>Putting names to faces can sometimes be challenging, but humans are generally extremely good at recognising faces. Computers, on the other hand, often find it difficult to categorize a face as a face. Indeed, a major challenge in face recognition arises because faces come in many different shapes and sizes. Moreover, both the lighting conditions and the orientation of the head can change, which makes the challenge even more difficult.</p><p>Young infants also show a preference for pictures of human faces over nonsense images, which suggests that the ability to recognise faces is at least partly hard-wired. Neuroimaging studies have revealed that face recognition depends on activity in specific regions of the right hemisphere of the brain, and adults who sustain damage to these regions lose their face recognition skills.</p><p>De Heering and Rossion have now provided the first evidence that the right hemisphere is specialized for distinguishing between natural images of faces and ‘non-face objects’ in infants as young as 4 to 6 months. By using scalp electrodes to record electrical activity in the brain as the infants viewed images on a screen, De Heering and Rossion showed that photographs of human faces triggered a distinct pattern of electrical activity in the right hemisphere: this pattern was clearly different to the patterns triggered by photographs of animals or objects.</p><p>A consistent response was triggered by faces of different genders and expressions, and by faces presented from various viewpoints and under different lighting conditions. In a control experiment, De Heering and Rossion demonstrated that low-level visual features such as differences in luminance or contrast do not contribute to this selective response to faces.</p><p>These results argue against the idea that face perception only becomes assigned to the right hemisphere of the brain when children learn to read (that is, when language processing begins to occupy parts of the left hemisphere). By generating significant responses in a short period of time (just five minutes or less), the protocol developed by De Heering and Rossion has the potential to prove very useful to researchers investigating developmental changes to the perception of visual images during childhood.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.002">http://dx.doi.org/10.7554/eLife.06564.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>face perception</kwd><kwd>infant</kwd><kwd>right hemisphere</kwd><kwd>natural image</kwd><kwd>visual categorization</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council (ERC)</institution></institution-wrap></funding-source><award-id>facessvep 284025</award-id><principal-award-recipient><name><surname>Rossion</surname><given-names>Bruno</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002661</institution-id><institution>Fonds De La Recherche Scientifique - FNRS</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Rossion</surname><given-names>Bruno</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Diverse photographs of human faces against their natural background trigger a specific electrical response in the right hemisphere of the brain in infants aged 4–6 months.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A fundamental function of the human brain is to organize sensory events into distinct classes, that is, perceptual categorization (<xref ref-type="bibr" rid="bib38">Rosch, 2007</xref>). This function is well illustrated in vision, the dominant sensory modality in humans: visual categorization in natural scenes occurs extremely rapidly (<xref ref-type="bibr" rid="bib47">Thorpe et al., 1996</xref>) and in the near absence of attention (<xref ref-type="bibr" rid="bib29">Li et al., 2002</xref>). Yet, visual categorization is extremely challenging. For instance, categorizing a visual stimulus as a face—arguably the most significant visual stimulus for human social ecology—requires to isolate the face from its natural background scene (‘figure-ground segregation’, <xref ref-type="bibr" rid="bib1">Appelbaum et al., 2006</xref>; <xref ref-type="bibr" rid="bib33">Peterson, 2014</xref>) and distinguish the face from the wide range of non-face stimuli in the environment which share visual properties with faces. Moreover, a common response (i.e., generalization) should be given to faces appearing under various viewing conditions (i.e., changes of head orientation, size, illumination, etc) and varying greatly in terms of gender, age, expression, ethnic origin, so on. Despite this challenge, human performance at face categorization is impressive (<xref ref-type="bibr" rid="bib6">Crouzet et al., 2010</xref>), surpassing even the most sophisticated automatic systems (<xref ref-type="bibr" rid="bib43">Scheirer et al., 2014</xref>).</p><p>Up to now, the ontogeny of face categorization remains largely unknown. Classical studies have reported preference for facelike over non-facelike patterns at birth (<xref ref-type="bibr" rid="bib18">Goren et al., 1975</xref>; <xref ref-type="bibr" rid="bib24">Johnson and Morton, 1991</xref>). At a few months of age, differences in event-related potentials (ERPs) have been found between face stimuli and meaningless patterns (<xref ref-type="bibr" rid="bib19">Halit et al., 2004</xref>; <xref ref-type="bibr" rid="bib27">Kouider et al., 2013</xref>) as well as between faces and exemplars of a single object category segmented from its natural background (e.g., toys, <xref ref-type="bibr" rid="bib7">de Haan and Nelson, 1999</xref>; cars, <xref ref-type="bibr" rid="bib34">Peykarjou and Hoehl, 2013</xref>; houses or cars, Gliga and Dehaene, 2007). However, there is no evidence on the effectiveness of infant vision in segmenting faces in natural images and representing them as a distinct, generalized category, or on the developing neural systems that may achieve this process. Clarifying this issue is also important for understanding the origin of hemispheric lateralization for face-selective processes in the human brain. In human adults, areas of the ventral and lateral occipito-temporal cortex are more active when viewing faces vs a variety of non-face objects (<xref ref-type="bibr" rid="bib45">Sergent et al., 1992</xref>; <xref ref-type="bibr" rid="bib36">Puce et al., 1995</xref>; <xref ref-type="bibr" rid="bib25">Kanwisher et al., 1997</xref>; <xref ref-type="bibr" rid="bib20">Haxby et al., 2000</xref>; <xref ref-type="bibr" rid="bib40a">Rossion et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Weiner and Grill-Spector, 2013</xref>). This face-selective activation is typically larger in the right than the left hemisphere and, in right handed individuals at least, right unilateral brain lesions can lead to selective impairment in face recognition (prosopagnosia: e.g., <xref ref-type="bibr" rid="bib2">Barton et al., 2002</xref>; <xref ref-type="bibr" rid="bib4">Busigny et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Hecaen and Angelergues, 1962</xref>; <xref ref-type="bibr" rid="bib46">Sergent and Signoret, 1992</xref>). According to a recent hypothesis, this right hemispheric dominance for face perception, which seems specific to humans (e.g., <xref ref-type="bibr" rid="bib48">Tsao et al., 2008</xref>), is driven by the left hemispheric lateralization for words emerging during reading acquisition (<xref ref-type="bibr" rid="bib11">Dundas et al., 2013</xref>). Thus, according to this view, right hemispheric lateralization for faces should not be present in infancy. Up to now, infant ERP studies have not been able to provide evidence for right hemispheric lateralization of face-selective processes (<xref ref-type="bibr" rid="bib7">de Haan and Nelson, 1999</xref>; Gliga et al., 2007; <xref ref-type="bibr" rid="bib34">Peykarjou and Hoehl, 2013</xref>) and right hemispheric lateralization has only been observed when comparing faces to meaningless stimuli that differ in terms of low-level visual cues (<xref ref-type="bibr" rid="bib50">Tzourio-Mazoyer et al., 2002</xref>; <xref ref-type="bibr" rid="bib27">Kouider et al., 2013</xref>).</p><p>We addressed these outstanding issues by means of a simple ‘frequency tagging’ or ‘fast periodic visual stimulation’ (FPVS) approach, providing robust electroencephalographic (EEG) responses—steady state visual evoked potentials (SSVEPs, <xref ref-type="bibr" rid="bib37">Regan, 1989</xref>; for a review see <xref ref-type="bibr" rid="bib31">Norcia et al., 2015</xref>)—over the left and right hemispheres of 4- to 6-month-old infants. This approach is ideal to study the infant brain because it is relatively immune from artifacts and provides high signal-to-noise ratio (SNR) responses in a few minutes only. Moreover, compared to other approaches such as ERPs to transient stimulation, the FPVS approach is objective and predictive because the response appears exactly at the periodic frequency of stimulation defined by the experimenter. So far, infants have been tested with this approach only in response to low-level visual stimuli (i.e., acuity, contrast sensitivity, spatial phase, orientation, or motion; e.g., <xref ref-type="bibr" rid="bib3">Braddick et al., 1986</xref>; <xref ref-type="bibr" rid="bib32">Norcia et al., 1990</xref>). A recent EEG study tested infants with segmented faces and objects in different stimulation streams, but without testing face vs object discrimination or generalization across diverse face views, and without providing evidence of hemispheric lateralization (<xref ref-type="bibr" rid="bib14">Farzin et al., 2012</xref>). Here, to achieve these goals, we isolated face-selective responses by means of a fast periodic oddball paradigm (<xref ref-type="bibr" rid="bib22">Heinrich et al., 2009</xref>) recently adapted to characterize adults' individual face discrimination (<xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>) and face-selective responses in adults (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Isolation of a face-selective right hemispheric response</title><p>We recorded 32-electrode EEG in a group of 15 4- to 6-month-old infants (5 females, mean age = 155 days, range 125–197 days) looking at complex images of various faces and objects presented one-by-one on a computer screen at a rapid frequency rate of 6 images/s (i.e., 6 Hz, stimulus onset asynchrony of 167 ms, <xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="other" rid="media1">Video 1</xref>), in sequences of 20 s. Infants viewed between 5 and 12 sequences (i.e., 100 s–240 s; eight sequences on average).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.06564.003</object-id><label>Figure 1.</label><caption><title>(<bold>A</bold>) Examples of face (F) and object (O) stimuli presented during a 20-s sequence at 6 Hz (i.e., 120 images).</title><p>Face stimuli, varying considerably in size, viewpoint, expression, gender, so on appeared as every fifth image, that is, at 1.2 Hz rate (=6 Hz/5). For copyright reasons, the face pictures displayed in the figure are different than those used in the actual experiment, but the degree of variability across images is respected. The full set of face pictures is available at <ext-link ext-link-type="uri" xlink:href="http://face-categorization-lab.webnode.com/publications/">http://face-categorization-lab.webnode.com/publications/</ext-link> together with the paper reporting the original study performed in adults (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>). (<bold>B</bold>) Stimuli were presented in the center of the screen by means of sinusoidal contrast modulation at a rate of 6 Hz (i.e., 6 images/s).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.003">http://dx.doi.org/10.7554/eLife.06564.003</ext-link></p></caption><graphic xlink:href="elife-06564-fig1-v1.tif"/></fig><media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="avi" mimetype="video" xlink:href="elife-06564-media1.avi"><object-id pub-id-type="doi">10.7554/eLife.06564.004</object-id><label>Video 1.</label><caption><title>8 s excerpt of experiment 1 (20 s sequences) showing faces at a rate of 1 image every 5 images, at a 6 Hz base rate.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.004">http://dx.doi.org/10.7554/eLife.06564.004</ext-link></p></caption></media></p><p>Thanks to the high temporal resolution of EEG and the high frequency resolution provided by the analysis (1/20 s = 0.05 Hz), responses occurring exactly at the fast 6 Hz rate were identified in the SNR spectrum, obtained by dividing each frequency bin by the 20 neighboring bins (<xref ref-type="bibr" rid="bib40a">Rossion et al., 2012</xref>; see ‘Materials and methods’). On grand-averaged data, this high SNR response at 6 Hz (averaged SNR = 8.87 at channel Oz) focused over the medial occipital cortex, reflecting infants' visual system synchronization to the stimulus presentation rate (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). On these grand-averaged data, a Z-Score computed as the difference between amplitude at the frequency of interest and the mean amplitude of 20 surrounding bins divided by the standard deviation of the 20 surrounding bins (e.g., <xref ref-type="bibr" rid="bib40a">Rossion et al., 2012</xref>; <xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>; see also ‘Materials and methods’) was highly significant at electrode Oz (Z = 52.9, p &lt; 0.00001). To ensure that this effect was not driven by the data of a few infants, a t-test against 1 (i.e., signal above noise level) was also performed using the individual SNR values at Oz (range: 0.19–17.07; <xref ref-type="fig" rid="fig2">Figure 2B</xref>). This response was highly significant (t(14) = 7.075, p &lt; 0.0001). Moreover, the high frequency resolution of the approach provides many frequency bins to estimate the noise so that the Z-score procedure could be applied to each individual infant's data. At electrode Oz, a significant response was observed in every infant tested but one (Z-score range of 14 infants: 6.10–35.46; not significant for 1 infant only). This observation indicates that the infant brain synchronizes strongly to the rapid 6 Hz visual presentations of multiple object categories.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.06564.005</object-id><label>Figure 2.</label><caption><title>(<bold>A</bold>) Grand-averaged EEG signal-to-noise ratio (SNR) spectrum at a medial occipital electrode site (channel Oz).</title><p>The SNR is computed across the whole spectrum as the ratio of the amplitude (in microvolts) at each frequency bin and the 20 surrounding frequency bins (<xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>; see ‘Materials and methods’). For EEG amplitude spectra. (<bold>B</bold>) The SNR response at 6 Hz on electrode Oz, showing above noise level (&gt;1) responses for all infants tested but one.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.005">http://dx.doi.org/10.7554/eLife.06564.005</ext-link></p></caption><graphic xlink:href="elife-06564-fig2-v1.tif"/></fig></p><p>Most interestingly, face stimuli were presented at a slower periodic rate in the stimulation sequence, that is, as every fifth stimulus (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Hence, if the infant's brain discriminates between faces and non-face objects, another response is expected exactly at a rate of 6 Hz/5 = 1.2 Hz in the EEG spectrum. On grand-averaged data, a clear 1.2 Hz response emerged, with the largest response found over the right occipito-temporal channel P8 (SNR = 2.56; i.e., 156% signal increase; <xref ref-type="fig" rid="fig3">Figure 3A</xref>; Table 1 in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1A</xref>). This peak at 1.2 Hz was well above noise level at P8 (Z = 12.16, p &lt; 0.001) even when correcting for multiple comparisons (all electrode channels, see Table 1 in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1A</xref> for SNR and Z-scores at every channel at 1.2 Hz). Four other electrodes were associated with significant 1.2 Hz responses on grand-averaged data (O1, F3, F7, P7; see Table 1 in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1A</xref>) but with much lower SNR values (range: 1.14–1.47). The subsequent analysis based on individual infant's data focused on electrode P8.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.06564.006</object-id><label>Figure 3.</label><caption><title>(<bold>A</bold>) Grand-averaged EEG SNR spectrum at the right hemisphere occipito-temporal channel P8, showing a distinct peak exactly at the face stimulation frequency (1.2 Hz).</title><p>(<bold>B</bold>) The SNR response of individual infants at 1.2 Hz, on electrode P8. Color codes are congruent with <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.006">http://dx.doi.org/10.7554/eLife.06564.006</ext-link></p></caption><graphic xlink:href="elife-06564-fig3-v1.tif"/></fig></p><p>Considering the variance across infants' data for statistical tests, the response at P8 is highly significant (i.e., above noise level, or SNR = 1, t(14) = 3.11, p = 0.004; <xref ref-type="fig" rid="fig3">Figure 3B</xref>). For 12 infants out of 15, the signal at 1.2 Hz is above noise level (SNR range of all 15 infants at P8: 0.52–6.13, <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Using the Z-score approach for testing individual infants, the response at P8 is also significant for the individual data of 7 infants out of 15 (ps &lt; 0.05, Z-score &gt; 1.64 for signal vs noise computed over neighboring frequency bins, see ‘Materials and methods’). The other 7 infants showed a significant 1.2 Hz face categorization response on at least one other electrode (p &lt; 0.05), while none of the electrodes reached significance for one infant. Even though a 1.2 Hz response was also observed over the homologous left occipito-temporal channel P7 (SNR of grand-averaged data = 1.47, Z = 3.61; Table 1 in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1A</xref>), this response was significantly lower than that at P8 (t(14) = 2.45, p = 0.013).</p><p>A significant response at 1.2 Hz indicates that the infant brain generates a <italic>specific</italic> response to faces compared to the other object categories presented in the stimulation sequences (i.e., discrimination) and that such a differential response is generated periodically, that is, for virtually every face presented in the sequence (i.e., generalization) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Moreover, although the faces and objects are relatively well centered, the color images are embedded in their natural and diverse backgrounds. Hence, to be identified as distinct shapes, both the face and object stimuli have to be segmented from their background, a nontrivial accomplishment for the visual system (<xref ref-type="bibr" rid="bib1">Appelbaum et al., 2006</xref>; <xref ref-type="bibr" rid="bib33">Peterson, 2014</xref>). Moreover, both the objects and faces substantially vary in size, color, lighting, and viewpoint, and the faces also vary in gender, age, ethnical origin, and expression. Thus, to generate a periodic discriminative 1.2 Hz response in the EEG, the infant brain has to categorize the face stimuli, namely to produce a response that is specific to face images and invariant to their differences (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>).</p></sec><sec id="s2-2"><title>Experiment 2: replication and exclusion of low-level contributions</title><p>In theory, putative low-level visual cues differing between faces and objects cannot contribute to the periodic response unless they are systematically present in all or the large majority of face stimuli and if they differ systematically between faces and objects but not within non-face object categories. Given the naturalness and variability of the images used, this is highly unlikely. Thus, the constraint of periodicity provides an elegant way to identify a high-level face categorization response while preserving the natural aspect of the stimuli (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>).</p><p>Nevertheless, to ensure that low-level visual cues do not contribute to the infant face-selective response, we exposed another group of 10 4–6 months infants (4 females, mean age = 163 days) to alternating 20-s sequences of phase-scrambled faces and objects (e.g., <xref ref-type="bibr" rid="bib42">Sadr and Sinha, 2004</xref>; <xref ref-type="bibr" rid="bib40">Rossion and Caharel, 2011</xref>) and of natural stimuli replicating exactly those used in the previous experiment. The phase-scrambled images contain the same low-level information (i.e., power spectrum) as the natural images, but they are unrecognizable as faces or objects (<xref ref-type="other" rid="media2">Video 2</xref>). In this second experiment, infants performed 2 to 12 sequences in total, with no significant difference in the number of sequences by condition (i.e., 90 s; 4.5 sequences on average). On grand-averaged data, we again found a large EEG response at the base stimulation frequency (6 Hz) over the medial occipital lobe for both conditions (electrode Oz; SNR for natural images: 6.01; Z = 29.42, p &lt; 0.00001; SNR for scrambled images: 7.25; Z = 27.4, p &lt; 0.00001).<media content-type="glencoe play-in-place height-250 width-310" id="media2" mime-subtype="avi" mimetype="video" xlink:href="elife-06564-media2.avi"><object-id pub-id-type="doi">10.7554/eLife.06564.007</object-id><label>Video 2.</label><caption><title>8 s excerpt of experiment 2 (20 s sequences) showing scrambled faces at a rate of 1 image every 5 scrambled images, at a 6 Hz base rate.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.007">http://dx.doi.org/10.7554/eLife.06564.007</ext-link></p></caption></media></p><p>The response at channel Oz was significant for every infant in each of the conditions (Z-score range of 10 infants for natural images: 1.66–29.58; for scrambled images: 2.81–27.76; SNR range for natural images: 1.9–13.65; for scrambled images: 2.57–13.55).</p><p>A comparison between the two conditions using the individual infants SNR values at 6 Hz did not reveal any difference (t(9) = 1.103, p = 0.3; <xref ref-type="fig" rid="fig4">Figure 4</xref>), indicating that the synchronization of the visual system to the stimuli does not differ between conditions.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.06564.008</object-id><label>Figure 4.</label><caption><title>Grand-averaged SNR at channel Oz in Experiment 2.</title><p>The SNR peak at the base stimulation frequency (6 Hz) is highly significant and spread over the medial occipital lobe (O1-Oz-O2) in both conditions, as indicated on the scalp topography. There was no significant difference between the 2 conditions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.008">http://dx.doi.org/10.7554/eLife.06564.008</ext-link></p></caption><graphic xlink:href="elife-06564-fig4-v1.tif"/></fig></p><p>On grand-averaged data, there was a significant response at the oddball (1.2 Hz) face frequency at the right occipito-temporal electrode P8 for natural images (mean SNR = 2.09, Z = 2.09, p &lt; 0.05; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). No other electrode was significant on grand-averaged data, which is based on a lower number of infants than in Experiment 1 (10 vs 15) and about half of the stimulation sequences. Critically, this response at P8 was absent for scrambled images (mean SNR = 0.78, Z = −0.8, p &gt; 0.05).<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.06564.009</object-id><label>Figure 5.</label><caption><title>(<bold>A</bold>) Grand averaged EEG SNR spectrum at 1.2 Hz in experiment 2, showing above noise-level (&gt;1) response for faces at channel P8, as shown on the scalp map.</title><p>On the right, individual SNR values at 1.2 Hz for this second experiment. (<bold>B</bold>) There was no distinct peak in the EEG spectrum at 1.2 Hz for corresponding phase-scrambled images, as displayed on the left. As in <xref ref-type="fig" rid="fig1">Figure 1</xref>, for copyright reasons, the face pictures displayed in the figure are different than those used in the actual experiment, but the degree of variability across images is respected. The full set of face pictures is available at <ext-link ext-link-type="uri" xlink:href="http://face-categorization-lab.webnode.com/publications/">http://face-categorization-lab.webnode.com/publications/</ext-link> together with the paper reporting the original study performed in adults (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.009">http://dx.doi.org/10.7554/eLife.06564.009</ext-link></p></caption><graphic xlink:href="elife-06564-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.06564.010</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Face-selective responses at first and second harmonic for natural images but not phase-scrambled images.</title><p>Top. Grandaveraged EEG spectrum (in microvolts) from 0 Hz to 5 Hz for experiment 2 (originalimages in green, scrambled images in black). The peak at 1.2 Hz is visible only for the original images. Note also the smaller response at the second harmonic (2.4 Hz). Middle row. SNR transformed grandaveraged spectrum, showing the clear responses at 1.2 Hz and 2.4 Hz, well above 1 (signal = noise level). Bottom. Topographical maps (back view) and SNR distribution across individuals for the original and scrambled images, for both harmonics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.010">http://dx.doi.org/10.7554/eLife.06564.010</ext-link></p></caption><graphic xlink:href="elife-06564-fig5-figsupp1-v1.tif"/></fig></fig-group></p><p>For natural images, the 1.2 Hz response was above noise level (i.e., 1) for 9 infants out of 10 (SNR range of all 10 infants: 0.82–3.98) and highly significant (t(9) = 3.431, p = 0.004; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). It reached significance for 6 individual infants out of 10 (ps &lt; 0.05, Z-score &gt; 1.64). The other 3 infants showed a significant 1.2 Hz face categorization response over at least one other electrode while none of the electrodes reached significance for the last infant. In contrast considering individual infants data as the source of variance, there was no significant response to phase-scrambled images at electrode P8 (SNR range = 0.11–1.93; t(9) = 1.156, p = 0.278; <xref ref-type="fig" rid="fig5">Figure 5B</xref>, see also <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for data in amplitude, also showing the second harmonic at 2.4 Hz). Hence, there was a significant difference at the oddball (1.2 Hz) frequency between natural and scrambled images at P8 (paired t-test: t(9) = 2.969, p = 0.016).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Collectively, the findings of Experiments 1 and 2 demonstrate that the infant right hemisphere discriminates natural photographs of faces from non-face objects of multiple categories and generalizes across face photographs despite their high physical variability. In both experiments, faces are temporally embedded in a rapid stimulation sequence of non-face objects, so that there is an inherent comparison, or contrast, without the need to perform a subtraction between conditions recorded at different times. That is, there is an oddball response only because the face is discriminated from all other object categories, activating a (face-)specific population of neurons at a rate of 1.2 Hz. Although this is unlikely, we cannot formally exclude at this stage that another visual category than faces would be represented by a distinct population of neurons and would therefore also elicit an oddball response of this amplitude at 4–6 months of age. However, to our knowledge, there is no other visual category that elicits such a large specific response, with a right hemisphere advantage, in the human adult brain. Moreover, the face is arguably the most frequent and socially relevant stimulus in the human (infant) visual environment, making it the best candidate for the early development of category-selective responses.</p><p>Thanks to this original fast periodic visual stimulation (FPVS) approach, the infant's face categorization response identified here goes beyond previous observations of discrimination between segmented faces and non-face stimuli in ERPs (<xref ref-type="bibr" rid="bib7">de Haan and Nelson, 1999</xref>; <xref ref-type="bibr" rid="bib19">Halit et al., 2004</xref>; <xref ref-type="bibr" rid="bib15">Gliga and Dehaene-Lambertz, 2007</xref>; <xref ref-type="bibr" rid="bib34">Peykarjou and Hoehl, 2013</xref>), near infrared spectroscopy responses (NIRS; <xref ref-type="bibr" rid="bib26">Kobayashi et al., 2011</xref>) or positron emission tomography (PET; <xref ref-type="bibr" rid="bib50">Tzourio-Mazoyer et al., 2002</xref>) activations obtained with a standard presentation mode (i.e., transient, slow, and non-periodic stimulation). Despite the great interest of these studies, it is fair to say that it is difficult to define sensitive (i.e., high SNR) and objective face-selective responses in infants with a conventional stimulation mode as used in these studies, so that there is a lack of consistency across studies. Moreover, given time constraints, these studies used segmented stimuli rather than natural images, and could only compare faces to a limited number of categories. Hence, the face-selective responses obtained in previous studies could be due to systematic differences between categories in terms of a homogenous stimulus, such as contour for instance (e.g., all round faces vs rectangular pictures of cars). Finally, a significant contribution of low-level visual cues to faces vs objects responses could not be excluded from these studies, or precisely evaluated.</p><p>Here, in Experiment 2, removing shape information while preserving low-level visual differences in the power spectrum completely erased the 1.2 Hz face-selective response. In other words, the 1.2 Hz face-selective response identified here for natural face images cannot be attributed to low-level visual confounds, such as differences in power spectrum between faces and other object categories. Moreover, the face stimuli were always embedded within distinct natural backgrounds, suggesting that the infant's brain is able to perform complex figure-ground segregation. This is even more impressive considering the brief presentation duration of each face stimulus (i.e., 167 ms SOA, about 100 ms for stimulus duration above 20% contrast, see ‘Materials and methods’) and the rapid mode of stimulation where each stimulus interrupts the processing of the previous one. Considering the enormous amount of resources devoted to develop face segmentation algorithms in computer vision (<xref ref-type="bibr" rid="bib43">Scheirer et al., 2014</xref>), this is not a trivial accomplishment.</p><p>Finding a dominant face-selective response over the right hemisphere in young infants has important implications for our understanding of hemispheric lateralization in humans. It demonstrates that the right hemispheric dominance for face-selective processes—typical of the adult brain (<xref ref-type="bibr" rid="bib21">Hecaen and Angelergues, 1962</xref>; <xref ref-type="bibr" rid="bib23">Hillger and Koenig, 1991</xref>; <xref ref-type="bibr" rid="bib45">Sergent et al., 1992</xref>; <xref ref-type="bibr" rid="bib25">Kanwisher et al., 1997</xref>; <xref ref-type="bibr" rid="bib4">Busigny et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Rossion, 2014</xref>; see <xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref> with the present approach) is already present in infancy, independently of low-level cues. This observation refutes the view that the right hemispheric lateralization for faces arises only after a few years of age, following and being driven by the left hemispheric lateralization for words that emerges during reading acquisition (<xref ref-type="bibr" rid="bib11">Dundas et al., 2013</xref>, <xref ref-type="bibr" rid="bib12">2014</xref>). Rather, even if literacy can refine cortical organization for vision and language (<xref ref-type="bibr" rid="bib10">Dehaene et al., 2010</xref>), the right hemispheric face-selective response identified here in young infants indicates that the right lateralization for face perception is present well before reading acquisition (see also <xref ref-type="bibr" rid="bib10">Dehaene et al., 2010</xref> for right hemisphere lateralization in illiterate adults, and <xref ref-type="bibr" rid="bib5">Cantlon et al., 2011</xref> for right lateralization in 4 years old children). Instead, our findings are in agreement with an early emergence of right lateralization for faces during development (<xref ref-type="bibr" rid="bib9">de Schonen and Mathivet, 1990</xref>), a view so far based on evidence collected with face stimuli only (<xref ref-type="bibr" rid="bib9">de Schonen and Mathivet, 1990</xref>; <xref ref-type="bibr" rid="bib50">Tzourio-Mazoyer et al., 2002</xref>; <xref ref-type="bibr" rid="bib28">Le Grand et al., 2003</xref>) or by comparing faces to meaningless stimuli that also differ in terms of low-level visual cues (<xref ref-type="bibr" rid="bib50">Tzourio-Mazoyer et al., 2002</xref>; <xref ref-type="bibr" rid="bib27">Kouider et al., 2013</xref>).</p><p>What is the origin of this early face-selective response? Some authors have suggested a face-processing module pre-specified in the genome (<xref ref-type="bibr" rid="bib13">Farah et al., 2000</xref>), compatible with newborns' preferential looking behavior for face patterns at birth (<xref ref-type="bibr" rid="bib18">Goren et al., 1975</xref>; <xref ref-type="bibr" rid="bib24">Johnson and Morton, 1991</xref>; but see; <xref ref-type="bibr" rid="bib49">Turati et al., 2002</xref>). However, infants are already extensively exposed to faces after a few months of life. Hence, face-selective responses observed here in 4–6 month-old infants may originate from a combination of initial biological constraints and of accumulation of visual experience with faces during early development. Neuroimaging studies in children show that the magnitude of face-selective neural responses is not adult-like at 7 years of age and keeps increasing until adolescence (<xref ref-type="bibr" rid="bib16">Golarai et al., 2007</xref>, <xref ref-type="bibr" rid="bib17">2010</xref>; <xref ref-type="bibr" rid="bib44">Scherf et al., 2007</xref>), suggesting that face-selectivity continues to increase during development. Given its advantages in terms of sensitivity, implicit recording and objectivity (i.e., measuring brain responses at a known, exact rate of periodic stimulation), the FPVS approach used here with electroencephalography is well positioned to test this hypothesis and characterize the full human developmental course of face processing and natural visual scene categorization.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experiment 1</title><sec id="s4-1-1"><title>Participants</title><p>Nineteen full-term 4- to 6-month-old infants completed Experiment 1 approved by the Biomedical Ethical Committee from the University of Louvain (Belgian number: B403201215103). Their parents gave written informed consent and none of them reported their infant suffering from any psychiatric or neurological disorders. The data of one infant were excluded because of large artifacts recorded at one channel of interest (P8) during the whole experiment. Three infants paid fully attention only to one sequence and were therefore excluded from the study. Thus, the final sample consisted of 15 healthy full-term 4- to 6-month-old infants (10 males, mean age = 155 days, SE = 6 days). Note that a rejection rate of 4 datasets out of 19 is extremely low compared to typical EEG studies run with infants of that age, requiring much longer testing durations and a data rejection rate of at least 50% (e.g., <xref ref-type="bibr" rid="bib7">de Haan and Nelson, 1999</xref>).</p></sec><sec id="s4-1-2"><title>Stimuli</title><p>Two-hundred images of various objects (animals, plants, man-made objects) and 48 images of faces were collected from the internet. They differed in terms of color, viewpoint, lighting conditions, and background (<xref ref-type="fig" rid="fig1">Figure 1</xref>). They were all resized to 200 × 200 pixels, equalized in terms of luminance and contrast in Matlab (Mathworks, USA), and shown in the center of the screen at a 800 × 600 pixel resolution. At a testing distance of 40 cm, they subtended approximately 13 by 13° of visual angle. The same stimuli were used in grayscale versions and with a slightly different stimulation paradigm in a recent study with adults (<xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>).</p></sec><sec id="s4-1-3"><title>Procedure</title><p>Stimuli were presented through sinusoidal contrast modulation (0–100%) at a rate of 6 Hz (6 images/s) using the Psychtoolbox 3.0.9 for Windows in Matlab 7.6 (MathWorks Inc.). This base stimulation frequency rate was selected because it elicits large periodic brain responses to faces in adults (<xref ref-type="bibr" rid="bib35">Alonso-Prieto et al., 2013</xref>). The stimulation cycle of each image presentation therefore lasted 166.66 ms (1000 ms/6) and started with a uniform grey background. A sinusoidal contrast modulation was used because it generates fewer harmonics (i.e., responses at exact multiple of the stimulation frequency, reflecting the nonlinearity of the brain response; <xref ref-type="bibr" rid="bib37">Regan, 1989</xref>; <xref ref-type="bibr" rid="bib31">Norcia et al., 2015</xref>) and because it is a smoother visual stimulation than a squarewave stimulation mode. Full contrast was reached midway through each cycle, that is, at 83.33 ms from cycle onset. Each sequence was composed of 4 objects (O) followed, every fifth stimulus, by a face (F), all randomly selected from their respective category (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Given this design, the face (F) stimulus was presented at the oddball frequency of 6 Hz/5 = 1.2 Hz and could be directly identified in the EEG spectrum as the signature of infants' face categorization response. Each trial lasted 20 s and was flanked by a 2-s fade-in and a 2-s fade-out, at the beginning and at the end of the sequence, respectively. This linear increase/decrease of contrast modulation depth at the beginning and end of each stimulation sequence was used to avoid abrupt onset and offset of the stimuli, which could elicit eye movements.</p><p>Infants were comfortably seated on their mother's laps (N = 5) or in a car seat (N = 10) in a dimly lit and sound-attenuated room during EEG recording. The mothers were instructed not to interact with their babies. Infants viewed between 5 and 12 trials during the experiment and therefore performed between 1 min and 40 s and 4 min of experimentation overall.</p></sec><sec id="s4-1-4"><title>EEG acquisition</title><p>EEG was acquired using a 32-channel BioSemi Active 2 system (BioSemi, Amsterdam, Netherlands), with electrodes including standard 10–20 system locations as well as 2 additional reference electrodes (<ext-link ext-link-type="uri" xlink:href="http://www.biosemi.com/">http://www.biosemi.com/</ext-link>). Electrode offset was reduced to between ±25 microvolts for each individual electrode by injecting the electrode with saline gel. Eye movements were monitored with a webcam fixed on the computer screen. The experimenter manually launched each sequence when the infant looked at the back-lit screen. If the infant did not look at the screen, the experimenter would attract his/her gaze towards it in between the stimulation sequences by means of her voice or of a ringing colored toy. During the experiment, triggers were sent from the stimulation computer through a parallel port to the recording computer at the start of each trial and at the minima of each stimulation cycle (grey background, 0% contrast) for the object (O) stimulus and the oddball face (F) stimulus.</p></sec><sec id="s4-1-5"><title>EEG analyses pre-processing</title><p>All EEG analyses were carried out using Letswave 5 (<ext-link ext-link-type="uri" xlink:href="http://nocions.webnode.com/letswave">http://nocions.webnode.com/letswave</ext-link>), and MATLAB 2012 (The Mathworks) following procedures described with adult participants (e.g., <xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>). EEG sequences could be removed because of (1) a technical problem during recording; (2) an electrode went off during recording; or (3) because the infant did not fixate for the majority of the 20 s. Additionally, the sequence was removed if the SNR was below 2 for the base rate frequency at all medial occipital electrodes Oz, O1, and O2. These criteria led to 1 to 5 sequences excluded per infant. As long as an infant performed one stimulation sequence satisfying these criteria, his/her data was considered into the analyses. EEG data were first filtered with a low cut-off value of 0.1 Hz and high cut-off value of 100 Hz using a FFT band-pass filter. They were then downsampled to 250 Hz to reduce file size and data processing time, and segmented in order to include 2 s of recording before and after each trial. The 28-s long sequences (i.e., 2-s baseline + 2-s fade-in + 20-s sequence + 2-s fade-out + 2-s baseline) were further examined in the time domain for possible channel artifacts. Only one electrode interpolation per infant had to be applied on the sequences of 3 infants only. A common average reference computation was applied to all channels.</p><p>After data pre-processing, the 28-s segments were reduced to the 20-s full contrast stimulation sequence, which is an integer number of 1.2 Hz cycles (i.e., 24 cycles, or 24 faces). Sequences were then averaged in the time-domain for each infant separately and examined for their amplitude spectra at all channels, which led to the exclusion of 8 noisy sequences over the whole group of infants. This preprocessed dataset is available in the public domain (<xref ref-type="bibr" rid="bib8">de Heering and Rossion, 2013</xref>). A Fast Fourier Transform (FFT) was then applied to the data for examination in the EEG frequency-domain at the high frequency resolution of 0.05 Hz (=1/20 s). Grand-averaged spectra were computed by averaging the EEG spectra of all individual infants tested. SNR was computed for each individual spectrum as the ratio between the amplitude at each frequency and the average of the 20 surrounding bins (10 on each side, excluding the immediate adjacent bin) (<xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>). On grand-averaged data, Z-Scores were computed at 6 Hz and 1.2 Hz as the difference between amplitude at the frequency of interest and the mean amplitude of 20 surrounding bins divided by the standard deviation of the 20 surrounding bins (<xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>). Given that the hypothesis is that the signal is above the noise, the threshold of significance was placed at a one-tailed Z-score of 1.64 (p &lt; 0.05). In Experiment 1, a test at all 32 electrodes on grand-averaged data was performed and a bonferroni corrected p-value of p &lt; 0.00156 (0.05/32) was considered to isolate the significant channels. Five channels reached significance (Table in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1A</xref>). To ensure that an effect was not due to a small subset of infants, <italic>t</italic>-tests against noise level (i.e., SNR = 1) were performed using individual infants' SNR values at the frequencies of interest.</p></sec></sec><sec id="s4-2"><title>Experiment 2</title><sec id="s4-2-1"><title>Participants</title><p>Eleven full-term 4- to 6-month-old infants completed Experiment 2 approved by the same Biomedical Ethical Committee. Parents all gave written informed consent from and none of them reported their infant as suffering from any psychiatric or neurological disorders. One infant did not look at the screen at all and was excluded from the sample. The final sample consisted of 10 healthy full-term 4- to 6-month-old infants (6 males, mean age = 163 days, SE = 7.5 days).</p></sec><sec id="s4-2-2"><title>Stimuli</title><p>The stimuli were identical to those used in Experiment 1 and their phase-scrambled versions were created by randomly phase-scrambling their power-spectrum.</p></sec><sec id="s4-2-3"><title>Procedure</title><p>The experiment consisted of 20-s identical periodic sequences to those used in Experiment 1, randomly alternating with 20-s phase-scrambled sequences. Consistently with Experiment 1, images were presented in the center of the screen in sinusoids (sinusoidal contrast modulation) at 6 Hz (6 images/s) with the oddball stimulus appearing every fifth stimulus, that is, at the rate of 1.2 Hz. As in experiment 1, EEG sequences could be removed because of (1) a technical problem during recording; (2) an electrode went off during recording; or (3) because the infant did not fixate for the majority of the 20 s. Additionally, the sequence was removed if the SNR was below 2 for the base rate frequency at all medial occipital electrodes Oz, O1, and O2. These criteria led to 1 to 8 sequences excluded per infant. In this experiment, infants viewed overall between 2 and 12 trials. The experiment lasted therefore between 40 s to 4 min. Only one channel, for one infant's dataset, had to be interpolated.</p></sec><sec id="s4-2-4"><title>EEG acquisition</title><p>EEG acquisition parameters were the same as described in Experiment 1.</p></sec><sec id="s4-2-5"><title>EEG analyses</title><p>EEG analyses were the same as described in Experiment 1. The pre-processed dataset is also available in the public domain (<xref ref-type="bibr" rid="bib8">de Heering and Rossion, 2013</xref>). Since the sample was smaller than in Experiment 1 and there were only half of the sequences tested for natural images, SNR was lower than in Experiment 1. The a priori hypothesis, based on Experiment 1, was to find a 1.2 Hz response on P8, which was tested at the significance threshold of p &lt; 0.05 on grand-averaged data. P8 was the only electrode reaching significance (Table in <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1B</xref>; Z = 2.01, p &lt; 0.015).</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>C Danneau and A Dor helped recruiting and testing infants, G Van Belle and C Jacques to set up the stimulation, T Retter to collect stimuli and edit the paper. This research was supported by the FNRS (Belgian National Fund for Scientific Research) and an ERC grant (facessvep 284025).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>AH, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>BR, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent, and consent to publish, was obtained by the parents of the infants tested. The Biomedical Ethical Committee from the University of Louvain (Belgian number: B403201215103) covered the study.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.06564.011</object-id><label>Supplementary file 1.</label><caption><p>Table 1A. All 32 electrodes from Experiment 1, ranked by significance (p &lt; 0.05, Bonferroni corrected for the number of channels: p &lt; 0.00156, Z &gt; 2.94). Significant responses were recorded at 5 channels on grand averaged data. Table 1B. All 32 electrodes from Experiment 2 ranked by significance. A significant response (p &lt; 0.01, uncorrected) was recorded at channel P8, only for natural images.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.06564.011">http://dx.doi.org/10.7554/eLife.06564.011</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-06564-supp1-v1.docx"/></supplementary-material><sec id="s6-1" sec-type="datasets"><title>Major dataset</title><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="dataro1" source-id="http://dx.doi.org/10.5061/dryad.c8t69" source-id-type="uri"><collab collab-type="author">de Heering A</collab>, <collab collab-type="author">Rossion B</collab>, <year>2013</year><x>, </x><source>Data from: Rapid Categorization of Natural Face Images in the Infant Right Hemisphere</source><x>, </x><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.c8t69">http://dx.doi.org/10.5061/dryad.c8t69</ext-link><x>, </x><comment>Available at Dryad Digital Repository under a CC0 Public Domain Dedication.</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonso-Prieto</surname><given-names>E</given-names></name><name><surname>Belle</surname><given-names>GV</given-names></name><name><surname>Liu-Shuang</surname><given-names>J</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2013</year><article-title>The 6Hz fundamental frequency rate for individual face discrimination in the right occipito-temporal cortex</article-title><source>Neuropsychologia</source><volume>51</volume><fpage>2863</fpage><lpage>2875</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.08.018</pub-id></element-citation></ref><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Appelbaum</surname><given-names>LG</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Vildavski</surname><given-names>VY</given-names></name><name><surname>Pettet</surname><given-names>MW</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name></person-group><year>2006</year><article-title>Cue-invariant networks for figure and background processing in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>11695</fpage><lpage>11708</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2741-06.2006</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barton</surname><given-names>JJ</given-names></name><name><surname>Press</surname><given-names>DZ</given-names></name><name><surname>Keenan</surname><given-names>JP</given-names></name><name><surname>O'Connor</surname><given-names>M</given-names></name></person-group><year>2002</year><article-title>Lesions of the fusiform face area impair perception of facial configuration in prosopagnosia</article-title><source>Neurology</source><volume>58</volume><fpage>71</fpage><lpage>78</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braddick</surname><given-names>OJ</given-names></name><name><surname>Wattam-Bell</surname><given-names>J</given-names></name><name><surname>Atkinson</surname><given-names>J</given-names></name></person-group><year>1986</year><article-title>Orientation-specific cortical responses develop in early infancy</article-title><source>Nature</source><volume>320</volume><fpage>617</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1038/320617a0</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busigny</surname><given-names>T</given-names></name><name><surname>Joubert</surname><given-names>S</given-names></name><name><surname>Felician</surname><given-names>O</given-names></name><name><surname>Ceccaldi</surname><given-names>M</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2010</year><article-title>Holistic perception of the individual face is specific and necessary: evidence from an extensive case study of acquired prosopagnosia</article-title><source>Neuropsychologia</source><volume>48</volume><fpage>4057</fpage><lpage>4092</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.09.017</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantlon</surname><given-names>JF</given-names></name><name><surname>Pinel</surname><given-names>P</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Pelphrey</surname><given-names>K</given-names></name></person-group><year>2011</year><article-title>Cortical representations of symbols, objects, and faces are pruned back during early childhood</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>191</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq078</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crouzet</surname><given-names>SM</given-names></name><name><surname>Kirchner</surname><given-names>H</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group><year>2010</year><article-title>Fast saccades towards faces: face detection in just 100 ms</article-title><source>Journal of Vision</source><volume>10</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1167/10.4.16</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Haan</surname><given-names>M</given-names></name><name><surname>Nelson</surname><given-names>CA</given-names></name></person-group><year>1999</year><article-title>Brain activity differentiates face and object processing in 6-month-old infants</article-title><source>Developmental Psychology</source><volume>35</volume><fpage>1113</fpage><lpage>1121</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.35.4.1113</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Heering</surname><given-names>A</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2013</year><article-title>Infant EEG recordings–preprocessed data</article-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.c8t69</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Schonen</surname><given-names>S</given-names></name><name><surname>Mathivet</surname><given-names>E</given-names></name></person-group><year>1990</year><article-title>Hemispheric asymmetry in a face discrimination task in infants</article-title><source>Child Development</source><volume>61</volume><fpage>1192</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8624.1990.tb02853.x</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Pegado</surname><given-names>F</given-names></name><name><surname>Braga</surname><given-names>LW</given-names></name><name><surname>Ventura</surname><given-names>P</given-names></name><name><surname>Nunes Filho</surname><given-names>G</given-names></name><name><surname>Jobert</surname><given-names>A</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name><name><surname>Kolinsky</surname><given-names>R</given-names></name><name><surname>Morais</surname><given-names>J</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name></person-group><year>2010</year><article-title>How learning to read changes the cortical networks for vision and language</article-title><source>Science</source><volume>330</volume><fpage>1359</fpage><lpage>1364</lpage><pub-id pub-id-type="doi">10.1126/science.1194140</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dundas</surname><given-names>EM</given-names></name><name><surname>Plaut</surname><given-names>DC</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><year>2013</year><article-title>The joint development of hemispheric lateralization for words and faces</article-title><source>Journal of Experimental Psychology General</source><volume>142</volume><fpage>348</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1037/a0029503</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dundas</surname><given-names>EM</given-names></name><name><surname>Plaut</surname><given-names>DC</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><year>2014</year><article-title>An ERP investigation of the co-development of hemispheric lateralization of face and word recognition</article-title><source>Neuropsychologia</source><volume>61</volume><fpage>315</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.05.006</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farah</surname><given-names>MJ</given-names></name><name><surname>Rabinowitz</surname><given-names>C</given-names></name><name><surname>Quinn</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>GT</given-names></name></person-group><year>2000</year><article-title>Early commitment of neural substrates for face recognition</article-title><source>Cognitive Neuropsychology</source><volume>17</volume><fpage>117</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1080/026432900380526</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farzin</surname><given-names>F</given-names></name><name><surname>Hou</surname><given-names>C</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name></person-group><year>2012</year><article-title>Piecing it together: infants' neural responses to face and object structure</article-title><source>Journal of Vision</source><volume>12</volume><fpage>6</fpage><pub-id pub-id-type="doi">10.1167/12.13.6</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gliga</surname><given-names>T</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group><year>2007</year><article-title>Development of a view-invariant representation of the human head</article-title><source>Cognition</source><volume>102</volume><fpage>261</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2006.01.004</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golarai</surname><given-names>G</given-names></name><name><surname>Ghahremani</surname><given-names>DG</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name><name><surname>Reiss</surname><given-names>A</given-names></name><name><surname>Eberhardt</surname><given-names>JL</given-names></name><name><surname>Gabrieli</surname><given-names>JD</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name></person-group><year>2007</year><article-title>Differential development of high-level visual cortex correlates with category-specific recognition memory</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>512</fpage><lpage>522</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golarai</surname><given-names>A</given-names></name><name><surname>Liberman</surname><given-names>JM</given-names></name><name><surname>Yoon</surname><given-names>K</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name></person-group><year>2010</year><article-title>Differential development of the ventral visual cortex extends through adolescence</article-title><source>Frontiers in Human Neuroscience</source><volume>3</volume><fpage>80</fpage><pub-id pub-id-type="doi">10.3389/neuro.09.080.2009</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goren</surname><given-names>CC</given-names></name><name><surname>Sarty</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>PY</given-names></name></person-group><year>1975</year><article-title>Visual following and pattern discrimination of face-like stimuli by newborn infants</article-title><source>Pediatrics</source><volume>56</volume><fpage>544</fpage><lpage>549</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halit</surname><given-names>H</given-names></name><name><surname>Csibra</surname><given-names>G</given-names></name><name><surname>Volein</surname><given-names>A</given-names></name><name><surname>Johnson</surname><given-names>MH</given-names></name></person-group><year>2004</year><article-title>Face-sensitive cortical processing in early infancy</article-title><source>Journal of Child Psychology and Psychiatry, and Allied Disciplines</source><volume>45</volume><fpage>1228</fpage><lpage>1234</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7610.2004.00321.x</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Hoffman</surname><given-names>EA</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><year>2000</year><article-title>The distributed human neural system for face perception</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>223</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01482-0</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hecaen</surname><given-names>H</given-names></name><name><surname>Angelergues</surname><given-names>R</given-names></name></person-group><year>1962</year><article-title>Agnosia for faces (prosopagnosia)</article-title><source>Archives of Neurology</source><volume>7</volume><fpage>92</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1001/archneur.1962.04210020014002</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>SP</given-names></name><name><surname>Mell</surname><given-names>D</given-names></name><name><surname>Bach</surname><given-names>M</given-names></name></person-group><year>2009</year><article-title>Frequency-domain analysis of fast oddball responses to visual stimuli: a feasibility study</article-title><source>International Journal of Psychophysiology</source><volume>73</volume><fpage>287</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2009.04.011</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hillger</surname><given-names>LA</given-names></name><name><surname>Koenig</surname><given-names>O</given-names></name></person-group><year>1991</year><article-title>Separable mechanisms in face processing: evidence from hemispheric specialization</article-title><source>Journal of Cognitive Neuroscience</source><volume>3</volume><fpage>42</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1162/jocn.1991.3.1.42</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>MH</given-names></name><name><surname>Morton</surname><given-names>J</given-names></name></person-group><year>1991</year><source>Biology and cognitive development: the case of face recognition</source><publisher-loc>Oxford, UK</publisher-loc><publisher-name>Blackwell</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><year>1997</year><article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayashi</surname><given-names>M</given-names></name><name><surname>Otsuka</surname><given-names>Y</given-names></name><name><surname>Nakato</surname><given-names>E</given-names></name><name><surname>Kanazawa</surname><given-names>S</given-names></name><name><surname>Yamaguchi</surname><given-names>MK</given-names></name><name><surname>Kakigi</surname><given-names>R</given-names></name></person-group><year>2011</year><article-title>Do infants recognize the Arcimboldo images as faces? Behavioral and near-infrared spectroscopic study</article-title><source>Journal of Experimental Child Psychology</source><volume>111</volume><fpage>22</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/j.jecp.2011.07.008</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kouider</surname><given-names>S</given-names></name><name><surname>Stahlhut</surname><given-names>C</given-names></name><name><surname>Gelskov</surname><given-names>SV</given-names></name><name><surname>Barbosa</surname><given-names>LS</given-names></name><name><surname>Dutat</surname><given-names>M</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Christophe</surname><given-names>A</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group><year>2013</year><article-title>A neural Marker of perceptual consciousness in infants</article-title><source>Science</source><volume>340</volume><fpage>376</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1126/science.1232509</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Grand</surname><given-names>R</given-names></name><name><surname>Mondloch</surname><given-names>CJ</given-names></name><name><surname>Maurer</surname><given-names>D</given-names></name><name><surname>Brent</surname><given-names>HP</given-names></name></person-group><year>2003</year><article-title>Expert face processing requires visual input to the right hemisphere during infancy</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1108</fpage><lpage>1112</lpage><pub-id pub-id-type="doi">10.1038/nn1121</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>FF</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><year>2002</year><article-title>Rapid natural scene categorization in the near absence of attention</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>99</volume><fpage>9596</fpage><lpage>9601</lpage><pub-id pub-id-type="doi">10.1073/pnas.092277599</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu-Shuang</surname><given-names>J</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2014</year><article-title>An objective index of individual face discrimination in the right occipito-temporal cortex by means of fast periodic oddball stimulation</article-title><source>Neuropsychologia</source><volume>52</volume><fpage>57</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.10.022</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Appelbaum</surname><given-names>G</given-names></name><name><surname>Ales</surname><given-names>J</given-names></name><name><surname>Cottereau</surname><given-names>B</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2015</year><article-title>The steady-state visual evoked potential in vision research: a review</article-title><source>Journal of Vision</source><volume>15</volume><fpage>4</fpage><pub-id pub-id-type="doi">10.1167/15.6.4</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Tyler</surname><given-names>CW</given-names></name><name><surname>Hamer</surname><given-names>RD</given-names></name></person-group><year>1990</year><article-title>Development of contrast sensitivity in the human infant</article-title><source>Vision Research</source><volume>30</volume><fpage>1475</fpage><lpage>1486</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(90)90028-J</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>MA</given-names></name></person-group><year>2014</year><article-title>Low-level and high-level contributions to figure-ground organization: evidence and theoretical implications</article-title><person-group person-group-type="editor"><name><surname>Wagemans</surname><given-names>J</given-names></name></person-group><source>The oxford handbook of perceptual organization</source><publisher-loc>NY</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peykarjou</surname><given-names>S</given-names></name><name><surname>Hoehl</surname><given-names>S</given-names></name></person-group><year>2013</year><article-title>Three-month-olds’ brain responses to upright and inverted faces and cars</article-title><source>Developmental Neuropsychology</source><volume>38</volume><fpage>272</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1080/87565641.2013.786719</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puce</surname><given-names>A</given-names></name><name><surname>Allison</surname><given-names>T</given-names></name><name><surname>Gore</surname><given-names>JC</given-names></name><name><surname>McCarthy</surname><given-names>G</given-names></name></person-group><year>1995</year><article-title>Face-sensitive regions in human extrastriate cortex studied by functional MRI</article-title><source>Journal of Neurophysiology</source><volume>74</volume><fpage>1192</fpage><lpage>1199</lpage></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D</given-names></name></person-group><year>1989</year><source>Human brain electrophysiology: evoked potentials and evoked magnetic fields in science and medicine</source><publisher-loc>New York</publisher-loc><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosch</surname><given-names>E</given-names></name></person-group><year>2007</year><article-title>Human categorization</article-title><person-group person-group-type="editor"><name><surname>Warren</surname><given-names>N</given-names></name></person-group><source>Advances in cross-cultural psychology</source><publisher-loc>London, UK</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>1</fpage><lpage>72</lpage></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year>2014</year><article-title>Understanding face perception by means of human electrophysiology</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>310</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.02.013</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Caharel</surname><given-names>S</given-names></name></person-group><year>2011</year><article-title>ERP evidence for the speed of face categorization in the human brain: disentangling the contribution of low-level visual cues from face perception</article-title><source>Vision Research</source><volume>51</volume><fpage>1297</fpage><lpage>1311</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.04.003</pub-id></element-citation></ref><ref id="bib40a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Hanseeuw</surname><given-names>B</given-names></name><name><surname>Dricot</surname><given-names>L</given-names></name></person-group><year>2012</year><article-title>Defining face perception areas in the human brain: a large-scale factorial fMRI face localizer analysis</article-title><source>Brain and Cognition</source><volume>79</volume><fpage>138</fpage><lpage>157</lpage></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Jacques</surname><given-names>C</given-names></name><name><surname>Torfs</surname><given-names>K</given-names></name><name><surname>Liu-Shuang</surname><given-names>J</given-names></name></person-group><year>2015</year><article-title>Fast periodic presentation of natural images reveals a robust face-selective electrophysiological response in the human brain</article-title><source>Journal of Vision</source><volume>15</volume><fpage>15.1.18</fpage><pub-id pub-id-type="doi">10.1167/15.1.18</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadr</surname><given-names>J</given-names></name><name><surname>Sinha</surname><given-names>P</given-names></name></person-group><year>2004</year><article-title>Object recognition and random image structure evolution</article-title><source>Cognitive Science</source><volume>28</volume><fpage>259</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog2802_7</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheirer</surname><given-names>WJ</given-names></name><name><surname>de Rezende Rocha</surname><given-names>A</given-names></name><name><surname>Sapkota</surname><given-names>A</given-names></name><name><surname>Boult</surname><given-names>TE</given-names></name></person-group><year>2014</year><article-title>Perceptual annotation: measuring human vision to improve computer vision</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>36</volume><fpage>1679</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2013.2297711</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scherf</surname><given-names>KS</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name><name><surname>Humphreys</surname><given-names>K</given-names></name><name><surname>Luna</surname><given-names>B</given-names></name></person-group><year>2007</year><article-title>Visual category-selectivity for faces, places and objects emerges along different developmental trajectories</article-title><source>Developmental Science</source><volume>10</volume><fpage>F15</fpage><lpage>F30</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2007.00595.x</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergent</surname><given-names>J</given-names></name><name><surname>Ohta</surname><given-names>S</given-names></name><name><surname>MacDonald</surname><given-names>B</given-names></name></person-group><year>1992</year><article-title>Functional neuroanatomy of face and object processing. A positron emission tomography study</article-title><source>Brain</source><volume>115</volume><fpage>15</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1093/brain/115.1.15</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergent</surname><given-names>J</given-names></name><name><surname>Signoret</surname><given-names>JL</given-names></name></person-group><year>1992</year><article-title>Varieties of functional deficits in prosopagnosia</article-title><source>Cerebral Cortex</source><volume>2</volume><fpage>375</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1093/cercor/2.5.375</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorpe</surname><given-names>S</given-names></name><name><surname>Fize</surname><given-names>D</given-names></name><name><surname>Marlot</surname><given-names>C</given-names></name></person-group><year>1996</year><article-title>Speed of processing in the human visual system</article-title><source>Nature</source><volume>381</volume><fpage>520</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1038/381520a0</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>DY</given-names></name><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name></person-group><year>2008</year><article-title>Comparing face patch systems in macaques and humans</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>9</volume><fpage>19514</fpage><lpage>19519</lpage><pub-id pub-id-type="doi">10.1073/pnas.0809662105</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turati</surname><given-names>C</given-names></name><name><surname>Simion</surname><given-names>F</given-names></name><name><surname>Milani</surname><given-names>I</given-names></name><name><surname>Umiltà</surname><given-names>C</given-names></name></person-group><year>2002</year><article-title>Newborns' preference for faces: what is crucial?</article-title><source>Developmental Psychology</source><volume>38</volume><fpage>875</fpage><lpage>882</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.38.6.875</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N</given-names></name><name><surname>De Schonen</surname><given-names>S</given-names></name><name><surname>Crivello</surname><given-names>F</given-names></name><name><surname>Reutter</surname><given-names>B</given-names></name><name><surname>Aujard</surname><given-names>Y</given-names></name><name><surname>Mazoyer</surname><given-names>B</given-names></name></person-group><year>2002</year><article-title>Neural correlates of woman face processing by 2-month-old infants</article-title><source>Neuroimage</source><volume>15</volume><fpage>454</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0979</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiner</surname><given-names>KS</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name></person-group><year>2013</year><article-title>Neural representations of faces and limbs neighbor in human high-level visual cortex: evidence for a new organization principle</article-title><source>Psychological Research</source><volume>77</volume><fpage>74</fpage><lpage>97</lpage></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.06564.012</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Culham</surname><given-names>Jody C</given-names></name><role>Reviewing editor</role><aff><institution>University of Western Ontario</institution>, <country>Canada</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled “Rapid Categorization of Natural Face Images in the Infant Right Hemisphere” for consideration at <italic>eLife</italic>. Your article has been favorably evaluated by a Senior editor and three reviewers, one of whom, Jody Culham, is a member of our Board of Reviewing Editors.</p><p>The Reviewing editor and the other reviewers discussed their comments before we reached this decision, and the Reviewing editor has assembled the following comments to help you prepare a revised submission.</p><p>All three reviewers were very positive about the manuscript, finding the approach interesting and the results intriguing.</p><p>One reviewer requested a number of clarifications regarding the statistics and technical aspects (these were straightforward and are appended below). These should be addressed in a revision.</p><p>Specific points:</p><p>1) In the Results section, it is not clear why/when the authors chose to use <italic>t</italic>-tests versus <italic>z</italic>-tests. For example, in the third paragraph, a <italic>t-</italic>test is reported for the group-level SNR at the 6 Hz frequency. In the following paragraph, a <italic>z</italic>-test is reported for the group-level SNR at the 1.2 Hz frequency. Adding a description to the beginning of the Results section describing the statistics used (and why) would be helpful. Please clarify in the text; preferably at the beginning of the Results section which analyses required a <italic>t</italic>-test versus a <italic>z</italic>-test (particularly for grand-averaged data). A general outline of the statistics used, and why, would be helpful for those planning to use this technique in the future.</p><p>2) Please provide clarification on the meaning of the SNR ranges that are reported across all infants. For example, in the Results section, the authors state: “For 12 infants out of 15 it is above noise level (SNR range at P8: 0.52-6.13).” My understanding is that a SNR = 1.0 is the base of comparison to determine whether a response is above noise level. However, in the above sentence, the provided range includes values below 1.0. Please clarify what this range is referring to, as it does not appear to be the range for infants whose responses were significantly above noise level?</p><p>3) At the end of the subsection headed “Experiment 2: replication and exclusion of low-level contributions”, the authors report that the magnitude of the base frequency (6 Hz) response was “significant for every infant and did not differ between conditions (t(9) = 1.103, p = .3; <xref ref-type="fig" rid="fig4">Figure 4</xref>).” It appears that the <italic>t</italic>-test is referring to the comparison between conditions? Could the authors please provide the statistics for the statement that the magnitude was significant for every infant as was done in the fifth paragraph of the Results?</p><p>4) I think a strong point of this paper is that the authors report statistics for grand-averaged data as well as for individual infants. This demonstrates that the ssVEP responses are relatively consistently seen across infants and that 1-2 infants are not driving the results. However, the current organization of the Results section causes the reader to constantly switch back and forth between statistics for grand-averaged data and for individual infant data. The authors might consider reformatting these sections to make this clearer. For example, it may be beneficial to have labeled subsections devoted to grand averaged data and individual infant data.</p><p>5) The authors do not report an impedance limit for the EEG recording, which is typically listed in ERP papers as well as previous adult ssVEP papers (e.g., <xref ref-type="bibr" rid="bib35">Prieto et al., 2013</xref>; Rossion &amp; Boremanse, 2011) and a previous infant ssVEP paper (<xref ref-type="bibr" rid="bib14">Farzin, Hou, &amp; Norcia, 2012</xref>). Adding this limit is helpful for those trying to use this method in the future.</p><p>6) In the “EEG Analyses Pre-processing” section the authors state that 1-5 sequences were excluded per infant with the 2 listed criteria applied. Does this means that each infant in the final analyses had between 1-5 sequences excluded due to these criteria? What was the minimum number of sequences required to be included in analyses? In the beginning of the Results section, the authors note that all infants completed a minimum of 5 sequences, but as written, this suggests that all infants who participated completed at least 5 sequences, before any sequence exclusion criteria were applied. Can the authors add the minimum number of sequences necessary for an infant's data to be kept in analyses? If this cutoff is 5, please clarify whether the infants who only viewed 5 sequences also had at least 1 sequence excluded. If so, should these infants have not been kept in the analyses?</p><p>7) In the subsection headed “EEG analyses Pre-processing”, the authors state that data were “downsampled to 250 Hz”. Why was this done? What was the original sample rate?</p><p>8) The “Experiment 2, the Analyses Pre-processing” section should contain more details on how many sequences per infant were removed based on the exclusion criteria, following the format of the Experiment 1's section.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.06564.013</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>1) In the Results section, it is not clear why/when the authors chose to use</italic> t<italic>-tests versus</italic> z<italic>-tests. For example, in the third paragraph, a</italic> t<italic>-test is reported for the group-level SNR at the 6 Hz frequency. In the following paragraph, a</italic> z<italic>-test is reported for the group-level SNR at the 1.2 Hz frequency. Adding a description to the beginning of the Results section describing the statistics used (and why) would be helpful. Please clarify in the text; preferably at the beginning of the Results section which analyses required a</italic> t<italic>-test versus a</italic> z<italic>-test (particularly for grand averaged data). A general outline of the statistics used, and why, would be helpful for those planning to use this technique in the future</italic>.</p><p>This is a good point, and this ambiguity arose because we did not specify the Z-score at 6 Hz in Experiment 1, but also because the Methods section is at the end of the paper. As in our previous studies in adults with this approach (fast periodic oddball stimulation in EEG, e.g., <xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>; Dzhelyova and Rossion, 2014; <xref ref-type="bibr" rid="bib41">Rossion et al., 2015</xref>), a Z-score is computed on grand-averaged data to define significant electrodes. The Z-score procedure is explained in the Methods (in the subsection headed “EEG analyses Pre-processing”) and we refer to the first (adult) study that used this approach (<xref ref-type="bibr" rid="bib30">Liu-Shuang et al., 2014</xref>): “On grand-averaged data, Z-Scores were computed at 6 Hz and 1.2 Hz as the difference between amplitude at the frequency of interest and the mean amplitude of 20 surrounding bins divided by the standard deviation of the 20 surrounding bins. Given that the hypothesis is that the signal is above the noise, the threshold of significance was placed at a one-tailed Z-score of 1.64 (p &lt; .05).”</p><p>For consistency in the revised version of the manuscript, we report the group Z-score at both 1.2 Hz (P8: Z = 12.16, p&lt; .001) and 6 Hz (Oz: Z = 52.9, p&lt; .00001), for both experiments. We also explain at the beginning of the Results section, the Z-score procedure and the different statistical tests used.</p><p><italic>2) Please provide clarification on the meaning of the SNR ranges that are reported across all infants. For example, in the Results section, the authors state: “For 12 infants out of 15 it is above noise level (SNR range at P8: 0.52-6.13).” My understanding is that a SNR = 1.0 is the base of comparison to determine whether a response is above noise level. However, in the above sentence, the provided range includes values below 1.0. Please clarify what this range is referring to</italic>, <italic>as it does not appear to be the range for infants whose responses were significantly above noise level?</italic></p><p>This was confusing indeed. In the parenthesis, we provided the SNR range for all 15 infants, and 3 infants out of 15 have a SNR below 1 at P8 (i.e., no signal above noise level). In the revised version, in the subsection “Isolation of a face-selective right hemispheric response”, we have clarified this: SNR range of all 15 infants at P8.</p><p><italic>3) At the end of the subsection headed “Experiment 2: replication and exclusion of low-level contributions”, the authors report that the magnitude of the base frequency (6 Hz) response was “significant for every infant and did not differ between conditions (t(9) = 1.103, p = .3;</italic> <xref ref-type="fig" rid="fig4"><italic>Figure 4</italic></xref><italic>).” It appears that the</italic> t<italic>-test is referring to the comparison between conditions? Could the authors please provide the statistics for the statement that the magnitude was significant for every infant as was done in the fifth paragraph of the Results?</italic></p><p>As for Experiment 1, we added that: “This response at channel Oz was significant for every infant in each of the conditions (Z-score range of 10 infants for natural images: 1.66 – 29.58 and for scrambled images: 2.81- 27.76; SNR range for natural images: 1.9 - 13.65 and for scrambled images: 2.57–13.55).”</p><p><italic>4) I think a strong point of this paper is that the authors report statistics for grand averaged data as well as for individual infants. This demonstrates that the ssVEP responses are relatively consistently seen across infants and that 1-2 infants are not driving the results. However, the current organization of the Results section causes the reader to constantly switch back and forth between statistics for grand averaged data and for individual infant data. The authors might consider reformatting these sections to make this clearer. For example, it may be beneficial to have labeled subsections devoted to grand averaged data and individual infant data</italic>.</p><p>Indeed, the approach allows reporting statistics for grand-averaged data, using the variation across the many frequency bins around the frequency bin of interest. However, such an effect could be driven by 1-2 infants having a response well above noise level, so that it is important to complement it by an analysis that takes into account the variability across infants at the frequency bin of interest only. In addition, we are in a position to run a statistical test in each individual infant using an estimation of the noise across 20 bins surrounding the frequency bin of interest. We have modified the Results section to make this clear, describing results on grand-averaged data in a different paragraph than the analysis based on individual infants. We have also ensured that there is consistency across the two experiments in the report of the statistics.</p><p><italic>5) The authors do not report an impedance limit for the EEG recording, which is typically listed in ERP papers as well as previous adult ssVEP papers (e.g.,</italic> <xref ref-type="bibr" rid="bib35"><italic>Prieto et al., 2013</italic></xref><italic>; Rossion &amp; Boremanse, 2011) and a previous infant ssVEP paper (</italic><xref ref-type="bibr" rid="bib14"><italic>Farzin, Hou, &amp; Norcia, 2012</italic></xref><italic>). Adding this limit is helpful for those trying to use this method in the future</italic>.</p><p>In the present study, in contrast with these previous studies, we use biosemi active electrodes, providing the best possible suppression of interference by impedance transformation directly on the electrode (<ext-link ext-link-type="uri" xlink:href="http://www.biosemi.com/faq/shielding%20vs%20active%20electrodes.htm">http://www.biosemi.com/faq/shielding vs active electrodes.htm</ext-link><ext-link ext-link-type="uri" xlink:href="http://www.biosemi.com/faq/shielding">http://www.biosemi.com/faq/shielding</ext-link> vs active electrodes.htm).</p><p>Active electrodes provide impedance transformation on the electrode: the input impedance is very high (so the EEG voltages are not influenced, even with high electrode impedances), while the output impedance is very low (&lt; 1 Ohm). Consequently, the interference currents now flow via very low impedances (the output of the active electrode), and cannot generate significant interference voltages anymore. In addition, the electrode impedance does no longer affect the level of interference.</p><p>Because the actual electrode impedance is not a very important variable, when active electrodes are used, the level of DC offset is used as an alternative indicator for the quality of the electrode contact. We added this information in the revised version of the paper: “Electrode offset was reduced between ± 25 microvolts for each individual electrode by injecting the electrode with saline gel.”</p><p><italic>6) In the “EEG Analyses Pre-processing” section the authors state that 1-5 sequences were excluded per infant with the 2 listed criteria applied. Does this means that each infant in the final analyses had between 1-5 sequences excluded due to these criteria?</italic></p><p>Yes, each infant in the final analyses had between 1-5 sequences excluded. The criteria for rejection of sequences have been clarified in the revised manuscript.</p><p><italic>What was the minimum number of sequences required to be included in analyses? In the beginning of the Results section, the authors note that all infants completed a minimum of 5 sequences, but as written, this suggests that all infants who participated completed at least 5 sequences, before any sequence exclusion criteria were applied</italic>.</p><p><italic>Can the authors add the minimum number of sequences necessary for an infant's data to be kept in analyses? If this cutoff is 5, please clarify whether the infants who only viewed 5 sequences also had at least 1 sequence excluded. If so, should these infants have not been kept in the analyses?</italic></p><p>The minimum for a participant to be included in the sample was to have paid full attention to more than 1 sequence by condition. Infants who performed the lowest number of sequences viewed at least five sequences, in addition to the excluded sequences. The term “minimum” used in the Results section was misleading and has been removed: it was not a criterion.</p><p><italic>7) In the subsection headed “EEG analyses Pre-processing”, the authors state that data were “downsampled to 250 Hz”. Why was this done? What was the original sample rate?</italic></p><p>The original sampling rate was 1024 Hz. Data files were then downsampled to 250 Hz to reduce file size and data processing time. This has been clarified in the Methods section. Note that we used this procedure in all of our previous SSVEP studies with adults, and there is no loss of frequency resolution.</p><p><italic>8) The “Experiment 2, the Analyses Pre-processing” section should contain more details on how many sequences per infant were removed based on the exclusion criteria, following the format of the Experiment 1's section</italic>.</p><p>The same exclusion criteria were used as in Experiment 1, and this led to 1 to 8 sequences excluded. This has been corrected.</p></body></sub-article></article>