<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">40946</article-id><article-id pub-id-type="doi">10.7554/eLife.40946</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Cellular cartography of the organ of Corti based on optical tissue clearing and machine learning</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-120013"><name><surname>Urata</surname><given-names>Shinji</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5947-6842</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-119838"><name><surname>Iida</surname><given-names>Tadatsune</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-53694"><name><surname>Yamamoto</surname><given-names>Masamichi</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-119840"><name><surname>Mizushima</surname><given-names>Yu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8184-4437</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-119841"><name><surname>Fujimoto</surname><given-names>Chisato</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-119842"><name><surname>Matsumoto</surname><given-names>Yu</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-119843"><name><surname>Yamasoba</surname><given-names>Tatsuya</given-names></name><email>tyamasoba-tky@umin.ac.jp</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-78472"><name><surname>Okabe</surname><given-names>Shigeo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1216-8890</contrib-id><email>okabe@m.u-tokyo.ac.jp</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Department of Cellular Neurobiology, Graduate School of Medicine</institution><institution>The University of Tokyo</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Otolaryngology, Graduate School of Medicine</institution><institution>The University of Tokyo</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Nephrology, Graduate School of Medicine</institution><institution>Kyoto University</institution><addr-line><named-content content-type="city">Kyoto</named-content></addr-line><country>Japan</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="editor"><name><surname>Whitfield</surname><given-names>Tanya T</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sheffield</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>18</day><month>01</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e40946</elocation-id><history><date date-type="received" iso-8601-date="2018-08-10"><day>10</day><month>08</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-01-05"><day>05</day><month>01</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Urata et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Urata et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-40946-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.40946.001</object-id><p>The highly organized spatial arrangement of sensory hair cells in the organ of Corti is essential for inner ear function. Here, we report a new analytical pipeline, based on optical clearing of tissue, for the construction of a single-cell resolution map of the organ of Corti. A sorbitol-based optical clearing method enabled imaging of the entire cochlea at subcellular resolution. High-fidelity detection and analysis of all hair cell positions along the entire longitudinal axis of the organ of Corti were performed automatically by machine learning–based pattern recognition. Application of this method to samples from young, adult, and noise-exposed mice extracted essential information regarding cellular pathology, including longitudinal and radial spatial characteristics of cell loss, implying that multiple mechanisms underlie clustered cell loss. Our method of cellular mapping is effective for system-level phenotyping of the organ of Corti under both physiological and pathological conditions.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>organ of Corti</kwd><kwd>optical tissue clearing</kwd><kwd>hair cell</kwd><kwd>hearing loss</kwd><kwd>hard tissue</kwd><kwd>machine learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001700</institution-id><institution>Ministry of Education, Culture, Sports, Science, and Technology</institution></institution-wrap></funding-source><award-id>26111506</award-id><principal-award-recipient><name><surname>Fujimoto</surname><given-names>Chisato</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>15K10743</award-id><principal-award-recipient><name><surname>Fujimoto</surname><given-names>Chisato</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>26253081</award-id><principal-award-recipient><name><surname>Yamasoba</surname><given-names>Tatsuya</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>16K15717</award-id><principal-award-recipient><name><surname>Yamasoba</surname><given-names>Tatsuya</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id>JPMJCR14W2</award-id><principal-award-recipient><name><surname>Okabe</surname><given-names>Shigeo</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009619</institution-id><institution>Japan Agency for Medical Research and Development</institution></institution-wrap></funding-source><award-id>17gm5010003</award-id><principal-award-recipient><name><surname>Okabe</surname><given-names>Shigeo</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>17H01387</award-id><principal-award-recipient><name><surname>Okabe</surname><given-names>Shigeo</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution>The UTokyo Center for Integrative Science of Human Behavior</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Okabe</surname><given-names>Shigeo</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001700</institution-id><institution>Ministry of Education, Culture, Sports, Science and Technology</institution></institution-wrap></funding-source><award-id>18H04727</award-id><principal-award-recipient><name><surname>Okabe</surname><given-names>Shigeo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A method of generating comprehensive maps of cochlear cells was created and enabled researchers to study characteristics of cellular damage in aged and noise-exposed inner ear.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A complete understanding of auditory perception and transduction relies on an accurate reconstruction of the intact, three-dimensional structure of the cochlea. The spatial organization of the organ of Corti, the mammalian auditory sensory epithelium, determines the cochlear tonotopic map, which associates the positions of the inner hair cells (IHCs) in the cochlea with local characteristic frequencies. The basic pattern of the tonotopic map is simple, with higher frequencies on the base of the cochlear spiral and lower frequencies on the apex (<xref ref-type="bibr" rid="bib47">von Békésy and Peake, 1990</xref>). However, multiple structural and cell biological factors influence the actual shape of the tonotopic map (<xref ref-type="bibr" rid="bib42">Temchin and Ruggero, 2014</xref>).</p><p>In humans, age-related (<xref ref-type="bibr" rid="bib6">Chien and Lin, 2012</xref>) and noise-induced hearing loss (<xref ref-type="bibr" rid="bib28">Nelson et al., 2005</xref>) are prevalent health problems that require early prevention (<xref ref-type="bibr" rid="bib8">Cunningham and Tucci, 2017</xref>). However, the field awaits the development of appropriate model animals that recapitulate human pathology (<xref ref-type="bibr" rid="bib48">Wang et al., 2002</xref>; <xref ref-type="bibr" rid="bib49">Yamasoba et al., 1998</xref>; <xref ref-type="bibr" rid="bib52">Zheng et al., 1999</xref>). Moreover, the complexities of cochlear structure have prohibited a comprehensive cellular cartography, and current histological techniques are far from satisfactory for comprehensive analyses. Therefore, new methods that enable simultaneous examination of molecular signatures and subcellular structures across the entire cochlea would greatly accelerate the progress of research on auditory mechanisms.</p><p>Optical access to the properties of cells within highly complex tissues and organs is an important technical goal of modern cell biology. Advancements in optical tissue clearing have enabled the acquisition of structural and molecular information from large volumes of tissues and organs (<xref ref-type="bibr" rid="bib7">Chung et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Dodt et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Hama et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Renier et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Susaki et al., 2014</xref>). Recent reports showed that both organic solvent– and hydrophilic solution–based clearing methods could be optimized in clearing hard tissues that contain large proportions of extracellular matrix (<xref ref-type="bibr" rid="bib2">Berke et al., 2016</xref>; <xref ref-type="bibr" rid="bib4">Cai et al., 2018</xref>; <xref ref-type="bibr" rid="bib5">Calve et al., 2015</xref>; <xref ref-type="bibr" rid="bib12">Greenbaum et al., 2017</xref>; <xref ref-type="bibr" rid="bib21">Jing et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Tainaka et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Treweek et al., 2015</xref>). The accumulating knowledge and technologies should be helpful in development of effective clearing and labeling protocols for the inner ear inside the temporal bone (<xref ref-type="bibr" rid="bib29">Nolte et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Tinne et al., 2017</xref>). To date, however, an integrated method of tissue processing, labeling, and imaging techniques with single cell resolution has not yet been developed and optimized for the inner ear.</p><p>Here, we report an analytical pipeline for the construction of a single-cell resolution map of the organ of Corti taken from C57BL/6J mice at postnatal day (PND) 5, 60, 120 and 360. The method is based on optical tissue clearing technology and automatic cell detection using a machine learning algorithm. In this method, a series of fixation, permeabilization, immunolabeling, and clearing processes transform the inner ear into optically transparent samples suitable for volume imaging at single-cell resolution. Automated high-fidelity recording and analysis of hair cell positions along the entire length of the organ of Corti were achieved based on machine learning–based cell detection. Application of this method to pathological samples revealed distinct impacts of aging and noise on spatial features of sensory hair cell pathology. Our method of cellular mapping is highly effective for system-level phenotyping of the organ of Corti.</p></sec><sec id="s2" sec-type="results|discussion"><title>Results and discussion</title><sec id="s2-1"><title>Analytical pipeline for cellular cartography of the organ of Corti</title><p>Our analytical pipeline for sensory hair cell mapping in the cochlea followed three steps. First, the mouse temporal bone was isolated at PND 60 and processed for clearing and immunolabeling of the sensory hair cells (<xref ref-type="fig" rid="fig1">Figure 1A</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Tissue clearing and immunolabeling were optimized for tissue transparency and antibody accessibility. After tissue preparation, three-dimensional two-photon excitation microscopy generated image stacks covering the entire structure of the organ of Corti, with an average size of 1200 × 1200 × 800 μm (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The image data were processed by custom-made software to stitch and linearize the sensory epithelium, followed by detection of cell positions (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The software automatically generated a spatial map of the total hair cells and estimated the positions of putative lost cells. The entire experimental procedure could be completed within 5 days, with 4 days for tissue clearing and labeling, 4 hr for image acquisition, and 30 min for automated analysis.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.002</object-id><label>Figure 1.</label><caption><title>Optical tissue clearing and whole-mount immunolabeling of the organ of Corti.</title><p>(<bold>A</bold>) Time course and individual steps of tissue clearing with or without immunostaining. (<bold>B</bold>) Three-dimensional imaging of the organ of Corti within the temporal bone. Top view (left), lateral view (middle), and the schematic presentation of the organ of Corti with its axis parallel to the modiolus. The size of the organ of Corti is indicated in the X, Y, and Z coordinates. Scale bar, 500 μm. (<bold>C</bold>) Computational processes of linearization, cell detection, and modeling. (<bold>D</bold>) Side-by-side comparison of 3DISCO, iDISCO, CLARITY, and CUBIC. Transmitted light images of samples before and after clearing, together with MYO7A staining. Scale bar, 500 μm. (<bold>E</bold>) Manual dissection of the iDISCO-processed sample confirmed MYO7A staining in the sensory epithelium. Scale bars, 500 μm (upper image) and 100 μm (lower image). (<bold>F</bold>) Lateral and horizontal views of the reconstructed three-dimensional images of the organ of Corti stained with anti-MYO7A. CUBIC with decalcification and original Sca<italic>l</italic>eS failed to detect the deepest part of the organ of Corti (green dotted lines). With modified Sca<italic>l</italic>eS, the entire structure of the organ of Corti could be visualized. Scale bar, 500 μm. (<bold>G</bold>) Modified Sca<italic>l</italic>eS sample of the organ of Corti stained with anti-MYO7A antibody, together with transmitted light images before (upper left) and after (upper right) treatment. Scale bar, 500 μm. (<bold>H</bold>) Three steps of the modified Sca<italic>l</italic>eS protocol. The initial decalcification step is followed by a clearing step, which mainly removes lipids from the extracellular matrix. Finally, the RI of the sample is matched with mounting solution. (<bold>I</bold>) Preservation of GFP fluorescence after modified Sca<italic>l</italic>eS treatment. Scale bar, 10 μm. (<bold>J</bold>) Preservation of rhodamine-phalloidin signal after modified Sca<italic>l</italic>eS treatment, which includes sorbitol to stabilize cytoskeletal polymers. Scale bar, 10 μm. IHC, inner hair cell; OHC, outer hair cell; RI, refractive index.</p><p><supplementary-material id="fig1sdata1"><object-id pub-id-type="doi">10.7554/eLife.40946.005</object-id><label>Figure 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig1">Figure 1B, E</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-40946-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Protocol of modified Sca/eS.</title><p>(<bold>A</bold>) Comparison of optical transparency of mouse brain samples using 3DISCO, iDISCO, CLARITY and CUBIC. Scale, 3 mm. (<bold>B</bold>) Relationship between imaging depths and RIs using the decalcified cochlea as a sample. (n = 5 samples. Dunnet’s multiple comparison test, *p &lt; 0.05; ***p &lt; 0.001; ns; not significant, p &gt; 0.05.) (<bold>C</bold>) Time course and individual steps of modified Sca/eS compared to the previous protocols of cochlear tissue preparations. (<bold>D</bold>) Macroscopic images of the cochlea through the steps of decalcification, clearing, and RI matching. Each image corresponds to the time points (<bold>i</bold>) to (viii) shown in (<bold>A</bold>). Scale bar, 1 mm. (<bold>E</bold>) Mouse brain sections with 100 μm thickness were treated with urea and guanidine solutions at varying concentrations. After tissue clearing, tissue volume expansion and optical transmittance were measured. Scale bar, 5 mm. (n = 5 samples for each condition. One-way ANOVA with Bonferroni’s post hoc test, *p &lt; 0.05; ***p &lt; 0.001; ns; not significant, p &gt; 0.05.) RI, refractive index.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Application of modified Sca<italic>l</italic>eS to other tissues.</title><p>(<bold>A</bold>) Tubular bone samples were treated with modified Sca<italic>l</italic>eS and CB-perfusion. CB-perfusion was designed for whole-body imaging (see Appendix 1 for the detail). Transmitted light Images before and after clearing procedures were presented. The trabecular regions of the tubular bone (boxed regions of the low magnification images with transmitted light) stained with anti-vascular endothelial (VE)-cadherin were imaged through the surface of the compact bone. Boxed regions in fluorescence images were further enlarged for presentation of vasculature details. Scale bar, 5 mm (transmission images), 100 μm (fluorescence images). The graph shows the maximal depth at which the VE-cadherin signals could be detected from the surface. (n = 3 samples for each condition. Two-tailed unpaired t test, *p &lt; 0.05.) (<bold>B</bold>) Application of modified Sca<italic>l</italic>eS to multiple biological samples. To test the effectiveness of modified Sca<italic>l</italic>eS for clearing the non-osseous tissue, multiple organs (brain, heart, stomach, lung, liver, kidney, intestine and spleen) were processed with modified Sca<italic>l</italic>eS and CB-perfusion. Performance of CB-perfusion was better than modified Sca<italic>l</italic>eS in stomach, lung, liver, kidney and spleen. This difference can be explained by better performance of CB-perfusion in elimination of blood cells by perfusion and effective delipidation and decolorization by aminoalcohol. Scale bar, 5 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig1-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Optimization of imaging of the whole intact cochlea</title><p>The mouse inner ear forms complex and intricate structures inside the temporal bone. To achieve deeper and clearer imaging of the organ of Corti, it was necessary to overcome two hurdles. First, an inorganic component of the bone, mainly composed of calcium phosphate, had to be removed. Second, refractive index (RI) matching had to be fine-tuned to decrease optical aberration induced by heterogenous tissue components (<xref ref-type="bibr" rid="bib1">Acar et al., 2015</xref>; <xref ref-type="bibr" rid="bib2">Berke et al., 2016</xref>). The existence of multiple methods for optical tissue clearing provided us with an opportunity to perform a side-by-side comparison of their applicability to the organ of Corti. We tested five independent, well-established clearing and labeling protocols (3DISCO (<xref ref-type="bibr" rid="bib10">Ertürk et al., 2012</xref>), iDISCO (<xref ref-type="bibr" rid="bib33">Renier et al., 2014</xref>), CLARITY (<xref ref-type="bibr" rid="bib7">Chung et al., 2013</xref>), CUBIC (<xref ref-type="bibr" rid="bib37">Susaki et al., 2014</xref>), and Sca<italic>l</italic>eS (<xref ref-type="bibr" rid="bib13">Hama et al., 2015</xref>)) for their performance in detection of total hair cells. Myosin 7a (MYO7A), specifically expressed in IHCs and outer hair cells (OHCs), was utilized as a standard marker for hair cells. We found that performances of different protocols were comparable when they were applied to adult mouse brains, but the efficiencies for clearing the temporal bone were variable (<xref ref-type="fig" rid="fig1">Figure 1D</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We failed to detect MYO7A-immunopositive hair cells in samples processed by 3DISCO, iDISCO, CLARITY, or CUBIC (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Microdissection of the membrane labyrinth of the iDISCO-processed samples confirmed the presence of MYO7A-immunopositive hair cells, suggesting that the surrounding bone tissue prevented the detection of fluorescence (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). When CUBIC was combined with decalcification, MYO7A fluorescence could be detected down to 180 μm from the surface, but the combined method still did not enable imaging of the deeper part of the organ of Corti (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). Among the pre-existing tissue clearing methods, Sca<italic>l</italic>eS combined with decalcification yielded the best results (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). However, this method still missed hair cells at the cochlear base, more than 500 μm away from the bone surface.</p><p>By modifying the original Sca<italic>l</italic>eS method, we achieved efficient in situ detection of all MYO7A-positive hair cells in the organ of Corti (<xref ref-type="fig" rid="fig1">Figure 1G</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). In the new protocol, we first decalcified the samples with EDTA (<xref ref-type="fig" rid="fig1">Figure 1H</xref>). In the subsequent clearing step, a combination of a nonionic detergent (Triton X-100) and an ionic chaotropic reagent (guanidine) was effective in increasing transparency. The Sca<italic>l</italic>eS and CUBIC1 protocols use urea instead of guanidine (<xref ref-type="bibr" rid="bib13">Hama et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Susaki et al., 2015</xref>), but high concentrations of urea can induce tissue expansion (<xref ref-type="bibr" rid="bib40">Tainaka et al., 2016</xref>). By contrast, our guanidine-based clearing solution did not induce detectable tissue expansion (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Although guanidine treatment denatures GFP and reduces its fluorescence intensity (<xref ref-type="bibr" rid="bib15">Huang et al., 2007</xref>), this fluorescence quenching could be reversed by incubation in phosphate-buffered saline (PBS). Finally, we tested the solutions with RIs from 1.41 to 1.56 for their performance in tissue clearing by measuring the maximal depth of detectable MYO7A-positive hair cells from the temporal bone surface (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We found that a RI matching solution with a RI of 1.47 was most effective for detecting MYO7A-positive hair cells away from the bone surface. This RI lies between that of bone matrix (RI = 1.56) and tissue with scarce extracellular matrix (RI = 1.38). The new protocol for the in situ detection of all MYO7A-positive hair cells in the organ of Corti could be completed within 4 to 6 days (<xref ref-type="fig" rid="fig1">Figure 1A,H</xref>, and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), and effectively detected GFP-based reporter molecules and F-actin by rhodamine phalloidin (<xref ref-type="fig" rid="fig1">Figure 1I,J</xref>). The presence of sorbitol in the clearing solution improved F-actin stabilization. The protocol could also be applied to detection of cellular components in other types of bone-containing samples (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p></sec><sec id="s2-3"><title>Machine learning–based automated detection of sensory hair cells</title><p>To obtain information about hair cell distribution along the entire longitudinal axis of the organ of Corti, we applied our optimized tissue clearing and labeling methods to samples from naïve C57BL/6J mice, and detected sensory hair cells with anti-MYO7A antibody. The combination of a widely used marker of sensory hair cells (MYO7A) and a standard mouse line (C57BL/6J) should facilitate replication of this protocol in other laboratories and comparative studies. Multiple image stacks that cover the entire structure of the organ of Corti were obtained by two-photon microscopy with voxel sizes of 0.99 × 0.99 × 1.0 μm for high-resolution imaging (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Spatially confined two-photon excitation effectively decreased photobleaching after repetitive imaging. To adjust the local fluorescence intensity of MYO7A-immunopositive hair cells, we controlled both excitation laser power and the cut-off range of pixel intensities.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.006</object-id><label>Figure 2.</label><caption><title>Computational analysis of hair cell distribution in the organ of Corti.</title><p>(<bold>A</bold>) Detection of single hair cells stained with anti-MYO7A. The border between hair cells can be clearly detected. Scale bar, 10 μm. (<bold>B</bold>) Sequential steps in reconstruction of the linearized voxel image of the organ of Corti. The linearized voxel image was generated using the row of IHCs as a structural reference of the longitudinal axis of the organ of Corti. Scale bar, 100 μm. (<bold>C</bold>) Plot of the total longitudinal length of the organ of Corti against the total number of IHCs. (<bold>D</bold>) Plot of radial distance of IHCs from the modiolus. (<bold>E</bold>) Plot of hair cell positions along the vertical axis of the organ of Corti. (<bold>F</bold>) Normalization of heterogeneity in hair cell positions. Before normalization, both x and y axes represent physical positions of OHCs. After normalization, the coordinates are arbitrary units and are equalized in x and y axes. (<bold>G</bold>) Transformation of the positions of hair cells to fit the standardized template. The template is a two-dimensional grid parallel to the surface of the sensory epithelium (upper image). This transformation is useful for estimation of lost hair cells based on the calculation of cell-free space. The accuracy of estimation by this method was comparable to the performance of manual estimation (lower plot). [n = 161 samples for each. Paired <italic>t</italic>-test; ns, not significant (p &gt; 0.05).] IHC, inner hair cell; OHC, outer hair cell; PND, postnatal day; RI, refractive index.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.40946.009</object-id><label>Figure 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig2">Figure 2D, E, G</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-40946-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Manual counting of lost hair cells and auditory brainstem-evoked response (ABR) in mice with age-related and noise-induced hearing loss.</title><p>(<bold>A</bold>) Numbers of total IHCs and OHCs of C57BL/6J mice at PND 5, PND 60, and PND 360. (n = 4 (PND 5), 4 (PND 60), and 3 (PND 360). One-way ANOVA with Bonferroni's post hoc test, ***p &lt; 0.001.) (<bold>B</bold>) ABR thresholds (left) and the numbers of lost OHCs (right) were compared between C57BL/6J (mouse model of age-related hearing loss) and CBA/Ca mice (control mice) at PND 60. (<bold>C</bold>) The effect of acoustic overexposure stimulus on ABR thresholds (left) and OHC loss (right) measured at PND 60. Acoustic overexposure stimulus induced an increase in ABR threshold and loss of OHCs. ABR, auditory brainstem response; IHC, inner hair cell; OHC, outer hair cell; PND, postnatal day.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.008</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Three-dimensional presentation of hair cell distribution projected to X-Y and Y-Z planes.</title><p>Positions of Inner hair cells were sampled with regular intervals and the position data from different samples were overlaid. Hair cells from different samples were plotted as dots with different colors. Spiral directions of samples from right ears were converted to those of left ears for alignment of samples from both sides. PND, postnatal day.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig2-figsupp2-v1.tif"/></fig></fig-group><p>To achieve automated detection of both IHCs and OHCs, we developed a series of custom-made MATLAB scripts (<xref ref-type="fig" rid="fig2">Figure 2B</xref> and <xref ref-type="table" rid="table1">Table 1</xref>, also see Appendices 1 and 2). Because loss of IHCs is rare even in pathological conditions, such as aging and noise exposure, the row of IHCs was used as a guide for linearization of the spiral sensory epithelium. First, multiple image stacks containing portions of the organ of Corti were assembled into a single image stack. Our image acquisition protocol was designed to obtain image stacks covering the volume of the entire cochlea. We also designed that the two adjacent imaged stacks always have the overlapping volume. With these image acquisition rules, the entire tissue volume containing the whole sensory epithelium could be easily reconstructed. Second, the best-fit arcs of the single IHC row were calculated to create a spiral that could be used as a structural reference for the entire organ of Corti. Third, a linearized voxel image was reconstructed using the best-fit spiral and the normal vectors of the plane fitted to the segments of the sensory epithelium. Finally, we employed machine learning models to perform an exhaustive search of all hair cells and recorded their positions as Cartesian coordinates. The search process by machine learning technique consists of two parts: the first step of signal-noise discrimination and the second step for the recovery of false negatives. The details are provided in <xref ref-type="table" rid="table1">Table 1</xref> and Appendix 2. (<xref ref-type="bibr" rid="bib22">LeCun et al., 1989</xref>; <xref ref-type="bibr" rid="bib11">Friedman et al., 2000</xref>; <xref ref-type="bibr" rid="bib3">Breiman, 2001</xref>)</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.010</object-id><label>Table 1.</label><caption><title>Details of machine learning models (related to <xref ref-type="fig" rid="fig2">Figure 2</xref>).</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Models</th><th>Type<sup><bold>‡</bold></sup></th><th>Algorithm</th><th>Configuration</th><th>Use</th><th>Predictor</th></tr></thead><tbody><tr><td>IHC<sup>*</sup> 1</td><td>Binary</td><td>Gentle Boost</td><td>300 classification trees</td><td>Reduction of noise</td><td>Area, barycentric coordinates, maximum correlation coefficients, maximum intensity, same data set of the nearest neighbor group and relative position of the nearest neighbor group</td></tr><tr><td>IHC<sup>*</sup> 2</td><td>Binary</td><td>Random Forest</td><td>300 classification trees</td><td>Detection of cells</td><td>Adding to the above, prediction score by ‘IHC<sup>*</sup> 1’ of itself and that of adjacent groups in six directions<sup><bold>¶</bold></sup>, relative position of the adjacent groups, and cropped image<sup>††</sup></td></tr><tr><td>OHC<sup><bold>†</bold></sup> 1</td><td>Binary</td><td>Gentle Boost</td><td>300 classification trees</td><td>Reduction of noise</td><td>Same as ‘IHC<sup>*</sup> 1’</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 2</td><td>Binary</td><td>Random Forest</td><td>300 classification trees</td><td>Detection of cells</td><td>Same as ‘IHC<sup>*</sup> 2’</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 3</td><td>Multiclass</td><td>Convolutional Neural Network</td><td>From the input, convolutional layer (filter size 5, number 60), ReLU<sup><bold>§</bold></sup> layer, fully connected layer, Softmax Layer (three classes), and output.</td><td>Estimation of belonging row</td><td>Cropped image (39 × 69 pixels in width and height)</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 4</td><td>Binary</td><td>Convolutional Neural Network</td><td>From the input, convolutional layer (filter size 5, number 60), ReLU<sup><bold>§</bold></sup> layer, convolutional layer (filter size 5, number 20), ReLU<sup><bold>§</bold></sup> layer, fully connected layer, Softmax Layer (two classes), and output.</td><td>Detection of cells in spaces</td><td>Cropped image (39 × 69 pixels in width and height)</td></tr></tbody></table><table-wrap-foot><fn><p>*. IHC, inner hair cell.</p><p><bold>†</bold>. OHC, outer hair cell.</p></fn><fn><p><bold>‡</bold>. Classification type.</p><p><bold>§</bold>. Rectified Linear Unit.</p></fn><fn><p><bold>¶</bold>. Adjacent groups in direction of 0–60°, 60–120°, 120–180°, 180–240°, 240–300°, 300–360° with the y-axis as an initial line in the x-y plane.</p><p>††. Initial image size is 21 × 69 pixels in width and height. The image is resized in 7 × 23 then reshaped in 1 × 161.</p></fn></table-wrap-foot></table-wrap><p>To test the ability of our automated cell detection protocol to reliably record hair cell positions, we studied its performance by comparing its outputs with manually identified OHC positions in four independent samples of the organ of Corti labeled with anti-MYO7A antibody. The automated detection protocol recovered 98.8 ± 0.6% of manually identified hair cells. In turn, 99.7 ± 0.2% of hair cells identified by the algorithm were also scored as hair cells by human operators, with the remaining 0.3% representing false positives (<xref ref-type="table" rid="table2">Table 2</xref>). The detection efficiency of our protocol was much higher than a standard imaging processing protocol based on three-dimensional watershed ((<xref ref-type="bibr" rid="bib34">Soille and Vincent, 1990</xref>; <xref ref-type="table" rid="table2">Table 2</xref> and Appendix 2).</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.011</object-id><label>Table 2.</label><caption><title>Detection efficiency of hair cells (related to <xref ref-type="fig" rid="fig2">Figure 2</xref>).<sup>*</sup></title></caption><table frame="hsides" rules="groups"><tbody><tr><th valign="top"/><th colspan="5"><break/>Inner hair cell</th></tr><tr><td valign="top"/><td>Detect. (n)<sup><bold>†</bold></sup></td><td>Undetect. (n)<sup><bold>‡</bold></sup></td><td>Err. detect. (n)<sup><bold>§</bold></sup></td><td>Recover Rate<sup><bold>¶</bold></sup></td><td>Accuracy rate<sup>††</sup></td></tr><tr><td>Our Method</td><td>576 ± 33</td><td>13 ± 12</td><td>2 ± 2</td><td>0.979 ± 0.021</td><td>0.997 ± 0.003</td></tr><tr><td>3D Watershed</td><td>424 ± 98</td><td>152 ± 82</td><td>110 ± 78</td><td>0.733 ± 0.149</td><td>0.818 ± 0.100</td></tr><tr><th valign="top"/><th colspan="5"> <break/><break/>Outer hair cell</th></tr><tr><td valign="top"/><td>Detect. (n)<sup><bold>†</bold></sup></td><td>Undetect. (n)<sup><bold>‡</bold></sup></td><td>Err. Detect. (n)<sup><bold>§</bold></sup></td><td>Recover Rate<sup><bold>¶</bold></sup></td><td>Accuracy rate<sup>††</sup></td></tr><tr><td>Our Method<sup>‡‡</sup></td><td>1989 ± 133</td><td>24 ± 13</td><td>6 ± 4</td><td>0.988 ± 0.006</td><td>0.997 ± 0.002</td></tr><tr><td>Principle 1 Only<sup>§§</sup></td><td>1925 ± 131</td><td>69 ± 41</td><td>16 ± 13</td><td>0.966 ± 0.021</td><td>0.992 ± 0.006</td></tr><tr><td>3D Watershed</td><td>1493 ± 197</td><td>496 ± 111</td><td>760 ± 381</td><td>0.748 ± 0.064</td><td>0.682 ± 0.103</td></tr></tbody></table><table-wrap-foot><fn><p>*. Data from 10 samples (PND30: two sample, PND60: three sample, ACL: two sample, NCL: three sample). Data are expressed as means ± SD.</p><p><bold>†</bold>. Detection number.</p></fn><fn><p><bold>‡</bold>. Undetected number.</p><p><bold>§</bold>. Erroneous detection number.</p></fn><fn><p><bold>¶</bold>. Recover rate of manually identified hair cells by the automated detection algorithm (almost synonymous with recall).</p><p>††. The number of hair cells identified by both manual and automated detection divided by the number of hair cells identified by automated detection (almost synonymous with precision).</p></fn><fn><p>‡‡.The proposed method in this study (principle 1 + principle 2).</p><p>§§. The method using the first half of the proposed method. For details please see ‘Principles of auto-detection by machine learning’ in Appendix 2.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-4"><title>Automated detection of hair cells in samples with hair cell pathology</title><p>Pathological changes in the sensory epithelium associated with aging or noise exposure can impair the hearing functions of the inner ear. Previous studies provided qualitative evidence showing that the cellular changes associated with age-associated or noise-induced hearing loss partially overlap, but also have distinct characteristics. C57BL/6J mice are widely used for aging research and exhibit the classic pattern of age-related hearing loss, with the loss of both hair cells and neurons starting from the base (<xref ref-type="bibr" rid="bib16">Hunter and Willott, 1987</xref>). The increase in auditory brainstem–evoked response (ABR) threshold starts at the age of 10 weeks (<xref ref-type="bibr" rid="bib20">Ison et al., 2007</xref>). Manual counting of lost cells in C57BL/6J mice at PND 5, 60, and 360 confirmed age-related cell loss (ACL) (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). For the assessment of noise-induced cell loss (NCL), we applied acoustic overexposure stimulus to C57BL/6J mice at PND 60 to induce a moderate threshold shift (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), as previously reported (<xref ref-type="bibr" rid="bib25">Mizushima et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Tuerdi et al., 2017</xref>). The cellular pathology varied from nearly normal appearance to severe hair cell damage in the basal end of the cochlea, and exhaustive screening of hair cell loss in this context should be useful.</p><p>To appropriately interpret cell position data from samples harvested under physiological and pathological conditions, it is necessary to evaluate variation in the morphology of the organ of Corti. Variation may also exist among samples collected under identical experimental conditions, potentially confounding data interpretation. To evaluate such variation in morphology, we performed the following three types of measurements (Appendix 2). First, we measured the total longitudinal length of the IHC row and the number of IHCs. The plot of IHC number vs. the length of the IHC row for multiple samples is useful for evaluating the longitudinal sizes of the organ of Corti (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The plot shows that data from young control samples (PND 30) scattered in the range of 550–650 IHCs, indicating the presence of physiological variation. Variation in the length and the cell number did not show a specific trend between samples from different ages. However, the data from noise-exposed mice exhibited a tendency of higher variation, potentially due to selective loss of hair cells at the basal end in some NCL samples. Second, we projected the position of IHCs onto a plane perpendicular to the modiolus and plotted the distance of IHCs from the modiolus (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This plot revealed small variation in IHC position among experimental groups. Third, the positions of IHCs were projected onto the axis of the modiolus, and the relative positions of every 25 IHCs were plotted (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). The IHC distributions along the axis of the modiolus in all samples were similar. In summary, these measurements confirmed that the overall spatial distribution of IHCs can be maintained under pathological conditions (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Hence, we performed further analysis of the pattern of hair cell loss using a standardized template of cell positions.</p><p>To simplify the treatment of hair cell position in the subsequent analysis, the Cartesian coordinates of hair cell positions were transformed and normalized to match the standardized template, which consisted of the normalized two-dimensional grids parallel to the surface of the sensory epithelium (<xref ref-type="fig" rid="fig2">Figure 2F,G</xref>). The first axis was defined by the line of detected IHCs, and the second was set perpendicular to the first axis. This simplified presentation is useful for measuring the space unoccupied by the hair cells. We hypothesized that the area of the unoccupied space reflects the space previously occupied by hair cells that were subsequently lost. By dividing the areas that were not occupied by existing OHCs by the average area of a single OHC, we could estimate the number of OHCs lost. Comparison of the performances of trained operators and automated calculation confirmed that adequate estimation of hair cell loss could be achieved by automated calculation; indeed, the two methods were similarly effective (<xref ref-type="fig" rid="fig2">Figure 2G</xref> and <xref ref-type="table" rid="table3">Table 3</xref>). The total number of lost OHCs was 26.3 ± 6.3, 34.6 ± 5.1, 55.8 ± 4.5, and 49.3 ± 17.3 (mean ±SD) in wild-type C57BL/6J mice at PND 30, 60, and 120, and PND 60 plus noise exposure. These data are consistent with previous estimates of hair cell loss based on manual counting in rats and chinchillas (<xref ref-type="bibr" rid="bib14">Hu et al., 2012</xref>; <xref ref-type="bibr" rid="bib50">Yang et al., 2004</xref>). Therefore, our protocol is suitable for quantitative analysis of IHCs and OHCs, including detection and counting of lost hair cells.</p><table-wrap id="table3" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.012</object-id><label>Table 3.</label><caption><title>Inter-operator percent match in void space detection (related to Experimental procedures).</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th colspan="4" valign="top">Inter-operator percent match</th><th colspan="3" valign="top">Number of detected void space</th></tr><tr><th>Sample number</th><th>A<sup><bold>¶</bold></sup>-B<sup><bold>¶</bold></sup></th><th>B<sup><bold>¶</bold></sup>-C<sup><bold>¶</bold></sup></th><th>A<sup><bold>¶</bold></sup>-C<sup><bold>¶</bold></sup></th><th>Auto<sup>††</sup>-HC<sup>‡‡</sup></th><th>Both</th><th>Auto<sup>††</sup>-only</th><th>HC<sup>‡‡</sup>-only</th></tr></thead><tbody><tr><td>1<sup>*</sup></td><td valign="top">0.960</td><td valign="top">0.880</td><td valign="top">0.917</td><td valign="top">0.920</td><td valign="top">24</td><td valign="top">1</td><td valign="top">1</td></tr><tr><td>2<sup><bold>†</bold></sup></td><td valign="top">0.898</td><td valign="top">0.917</td><td valign="top">0.906</td><td valign="top">0.952</td><td valign="top">84</td><td valign="top">2</td><td valign="top">2</td></tr><tr><td>3<sup>‡</sup></td><td valign="top">0.923</td><td valign="top">0.885</td><td valign="top">0.958</td><td valign="top">0.889</td><td valign="top">24</td><td valign="top">3</td><td valign="top">0</td></tr><tr><td>4<sup><bold>§</bold></sup></td><td valign="top">0.923</td><td valign="top">0.882</td><td valign="top">0.846</td><td valign="top">0.926</td><td valign="top">50</td><td valign="top">3</td><td valign="top">1</td></tr><tr><td valign="top">Overall</td><td valign="bottom">0.916</td><td valign="bottom">0.898</td><td valign="bottom">0.897</td><td valign="bottom">0.931</td><td valign="bottom">182</td><td valign="bottom">9</td><td valign="bottom">4</td></tr></tbody></table><table-wrap-foot><fn><p>*. Sample 1, two months old, total loss rate of OHCs: 1.7%.</p><p><bold>†</bold>. Sample 2, two months old with noise exposure, total loss rate of OHCs: 8.1%.</p></fn><fn><p>‡. Sample 3, one month old, total loss rate of OHCs: 2.2%.</p><p><bold>§</bold>. Sample 4, four months old, total loss rate of OHCs: 4.2%.</p></fn><fn><p><bold>¶</bold>. Skilled human operators (A, B, and C).</p><p>††. Auto, automated OHC loss counting program.</p></fn><fn><p>‡‡. HC, human consensus.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-5"><title>Spatial characteristics of hair cell loss</title><p>Presentation of lost cell density in the form of two-dimensional grids facilitates side-by-side comparison of hair cell loss along the longitudinal axis of the organ of Corti (<xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). In samples from young mice not exposed to noise, small numbers of hair cells were lost along both the longitudinal and radial axes (<xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Samples of aged mice had a higher density of lost cells at both ends of the organ of Corti (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The difference between adult and aged mice was confirmed by comparison across ages. In particular, the age-dependent increase in lost cell density was prominent at the apical end (PND 60: 0.0596 ± 0.0048, PND 120: 0.116 ± 0.0150, Welch’s <italic>t</italic>-test, p &lt; 0.01, t = 3.59, df = 9.68). By contrast, previous studies reported a higher rate of ACL in the basal portion, but failed to detect a prominent increase in the proportion of lost cells in the apical region. This difference may be due to the fact that our tissue clearing technique enabled complete visualization of hair cells at the helicotrema (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). ACL also had spatial features along the radial axis, with a higher density at positions distal to the modiolus (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). This trend along the radial axis was already present in cochleae at PND 60, indicating that ACL may represent acceleration of a pathology already present in the early stage of life. In summary, the method we developed was well suited for comprehensive analysis of ACL.</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.013</object-id><label>Figure 3.</label><caption><title>Spatial pattern of hair cell loss.</title><p>(<bold>A</bold>) Pseudo-color presentation of hair cell loss along the longitudinal axis of the organ of Corti (PND 30, 60, and 120 and noise exposure at PND 60). Each row represents a single cochlear sample. Numbers of lost hair cells within 50 μm segments along the longitudinal axis were measured. For samples with higher cell loss in the basal portion, it was difficult to define the basal end of the sensory epithelium. These samples with ambiguous starting points of the epithelium were marked by thin red lines in rows of noise-exposed samples. The raw fluorescence image shows the definition of directions (distal and proximal, apex and base) relative to the sensory epithelium. (<bold>B</bold>) Distribution of lost cells along the longitudinal axis of the organ of Corti in three experimental groups. PND 60 and 120, and noise exposure at PND 60, exhibit distinct patterns of hair cell loss (Kruskal–Wallis test with Steel–Dwass test). (<bold>C</bold>) Detection of hair cell loss at the helicotrema. Scale bar, 100 μm. (<bold>D</bold>) Distribution of lost cells along the radial axis of the organ of Corti. Samples from PND 60 and 120 exhibit gradients of cell loss. (Paired <italic>t</italic>-test followed by Bonferroni’s correction, *p &lt; 0.05; ***p &lt; 0.001.) Number of samples; n = 10 (PND 30), 14 (PND 60), 9 (PND 120), and 10 (Noise), except for n = 7 in segment ‘a’ of Noise in (<bold>B</bold>). *p &lt; 0.05; **p &lt; 0.01; ***p &lt; 0.001. PND, postnatal day.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.40946.015</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figure 3D</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-40946-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.014</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Longitudinal and radial distribution of hair cell loss in the organ of Corti.</title><p>(<bold>A</bold>) Pseudo-color presentation of the OHC loss frequency along the radial axis. Each row represents a single cochlear sample. The sample IDs were written on the left of the map. Note that the direction of comparison (proximal to distal) is perpendicular to the map shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. Samples were arranged according to the extent of total cell loss in each experimental group from the highest to the lowest. The radial positions were divided into 15 sections and the scores were averaged within the sections. (<bold>B</bold>) Principal-component analysis (PCA) of the lost cell distribution in samples at PND 120 and at PND 60 with noise exposure (left). PCA was performed with the local OHC loss frequencies as variables. Frequencies of cell loss were calculated in individual segments set along the longitudinal and the radial axes. The percent variation explained by each principal component (PC) is indicated in parentheses. A dotted line indicates the decision boundary of the linear discriminant analysis. Coefficients of the first principal component (middle) and the second principal component (right) were presented from basal to apical and from proximal to distal. PND, postnatal day.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig3-figsupp1-v1.tif"/></fig></fig-group><p>The cellular pathology of NCL was more complex than that of ACL, exhibiting a highly variable pattern among samples. This may be inevitable in our paradigm of NCL, because this protocol is expected to induce milder insults to the sensory epithelium (<xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Our comprehensive analysis was useful in detecting higher variability of cell loss at the basal end after noise exposure (position ‘a’ against ‘e’ in <xref ref-type="fig" rid="fig3">Figure 3</xref>; p &lt; 0.001, F(6,9) = 15.5) and also in aged mice, (position ‘a’ against ‘e’ in <xref ref-type="fig" rid="fig3">Figure 3</xref>; p &lt; 0.05, F(8, 8)= 5.69), suggesting that vulnerability at the basal end may be intrinsically variable. Principal component analysis applied to the spatial pattern of cell loss was helpful in isolating ACL- and NCL-related parameters (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), and the results revealed that NCL had a weaker impact in the apical portion. Thus, distinct mechanisms of cellular pathology may be responsible for ACL and NCL.</p></sec><sec id="s2-6"><title>Model-based analysis of hair cell loss</title><p>The positions of putative lost cells revealed spatial clustering above the level that would be expected by chance, regardless of age and the presence or absence of noise exposure (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). To evaluate the spatial patterns of clustering, we constructed two distinct mechanistic models (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). In the first model, cell loss occurs stochastically, but the probability increases if adjacent cells have been lost (neighborhood effect model). In the second model, the frequency of cell loss depends on adverse factors localized along the longitudinal axis of the organ of Corti (position effect model).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.016</object-id><label>Figure 4.</label><caption><title>Model-based analysis of clustered cell loss.</title><p>(<bold>A</bold>) Evaluation of the extent of clustered cell loss by comparison with the extent of clustering based on a model of random cell loss. The extent of cell clustering in the experimental data was much higher than would have been expected from random cell loss (99% confidence intervals within two lines) (Welch’s <italic>t</italic>-test, ***p &lt; 0.001). (<bold>B</bold>) Construction of two models of hair cell loss (upper: neighborhood effect model; lower: position effect model). Virtual cell loss data were generated from the models and compared with the experimental data (measured). (<bold>C</bold>) Evaluation of the goodness-of-fit of the two models to the experimental data using the error score, which measures the extent of deviation of the clustering properties generated by the models from those observed in real samples. (<bold>D</bold>) Assessment of the relative contributions of the two models (neighborhood effect and position effect) to achieve the best fit to the experimental data. The two models contribute differentially under various conditions. The color code shows the proportion of lost OHCs against the total OHCs. (<bold>E</bold>) Overall pattern of contribution from two models. Note that the neighborhood effect makes a stronger contribution in young adult mice, whereas the position effect makes a stronger contribution in aged mice (means ± SD). Number of samples; n = 10 (PND 30), 14 (PND 60), 9 (PND 120), and 10 (Noise). PND, postnatal day.</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.40946.018</object-id><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4A, C, D and E</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-40946-fig4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40946.017</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Simulation analysis of clustered cell loss.</title><p>(<bold>A</bold>) A pair of ‘probability matrix’ (upper panel) and ‘cell matrix’ (lower panel). The intensities of elements in the ‘probability matrix’ indicate the probability of cell loss for the next round of the simulation runs for individual cells. White pixels in the ‘cell matrix’ indicate the locations of already lost cells in previous rounds of the simulation runs. (<bold>B</bold>) An example of simulated histograms with different amounts of two effects (neighborhood effect and position effect). These histograms indicate the frequency distribution of cell loss clusters with different sizes. (<bold>C</bold>) Comparison of experimental data and simulation results for a given cochlear sample (No. 517). A heat map (right) shows the relative similarities between the experimental data and the simulation result (reverse of the error score in <xref ref-type="fig" rid="fig4">Figure 4C</xref>) when the weights of the neighborhood effect and the position effect were systematically changed. The weighted average point indicated by the red dot was taken as the estimated contributions of two effects to this sample.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig4-figsupp1-v1.tif"/></fig></fig-group><p>Fitting of the two models was comparable in samples from aged mice or after noise exposure (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), suggesting the complex relationship between lost cell clustering, various hair cell pathologies, and the extent of cell loss. Therefore, we developed a two-component model in which both the neighborhood effect and the position effect induced cell loss, but with different weights. By controlling the weights of the two effects, it was possible to improve fitting to the experimental data. The combinations of the two effects yielding the best fit to the experimental data were plotted along with a color code for the extent of cell loss (<xref ref-type="fig" rid="fig4">Figure 4D</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The overall pattern of data distribution suggests a higher contribution of the neighborhood effect in young and adult mice not exposed to noise (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). With age, the contribution of the position effect increased, whereas noise exposure in adult mice resulted in a variable extent of damage; data points were dispersed, with highly damaged sensory epithelium experiencing a greater contribution from the position effect.</p></sec><sec id="s2-7"><title>Automatic evaluation of cell damage and detection of multiple intracellular components</title><p>Fluorescence-based detection of cytoskeletal components, such as F-actin, enabled us to obtain information about the integrity of subcellular structure in hair cells. We evaluated F-actin integrity of OHCs at multiple positions of the organ of Corti, specified by the extent of cell loss and clustering of lost cells (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This approach is useful for automatic evaluation of the extent of stereocilia damage at multiple points of the organ of Corti. The reduction of F-actin content in hair cells near to lost hair cells supports the neighborhood effect model of lost cell clustering, described above.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.019</object-id><label>Figure 5.</label><caption><title>Efficient mapping of subcellular pathology and multiple cellular components.</title><p>(<bold>A</bold>) Automated detection of areas with variable degrees of hair cell loss, combined with evaluation of subcellular pathology. All sites of hair cell loss (white squares) were selected, and changes in the F-actin content were evaluated (upper image). White squares with dotted lines are representative analysis areas, and are enlarged at lower left. Hair cells surrounded by intact hair cells (crosses) or next to lost cells (asterisks) were compared for their F-actin content (lower right). The graph reveals loss of F-actin in hair cells adjacent to lost cells. Scale bars, 100 μm (upper) and 10 μm (lower). [n = 108 (PND 60) and 103 (Noise), paired t-test for comparison within the group, Welch’s t-test with Bonferroni’s correction for comparison of cell groups between different experimental conditions, ***p &lt; 0.001; ns, not significant, p &gt; 0.05.] (<bold>B</bold>) Modified Sca<italic>l</italic>eS technique can be adapted to multiple immunohistochemistry of cellular and subcellular components at PND 5. Antibodies against CtBP2, VGLUT3, NF200, and SOX2 were used to detect multiple components in situ. Scale bars, 10 μm. HC, hair cell; IHC, inner hair cell; OHC, outer hair cell; PND, postnatal day.</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.40946.020</object-id><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5A</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-40946-fig5-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-fig5-v1.tif"/></fig><p>We also tried to image subcellular components in hair cells using specific antibodies against presynaptic ribbons (C-terminal-binding protein 2, CtBP2) and synaptic vesicles (vesicular glutamate transporter type 3, VGLUT3). Similar immunocytochemical approaches were applied to other components of the organ of Corti, including axons immunopositive for high–molecular weight neurofilament protein (NF200) and supporting cells positive for SRY (sex determining region Y)-box 2 (SOX2) immunoreactivity (<xref ref-type="bibr" rid="bib30">Oesterle et al., 2008</xref>) (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). These results suggest that this method can be applicable to analysis of multiple cellular components in the cochlea. In this study we utilized a water immersion objective with moderate numerical aperture (NA). In future, modification of our method with an objective lens with higher NA may enable more precise imaging of intracellular structure in a scale of the entire cochlea.</p><p>In this study, we developed a rapid method for optical tissue clearing, labeling, and automated image analysis of the inner ear. Currently available tissue clearing and labeling technologies have limited applicability to hard tissues, including bone, tooth, cartilage, and tendon. Effective removal of fine hydroxyapatite crystals in hard tissues is a key to establishing clearing methods. Here, we demonstrated that our modified Sca<italic>l</italic>eS method represents a powerful approach for exhaustive analysis of expression profiles in hair cells along the entire organ of Corti, using multiple antibodies. This technique can be directly applied to the characterization of genetic and environmental models of hearing loss. In future, the analytical pipeline we developed will be integrated with active elimination of bone mineral and organic components by physical principles (<xref ref-type="bibr" rid="bib23">Lee et al., 2016</xref>). To further increase efficiency, the decalcification solution should be elaborated. Rapid decalcification can be achieved by combining EDTA with formic or hydrochloric acid (<xref ref-type="bibr" rid="bib45">Treweek et al., 2015</xref>). A recent report also examined multiple conditions of clearing hard tissues and recommended lowering pH of the EDTA-containing decalcification solution (<xref ref-type="bibr" rid="bib41">Tainaka et al., 2018</xref>). However, prolonged sample treatment with high concentrations of acid can reduce immunoreactivity and accelerate quenching of fluorescent proteins. Future investigations should seek to establish clearing and labeling methods optimized for a wide spectrum of hard tissue components.</p><p>System-level analysis of the organ of Corti is important for extracting the operating principles of mechanosensory transduction. In parallel, generation of a variety of model mice harboring mutations in genes involved in hearing function will facilitate functional studies. While the functional consequences of gene mutation can be assessed using standardized protocols, such as ABR, at present we have no widely approved format for the assessment of cellular pathology. The method we developed in this study may be useful for standardization of cell-based analysis. A recent study of in situ two-photon imaging of the organ of Corti revealed the detailed architecture of the mechanical framework in the sensory epithelium (<xref ref-type="bibr" rid="bib36">Soons et al., 2015</xref>). The method described here could be combined with information about mechanical characteristics. By integrating position-specific mechanical property, fluid dynamics, and hair cell physiology, such an approach would be useful for modeling of cochlear function (<xref ref-type="bibr" rid="bib24">Liu et al., 2015</xref>). Manual identification of more than 2500 hair cells per sample and subsequent analysis of cell loss is not possible for large sets of cleared samples from animals of different ages, genetic backgrounds, and experimental conditions. Accordingly, the analytical pipeline described here was designed to minimize manual processing. Objective comparison of position-dependent cell pathology among multiple mouse models of hearing loss will facilitate identification of critical molecular signatures associated with cochlear pathology.</p></sec></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><p>For detailed procedures, see Appendix 1 and 2.</p><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type <break/>(species) or resource</th><th valign="top">Designation</th><th valign="top">Source or reference</th><th valign="top">Identifiers</th><th valign="top">Additional <break/>information</th></tr></thead><tbody><tr><td valign="top">Genetic <break/>reagent <break/>(M. musculus)</td><td valign="top">C57BL/6J</td><td valign="top">Sankyo Lab (JAPAN)</td><td valign="top">PRID:MGI:5658686</td><td valign="top"/></tr><tr><td valign="top">Genetic <break/>reagent <break/>(M. musculus)</td><td valign="top">CBA/Ca</td><td valign="top">Sankyo Lab (JAPAN)</td><td valign="top">PRID:MGI:2159826</td><td valign="top"/></tr><tr><td valign="top">Genetic <break/>reagent <break/>(M. musculus)</td><td valign="top">Thy1-GFP line-M</td><td valign="top">Jackson Lab</td><td valign="top">PRID:MGI:3766828</td><td valign="top"/></tr><tr><td valign="top">Genetic <break/> reagent <break/>(M. musculus)</td><td valign="top">GO-Ateam</td><td valign="top">PMID: 19720993</td><td valign="top"/><td valign="top">Dr. M Yamamoto (Kyoto University, Japan)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Rabbit polyclonal anti- <break/>Myosin VIIa</td><td valign="top">Proteus Biosciences</td><td valign="top">cat# 25–6790 <break/>PRID:AB_10013626</td><td valign="top">IHC (1:100)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Mouse monoclonal anti-Neurofilament 200</td><td valign="top">SIGMA</td><td valign="top">cat# N5389 <break/>PRID:AB_260781</td><td valign="top">IHC (1:100)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Mouse monoclonal anti-SOX-2</td><td valign="top">EMD Millipore</td><td valign="top">cat# MAB4343 <break/>PRID:AB_827493</td><td valign="top">IHC (1:200)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Mouse monoclonal anti-CTBP2</td><td valign="top">BD Bioscience</td><td valign="top">cat# 612044 <break/>PRID:AB_399431</td><td valign="top">IHC (1:100)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Guinea pig polyclonal anti-VGLUT3</td><td valign="top">PMID: 20034056</td><td valign="top"/><td valign="top">IHC (1:500), Dr. H <break/>Hioki (Juntendo <break/>University, Japan)</td></tr><tr><td valign="top">Antibody</td><td valign="top">Alexa Fluor 488-conjugated mouse monoclonal anti-VE cadherin</td><td valign="top">eBioscience</td><td valign="top">cat# 16-1441-81 <break/>PRID:AB_15604224</td><td valign="top">IHC (1:500)</td></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Rhodamine phalloidin</td><td valign="top">Invitrogen</td><td valign="top">cat# R415</td><td valign="top">IHC (1:500)</td></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Triton X-100</td><td valign="top">Nakalai-tesque</td><td valign="top">cat# 12967–45</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Urea</td><td valign="top">SIGMA</td><td valign="top">cat# U0631-1KG</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/> compound, drug</td><td valign="top">N,N,N',N'-Tetrakis (2-eydroxypropyl) ethylendiamine</td><td valign="top">TCI</td><td valign="top">cat# T0781</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">D-sucrose</td><td valign="top">Wako</td><td valign="top">cat# 196–00015</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">2,2',2''-nitrilotriethanol</td><td valign="top">Wako</td><td valign="top">cat# 145–05605</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Dichloromethane</td><td valign="top">SIGMA</td><td valign="top">cat# 270997–100 ML</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Tetrahydrofuran</td><td valign="top">SIGMA</td><td valign="top">cat# 186562–100 ML</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Dibenzyl Ether</td><td valign="top">Wako</td><td valign="top">cat# 022–01466</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Methanol</td><td valign="top">Wako</td><td valign="top">cat# 132–06471</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">D-glucose</td><td valign="top">SIGMA</td><td valign="top">cat# G8270-100G</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">D-sorbitol</td><td valign="top">SIGMA</td><td valign="top">cat# S1816-1KG</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Thiodiethanol</td><td valign="top">Wako</td><td valign="top">cat# 205–00936</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Acrylamide</td><td valign="top">Wako</td><td valign="top">cat# 011–08015</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Bis-acrylamide</td><td valign="top">SIGMA</td><td valign="top">cat# 146072–100G</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">VA-044 initiator</td><td valign="top">Wako</td><td valign="top">cat# 225–02111</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Sodium dodecyl <break/>sulfate</td><td valign="top">TCI</td><td valign="top">cat# I0352</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">FocusClear</td><td valign="top">CelExplorer Labs</td><td valign="top">cat# F101-KIT</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Glycerol</td><td valign="top">Wako</td><td valign="top">cat# 075–00616</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Dimethyl sulfoxide</td><td valign="top">Wako</td><td valign="top">cat# 043–07216</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">N-acetyl-L-hydroxyproline</td><td valign="top">TCI</td><td valign="top">cat# A2265</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Methyl-β-cyclodextrin</td><td valign="top">TCI</td><td valign="top">cat# M1356</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">γ-cyclodextrin</td><td valign="top">TCI</td><td valign="top">cat# C0869</td><td valign="top"/></tr><tr><td valign="top">Chemical <break/>compound, drug</td><td valign="top">Tween-20</td><td valign="top">Wako</td><td valign="top">cat# 167–11515</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">ImageJ</td><td valign="top">NIH</td><td valign="top">PRID: SCR_003070</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">GraphPad Prism 6</td><td valign="top">GraphPad Software</td><td valign="top">PRID: SCR_002798</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">MATLAB</td><td valign="top">MathWorks</td><td valign="top">PRID: SCR_001622</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">Microsoft Excel</td><td valign="top">Microsoft</td><td valign="top">PRID: SCR_016137</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">Adobe <break/>Illustrator</td><td valign="top">Adobe</td><td valign="top">PRID: SCR_010279</td><td valign="top"/></tr><tr><td valign="top">Software, <break/>algorithm</td><td valign="top">Signal <break/>processor</td><td valign="top">Nihon Kouden</td><td valign="top">Neuropack MEB2208</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">MATLAB codes</td><td valign="top">This paper</td><td valign="top"/><td valign="top"><ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/cochlea-analyzer">https://github.com/okabe-lab/cochlea-analyzer</ext-link></td></tr><tr><td valign="top">Other</td><td valign="top">25x water- <break/>immersion objective lens</td><td valign="top">Nikon</td><td valign="top">N25X-APO-MP</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">25x water- <break/>immersion objective lens</td><td valign="top">Olympus</td><td valign="top">XPLN25XWMP</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Sound speaker</td><td valign="top">TOA</td><td valign="top">HDF-261–8</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Power amplifier</td><td valign="top">TOA</td><td valign="top">IP-600D</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Condenser microphone</td><td valign="top">RION</td><td valign="top">UC-31 and UN14</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Sound calibrator</td><td valign="top">RION</td><td valign="top">NC-74</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Noise generator</td><td valign="top">RION</td><td valign="top">AA-61B</td><td valign="top"/></tr><tr><td valign="top">Other</td><td valign="top">Dual channel <break/>programmable <break/>filter</td><td valign="top">NF corporation</td><td valign="top">3624</td><td valign="top"/></tr></tbody></table></table-wrap><sec id="s3-1"><title>Tissue acquisition</title><p>After euthanasia, mice were perfused transcardially with 4% paraformaldehyde in PBS. Osteochondral samples (cochlea embedded in temporal bones and femurs) and other soft tissues (brain, heart, stomach, lung, liver, kidney, intestine, and spleen) were isolated by standard dissection techniques.</p></sec><sec id="s3-2"><title>Decalcification</title><p>Samples were washed for 30 to 180 min in PBS containing 0.1% Triton X-100 with continuous rocking at 40 rpm. Decalcification was performed by incubating samples for 48 to 120 hr in 500 mM EDTA in PBS at 37°C, and terminated by washing samples several times with PBS.</p></sec><sec id="s3-3"><title>Tissue extraction</title><p>Samples were placed in a solution containing 3 M guanidinium chloride, 35% (w/v) D-sorbitol, 15% (w/v) D-glucose, and 4% (w/v) Triton X-100 in PBS (pH 6.0–8.0) and incubated at 37°C for 2 to 12 hr.</p></sec><sec id="s3-4"><title>Labeling with antibodies and small molecules</title><p>After tissue extraction, samples were washed with PBS containing 0.1% Triton X-100 for 30 min with continuous rocking at 40 rpm. Samples were incubated for 2 to 48 hr in a solution containing primary antibodies or small molecules (details provided in Appendix 1) with appropriate dilutions at 37°C. Unbound antibodies or small molecules were removed by washing for 30 min with PBS containing 0.1% Triton X-100, with continuous rocking at 40 rpm. Primary antibodies were detected by incubation for 12 to 48 hr with a solution containing secondary antibodies at 37°C, followed by washing as described for removal of primary antibodies. Duration of antibody incubation was adjusted depending on the size of the sample and the affinity and specificity of the antibodies.</p></sec><sec id="s3-5"><title>Adjustment of RI</title><p>For the adjustment of tissue RI, samples were incubated for 15 min to 2 hr at 37°C in a RI matching solution. The duration of this step was adjusted depending on the size and properties of the sample. Our optimized RI matching solution (RI = 1.47) contained 3 M guanidinium chloride (or 4 M urea), 60% (w/v) D-sorbitol, and 0.1% (w/v) Triton X-100 in PBS (pH 7.1). For the optimization of RI, we tested multiple RI matching solutions with their RIs ranging from 1.41 to 1.56. The RI matching solutions with their RI lower than 1.47 were made by diluting the RI matching solution with RI = 1.47 with water. The final RIs were confirmed by a refractometer. The RI matching solutions with RI = 1.52 and 1.57 were thiodiethanol and dibenzyl ether, respectively. After RI adjustment, samples were placed in a chamber with the same RI matching solution, covered by a coverslip, and imaged by a two-photon microscope. The same cochlear sample was imaged repetitively in the RI matching solutions with increasing RIs. The maximal image depth was determined by measuring the distance from the bone surface to the deepest position where fluorescence signal of MYO7A-positive hair cells can be detected (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). In total, five independent cochlear preparations were imaged.</p></sec><sec id="s3-6"><title>Microscopy and image acquisition</title><p>Imaging of IHCs and OHCs of the organ of Corti was performed on a two-photon microscope (Nikon A1MP) equipped with a mode-locked Ti:sapphire laser (Mai Tai Deep See, Spectra Physics) operated at 800 nm with a 25 × water immersion objective lens (NA = 1.10). A chamber containing the sample was filled with the RI matching solution, covered by a glass coverslip, and placed under the objective lens. The size of single horizontal images was set to 512 × 512, with pixel sizes of 0.99 × 0.99 μm and z-spacing of 1 μm. Images were successively acquired with 10–40% overlap. Image processing was performed using the ImageJ software (National Institute of Health), and three-dimensional rotation was performed using Imaris (Bitplane), FluoRender (Version 2.18, the University of Utah), and NIS-Element AR (Version 4.51, Nikon). Adjustment of fluorescence intensity along the longitudinal axis of the organ of Corti was performed using a MATLAB script written in-house (MathWorks).</p></sec><sec id="s3-7"><title>Automated cell-count and three-dimensional morphology analysis</title><p>Hair cell detection and analysis were performed automatically using custom MATLAB scripts (R2017b, MathWorks); details are provided in Appendix 2. MATLAB source code is available on GitHub (<xref ref-type="bibr" rid="bib17">Iida, 2018a</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/cochlea-analyzer">https://github.com/elifesciences-publications/cochlea-analyzer</ext-link>).</p><sec id="s3-7-1"><title>Step 1: Stitching of multiple image stacks into a single stack</title><p>Multiple image stacks containing portions of the organ of Corti were assembled into a single image stack. Shifts of coordinates between image stacks were calculated based on cross-correlation (MATLAB ‘normxcorr2’ function). After image stitching, a blending algorithm (<xref ref-type="bibr" rid="bib32">Rankov et al., 2005</xref>) was applied to remove sharp intensity changes in the zone of overlap.</p></sec><sec id="s3-7-2"><title>Step 2: Reconstruction of linearized image</title><p>Hair cells in each image stack were detected as local intensity peaks (MATLAB ‘imregionalmax’ function). Single-linkage clustering (maximal distance of connection, 25 μm) was effective for eliminating or reducing the number of false positives. A stretch of local peaks corresponding to the entire row of hair cells were divided into segments of 200–300 μm in length. In each segment, the best-fit plane was calculated (MATLAB ‘pca’ function), together with the best-fit arc along the rows of hair cells. The multiple best-fit arcs were stitched into a continuous curve (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). A voxel image containing the entire straightened row of hair cells was reconstructed from the image stacks, based on the stitched-fit curve and the normal vectors of the fit planes.</p></sec><sec id="s3-7-3"><title>Step 3: Automated detection of IHCs</title><p>First, local correlation between the hair cell template and the voxel image of linearized epithelium was calculated by template matching (MATLAB ‘normxcorr2’ function), and the peaks of the correlation were detected. Pixels corresponding to detected peaks were grouped according to the physical size of the IHCs via connected-component labeling. These connected pixel groups (hereinafter called ‘cell candidates’) were used as a first approximation of IHC positions linked to other attributes, including correlation values and local intensity distributions.</p><p>The cell candidates were further evaluated to eliminate false positives using two successive machine learning models. The first ensemble learning method created the model for selection with predictor data consisting of areas, barycentric coordinates, correlation values, the intensities of the peaks, and the corresponding values of nearby cell candidates (MATLAB ‘fitensemble’ function with ‘GentleBoost’ method) (<xref ref-type="bibr" rid="bib11">Friedman et al., 2000</xref>). The model was trained to calculate posterior probability (prediction score), and cell candidates with a high prediction score (~1000 candidates out of initial ~50,000) were selected and further analyzed by the second ensemble learning method (MATLAB ‘fitensemble’ function with ‘Bag’ method) (<xref ref-type="bibr" rid="bib3">Breiman, 2001</xref>). This method was based on expanded predictors (the prediction score from the first step of the candidate and nearby candidates, and the local intensity distribution centered on the barycentric coordinates of the peaks). The cell candidates after the second selection were connected sequentially, subject to the physical constraint that the IHCs must form a single row with roughly constant intervals of more than 6 μm. The resulting putative positions of IHCs were used for fine readjustment of image linearization and three-dimensional structural analysis.</p></sec><sec id="s3-7-4"><title>Step 4: Automated detection of OHCs</title><p>The image processing applied for IHCs in Step 3 was also applied to OHCs. Detection accuracy was improved by two additional evaluations based on machine learning. First, physical constraints of OHC alignment were introduced into three rows. A multiclass classification model, based on the convolutional neural network method [Neural Network Toolbox of MATLAB (<xref ref-type="bibr" rid="bib22">LeCun et al., 1989</xref>)], sorted cell candidates into respective rows using input images each containing three rows of four or five OHCs. If the distance between two adjacent cell candidates in the same row exceeded 1.5 times the average distance, the presence of additional cells in the gap was assessed by the fourth model based on the convolutional neural network method. Input images for machine learning were sampled by placing small rectangular areas at equal distances from one another within the gap. If the model predicted the existence of additional cells in the gap, the nearest peaks of the correlation coefficient from the first template matching were recovered.</p></sec></sec><sec id="s3-8"><title>Frameworks of machine learning models</title><p>Details of the models used in the detection are shown in <xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="table" rid="table4">Table 4</xref> (<xref ref-type="bibr" rid="bib35">Sokolova and Lapalme, 2009</xref>). Ensemble learning methods were applied to a one-dimensional predictor data set, and the convolutional neural network method was applied to a two-dimensional predictor data set (images). For the first ensemble learning in Steps 3 and 4, the GentleBoost algorithm was selected because of its superior training performance on large data sets relative to the Random Forest algorithm [GentleBoost, MATLAB ‘fitensemble’ function with ‘GentleBoost’ method (<xref ref-type="bibr" rid="bib11">Friedman et al., 2000</xref>); Random Forest, ‘Bag’ method in MATLAB (<xref ref-type="bibr" rid="bib3">Breiman, 2001</xref>)].</p><table-wrap id="table4" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.021</object-id><label>Table 4.</label><caption><title>Number of training and test dataset, and performance evaluation of machine learning models (related to <xref ref-type="fig" rid="fig2">Figure 2</xref>).</title></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Model</th><th colspan="2">Training</th><th colspan="2">Test</th><th rowspan="2">Recall</th><th rowspan="2">Precision</th><th rowspan="2">F score</th></tr><tr><th>Total (n)</th><th>Positive labels (n)</th><th>Total (n)</th><th>Positive labels (n)</th></tr></thead><tbody><tr><td>IHC* 1</td><td>607,954</td><td>5906</td><td>578,851</td><td>5741</td><td>0.961</td><td>0.941</td><td>0.951</td></tr><tr><td>IHC* 2</td><td>37,576</td><td>11,977</td><td>18,104</td><td>5753</td><td>0.977</td><td>0.986</td><td>0.981</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 1</td><td>1,112,659</td><td>20,576</td><td>1,099,519</td><td>19,959</td><td>0.978</td><td>0.914</td><td>0.945</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 2</td><td>28,702</td><td>20,576</td><td>27,185</td><td>19,959</td><td>0.959</td><td>0.979</td><td>0.969</td></tr><tr><td>OHC<sup><bold>†</bold></sup> 3</td><td>20,416</td><td>Row1: 6706 <break/>Row2: 6745 <break/>Row3: 6965</td><td>19,594</td><td>Row1: 6421 <break/>Row2: 6450 <break/>Row3: 6723</td><td>0.993<sup><bold>‡</bold></sup></td><td>0.993<sup><bold>‡</bold></sup></td><td>0.993<sup><bold>‡</bold></sup></td></tr><tr><td>OHC<sup><bold>†</bold></sup> 4</td><td>4114</td><td>1365</td><td>2990</td><td>905</td><td>0.920</td><td>0.946</td><td>0.933</td></tr></tbody></table><table-wrap-foot><fn><p>*. IHC, inner hair cell.</p><p><bold>†</bold>. OHC, outer hair cell.</p></fn><fn><p><bold>‡</bold>. Calculated by micro-average of recall and precision (Sokolova M and Lapalme G, 2009)</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3-9"><title>Evaluation of automated detection system for hair cells</title><p>The detection efficiency of the system is shown in <xref ref-type="table" rid="table2">Table 2</xref>. The models used in the system were trained on ten cochleae as described above, and the efficiency of the trained system was evaluated on ten other cochleae. The results of auto-detection were compared against a reference created by independent manual counting by three human operators. The reference contains fluorescent objects judged to be hair cells by at least two operators.</p></sec><sec id="s3-10"><title>Analysis of spatial distribution of OHCs</title><p>Loss of OHCs results in formation of spatial gaps. To evaluate the extent of cell loss, conventional manual counting estimates the number of lost cells based on the sizes of spatial gaps. In this study, a method that can directly and systematically evaluate the sizes of holes without assuming horizontal rows of hair cells was introduced. The first step of this method was equalization of the coordinates of detected cells throughout the cochlear. Cell positions were adjusted to normalize the average intercellular distance both horizontally and vertically, and to normalize the intercellular distances along the entire organ of Corti. Subsequent placement of square areas with positions matched to the normalized coordinates of detected hair cells left connected pixel groups corresponding to the spaces of putative lost cells. Details of these analyses are provided in Appendix 2.</p></sec><sec id="s3-11"><title>Principal component analysis on OHC loss frequency</title><p>Principal component analysis was performed on the OHC loss frequency along the longitudinal and radial axes of NCL and ACL samples. Variables were the frequency of OHC loss in specific spatial segments. These spatial segments were 13 longitudinal and 15 radial segments that equally divide the total area. A singular value decomposition algorithm was utilized for the calculation of coefficients for the first and second principal components (‘svd’ option of MATLAB ‘pca’ function).</p></sec><sec id="s3-12"><title>Analysis of the three-dimensional structure of the cochlea</title><p>The spiral structure of the cochlea was analyzed based on the three-dimensional spatial distribution of IHCs because these cells formed a row that was rarely disturbed. Details of these analyses are provided in Appendix 2.</p></sec><sec id="s3-13"><title>Simulation analysis of clustered cell loss</title><p>It was observed that lost OHCs tended to be clustered. Simulation analysis was performed to evaluate two independent factors that could be responsible for such clustering. (1) A lost cell increases the probability that neighboring cells will be lost (Model 1; neighborhood effect). (2) Cell loss takes place with a probability that is a function of the local environment of the sensory epithelium (Model 2; position effect). The simulation was performed on each cochlea sample, using the measured ratio of cell loss, the number of clusters, and the cluster sizes. The simulation was performed on two matrices, the ‘cell matrix’ and ‘probability matrix’, with sizes of 3 rows × 600 columns corresponding to the distribution of OHCs (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The cell matrix recorded the positions of cell loss, and the probability matrix recorded the probabilities of cell loss in each step of the simulation.</p><p>Each operation started with a cell matrix with no lost cells and a probability matrix with or without an initial position effect. In each step, a single cell was selected for removal with a probability given by the probability matrix, and the position was recorded in the cell matrix. The operation was stopped when the total number of lost cells reached the number of cells lost in a given sample.</p><p>The neighborhood effect was created by adding an additional weight to the adjacent probability matrix elements. To introduce the position effect, random numbers were generated according to a power-law distribution calculated by the following function.<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.1</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>0.1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where p is the parameter controlling the shape of distribution. The values along the row of the probability matrix were obtained from the function P(x), with input x drawn from a uniform distribution between 0 and 1. Values in the same column were set to be identical. Gaussian filtering was applied to the probability matrix to broaden the peak width.</p><p>A panel of 16 simulated histograms was created for each sample by changing the relative weights of two effects (neighborhood and position effects) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The operation was repeated 500 times for each parameter set. A histogram of cluster size was constructed, and similarity to the measured data was evaluated (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The extent of histogram dissimilarity between measured and simulation results was calculated by the sum of squared errors (error score), and a two-dimensional heat map was created (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). The weighted average of the top three combinations of weights was calculated and taken to represent the relative contribution of two factors to cell loss events.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>We thank Dr. Hiroyuki Hioki for anti-VGLUT3 antibody.</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft</p></fn><fn fn-type="con" id="con3"><p>Resources, Writing—original draft</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Investigation</p></fn><fn fn-type="con" id="con5"><p>Supervision, Funding acquisition, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Supervision, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Funding acquisition, Writing—original draft, Project administration</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the University of Tokyo. All of the animals were handled according to approved institutional animal care and use committee protocol (Medicine-P12-138) of the University of Tokyo.</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.40946.022</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-40946-transrepform-v1.docx"/></supplementary-material><sec id="s8" sec-type="data-availability"><title>Data availability</title><p>Data generated or analysed during this study are included in the supporting files (Figures 1-5 - Source Data, excel files). Source code is available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/cochlea-analyzer">https://github.com/okabe-lab/cochlea-analyzer</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/Watershed">https://github.com/okabe-lab/Watershed</ext-link></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acar</surname> <given-names>M</given-names></name><name><surname>Kocherlakota</surname> <given-names>KS</given-names></name><name><surname>Murphy</surname> <given-names>MM</given-names></name><name><surname>Peyer</surname> <given-names>JG</given-names></name><name><surname>Oguro</surname> <given-names>H</given-names></name><name><surname>Inra</surname> <given-names>CN</given-names></name><name><surname>Jaiyeola</surname> <given-names>C</given-names></name><name><surname>Zhao</surname> <given-names>Z</given-names></name><name><surname>Luby-Phelps</surname> <given-names>K</given-names></name><name><surname>Morrison</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep imaging of bone marrow shows non-dividing stem cells are mainly perisinusoidal</article-title><source>Nature</source><volume>526</volume><fpage>126</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1038/nature15250</pub-id><pub-id pub-id-type="pmid">26416744</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berke</surname> <given-names>IM</given-names></name><name><surname>Miola</surname> <given-names>JP</given-names></name><name><surname>David</surname> <given-names>MA</given-names></name><name><surname>Smith</surname> <given-names>MK</given-names></name><name><surname>Price</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Seeing through musculoskeletal tissues: improving in situ imaging of bone and the lacunar canalicular system through optical clearing</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0150268</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0150268</pub-id><pub-id pub-id-type="pmid">26930293</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Random forests</article-title><source>Machine Learning</source><volume>45</volume><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cai</surname> <given-names>R</given-names></name><name><surname>Pan</surname> <given-names>C</given-names></name><name><surname>A</surname> <given-names>G</given-names></name><name><surname>Todorov</surname> <given-names>MI</given-names></name><name><surname>Foerstera</surname> <given-names>B</given-names></name><name><surname>Zhao</surname> <given-names>S</given-names></name><name><surname>Bhatia</surname> <given-names>HS</given-names></name><name><surname>Mrowka</surname> <given-names>L</given-names></name><name><surname>Theodorou</surname> <given-names>D</given-names></name><name><surname>Rempfler</surname> <given-names>M</given-names></name><name><surname>Xavier</surname> <given-names>A</given-names></name><name><surname>Kress</surname> <given-names>BT</given-names></name><name><surname>Benakis</surname> <given-names>C</given-names></name><name><surname>Liesz</surname> <given-names>A</given-names></name><name><surname>Menze</surname> <given-names>B</given-names></name><name><surname>Kerschensteiner</surname> <given-names>M</given-names></name><name><surname>Nedergaard</surname> <given-names>M</given-names></name><name><surname>Erturk</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Panoptic vDISCO imaging reveals neuronal connectivity, remote trauma effects and meningeal vessels in intact transparent mice</article-title><source>BioRxiv</source><pub-id pub-id-type="doi">10.1101/374785</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calve</surname> <given-names>S</given-names></name><name><surname>Ready</surname> <given-names>A</given-names></name><name><surname>Huppenbauer</surname> <given-names>C</given-names></name><name><surname>Main</surname> <given-names>R</given-names></name><name><surname>Neu</surname> <given-names>CP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Optical clearing in dense connective tissues to visualize cellular connectivity in situ</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0116662</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0116662</pub-id><pub-id pub-id-type="pmid">25581165</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chien</surname> <given-names>W</given-names></name><name><surname>Lin</surname> <given-names>FR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Prevalence of hearing aid use among older adults in the United States</article-title><source>Archives of Internal Medicine</source><volume>172</volume><fpage>292</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1001/archinternmed.2011.1408</pub-id><pub-id pub-id-type="pmid">22332170</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname> <given-names>K</given-names></name><name><surname>Wallace</surname> <given-names>J</given-names></name><name><surname>Kim</surname> <given-names>SY</given-names></name><name><surname>Kalyanasundaram</surname> <given-names>S</given-names></name><name><surname>Andalman</surname> <given-names>AS</given-names></name><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Mirzabekov</surname> <given-names>JJ</given-names></name><name><surname>Zalocusky</surname> <given-names>KA</given-names></name><name><surname>Mattis</surname> <given-names>J</given-names></name><name><surname>Denisin</surname> <given-names>AK</given-names></name><name><surname>Pak</surname> <given-names>S</given-names></name><name><surname>Bernstein</surname> <given-names>H</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Grosenick</surname> <given-names>L</given-names></name><name><surname>Gradinaru</surname> <given-names>V</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Structural and molecular interrogation of intact biological systems</article-title><source>Nature</source><volume>497</volume><fpage>332</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1038/nature12107</pub-id><pub-id pub-id-type="pmid">23575631</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname> <given-names>LL</given-names></name><name><surname>Tucci</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hearing loss in adults</article-title><source>New England Journal of Medicine</source><volume>377</volume><fpage>2465</fpage><lpage>2473</lpage><pub-id pub-id-type="doi">10.1056/NEJMra1616601</pub-id><pub-id pub-id-type="pmid">29262274</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodt</surname> <given-names>HU</given-names></name><name><surname>Leischner</surname> <given-names>U</given-names></name><name><surname>Schierloh</surname> <given-names>A</given-names></name><name><surname>Jährling</surname> <given-names>N</given-names></name><name><surname>Mauch</surname> <given-names>CP</given-names></name><name><surname>Deininger</surname> <given-names>K</given-names></name><name><surname>Deussing</surname> <given-names>JM</given-names></name><name><surname>Eder</surname> <given-names>M</given-names></name><name><surname>Zieglgänsberger</surname> <given-names>W</given-names></name><name><surname>Becker</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Ultramicroscopy: three-dimensional visualization of neuronal networks in the whole mouse brain</article-title><source>Nature Methods</source><volume>4</volume><fpage>331</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1038/nmeth1036</pub-id><pub-id pub-id-type="pmid">17384643</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ertürk</surname> <given-names>A</given-names></name><name><surname>Becker</surname> <given-names>K</given-names></name><name><surname>Jährling</surname> <given-names>N</given-names></name><name><surname>Mauch</surname> <given-names>CP</given-names></name><name><surname>Hojer</surname> <given-names>CD</given-names></name><name><surname>Egen</surname> <given-names>JG</given-names></name><name><surname>Hellal</surname> <given-names>F</given-names></name><name><surname>Bradke</surname> <given-names>F</given-names></name><name><surname>Sheng</surname> <given-names>M</given-names></name><name><surname>Dodt</surname> <given-names>HU</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Three-dimensional imaging of solvent-cleared organs using 3disco</article-title><source>Nature Protocols</source><volume>7</volume><fpage>1983</fpage><lpage>1995</lpage><pub-id pub-id-type="doi">10.1038/nprot.2012.119</pub-id><pub-id pub-id-type="pmid">23060243</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname> <given-names>J</given-names></name><name><surname>Tibshirani</surname> <given-names>R</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Additive logistic regression: a statistical view of boosting</article-title><source>The Annals of Statistics</source><volume>28</volume><fpage>337</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1214/aos/1016218223</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenbaum</surname> <given-names>A</given-names></name><name><surname>Chan</surname> <given-names>KY</given-names></name><name><surname>Dobreva</surname> <given-names>T</given-names></name><name><surname>Brown</surname> <given-names>D</given-names></name><name><surname>Balani</surname> <given-names>DH</given-names></name><name><surname>Boyce</surname> <given-names>R</given-names></name><name><surname>Kronenberg</surname> <given-names>HM</given-names></name><name><surname>McBride</surname> <given-names>HJ</given-names></name><name><surname>Gradinaru</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Bone CLARITY: clearing, imaging, and computational analysis of osteoprogenitors within intact bone marrow</article-title><source>Science Translational Medicine</source><volume>9</volume><elocation-id>eaah6518</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.aah6518</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hama</surname> <given-names>H</given-names></name><name><surname>Hioki</surname> <given-names>H</given-names></name><name><surname>Namiki</surname> <given-names>K</given-names></name><name><surname>Hoshida</surname> <given-names>T</given-names></name><name><surname>Kurokawa</surname> <given-names>H</given-names></name><name><surname>Ishidate</surname> <given-names>F</given-names></name><name><surname>Kaneko</surname> <given-names>T</given-names></name><name><surname>Akagi</surname> <given-names>T</given-names></name><name><surname>Saito</surname> <given-names>T</given-names></name><name><surname>Saido</surname> <given-names>T</given-names></name><name><surname>Miyawaki</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>ScaleS: an optical clearing palette for biological imaging</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1518</fpage><lpage>1529</lpage><pub-id pub-id-type="doi">10.1038/nn.4107</pub-id><pub-id pub-id-type="pmid">26368944</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname> <given-names>BH</given-names></name><name><surname>Cai</surname> <given-names>Q</given-names></name><name><surname>Hu</surname> <given-names>Z</given-names></name><name><surname>Patel</surname> <given-names>M</given-names></name><name><surname>Bard</surname> <given-names>J</given-names></name><name><surname>Jamison</surname> <given-names>J</given-names></name><name><surname>Coling</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Metalloproteinases and their associated genes contribute to the functional integrity and noise-induced damage in the cochlear sensory epithelium</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>14927</fpage><lpage>14941</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1588-12.2012</pub-id><pub-id pub-id-type="pmid">23100416</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>JR</given-names></name><name><surname>Craggs</surname> <given-names>TD</given-names></name><name><surname>Christodoulou</surname> <given-names>J</given-names></name><name><surname>Jackson</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Stable intermediate states and high energy barriers in the unfolding of GFP</article-title><source>Journal of Molecular Biology</source><volume>370</volume><fpage>356</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1016/j.jmb.2007.04.039</pub-id><pub-id pub-id-type="pmid">17512539</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname> <given-names>KP</given-names></name><name><surname>Willott</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Aging and the auditory brainstem response in mice with severe or minimal presbycusis</article-title><source>Hearing Research</source><volume>30</volume><fpage>207</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(87)90137-7</pub-id><pub-id pub-id-type="pmid">3680066</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Iida</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018a</year><data-title>cochlea-analyzer</data-title><source>GitHub</source><version designator="2d191ca">2d191ca</version><ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/cochlea-analyzer">https://github.com/okabe-lab/cochlea-analyzer</ext-link></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Iida</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018b</year><data-title>Watershed</data-title><source>GitHub</source><version designator="de83d0a">de83d0a</version><ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/Watershed">https://github.com/okabe-lab/Watershed</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Imamura</surname> <given-names>H</given-names></name><name><surname>Nhat</surname> <given-names>KP</given-names></name><name><surname>Togawa</surname> <given-names>H</given-names></name><name><surname>Saito</surname> <given-names>K</given-names></name><name><surname>Iino</surname> <given-names>R</given-names></name><name><surname>Kato-Yamada</surname> <given-names>Y</given-names></name><name><surname>Nagai</surname> <given-names>T</given-names></name><name><surname>Noji</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visualization of ATP levels inside single living cells with fluorescence resonance energy transfer-based genetically encoded indicators</article-title><source>PNAS</source><volume>106</volume><fpage>15651</fpage><lpage>15656</lpage><pub-id pub-id-type="doi">10.1073/pnas.0904764106</pub-id><pub-id pub-id-type="pmid">19720993</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ison</surname> <given-names>JR</given-names></name><name><surname>Allen</surname> <given-names>PD</given-names></name><name><surname>O'Neill</surname> <given-names>WE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Age-related hearing loss in C57BL/6J mice has both frequency-specific and non-frequency-specific components that produce a hyperacusis-like exaggeration of the acoustic startle reflex</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>8</volume><fpage>539</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1007/s10162-007-0098-3</pub-id><pub-id pub-id-type="pmid">17952509</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jing</surname> <given-names>D</given-names></name><name><surname>Zhang</surname> <given-names>S</given-names></name><name><surname>Luo</surname> <given-names>W</given-names></name><name><surname>Gao</surname> <given-names>X</given-names></name><name><surname>Men</surname> <given-names>Y</given-names></name><name><surname>Ma</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>X</given-names></name><name><surname>Yi</surname> <given-names>Y</given-names></name><name><surname>Bugde</surname> <given-names>A</given-names></name><name><surname>Zhou</surname> <given-names>BO</given-names></name><name><surname>Zhao</surname> <given-names>Z</given-names></name><name><surname>Yuan</surname> <given-names>Q</given-names></name><name><surname>Feng</surname> <given-names>JQ</given-names></name><name><surname>Gao</surname> <given-names>L</given-names></name><name><surname>Ge</surname> <given-names>WP</given-names></name><name><surname>Zhao</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Tissue clearing of both hard and soft tissue organs with the PEGASOS method</article-title><source>Cell Research</source><volume>28</volume><fpage>803</fpage><lpage>818</lpage><pub-id pub-id-type="doi">10.1038/s41422-018-0049-z</pub-id><pub-id pub-id-type="pmid">29844583</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname> <given-names>Y</given-names></name><name><surname>Boser</surname> <given-names>B</given-names></name><name><surname>Denker</surname> <given-names>JS</given-names></name><name><surname>Henderson</surname> <given-names>D</given-names></name><name><surname>Howard</surname> <given-names>RE</given-names></name><name><surname>Hubbard</surname> <given-names>W</given-names></name><name><surname>Jackel</surname> <given-names>LD</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Backpropagation applied to handwritten zip code recognition</article-title><source>Neural Computation</source><volume>1</volume><fpage>541</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1162/neco.1989.1.4.541</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>E</given-names></name><name><surname>Choi</surname> <given-names>J</given-names></name><name><surname>Jo</surname> <given-names>Y</given-names></name><name><surname>Kim</surname> <given-names>JY</given-names></name><name><surname>Jang</surname> <given-names>YJ</given-names></name><name><surname>Lee</surname> <given-names>HM</given-names></name><name><surname>Kim</surname> <given-names>SY</given-names></name><name><surname>Lee</surname> <given-names>HJ</given-names></name><name><surname>Cho</surname> <given-names>K</given-names></name><name><surname>Jung</surname> <given-names>N</given-names></name><name><surname>Hur</surname> <given-names>EM</given-names></name><name><surname>Jeong</surname> <given-names>SJ</given-names></name><name><surname>Moon</surname> <given-names>C</given-names></name><name><surname>Choe</surname> <given-names>Y</given-names></name><name><surname>Rhyu</surname> <given-names>IJ</given-names></name><name><surname>Kim</surname> <given-names>H</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>ACT-PRESTO: rapid and consistent tissue clearing and labeling method for 3-dimensional (3D) imaging</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>18631</elocation-id><pub-id pub-id-type="doi">10.1038/srep18631</pub-id><pub-id pub-id-type="pmid">26750588</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Gracewski</surname> <given-names>SM</given-names></name><name><surname>Nam</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Consequences of Location-Dependent organ of corti Micro-Mechanics</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0133284</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0133284</pub-id><pub-id pub-id-type="pmid">26317521</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizushima</surname> <given-names>Y</given-names></name><name><surname>Fujimoto</surname> <given-names>C</given-names></name><name><surname>Kashio</surname> <given-names>A</given-names></name><name><surname>Kondo</surname> <given-names>K</given-names></name><name><surname>Yamasoba</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Macrophage recruitment, but not interleukin 1 beta activation, enhances noise-induced hearing damage</article-title><source>Biochemical and Biophysical Research Communications</source><volume>493</volume><fpage>894</fpage><lpage>900</lpage><pub-id pub-id-type="doi">10.1016/j.bbrc.2017.09.124</pub-id><pub-id pub-id-type="pmid">28951212</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Machine Learning: A Probabilistic Perspective</source><publisher-loc>Cambridge</publisher-loc><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakano</surname> <given-names>M</given-names></name><name><surname>Imamura</surname> <given-names>H</given-names></name><name><surname>Nagai</surname> <given-names>T</given-names></name><name><surname>Noji</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ca²⁺ regulation of mitochondrial ATP synthesis visualized at the single cell level</article-title><source>ACS Chemical Biology</source><volume>6</volume><fpage>709</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1021/cb100313n</pub-id><pub-id pub-id-type="pmid">21488691</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname> <given-names>DI</given-names></name><name><surname>Nelson</surname> <given-names>RY</given-names></name><name><surname>Concha-Barrientos</surname> <given-names>M</given-names></name><name><surname>Fingerhut</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The global burden of occupational noise-induced hearing loss</article-title><source>American Journal of Industrial Medicine</source><volume>48</volume><fpage>446</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1002/ajim.20223</pub-id><pub-id pub-id-type="pmid">16299704</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname> <given-names>L</given-names></name><name><surname>Tinne</surname> <given-names>N</given-names></name><name><surname>Schulze</surname> <given-names>J</given-names></name><name><surname>Heinemann</surname> <given-names>D</given-names></name><name><surname>Antonopoulos</surname> <given-names>GC</given-names></name><name><surname>Meyer</surname> <given-names>H</given-names></name><name><surname>Nothwang</surname> <given-names>HG</given-names></name><name><surname>Lenarz</surname> <given-names>T</given-names></name><name><surname>Heisterkamp</surname> <given-names>A</given-names></name><name><surname>Warnecke</surname> <given-names>A</given-names></name><name><surname>Ripken</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Scanning laser optical tomography for in toto imaging of the murine cochlea</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0175431</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0175431</pub-id><pub-id pub-id-type="pmid">28388662</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oesterle</surname> <given-names>EC</given-names></name><name><surname>Campbell</surname> <given-names>S</given-names></name><name><surname>Taylor</surname> <given-names>RR</given-names></name><name><surname>Forge</surname> <given-names>A</given-names></name><name><surname>Hume</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sox2 and JAGGED1 expression in normal and drug-damaged adult mouse inner ear</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>9</volume><fpage>65</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1007/s10162-007-0106-7</pub-id><pub-id pub-id-type="pmid">18157569</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otsu</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>A threshold selection method from Gray-Level histograms</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics</source><volume>9</volume><fpage>62</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1109/TSMC.1979.4310076</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rankov</surname> <given-names>V</given-names></name><name><surname>Locke</surname> <given-names>RJ</given-names></name><name><surname>Edens</surname> <given-names>RJ</given-names></name><name><surname>Barber</surname> <given-names>PR</given-names></name><name><surname>Vojnovic</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An algorithm for image stitching and blending</article-title><source>Proceeding of SPIE</source><volume>5701</volume><fpage>190</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1117/12.590536</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renier</surname> <given-names>N</given-names></name><name><surname>Wu</surname> <given-names>Z</given-names></name><name><surname>Simon</surname> <given-names>DJ</given-names></name><name><surname>Yang</surname> <given-names>J</given-names></name><name><surname>Ariel</surname> <given-names>P</given-names></name><name><surname>Tessier-Lavigne</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>iDISCO: a simple, rapid method to immunolabel large tissue samples for volume imaging</article-title><source>Cell</source><volume>159</volume><fpage>896</fpage><lpage>910</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.10.010</pub-id><pub-id pub-id-type="pmid">25417164</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soille</surname> <given-names>P</given-names></name><name><surname>Vincent</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Determining watersheds in digital pictures via flooding simulations</article-title><source>Proceeding of SPIE</source><volume>1360</volume><fpage>240</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1117/12.24211</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokolova</surname> <given-names>M</given-names></name><name><surname>Lapalme</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A systematic analysis of performance measures for classification tasks</article-title><source>Information Processing &amp; Management</source><volume>45</volume><fpage>427</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1016/j.ipm.2009.03.002</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soons</surname> <given-names>JA</given-names></name><name><surname>Ricci</surname> <given-names>AJ</given-names></name><name><surname>Steele</surname> <given-names>CR</given-names></name><name><surname>Puria</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cytoarchitecture of the mouse organ of corti from base to apex, determined using in situ two-photon imaging</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>16</volume><fpage>47</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1007/s10162-014-0497-1</pub-id><pub-id pub-id-type="pmid">25348579</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Susaki</surname> <given-names>EA</given-names></name><name><surname>Tainaka</surname> <given-names>K</given-names></name><name><surname>Perrin</surname> <given-names>D</given-names></name><name><surname>Kishino</surname> <given-names>F</given-names></name><name><surname>Tawara</surname> <given-names>T</given-names></name><name><surname>Watanabe</surname> <given-names>TM</given-names></name><name><surname>Yokoyama</surname> <given-names>C</given-names></name><name><surname>Onoe</surname> <given-names>H</given-names></name><name><surname>Eguchi</surname> <given-names>M</given-names></name><name><surname>Yamaguchi</surname> <given-names>S</given-names></name><name><surname>Abe</surname> <given-names>T</given-names></name><name><surname>Kiyonari</surname> <given-names>H</given-names></name><name><surname>Shimizu</surname> <given-names>Y</given-names></name><name><surname>Miyawaki</surname> <given-names>A</given-names></name><name><surname>Yokota</surname> <given-names>H</given-names></name><name><surname>Ueda</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Whole-brain imaging with single-cell resolution using chemical cocktails and computational analysis</article-title><source>Cell</source><volume>157</volume><fpage>726</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.03.042</pub-id><pub-id pub-id-type="pmid">24746791</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Susaki</surname> <given-names>EA</given-names></name><name><surname>Tainaka</surname> <given-names>K</given-names></name><name><surname>Perrin</surname> <given-names>D</given-names></name><name><surname>Yukinaga</surname> <given-names>H</given-names></name><name><surname>Kuno</surname> <given-names>A</given-names></name><name><surname>Ueda</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Advanced CUBIC protocols for whole-brain and whole-body clearing and imaging</article-title><source>Nature Protocols</source><volume>10</volume><fpage>1709</fpage><lpage>1727</lpage><pub-id pub-id-type="doi">10.1038/nprot.2015.085</pub-id><pub-id pub-id-type="pmid">26448360</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tainaka</surname> <given-names>K</given-names></name><name><surname>Kubota</surname> <given-names>SI</given-names></name><name><surname>Suyama</surname> <given-names>TQ</given-names></name><name><surname>Susaki</surname> <given-names>EA</given-names></name><name><surname>Perrin</surname> <given-names>D</given-names></name><name><surname>Ukai-Tadenuma</surname> <given-names>M</given-names></name><name><surname>Ukai</surname> <given-names>H</given-names></name><name><surname>Ueda</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Whole-body imaging with single-cell resolution by tissue decolorization</article-title><source>Cell</source><volume>159</volume><fpage>911</fpage><lpage>924</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.10.034</pub-id><pub-id pub-id-type="pmid">25417165</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tainaka</surname> <given-names>K</given-names></name><name><surname>Kuno</surname> <given-names>A</given-names></name><name><surname>Kubota</surname> <given-names>SI</given-names></name><name><surname>Murakami</surname> <given-names>T</given-names></name><name><surname>Ueda</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Chemical principles in tissue clearing and staining protocols for Whole-Body cell profiling</article-title><source>Annual Review of Cell and Developmental Biology</source><volume>32</volume><fpage>713</fpage><lpage>741</lpage><pub-id pub-id-type="doi">10.1146/annurev-cellbio-111315-125001</pub-id><pub-id pub-id-type="pmid">27298088</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tainaka</surname> <given-names>K</given-names></name><name><surname>Murakami</surname> <given-names>TC</given-names></name><name><surname>Susaki</surname> <given-names>EA</given-names></name><name><surname>Shimizu</surname> <given-names>C</given-names></name><name><surname>Saito</surname> <given-names>R</given-names></name><name><surname>Takahashi</surname> <given-names>K</given-names></name><name><surname>Hayashi-Takagi</surname> <given-names>A</given-names></name><name><surname>Sekiya</surname> <given-names>H</given-names></name><name><surname>Arima</surname> <given-names>Y</given-names></name><name><surname>Nojima</surname> <given-names>S</given-names></name><name><surname>Ikemura</surname> <given-names>M</given-names></name><name><surname>Ushiku</surname> <given-names>T</given-names></name><name><surname>Shimizu</surname> <given-names>Y</given-names></name><name><surname>Murakami</surname> <given-names>M</given-names></name><name><surname>Tanaka</surname> <given-names>KF</given-names></name><name><surname>Iino</surname> <given-names>M</given-names></name><name><surname>Kasai</surname> <given-names>H</given-names></name><name><surname>Sasaoka</surname> <given-names>T</given-names></name><name><surname>Kobayashi</surname> <given-names>K</given-names></name><name><surname>Miyazono</surname> <given-names>K</given-names></name><name><surname>Morii</surname> <given-names>E</given-names></name><name><surname>Isa</surname> <given-names>T</given-names></name><name><surname>Fukayama</surname> <given-names>M</given-names></name><name><surname>Kakita</surname> <given-names>A</given-names></name><name><surname>Ueda</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chemical landscape for tissue clearing based on hydrophilic reagents</article-title><source>Cell Reports</source><volume>24</volume><fpage>2196</fpage><lpage>2210</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.07.056</pub-id><pub-id pub-id-type="pmid">30134179</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Temchin</surname> <given-names>AN</given-names></name><name><surname>Ruggero</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial irregularities of sensitivity along the organ of corti of the cochlea</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>11349</fpage><lpage>11354</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2558-13.2014</pub-id><pub-id pub-id-type="pmid">25143615</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tinne</surname> <given-names>N</given-names></name><name><surname>Antonopoulos</surname> <given-names>GC</given-names></name><name><surname>Mohebbi</surname> <given-names>S</given-names></name><name><surname>Andrade</surname> <given-names>J</given-names></name><name><surname>Nolte</surname> <given-names>L</given-names></name><name><surname>Meyer</surname> <given-names>H</given-names></name><name><surname>Heisterkamp</surname> <given-names>A</given-names></name><name><surname>Majdani</surname> <given-names>O</given-names></name><name><surname>Ripken</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Three-dimensional hard and soft tissue imaging of the human cochlea by scanning laser optical tomography (SLOT)</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0184069</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0184069</pub-id><pub-id pub-id-type="pmid">28873437</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomer</surname> <given-names>R</given-names></name><name><surname>Ye</surname> <given-names>L</given-names></name><name><surname>Hsueh</surname> <given-names>B</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Advanced CLARITY for rapid and high-resolution imaging of intact tissues</article-title><source>Nature Protocols</source><volume>9</volume><fpage>1682</fpage><lpage>1697</lpage><pub-id pub-id-type="doi">10.1038/nprot.2014.123</pub-id><pub-id pub-id-type="pmid">24945384</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treweek</surname> <given-names>JB</given-names></name><name><surname>Chan</surname> <given-names>KY</given-names></name><name><surname>Flytzanis</surname> <given-names>NC</given-names></name><name><surname>Yang</surname> <given-names>B</given-names></name><name><surname>Deverman</surname> <given-names>BE</given-names></name><name><surname>Greenbaum</surname> <given-names>A</given-names></name><name><surname>Lignell</surname> <given-names>A</given-names></name><name><surname>Xiao</surname> <given-names>C</given-names></name><name><surname>Cai</surname> <given-names>L</given-names></name><name><surname>Ladinsky</surname> <given-names>MS</given-names></name><name><surname>Bjorkman</surname> <given-names>PJ</given-names></name><name><surname>Fowlkes</surname> <given-names>CC</given-names></name><name><surname>Gradinaru</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Whole-body tissue stabilization and selective extractions via tissue-hydrogel hybrids for high-resolution intact circuit mapping and phenotyping</article-title><source>Nature Protocols</source><volume>10</volume><fpage>1860</fpage><lpage>1896</lpage><pub-id pub-id-type="doi">10.1038/nprot.2015.122</pub-id><pub-id pub-id-type="pmid">26492141</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tuerdi</surname> <given-names>A</given-names></name><name><surname>Kinoshita</surname> <given-names>M</given-names></name><name><surname>Kamogashira</surname> <given-names>T</given-names></name><name><surname>Fujimoto</surname> <given-names>C</given-names></name><name><surname>Iwasaki</surname> <given-names>S</given-names></name><name><surname>Shimizu</surname> <given-names>T</given-names></name><name><surname>Yamasoba</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Manganese superoxide dismutase influences the extent of noise-induced hearing loss in mice</article-title><source>Neuroscience Letters</source><volume>642</volume><fpage>123</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1016/j.neulet.2017.02.003</pub-id><pub-id pub-id-type="pmid">28163078</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Békésy</surname> <given-names>G</given-names></name><name><surname>Peake</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Experiments in hearing</article-title><source>The Journal of the Acoustical Society of America</source><volume>88</volume><elocation-id>2905</elocation-id><pub-id pub-id-type="doi">10.1121/1.399656</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Hirose</surname> <given-names>K</given-names></name><name><surname>Liberman</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dynamics of noise-induced cellular injury and repair in the mouse cochlea</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>3</volume><fpage>248</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1007/s101620020028</pub-id><pub-id pub-id-type="pmid">12382101</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamasoba</surname> <given-names>T</given-names></name><name><surname>Nuttall</surname> <given-names>AL</given-names></name><name><surname>Harris</surname> <given-names>C</given-names></name><name><surname>Raphael</surname> <given-names>Y</given-names></name><name><surname>Miller</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Role of glutathione in protection against noise-induced hearing loss</article-title><source>Brain Research</source><volume>784</volume><fpage>82</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(97)01156-6</pub-id><pub-id pub-id-type="pmid">9518561</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>WP</given-names></name><name><surname>Henderson</surname> <given-names>D</given-names></name><name><surname>Hu</surname> <given-names>BH</given-names></name><name><surname>Nicotera</surname> <given-names>TM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Quantitative analysis of apoptotic and necrotic outer hair cells after exposure to different levels of continuous noise</article-title><source>Hearing Research</source><volume>196</volume><fpage>69</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2004.04.015</pub-id><pub-id pub-id-type="pmid">15464303</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yokomizo</surname> <given-names>T</given-names></name><name><surname>Yamada-Inagawa</surname> <given-names>T</given-names></name><name><surname>Yzaguirre</surname> <given-names>AD</given-names></name><name><surname>Chen</surname> <given-names>MJ</given-names></name><name><surname>Speck</surname> <given-names>NA</given-names></name><name><surname>Dzierzak</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Whole-mount three-dimensional imaging of internally localized immunostained cells within mouse embryos</article-title><source>Nature Protocols</source><volume>7</volume><fpage>421</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1038/nprot.2011.441</pub-id><pub-id pub-id-type="pmid">22322215</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>QY</given-names></name><name><surname>Johnson</surname> <given-names>KR</given-names></name><name><surname>Erway</surname> <given-names>LC</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Assessment of hearing in 80 inbred strains of mice by ABR threshold analyses</article-title><source>Hearing Research</source><volume>130</volume><fpage>94</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(99)00003-9</pub-id><pub-id pub-id-type="pmid">10320101</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.40946.023</object-id><sec id="s6" sec-type="appendix"><title>Supplemental materials and methods</title><sec id="s6-1"><title>Animals</title><p>Mouse husbandry, anesthesia, and euthanasia conformed to related regulations of the government and the institutional guidelines. Protocols related to animal handling were approved by the Animal Care and Use Committee of the Graduate School of Medicine, the University of Tokyo. Male or female wild type C57BL/6J, ICR, and CBA/Ca mice at ages of PND 0 to 360 were used for application of modified Sca/eS with or without antibody labeling. For the detection of fluorescent protein signals, Thy1-GFP M line and a transgenic line expressing a fluorescence resonance energy transfer (FRET)-based indicators (GO-ATeam mouse line) (<xref ref-type="bibr" rid="bib19">Imamura et al., 2009</xref>; <xref ref-type="bibr" rid="bib27">Nakano et al., 2011</xref>) were used at ages of PND 0 to 120.</p></sec><sec id="s6-2"><title>Tissue acquisition</title><p>After euthanasia, mice were perfused transcardially with 4% paraformaldehyde (PFA) in phosphate buffered saline (PBS). Osteochondral samples (cochlea embedded in temporal bones and femurs) and other soft tissues (brain, heart, stomach, lung, liver, kidney, intestine, and spleen) were isolated by standard dissection techniques. For mice younger than PND 5, the step of transcardial perfusion was omitted. The isolated tissues were placed in the same fixative (4% PFA in PBS) for 10 to 24 hr. Fixed brain samples were sectioned into 100 μm to 2 mm thick sections using a vibratome.</p></sec><sec id="s6-3"><title><bold>Tissue clearing methods</bold></title><p><bold>iDISCO</bold>; iDISCO was performed according to the published protocol (<xref ref-type="bibr" rid="bib33">Renier et al., 2014</xref>). Fixed samples were treated with methanol with increasing concentrations, bleached with 5% H<sub>2</sub>O<sub>2</sub>, and rehydrated by decreasing concentration of methanol in PBS. Anti-MYO7A staining was performed after 0.3 M glycine treatment and blocking with 6% normal goat serum. Tissue clearing was achieved by treatment with increasing concentration of tetrahydrofuran/H<sub>2</sub>O up to 80% (v/v), subsequent transfer to dichloromethane, and final incubation with dibenzyl ether.</p><p><bold>3DISCO</bold>; 3DISCO was performed according to the published protocols (<xref ref-type="bibr" rid="bib1">Acar et al., 2015</xref>; <xref ref-type="bibr" rid="bib10">Ertürk et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Yokomizo et al., 2012</xref>). Fixed samples were blocked with normal goat serum and then reacted with primary and secondary antibodies. After immunolabeling, samples were treated with increasing concentration of tetrahydrofuran/H<sub>2</sub>O up to 80% (v/v), subsequent transfer to dichloromethane, and final incubation with dibenzyl ether.</p><p><bold>CLARITY</bold>; CLARITY was performed according to the published protocols (<xref ref-type="bibr" rid="bib7">Chung et al., 2013</xref>; <xref ref-type="bibr" rid="bib44">Tomer et al., 2014</xref>). Briefly, animals were fixed by perfusion with a solution containing 4% paraformaldehyde, 4% acrylamide, 0.05% bis-acrylamide, 0.25% VA-044 initiator in PBS, followed by induction of hydrogel tissue embedding by raising temperature to 37°C for 3 hr. After electrophoretic tissue clearing in a chamber containing 200 mM boric acid and 4% sodium dodecyl sulfate with 20 V applied across the sample at 37°C for 72 hr, samples were blocked with normal goat serum, reacted with primary and secondary antibodies. After washing, the samples were placed in FocusClear (CelExplorer Labs) medium.</p><p><bold>CUBIC</bold>; CUBIC was performed according to the published protocols (<xref ref-type="bibr" rid="bib37">Susaki et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Susaki et al., 2015</xref>; <xref ref-type="bibr" rid="bib39">Tainaka et al., 2014</xref>). Briefly, fixed samples were placed in ScaleCUBIC-1 (25% urea, 25% N,N,N’,N’-tetrakis (2-hydroxypropyl) ethylenediamine, 15% Triton X-100) at 37°C for 24 hr, followed by brief washing and incubation with Sca<italic>l</italic>eCUBIC-2 (50% sucrose, 25% urea, 10% 2,2’,2’’-nitrilotriethanol) for 2 hr. After brief washing, samples were placed in Sca<italic>l</italic>eCUBIC-2.</p><p><bold>CB-perfusion</bold>; CB-perfusion was performed according to the published protocols (<xref ref-type="bibr" rid="bib39">Tainaka et al., 2014</xref>). Briefly, animals were first treated with perfusion of an excess amount of 4% paraformaldehyde in PBS, followed by sequential perfusion with PBS and 50% of Sca<italic>l</italic>eCUBIC-1. The target organs were excised and immersed in Sca<italic>l</italic>eCUBIC-1 for 5 days. After this step, samples were transferred to Sca<italic>l</italic>eCUBIC-2 and incubated for 2–3 days. After brief washing, samples were placed in Sca<italic>l</italic>eCUBIC-2.</p><p><bold>Sca<italic>l</italic>eS</bold>; Sca<italic>l</italic>eS was performed according to the published protocols (<xref ref-type="bibr" rid="bib13">Hama et al., 2015</xref>). Briefly, inner ear was isolated by a standard dissection procedure. Cochleae were isolated and 4% paraformaldehyde in PBS was perfused from the oval window. Sca<italic>l</italic>eS0 (20% sorbitol, 5% glycerol, 3% dimethylsulfocide, 1% N-acetyl-L-hydroxyproline, 1 nM methyl-β-cyclodextrin, 1 mM γ-cyclodextrin), Sca<italic>l</italic>eA2 (10% glycerol, 4 M urea, 0.1% Triton-X-100), Sca<italic>l</italic>eB4(0) (8 M urea), and Sca<italic>l</italic>eA2 were applied sequentially for permeabilization and tissue clearing. After samples were returned to PBS, immunolabeling was performed. Samples were rinsed by AbSca<italic>l</italic>e solution (0.33M urea, 0.1–0.5% Triton X-100 in PBS) and AbSca<italic>l</italic>e rinse solution (2.5% BSA, 0.05% Tween-20 in 0.1 × PBS). Finally, samples were placed in Sca<italic>l</italic>eS4 (40% sorbitol, 10% glycerol, 4 M urea, 0.2% Triton X-100, 15–25% dimethylsulfoxide).</p></sec><sec id="s6-4"><title>Antibodies</title><p>Antibodies used in this study were as follows:</p><p>MYO7A (rabbit polyclonal, Proteus Bioscience), 200 kDa subunit of neurofilament protein (anti-NF200, mouse monoclonal, clone NE14, Sigma Aldrich), SOX2 (rabbit polyclonal, EMD Millipore), CtBP2 (mouse monoclonal, clone 16/CTBP2, BD Biosciences), VGLUT3 (guinea pig polyclonal, kindly gifted from Dr. Hioki), Alexa Fluor 488 goat anti-rabbit IgG (H + L) (Life Technologies), Alexa Fluor 546 goat anti-mouse IgG (H + L) (Life Technologies), Alexa Fluor 647 goat anti-mouse IgG (H + L) (Life Technologies), and Alexa Fluor 488-conjugated VE cadherin (mouse monoclonal, clone BV13, eBioscience). Concentration of antibodies should be adjusted depending on the sample size. Rhodamine phalloidin (Thermo Fisher) was used for labeling F-actin.</p></sec><sec id="s6-5"><title>Confocal microscopy</title><p>For samples labeled with multiple antibodies shown in <xref ref-type="fig" rid="fig5">Figure 5B</xref>, images were obtained by a FV1000 laser scanning microscope (Olympus) with a 25 × objective lens (NA = 1.05). Fluorophores were excited by 488, 564, and 635 nm lines of diode lasers. The sizes of single horizontal images were set to 512 × 512, with pixel sizes of 0.43 × 0.43 μm and z-spacing of 0.75 or 2 μm.</p></sec><sec id="s6-6"><title>Measurement of fluorescence intensity of F-actin.</title><p>In double-labeling (anti-MYO7A antibody and rhodamine phalloidin) samples, fluorescence intensity of rhodamine phalloidin was measured as follows. First, MYO7A positive cells were automatically detected by the custom-made program. The space without MYO7A staining was simultaneously detected as a putative position of cell loss. Second, rhodamine phalloidin fluorescence intensity was measured using ImageJ software. OHCs surrounded by intact OHCs and nearby OHCs next to the cell loss positions were selected. Finally, the rhodamine phalloidin intensities between different positions of the organ of Corti were normalized by the intensity of OHCs surrounded by intact OHCs (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p></sec><sec id="s6-7"><title>Measurement of tissue transparency and size change</title><p>Tissue transparency was measured according to the methods described by Hama et al (<xref ref-type="bibr" rid="bib13">Hama et al., 2015</xref>). Light transmitted through 100 μm-thick mouse brain sections before and after clearing was captured with a CCD camera and quantitated. Transparency was normalized to the samples without clearing treatments. Increase in tissue size was determined by measuring the area of brain sections before and after clearing. The extent of size increase was expressed as a ratio against the pre-cleared area (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s6-8"><title>Imaging depth quantification</title><p>To assess the imaging depth of bony tissue, 20 μg of Alexa Fluor 488-conjugated anti-mouse VE cadherin antibody was administered into tail vein followed by tissue fixation. The metaphysis of the tubular bone was analyzed. Imaging depth was measured from the surface and the position at which specific fluorescence signal of the vasculature over the background could no longer be detected was taken as the limit of the imaging depth (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p></sec><sec id="s6-9"><title>Noise exposure</title><p>Mice were placed within steel wire cages (20 cm ×12 cm × 7 cm) in a ventilated sound exposure chamber. The acoustic stimulus was an octave band noise with a center of 4 kHz at 121 dB sound pressure level (SPL) for 4 hr. The sound-delivery speakers (HFD-261–8, TOA) were driven by a power amplifier (IP-600D, TOA) attached to a noise generator (AA-61B, RION) through a programmable filter (3624, NF Corporation). Sound levels were measured (UC-31 and UN14, RION) at multiple locations within the sound chamber and calibrated (NC-74, RION) to ensure uniformity and stability of the stimulus.</p></sec><sec id="s6-10"><title>Auditory Brainstem Response (ABR) tests</title><p>ABRs were recorded before and 7 days after noise exposure. Mice were anesthetized with ketamine hydrochloride (50 mg/kg, i.p.) and xylazine hydrochloride (10 mg/kg, i.p.). Before the ABR test, the tympanic membranes were confirmed to be normal. ABRs were evoked with tone-bursts (5 ms duration at 4, 8, 16, and 31.25 kHz) and measured by a recording system (Neuropack ∑ MEB2208, Nihon Kohden). Needle electrodes were placed subcutaneously at the vertex of the skull, under the ear exposed to noise, and under the opposite ear for ground. A speaker was placed 10 cm from the tragus of the stimulated ear. ABRs from 500 trials were averaged at each sound intensity. ABR thresholds were estimated by changing the intensity in 5 bB steps and finding the lowest sound intensity where reliable response peaks were detected</p></sec><sec id="s6-11"><title>Statistical analysis</title><p>C57BL/6J (PND 5: four samples, PND 30: 10 samples, PND 60: 14 samples, PND 120: nine samples, PND 360: four samples, and PND 60 with noise: 10 samples) mice and CBA/Ca (PND 60: five samples) mice were analyzed. Statistical analysis was performed by paired <italic>t</italic>-test (<xref ref-type="fig" rid="fig2">Figure 2G</xref>), Kruskal-Wallis test with Steel-Dwass multiple comparison test (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), paired <italic>t</italic>-test followed by Bonferroni’s correction (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), Welch’s <italic>t</italic>-test (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), paired <italic>t</italic>-test with Bonferroni’s correction and Welch’s <italic>t</italic>-test with Bonferroni’s correction (<xref ref-type="fig" rid="fig5">Figure 5</xref>), one-way ANOVA followed by Bonferroni’s post hoc test (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>), or a two-tailed unpaired <italic>t</italic>-test (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B,C</xref>). Data are presented as means ± standard errors of the mean (SEM) except standard deviation (SD) in <xref ref-type="fig" rid="fig4">Figure 4E</xref>. The p-values are as follows: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.</p></sec><sec id="s6-12"><title>The auto cell-count and three-dimensional morphology analysis</title><p>The outline of the protocol, including stitching of multiple image stacks into a single stack, reconstruction of linearized image, automated detection of IHCs, and automated detection of OHCs, was described in the main text. Full description of the algorithm is in Appendix 2.</p></sec><sec id="s6-13"><title>Frameworks of machine learning models</title><p>The outline of the framework was described in the main text. Full description of the models is in Appendix 2.</p></sec><sec id="s6-14"><title>Validation of the automated OHC loss detection and counting</title><p>To evaluate the performance of automated OHC loss counting program, three skilled human operators (A, B, and C) initially detected empty spaces in the same set of the images (n = 4). A human consensus (HC) was established for the presence of empty spaces when more than two operators agreed. The match rates among human operators (A-B, B-C, and A-C) and between the program and HC were comparable (A-B: 91.6, B-C: 89.8, A-C: 89.7, Auto-HC: 93.1, <xref ref-type="table" rid="table3">Table 3</xref>). The numbers of lost cells in individual empty spaces were then estimated by both the human operators and the program using 161 empty spaces (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). The differences between the human operators and the program were defined as absolute errors, and the errors were averaged (mean absolute error) and compared between the program and the human operator (Auto-M1, Auto-M2, and Auto-M3) or between the human operators (M1-M2, M2-M3, and M1-M3).</p></sec><sec id="s6-15"><title>Analysis of lost cell distribution in the organ of Corti</title><p>The longitudinal pattern of cell loss was analyzed among five segments (‘a’, ‘b’, ‘c’, ‘d’, and ‘e’) along the longitudinal axis (x-axis). The two segments from the basal end with their lengths of 800 μm ('a’ and ‘b’), two segments from the apical end with their lengths of 800 μm (‘e’ and ‘d’) were defined, and the middle remaining segment was defined as ‘c’ (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The radial axis (y-axis) was divided into 15 successive zones from the proximal to the distal, covering the width of three rows of OHCs (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p></sec></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.40946.024</object-id><sec id="s7" sec-type="appendix"><title>Supplemental materials and methods for data processing</title><p>MATLAB source code is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/okabe-lab/cochlea-analyzer.git">https://github.com/okabe-lab/cochlea-analyzer.git</ext-link>).</p><sec id="s7-1"><title>Datasets for automated detection and analyses</title><p>For automated detection and analyses of hair cells, we examined 43 sets of images from 43 samples (PND 30: 10 samples, PND 60: 14 samples, PND 120: nine samples, noise exposure at PND 60: 10 samples). The samples immunostained with MYO7A were imaged with a two-photon microscope. To cover the entire longitudinal length of the organ of Corti, multiple image stacks with overlapping volumes should be obtained. Single image stack consists of 2D images with their pixel sizes of 512 × 512, with image numbers in the range of 36–459 along the z-axis. Large differences in the stack sizes were due to changes in the height of the fluorescent objects along the spiral of the cochlea. The image data set for a single cochlea sample contains 11–16 image stacks, which follow the spiral organization of the organ of Corti from an apical end toward the hook portion. There were 10–40% of overlap in length between adjacent image stacks. Physical longitudinal lengths of the organ of Corti were relatively uniform across samples (<xref ref-type="fig" rid="fig2">Figure 2C</xref> in the main text). The voxel sizes in x, y, and z directions were 0.99, 0.99, and 1.0 μm, respectively.</p></sec><sec id="s7-2"><title>Outline of automated cell detection and analyses</title><p>The scripts written for computational detection and analysis of hair cells consist of the following steps:</p><p>Step 1: Stitching of multiple image stacks into a single stack</p><p>Step 2: Reconstruction of linearized image</p><p>Step 3; Automated detection of IHCs</p><p>Step 4; Automated detection of OHCs</p></sec><sec id="s7-3"><title>Step 1: Stitching of multiple image stacks into a single stack</title><p>Multiple image stacks containing parts of the organ of Corti were assembled into a single image stack (<xref ref-type="bibr" rid="bib32">Rankov et al., 2005</xref>). The cross-correlation method was used to image stitching. For rough estimation of the relative positions of two adjacent image stacks, we used recorded positions of the microscope stage and the overall distribution of fluorescent signals derived from the organ of Corti after appropriate image thresholding. Relative positions of two adjacent images were determined by searching best cross-correlation of images at the putative region of overlap (MATLAB ‘normxcorr2’).</p><p>Overlapped images were blended with gradient mixing of intensities. To simplify the explanation, the following protocol is for two-dimensional blending. Blending of image stacks could be performed with similar principles by setting blending gradient in three dimensions. The mixing ratio of the two images was calculated using a sigmoid function as:<disp-formula id="equ2"><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>10</mml:mn><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mi/><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mi/><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> denote mixing ratios of the first and the second images, respectively. The value <inline-formula><mml:math id="inf3"><mml:mi>x</mml:mi></mml:math></inline-formula> was set to reflect the relative distance of each pixel from the line running through the points with equal distance from two image centers (the center line). The normalized distance was measured from the center line, where both <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> were 0.5. <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> reaches ~1 as <inline-formula><mml:math id="inf7"><mml:mi>x</mml:mi></mml:math></inline-formula> moves toward the center of the first image, while <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> reaches ~0. Because the blending process ends at the pixel position within the image overlap that has the largest distance from the center line, value <inline-formula><mml:math id="inf9"><mml:mi>x</mml:mi></mml:math></inline-formula> was normalized to be 1 at this largest distance (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>).</p><fig id="app2fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.025</object-id><label>Appendix 2—figure 1.</label><caption><title>First the line passing through the centers of two images were generated, and the line passing through the center of the image overlap and perpendicular to the first line was created (the center line).</title><p>Distance of each pixel to the center line was defined as <inline-formula><mml:math id="inf10"><mml:mi>x</mml:mi></mml:math></inline-formula>. The pixel that has the largest distance was selected and its <inline-formula><mml:math id="inf11"><mml:mi>x</mml:mi></mml:math></inline-formula> value was normalized to be 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig1-v1.tif"/></fig></sec><sec id="s7-4"><title>Step 2: Reconstruction of linearized images</title><p>After Image processing by a median filter (MATLAB ‘medfilt3’, neighborhood size: 3-by-3-by-3), local intensity peaks were automatically detected (MATLAB 'imregionalmax, 26-connected neighborhoods). Candidate anti-MYO7A-derived signals were selected from the local intensity peaks by eliminating those with their intensities below the threshold value α determined by the following formula.<disp-formula id="equ4"><mml:math id="m4"><mml:mi mathvariant="normal">α</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">μ</mml:mi><mml:mo>+</mml:mo><mml:mn>5</mml:mn><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="inf12"><mml:mi mathvariant="normal">μ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf13"><mml:mi mathvariant="normal">σ</mml:mi></mml:math></inline-formula> denote the mean and the standard deviation of image intensities in the background. Otsu’s method was used to determine the background thresholds (MATLAB 'multithresh', number of threshold values: 2, lower value was used) (Otsu, 1979). To further eliminate the intensity peaks derived from non-specific fluorescence, single-linkage clustering was performed (maximal distance of connection, 25 μm). This procedure was effective in identifying clustered intensity peaks corresponding to the organ of Corti as the largest assembly of linked intensity peaks.</p><p>The stretch of these intensity peaks corresponded to the entire row of hair cells. In the next step of the analysis, more precise determination of the structural parameters for the sensory epithelium is required. For this purpose, the spiral of the hair cell rows should be divided into segments of 200–300 μm in length. Because the sensory epithelium is curved in each original image stack and the spatial distribution of the intensity peaks roughly follows the shape of the sensory epithelium, principal component analysis [PCA (MATLAB ‘pca’)] was effective in extracting the direction and distance in both longitudinal and radial axes of the organ of Corti (<xref ref-type="fig" rid="app2fig2">Appendix 2—figure 2</xref>). Intensity peaks within a single image stack were divided into two equal halves along the first principal component axis, which were generally 200–300 μm in length. Both were projected onto PCA plane defined by the first and second principal component axes, and the best-fit arcs were calculated. The center and the radius of the arc were determined to minimize the mean square error (MATLAB ‘fminsearch’). Repetition of this procedure for all the original image stacks gave rise to a collection of the sensory epithelium segments, that encompassed the entire spiral of the organ of Corti.</p><fig id="app2fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.026</object-id><label>Appendix 2—Figure 2.</label><caption><title>Distribution of intensity peaks within the plane of the first and second principal components.</title><p>The first principal component matched the longitudinal axis, while the second matched the radial axis.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig2-v1.tif"/></fig><p>The multiple best-fit arcs were stitched into a continuous curve. The nearest-neighbor points of two adjacent arcs were detected (<xref ref-type="fig" rid="app2fig3">Appendix 2—figure 3</xref>). Starting from these nearest-neighbor points, both of the arcs were converted to the connection of points with regular intervals of 50 μm. For the calculation of a spline curve that fits two adjacent arcs, the points along each arc were divided into two groups at the position of the nearest-neighbor point and the groups of points that belong to the main portion of the sensory epithelium were selected and combined into a single group. The nearest-neighbor points themselves were excluded from the combined group. The combined points were interpolated by using the spline interpolation method (MATLAB ‘interp1’, method: ‘spline’) and principal normal vectors were calculated (hereinafter just called ‘normal vectors’).</p><fig id="app2fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.027</object-id><label>Appendix 2—Figure 3.</label><caption><title>The method of stitching two arcs.</title><p>Among the dots on the two arcs, the open dots were removed and the closed dots were fitted with a spline curve.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig3-v1.tif"/></fig><p>A voxel image containing the entire straightened rows of hair cells was reconstructed based on the stitched fit curve and the normal vectors. The horizontal center line (x axis) of the reconstructed image was set to match the fit curve. The y axis of the reconstructed image corresponds to the normal vector of the fit curve. The sizes of a voxel along the x, y, and z axes in the reconstructed image were all set to 1.0 μm. As each voxel in the linearized image does not show one-to-one correspondence to the original voxel image, interpolation was necessary to estimate the voxel intensity. In general, when a single voxel in the first image was projected to the second image, it was possible to define 2 × 2 × 2 voxels in the second image enclosing the volume projected from the first image. Therefore, the intensity of a voxel in the linearized image was estimated by the trilinear interpolation method using the corresponding 2 × 2 × 2 voxel in the original voxel image. More precise linearization was performed using a fit curve of IHCs detected by the procedure described in the next section. The voxel values are set to zero when the corresponding voxels are outside the original images.</p></sec><sec id="s7-5"><title>Step 3; Automated detection of IHCs</title><p>Template matching was performed with a template image of an IHC (MATLAB ‘normxcorr2’, template image size: 11 × 11 pixels). This process puts a correlation coefficient to each element of a three dimensional matrix, which reflects the degree of matching to the template. By conducting two-dimensional peak detection on this matrix (MATLAB ‘imregionalmax’), candidate voxels for IHC positions were selected. The connected-component labeling was then carried out on the binary matrix of candidate IHCs (26-connectivity based). These connected pixel groups (hereinafter called ‘cell candidates’, <xref ref-type="fig" rid="app2fig4">Appendix 2—figure 4</xref>) were used as the first approximation of IHC positions linked to other attributes, including correlation values and local intensity distributions. The cell candidates were further evaluated to eliminate false positives using two successive machine learning models (the overview of our method related to machine learning is described in ‘Principles of auto-detection with machine learning’ section below).</p><fig id="app2fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.028</object-id><label>Appendix 2—figure 4.</label><caption><title>Extraction of cell candidates by template matching.</title><p>Left; Template matching with the small template image (upper left) was performed for individual x-y images within the image stack. Right; Detection and labeling of correlation peaks distributed within three-dimensional matrix generated by calculation of cross-correlation. Cell candidates were assemblies of correlation peaks grouped by connected-component labeling.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig4-v1.tif"/></fig><p>In the first step, the cell candidates were narrowed down to the number approximately twice larger than the expected number of IHCs. Specifically, the typical initial number of cell candidates was ~50,000 per one linearized image and they were narrowed down to ~ 1000 in this step. An ensemble learning method was employed to create the model for this selection (MATLAB ‘fitensemble’, method: ‘GentleBoost’) (<xref ref-type="bibr" rid="bib11">Friedman et al., 2000</xref>). The predictor data was composed of the area, barycentric coordinates, correlation values, peak intensities, and those of nearby cell candidates. The model was trained to calculate posterior probability (prediction score) that the cell candidates corresponds to IHCs. The cell candidates with high prediction scores were selected for the next step.</p><p>In the second step, further selection of the cell candidates was performed by another machine learning model with expanded predictor data. The model was built based on an ensemble learning method (MATLAB ‘fitensemble’ function with ‘Bag’ method) (<xref ref-type="bibr" rid="bib3">Breiman, 2001</xref>). The expanded predictor data was composed of the prediction score from the first step of the cell candidates and nearby cell candidates, and a small intensity image centered on the barycentric coordinates of the cell candidate.</p><p>Finally, the cell candidates were connected sequentially using physical constraints that the IHCs form a single row with roughly constant intervals of more than 6 μm along the x-axis. The obtained coordinates of estimated cells were used for fine readjustment of image linearization and the three dimensional structural analysis of the whole cochlea.</p></sec><sec id="s7-6"><title>Step 4; Automated detection of OHCs</title><p>The first several steps of cell detection protocol were similar to those for IHCs described above. In short, template matching was performed with a small template image of OHCs (image size: 7 × 7 pixels) to create the matrix of correlation coefficients. The connected-component labeling was carried out on the binary matrix for the positions of the correlation peaks. The groups of peaks were taken as the cell candidates and narrowed down through two steps of prediction by two machine learning models. Ensemble learning methods were employed to build these models with similar predictors as described above.</p><p>For accuracy improvement, several steps were added after the second prediction step. As OHCs are typically distributed in three rows, the selected cell candidates were classified into three rows by a multiclass classification model (<xref ref-type="fig" rid="app2fig5">Appendix 2—figure 5</xref>). The model was built based on the convolutional neural network method (Neural Network Toolbox of MATLAB) (<xref ref-type="bibr" rid="bib22">LeCun et al., 1989</xref>). The input of the model was a small image centered on the estimated cells. To reduce the chance of missing OHCs, regularity of distances between adjacent cell candidates in row was investigated. If the distance between two adjacent cell candidates in the same row exceeds 1.5 times of average distance, presence of additional cells in the gap was judged by the fourth model.</p><fig id="app2fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.029</object-id><label>Appendix 2—figure 5.</label><caption><title>Functions of the third and fourth machine learning models.</title><p>Cell candidates detected by the first and the second machine learning models were further categorized into three rows by the third model (cells marked by dots with different colors correspond to the three rows.). The spaces between detected OHCs (asterisks) were detected and evaluated the possible presence of OHCs escaped in the previous detection processes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig5-v1.tif"/></fig><p>To evaluate the missing cells in the space, the forth model was used. This model is also built based on the convolutional neural network method and uses small images as an input. Input small images for machine learning were sampled by placing small rectangular areas as region of interest (ROI) with equal distance from each other within the gap between preexisting cell candidates. The number of ROI per space was set to be equal to the integer portion of the quotient with the gap length as a numerator and the average distance of adjacent cells as a denominator. In the case that the model predicted the existence of a cell at the space, the nearest peak of correlation coefficient by the first template matching was added to the list of estimated cells. The obtained coordinates of estimated cells were used for the analysis of cell loss.</p></sec><sec id="s7-7"><title>Remarks on principles and realization of data processing</title><sec id="s7-7-1"><title>Comparison of detection efficiency with standard image processing method</title><p>Performance of our automated cell detection system (Step 3 and 4) was compared with a classical image processing method, a three-dimensional watershed method, with optimized parameters, such as threshold values for intensity and volume. The accuracy (F score) was ~ 70% on average, corresponding to ~ 600 false positives and ~ 600 false negatives in a linearized image containing 2500 hair cells (<xref ref-type="fig" rid="app2fig6">Appendix 2—figure 6</xref>, <xref ref-type="table" rid="table2">Table 2</xref>). This performance is not adequate for practical use. The details of the watershed technique are described below (‘Auto-detection with three-dimensional watershed algorithm’ section).</p><fig id="app2fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.030</object-id><label>Appendix 2—figure 6.</label><caption><title>Comparison of detection efficiencies between a standard image processing method and our method (Paired t-test, both p &lt; 0.0001, n = 10 linearized whole cochlear images).</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig6-v1.tif"/></fig><p>The poor performance of the standard watershed method may be derived from several reasons (<xref ref-type="fig" rid="app2fig7">Appendix 2—figure 7</xref>). First, hair cells were often counted more than once, because of multiple intensity peaks within a single hair cell. The watershed method typically selects seeds from peaks of intensity in the image. Reduction of peaks can be done by image smoothing with a Gaussian filter before the watershed method. However, optimization of Gaussian filter size was difficult, as hair cell shapes are highly heterogenous at different positions of the cochlea. The second reason was false detection of nonspecific signals of anti-MYO7A antibody and background noise. This error can be reduced by a volume, intensity or morphological filtering, but optimization of filter settings was again difficult for heterogeneous hair cells along the longitudinal axis of the sensory epithelium.</p><fig id="app2fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.031</object-id><label>Appendix 2—figure 7.</label><caption><title>Comparison of 3D watershed and our machine learning based method.</title><p>There are many duplicate count and false detection with 3D watershed method.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig7-v1.tif"/></fig><p>To achieve practical accuracy for cell detection in a large data set of whole cochlear image, we designed the method based on multiple pattern recognition techniques. We overcome the first problem, duplicated cell counting, with template matching technique (<xref ref-type="fig" rid="app2fig4">Appendix 2—figure 4</xref>). The second problem, noise filtering, was addressed by machine learning models as described in the next section. To further improve the accuracy of detection, we also added a step of recovering false negatives based also on machine learning that detected three-row arrangement of outer hair cells.</p></sec></sec><sec id="s7-8"><title>Principles of auto-detection with machine learning</title><p>Our machine learning based auto-detection system utilizes two principles. The first principle is sorting hair cells from background noise. The models were trained with labeled dataset containing multiple feature values of cell candidates, such as volume, signal intensity, similarity with template image, coordinates, and relative position from neighboring candidates (<xref ref-type="table" rid="table1">Table 1</xref>). As morphology of hair cells and imaging conditions vary from place to place within the image, it was almost impossible to find the single or a few feature values that could efficiently distinguish cells from background noise. The approach with machine learning models, however, dramatically improved the accuracy of cell detection (<xref ref-type="fig" rid="app2fig6">Appendix 2—figure 6</xref>). Incorporation of excessive feature values may introduce a risk of overfitting. It is important to select machine learning algorithms resistant to the overfitting problem. After evaluation of available supervised learning algorithms in MATLAB (‘Statistics and Machine Learning Toolbox’ in MATLAB R2017b; Decision trees, Discriminant analysis, Nearest neighbors, Naïve Bayes, Support vector machines, and Classification ensembles), we chose classification ensembles (Gentle AdaBoost and Random forest algorithms) because of their high generalization abilities and processing speeds. Training dataset from ten cochlear samples and test dataset from other four samples were used.</p><p>The second principle is recovery of false negatives based on auto-recognition of three-row arrangement of outer hair cells (<xref ref-type="fig" rid="app2fig5">Appendix 2—figure 5</xref>). Although the detection based on the first principle shows high specificity of hair cell detection, it sometimes misses cells with atypical morphology or features. The first step of the false negative recovery is grouping of each cell candidate into one of three rows. Then, spatial gaps are detected by checking irregularity of intervals of cell candidates within each row. Finally, the gaps were evaluated whether there were overlooking cells or not by another model. This step of false negative recovery was realized by a convolutional neural network algorithm. The advantage is that it only requires an image as an input without any additional feature extraction. We expected the complementary effect by combining the first and second principles. Indeed, the recovery rate of the detection was further improved by adding the second process (<xref ref-type="table" rid="table2">Table 2</xref>, Paired <italic>t</italic>-test, p &lt; 0.005, t = 3.94, df = 9).</p></sec><sec id="s7-9"><title>Auto-detection with three-dimensional watershed algorithm</title><p>We tested another auto-detection method for linearized image implemented in ‘Classic Watershed’ plugin for Fiji (<xref ref-type="bibr" rid="bib34">Soille and Vincent, 1990</xref>). Several settings should be configured for this approach. First, a threshold value for voxel intensity should be provided. With lower threshold, more cells will be detected, but false positives will also increase. A threshold value for volume of the segmented region is also required for reducing false positives. In addition, inner and outer hair cells were distinguished based on their center coordinates along the radial axis in the linearized image. We optimized these parameters by grid search on the test samples for maximizing the detection efficiency (F score). Fiji macro and MATLAB source code of this method is available on GitHub (<xref ref-type="bibr" rid="bib18">Iida, 2018b</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/Watershed">https://github.com/elifesciences-publications/Watershed</ext-link>).</p></sec><sec id="s7-10"><title>Training of machine learning models</title><p>The models were trained with the dataset obtained from ten cochleae with manual labeling (PND60: two samples, ACL: five samples, NCL: three samples). The numbers of observations of the training datasets are shown in <xref ref-type="table" rid="table4">Table 4</xref>. Details of the predictors of datasets are shown in <xref ref-type="table" rid="table1">Table 1</xref>. The datasets for the models IHC1 and OHC1 include all the peak groups obtained from the ten linearized images with template matching (<xref ref-type="fig" rid="app2fig4">Appendix 2—figure 4</xref>). These models are based on a GentleBoost algorithm. To deal with the imbalance between positives and negatives, we set the cost matrix when training IHC1 and OHC1 (100 times and 50 times higher costs for false negatives than false positives, respectively). The hyperparameter was optimized by five-fold cross validation with a Bayesian optimization method on the training dataset (number of the trees, learn rate; ‘OptimizeHyperparameters’ option for ‘fitcensemble’ function of MATLAB).</p><p>A subgroup of cell candidates was selected for further processing with the models ICH2 and OHC2, based on their higher posterior probability computed by IHC1 and OHC1. The fraction of this subgroup over the total sample population was fixed. The models ICH2 and OHC2 were based on a Random Forest algorithm. We set the cost matrix to deal with the imbalance of the dataset when training IHC2 and OHC2 (2 times and 0.4 times costs for false negatives, respectively). The hyperparameter was optimized as with IHC1 and OHC1.</p><p>The training dataset for the model OHC3 includes small images centered on each outer hair cell extracted from ten linearized images. This model is based on a CNN algorithm. We used a shallow network with typical settings for training. Details of the layer configuration (filter size and number of convolutional layer) were optimized by five-fold cross validation with a Bayesian optimization method on the training dataset. We trained the network with stochastic gradient descent with momentum algorithm, with the maximum number of epochs of 15, and the initial learning rate of 0.001 (<xref ref-type="bibr" rid="bib26">Murphy, 2012</xref>). We used the default settings of ‘trainingOptions’ function of MATLAB for the other training options.</p><p>The dataset for the model OHC4 includes small images of gaps between cell candidates within each row of outer hair cells (<xref ref-type="fig" rid="app2fig5">Appendix 2—figure 5</xref>). The model was based on a shallow CNN with typical settings for training. We optimized the details of the layer configuration of the model and trained it in the same way as OHC3.</p></sec><sec id="s7-11"><title>Evaluation of machine learning models</title><p>The models were tested by ten cochleae that were not used in the training (PND30: two sample, PND60: three sample, ACL: two sample, NCL: three sample). The way of making the test datasets was the same as the training dataset. The numbers of the test dataset of each model are shown in <xref ref-type="table" rid="table4">Table 4</xref>. The indices of the performance were obtained as follows:<disp-formula id="equ5"><mml:math id="m5"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac> <mml:mi/><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="equ6"><mml:math id="m6"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac> <mml:mi mathvariant="normal"/><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="equ7"><mml:math id="m7"><mml:mi>F</mml:mi> <mml:mi/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac> <mml:mi mathvariant="normal"/><mml:mo>,</mml:mo></mml:math></disp-formula>where TP, FP and FN mean True Positive, False Positive and False Negative, respectively. For multiclass classification, the micro-averages of recall and precision were calculated (<xref ref-type="bibr" rid="bib35">Sokolova and Lapalme, 2009</xref>).</p></sec><sec id="s7-12"><title>Details of procedures for the analysis of cochlear structure and hair cell position</title><sec id="s7-12-1"><title>Analysis of three-dimensional structure of cochlea</title><p>Spiral structures of the organ of Corti were analyzed using three dimensional spatial distribution of IHCs. The distribution of IHCs was used because they form a row with little cell loss. The coordinates of IHCs in the linearized image were transformed inversely into the original three dimensional coordinates based on the fit curve and the normal vectors which were also used in the forward linearization.</p><p>A cylindrical coordinate system of each sample was set for registration and comparison between samples. In this system, the position of the <italic>i </italic>th IHC along the organ of Corti is expressed as the combination of the longitudinal coordinate (<inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), the azimuth (<inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), and the radial coordinate (<inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). Please note that here we refer the direction of the modiolus from the apex to the base as the longitudinal axis. In the previous description of the protocol, we refer the direction along the long axis of the sensory epithelium as “longitudinal”.</p><p>The strategy of the initial search for the longitudinal axis was to find the arguments of the minimum for the function that gives smaller values when a line (longitudinal axis) is set to provide the spiral fitting better to the distribution of IHCs. The longitudinal axis <inline-formula><mml:math id="inf17"><mml:mi>l</mml:mi></mml:math></inline-formula> of the coordinate system was chosen as follows:<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:munder><mml:mo form="prefix">min</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:munder><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf18"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is a set of lines in three-dimensional Euclidean space and <inline-formula><mml:math id="inf19"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is the objective function as:<disp-formula id="equ9"><mml:math id="m9"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="italic">min</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where IHCs in a sample were numbered in the order of distance from the apical end along the organ of Corti, and <inline-formula><mml:math id="inf20"><mml:mi>n</mml:mi></mml:math></inline-formula> denotes the total number of IHCs. Values <inline-formula><mml:math id="inf21"><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> denote the radial coordinate and the azimuth respectively, for the <inline-formula><mml:math id="inf23"><mml:mi>j</mml:mi></mml:math></inline-formula>-th IHC in a coordinate system with a given longitudinal axis <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The azimuth <inline-formula><mml:math id="inf25"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> for the first IHC located at the apical end was set to 0 and the others were set to satisfy the condition:<disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The objective function <inline-formula><mml:math id="inf26"><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> means the goodness of fit (the minimum sum of squared errors) of IHCs’ locations to a curve defined by the equation:<disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mi>φ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf27"><mml:mi>ρ</mml:mi></mml:math></inline-formula> is the radial coordinate, <inline-formula><mml:math id="inf28"><mml:mi>φ</mml:mi></mml:math></inline-formula> is the azimuth (<xref ref-type="fig" rid="app2fig8">Appendix 2—figure 8</xref> and <xref ref-type="fig" rid="app2fig9">Appendix 2—figure 9</xref>). Parameter optimization was performed by using the 'fminseach' function of MATLAB. The longitudinal axis <inline-formula><mml:math id="inf29"><mml:mi>l</mml:mi></mml:math></inline-formula> that provides the arguments of the minimum was considered as the modiolus in this protocol. The distance and the cell number from the basal end of the IHC row along the spiral connecting IHCs was measured ('Distance from Base' and 'Cell Number' in <xref ref-type="fig" rid="fig2">Figure 2</xref> of the main text).</p><fig id="app2fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.032</object-id><label>Appendix 2—figure 8.</label><caption><title>An example of fitting the increasing distance between IHCs and the modiolus to a smooth spiral.</title><p>The line with the minimum sum of squared errors was chosen to be the longitudinal axis of the cylindrical coordinate system.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig8-v1.tif"/></fig><fig id="app2fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.033</object-id><label>Appendix 2—figure 9.</label><caption><title>An example of inner hair cell locations (black dots) viewed from the axial direction.</title><p>The angle (<inline-formula><mml:math id="inf30"><mml:mi>φ</mml:mi></mml:math></inline-formula>) was measured from the line (red line) connecting the center of the spiral and the inner hair cell located at the end of the apex (green dot).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig9-v1.tif"/></fig></sec></sec><sec id="s7-13"><title>Registration of samples based on 3D structure</title><p>In the previous section, the longitudinal axis (modiolus axis) was set for each sample and utilized for the presentation of the IHC spiral in the cylindrical coordinate system. Registration of multiple samples were performed using these parameters. To reduce sampling bias in the alignment process of multiple samples, we followed the strategy of first creating a generic template of the IHC spiral by averaging all the available samples. After this step, alignment of individual samples to the generic template was performed. Nevertheless, in both cases we utilized the common protocol for alignment. To simplify the following explanation, we refer two spirals to be aligned as spirals A and B (<xref ref-type="fig" rid="app2fig10">Appendix 2—figure 10</xref>).</p><fig id="app2fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.034</object-id><label>Appendix 2—figure 10.</label><caption><title>Evaluation of the extent of correlation between two curves in the plane of <inline-formula><mml:math id="inf31"><mml:mi>φ</mml:mi></mml:math></inline-formula><bold>-</bold><inline-formula><mml:math id="inf32"><mml:mi>p</mml:mi></mml:math></inline-formula>.</title><p>Within this plane, the positions of spiral A and B were aligned. First, the shift in <inline-formula><mml:math id="inf33"><mml:mi>φ</mml:mi></mml:math></inline-formula> was adjusted (middle). Subsequently, the shift in <inline-formula><mml:math id="inf34"><mml:mi>p</mml:mi></mml:math></inline-formula> was adjusted (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig10-v1.tif"/></fig><p>We first performed alignment between spirals A and B by rotating objects around the longitudinal axis. This can be mathematically achieved by shifting the value <inline-formula><mml:math id="inf35"><mml:mi>φ</mml:mi></mml:math></inline-formula> of one spiral against the other. To estimate the amount of shift in <inline-formula><mml:math id="inf36"><mml:mi>φ</mml:mi></mml:math></inline-formula>, a two-dimensional plot of <inline-formula><mml:math id="inf37"><mml:mi>p</mml:mi></mml:math></inline-formula>against <inline-formula><mml:math id="inf38"><mml:mi>φ</mml:mi></mml:math></inline-formula> was created and overlaid for spirals A and B. By evaluating the extent of correlation between two curves in the plane of <inline-formula><mml:math id="inf39"><mml:mi>φ</mml:mi></mml:math></inline-formula><bold>-</bold><inline-formula><mml:math id="inf40"><mml:mi>p</mml:mi></mml:math></inline-formula>, the optimized shift in <inline-formula><mml:math id="inf41"><mml:mi>φ</mml:mi></mml:math></inline-formula> can be estimated. To calculate the extent of correlation, two curves were converted to series of points with their angular intervals of 0.1 rad and their cross-correlation was calculated (MATLAB “normxcorr2”). The shift in <inline-formula><mml:math id="inf42"><mml:mi>φ</mml:mi></mml:math></inline-formula> that gives the highest cross-correlation was selected and the rotational shift between two curves A and B were corrected.</p><p>The last step of alignment between spiral A and B was translation along the longitudinal axis. To this end, the spiral A was fixed and the origin of the second spiral B was shifted along the longitudinal axis. Comparison of the two spirals was based on the search for the minimum sum of the squared distances along the longitudinal axis between points from two spirals. These points were selected within the region of overlapping azimuth for the two spirals. Two corresponding points on different spirals share the same <inline-formula><mml:math id="inf43"><mml:mi>φ</mml:mi></mml:math></inline-formula>. The origin of the second spiral was determined by finding the arguments of the minimum for the function of squared distance between corresponding points for two spirals projected to the longitudinal axis as follows:<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:munder><mml:mrow><mml:mi mathvariant="italic">m</mml:mi><mml:mi mathvariant="italic">i</mml:mi><mml:mi mathvariant="italic">n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf44"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is a set of positions on the longitudinal axis <inline-formula><mml:math id="inf45"><mml:mi>l</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf46"><mml:mi>Φ</mml:mi></mml:math></inline-formula> is a set of azimuth <inline-formula><mml:math id="inf47"><mml:mi>φ</mml:mi></mml:math></inline-formula> shared by the points of comparison between spirals A and B. The function <inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes an axial coordinate of the point on the spiral A. The function <inline-formula><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> denotes an axial coordinate of the point on the spiral B when the origin of the spiral was set at the position <inline-formula><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The values 'Distance from Base (μm)' (<xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref> in the main text) and 'Cell Number' (<xref ref-type="fig" rid="fig2">Figure 2</xref> in the main text) were also plotted after alignment at the midpoint of the spiral segments.</p></sec><sec id="s7-14"><title>Analysis of spatial distribution of OHCs</title><p>The outline of the procedure was described in the main text. Loss of OHCs results in the formation of empty spaces in the epithelium. Conventionally, the lost cell number was estimated by the size of the empty space. This method is not reliable when the empty space is large, the rows of OHCs are difficult to define, or cell-to-cell distances vary in different epithelial positions (<xref ref-type="fig" rid="app2fig11">Appendix 2—figure 11</xref>).</p><fig id="app2fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.035</object-id><label>Appendix 2—figure 11.</label><caption><title>Representative examples of hair cell images where manual estimation of cell loss was difficult.</title><p>The number of lost cells is difficult to estimate when the size of cell-negative area increases in the basal turn (left). Disorganized rows of OHCs were frequently observed in the apical turn (right). Identification of lost cell positions is difficult when cell density is not high enough to estimate the rows (left) or cells are not aligned as horizontal rows (right). Scale bars, 10 μm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig11-v1.tif"/></fig><p>In this study, we evaluated the space where cells were lost without assuming OHC rows. First, the x and y coordinates of the centers of detected cells (hereinafter called ‘cell centers’) were measured in the linearized image and created a scatter plot. Second, we obtained parameters necessary for radial alignment (along y-axis) of cell centers. For this purpose, we searched the longitudinal positions (along x-axis) along the organ of Corti, where a zone with the width of 8 μm (a gray zone in <xref ref-type="fig" rid="app2fig12">Appendix 2—figure 12</xref>) contained more than two cell centers (three black points within the gray zone in <xref ref-type="fig" rid="app2fig12">Appendix 2—figure 12</xref>). When the zone was found, two values, the averaged x coordinates (red circle in <xref ref-type="fig" rid="app2fig12">Appendix 2—figure 12</xref>) and the largest and smallest y coordinates (red line in <xref ref-type="fig" rid="app2fig12">Appendix 2—figure 12</xref>) of cell centers, were calculated for this zone. The former value was used as a reference of the center position of the epithelium and the latter value as a reference of its width (<italic>Wy</italic>). The vertical widths (subtraction of the largest and smallest y coordinates) were interpolated linearly along the x-axis and used for normalizing the y coordinates of cell centers. Third, we obtained parameters necessary for longitudinal alignment (along x-axis) of cell centers. For this purpose, we searched all the cell centers and created rectangles with their edge lengths of 24 μm along the x-axis and 8 μm along the y-axis with their centers aligned with the cell centers (a red point and a gray rectangle in <xref ref-type="fig" rid="app2fig13">Appendix 2—figure 13</xref>). Distances between the original cell center and the center of the nearest cell within the rectangle along x-axis were calculated (<italic>Wx</italic>). The averages were calculated with 100 μm intervals along the x-axis and interpolated linearly. Fourth, the coordinates of the cell centers were normalized using averaged <italic>Wx</italic> and <italic>Wy</italic> values to equalize the horizontal and vertical distances and to keep the distances uniform along the organ of Corti (<xref ref-type="fig" rid="fig2">Figure 2F</xref> in the main text).</p><fig id="app2fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.036</object-id><label>Appendix 2—figure 12.</label><caption><title>Procedures of obtaining parameters necessary for radial alignment (along y-axis) of cell centers.</title><p>Calculation of an averaged y position of the cell group (a red circle) and a vertical spread of the cell group (a red vertical line). These two parameters were calculated in the area (colored in gray) containing more than two ‘cell centers’. Black dots indicate the positions of ‘cell centers’, and the variable x<sub>0</sub> indicates the x-coordinate of the averaged cell center within the gray area.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig12-v1.tif"/></fig><fig id="app2fig13" position="float"><object-id pub-id-type="doi">10.7554/eLife.40946.037</object-id><label>Appendix 2—figure 13.</label><caption><title>Procedures of obtaining parameters necessary for longitudinal alignment (along x-axis) of cell centers.</title><p>Calculation of the horizontal distance between adjacent cells (red horizontal line). The nearest cell in the rectangular area (colored in gray) was selected for the calculation. The variables x<sub>0</sub> and y<sub>0</sub> are the coordinates of the parental cell center (red dot).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40946-app2-fig13-v1.tif"/></fig><p>A binary image of the normalized epithelium was created based on the equalized coordinates of cell centers (<xref ref-type="fig" rid="fig2">Figure 2G</xref> in the main text). The coordinates projected onto an image were adjusted to have the average distances between neighbors in x and y as five pixels. The horizontal center line of the image was set to be on the line y = 0. The height of image was set to 15 pixels and the width was adjusted to the range of x coordinates. Then squares of 5 × 5 pixels centered on each cell point were drawn on the image. Small holes were removed by a morphological closing operation. The empty spaces in the image were considered to be the putative cell loss sites.</p><p>The estimated amount of cell loss in the entire organ of Corti or in specific areas was shown as either the number of pixels in the empty spaces (<xref ref-type="fig" rid="fig3">Figure 3D</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>) or the cell number obtained by the formula <inline-formula><mml:math id="inf51"><mml:mi mathvariant="normal">n</mml:mi><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>25</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>, where <inline-formula><mml:math id="inf52"><mml:mi mathvariant="normal">n</mml:mi></mml:math></inline-formula> is the estimated number of cell loss and <inline-formula><mml:math id="inf53"><mml:mi>v</mml:mi></mml:math></inline-formula> is the area of each connected region. The estimated number of cell loss was rounded off to the nearest integer (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A,C</xref>). For the simulation analysis of cell loss models, the same formula was used for the estimated number of cell loss (<xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p></sec><sec id="s7-15"><title>In case of transferring to other programming language</title><p>The MATLAB scripts can be viewed on the website of GitHub without installation of MATLAB environment. The scripts have modular architecture, and the inputs and outputs of each module are annotated in the scripts. It would be relatively easy to transfer to the language which can preserve the architecture, such as C/C ++ or Python, by transferring the modules one by one. As there are several built-in functions specific to MATLAB (ex. ‘findpeaks’), however, alternative means would be needed in some cases. Please refer to the website of MathWorks for the syntax and built-in functions of MATLAB in such cases (<ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com">https://www.mathworks.com</ext-link>). In our scripts, the names of modules we made are written in upper camel case. The variables are written in lower camel case, and the constants in all capital letters. The names of built-in functions are written in lower case. Regarding how to train machine learning models, please refer to the ‘Training of machine learning models’ section above. Feel free to contact the corresponding author in case you have questions regarding the contents of the code. We would consider the transfer to other programming languages as needed.</p></sec></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40946.039</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Whitfield</surname><given-names>Tanya T</given-names></name><role>Reviewing Editor</role><aff><institution>University of Sheffield</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Heller</surname><given-names>Stefan</given-names> </name><role>Reviewer</role><aff><institution>Stanford University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Cellular cartography of the organ of Corti based on optical tissue clearing and machine learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Andrew King as the Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: Stefan Heller (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and agree that the manuscript requires minor revisions, which should be relatively quick to address. The Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In this manuscript, Urata and colleagues describe a technical solution to minimize manual processing of cochlear samples from mice for quantitative analysis of hair cell numbers and location. The concept builds on a modified Sca/eS tissue clearing method, combined with immunolabeling of hair cells, 2-photon microscopy, and an elegant way of stitching image stacks and assembling a 3-dimensional image. The core of the automated analysis method is a series of MATLAB scripts that perform the analysis.</p><p>Essential revisions:</p><p>1) Please give more information about the methodology for the machine learning model and include a comparison with other methods. Transfer to other scripts is not essential, but please comment on whether such a transfer would be an option and how this might be done by someone interested in doing a similar analysis.</p><p>The full reviews are appended below.</p><p><italic>Reviewer #1:</italic></p><p>The MATLAB scripts appear well-documented and utilize common toolboxes. Unfortunately, this reviewer currently does not own a MATLAB license and therefore was not able to run the scripts to test for general applicability.</p><p>This brings me to my main critique. The beauty of this work is that it allows the researcher to process a large number of cochlear samples in parallel. With acquisition times of about 4h per sample using a 2-photon microscope and a 25x (NA = 1.1) objective and 30 min for an average analysis workflow, this method is indeed a major advancement for laboratories interested in an efficient and throughput-oriented method for quantitative assessment of hair cells and hair cell loss in the cochlea.</p><p>Nevertheless, the requirement for an expensive software package diminishes enthusiasm. What would it take to transfer the scripts to a widely available and free-for-all environment such as Python, Java, or R? Even C/C++ or a combination of languages comes to mind.</p><p>The overall approach is quite clever and this reviewer is enthusiastic about the work. Besides the automated data analysis, there is another very interesting hidden gem in this manuscript that this is related to Figure 4, and to the principles of observed clustering of lost hair cells and the two-component model. The use of a combination and dynamically changing (with age or noise challenge) model that takes into account local neighborhoods and position is truly a creative way to approach the analysis of such an observation. In this respect, I consider the results presented in this section of the paper and summarized in the last paragraph of the subsection “Model-based analysis of hair cell loss”, as a quite important and relevant finding.</p><p>A second critique concerns the core method used for data analysis. Machine learning is such a buzzword, but it is not a simple method that is replicable for the common reader. Exactly what kind of principle was utilized? Please provide accurate references already in the text presented in the second paragraph of the subsection “Machine learning–based automated detection of sensory hair cells”, and explain in more palatable fashion the kind of neural network approach that was used. Appendix 3 (Step 4) has some of this information, but the description there is difficult to follow and perhaps should be illustrated with some kind of drawing of the process. Appendix 2—figure 5 is a good start as it shows the sample that is investigated directly, but it does not communicate the process. Since this is an important component of the core method that is presented, one would expect a more detailed and more approachable description of the procedure.</p><p><italic>Reviewer #2:</italic></p><p>This manuscript by Urata et al. reports an application of a tissue clearing method for whole organ of Corti imaging and a following quantitative analysis. This reviewer thinks that the work is very important for the field, because a limited method had been applicable for the observation of the organ. The quantification and modeling analysis on the mechanism of hair cell loss due to aging and noise will also give an impact to the field. This reviewer thus appreciate the basic concept of the study, while I found many points which should be corrected and improved in future manuscript.</p><p>1) Please provide a simple and easily understandable figure indicating the step-by-step procedures of data processing according to the information in Materials and methods and Appendix part (e.g., Steps in Appendix 3) by modifying Figure 2. In the current manuscript, it was very difficult to follow and find relations of these steps in Figure 2 and Materials and methods/Appendix. Also, it seems problematic that there is no indication of procedure in Figure 2B (e.g., words such as &quot;raw data&quot; &quot;stitching&quot; &quot;linearize&quot; should be indicated in the panel).</p><p>2) The panels in Figure 3A and Figure 3—figure supplement 1A and the graph in panel B seem the same. Reuse of the same figure panel or data should be made explicit in figure legend. Is there any reason why the Figure 3—figure supplement 1A is elongated?</p><p><italic>Reviewer #3:</italic></p><p>This manuscript describes a method to image and quantitatively characterize the spatial arrangement of sensory hair cells in the organ of Corti. A sorbitol-based optical clearing method was developed to optimize tissue clearing and immunolabeling to improve tissue transparency and antibody accessibility. Two-photon microscopy was used to image the organ of Corti in 3D. The spiral sensory epithelium was then linearized and the positions of the inner and outer hair cells (IHCs and OHCs) were automatically located using a machine learning based algorithm. Using the new sample preparation and imaging analysis method, the authors analyzed age-related and noise-induced cell loss in young, adult, and noise-exposed mice.</p><p>One novel aspect of the paper is the modification of the Sca/eS optical clearing protocol, which first decalcifies the bones and then uses a guanidine-based solution to increase transparency of the sample with minimal tissue expansion and GFP fluorescence quenching. The modified Sca/eS method was compared to established methods, including 3DISCO, iDISCO, CLARITY, CUBIC and Sca/eS, and MYO7A and F-actin labeled hair cells were most clearly identified in samples treated with the modified Sca/eS protocol.</p><p>The authors then fit a spiral curve based on the 3D image information and linearized the entire sensory epithelium of the organ of Corti for further image analysis. This approach is quite impressive to me, although I have to admit that I am not an expert in this field and am not sure whether this approach (e.g. linearization of the entire sensory epithelium) is novel to the auditory research field.</p><p>Localization and classification of IHCs and OHCs using a machine learning method are nice. But very little details were provided to describe the convolution neural network model and how the training and testing were performed. This needs to be further clarified and fleshed out in the revised manuscript. It does not look like that the authors have improved the structure of the machine learning model. The number of samples used for training and testing the machine learning model is limited and can be improved.</p><p>Since the two-photon fluorescence images have very high contrast, a standard imaging processing method, such as 3D watershed, may just do the job with sufficient accuracy. It would be helpful to include a direct comparison of the machine learning model and the watershed algorithm. The reviewer also felt that the authors may consider downplaying the role of machine learning in the title and throughout the manuscript as traditional methods may achieve similar performance.</p><p>Based on the localization analysis of the IHCs and OHCs, age-related and noise-induced cell loss was quantified and compared between different mice models. I will not comment on the biology of the auditory system since this is beyond my expertise.</p><p>Overall, I commend the authors for providing a very careful analysis of the experiment results and assembled a comprehensive manuscript. Addressing the above comments may help to further strengthen the manuscript.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40946.040</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Please give more information about the methodology for the machine learning model and include a comparison with other methods.</p></disp-quote><p>As suggested, we modified the main text to include brief description of the machine learning model (subsection “Machine learning–based automated detection of sensory hair cells”, second paragraph). In this description, we incorporated comparison with a different technique (3D watershed algorithm), which showed much lower performance for hair cell detection. For the details of the machine learning model, we inserted the description in the corresponding section (Materials and methods). In brief, we made six machine learning models in this research, with two for IHC detection (IHC1,2), four for OHC detection (OHC 1,2,3,4). Initial two IHC machine learning models (IHC1,2) are similar to two OHC models (OHC1, 2). IHC 1,2 and OHC1,2 are decision tree ensemble methods (GentleBoost and Random Forest) for discrimination of true signals and noise. OHC3, 4 are convolutional neural network models with small images for matching to templates.</p><disp-quote content-type="editor-comment"><p>Transfer to other scripts is not essential, but please comment on whether such a transfer would be an option and how this might be done by someone interested in doing a similar analysis.</p></disp-quote><p>Thank you for suggesting that transfer to other scripts is not essential for revision. We think the transfer will be relatively easy if the script could maintain the modular architecture of our code, and had built-in functions similar to MATLAB. We inserted several comments for the transfer in the corresponding section (Materials and methods).</p><disp-quote content-type="editor-comment"><p>The full reviews are appended below.</p><p>Reviewer #1:</p><p>The MATLAB scripts appear well-documented and utilize common toolboxes. Unfortunately, this reviewer currently does not own a MATLAB license and therefore was not able to run the scripts to test for general applicability.</p><p>This brings me to my main critique. The beauty of this work is that it allows the researcher to process a large number of cochlear samples in parallel. With acquisition times of about 4h per sample using a 2-photon microscope and a 25x (NA = 1.1) objective and 30 min for an average analysis workflow, this method is indeed a major advancement for laboratories interested in an efficient and throughput-oriented method for quantitative assessment of hair cells and hair cell loss in the cochlea.</p><p>Nevertheless, the requirement for an expensive software package diminishes enthusiasm. What would it take to transfer the scripts to a widely available and free-for-all environment such as Python, Java, or R? Even C/C++ or a combination of languages comes to mind.</p></disp-quote><p>As the Editor did not request transfer the scripts to other program languages, we maintained the current framework.</p><disp-quote content-type="editor-comment"><p>The overall approach is quite clever and this reviewer is enthusiastic about the work. Besides the automated data analysis, there is another very interesting hidden gem in this manuscript that this is related to Figure 4, and to the principles of observed clustering of lost hair cells and the two-component model. The use of a combination and dynamically changing (with age or noise challenge) model that takes into account local neighborhoods and position is truly a creative way to approach the analysis of such an observation. In this respect, I consider the results presented in this section of the paper and summarized in the last paragraph of the subsection “Model-based analysis of hair cell loss”, as a quite important and relevant finding.</p><p>A second critique concerns the core method used for data analysis. Machine learning is such a buzzword, but it is not a simple method that is replicable for the common reader. Exactly what kind of principle was utilized? Please provide accurate references already in the text presented in the second paragraph of the subsection “Machine learning–based automated detection of sensory hair cells”, and explain in more palatable fashion the kind of neural network approach that was used. Appendix 3 (Step 4) has some of this information, but the description there is difficult to follow and perhaps should be illustrated with some kind of drawing of the process. Appendix 2—figure 5 is a good start as it shows the sample that is investigated directly, but it does not communicate the process. Since this is an important component of the core method that is presented, one would expect a more detailed and more approachable description of the procedure.</p></disp-quote><p>We added a description about principles of auto-detection in the corresponding section (Materials and methods). We utilized two principles for the auto-detection. One is a distinction of cells from background noise based on local feature values of each candidate point. Another is a process for the recovery of false negatives based on a recognition of the distributional pattern of hair cells.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>This manuscript by Urata et al. reports an application of a tissue clearing method for whole organ of Corti imaging and a following quantitative analysis. This reviewer thinks that the work is very important for the field, because a limited method had been applicable for the observation of the organ. The quantification and modeling analysis on the mechanism of hair cell loss due to aging and noise will also give an impact to the field. This reviewer thus appreciate the basic concept of the study, while I found many points which should be corrected and improved in future manuscript.</p><p>1) Please provide a simple and easily understandable figure indicating the step-by-step procedures of data processing according to the information in Materials and methods and Appendix part (e.g., Steps in Appendix 3) by modifying Figure 2. In the current manuscript, it was very difficult to follow and find relations of these steps in Figure 2 and Materials and methods/Appendix. Also, it seems problematic that there is no indication of procedure in Figure 2B (e.g., words such as &quot;raw data&quot; &quot;stitching&quot; &quot;linearize&quot; should be indicated in the panel).</p></disp-quote><p>As suggested, we modified Figure 2B for better understanding and added words for explanation of the procedure (“raw data”, “stitching”,”linearize”,”IHC counting”,”OHC &amp; cell loss counting”) in the panel.</p><disp-quote content-type="editor-comment"><p>2) The panels in Figure 3A and Figure 3—figure supplement 1A and the graph in panel B seem the same. Reuse of the same figure panel or data should be made explicit in figure legend. Is there any reason why the Figure 3—figure supplement 1A is elongated?</p></disp-quote><p>As pointed out, the 2D color plot of cell loss in Figure 3A and the 2D color plot in Figure 3—figure supplement 1A are the same data. The reason we reuse the same data is that in supplement we provided the ID of each cochlear sample in the left edge of the color plot, in order to make explicit about the data identity. We agree that duplication of the same 2D color plot with different aspect ratio may be confusing to the readers and decided to delete the plot in the supplement. The IDs of the samples are now added to the second 2D color plot (along the proximal-distal direction).</p><p>Along the same lines, we decided to remove the duplicated bar graph attached to the 2D color plot in Figure 3—figure supplement 1B. We initially thought that this bar graph may help the readers to note differences in the total number of lost hair cells, but this can be done by comparing the panel A in Figure 3 and the (previous) panel B in the supplement.</p><p>Accordingly, panel alphabets were changed as follows.</p><p>“Figure 3—figure supplement 1A” =&gt; removed</p><p>“Figure 3—figure supplement 1B” =&gt; “Figure 3—figure supplement 1A”</p><p>“Figure 3—figure supplement 1C” =&gt; “Figure 3—figure supplement 1B”</p><p>The legends of Figure 3A and Figure 3—figure supplement 1A were modified as follows:</p><p>Figure 3A</p><p>“Pseudo-color presentation of hair cell loss along the longitudinal axis of the organ of Corti (PND 30, 60, and 120 and noise exposure at PND 60). […] The raw fluorescence image shows the definition of directions (distal and proximal, apex and base) relative to the sensory epithelium.”</p><p>Figure 3—figure supplement 1A</p><p>“Pseudo-color presentation of the OHC loss frequency along the radial axis. Each row represents a single cochlear sample. […] The radial positions were divided into 15 sections and the scores were averaged within the sections.”</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[…] Localization and classification of IHCs and OHCs using a machine learning method are nice. But very little details were provided to describe the convolution neural network model and how the training and testing were performed. This needs to be further clarified and fleshed out in the revised manuscript.</p></disp-quote><p>The convolutional neural network models were used in the second step of machine learning-based hair cell search. The aim of this step is recovery of false negatives after the first machine learning step based on decision tree ensemble methods (GentleBoost and Random Forest) (the detailed description was inserted in Materials and methods). As suggested, we modified the description about the training and testing of the models in the corresponding section (Table 4; Materials and methods).</p><disp-quote content-type="editor-comment"><p>It does not look like that the authors have improved the structure of the machine learning model.</p></disp-quote><p>As you pointed out, we have not improved the structure of the machine learning model. Instead, we have combined several machine learning algorithms, ensemble learning and convolutional neural network, so as to improve the overall detection efficiency (Materials and methods).</p><disp-quote content-type="editor-comment"><p>The number of samples used for training and testing the machine learning model is limited and can be improved.</p></disp-quote><p>We summarized the sizes of training datasets used for each model as a new table (Table 4). As shown in the table, the datasets include at least several thousand observations, which would be large enough to train the models. As you mentioned, however, these datasets are derived from ten samples, which may not be sufficiently large. Practically, it is not easy to prepare dozens of samples for training, even though our protocol is efficient and automated. We therefore searched the machine learning algorithms that efficiently avoid overfitting with the limited number of samples for training. We added the description about the issue in the corresponding section (Materials and methods). Following your advice, we increased the sample size for test datasets for performance evaluation of the models (Please see Materials and methods).</p><disp-quote content-type="editor-comment"><p>Since the two-photon fluorescence images have very high contrast, a standard imaging processing method, such as 3D watershed, may just do the job with sufficient accuracy. It would be helpful to include a direct comparison of the machine learning model and the watershed algorithm. The reviewer also felt that the authors may consider downplaying the role of machine learning in the title and throughout the manuscript as traditional methods may achieve similar performance.</p></disp-quote><p>As described in our response to the first essential revision above, the approach with 3D watershed could not show enough accuracy of detection on our linearized cochlear images. The main problem was probably the heterogeneity in morphology of hair cells, and the heterogeneity of signal to noise ratio across the image, which make it difficult to set the appropriate thresholds (For details, please see Materials and methods).</p></body></sub-article></article>