<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">36018</article-id><article-id pub-id-type="doi">10.7554/eLife.36018</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Ongoing, rational calibration of reward-driven perceptual biases</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-93941"><name><surname>Fan</surname><given-names>Yunshu</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2597-5173</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-17965"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6018-0483</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-28145"><name><surname>Ding</surname><given-names>Long</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1716-3848</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Neuroscience</institution>, <institution>University of Pennsylvania</institution>, <addr-line><named-content content-type="city">Philadelphia</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-6945"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing editor</role><aff><institution>University College London</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>lding@mail.med.upenn.edu</email> (LD);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>10</day><month>10</month><year>2018</year></pub-date><volume>7</volume><elocation-id>e36018</elocation-id><history><date date-type="received"><day>19</day><month>02</month><year>2018</year></date><date date-type="accepted"><day>07</day><month>10</month><year>2018</year></date></history><permissions><copyright-statement>Â© 2018, Fan et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Fan et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-36018-v1.pdf"/><abstract><p>Decision-making is often interpreted in terms of normative computations that maximize a particular reward function for stable, average behaviors. Aberrations from the reward-maximizing solutions, either across subjects or across different sessions for the same subject, are often interpreted as reflecting poor learning or physical limitations. Here we show that such aberrations may instead reflect the involvement of additional satisficing and heuristic principles. For an asymmetric-reward perceptual decision-making task, three monkeys produced adaptive biases in response to changes in reward asymmetries and perceptual sensitivity. Their choices and response times were consistent with a normative accumulate-to-bound process. However, their context-dependent adjustments to this process deviated slightly but systematically from the reward-maximizing solutions. These adjustments were instead consistent with a rational process to find satisficing solutions based on the gradient of each monkey's reward-rate function. These results suggest new dimensions for assessing the rational and idiosyncratic aspects of flexible decision-making.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01-EY022411</award-id><principal-award-recipient><name><surname>Gold</surname><given-names>Joshua I</given-names></name><name><surname>Ding</surname><given-names>Long</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006920</institution-id><institution>University of Pennsylvania</institution></institution-wrap></funding-source><award-id>University Research Foundation Pilot Award</award-id><principal-award-recipient><name><surname>Ding</surname><given-names>Long</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000933</institution-id><institution>Hearst Foundations</institution></institution-wrap></funding-source><award-id>Graduate student fellowship</award-id><principal-award-recipient><name><surname>Fan</surname><given-names>Yunshu</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf2"><p>Joshua I Gold, Reviewing editor, <italic>eLife</italic>.</p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All training and experimental procedures were in accordance with the National Institutes of Health Guide for the Care and Use of Laboratory Animals and were approved by the University of Pennsylvania Institutional Animal Care and Use Committee (#804726).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Raw data used during this study are included as the supporting files.</p></sec><supplementary-material><ext-link xlink:href="elife-36018-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>