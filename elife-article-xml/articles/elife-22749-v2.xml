<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">22749</article-id><article-id pub-id-type="doi">10.7554/eLife.22749</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural markers of predictive coding under perceptual uncertainty revealed with Hierarchical Frequency Tagging</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-72232"><name><surname>Gordon</surname><given-names>Noam</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4438-7449</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-72816"><name><surname>Koenig-Robert</surname><given-names>Roger</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8767-3552</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-28525"><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4216-8701</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-72947"><name><surname>van Boxtel</surname><given-names>Jeroen JA</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2643-0474</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-72815"><name><surname>Hohwy</surname><given-names>Jakob</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3906-3060</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Cognition and Philosophy Lab</institution>, <institution>Philosophy Department, Monash University</institution>, <addr-line><named-content content-type="city">Clayton</named-content></addr-line>, <country>Australia</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">School of Psychology</institution>, <institution>The University of New South Wales</institution>, <addr-line><named-content content-type="city">Sydney</named-content></addr-line>, <country>Australia</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Monash Institute of Cognitive and Clinical Neurosciences</institution>, <institution>Monash University</institution>, <addr-line><named-content content-type="city">Clayton</named-content></addr-line>, <country>Australia</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">School of Psychological Sciences</institution>, <institution>Monash University</institution>, <addr-line><named-content content-type="city">Clayton</named-content></addr-line>, <country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Stephan</surname><given-names>Klaas Enno</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>University of Zurich and ETH Zurich</institution>, <country>Switzerland</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>noam.gordon@monash.edu</email> (NG);</corresp><corresp id="cor2"><email>jakob.hohwy@monash.edu</email> (JH)</corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>28</day><month>02</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e22749</elocation-id><history><date date-type="received"><day>27</day><month>10</month><year>2016</year></date><date date-type="accepted"><day>26</day><month>02</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Gordon et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Gordon et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-22749-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.22749.001</object-id><p>There is a growing understanding that both top-down and bottom-up signals underlie perception. But it is not known how these signals integrate with each other and how this depends on the perceived stimuli’s predictability. ‘Predictive coding’ theories describe this integration in terms of how well top-down predictions fit with bottom-up sensory input. Identifying neural markers for such signal integration is therefore essential for the study of perception and predictive coding theories. To achieve this, we combined EEG methods that preferentially tag different levels in the visual hierarchy. Importantly, we examined intermodulation components as a measure of integration between these signals. Our results link the different signals to core aspects of predictive coding, and suggest that top-down predictions indeed integrate with bottom-up signals in a manner that is modulated by the predictability of the sensory input, providing evidence for predictive coding and opening new avenues to studying such interactions in perception.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.001">http://dx.doi.org/10.7554/eLife.22749.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>Hierarchical Frequency Tagging</kwd><kwd>predictive coding</kwd><kwd>Semantic Wavelet-Induced Frequency Tagging</kwd><kwd>intermodulation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP130100194</award-id><principal-award-recipient><name><surname>Koenig-Robert</surname><given-names>Roger</given-names></name><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>FT120100619</award-id><principal-award-recipient><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>FT100100322</award-id><principal-award-recipient><name><surname>Hohwy</surname><given-names>Jakob</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP160102770</award-id><principal-award-recipient><name><surname>Hohwy</surname><given-names>Jakob</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The novel neural marker for the integration of top-down predictions and bottom-up signals in perception elucidates uncertainty in perceptual inference and provides evidence for the predictive coding account of perception.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perception is increasingly being understood to arise by means of cortical integration of ‘bottom-up’ or sensory-driven signals and ‘top-down’ information. Prior experience, expectations and knowledge about the world allow for the formation of priors or hypotheses about the state of the external world (i.e., the causes of the sensory input) that help, via top-down signals, resolve ambiguity in bottom-up sensory signals. Such neuronal representations, or ‘state-units’ can then be optimised in light of new sensory input. Early models of neural processing implementing such a predictive coding framework explicitly incorporated prior knowledge of statistical regularities in the environment (<xref ref-type="bibr" rid="bib48">Srinivasan et al., 1982</xref>). Contemporary accounts treat these ideas in terms of Bayesian inference and prediction error minimization (<xref ref-type="bibr" rid="bib40">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib14">Friston, 2005</xref>; <xref ref-type="bibr" rid="bib16">Friston and Stephan, 2007</xref>; <xref ref-type="bibr" rid="bib20">Hohwy, 2013</xref>; <xref ref-type="bibr" rid="bib8">Clark, 2013</xref>).</p><p>That perception is essentially an inferential process is supported by many behavioural findings demonstrating the significant role of contextual information (<xref ref-type="bibr" rid="bib17">Geisler and Kersten, 2002</xref>; <xref ref-type="bibr" rid="bib25">Kersten et al., 2004</xref>; <xref ref-type="bibr" rid="bib30">Kok and Lange, 2015</xref>; <xref ref-type="bibr" rid="bib59">Weiss et al., 2002</xref>) and of top-down signals (<xref ref-type="bibr" rid="bib31">Kok et al., 2012b</xref>, <xref ref-type="bibr" rid="bib39">Pascual-Leone and Walsh, 2001</xref>; <xref ref-type="bibr" rid="bib43">Ro et al., 2003</xref>; <xref ref-type="bibr" rid="bib56">Vetter et al., 2014</xref>) in perception. Several studies additionally suggest different neural measures of feedforward and feedback signals (<xref ref-type="bibr" rid="bib22">Hupe et al., 1998</xref>) primarily in terms of their characteristic oscillatory frequency bands (<xref ref-type="bibr" rid="bib3">Bastos et al., 2015</xref>; <xref ref-type="bibr" rid="bib6">Buschman and Miller, 2007</xref>; <xref ref-type="bibr" rid="bib13">Fontolan et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Mayer et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Michalareas et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Sherman et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">van Kerkoerle et al., 2014</xref>).</p><p>However, studying the neural basis of perception requires not only distinguishing between top-down and bottom-up signals but also examining the actual integration between such signals. This is particularly important for predictive coding, which hypothesizes such integration as a mechanism for prediction error minimization. According to predictive coding this mechanism is marked by the probabilistic properties of predictions and prediction errors such as the level of certainty or precision attributed to the predictions. Hence, the goals of this study were to simultaneously tag top-down and bottom-up signals, to identify a direct neural marker for the integration of these signals during visual perception and, further, to examine if, and how, such a marker is modulated by the strength of prior expectations.</p><p>In order to differentiate between top-down signals related to predictions, bottom-up signals related to the accumulation of sensory input, and the interaction between such signals, we developed the Hierarchical Frequency Tagging (HFT) paradigm in which two frequency tagging methods are combined in the visual domain in a hierarchical manner. To preferentially track top-down signals (i.e., putative prediction signals) we used semantic wavelet induced frequency tagging (SWIFT) that has been shown to constantly activate low-level visual areas while periodically engaging high-level visual areas (thus, selectively tagging the high-level visual areas; [<xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>]). To simultaneously track bottom-up signals we used classic frequency tagging, or so called steady state visual evoked potentials (SSVEP) (<xref ref-type="bibr" rid="bib37">Norcia et al., 2015</xref>; <xref ref-type="bibr" rid="bib57">Vialatte et al., 2010</xref>). We combined the two methods by presenting SWIFT-modulated images at 1.3 HZ while modulating the global luminance of the stimulus at 10 Hz to elicit SSVEP (See Materials and methods for details). Critically, we hypothesized that intermodulation (IM) components would appear as a marker of integration between these differentially tagged signals.</p><p>Intermodulation is a common phenomenon manifesting in non-linear systems. When the input signal is comprised of more than one fundamental frequency (e.g., <italic>F1</italic> and <italic>F2</italic>) that interact within a non-linear system, the response output will show additional frequencies as linear combinations of the input frequencies (e.g., <italic>f1</italic> +<italic>f2</italic>, <italic>f1 - f2</italic>, etc.) (note that throughout the paper we denote stimulus frequencies with capital letters (e.g., <italic>F1</italic>) and response frequencies with small letters (e.g., <italic>f1</italic>)). Intermodulation components in EEG recordings have been used to study non-linear interactions in the visual system (<xref ref-type="bibr" rid="bib9">Clynes, 1961</xref>; <xref ref-type="bibr" rid="bib42">Regan and Regan, 1988</xref>; <xref ref-type="bibr" rid="bib61">Zemon and Ratliff, 1984</xref>), with some recent applications for the study of high-level visual-object recognition systems (<xref ref-type="bibr" rid="bib5">Boremanse et al., 2013</xref>; <xref ref-type="bibr" rid="bib18">Gundlach and Müller, 2013</xref>; <xref ref-type="bibr" rid="bib62">Zhang et al., 2011</xref>). Instead of tagging two ‘bottom-up’ signals, however, our paradigm was designed to enable the examination of the integration between both bottom-up <italic>and</italic> top-down inputs to the lower visual areas.</p><p>Optimal perceptual inference relies on our ability to take into account the statistical properties of the stimuli and the context in which they occur. One such property is expectation, which reflects the continuous process of probabilistic learning about what is possible or probable in the forthcoming sensory environment (<xref ref-type="bibr" rid="bib50">Summerfield and Egner, 2009</xref>) and therefore plays a central role in predictive coding. Indeed, various studies have demonstrated the relationship between stimulus predictability and neural responses (<xref ref-type="bibr" rid="bib29">Kok et al., 2012a</xref>, <xref ref-type="bibr" rid="bib53">Todorovic et al., 2011</xref>). Accordingly, we hypothesised that manipulating the predictability, or, as we label it, the level of <italic>certainty</italic> about the stimuli would modulate the IM responses. Certainty was manipulated by changing the frequency of images in each trial; the more frequent the image is presented, the easier to successfully predict what the next stimulus will be.</p><p>From the viewpoint of Bayesian belief updating, belief updates occur by combining predictions derived from prior probabilities with sensory-driven data, resulting in prediction errors which are weighted by their relative precisions (<xref ref-type="bibr" rid="bib34">Mathys et al., 2014</xref>). The certainty manipulation thus affected the precision of predictions such that higher certainty means higher prior precision and less weighting for the bottom-up prediction error. The precision of the stimuli themselves (e.g. the level of noise in the stimulus) did not vary across trials.</p><p>Overall, our aim was therefore to find not only neural markers for the integration of sensory-driven and prediction-driven signals, but also to examine how this process is modulated by certainty – a core element in the predictive coding framework.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Participants were presented with 50 s ‘movie’ streams in which either a house or a face image appeared briefly at a frequency of 1.3 Hz (F2). Each 50 s trial was constructed using one face and one house image randomly selected from a pool of images. Images were scrambled using two frequency tagging methods - SWIFT and SSVEP - that differentially tag areas in the cortical hierarchy (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Prior to each trial, participants were instructed to count the number of times one of the two images appeared in the trial (either the house or the face image) and they reported their response at the end of each trial. The proportion of images changed over trials, ranging from trials in which both images appeared in nearly half the cycles (referred to as ‘low certainty’ trials) to trials in which one of the images appeared in nearly all cycles (referred to as ‘high certainty’ trials).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.002</object-id><label>Figure 1.</label><caption><title>Stimuli construction.</title><p>Schematic illustration of stimuli construction. (<bold>A</bold>) A pool of 28 face and 28 house images were used in the paradigm (images with ‘free to use, share or modify, even commercially’ usage rights, obtained from Google Images). (<bold>B</bold>) The SWIFT principle. Cyclic local-contour scrambling in the wavelet-domain allows us to modulate the semantics of the image at a given frequency (i.e. the tagging-frequency, F2 = 1.3 hz, illustrated by the red line) while keeping low-level principal physical attributes constant over time (illustrated by the blue line) (<bold>C</bold>) Each trial (50 s) was constructed using one SWIFT cycle (~769 ms) of a randomly chosen face image (blue solid rectangle) and one SWIFT cycle of a randomly chosen house image (orange solid rectangle). For each SWIFT cycle, a corresponding ‘noise’ SWIFT cycle was created based on one of the scrambled frames of the original SWIFT cycle (orange and blue dashed rectangles). Superimposition of the original (solid rectangles) and noise (dashed rectangles) SWIFT cycles ensures similar principal local physical properties across all SWIFT frames, regardless of the image appearing in each cycle. (<bold>D</bold>) The two SWIFT cycles (house and face) were presented repeatedly in a pseudo-random order for a total of 65 cycles. The resulting trial was a 50 s movie in which images peaked in a cyclic manner (F2 = 1.3 Hz). Finally, a global sinusoidal contrast modulation at F1 = 10 Hz was applied onto the whole movie to evoke the SSVEP.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.002">http://dx.doi.org/10.7554/eLife.22749.002</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig1-v2"/></fig></p><p>Having assured that participants were able to perform the task (Figure 6), we first verified whether our two frequency-tagging methods were indeed able to entrain brain activity, and whether we could observe intermodulation (IM) components. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the results of the fast Fourier transform (FFT) averaged across all 64 electrodes, trials and participants (N = 17). Importantly, significant peaks can be seen at both tagging frequencies (f1 = 10 Hz and f2 = 1.3 Hz) and their harmonics (n1f1 and n2f2 where n1 = 1,2 and n2 = 1,2,3...8 and 11; red and pink solid lines in <xref ref-type="fig" rid="fig2">Figure 2</xref>) and at various IM components (n1f1 + n2f2 where n1 = 1, n2 = +−1,+−2,+−3,+−4 as well as n1 = 2, n2 = −1,+2; orange dashed lines in <xref ref-type="fig" rid="fig2">Figure 2</xref>) (one sample t-test, FDR-adjusted p&lt;0.01 for frequencies of interest in the range of 1 Hz–40Hz).<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.003</object-id><label>Figure 2.</label><caption><title>Amplitude SNR spectra.</title><p>Amplitude SNRs (see Materials and methods for the definition of SNR), averaged across all electrodes, trials and participants, are shown for frequencies up to 23 Hz. Peaks can be seen at the tagging frequencies, their harmonics and at IM components. Solid red lines mark the SSVEP frequency and its harmonic (10 Hz and 20 Hz, both with SNRs significantly greater than one). Solid pink lines mark the SWIFT frequency and harmonics with SNRs significantly greater than one (n2f2 where n2 = 1,2,3…8 and 11). Solid black lines mark SWIFT harmonics with SNRs not significantly greater than one. Yellow dashed lines mark IM components with SNRs significantly greater than one (n1f1 + n2f2; n1 = 1, n2 = +−1,+−2,+−3,+−4 as well as n1 = 2, n2 = −1,+2) and black dashed lines mark IM components with SNRs not significantly greater than one.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.003">http://dx.doi.org/10.7554/eLife.22749.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig2-v2"/></fig></p><p>After establishing that both tagging frequencies and their IM components are present in the data, we examined their spatial distribution on the scalp, averaged across all trials. We expected to find strongest SSVEP amplitudes over the occipital region (as the primary visual cortex is known to be a principal source of SSVEP [<xref ref-type="bibr" rid="bib11">Di Russo et al., 2007</xref>]) and strongest SWIFT amplitudes over more temporal and parietal regions (as SWIFT has been shown to increasingly activate higher areas in the visual pathway [<xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>]). IM components, in contrast, should originate from local processing units which process both SSVEP and SWIFT inputs. Under the predictive coding framework, predictions are projected to lower levels in the cortical hierarchy where they are integrated with sensory input. We therefore speculated that IM signals will be found primarily over occipital regions.</p><p>SSVEP amplitude signal-to-noise ratios (SNRs) were strongest, as expected, over the occipital region (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). For SWIFT, highest SNRs were found over more temporo- and centro-parietal electrodes (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Strongest SNR values for the IM components were indeed found over occipital electrodes (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). To better quantify the similarity between the scalp distributions of SSVEP, SWIFT and IM frequencies we examined the correlations between the SNR values across all 64 channels. We then examined whether the correlation coefficients for the comparison between the IMs and the SSVEP were higher than the correlation coefficients for the comparison between the IMs and the SWIFT. To do so, we applied the Fisher’s r to z transformation and performed a Z-test for the difference between correlations. We found that the distributions of all IM components were significantly more correlated with the SSVEP than with the SWIFT distribution (z = 6.44, z = 5.52, z = 6.5 and z = 6.03 for f1+f2, f1−f2, f1+2f2 and f1−2f2, respectively; two-tailed, FDR adjusted p&lt;0.01 for all comparisons; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.004</object-id><label>Figure 3.</label><caption><title>Scalp distributions.</title><p>Topography maps (log2(SNR)) for SSVEP (f1 = 10 Hz) (<bold>A</bold>), SWIFT (f2 = 1.3 Hz) (<bold>B</bold>), and four IM components (f1+f2, f1−f2, f1+2f2 and f1−2f1) (<bold>C</bold>). SSVEP SNRs were generally stronger than SWIFT SNRs, which in turn were stronger than the IM SNRs (note the different colorbar scales).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.004">http://dx.doi.org/10.7554/eLife.22749.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.22749.005</object-id><label>Figure 3—figure supplement 1.</label><caption><title>As a measure of the similarity between the scalp distributions of the SSVEP, SWIFT and IM frequencies, we examined the Pearson correlation between the mean SNR values across participants for the IM, SSVEP and SWIFT frequencies across all 64 channels (each point represents the mean SNR for a single channel across 17 participants).</title><p>To examine whether the correlation coefficients for the comparison between the IMs and the SSVEP were higher than the correlation coefficients for the comparison between the IMs and the SWIFT, we applied the Fisher’s r to z transformation and performed a Z-test for the difference between correlations. We found that the distributions of all IM components were more highly correlated with the SSVEP than with the SWIFT distribution (z = 6.44, z = 5.52, z = 6.5 and z = 6.03 for f1 +f2, f1-f2, f1 +2f2 and f1-2f2, respectively; two-tailed, FDR adjusted p&lt;0.01 for all comparisons).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.005">http://dx.doi.org/10.7554/eLife.22749.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig3-figsupp1-v2"/></fig></fig-group></p><p>As further detailed in the Discussion, we suggest that this result is consistent with the notion that top-down signals (as tagged with SWIFT) are projected to occipital areas, where they are integrated with SSVEP-tagged signals.</p><p>The final stage of our analysis was to examine the effect of certainty on the SSVEP, SWIFT and IM signals. If the IM components observed in our data reflect a perceptual process in which bottom-up sensory signals are integrated nonlinearly with top-down predictions, we should expect them to be modulated by the level of certainty about the upcoming stimuli (here, whether the next stimulus would be a face or house image). To test this hypothesis we modulated certainty levels across trials by varying the proportion of house and face images presented.</p><p>Using likelihood ratio tests with linear mixed models (see Materials and methods) we found that certainty indeed had a different effect on the SSVEP, SWIFT and IM signals (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.006</object-id><label>Figure 4.</label><caption><title>Summary of the linear mixed-effects (LME) modelling.</title><p>We used LME to examine the significance of the effect of certainty for SSVEP (f1 = 10 Hz), SWIFT (f2 = 1.3 Hz) and IM (separately for f1−2f2, f1−f2, f1+f2, and f1+2f2, as well as across all four components) recorded from posterior ROI electrodes. The table lists the direction of the effects, χ2 value and FDR-corrected p-value from the likelihood ratio tests (See Materials and methods).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.006">http://dx.doi.org/10.7554/eLife.22749.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig4-v2"/></fig><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.007</object-id><label>Figure 5.</label><caption><title>Modulation by certainty.</title><p>Bar plots of signal strength (log of SNR, averaged across 30 posterior channels and 17 participants) as a function of certainty levels for SSVEP (<bold>A</bold>), SWIFT (<bold>B</bold>) and IMs (averaged across the 4 IM components) (<bold>C</bold>). Red lines show the linear regressions for each frequency category. Slopes that are significantly different from 0 are marked with red asterisks (** for p&lt;0.001). While no significant main effect of certainty was found for the SSVEP (p&gt;0.05), a significant negative slope was found for the SWIFT, and a significant positive slope was found for the IM. Error bars are SEM across participants. Bottom) Topo-plots, averaged across participants, for low certainty (averaged across bins 1–3), medium certainty (averaged across bins 4–7) and high certainty (averaged across bins 8–10) are shown for SSVEP (<bold>A</bold>), SWIFT (<bold>B</bold>) and IM (averaged across the 4 IM components) (<bold>C</bold>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.007">http://dx.doi.org/10.7554/eLife.22749.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig5-v2"/></fig></p><p>First, SSVEP (log of SNR at f1 = 10 Hz) was not significantly modulated by certainty (all Chi square and p-values are shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>). This result is consistent with the interpretation of SSVEP as mainly reflecting low-level visual processing which should be mostly unaffected by the degree of certainty about the incoming signals.</p><p>Second, the SWIFT signals (log of SNR at f2 = 1.3 Hz) significantly decreased in trials with higher certainty. This is consistent with an interpretation of SWIFT as being related to the origin of top-down signals which are modulated by certainty. Specifically, better, more certain predictions would elicit less weighting for the prediction error and therefore less revisions of the high level semantic representation.</p><p>Critically, the IM signals were found to increase as a function of increasing certainty for three of the four IM components (f1−2f2 = 7.4 Hz, f1−f2 = 8.7 Hz, and f1+2f2 = 12.6 Hz though not for f1+f2 = 11.3 Hz; <xref ref-type="fig" rid="fig4">Figure 4</xref>). The effect remained highly significant also when including all four IM components in one model. Indeed, this is the effect we would expect to find if IMs reflect the efficacy of integration between top-down, prediction-driven signals and bottom-up sensory input. In high-certainty trials the same image appeared in the majority of cycles, allowing for the best overall correspondence between predictions and bottom-up sensory signals.</p><p>In addition, we found significant interactions between the level of certainty and the different frequency categories (SSVEP/SWIFT/IM). The certainty slope was significantly higher for the IM than for SSVEP (χ2 = 12.49, p&lt;0.001) and significantly lower for SWIFT than for SSVEP (χ2 = 64.45, p&lt;0.001).</p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Key to perception is the ability to integrate neural information derived from different levels of the cortical hierarchy (<xref ref-type="bibr" rid="bib12">Fahrenfort et al., 2012</xref>; <xref ref-type="bibr" rid="bib54">Tononi and Edelman, 1998</xref>). The goal of this study was to identify neural markers for the integration between top-down and bottom-up signals in perceptual inference, and to examine how this process is modulated by the level of certainty about the stimuli. Hierarchical Frequency Tagging combines the SSVEP and SWIFT methods that have been shown to predominantly tag low levels (V1/V2) and higher, semantically rich levels in the visual hierarchy, respectively. We hypothesised that these signals reflect bottom-up sensory-driven signals (or prediction errors) and top-down predictions. Critically, we considered intermodulation (IM) components as an indicator of integration between these signals and hypothesised that they reflect the level of integration between top-down predictions (of different strengths manipulated by certainty) and bottom-up sensory-driven input.</p><p>We found significant frequency-tagging for both the SSVEP and SWIFT signals, as well as at various IM components (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This confirms our ability to simultaneously use two tagging methods in a single paradigm and, more importantly, provides evidence for the cortical integration of the SWIFT- and SSVEP-tagged signals. Indeed, the scalp topography for the three frequency categories (SSVEP, SWIFT and IMs) were, as we discuss further below, largely consistent with our hypotheses (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and importantly, they all differed in the manner by which they were modulated by the level of certainty regarding upcoming stimuli. While SSVEP signals were not significantly modulated by certainty, the SWIFT signals decreased and the IM signals increased as a function of increasing certainty (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In the following discussion we examine how our results support the predictive coding framework.</p><sec id="s3-1"><title>The predictive coding framework for perception</title><p>The notion of perceptual inference and the focus on prior expectations goes back as far as Ibn al Haytham in the 11th century who noted that ‘Many visible properties are perceived by judgment and inference in addition to sensing the object’s form’ (<xref ref-type="bibr" rid="bib45">Sabra, 1989</xref>). Contemporary accounts of perception treat these ideas in terms of Bayesian inference and predictive coding (<xref ref-type="bibr" rid="bib14">Friston, 2005</xref>, <xref ref-type="bibr" rid="bib15">2009</xref>; <xref ref-type="bibr" rid="bib20">Hohwy, 2013</xref>; <xref ref-type="bibr" rid="bib8">Clark, 2013</xref>; <xref ref-type="bibr" rid="bib16">Friston and Stephan, 2007</xref>). Under the predictive coding framework, hypotheses about the state of the external world are formed on the basis of prior experience. Predictions are generated from these hypotheses, which are then projected to lower levels in the cortical hierarchy, and continually tested and adjusted in light of the incoming, stimulus-driven, information. Indeed, the role of top-down signals in perception has been demonstrated in both animal and human studies (<xref ref-type="bibr" rid="bib22">Hupe et al., 1998</xref>, <xref ref-type="bibr" rid="bib39">Pascual-Leone and Walsh, 2001</xref>). The elements of the sensory input that cannot be explained away by the current top-down predictions are referred to as the prediction error (PE). This PE is suggested to be the (precision weighted) bottom-up signal that propagates from lower to higher levels in the cortical hierarchy until it can be explained away, allowing for subsequent revisions of higher-level parts of the overall hypotheses. The notion of PEs has been validated by numerous studies (<xref ref-type="bibr" rid="bib21">Hughes et al., 2001</xref>; <xref ref-type="bibr" rid="bib24">Kellermann et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Lee and Nguyen, 2001</xref>; <xref ref-type="bibr" rid="bib53">Todorovic et al., 2011</xref>; <xref ref-type="bibr" rid="bib58">Wacongne et al., 2011</xref>) and several studies suggest that top-down and bottom-up signals can be differentiated in terms of their typical oscillatory frequency bands (<xref ref-type="bibr" rid="bib13">Fontolan et al., 2014</xref>; <xref ref-type="bibr" rid="bib46">Sedley et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Sherman et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Michalareas et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Mayer et al., 2016</xref>). Perception, under the predictive coding framework, is achieved by an iterative process that singles out the hypothesis that best minimizes the overall prediction error across multiple levels of the cortical hierarchy while taking prior learning, the wider context, and precision estimations into account (<xref ref-type="bibr" rid="bib15">Friston, 2009</xref>). Constant integration of bottom-up and top-down neural information is therefore understood to be a crucial element in perception (<xref ref-type="bibr" rid="bib12">Fahrenfort et al., 2012</xref>; <xref ref-type="bibr" rid="bib14">Friston, 2005</xref>; <xref ref-type="bibr" rid="bib54">Tononi and Edelman, 1998</xref>).</p></sec><sec id="s3-2"><title>SSVEP, SWIFT and their modulation by certainty</title><p>The SSVEP method predominantly tags activity in low levels of the visual hierarchy and indeed highest SSVEP SNRs were measured in our design over occipital electrodes (<xref ref-type="fig" rid="fig3">Figure 3</xref>). We showed that the SSVEP signal was not significantly modulated by certainty (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). These findings suggest that the SSVEP reflects persistent bottom-up sensory input, which does not strongly depend on top-down predictions occurring at the SWIFT frequency.</p><p>The SWIFT method, in contrast, has been shown to increasingly tag higher areas along the visual pathway which process semantic information (<xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>), and we indeed found highest SWIFT SNRs over more temporal and parietal electrodes (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Since the activation of these areas depends on image recognition (<xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>), we hypothesised that contrary to the SSVEP, the SWIFT signal should show greater dependency on certainty. Indeed, we observed that SWIFT SNR decreased as certainty levels increased (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><p>One interpretation of this result is that it reflects the decreasing weight on PE signals under high certainty (which in turn drive the subsequent top-down predictions). The notion of certainty used here is captured well in work on the Hierarchical Gaussian Filter (<xref ref-type="bibr" rid="bib34">Mathys et al., 2014</xref>): ‘…it makes sense that the update should be antiproportional to [the precision of the belief about the level being updated] since the more certain the agent is that it knows the true value …, the less inclined it should be to change it’ (for a mathematical formulation, see eq. 56 in that work, and, for the hierarchical case and yielding a variable learning rate, eq. 59). Indeed, various studies have previously demonstrated that highly predictable stimuli tend to evoke reduced neural responses (<xref ref-type="bibr" rid="bib1">Alink et al., 2010</xref>; <xref ref-type="bibr" rid="bib52">Todorovic and de Lange, 2012</xref>; <xref ref-type="bibr" rid="bib53">Todorovic et al., 2011</xref>). Since PEs reflect the elements of sensory input that cannot be explained by predictions, such reduced neural responses have been suggested to reflect decreased PE signals (<xref ref-type="bibr" rid="bib53">Todorovic et al., 2011</xref>).</p><p>The SWIFT SNR decline with certainty can also be described in terms of neural adaptation (or repetition suppression), that is, the reduction in the evoked neural response measured upon repetition of the same stimulus or when the stimulus is highly expected. In our current study, high-certainty trials contained more consecutive cycles in which the same image was presented, thus adaptation is expected to occur. From the predictive coding perspective, however, adaptation is explained in terms of increasing precision of predictions stemming from perceptual learning (<xref ref-type="bibr" rid="bib2">Auksztulewicz and Friston, 2016</xref>; <xref ref-type="bibr" rid="bib14">Friston, 2005</xref>; <xref ref-type="bibr" rid="bib19">Henson, 2003</xref>). Adaptation then ‘reflects a reduction in perceptual 'prediction error'… that occurs when sensory evidence conforms to a more probable (previously seen), compared to a less probable (novel), percept.’ (<xref ref-type="bibr" rid="bib51">Summerfield et al., 2008</xref>).</p></sec><sec id="s3-3"><title>Intermodulation (IM) as the marker of neural integration of top-down and bottom-up processing</title><p>The intermodulation (IM) marker was employed because studying perception requires not only distinguishing between top-down and bottom-up signals but also examining the integration between such signals. Accordingly, the strength of the Hierarchical Frequency Tagging (HFT) paradigm is in its potential ability to obtain, through the occurrence of IM, a direct electrophysiological measure of integration between signals derived from different levels in the cortical hierarchy.</p><p>From the most general perspective, the presence of IM components simply imply a non-linear integration of the steady-state responses elicited by the SWIFT and SSVEP manipulations. Various biologically plausible neural circuits for implementing nonlinear neuronal operations have been suggested (<xref ref-type="bibr" rid="bib32">Kouh and Poggio, 2008</xref>), and such non-linear neuronal dynamics may be consistent with a number of models, ranging from cascades of non-linear forward filters (e.g., convolution networks used in deep learning) through to the recurrent architectures implied by predictive coding. The presence of IMs in themselves therefore cannot point conclusively at specific computational or neuronal processes to which the IMs could be mapped. Suggesting IMs as evidence for predictive coding rather than other theories of perception therefore remains to some degree indirect, however, various arguments indeed point to the recurrent and top-down mediation of the IM responses in our data.</p><p>First, the scalp distributions of the IM components were more strongly correlated to the spatial distribution of the SSVEP (f1 = 10 Hz) rather than to the SWIFT (f2 = 1.3 Hz) (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). This pattern supports the notion that the IM components in our Hierarchical Frequency Tagging (HFT) data reflect the integration of signals generated in SWIFT-tagged areas which project to, and are integrated with, signals generated at lower levels of the visual cortex, as tagged by the SSVEP. This of course is consistent with the predictive coding framework in which predictions generated at higher levels in the cortical hierarchy propagate to lower areas in the hierarchy where they can be tested in light of incoming sensory-driven signals.</p><p>Second, and more importantly, the IM SNRs increased as a function of certainty (contrary to the SWIFT SNR). We suggest that this result lends specific support to the predictive coding framework where translating predictions into prediction errors rests upon nonlinear functions (<xref ref-type="bibr" rid="bib2">Auksztulewicz and Friston, 2016</xref>). Indeed, nonlinearities in predictive coding models are a <italic>specific</italic> corollary of top-down modulatory signals (<xref ref-type="bibr" rid="bib14">Friston, 2005</xref>). Varying certainty levels, as operationalised in our stimuli, would therefore be expected to impact IM signal strength through the nonlinear modulation of bottom-up input by top-down predictions. Specifically, higher certainty trials induced greater predictability of upcoming images and a greater overall match throughout the trial between predictions and sensory input. The increase in IM SNRs in our data may therefore reflect the efficient integration of, or the overall ‘fit’ between, predictions and sensory input that should be expected when much of the upcoming stimuli is highly predictable.</p></sec><sec id="s3-4"><title>Mapping HFT responses to predictive coding models</title><p>In line with the notion above, it is possible to suggest a more specific mapping of the HFT components (SWIFT, SSVEP and IMs) onto elements of predictive coding. According to the model set forward by Auksztulewicz and Friston (<xref ref-type="bibr" rid="bib2">Auksztulewicz and Friston, 2016</xref>), for example, top-down nonlinearities (functions g and f in equations 6 and 7, as well as in <xref ref-type="fig" rid="fig1">Figure 1</xref> in that work) are driven by two elements: (1) the conditional expectations of the hidden causes (µ<sub>v</sub>, i.e. the brain’s ‘best estimate’ as to what is driving the changes in the physical world), and (2) the conditional expectations of the hidden states (µ<sub>x</sub>, i.e. the brain’s best estimate about the actual ‘physics’ of the external world that drives the responses of the sensory organs). The relationships between possible ‘causes’ and ‘states’ (e.g. how the movement of a cloud in the sky impacts the luminance of objects on the ground) is learnt over time and is the crux of the dynamic generative model embodied by the brain. Appealing to this model, the conditional expectations of hidden causes and states may be suggested to be driven primarily by the SWIFT (tagging activity in areas rich in semantic information) and the SSVEP (tagging activity in areas responding to low-level visual features), respectively. Top-down predictions can therefore be expected to result in the formation of the IM components that reflect the nonlinear integration of SWIFT- and SSVEP-driven signals.</p><p>A further question concerns potential quantitative interpretations of the IMs and their increase with certainty. One such interpretation is that the IMs collectively encode (some approximation to the log) model evidence. This notion is compatible with our interpretation of IMs in terms of the ‘fit’ between predictions and sensory input. In this case, one would expect the IMs to increase with certainty, as shown in <xref ref-type="fig" rid="fig5">Figure 5c</xref>. It is an interesting question for further research if this interpretation of IM as encoding model evidence can generate quantitative predictions for the IM magnitude in different experimental manipulations of SWIFT and SSVEP, and further, if different IMs might result from distinct manipulations of expectations and precisions.</p></sec><sec id="s3-5"><title>Alternative interpretations for the IM components</title><p>One could potentially argue that our IM findings may arise from sensory processing alone. For example, consider a population of neurons confined within the visual cortex, in which some are modulated by stimulus contrast via SSVEP and some are modulated by category information via SWIFT. Interactions between these neurons, in such an essentially feedforward mechanism, may potentially account for the formation of IM components even without any top-down signals. However, this alternative interpretation cannot easily account for the pattern of reciprocal changes with certainty found in our data (decreasing SWIFT and increasing IMs). Integration of bottom-up sensory input alone should be blind to the probabilistic properties of the trial such that accounting for the pattern of data here requires suggesting an additional local mechanism which is sensitive to the certainty manipulation. Therefore, it seems more reasonable to assume an interaction between early and higher sensory areas, which have been shown to be sensitive to the predictability of stimuli (<xref ref-type="bibr" rid="bib29">Kok et al., 2012a</xref>, <xref ref-type="bibr" rid="bib41">Rauss et al., 2011</xref>).</p><p>In addition, the IM components could in principle result from the integration of low-level SSVEP signals with minimal, non-semantic, SWIFT-driven signals entrained in the early visual cortex (e.g. by residual tagging of the noise components within the SWIFT frames). While this possibility cannot be fully excluded, previous findings suggest that SWIFT does not tag V1-level activity as no tagging could be detected neither for trials in which non-semantic patterns were used nor for trials in which attention was driven away from the image (<xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>). Residual low-level SWIFT-tagging is therefore not likely to be the primary contributor to the IM components found here.</p><p>Several studies have demonstrated a relationship between IM components and perception (<xref ref-type="bibr" rid="bib5">Boremanse et al., 2013</xref>; <xref ref-type="bibr" rid="bib18">Gundlach and Müller, 2013</xref>; <xref ref-type="bibr" rid="bib62">Zhang et al., 2011</xref>). In all of these studies, the reported increase in IM signal strength potentially reflects the integration of different input elements within a single neural representation. However, the strength of Hierarchical Frequency Tagging is in its ability to simultaneously tag both bottom-up <italic>and</italic> top-down inputs to the lower visual areas. The IM signals, in our paradigm, would then reflect the crux of the hypothesis-testing function, namely, the comparison of prediction and sensory-driven signals, or the integration between state-units and error-units.</p></sec><sec id="s3-6"><title>Manipulating certainty through implicit learning</title><p>An additional point worth noting is that the certainty manipulation we used in this study differs from several other studies (e.g. [<xref ref-type="bibr" rid="bib28">Kok et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Kok et al., 2012a</xref>]) whereby expectation is explicitly manipulated with a preceding cue. In each of the current study’s trials certainty levels were learnt ‘online’ based on the proportion of images that appeared in that trial. Operationalizing certainty in this manner may add sources of variability we did not control for, such as individual differences in learning rates. On the other hand, belief about the probability of an event is often shaped through repeated exposure to the same type of event, placing greater ecological validity to our study design. It is an interesting question for further research whether a priori knowledge of certainty levels will give rise to different IMs, as well as whether individual differences in learning rates (including for example differences in ‘optimal forgetting’, [<xref ref-type="bibr" rid="bib34">Mathys et al., 2014</xref>]) affect IMs.</p></sec><sec id="s3-7"><title>Conclusion</title><p>Overall, the evidence we have presented plausibly demonstrates the ability of the novel HFT technique to obtain a direct physiological measure of the integration of information derived from different levels of the cortical hierarchy during perception. Supporting the predictive coding account of perception, our results suggest that top-down, semantically tagged signals are integrated with bottom-up sensory-driven signals, and this integration is modulated by the level of certainty about the causes of the perceived input.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Stimulus construction</title><sec id="s4-1-1"><title>SSVEP and SWIFT</title><p>In steady-state-visual-evoked-potentials (SSVEP) studies, the intensity (luminance or contrast) of a stimulus is typically modulated over time at a given frequency, <italic>F</italic> Hz (i.e. the ‘tagging frequency’). Peaks at the tagging-frequency, <italic>f</italic> Hz, in the spectrum of the recorded signal are thus understood to reflect stimulus-driven neural activity. However, the use of SSVEP methods impose certain limitations for studying perceptual hierarchies. When the contrast or luminance of a stimulus is modulated over time, then all levels of the visual hierarchy are entrained at the tagging frequency. Thus, it becomes difficult to dissociate frequency tagging related to low-level feature processing from that related to high-level semantic representations.</p><p>Semantic wavelet-induced frequency-tagging (SWIFT) overcomes this obstacle by scrambling image sequences in a way that maintains low-level physical features while modulating mid to high-level image properties. In this manner, SWIFT has been shown to constantly activate early visual areas while selectively tagging high-level object representations both in EEG (<xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>) and fMRI (<xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>).</p><p>The method for creating the SWIFT sequences is described in detail elsewhere (<xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>). In brief, sequences were created by cyclic wavelet scrambling in the wavelets 3D space, allowing to scramble contours while conserving local low-level attributes such as luminance, contrast and spatial frequency. First, wavelet transforms were applied based on the discrete Meyer wavelet and six decomposition levels. At each location and scale, the local contour is represented by a 3D vector. Vectors pointing at different directions but of the same length as the original vector represent differently oriented versions of the same local image contour. Two such additional vectors were randomly selected in order to define a circular path (maintaining vector length along the path). The cyclic wavelet-scrambling was then performed by rotating each original vector along the circular path. The inverse wavelet transform was then used to obtain the image sequences in the pixel domain. By construction, the original unscrambled image appeared once in each cycle (1.3 Hz). The original image was identifiable briefly around the peak of the embedded image (see <xref ref-type="other" rid="media1">Video 1</xref>, also available at <ext-link ext-link-type="uri" xlink:href="https://figshare.com/s/44f1a26ecf55b6a35b2f">https://figshare.com/s/44f1a26ecf55b6a35b2f</ext-link>), as has been demonstrated psychophysically (<xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>).<media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="mp4" mimetype="video" xlink:href="elife-22749-media1.mp4"><object-id pub-id-type="doi">10.7554/eLife.22749.008</object-id><label>Video 1.</label><caption><title>A slow-motion representation of two SWIFT cycles.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.008">http://dx.doi.org/10.7554/eLife.22749.008</ext-link></p></caption></media></p></sec><sec id="s4-1-2"><title>SWIFT-SSVEP trial</title><p>SWIFT sequences were created from a pool of grayscale images of houses and faces (28 each, downloaded from the Internet using Google Images (<ext-link ext-link-type="uri" xlink:href="https://www.%20google.com/imghp">https://www. google.com/imghp</ext-link>) to find images with ‘free to use, share or modify, even commercially’ usage rights; <xref ref-type="fig" rid="fig1">Figure 1A–B</xref>).</p><p>Each trial was constructed using one house and one face sequence, randomly selected from the pool of sequences (independently from the other trials). Using these two sequences, which, in the context of a full trial we refer to as SWIFT ‘cycles’, we created a 50 s ‘movie’ containing 65 consecutive cycles repeated in a pseudorandom order at F2 = 1.3 Hz (~769 ms per cycle, <xref ref-type="fig" rid="fig1">Figure 1D</xref>). The identifiable image at the peak of each cycle was either the face or the house image. The SWIFT method was designed to ensure that the low-level local visual properties within each sequence (cycle) are preserved across all frames. However, these properties could differ significantly between the face and the house sequences, resulting in the potential association of SWIFT-tagged activity with differences in the low level features between the face and house cycles. To prevent this, we created and merged additional ‘noise’ sequences in the following way: First, we selected one of the scrambled frames from each of the original SWIFT sequences (the ‘most scrambled’ one, i.e. the frame most distant from the original image presented at the peak of the cycle). Then, we created noise sequences by applying the SWIFT method on each of the selected scrambled frames. In this way, each original ‘image’ sequence had a corresponding ‘noise’ sequence that matched the low-level properties of the image sequence. Finally, ‘image’ sequences were alpha blended with the ‘noise’ sequences of the other category with equal weights (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, image sequences are surrounded by solid squares and noise sequences with dashed squares). For example, cycles in which a face image was to appear contained the face image sequence superimposed with a house noise sequence (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, right side). This way, the overall low level visual attributes were constant across all frames in the trial regardless of the identifiable image in each cycle.</p><p>A global sinusoidal contrast modulation at F1 = 10 Hz was applied on the whole movie to evoke the SSVEP (see <xref ref-type="other" rid="media2">Videos 2</xref> and <xref ref-type="other" rid="media3">3</xref>, also available at <ext-link ext-link-type="uri" xlink:href="https://figshare.com/s/75aed271d32ba024d1ee">https://figshare.com/s/75aed271d32ba024d1ee</ext-link>).<media content-type="glencoe play-in-place height-250 width-310" id="media2" mime-subtype="mp4" mimetype="video" xlink:href="elife-22749-media2.mp4"><object-id pub-id-type="doi">10.7554/eLife.22749.009</object-id><label>Video 2.</label><caption><title>An 8 s animated movie representation of a HFT trial.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.009">http://dx.doi.org/10.7554/eLife.22749.009</ext-link></p></caption></media><media content-type="glencoe play-in-place height-250 width-310" id="media3" mime-subtype="mp4" mimetype="video" xlink:href="elife-22749-media3.mp4"><object-id pub-id-type="doi">10.7554/eLife.22749.010</object-id><label>Video 3.</label><caption><title>A slow motion animation of the first few cycles within a HFT trial.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.010">http://dx.doi.org/10.7554/eLife.22749.010</ext-link></p></caption></media></p></sec></sec><sec id="s4-2"><title>Participants and procedure</title><p>A total of 27 participants were tested for this study (12 females; mean age = 28.9 y, std = 6.6). Participants gave their written consent to participate in the experiment. Typical sample sizes in SSVEP and SWIFT studies range between 8–22 participants per experimental group (<xref ref-type="bibr" rid="bib7">Chicherov and Herzog, 2015</xref>; <xref ref-type="bibr" rid="bib23">Katyal et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Koenig-Robert and VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib26">Koenig-Robert et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Painter et al., 2014</xref>). As this is the first study to simultaneously combine the SWIFT and SSVEP tagging methods we aimed to be on the higher end of this range. Experimental procedures were approved by the Monash University Human Research Ethics Committee.</p><p>Participants were comfortably seated with their head supported by a chin rest 50 cm from the screen (CRT, 120 HZ refresh rate) in a dimly lit room. Sequences were presented at the center of the screen over a grey background and participants were asked to keep their fixation at the center of the display. Participants were asked to minimise blinking or moving during each trial, but were encouraged to do so if needed in the breaks between each 50 s trial. A total of 56 such 50 s trials were presented to each participant. Importantly, the proportion of house and face images varied over trials, spanning the full possible range (pseudorandomly selected such that a particular proportion was not repeated within each participant). Each trial therefore varied in the level of certainty associated with upcoming images.</p><p>In order to verify that the participants engaged with the task, a sentence appeared on the screen before each trial instructing them to count either the number of house or face presentations. Trials began when the participant pressed the spacebar. They used the keyboard at the end of each trial to enter the number of images counted. These responses were recorded and used later to exclude poorly-performing participants from the analysis. A 2–3 min rest break was introduced after every 14 trials. Continuous EEG was acquired from 64 scalp electrodes using a Brain Products BrainAmp DC system. Data were sampled at 1000 Hz for 23 participants and at 500 Hz for the remaining four participants.</p></sec><sec id="s4-3"><title>Data analysis</title><p>Data processing was performed using the EEGLAB toolbox (<xref ref-type="bibr" rid="bib10">Delorme and Makeig, 2004</xref>) in MATLAB. All data sampled at 1000 Hz were resampled to 500 Hz. A high-pass filter was applied at 0.6 Hz and data was converted to average reference.</p><sec id="s4-3-1"><title>Exclusion criteria</title><p>We defined two criteria to exclude participants from the analysis. First, we excluded participants who had poor counting accuracy because we cannot be sure if these participants were attentive throughout the task. For this purpose, we calculated correlations for each participant between their responses (number of image presentations counted in each trial) and the actual number of cycles in which the relevant image was presented. We excluded five participants whose correlation value r was lower than 0.9 (<xref ref-type="fig" rid="fig6">Figure 6A</xref>).<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.22749.011</object-id><label>Figure 6.</label><caption><title>Behavioral performance.</title><p>(<bold>A</bold>) Histogram across all participants for counting accuracy measured as the correlation between the participant’s response (number of image presentations counted in each trial) and the actual number of presentations. Five participants with a counting accuracy below r = 0.9 (vertical red dashed line) were excluded from the analysis. (<bold>B</bold>) Scatter plot showing responses across 56 trials for all participants included in the analysis. The size of each dot corresponds to the number of occurrences at that point. (<bold>C</bold>) An example scatter plot for a single participant demonstrating the within-participant exclusion criterion for single trials. The solid line (y=x) illustrates the theoretical location of accurate responses. For each trial, we calculated the distance between the participant’s response and the actual number of cycles in which the relevant image was presented (i.e., the distance between each dot in the plot and the solid line). The within-participant cutoff was then defined as ±2.5 standard deviations from the mean of this distance. Dashed lines mark the within-participant cutoff for exclusion of single trials.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.22749.011">http://dx.doi.org/10.7554/eLife.22749.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-22749-fig6-v2"/></fig></p><p>The second criterion was based on the quality of EEG recordings. Sample points were regarded as being noisy if they were either greater than ±80 μV, contained a sudden fluctuation greater than 40μV from the previous sample point, or if the signal was more than ±6 std from the mean of the trial data in each channel. Cycles in which over 2% of sample points were noisy were regarded as noisy cycles. For each channel, all sample points within the noisy cycles were replaced by the mean signal across the trial. Participants for which over 10% of cycles were noisy were excluded from the analysis. Five additional participants were excluded on the basis of this criterion for poor EEG recording (on average, 37% of cycles were noisy for these participants). A total of 17 remaining participants were included in the analysis.</p><p>In addition, we excluded within-participant subsets of trials. For each participant, we calculated the mean and standard deviation of the difference between the participant’s response (count) and the number of cycles in which the relevant image was presented. We then excluded all trials in which the participant’s response fell further than 2.5 standard deviations from his mean accuracy (e.g., <xref ref-type="fig" rid="fig6">Figure 6C</xref>). From this criterion, we excluded 5.5% of the trials (52 out of 952 trials in total, 0–5 trials out of 56 for any individual participant).</p></sec><sec id="s4-3-2"><title>Spectral analysis</title><p>EEG signal amplitude was extracted at the tagging and intermodulation frequencies by applying the fast Fourier transform (FFT) over each trial (50 s, 25,000 sample-points, frequency resolution = 0.02 Hz). Signal-to-noise ratios (SNR) at frequency f was computed by dividing the amplitude at f by the mean amplitude across 20 neighbouring frequencies (from f-0.2Hz to f-0.02Hz and from f + 0.02 Hz to f + 0.2 Hz) (<xref ref-type="bibr" rid="bib49">Srinivasan et al., 1999</xref>; <xref ref-type="bibr" rid="bib54">Tononi and Edelman, 1998</xref>).</p><sec id="s19"><title>Intermodulation components</title><p>IM components include all linear combinations of the fundamental frequencies that comprise the input signal (n1f1 + n2f2, n = ±1,±2,±3…). While a large number of potential IM components exist in our data, we focused our analysis on the four lowest-order components (f1−2f2 = 7.4 Hz, f1−f2 = 8.7 Hz, f1+f2 = 11.3 Hz and f1+2f2 = 12.6 Hz, where f1 = 10 Hz and f2 = 1.3 Hz).</p></sec></sec><sec id="s4-3-3"><title>Statistical analysis</title><p>For analysis of the modulatory effects of certainty we used RStudio (<xref ref-type="bibr" rid="bib44">RStudio Team, 2015</xref>) and lme4 (<xref ref-type="bibr" rid="bib4">Bates et al., 2015</xref>) to perform linear mixed-effect analysis of the data. Eight frequencies of interest were analysed: f2 = 1.3 Hz and 2f2 = 2.6 Hz (SWIFT and harmonic), f1 = 10 Hz and 2f1 = 20 Hz (SSVEP and harmonic), and f1-2f2 = 7.4 Hz, f1−f2 = 8.7 Hz, f1+f2 = 11.3 Hz and f1+2f2 = 12.6 Hz (IM components). We used log<sub>2</sub>(amplitude SNR) as the dependant variable for all analyses. We chose this transformation because the amplitude SNR has a lower bound of 0 and does not distribute normally. The distribution of log<sub>2</sub>(SNR) on the other hand is closer to a normal distribution and allows for better homoscedasticity in the linear models.</p><p>In order to examine the modulatory effect of certainty, we divided trials into 10 certainty bins ranging from 1 (lowest certainty) to 10 (highest certainty). Bin limits were defined in terms of the percentage of cycles at which the more frequent image appeared, thus creating 5%-wide bins (trials in which the more frequent image appeared in 50–55%, 55–60%, … and 95–100% of cycles are defined as bin 1, 2, ... and 10, respectively).</p><p>Different statistical models were applied for each of the three levels of analysis performed: (1) within each of 6 frequencies of interest (e.g., f1, f2, f1+f2, etc.), (2) within the IM category (f1−2f2, f1−f2, f1+f2 and f1+2f2) and (3) between frequency categories (SSVEP/SWIFT/IM). All analyses were performed on a posterior ROI (30 electrodes) including all centro-parietal (CPz and CP1-CP6), temporo-parietal (TP7-TP10), parietal (Pz and P1-P8), parieto-occipital (POz, PO3-PO4, and PO7-PO10) and occipital (Oz,O1 and O2) electrodes. Channels were added to all models as a random effect. All random effects allowed for both random intercepts and slopes.</p><p>To examine if certainty had a significant modulatory effect within each frequency of interest, the first level of analysis included certainty as the fixed effect, and channel nested within participants as the random effect. To examine if there was a main effect for certainty within each frequency category (SSVEP/SWIFT/IM), the second level of analysis included certainty as the fixed effect, and frequency nested within channel nested within participants as the random effect. To examine if the main effect of certainty differed between frequency categories (i.e. a significant interaction between certainty and frequency category), the third level of analysis included certainty, frequency category and a certainty-category interaction as the fixed effects, and frequency nested within frequency category nested within channel nested within participants as the random effect.</p><p>To test for the significance of a given factor or interaction, we performed likelihood ratio tests between the full model, as described above, and the reduced model which did not include the factor or interaction in question (<xref ref-type="bibr" rid="bib4">Bates et al., 2015</xref>). When applicable, we adjusted p values using the false discovery rate (<xref ref-type="bibr" rid="bib60">Yekutieli and Benjamini, 1999</xref>).</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We would like to thank Bryan Paton for his important assistance at the early stages of this study and Karl Friston for his insightful comments.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>NG, Data curation, Formal analysis, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>RK-R, Conceptualization, Data curation, Formal analysis, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>NT, Conceptualization, Formal analysis, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>JJAvB, Formal analysis, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>JH, Conceptualization, Formal analysis, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Participants gave their written consent to participate in the experiment. Experimental procedures were approved by the Monash University Human Research Ethics Committee (CF12/2542 - 2012001375)</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alink</surname><given-names>A</given-names></name><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Kohler</surname><given-names>A</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Muckli</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus predictability reduces responses in primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>2960</fpage><lpage>2966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3730-10.2010</pub-id><pub-id pub-id-type="pmid">20181593</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auksztulewicz</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Repetition suppression and its contextual determinants in predictive coding</article-title><source>Cortex</source><volume>80</volume><fpage>125</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2015.11.024</pub-id><pub-id pub-id-type="pmid">26861557</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Bosman</surname><given-names>CA</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Dowdall</surname><given-names>JR</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visual areas exert feedforward and feedback influences through distinct frequency channels</article-title><source>Neuron</source><volume>85</volume><fpage>390</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.018</pub-id><pub-id pub-id-type="pmid">25556836</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting linear Mixed-Effects models using lme4</article-title><source>Journal of Statistical Software</source><volume>67</volume><elocation-id>48</elocation-id><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boremanse</surname><given-names>A</given-names></name><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>An objective signature for visual binding of face parts in the human brain</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1167/13.11.6</pub-id><pub-id pub-id-type="pmid">24023273</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Top-down versus bottom-up control of attention in the prefrontal and posterior parietal cortices</article-title><source>Science</source><volume>315</volume><fpage>1860</fpage><lpage>1862</lpage><pub-id pub-id-type="doi">10.1126/science.1138071</pub-id><pub-id pub-id-type="pmid">17395832</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chicherov</surname><given-names>V</given-names></name><name><surname>Herzog</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Targets but not flankers are suppressed in crowding as revealed by EEG frequency tagging</article-title><source>NeuroImage</source><volume>119</volume><fpage>325</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.047</pub-id><pub-id pub-id-type="pmid">26102568</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title><source>Behavioral and Brain Sciences</source><volume>36</volume><fpage>181</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1017/S0140525X12000477</pub-id><pub-id pub-id-type="pmid">23663408</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clynes</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1961">1961</year><article-title>Unidirectional rate sensitivity: a biocybernetic law of reflex and humoral systems as physiologic channels of control and communication</article-title><source>Annals of the New York Academy of Sciences</source><volume>92</volume><fpage>946</fpage><lpage>969</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.1961.tb40968.x</pub-id><pub-id pub-id-type="pmid">13694164</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Russo</surname><given-names>F</given-names></name><name><surname>Pitzalis</surname><given-names>S</given-names></name><name><surname>Aprile</surname><given-names>T</given-names></name><name><surname>Spitoni</surname><given-names>G</given-names></name><name><surname>Patria</surname><given-names>F</given-names></name><name><surname>Stella</surname><given-names>A</given-names></name><name><surname>Spinelli</surname><given-names>D</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spatiotemporal analysis of the cortical sources of the steady-state visual evoked potential</article-title><source>Human Brain Mapping</source><volume>28</volume><fpage>323</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1002/hbm.20276</pub-id><pub-id pub-id-type="pmid">16779799</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Snijders</surname><given-names>TM</given-names></name><name><surname>Heinen</surname><given-names>K</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name><name><surname>Scholte</surname><given-names>HS</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuronal integration in visual cortex elevates face category tuning to conscious face perception</article-title><source>PNAS</source><volume>109</volume><fpage>21504</fpage><lpage>21509</lpage><pub-id pub-id-type="doi">10.1073/pnas.1207414110</pub-id><pub-id pub-id-type="pmid">23236162</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontolan</surname><given-names>L</given-names></name><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Liegeois-Chauvel</surname><given-names>C</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The contribution of frequency-specific activity to hierarchical information processing in the human auditory cortex</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>4694</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms5694</pub-id><pub-id pub-id-type="pmid">25178489</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id><pub-id pub-id-type="pmid">15937014</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The free-energy principle: a rough guide to the brain?</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>293</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.04.005</pub-id><pub-id pub-id-type="pmid">19559644</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Free-energy and the brain</article-title><source>Synthese</source><volume>159</volume><fpage>417</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1007/s11229-007-9237-y</pub-id><pub-id pub-id-type="pmid">19325932</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>WS</given-names></name><name><surname>Kersten</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Illusions, perception and Bayes</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>508</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1038/nn0602-508</pub-id><pub-id pub-id-type="pmid">12037517</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gundlach</surname><given-names>C</given-names></name><name><surname>Müller</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Perception of illusory contours forms intermodulation responses of steady state visual evoked potentials as a neural signature of spatial integration</article-title><source>Biological Psychology</source><volume>94</volume><fpage>55</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2013.04.014</pub-id><pub-id pub-id-type="pmid">23665197</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neuroimaging studies of priming</article-title><source>Progress in Neurobiology</source><volume>70</volume><fpage>53</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/S0301-0082(03)00086-8</pub-id><pub-id pub-id-type="pmid">12927334</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hohwy</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>The Predictive Mind</source><publisher-loc>Oxford, United Kingdom</publisher-loc><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780199682737.001.0001</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname><given-names>HC</given-names></name><name><surname>Darcey</surname><given-names>TM</given-names></name><name><surname>Barkan</surname><given-names>HI</given-names></name><name><surname>Williamson</surname><given-names>PD</given-names></name><name><surname>Roberts</surname><given-names>DW</given-names></name><name><surname>Aslin</surname><given-names>CH</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Responses of human auditory association cortex to the omission of an expected acoustic event</article-title><source>NeuroImage</source><volume>13</volume><fpage>1073</fpage><lpage>1089</lpage><pub-id pub-id-type="doi">10.1006/nimg.2001.0766</pub-id><pub-id pub-id-type="pmid">11352613</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupé</surname><given-names>JM</given-names></name><name><surname>James</surname><given-names>AC</given-names></name><name><surname>Payne</surname><given-names>BR</given-names></name><name><surname>Lomber</surname><given-names>SG</given-names></name><name><surname>Girard</surname><given-names>P</given-names></name><name><surname>Bullier</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Cortical feedback improves discrimination between figure and background by V1, V2 and V3 neurons</article-title><source>Nature</source><volume>394</volume><fpage>784</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1038/29537</pub-id><pub-id pub-id-type="pmid">9723617</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katyal</surname><given-names>S</given-names></name><name><surname>Engel</surname><given-names>SA</given-names></name><name><surname>He</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurons that detect interocular conflict during binocular rivalry revealed with EEG</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.1167/16.3.18</pub-id><pub-id pub-id-type="pmid">26891825</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kellermann</surname><given-names>T</given-names></name><name><surname>Scholle</surname><given-names>R</given-names></name><name><surname>Schneider</surname><given-names>F</given-names></name><name><surname>Habel</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decreasing predictability of visual motion enhances feed-forward processing in visual cortex when stimuli are behaviorally relevant</article-title><source>Brain Structure and Function</source><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1007/s00429-016-1251-8</pub-id><pub-id pub-id-type="pmid">27334340</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kersten</surname><given-names>D</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name><name><surname>Yuille</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Object perception as bayesian inference</article-title><source>Annual Review of Psychology</source><volume>55</volume><fpage>271</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.142005</pub-id><pub-id pub-id-type="pmid">14744217</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenig-Robert</surname><given-names>R</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name><name><surname>Tsuchiya</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Semantic Wavelet-Induced Frequency-Tagging (SWIFT) Periodically activates category selective areas while steadily activating early visual areas</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0144858</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0144858</pub-id><pub-id pub-id-type="pmid">26691722</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenig-Robert</surname><given-names>R</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>SWIFT: a novel method to track the neural correlates of recognition</article-title><source>NeuroImage</source><volume>81</volume><fpage>273</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.116</pub-id><pub-id pub-id-type="pmid">23664953</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>van Gerven</surname><given-names>MA</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Prior expectations Bias sensory representations in visual cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>16275</fpage><lpage>16284</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0742-13.2013</pub-id><pub-id pub-id-type="pmid">24107959</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Jehee</surname><given-names>JF</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Less is more: expectation sharpens representations in the primary visual cortex</article-title><source>Neuron</source><volume>75</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.034</pub-id><pub-id pub-id-type="pmid">22841311</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Lange</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Predictive cding in sensory cortex</chapter-title><person-group person-group-type="editor"><name><surname>Forstmann</surname> <given-names>U. B</given-names></name><name><surname>Wagenmakers</surname> <given-names>E. J</given-names></name></person-group><source>An Introduction to Model-Based Cognitive Neuroscience</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer New York</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name><name><surname>Jehee</surname><given-names>JF</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Attention reverses the effect of prediction in silencing sensory signals</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>2197</fpage><lpage>2206</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr310</pub-id><pub-id pub-id-type="pmid">22047964</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kouh</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A canonical neural circuit for cortical nonlinear operations</article-title><source>Neural Computation</source><volume>20</volume><fpage>1427</fpage><lpage>1451</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.02-07-466</pub-id><pub-id pub-id-type="pmid">18254695</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>TS</given-names></name><name><surname>Nguyen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamics of subjective contour formation in the early visual cortex</article-title><source>PNAS</source><volume>98</volume><fpage>1907</fpage><lpage>1911</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.4.1907</pub-id><pub-id pub-id-type="pmid">11172049</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathys</surname><given-names>CD</given-names></name><name><surname>Lomakina</surname><given-names>EI</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Iglesias</surname><given-names>S</given-names></name><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Uncertainty in perception and the hierarchical gaussian filter</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>825</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00825</pub-id><pub-id pub-id-type="pmid">25477800</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>A</given-names></name><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Expecting to see a letter: alpha oscillations as carriers of Top-Down sensory predictions</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>3146</fpage><lpage>3160</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv146</pub-id><pub-id pub-id-type="pmid">26142463</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michalareas</surname><given-names>G</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>van Pelt</surname><given-names>S</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Alpha-Beta and gamma rhythms subserve feedback and feedforward influences among human visual cortical areas</article-title><source>Neuron</source><volume>89</volume><fpage>384</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.018</pub-id><pub-id pub-id-type="pmid">26777277</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norcia</surname><given-names>AM</given-names></name><name><surname>Appelbaum</surname><given-names>LG</given-names></name><name><surname>Ales</surname><given-names>JM</given-names></name><name><surname>Cottereau</surname><given-names>BR</given-names></name><name><surname>Rossion</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The steady-state visual evoked potential in vision research: a review</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/15.6.4</pub-id><pub-id pub-id-type="pmid">26024451</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Painter</surname><given-names>DR</given-names></name><name><surname>Dux</surname><given-names>PE</given-names></name><name><surname>Travis</surname><given-names>SL</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural responses to target features outside a search array are enhanced during conjunction but not unique-feature search</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>3390</fpage><lpage>3401</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3630-13.2014</pub-id><pub-id pub-id-type="pmid">24573295</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascual-Leone</surname><given-names>A</given-names></name><name><surname>Walsh</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Fast backprojections from the motion to the primary visual area necessary for visual awareness</article-title><source>Science</source><volume>292</volume><fpage>510</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1126/science.1057099</pub-id><pub-id pub-id-type="pmid">11313497</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RP</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauss</surname><given-names>K</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name><name><surname>Pourtois</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Top-down effects on early visual processing in humans: a predictive coding framework</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>35</volume><fpage>1237</fpage><lpage>1253</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2010.12.011</pub-id><pub-id pub-id-type="pmid">21185860</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D</given-names></name><name><surname>Regan</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Objective evidence for phase-independent spatial frequency analysis in the human visual pathway</article-title><source>Vision Research</source><volume>28</volume><fpage>187</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(88)80018-X</pub-id><pub-id pub-id-type="pmid">3413995</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ro</surname><given-names>T</given-names></name><name><surname>Breitmeyer</surname><given-names>B</given-names></name><name><surname>Burton</surname><given-names>P</given-names></name><name><surname>Singhal</surname><given-names>NS</given-names></name><name><surname>Lane</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Feedback contributions to visual awareness in human occipital cortex</article-title><source>Current Biology</source><volume>13</volume><fpage>1038</fpage><lpage>1041</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(03)00337-3</pub-id><pub-id pub-id-type="pmid">12814549</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="software"><person-group person-group-type="author"><collab>RStudio Team</collab></person-group><year iso-8601-date="2015">2015</year><source>RStudio: Integrated Development for R</source><version>0.99.902</version><publisher-loc>Boston, MA</publisher-loc><uri xlink:href="http://www.rstudio.com">http://www.rstudio.com</uri></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sabra</surname><given-names>AI</given-names></name></person-group><year iso-8601-date="1989">1989</year><source>The Optics of Ibn Al-Haytham: On Direct Vision</source><publisher-name>The Warburg Institute, University of London</publisher-name></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedley</surname><given-names>W</given-names></name><name><surname>Gander</surname><given-names>PE</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Kovach</surname><given-names>CK</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><name><surname>Kawasaki</surname><given-names>H</given-names></name><name><surname>Howard</surname><given-names>MA</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural signatures of perceptual inference</article-title><source>eLife</source><volume>5</volume><elocation-id>e11476</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11476</pub-id><pub-id pub-id-type="pmid">26949254</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>MT</given-names></name><name><surname>Kanai</surname><given-names>R</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rhythmic influence of Top-Down perceptual priors in the phase of prestimulus occipital alpha oscillations</article-title><source>Journal of Cognitive Neuroscience</source><volume>28</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00973</pub-id><pub-id pub-id-type="pmid">27082046</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>MV</given-names></name><name><surname>Laughlin</surname><given-names>SB</given-names></name><name><surname>Dubs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Predictive coding: a fresh view of inhibition in the retina</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>216</volume><fpage>427</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1098/rspb.1982.0085</pub-id><pub-id pub-id-type="pmid">6129637</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>R</given-names></name><name><surname>Russell</surname><given-names>DP</given-names></name><name><surname>Edelman</surname><given-names>GM</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Increased synchronization of neuromagnetic responses during conscious perception</article-title><source>Journal of Neuroscience</source><volume>19</volume><fpage>5435</fpage><lpage>5448</lpage><pub-id pub-id-type="pmid">10377353</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Egner</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Expectation (and attention) in visual cognition</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>403</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.06.003</pub-id><pub-id pub-id-type="pmid">19716752</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Trittschuh</surname><given-names>EH</given-names></name><name><surname>Monti</surname><given-names>JM</given-names></name><name><surname>Mesulam</surname><given-names>MM</given-names></name><name><surname>Egner</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural repetition suppression reflects fulfilled perceptual expectations</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1004</fpage><lpage>1006</lpage><pub-id pub-id-type="doi">10.1038/nn.2163</pub-id><pub-id pub-id-type="pmid">19160497</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Repetition suppression and expectation suppression are dissociable in time in early auditory evoked fields</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>13389</fpage><lpage>13395</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2227-12.2012</pub-id><pub-id pub-id-type="pmid">23015429</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorovic</surname><given-names>A</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Prior expectation mediates neural adaptation to repeated sounds in the auditory cortex: an MEG study</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>9118</fpage><lpage>9123</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1425-11.2011</pub-id><pub-id pub-id-type="pmid">21697363</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Edelman</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Consciousness and complexity</article-title><source>Science</source><volume>282</volume><fpage>1846</fpage><lpage>1851</lpage><pub-id pub-id-type="doi">10.1126/science.282.5395.1846</pub-id><pub-id pub-id-type="pmid">9836628</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Dagnino</surname><given-names>B</given-names></name><name><surname>Gariel-Mathis</surname><given-names>MA</given-names></name><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>van der Togt</surname><given-names>C</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>Proceedings of the National Academy of Sciences</source><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id><pub-id pub-id-type="pmid">25205811</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vetter</surname><given-names>P</given-names></name><name><surname>Smith</surname><given-names>FW</given-names></name><name><surname>Muckli</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding sound and imagery content in early visual cortex</article-title><source>Current Biology</source><volume>24</volume><fpage>1256</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.04.020</pub-id><pub-id pub-id-type="pmid">24856208</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vialatte</surname><given-names>FB</given-names></name><name><surname>Maurice</surname><given-names>M</given-names></name><name><surname>Dauwels</surname><given-names>J</given-names></name><name><surname>Cichocki</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Steady-state visually evoked potentials: focus on essential paradigms and future perspectives</article-title><source>Progress in Neurobiology</source><volume>90</volume><fpage>418</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2009.11.005</pub-id><pub-id pub-id-type="pmid">19963032</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Evidence for a hierarchy of predictions and prediction errors in human cortex</article-title><source>PNAS</source><volume>108</volume><fpage>20754</fpage><lpage>20759</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117807108</pub-id><pub-id pub-id-type="pmid">22147913</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>Y</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Adelson</surname><given-names>EH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Motion illusions as optimal percepts</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>598</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1038/nn0602-858</pub-id><pub-id pub-id-type="pmid">12021763</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yekutieli</surname><given-names>D</given-names></name><name><surname>Benjamini</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics</article-title><source>Journal of Statistical Planning and Inference</source><volume>82</volume><fpage>171</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1016/S0378-3758(99)00041-5</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zemon</surname><given-names>V</given-names></name><name><surname>Ratliff</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Intermodulation components of the visual evoked potential: responses to lateral and superimposed stimuli</article-title><source>Biological Cybernetics</source><volume>50</volume><fpage>401</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1007/BF00335197</pub-id><pub-id pub-id-type="pmid">6487677</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>P</given-names></name><name><surname>Jamison</surname><given-names>K</given-names></name><name><surname>Engel</surname><given-names>S</given-names></name><name><surname>He</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Binocular rivalry requires visual attention</article-title><source>Neuron</source><volume>71</volume><fpage>362</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.035</pub-id><pub-id pub-id-type="pmid">21791293</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.22749.012</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Stephan</surname><given-names>Klaas Enno</given-names></name><role>Reviewing editor</role><aff id="aff6"><institution>University of Zurich and ETH Zurich</institution>, <country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Neural markers of predictive coding under perceptual uncertainty revealed with Hierarchical Frequency Tagging&quot; for consideration by <italic>eLife</italic>. Your article has been favorably evaluated by Timothy Behrens (Senior Editor) and three reviewers, one of whom, Klaas Enno Stephan (Reviewer #1), is a member of our Board of Reviewing Editors. The following individual involved in review of your submission has agreed to reveal their identity: Peter Kok (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary of manuscript:</p><p>This EEG study of healthy human volunteers tests a key corollary of predictive coding: that brain activity of visual areas during perceptual inference should reflect the integration of top-down predictions with bottom-up inputs. To test this hypothesis, this study uses a novel hierarchical frequency tagging method which combines a recently developed semantic wavelet induced frequency tagging (SWIFT) with classical SSVEP (here: a sinusoidal contrast modulation of images). This allows for studying the effects of predictions and sensory inputs on brain activity in separate frequency bands and, importantly, examine integration of both signals in terms of intermodulation components.</p><p>Summary of reviews:</p><p>Overall, all reviewers agreed that the paper contributes an important step forward in empirical investigations of predictive coding. In particular, all three reviewers liked the experimental approach adopted by this study and agreed that it represents a novel and clever method to test a central aspect of predictive coding theory. We had an engaging discussion (and slightly diverging opinions) about potential limits of interpretation due to experimental confounds; this is detailed below and represents a key issue that needs to be addressed convincingly in the revision of the manuscript.</p><p>The policy of the journal is to provide you with a single set of comments which reflect the consensus view amongst reviewers. These comments can be found below and must be addressed convincingly. We hope that you will find these comments helpful to further improve the paper.</p><p>Essential revisions:</p><p>1) IM components are said to reflect integration of predictions and sensory inputs, but could they be the result of sensory inputs alone? That is, if both SSVEP and SWIFT components are present in the occipital cortex (the fact that the scalp distribution for SWIFT also seems to include some more anterior sensors does not mean that these signals are absent in the occipital cortex), we wondered whether the IMs might also be present there as a result of sensory processing. To give an intuition for this: if certain neurons respond to, let's say, houses, and if their 'house response' is modulated by the contrast of the house stimulus (as is highly likely), wouldn't these neurons show IM components without any involvement of top-down predictions? This point requires, at the very least, detailed consideration in the Discussion. It could potentially be tested by source space analyses, examining whether responses in FFA/OFA and PPA, respectively, show interactions between semantic category and contrast. However, we appreciate that this is a non-trivial extension of the study and leave the decision to the authors.</p><p>2) We wondered to what degree the effects of certainty on SWIFT components might reflect adaptation effects. This is because under high certainty, consecutive images are more likely to be of the same category, thus possibly leading to adaptation in face/house sensitive neurons and hence a reduced SWIFT response. In other words, in the present design, certainty is confounded with stimulus adaptation. Again, this point would require a detailed discussion and the limits of interpretation should be acknowledged clearly.</p><p>3) We had an extensive discussion about the interpretation of the IM responses and their increase with certainty in <xref ref-type="fig" rid="fig4">Figure 4C</xref> in computational (Bayesian) and neurophysiological terms. There was some concern that it is difficult to interpret this slope in <xref ref-type="fig" rid="fig4">Figure 4C</xref> unless one proposes a particular neuronal model that implements predictive coding and emits the IMs observed here. To illustrate the range of possible interpretations, two possibilities may be worth considering: If these IMs (collectively) represented the expectation of posterior beliefs, one might expect them to decline with certainty because &quot;certainty&quot; in this study equals the precision of prediction which should downweight prediction errors / reduce synaptic gain (in contradistinction to precision of sensory input) in predictive coding. If, however, these IMs encoded (some approximation to the log) model evidence – a notion compatible with the argument put forward by the authors – one would expect them to increase with certainty, as shown in the plot.</p><p>4) A general point that deserves more detailed discussion is that using IM components as evidence for the operation of nonlinear integration has pros and cons. The beauty is that this circumvents the need to choose a particular implementation of predictive coding. The downside is that the absence of such a neuronal model renders it impossible to map distinct IM components to specific computational or neuronal processes. IMs simply provide evidence for a nonlinear interaction between different (experimentally controlled) frequencies. While this is indeed a corollary of predictive coding, it does not appear to be a specific one and may also emerge from other theories of perceptual inference.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.22749.013</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Essential revisions:</italic> </p><p><italic>1) IM components are said to reflect integration of predictions and sensory inputs, but could they be the result of sensory inputs alone? That is, if both SSVEP and SWIFT components are present in the occipital cortex (the fact that the scalp distribution for SWIFT also seems to include some more anterior sensors does not mean that these signals are absent in the occipital cortex), we wondered whether the IMs might also be present there as a result of sensory processing. To give an intuition for this: if certain neurons respond to, let's say, houses, and if their 'house response' is modulated by the contrast of the house stimulus (as is highly likely), wouldn't these neurons show IM components without any involvement of top-down predictions? This point requires, at the very least, detailed consideration in the Discussion. It could potentially be tested by source space analyses, examining whether responses in FFA/OFA and PPA, respectively, show interactions between semantic category and contrast. However, we appreciate that this is a non-trivial extension of the study and leave the decision to the authors.</italic> </p><p>Thank you for this important comment. The alternative mechanism of neuronal integration involving sensory inputs alone should indeed be considered and addressed in the paper. We have given this issue much thought and have revised, employing your comments, to reflect that there are different ways to formulate this alternative interpretation. We also considered the possibility of source analysis, which we believe is an important avenue of research on IMs. We are currently thinking of the best study design (e.g., use of MEG rather than EEG for better localization) using hierarchical frequency tagging for source localization analysis. However, we believe that this may best be done in a separate future paper.</p><p>To address the alternative interpretation, we have revised our Discussion by inserting a subsection titled “Alternative interpretations for the IM components”:</p><p>“One could potentially argue that our IM findings may arise from sensory processing alone. […] Residual low-level SWIFT-tagging is therefore not likely to be the primary contributor to the IM components found here.”</p><p><italic>2) We wondered to what degree the effects of certainty on SWIFT components might reflect adaptation effects. This is because under high certainty, consecutive images are more likely to be of the same category, thus possibly leading to adaptation in face/house sensitive neurons and hence a reduced SWIFT response. In other words, in the present design, certainty is confounded with stimulus adaptation. Again, this point would require a detailed discussion and the limits of interpretation should be acknowledged clearly.</italic> </p><p>We agree this is an important point to consider in the paper. We have changed the manuscript to discuss this point and acknowledge this as a potential confound. Overall, we think this actually gives a meaningful and interesting interpretation of our results, namely in terms of predictive coding approaches to adaptation. We have inserted the following paragraph in Discussion:</p><p>“The SWIFT SNR decline with certainty can also be described in terms of neural adaptation (or repetition suppression), that is, the reduction in the evoked neural response measured upon repetition of the same stimulus or when the stimulus is highly expected. […] Adaptation then “reflects a reduction in perceptual 'prediction error'… that occurs when sensory evidence conforms to a more probable (previously seen), compared to a less probable (novel), percept.” (Summerfield et al., 2008).”</p><p><italic>3) We had an extensive discussion about the interpretation of the IM responses and their increase with certainty in <xref ref-type="fig" rid="fig4">Figure 4C</xref> in computational (Bayesian) and neurophysiological terms. There was some concern that it is difficult to interpret this slope in <xref ref-type="fig" rid="fig4">Figure 4C</xref> unless one proposes a particular neuronal model that implements predictive coding and emits the IMs observed here. To illustrate the range of possible interpretations, two possibilities may be worth considering: If these IMs (collectively) represented the expectation of posterior beliefs, one might expect them to decline with certainty because &quot;certainty&quot; in this study equals the precision of prediction which should downweight prediction errors / reduce synaptic gain (in contradistinction to precision of sensory input) in predictive coding. If, however, these IMs encoded (some approximation to the log) model evidence – a notion compatible with the argument put forward by the authors – one would expect them to increase with certainty, as shown in the plot.</italic> </p><p>Thank you for this helpful comment; we have welcomed this challenge and have added a subsection in the Discussion titled “Mapping HFT components to predictive coding models”. We believe that this provides the interested reader with a more in depth discussion about the possible links to specific elements of predictive coding (both in terms of sources of nonlinearities and in terms of quantitative interpretations of the IMs):</p><p>“In line with the notion above, it is possible to suggest a more specific mapping of the HFT components (SWIFT, SSVEP and IMs) onto elements of predictive coding. […] It is an interesting question for further research if this interpretation of IM as encoding model evidence can generate quantitative predictions for the IM magnitude in different experimental manipulations of SWIFT and SSVEP, and further, if different IMs might result from distinct manipulations of expectations and precisions.”</p><p>Note: Given the arrows in Table 1, <italic>eLife</italic>’s editorial suggested that it might be better to process this as an image. We have accordingly labelled the table as ‘<xref ref-type="fig" rid="fig4">Figure 4</xref>’ and as a result, the original <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref> are now labelled <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>, respectively.</p><p><italic>4) A general point that deserves more detailed discussion is that using IM components as evidence for the operation of nonlinear integration has pros and cons. The beauty is that this circumvents the need to choose a particular implementation of predictive coding. The downside is that the absence of such a neuronal model renders it impossible to map distinct IM components to specific computational or neuronal processes. IMs simply provide evidence for a nonlinear interaction between different (experimentally controlled) frequencies. While this is indeed a corollary of predictive coding, it does not appear to be a specific one and may also emerge from other theories of perceptual inference.</italic> </p><p>We acknowledge that this is indeed a strength of the study but also a limitation. We have indicated our answer below, which also to some extent depends on our answers to point 1 and 3 above. We have inserted the following paragraph in the Discussion:</p><p>“From the most general perspective, the presence of IM components simply imply a non-linear integration of the steady-state responses elicited by the SWIFT and SSVEP manipulations. […] Suggesting IMs as evidence for predictive coding rather than other theories of perception therefore remains to some degree indirect, however, various arguments indeed point to the recurrent and top-down mediation of the IM responses in our data…”</p></body></sub-article></article>