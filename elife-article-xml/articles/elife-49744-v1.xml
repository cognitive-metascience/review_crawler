<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">49744</article-id><article-id pub-id-type="doi">10.7554/eLife.49744</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Lateral orbitofrontal cortex promotes trial-by-trial learning of risky, but not spatial, biases</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-147419"><name><surname>Constantinople</surname><given-names>Christine M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4435-4460</contrib-id><email>constantinople@nyu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">†</xref></contrib><contrib contrib-type="author" id="author-148412"><name><surname>Piet</surname><given-names>Alex T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6529-1414</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa2">‡</xref></contrib><contrib contrib-type="author" id="author-148413"><name><surname>Bibawi</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-148414"><name><surname>Akrami</surname><given-names>Athena</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa3">§</xref></contrib><contrib contrib-type="author" id="author-70529"><name><surname>Kopec</surname><given-names>Charles</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-3699"><name><surname>Brody</surname><given-names>Carlos D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4201-561X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Princeton Neuroscience Institute</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Molecular Biology</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Howard Hughes Medical Institute, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Center for Neural Science, New York University, New York, United States</p></fn><fn fn-type="present-address" id="pa2"><label>‡</label><p>Allen Institute for Brain Science, Seattle, United States</p></fn><fn fn-type="present-address" id="pa3"><label>§</label><p>Sainsbury Wellcome Centre, London, United Kingdom</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>06</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e49744</elocation-id><history><date date-type="received" iso-8601-date="2019-06-27"><day>27</day><month>06</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-10-15"><day>15</day><month>10</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Constantinople et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Constantinople et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-49744-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.49744.001</object-id><p>Individual choices are not made in isolation but are embedded in a series of past experiences, decisions, and outcomes. The effects of past experiences on choices, often called sequential biases, are ubiquitous in perceptual and value-based decision-making, but their neural substrates are unclear. We trained rats to choose between cued guaranteed and probabilistic rewards in a task in which outcomes on each trial were independent. Behavioral variability often reflected sequential effects, including increased willingness to take risks following risky wins, and spatial ‘win-stay/lose-shift’ biases. Recordings from lateral orbitofrontal cortex (lOFC) revealed encoding of reward history and receipt, and optogenetic inhibition of lOFC eliminated rats’ increased preference for risk following risky wins, but spared other sequential effects. Our data show that different sequential biases are neurally dissociable, and the lOFC’s role in adaptive behavior promotes learning of more abstract biases (here, biases for the risky option), but not spatial ones.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>orbitofrontal cortex</kwd><kwd>sequential bias</kwd><kwd>learning</kwd><kwd>reinforcement learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>K99/R00 MH111926-03</award-id><principal-award-recipient><name><surname>Constantinople</surname><given-names>Christine M</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The lateral orbitofrontal cortex promotes learning of abstract, task-specific biases, but not spatial ones.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sequential biases permeate human decision-making, and while using past experiences to guide decision-making can be useful in dynamic environments, it can cause us to make suboptimal decisions if the past is not informative (but see <xref ref-type="bibr" rid="bib67">Yu and Cohen, 2008</xref>). A variety of biases have been described in two-alternative forced choice tasks in humans and animal models, including repetition of successful choices (‘win-stay’), switching after unsuccessful choices (‘lose-switch’), and biases due to previous sensory experiences (<xref ref-type="bibr" rid="bib1">Abrahamyan et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Akrami et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Busse et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Hollingworth, 1910</xref>; <xref ref-type="bibr" rid="bib26">Kagel et al., 1995</xref>; <xref ref-type="bibr" rid="bib55">Scott et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Visscher et al., 2009</xref>). Moreover, depending on task design, these biases can be expressed in different ways: if choice options are fixed in space, as is often the case in studies of rodent behavior, sequential biases will appear spatial and action-dependent. Alternatively, if the choice options are not fixed in space, sequential biases may be expressed in non-spatial, task-dependent coordinates. It is unclear whether different sequential biases, or biases expressed in different coordinate reference frames, rely on shared or distinct neural circuits and mechanisms.</p><p>We trained rats to choose between explicitly cued guaranteed or probabilistic (i.e., risky) rewards (<xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>). Guaranteed and risky rewards were randomly assigned to different locations on each trial, disambiguating biases expressed in spatial coordinates and those expressed in more abstract coordinates for the task (biases for risky or safe options). We found that the lateral orbitofrontal cortex (lOFC) was required for rats’ expression of abstract, but not spatial, sequential biases. We interpret these data as consistent with proposals that OFC represents the animal’s current location within an abstract cognitive map of the task (<xref ref-type="bibr" rid="bib66">Wilson et al., 2014</xref>).</p><p>The OFC is not a monolithic structure: in rats, subdivisions (e.g., ventral orbital area, lateral orbital area, agranular insula) are characterized by distinct efferent and afferent projections and, presumably as a consequence, there is growing evidence that these subdivisions make distinct functional contributions to behavior (<xref ref-type="bibr" rid="bib11">Dalton et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Groenewegen, 1988</xref>; <xref ref-type="bibr" rid="bib19">Hervig et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Izquierdo, 2017</xref>; <xref ref-type="bibr" rid="bib37">Murphy and Deutch, 2018</xref>; <xref ref-type="bibr" rid="bib46">Ray and Price, 1992</xref>). Based on connectivity, the rat lOFC (including lateral orbital and agranular insular areas) is thought to be homologous to the central-lateral OFC of monkeys (<xref ref-type="bibr" rid="bib18">Heilbronner et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Izquierdo, 2017</xref>; <xref ref-type="bibr" rid="bib57">Stalnaker et al., 2015</xref>), although differences have been observed in these areas across species, for example in neural dynamics following reversal learning (<xref ref-type="bibr" rid="bib36">Morrison et al., 2011</xref>; <xref ref-type="bibr" rid="bib53">Schoenbaum et al., 1999</xref>).</p><p>The rodent lOFC and primate central-lateral OFC have been shown to play critical roles in adapting behavior to dynamic task contingencies, especially when those contingencies are partially observable (<xref ref-type="bibr" rid="bib49">Rushworth et al., 2011</xref>; <xref ref-type="bibr" rid="bib56">Stalnaker et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Wallis, 2007</xref>; <xref ref-type="bibr" rid="bib66">Wilson et al., 2014</xref>). Lesion experiments have implicated the lOFC in tracking rewards and value, for example in extinction, devaluation, and reversal learning paradigms, in which reward contingencies were explicitly manipulated by the experimenter (<xref ref-type="bibr" rid="bib13">Gallagher et al., 1999</xref>; <xref ref-type="bibr" rid="bib23">Izquierdo et al., 2004</xref>; <xref ref-type="bibr" rid="bib45">Pickens et al., 2003</xref>). A related body of work implicates the lOFC in evaluative processes, including comparing current choices to previous outcomes (<xref ref-type="bibr" rid="bib27">Kennerley et al., 2011</xref>), and regret (<xref ref-type="bibr" rid="bib59">Steiner and Redish, 2014</xref>; <xref ref-type="bibr" rid="bib58">Steiner and Redish, 2012</xref>).</p><p>Most of the studies demonstrating that OFC promotes behavioral flexibility have used tasks in which trial-by-trial learning improves behavioral performance (e.g., reversal learning). We hypothesized that OFC’s role in behavioral flexibility might drive sequential biases even when they are deleterious. We developed a task in which sequential biases were maladaptive: trials were independent and reward contingencies were stable over months of training (<xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>). Rats exhibited several dissociable biases reflecting trial and reward history, and we identified lOFC as critical for one bias in particular: an increased willingness to take risk following risky wins.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Rats choosing between guaranteed and probabilistic rewards show a risky ‘win-stay’ bias</title><p>We developed a task in which rats chose between explicitly cued guaranteed and probabilistic rewards (<xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>). Animals initiated a trial by nose-poking in the center of three ports. Auditory clicks were presented from left and right speakers, and the click rate (6–48 Hz) conveyed the volume of water reward baited at each of the two side ports. Simultaneously, light flashes were presented from side ports, and the number of flashes (0–10) conveyed the probability of receiving water reward at each port (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). One port offered a guaranteed or ‘safe’ reward (p=1), and the other offered a probabilistic or ‘risky’ reward (p≤1). Rewards were delivered 100 ms after rats entered the side port. The location of the safe and risky ports varied randomly on each trial. Four possible water volumes were offered (6, 12, 24, 48 μL), and risky reward probabilities ranged from 0 to 1, in increments of 0.1 (<xref ref-type="fig" rid="fig1">Figure 1B,C</xref>). The trials were self-paced, and following a choice, rats were free to initiate the next trial within 100–200 ms, although they typically took longer (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). However, if animals terminated the trial prematurely by breaking center fixation, they were penalized with a time-out penalty (1.5–8 s, adjusted across rats as needed).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.49744.002</object-id><label>Figure 1.</label><caption><title>Behavioral task: Rats performing the task exhibit stable performance over months, but also trial-by-trial learning dynamics.</title><p>(<bold>A</bold>) Example trial: rat initiates a trial by nose-poking and fixating in center. On each side, light flashes and click rates convey reward probability and water volume, respectively. One side (here, the right port) offers guaranteed reward (‘safe’); safe and risky sides vary randomly over trials. (<bold>B</bold>) Relationship between flashes and probability, and click rates and reward volumes (6, 12, 24, or 48 μL) in one version of the task. Risky side could have rewarded probability between 0–1 (increments of 0.1). (<bold>C</bold>) Offered reward volumes and probabilities. (<bold>D</bold>) Behavioral performance in units of ‘efficiency’ for five representative rats in the final training stage (Materials and methods). We compared the average expected value (reward x probability) per trial the rat received compared to an agent choosing randomly, or one that always chose the option with the greater expected value (‘ideal performance’). The dashed line is criterion performance for each rat (see ‘Materials and methods’). (<bold>E</bold>) Percent of trials one rat chose the safe option for each of the four safe volumes. Axes show probability and volume of risky alternatives. (<bold>F</bold>) Difference in probability of choosing the safe option following guaranteed rewards and risky rewards (relative to the mean probability of choosing safe) for all rats (black is mean). Rats were more likely to gamble following risky rewards (p=8.35e-16, paired t-test). (<bold>G</bold>) The magnitude of the risky win-stay bias exhibits graded dependence on the reward probability of the gamble (mean across rats). p=0.0035 of slope parameter of least-squares regression line (dashed line). The riskier the gamble that won, the more likely that rats will choose to gamble again. See also <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. (<bold>H</bold>) Change in the probability of repeating left or right choices following rewarded or unrewarded trials. Asterisks indicate that rats’ ‘win-stay’ biases were significantly different from zero (p=2.06e-13, paired t-test), as were their ‘lose-switch’ biases (p=2.65e-15).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Supplemental behavioral analyses.</title><p>(<bold>A</bold>) Distribution of inter-trial intervals (ITIs) for three representative rats. Trials were self-paced, rats were free to initiate trials within 100–200 ms of the preceding trial. If rats terminated the trial early by breaking center fixation, they were penalized with a time-out penalty (those trials are not shown). (<bold>B</bold>) Average number of trials per session for each rat, excluding trials that were terminated prematurely. Mean of this distribution (368 trials/session) is shown by the red arrow. (<bold>C</bold>) Mean behavioral performance across rats, including &gt;2.5 million trials. Percent of trials all rats chose the safe option for each of the four safe side volumes. Axes show the probability and volume of risky alternatives. Mean performance across 36 rats (normalized to max before averaging). (<bold>D</bold>) Estimates of conditional probabilities in finite sequential data can have small biases (<xref ref-type="bibr" rid="bib34">Miller and Sanjurjo, 2015</xref>). If this bias were driving sequential effects in our data, such as increased willingness to take risks following risky wins, we reasoned that computing this bias from random flips (of the same length as our data) of a weighted coin would also reveal an effect. Therefore, we generated random choices for each rat with a generative probability corresponding to the mean probability of choosing the safe option for that rat. We then calculated the change in the probability of choosing the safe option based on reward history for the simulated choices; the same number of trials that were used in <xref ref-type="fig" rid="fig1">Figure 1F</xref> were applied to this analysis. There was no observable risky win-stay bias in the simulated dataset, indicating that the effect we observed did not reflect biased estimates of conditional probabilities. (<bold>E</bold>) Difference in probability of choosing the safe option following guaranteed rewards and risky rewards of different probabilities (relative to the mean probability of choosing safe) for simulated data, as in B. Randomly simulated choices with the same sample sizes as the data (<xref ref-type="fig" rid="fig1">Figure 1G</xref>) did not exhibit a bias for risky choices with a graded dependence on reward probability. p=0.80 of slope parameter of least-squares regression line (dashed line). Therefore, the risky win-stay bias we observe, with graded dependence on reward probability, does not reflect biased estimation of conditional probabilities. (<bold>F</bold>) Difference in probability of choosing the safe option following guaranteed rewards, or risky unrewarded choices. There was no systematic, significant change in probability of choosing safe following unrewarded trials (paired t-test comparing change in probability of choosing safe).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig1-figsupp1-v1.tif"/></fig></fig-group><p>The ‘cue period’ is the period when the rat is center poking, and flashes and clicks are presented. The ‘choice reporting period’ begins when the rat exits the center poke and is free to report his choice by poking in one of the side ports.</p><p>To determine when rats were sufficiently trained to understand the meaning of the cues in the task, we evaluated the ‘efficiency’ of their choices, by comparing their mean expected value (probability x reward) per trial relative to an agent that always chose the option with greater expected value (‘ideal performance’) and one that chose randomly (‘random’; <xref ref-type="fig" rid="fig1">Figure 1D</xref>; see also <xref ref-type="bibr" rid="bib50">Rustichini et al., 2017</xref>). While variable, most rats learned the meaning of the cues within 1–2 months of training in the final training stage (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Well-trained rats (n = 36 animals) performed, on average, 368 trials per day (± 28 trials, s.e.m.; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). They tended to choose the option with the higher expected value; on trials when both sides offered certain rewards, rats chose the larger reward, and when one side offered no reward (p=0), they chose the alternative (<xref ref-type="fig" rid="fig1">Figure 1D,E</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>; <xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>).</p><p>Rats also exhibited sequential biases observed in primates: if they chose the risky option and were rewarded on the previous trial, they were more likely to gamble and choose the risky side again (<xref ref-type="fig" rid="fig1">Figure 1F</xref>; <xref ref-type="bibr" rid="bib5">Blanchard et al., 2014</xref>; <xref ref-type="bibr" rid="bib17">Hayden et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Neiman and Loewenstein, 2011</xref>). The change in probability of choosing the risky side following a risky win was significantly different from zero (p=1.29e-13, paired t-test across rats). This bias was not due to rats ‘un-learning’ the meaning of the flashes: there was no change in performance on trials where both sides offered the same reward volume, in which case the better option is the guaranteed reward, indicated by the flashes (p=0.397, paired t-test across rats). The magnitude of the risky win-stay bias depended on the risky reward probability (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). We emphasize that in this task, the belief that a risky ‘win’ increases the probability of future wins is a fallacy: outcomes are independent on each trial, by design. This result did not reflect biased estimates of conditional probabilities, often observed in finite sequential data (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D,E</xref>). There was no change in rats’ willingness to choose the gamble following a risky loss, indicating that rats were not simply going through phases of preference for risky or safe options (p=0.79 paired t-test; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). Similarly, there was no systematic change in rats’ risk preferences over the course of the training session: we examined trials where the guaranteed and risky reward had the same expected value. Rats’ choices on these trials indicate their risk attitudes, with risk averse rats preferring the guaranteed reward and risk seeking rats preferring the gamble (<xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>). There was no significant change in the probability of choosing the safe option on these trials, comparing the first and second half of trials in each session (p=0.15, paired t-test), again indicating that the risky win-stay bias was not due to slow fluctuations in rats’ risk preferences. Finally, because the risky and safe ports switch on each trial, this risky win-stay bias was independent of a spatial win-stay/lose-switch bias for the left or right ports (<xref ref-type="fig" rid="fig1">Figure 1H</xref>), or repetitive behavioral patterns such as perseveration (<xref ref-type="bibr" rid="bib32">Miller et al., 2017</xref>). It is notable, however, that the magnitude of rats’ spatial win-stay/lose-switch biases was much larger than the magnitude of their risky win-stay biases (<xref ref-type="fig" rid="fig1">Figure 1F,H</xref>).</p></sec><sec id="s2-2"><title>lOFC represents reward history during the cue period</title><p>We performed tetrode recordings in lOFC while rats performed the task. Many lOFC neurons exhibited transient responses at trial initiation, the magnitude of which reflected whether the previous trial was rewarded (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). To quantify this, we measured the mean discriminability (<italic>d’</italic>) of firing rates at each time point comparing trials following rewarded and unrewarded choices (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), analyzing cells with significantly different spike counts on these trials (n = 512 of 1459 units; p&lt;0.05, unpaired t-test). lOFC neurons reflected reward history most strongly at trial initiation, when the animal has no information yet about the prospects on the current trial (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>; <xref ref-type="bibr" rid="bib40">Nogueira et al., 2017</xref>). A significantly greater fraction of neurons exhibited higher firing rates following unrewarded trials, compared to rewarded trials, consistent with adaptation effects (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; <xref ref-type="bibr" rid="bib7">Conen and Padoa-Schioppa, 2019</xref>; <xref ref-type="bibr" rid="bib27">Kennerley et al., 2011</xref>; <xref ref-type="bibr" rid="bib41">Padoa-Schioppa, 2009</xref>; <xref ref-type="bibr" rid="bib51">Saez et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Zimmermann et al., 2018</xref>).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.49744.004</object-id><label>Figure 2.</label><caption><title>lOFC encodes reward history during the cue period.</title><p>(<bold>A</bold>) lOFC neuron with activity aligned to trial initiation. This neuron’s firing rate reflected whether the previous trial was rewarded. (<bold>B</bold>) Mean encoding of reward history (discriminability or d’) across lOFC neurons that exhibited significantly different spike counts based on reward history. Mean ± s.e.m. See also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. (<bold>C</bold>) Fraction of neurons with significantly different spike counts based on reward history, with more spikes following unrewarded (no rew &gt;rew) or rewarded (rew &gt;no rew) trials. (<bold>D</bold>) Schematic of analysis (TCA/PARAFAC) used to discover low dimensional descriptions of trial-by-trial population dynamics. See also <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. (<bold>E</bold>) Result of TCA/PARAFAC from one recording session. Y-axis is in arbitrary units (A.U.; see Materials and methods). (<bold>F</bold>) Mean (± s.d.) shuffle-corrected reward (blue) and no-reward (black) triggered averages of trial factors across all sessions (see Materials and methods). (<bold>G</bold>) Correlation between trial factors and reward history for each session. Gray bars indicate significance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Method for identifying putatively identical waveforms over days.</title><p>(<bold>A</bold>) Distribution of <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> values comparing waveforms across rats produces a null distribution (gray, see Materials and methods). Distribution of values comparing waveforms within rats from subsequent recording sessions (red). Dashed lines are empirically chosen thresholds. (<bold>B</bold>) Subplot from panel A. (<bold>C</bold>) Neuron that was identified as putatively identical across four recording sessions. Raster plots only show 150 trials (out of 400–600 each day) for display purposes (upper panels). PSTHs (derived from all trials) are shown below (lower panels). (<bold>D</bold>) <xref ref-type="fig" rid="fig2">Figure 2B</xref> was reproduced combining putatively identical units recorded over multiple days. Mean discriminability index (<bold>d’</bold>) depending on whether the previous trial was rewarded or not, computed in 50 ms bins. Error bars are ± s.e.m.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>TCA/PARAFAC tensor decomposition applied to neural data.</title><p>(<bold>A–C</bold>) Method used to determine model rank. We performed 20 random initializations and compared the similarity of the factors recovered from each iteration to those recovered from the previous one. We show the distribution of similarity indices for example recording sessions that were determined to be rank 1, 2, and 3 (A,B,C, respectively). Black lines are mean ± s.e.m. The majority of the data was either rank 1 or 2 (50/105 sessions were rank 1, 50/105 were rank 2, 5/105 were rank 3), so for simplicity, we fit a rank one model to each session. (<bold>D</bold>) Four neurons from the recording session in panel 3D; firing rates are plotted when the trial factor was high (&gt;85 th percentile) or low (&lt;15 th percentile). (<bold>E</bold>) Mean (± s.d.) shuffle-corrected reward (blue) and no-reward (black) triggered averages of trial factors across all sessions (see Materials and methods), excluding cells that had significantly different spike counts following rewarded or unrewarded trials. (<bold>F</bold>) Mean (± s.d.) shuffle-corrected reward (blue) and no-reward (black) triggered averages of trial factors, excluding random subsets of cells, of the same number that were excluded in panel E. (<bold>G</bold>) Distribution of simultaneously recorded units across all recording sessions. (<bold>H</bold>) Relationship between the Pearson’s correlation between trial factors and reward history, and number of units recorded in each session. (<bold>I</bold>) Relationship between the absolute magnitude of the Pearson’s correlation between trial factors and reward history, and number of units recorded in each session.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig2-figsupp2-v1.tif"/></fig></fig-group><p>Our data show that lOFC neurons encode information about reward history (Figure 2A,B), which might be expected from neurons mediating trial history biases. Given that behavior likely requires the activity of populations of neurons, we next sought an unsupervised description of simultaneously recorded neurons. We employed an extension of principal components analysis, tensor components analysis (<xref ref-type="bibr" rid="bib65">Williams et al., 2018</xref>); TCA, also known as CANDECOMP/PARAFAC tensor decomposition (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This method extracts features of three aspects of neural data: (1) neuron factors, which weight each neuron’s activity; (2) temporal factors, which capture time-varying dynamics within a trial; and (3) trial factors, which capture dynamics across trials. TCA/PARAFAC provides a low dimensional description of neural dynamics both <italic>within</italic> and <italic>across</italic> trials, allowing for simple descriptions of complex, multi-neuron responses across multiple timescales. TCA provides a key advantage over more common dimensionality reduction techniques like PCA or Factor Analysis which require averaging over trials; TCA allows us to independently quantify trial to trial fluctuations in neural activity. TCA decomposes a 3rd order data tensor <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mi/></mml:math></inline-formula> (with n neurons over k trials of length t) by a sum of rank 1 factors <inline-formula><mml:math id="inf4"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi> <mml:mi/></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi> <mml:mi/></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, for each rank r, w is a vector of neuron factors, b is a vector of temporal (time within trial) factors, and a is a vector of across trial factors. <xref ref-type="fig" rid="fig2">Figure 2E</xref> shows the neuron, temporal, and trial factors for one recording session (see Materials and methods, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><p>Trial factors were significantly modulated by reward history two trials in the past, on average (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). This modulation required the neurons whose firing rates reflected reward history (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2E–F</xref>). On 43% of recording sessions (45/105 sessions), there was a significant correlation between rats’ reward history and the trial factors, and these correlations were typically negative (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). The trial factor can be thought of as a gain factor applied to the population response (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2D</xref>); a negative correlation suggests that when rats received reward, neural activity in lOFC generally decreased on the subsequent trial, consistent with several reports of reward adaptation in OFC (<xref ref-type="bibr" rid="bib7">Conen and Padoa-Schioppa, 2019</xref>; <xref ref-type="bibr" rid="bib27">Kennerley et al., 2011</xref>; <xref ref-type="bibr" rid="bib41">Padoa-Schioppa, 2009</xref>; <xref ref-type="bibr" rid="bib51">Saez et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Zimmermann et al., 2018</xref>). We note that there was no systematic relationship between the correlation of rats’ reward history and the trial factors, and the number of simultaneously recorded neurons in each session (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2H,I</xref>).</p><p>Given the strong encoding of aggregated reward history, we hypothesized that disrupting lOFC dynamics during the cue period would disrupt trial-by-trial learning. Optogenetic inhibition during the cue period, however, did not affect spatial win-stay or lose-switch biases (<xref ref-type="fig" rid="fig3">Figure 3A–D</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Photoinhibition also did not affect the risky win-stay bias, in wild-type CaMKIIα-eNpHR3.0 or Pvalb-iCre-ChR2 rats (<xref ref-type="fig" rid="fig3">Figure 3E</xref>; p=0.005, one-way ANOVA comparing safe choices following safe or risky rewards, pooling data across all 13 optogenetic rats).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.49744.007</object-id><label>Figure 3.</label><caption><title>Optogenetic perturbation of lOFC during the cue period does not affect spatial or risky trial history biases.</title><p>(<bold>A</bold>) Schematic of bilateral optogenetic perturbations. For CaMKIIα-eNpHR3.0 rats (n = 8), we used continuous illumination of a green laser for photoinhibition. For Pvalb-iCre-ChR2 rats (n = 5), a blue laser was pulsed at 20 Hz. See also <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. While the schematic shows a 3 s trial, trial durations were variable (2.6–3.35 s); photoinhibition persisted for the duration of the cue period. (<bold>B</bold>) Histological section from Pvalb-iCre-ChR2 rats also stained for DAPI and parvalbumin (PV) immunoreactivity. (<bold>C</bold>) Virus injection in a wild type rat expressing CaMKIIα-eNpHR3.0. Location of fibers were estimated by damage at brain surface and fiber tracks. (<bold>D</bold>) Magnitude of spatial win-stay and lose-switch biases (difference in probability of repeating a left or right choice) on control and laser trials. Error bars are normal approximation of 95% confidence intervals (Materials and methods). (<bold>E</bold>) Magnitude of risky win-stay bias (difference in probability of choosing the safe option following safe or risky rewards) on control and laser trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Characterization of photoinhibition in Pvalb-iCre-ChR2 rats.</title><p>(<bold>A</bold>) Representative unit recorded from Pvalb-iCre rats expressing ChR2. Three epochs of photoinhibition (blue lines) reliably suppressed spiking activity. Blue laser was pulsed at 20 Hz, 10 ms pulse width, for 8 s. (<bold>B</bold>) Normalized activity of the cell shown in A; mean ± s.e.m. over 30 photoinhibition epochs. (<bold>C</bold>) Mean suppression over 65 recorded units from two rats. (<bold>D</bold>) Activity change of each unit plotted as a function of its distance from the optical fiber. Units were recorded in four tracks, 250, 500, 750, or 1000 μm from the fiber tip. Robust photoinhibition was observed in all tracks. (<bold>E</bold>) Example injection site shown in <xref ref-type="fig" rid="fig4">Figure 4C</xref>; inset shows putative fiber track. (<bold>F</bold>) Percent of parvalbumin-immunoreactive cells that co-expressed eYFP in Pvalb-iCre rats expressing eYFP-ChR2 (left), and fraction of eYFP-expressing cells co-labeled for parvalbumin immunoreactivity (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Disrupting lOFC during the choice report eliminated the risky win-stay bias</title><p>In contrast to during the cue period, activity at the time of the choice report, when rats exited the center poke, often reflected whether rats chose the safe or risky prospect (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>). A subset of lOFC neurons exhibited significantly different spike counts on rewarded trials when rats chose the safe compared to the risky option (<xref ref-type="fig" rid="fig4">Figure 4B–E</xref>; n = 128 units, unpaired t-test). For these neurons, discriminability peaked shortly after rats left the center poke (<xref ref-type="fig" rid="fig4">Figure 4C,D</xref>). We also observed prominent side-selectivity (n = 628 units) and strong encoding of reward receipt (n = 459) during the choice reporting period (<xref ref-type="fig" rid="fig4">Figure 4F–H</xref>). Of the neurons whose activity reflected safe/risky choice, there was no significant side bias (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.49744.009</object-id><label>Figure 4.</label><caption><title>At time of choice report, lOFC neurons represent risk, reward, and left/right choice.</title><p>(<bold>A</bold>) Example lOFC neuron with activity aligned to when the rat left the center poke to report his choice. This neuron’s firing rate reflected whether the rat chose the risky (magenta) or safe (black) option on the current trial, analyzing rewarded trials only. (<bold>B</bold>) Mean d’ across lOFC neurons with significantly different spike counts on trials with risky or safe choices. See also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. (<bold>C,D</bold>) Mean z-scored firing rate of neurons in panel B aligned to entering the center poke (<bold>C</bold>), or leaving it to report choice (<bold>D</bold>). (<bold>E</bold>) Fraction of neurons in panels B-D that preferred trials when rats made risky or safe choices. Higher firing rates on trials in which rats chose the safe reward could reflect encoding of decision confidence or reward expectation (<xref ref-type="bibr" rid="bib30">Lak et al., 2014</xref>). (<bold>F</bold>) Mean d’ reflecting whether rats chose the left/right ports, or whether rats received reward, averaged across neurons with significantly different spike counts on those trials. See also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>. (<bold>G</bold>) Venn diagram of overlap between neurons whose activity differentiated between left/right choices and rewarded/unrewarded trials. (<bold>H</bold>) Fraction of neurons in panels F,G preferring left/right choices or rewarded/unrewarded trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.010</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Results do not depend on whether units are treated independently over days.</title><p>(<bold>A,B</bold>) <xref ref-type="fig" rid="fig4">Figure 4B</xref> (<bold>A</bold>) and 4F (<bold>B</bold>) were reproduced combining putatively identical units recorded over multiple days. Mean discriminability index (<bold>d’</bold>) depending on whether the rat chose the safe or risky option on rewarded trials only (<bold>A</bold>), chose left or right (B, purple), or was rewarded (B, yellow), computed in 50 ms bins. Error bars are ± s.e.m. (<bold>C</bold>) Of the units with significantly different spike counts on trials in which rats chose risky or safe, the fraction selective (or not) for choosing the left or right port.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig4-figsupp1-v1.tif"/></fig></fig-group><p>Given the prominent encoding of rats’ left/right choices during this period (<xref ref-type="fig" rid="fig4">Figure 4F,G</xref>), we next tested whether photoinhibition affected spatial win-stay/lose-switch biases for the left/right ports. We optogenetically perturbed lOFC during the choice reporting period (triggered when rats exited the center port) for 4 s, and then analyzed performance on subsequent trials. Inhibition during the choice reporting period was interleaved in the same sessions as inhibition during the cue period, in the animals shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. While there was a significant reduction in spatial biases, sham rats also exhibited reduced win-stay/lose-switch biases (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Photoinhibition during the choice reporting period imposed a minimum inter-trial interval (ITI) of 4 s (for laser illumination), which was longer than the average ITI (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). Comparing the photoinhibition trials to control trials with a minimum ITI of 4 s eliminated the reduction in spatial win-stay/lose-switch biases in CaMKIIα-eNpHR3.0, Pvalb-iCre-ChR2, and sham rats (data not shown).</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.49744.011</object-id><label>Figure 5.</label><caption><title>Photoinhibition of lOFC at the time of choice report selectively eliminates the risky win-stay bias.</title><p>(<bold>A</bold>) For choice reporting period perturbations, the laser was triggered when rats left the center poke, and persisted for 4 s into the inter-trial-interval. See also <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>. (<bold>B</bold>) Spatial win-stay/lose-switch biases following photoinhibition during the choice reporting period; sham rats also exhibited a significant reduction in lose-switch biases, and trended towards a reduction in win-stay biases. Control data are replotted from <xref ref-type="fig" rid="fig3">Figure 3D</xref>. (<bold>C</bold>) Magnitude of the risky win-stay bias following choice reporting period inactivations. Control data are replotted from <xref ref-type="fig" rid="fig3">Figure 3E</xref>. Error bars are 95% confidence intervals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.49744.012</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Photoinhibition during the choice reporting period does not affect baseline performance, but selectively reduces the risky win–stay bias.</title><p>(<bold>A</bold>) Psychometric performance for each CaMKIIα-eNpHR3.0 rat on control trials (black) and trials following photoinhibition during the choice period. These plots include all trials, regardless of trial history, so the elimination of the risky win-stay bias is not evident. (<bold>B</bold>) Psychometric performance for each Pvalb-iCre-ChR2 rat on control trials (black) and trials following photoinhibition during the choice period. (<bold>C</bold>) Difference in logistic regression coefficients (control - photoinhibition) parameterizing different choice biases. Data are mean ± standard deviation across rats. Asterisks indicate significant Bonferroni-corrected p-value from one-way ANOVA (p=0.0063).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-49744-fig5-figsupp1-v1.tif"/></fig></fig-group><p>In contrast, optogenetic inhibition of lOFC during the choice reporting period eliminated the risky win-stay bias on the subsequent trial in rats expressing light-sensitive opsins (<xref ref-type="fig" rid="fig5">Figure 5A,C</xref>; p=0.667 CaMKIIα-eNpHR3.0; p=0.778 Pvalb-iCre-ChR2; one-way ANOVA comparing safe choices following safe or risky rewards, pooling data across rats). Laser illumination did not disrupt the risky win-stay bias in sham rats not expressing light-activated opsins (<xref ref-type="fig" rid="fig5">Figure 5C</xref>; p=0.009, one-way ANOVA comparing safe choices following safe or risky rewards, n = 3 rats). For the majority of rats (7/8 CaMKIIα-eNpHR3.0 rats and 4/5 Pvalb-iCre-ChR2 rats), there was no significant effect on choice latencies compared to control trials (Wilcoxon rank-sum test, Bonferroni correction for multiple comparisons). Moreover the behavioral effect occurred on trials <italic>subsequent</italic> to the optogenetic perturbations (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), making it unlikely that they were due to off-target illumination of motor cortex, including overlying M2.</p><p>We wanted to determine if photoinhibition of lOFC affected other potential biases, so we used logistic regression with parameters for choice repetition for safe/risky choices, the risky win-stay bias described above, left/right choice repetition, and systematic left/right side biases (<xref ref-type="bibr" rid="bib26">Kagel et al., 1995</xref>; <xref ref-type="bibr" rid="bib43">Padoa-Schioppa, 2013</xref>). Photoinhibition during the choice report exclusively reduced the risky win-stay bias parameter, but not others (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>; p=0.0063, one-way ANOVA with Bonferroni correction; Materials and methods).</p><p>The reduction of the risky win-stay bias did not reflect changes in the baseline probability of choosing safe (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>), and was observed on a rat-by-rat basis (pooling CaMKIIα-eNpHR3.0 and Pvalb-iCre-ChR2 rats, p=0.015; paired t-test across rats). Therefore, photoinhibition of lOFC specifically eliminated risky biases and not spatial biases. Moreover, risky biases were not sensitive to ITI duration (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, sham), whereas spatial biases decreased with ITI duration (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, sham), further suggesting that these sequential dependencies are dissociable.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Across species, OFC has been implicated in myriad aspects of value-based decision-making, including representing the value of offered and chosen goods, expected outcomes, confidence, regret, and credit assignment (<xref ref-type="bibr" rid="bib2">Akaishi et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Kepecs et al., 2008</xref>; <xref ref-type="bibr" rid="bib42">Padoa-Schioppa, 2011</xref>; <xref ref-type="bibr" rid="bib48">Rudebeck and Murray, 2014</xref>; <xref ref-type="bibr" rid="bib52">Schoenbaum et al., 1998</xref>; <xref ref-type="bibr" rid="bib59">Steiner and Redish, 2014</xref>). Evidence from studies using reversal learning paradigms or Pavlovian instrumental transfer suggests that the OFC is critical for behavioral flexibility (<xref ref-type="bibr" rid="bib23">Izquierdo et al., 2004</xref>; <xref ref-type="bibr" rid="bib54">Schoenbaum et al., 2003</xref>), and recent work indicates that value representations in lOFC may drive learning rather than action selection or choice (<xref ref-type="bibr" rid="bib33">Miller et al., 2018</xref>). Relatedly, a recent study showed that rats with lOFC lesions exhibited disrupted sensitivity to previous trial outcomes, especially when those outcomes were unexpected, analogous to probabilistic rewards in our task (<xref ref-type="bibr" rid="bib60">Stolyarova and Izquierdo, 2017</xref>). Our data are consistent with a role for lOFC in updating rats’ risk attitudes or their beliefs about the world (<xref ref-type="bibr" rid="bib25">Jones et al., 2012</xref>; <xref ref-type="bibr" rid="bib31">McDannald et al., 2011</xref>; <xref ref-type="bibr" rid="bib32">Miller et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Wilson et al., 2014</xref>). lOFC neurons reflected reward history most strongly at trial initiation, when the animal has no information yet about the prospects on the current trial (<xref ref-type="bibr" rid="bib40">Nogueira et al., 2017</xref>). These dynamics are therefore distinct from relative value coding observed in primate OFC, in which neurons encode the value of rewards on the current trial relative to rewards on the previous trial (<xref ref-type="bibr" rid="bib27">Kennerley et al., 2011</xref>; <xref ref-type="bibr" rid="bib41">Padoa-Schioppa, 2009</xref>; <xref ref-type="bibr" rid="bib51">Saez et al., 2017</xref>). The temporal response profiles we observed are generally consistent with reports that OFC neurons fire transiently when an animal initiates reward-seeking behavior, here, trial initiation (<xref ref-type="bibr" rid="bib35">Moorman and Aston-Jones, 2014</xref>).</p><p>We observed many ‘side-selective’ neurons whose activity reflected which side the rat chose. A hallmark of primate OFC is that neurons do not encode spatial location (<xref ref-type="bibr" rid="bib14">Grattan and Glimcher, 2014</xref>; <xref ref-type="bibr" rid="bib44">Padoa-Schioppa and Cai, 2011</xref>). This discrepancy could reflect a species difference (<xref ref-type="bibr" rid="bib12">Feierstein et al., 2006</xref>; <xref ref-type="bibr" rid="bib29">Kuwabara and Holy, 2019</xref>; <xref ref-type="bibr" rid="bib47">Roesch et al., 2006</xref>). Alternatively, side-selectivity could reflect encoding of the left and right prospects or ‘goods’ on each trial (<xref ref-type="bibr" rid="bib42">Padoa-Schioppa, 2011</xref>).</p><p>This study used sensory stimuli (visual flashes, auditory clicks) to convey information about reward options to the animal. Evidence from primates suggests that some OFC neurons may be selective for particular stimulus identities used to indicate reward attributes (<xref ref-type="bibr" rid="bib22">Hunt et al., 2018</xref>). An intriguing direction for future research would be to record neural activity in OFC as animals learn the associations between sensory stimuli and reward attributes, to characterize the evolution of dynamics in OFC from early to late in training.</p><p>We found that perturbation effects were uncoupled from task variables that seemed to be encoded most strongly, quantified by either fraction of neurons or discriminability, both during the cue period (reward history) and during the choice reporting period (left/right choice). This raises an intriguing question: why are these variables so strongly represented in lOFC if the animal appears to not be using those representations to guide behavior? It is possible that representations of reward history and choice may be distributed broadly enough that other brain areas can compensate for local perturbations, whereas representations used to update risk preferences may be more narrowly localized within or read out from OFC.</p><p>Are specific subcircuits within OFC responsible for the risky win-stay bias, and updating dynamic risk preferences more generally? The relatively small fraction of neurons (~9%) that reflect whether choices are risky or safe may be behaviorally relevant, perhaps occupying a privileged position in the circuit and/or projecting to a common target. Alternatively, the more substantial fraction of neurons representing whether animals received reward (~31%) may be involved in updating risk preferences, in which case their activity is read out to specifically update abstract task-specific (here, risky), but not spatial, biases. This latter hypothesis is consistent with a recent study of medial OFC (mOFC) in mice (<xref ref-type="bibr" rid="bib38">Namboodiri et al., 2019</xref>). In a Pavlovian conditioning paradigm, in which a tone probabilistically predicted a sucrose reward, mice exhibited trial-by-trial updating of their reward expectation, revealed by their anticipatory licking, based on reward history. Optogenetic inactivation of mOFC neurons projecting to the ventral tegmental area (VTA) during the reward period, but not the cue period, disrupted this trial-by-trial learning (<xref ref-type="bibr" rid="bib38">Namboodiri et al., 2019</xref>). While there is increasing evidence for functional differences between medial and lateral OFC in rodents, these results are consistent with the present study, and suggest that the risky win-stay bias we observed may derive from lOFC neurons projecting to the VTA.</p><p>The risky win-stay bias may reflect evolutionary pressures in dynamic foraging environments, in which sequential successful outcomes are often not independent but reflect ‘clumped’ resources (<xref ref-type="bibr" rid="bib5">Blanchard et al., 2014</xref>; <xref ref-type="bibr" rid="bib64">Wilke and Barrett, 2009</xref>). However, today it demonstrably (and often adversely) affects behavior in finance, recreational gambling, and sports (<xref ref-type="bibr" rid="bib10">Croson and Sundali, 2005</xref>; <xref ref-type="bibr" rid="bib20">Hoffmann et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Neiman and Loewenstein, 2011</xref>). Our data show that this particular sequential bias is observable and manipulable in populations of neurons in lOFC, although lOFC’s involvement may depend upon task design.</p><p>OFC has been proposed to represent the animal’s location in a cognitive map of the task, which, in a reinforcement learning framework, corresponds to the current state in an abstract representation of task states and transitions between them (<xref ref-type="bibr" rid="bib40">Nogueira et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Wilson et al., 2014</xref>). The cognitive map hypothesis parsimoniously accounts for the results of OFC lesions in a variety of paradigms including delayed alternation, extinction, devaluation, and reversal learning, and is consistent with OFC’s role in evaluative processes such as regret (<xref ref-type="bibr" rid="bib13">Gallagher et al., 1999</xref>; <xref ref-type="bibr" rid="bib23">Izquierdo et al., 2004</xref>; <xref ref-type="bibr" rid="bib45">Pickens et al., 2003</xref>; <xref ref-type="bibr" rid="bib59">Steiner and Redish, 2014</xref>; <xref ref-type="bibr" rid="bib58">Steiner and Redish, 2012</xref>; <xref ref-type="bibr" rid="bib66">Wilson et al., 2014</xref>). A recent study showed that the OFC may be particularly important for <italic>learning</italic> of action-outcome values (<xref ref-type="bibr" rid="bib33">Miller et al., 2018</xref>). Our data are consistent with this hypothesis, and indicate that the coordinate space of the cognitive map in which OFC promoted learning in this task was in abstract (risky or safe), but not spatial (left or right) coordinates.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animal subjects</title><p>A total of 39 male rats between the ages of 6 and 24 months were used for this study. These included 35 Long-evans and 4 Sprague-Dawley rats (<italic>Rattus norvegicus</italic>). Of these, three rats were used for neural recordings, and 16 for optogenetic experiments, including LE-Tg (Pvalb-iCre)2Ottc rats (n = 5) made at NIDA/NIMH and obtained from the University of Missouri RRRC (transgenic line 0773). These are BAC transgenic rats expressing Cre recombinase in parvalbumin expressing neurons. Investigators were not blinded to experimental groups during data collection or analysis. Animal use procedures were approved by the Princeton University Institutional Animal Care and Use Committee and carried out in accordance with National Institutes of Health standards.</p><p>Animals were water restricted to motivate them to perform behavioral trials. They obtained water rewards during behavioral training sessions, which ranged from 1 to 5 hr per day, and an ad lib access period of up to 1 hr. Food was typically placed in the behavioral box during training, so it was available during the water access period. All rats obtained a minimum volume of water equal to 3–5% of their body mass, (30–50 mL/kg). Water consumption was monitored during the behavioral session, and if rats consumed less than the minimum requirement, additional water was offered during an ad lib period. The ad lib period terminated either when the target water volume was exceeded or after 1 hr.</p></sec><sec id="s4-2"><title>Behavior</title><p>We have previously described rats’ behavior on this task in detail (<xref ref-type="bibr" rid="bib8">Constantinople et al., 2019</xref>). Briefly, rats were trained in a high-throughput facility using a computerized training protocol. Rats were trained in operant training boxes with three nose ports. When an LED from the center port was illuminated, the animal could initiate a trial by poking his nose in that port; upon trial initiation the center LED turned off. While in the center port, rats were continuously presented with a train of randomly timed clicks from a left speaker and, simultaneously, a different train of clicks from a right speaker. The click trains were generated by Poisson processes with different underlying rates (<xref ref-type="bibr" rid="bib16">Hanks et al., 2015</xref>); the rates conveyed the water volume baited at each side port. After a variable pre-flash interval ranging from 0 to 350 ms, rats were also presented with light flashes from the left and right side ports; the number of flashes conveyed reward probability at each port. Each flash was 20 ms in duration; flashes were presented in fixed bins, spaced every 250 ms, to avoid perceptual fusion of consecutive flashes. After a variable post-flash delay period from 0 to 500 ms, the end of the trial was cued by a go sound and the center LED turning back on. The animal was then free to choose the left or right center port, and potentially collect reward.</p><p>In this task, the rats were required to reveal their preference between safe and risky rewards. First, rats proceeded through a series of early training stages that included training the rat to center poke, gradually growing the duration of center fixation, and introducing cues representing certain rewards of each volume on one side at a time. Once they were in the final training stage they were presented with the full choice set. To determine when rats were sufficiently trained to understand the meaning of the cues in the task, we evaluated the ‘efficiency’ of their choices as follows. For each training session, we computed the average expected value per trial of an agent that chose randomly, and an expected value maximizer, or an agent that always chose the side with the greater expected value. We compared the expected value per trial from the rat’s choices relative to these lower and upper bounds. Specifically, the efficiency was calculated as follows:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mfrac><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The threshold for analysis was the median performance of all sessions minus 1.5 times the interquartile range of performance across the second half of all sessions. Once performance surpassed this threshold, it was typically stable across months. Occasional days with poor performance were usually due to hardware malfunctions in the rig or a change in the experiment (e.g., the first day being tethered for electrophysiological recordings). Days in which performance was below threshold were excluded from analysis.</p></sec><sec id="s4-3"><title>Psychometric curves</title><p>We measured rats’ psychometric performance when choosing between the safe and risky options. For these analyses, we excluded trials where both the left and right side ports offered certain rewards. We binned the data into 11 bins of the difference in the expected value (reward x probability) of the safe minus the risky option. Psychometric plots show the probability that the subjects chose the safe option as a function of this difference (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). We fit a 4-parameter sigmoid of the form:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where y0, a, b, and x0 were free parameters. Parameters were fit using a gradient-descent algorithm to minimize the mean square error between the data and the sigmoid, using the sqp algorithm in Matlab’s constrained optimization function fmincon.</p></sec><sec id="s4-4"><title>Chronic electrophysiology</title><p>Tetrodes were constructed from twisted wires that were either PtIr (18 µm, California Fine Wire) or NiCr (25 µm, Sandvik). Tetrode tips were platinum- or gold-plated to reduce impedances to 100–250 kΩ at 1 kHz using a nanoZ (White Matter LLC).</p><p>Microdrive assemblies were custom-made as described previously (<xref ref-type="bibr" rid="bib4">Aronov and Tank, 2014</xref>). Each drive contained eight independently movable tetrodes, plus an immobile PtIR reference electrode. Each animal was implanted over the right OFC. On the day of implantation, electrodes were lowered to ~4.1 mm DV. Animals were allowed to recover for 2–3 weeks before recording. Shuttles were lowered ~30–60 µm approximately every 2–4 days.</p><p>Data were acquired using a Neuralynx data acquisition system. Spikes were manually sorted using MClust software. Units with fewer than 1% inter-spike intervals less than 2 ms were deemed single units. All units that fired more than two spikes on half of trials were included in analysis (n = 1459/1881). To convert spikes to firing rates, spike counts were binned in 50 ms bins and smoothed using Matlab’s smooth.m function.</p></sec><sec id="s4-5"><title>Discriminability, or <italic>d’</italic>, of OFC neurons</title><p>To measure neuronal discriminability for different task variables, such as whether the previous trial was rewarded, we computed the mean difference in the smoothed firing rate on different trial types divided by the square root of their mean variance:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Because we computed the absolute value of the difference in firing rates, we subtracted the mean shuffled <italic>d’</italic>, computed from shuffling the data 15 times. <italic>d’</italic> was computed in 50 ms bins, as this was the bin-width used for computing the firing rates (see above).</p></sec><sec id="s4-6"><title>Spike waveform analysis for identifying the same neurons recorded over days</title><p>The single neuron data shown in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref> treated each unit recorded on a different day/recording session as a unique unit. However, we also modified previously published methods (<xref ref-type="bibr" rid="bib61">Tolias et al., 2007</xref>) to identify units recorded over days (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We computed two metrics (<xref ref-type="bibr" rid="bib61">Tolias et al., 2007</xref>), which we describe below, based on the spike waveform. The first metric compared how similar the shape of the waveform was across recording sessions. For each waveform on session 1 (x), we computed α to make it as close as possible to the waveform on session 2 (y):<disp-formula id="equ4"><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:munder><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We used Matlab’s constrained minimization function fmincon.m to find α. We then computed the Euclidean distance between the scaled waveforms, d<sub>1</sub>.<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The second metric, d<sub>2</sub> quantified the difference in amplitude across the 4 channels of each tetrode.<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We computed these metrics for all pairs of waveforms recorded on the same tetrode on subsequent recording sessions. To compare these values to a null distribution, we computed the d<sub>1</sub> and d<sub>2</sub> metrics for units recorded from two different animals, which could not have identical waveforms. We used this null distribution to empirically determine thresholds for d<sub>1</sub> (0.8) and d<sub>2</sub> (1). Units recorded on consecutive sessions with values below these thresholds, and with significant Pearson’s correlation coefficients of their mean firing rates aligned to trial start (p&lt;0.05), were tentatively classified as identical (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Putatively identical neurons were then manually examined, and those that exhibited qualitatively different PSTHs, or different mean firing rates over days were rejected and treated as separate units. 191/1459 (13%) units that met criteria for inclusion in analysis were recorded over multiple sessions. Combining data from these units over sessions did not change the results (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). For population analyses (TCA/PARAFAC; <xref ref-type="fig" rid="fig2">Figure 2D-G</xref>), data were not combined across recording sessions.</p></sec><sec id="s4-7"><title>Tensor components analysis/CANDECOMP/PARAFAC tensor decomposition</title><p>To fit the tensor decomposition model, we used software recently made publicly available (<xref ref-type="bibr" rid="bib65">Williams et al., 2018</xref>): <ext-link ext-link-type="uri" xlink:href="https://github.com/ahwillia/tensortools">https://github.com/ahwillia/tensortools</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/tensortools">https://github.com/elifesciences-publications/tensortools</ext-link>).</p><p>To initially determine the dimensionality, or rank, that should be applied to each recording session, we iteratively tried different numbers of dimensions, or ‘tensor components’, and computed a similarity index to determine how sensitive the recovered factors were to the initialized values of the optimization procedure (<xref ref-type="bibr" rid="bib65">Williams et al., 2018</xref>). The similarity index was computed on factors recovered from consecutive initializations using the score.m function in Matlab’s Tensor Toolbox. The maximum number of components that yielded an average similarity index &gt;90% was used as the number of components, or rank, for each recording session (Figure S3). Nearly all of our recording sessions were rank 1 or 2 (by this method). TCA/PARAFAC is notably different from principal components analysis (PCA) in that the first component does not necessarily explain the most variance of the data (<xref ref-type="bibr" rid="bib65">Williams et al., 2018</xref>). Therefore, given that most of our data were low rank, to simplify the problem of determining which trial factors to analyze, we fit a rank one model to each recording session.</p><p>We computed the shuffle-corrected reward-triggered averages of trial factors (and no reward-triggered averages) as follows. We computed the average change in trial factors relative to the mean trial factor relative to each rewarded (and unrewarded) trial, up to seven trials in the future. We then performed a shuffle correction, shuffling the trials randomly with respect to reward history, and computed the average change in trial factors relative to rewarded and unrewarded trials (relative to the mean) for the shuffled data. We subtracted the shuffled averages from the true averages to obtain the plot in <xref ref-type="fig" rid="fig2">Figure 2F</xref>.</p><p>TCA decomposes a 3rd order data tensor <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mi/></mml:math></inline-formula>(with n neurons over k trials of length t) by a sum of rank 1 factors <inline-formula><mml:math id="inf6"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi> <mml:mi/></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi> <mml:mi/></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, for each rank r, w is a vector of neuron factors, b is a vector of temporal (time within trial) factors, and a is a vector of across trial factors. We note that each of the factors (neuron, temporal, and trial) is a linear gain factor, multiplied by the others; therefore, meaningful units are difficult to determine (as all the factors are multiplied); their scale is a gain on the other terms.</p></sec><sec id="s4-8"><title>Acute electrophysiology</title><p>To confirm photoinhibition in Pvalb-iCre-ChR2 rats, we performed virus delivery as described below. After 6–8 weeks to allow for expression, rats (n = 2) were anesthetized with for surgery with 0.2 mL ketamine and 0.2 mL buprenorphine. Craniotomies were made over frontal orienting field (FOF; centered 2 mm anterior to the Bregma and 1.3 mm lateral to the midline), and the rat was maintained under isoflurane anesthesia.</p><p>A chemically sharpened fiber optic (50 um core, 125 um cladding) was inserted into the field of infected neurons to a depth of 1 mm. A sharp tungsten electrode (0.5 MW) mounted to a Narishige oil hydraulic micromanipulator was manually lowered into the brain. Recordings were made using a Neuralynx Cheetah system applying a bandpass filter from 300 to 6000 Hz to the voltage signal. At each site an 8 s laser illumination (473 nm, 25 mW, 20 Hz, 20 ms of pulse duration) was delivered every 20 s, 10 times. A mechanical shutter (Thor Labs optical beam shutter) was used to control the laser timing.</p><p>Spikes were automatically detected as brief (&lt;1 ms) events that crossed a threshold of ± 5 standard deviations on the filtered voltage trace. In order to remove light artifact and possible population spikes of driven PV neurons, we removed spikes within the 20 ms of the laser pulse onset. Inhibition was defined as the mean spike rate during the 8 s laser on period/the mean spike rate during the 12 s laser off period.</p></sec><sec id="s4-9"><title>Optical fiber chemical sharpening</title><p>We used standard off the shelf FC-FC duplex fiber optic cables (#FCC2433, <ext-link ext-link-type="uri" xlink:href="http://FiberCables.com">FiberCables.com</ext-link>), and as previously described (<xref ref-type="bibr" rid="bib16">Hanks et al., 2015</xref>), stripped the outer plastic coating. To etch the fiber, 2–2.5 mm of the fiber tip was submerged in 48% hydrofluoric acid with mineral oil on top. Over the course of ~17 min, a motor (Narishige) slowly pulled the fiber tip out of the hydrofluoric acid, producing a long taper. The speed of the motor was then increased and maintained at a constant speed until the tip was entirely removed from the acid (usually by 13–15 min). This protocol reliably produced sharp, well-etched fibers with uniform and broad light scatter. Fibers that did not produce sufficiently broad or uniform scatter were discarded.</p></sec><sec id="s4-10"><title>Virus delivery and fiber implantation</title><p>We used methods described previously (<xref ref-type="bibr" rid="bib16">Hanks et al., 2015</xref>); here we describe procedures specific to this experiment. We injected 2 µL of AAV virus (AAV5-CaMKIIα-eNpHR3.0-eYFP in wild type rats, or AAV-FLEX-rev-ChR2-tdtomato in Pvalb-iCre rats) using a Nanoject (Drummond Scientific). Six closely spaced injection tracts (typically 500 µm apart) were made in each craniotomy; each rat had bilateral craniotomies and injections, so there were 12 total injection tracts per animal. For OFC injections, in each track, 18 injections of 14.1 nL were made every 100 µm in depth starting at 3.7 mm below brain surface (3.7–5.4 mm DV). Virus was expelled at 20 nL/sec. Injections were made once every 10 s; at the final injection in a tract, the pipette was left in place for at least 2 min before removal.</p><p>Chemically sharpened fibers (50 µm core, 125 µm cladding) were implanted at 5° angles relative to the midline. Fiber tips were positioned 0.4 mm lateral from the center track at brain surface so that, when the tip was lowered to 4.6 mm DV, it was centered at the target coordinates (+3.5 AP, ± 2.5 ML). Viral constructs were allowed to develop for 6–8 weeks before behavioral experiments began.</p></sec><sec id="s4-11"><title>Optogenetic perturbation</title><p>For bilateral halorhodopsin inactivations, the laser beam from a 200 mW, 532 nm laser (OEM Laser Systems) was split into two beams of roughly equal power (~25 mW) using a beam splitter (Doric DMC_1 × 2i_VIS_FC). Laser illumination was delivered on a subset of trials by opening a shutter with a 5 V TTL. On a random subset of 15% of trials, illumination occurred during the entire trial (triggered when the rat entered the center poke until he was free to leave it), or on a random 15% of trials, illumination was triggered when the rat left the center poke, and persisted for the first 4 s of the inter-trial interval, resulting in transient silencing of cortical dynamics. In Pvalb-iCre-ChR2 rats, we used a 473 nm laser. Laser pulses (10 ms pulse width) were delivered at 20 Hz.</p><p>The rats generally chose risky on a minority of trials, and by definition, the fraction of those that were rewarded is a smaller subset. Moreover, rewarded trials were more frequent than non-rewarded trials. To overcome these challenges, we collected data from many sessions. The median number of sessions in which rats experienced photoinhibition was 27 (range: 21–70, mean: 37). We did not observe differences in the optogenetic result when comparing the first or second half of all sessions (data not shown).</p></sec><sec id="s4-12"><title>Normal approximation of 95% binomial confidence intervals</title><p>To compute error bars on the choice probabilities for the risky and spatial win-stay biases (<xref ref-type="fig" rid="fig3">Figures 3D,E</xref> and <xref ref-type="fig" rid="fig5">5B,C</xref>), we computed the 95% confidence intervals using the test statistic for the chi-square distribution (<xref ref-type="bibr" rid="bib9">Corder and Foreman, 2014</xref>) as follows:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>95</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></disp-formula>where p<sub>psr</sub> is the probability of choosing safe following a safe reward (‘post-safe reward’) and p<sub>prr</sub> is the probability of choosing safe ‘post-risky reward’, n is the number of observations for each condition (post-safe reward and post-risky reward), and z the z-score for 95% confidence intervals from a normal distribution.</p></sec><sec id="s4-13"><title>Logistic regression model of choice biases</title><p>To evaluate the contribution of different potential choice biases to behavior, we implemented a logistic regression model, in which we parameterized the rats’ probability of choosing right as follows:<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>y</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>y</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where Δ<italic>EV</italic> is the right minus left expected value (reward x probability) on each trial, rs<sub>hyst</sub> captures risky/safe hysteresis (i.e., if the rat just chose safe, the likelihood he will choose safe on the next trial), risky<sub>win—stay</sub> parameterizes increased willingness to choose the gamble conditioned on a risky win, lr<sub>hyst</sub> parameterizes the probability of repeating left/right choices, and lr<sub>bias</sub> parameterizes overall side biases for the left and right port. The only parameter that was significantly changed (and in fact reduced) by photoinhibition during the choice report was the risky<sub>win—stay</sub> parameter (p=0.0063, one-way ANOVA comparing parameters fit to control and opto conditions across rats, Bonferroni correction for multiple comparisons).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Paul Glimcher, Kenway Louie, Mike Long, David Schneider, Ben Scott, Emily Dennis, Mikio Aoi, Matthew Lovett-Barron, Cristina Domnisoru, Alejandro Ramirez and members of the Brody lab for helpful discussions and comments on the manuscript. We thank Alex Williams for feedback on the manuscript and for providing guidance and software for implementing TCA/PARAFAC tensor decomposition analysis. We thank Claudia Farb, Adam Carter, and Mike Hawken for reagents and assistance with histology and confocal imaging. We thank J Teran, K Osorio, L Teachen, and A Sirko for animal training. This work was funded in part by a K99/R00 award from NIMH (MH111926, to CMC).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Writing—review and editing, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con3"><p>Investigation, Visualization</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation, Visualization</p></fn><fn fn-type="con" id="con5"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Supervision, Writing—review and editing, Interpretation of data</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in accordance with the National Institutes of Health standards. Animal use procedures were approved by the Princeton University Institutional Animal Care and Use Committee (protocol #1853).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.49744.013</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-49744-transrepform-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data generated during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrahamyan</surname> <given-names>A</given-names></name><name><surname>Silva</surname> <given-names>LL</given-names></name><name><surname>Dakin</surname> <given-names>SC</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Gardner</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptable history biases in human perceptual decisions</article-title><source>PNAS</source><volume>113</volume><fpage>E3548</fpage><lpage>E3557</lpage><pub-id pub-id-type="doi">10.1073/pnas.1518786113</pub-id><pub-id pub-id-type="pmid">27330086</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaishi</surname> <given-names>R</given-names></name><name><surname>Kolling</surname> <given-names>N</given-names></name><name><surname>Brown</surname> <given-names>JW</given-names></name><name><surname>Rushworth</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural mechanisms of credit assignment in a multicue environment</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>1096</fpage><lpage>1112</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3159-15.2016</pub-id><pub-id pub-id-type="pmid">26818500</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akrami</surname> <given-names>A</given-names></name><name><surname>Kopec</surname> <given-names>CD</given-names></name><name><surname>Diamond</surname> <given-names>ME</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title><source>Nature</source><volume>554</volume><fpage>368</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nature25510</pub-id><pub-id pub-id-type="pmid">29414944</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname> <given-names>D</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Engagement of neural circuits underlying 2D spatial navigation in a rodent virtual reality system</article-title><source>Neuron</source><volume>84</volume><fpage>442</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.042</pub-id><pub-id pub-id-type="pmid">25374363</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanchard</surname> <given-names>TC</given-names></name><name><surname>Wilke</surname> <given-names>A</given-names></name><name><surname>Hayden</surname> <given-names>BY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hot-hand Bias in rhesus monkeys</article-title><source>Journal of Experimental Psychology: Animal Learning and Cognition</source><volume>40</volume><fpage>280</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1037/xan0000033</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname> <given-names>L</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name><name><surname>Dhruv</surname> <given-names>NT</given-names></name><name><surname>Katzner</surname> <given-names>S</given-names></name><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Schölvinck</surname> <given-names>ML</given-names></name><name><surname>Zaharia</surname> <given-names>AD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The detection of visual contrast in the behaving mouse</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11351</fpage><lpage>11361</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6689-10.2011</pub-id><pub-id pub-id-type="pmid">21813694</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conen</surname> <given-names>KE</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Partial adaptation to the value range in the macaque orbitofrontal cortex</article-title><source>The Journal of Neuroscience</source><elocation-id>2279-18</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2279-18.2019</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinople</surname> <given-names>CM</given-names></name><name><surname>Piet</surname> <given-names>AT</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An analysis of decision under risk in rats</article-title><source>Current Biology</source><volume>29</volume><fpage>2066</fpage><lpage>2074</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.05.013</pub-id><pub-id pub-id-type="pmid">31155352</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Corder</surname> <given-names>GW</given-names></name><name><surname>Foreman</surname> <given-names>DI</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Nonparametric Statistics: A Step-by-Step Approach</source><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croson</surname> <given-names>R</given-names></name><name><surname>Sundali</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The gambler’s Fallacy and the Hot Hand: Empirical Data from Casinos</article-title><source>Journal of Risk and Uncertainty</source><volume>30</volume><fpage>195</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1007/s11166-005-1153-2</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalton</surname> <given-names>GL</given-names></name><name><surname>Wang</surname> <given-names>NY</given-names></name><name><surname>Phillips</surname> <given-names>AG</given-names></name><name><surname>Floresco</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multifaceted contributions by different regions of the orbitofrontal and medial prefrontal cortex to probabilistic reversal learning</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>1996</fpage><lpage>2006</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3366-15.2016</pub-id><pub-id pub-id-type="pmid">26865622</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feierstein</surname> <given-names>CE</given-names></name><name><surname>Quirk</surname> <given-names>MC</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Sosulski</surname> <given-names>DL</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Representation of spatial goals in rat orbitofrontal cortex</article-title><source>Neuron</source><volume>51</volume><fpage>495</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.06.032</pub-id><pub-id pub-id-type="pmid">16908414</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallagher</surname> <given-names>M</given-names></name><name><surname>McMahan</surname> <given-names>RW</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Orbitofrontal cortex and representation of incentive value in associative learning</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>6610</fpage><lpage>6614</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-15-06610.1999</pub-id><pub-id pub-id-type="pmid">10414988</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grattan</surname> <given-names>LE</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Absence of spatial tuning in the orbitofrontal cortex</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e112750</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0112750</pub-id><pub-id pub-id-type="pmid">25386837</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groenewegen</surname> <given-names>HJ</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Organization of the afferent connections of the mediodorsal thalamic nucleus in the rat, related to the mediodorsal-prefrontal topography</article-title><source>Neuroscience</source><volume>24</volume><fpage>379</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/0306-4522(88)90339-9</pub-id><pub-id pub-id-type="pmid">2452377</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Kopec</surname> <given-names>CD</given-names></name><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct relationships of parietal and prefrontal cortices to evidence accumulation</article-title><source>Nature</source><volume>520</volume><fpage>220</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature14066</pub-id><pub-id pub-id-type="pmid">25600270</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname> <given-names>BY</given-names></name><name><surname>Nair</surname> <given-names>AC</given-names></name><name><surname>McCoy</surname> <given-names>AN</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Posterior cingulate cortex mediates outcome-contingent allocation of behavior</article-title><source>Neuron</source><volume>60</volume><fpage>19</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.012</pub-id><pub-id pub-id-type="pmid">18940585</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heilbronner</surname> <given-names>SR</given-names></name><name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></name><name><surname>Quirk</surname> <given-names>GJ</given-names></name><name><surname>Groenewegen</surname> <given-names>HJ</given-names></name><name><surname>Haber</surname> <given-names>SN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Circuit-Based corticostriatal homologies between rat and primate</article-title><source>Biological Psychiatry</source><volume>80</volume><fpage>509</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2016.05.012</pub-id><pub-id pub-id-type="pmid">27450032</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hervig</surname> <given-names>ME</given-names></name><name><surname>Fiddian</surname> <given-names>L</given-names></name><name><surname>Piilgaard</surname> <given-names>L</given-names></name><name><surname>Božič</surname> <given-names>T</given-names></name><name><surname>Blanco-Pozo</surname> <given-names>M</given-names></name><name><surname>Knudsen</surname> <given-names>C</given-names></name><name><surname>Olesen</surname> <given-names>SF</given-names></name><name><surname>Alsiö</surname> <given-names>J</given-names></name><name><surname>Robbins</surname> <given-names>TW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociable and paradoxical roles of rat medial and lateral orbitofrontal cortex in visual serial reversal learning</article-title><source>Cerebral Cortex</source><volume>340</volume><elocation-id>bhz144</elocation-id><pub-id pub-id-type="doi">10.1093/cercor/bhz144</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname> <given-names>AOI</given-names></name><name><surname>Pennings</surname> <given-names>JME</given-names></name><name><surname>Post</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Individual investor perceptions and behavior during the financial crisis</article-title><source>SSRN Electronic Journal</source><pub-id pub-id-type="doi">10.2139/ssrn.1571473</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hollingworth</surname> <given-names>HL</given-names></name></person-group><year iso-8601-date="1910">1910</year><article-title>The central tendency of judgment</article-title><source>The Journal of Philosophy, Psychology and Scientific Methods</source><volume>7</volume><elocation-id>461</elocation-id><pub-id pub-id-type="doi">10.2307/2012819</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname> <given-names>LT</given-names></name><name><surname>Malalasekera</surname> <given-names>WMN</given-names></name><name><surname>de Berker</surname> <given-names>AO</given-names></name><name><surname>Miranda</surname> <given-names>B</given-names></name><name><surname>Farmer</surname> <given-names>SF</given-names></name><name><surname>Behrens</surname> <given-names>TEJ</given-names></name><name><surname>Kennerley</surname> <given-names>SW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Triple dissociation of attention and decision computations across prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1471</fpage><lpage>1481</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0239-5</pub-id><pub-id pub-id-type="pmid">30258238</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izquierdo</surname> <given-names>A</given-names></name><name><surname>Suda</surname> <given-names>RK</given-names></name><name><surname>Murray</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Bilateral orbital prefrontal cortex lesions in rhesus monkeys disrupt choices guided by both reward value and reward contingency</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>7540</fpage><lpage>7548</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1921-04.2004</pub-id><pub-id pub-id-type="pmid">15329401</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izquierdo</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional heterogeneity within rat orbitofrontal cortex in reward learning and decision making</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>10529</fpage><lpage>10540</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1678-17.2017</pub-id><pub-id pub-id-type="pmid">29093055</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>JL</given-names></name><name><surname>Esber</surname> <given-names>GR</given-names></name><name><surname>McDannald</surname> <given-names>MA</given-names></name><name><surname>Gruber</surname> <given-names>AJ</given-names></name><name><surname>Hernandez</surname> <given-names>A</given-names></name><name><surname>Mirenzi</surname> <given-names>A</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Orbitofrontal cortex supports behavior and learning using inferred but not cached values</article-title><source>Science</source><volume>338</volume><fpage>953</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1126/science.1227489</pub-id><pub-id pub-id-type="pmid">23162000</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kagel</surname> <given-names>JH</given-names></name><name><surname>Battalio</surname> <given-names>RC</given-names></name><name><surname>Green</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Economic Choice Theory: An Experimental Analysis of Animal Behavior</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511664854</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennerley</surname> <given-names>SW</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Wallis</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Double dissociation of value computations in orbitofrontal and anterior cingulate neurons</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1581</fpage><lpage>1589</lpage><pub-id pub-id-type="doi">10.1038/nn.2961</pub-id><pub-id pub-id-type="pmid">22037498</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Zariwala</surname> <given-names>HA</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><volume>455</volume><fpage>227</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature07200</pub-id><pub-id pub-id-type="pmid">18690210</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kuwabara</surname> <given-names>M</given-names></name><name><surname>Holy</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural mechanisms of economic choices in mice</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/682740</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lak</surname> <given-names>A</given-names></name><name><surname>Costa</surname> <given-names>GM</given-names></name><name><surname>Romberg</surname> <given-names>E</given-names></name><name><surname>Koulakov</surname> <given-names>AA</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name><name><surname>Kepecs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal cortex is required for optimal waiting based on decision confidence</article-title><source>Neuron</source><volume>84</volume><fpage>190</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.039</pub-id><pub-id pub-id-type="pmid">25242219</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDannald</surname> <given-names>MA</given-names></name><name><surname>Lucantonio</surname> <given-names>F</given-names></name><name><surname>Burke</surname> <given-names>KA</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ventral striatum and orbitofrontal cortex are both required for model-based, but not model-free, reinforcement learning</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>2700</fpage><lpage>2705</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5499-10.2011</pub-id><pub-id pub-id-type="pmid">21325538</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>KJ</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dorsal Hippocampus contributes to model-based planning</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1269</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1038/nn.4613</pub-id><pub-id pub-id-type="pmid">28758995</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>KJ</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Value representations in orbitofrontal cortex drive learning, but not choice</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/245720</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>JB</given-names></name><name><surname>Sanjurjo</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Surprised by the gambler's and Hot Hand Fallacies? A Truth in the Law of Small Numbers</article-title><source>SSRN Electronic Journal</source><pub-id pub-id-type="doi">10.2139/ssrn.2627354</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moorman</surname> <given-names>DE</given-names></name><name><surname>Aston-Jones</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal cortical neurons encode expectation-driven initiation of reward-seeking</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>10234</fpage><lpage>10246</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3216-13.2014</pub-id><pub-id pub-id-type="pmid">25080585</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname> <given-names>SE</given-names></name><name><surname>Saez</surname> <given-names>A</given-names></name><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Salzman</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Different time courses for learning-related changes in amygdala and orbitofrontal cortex</article-title><source>Neuron</source><volume>71</volume><fpage>1127</fpage><lpage>1140</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.016</pub-id><pub-id pub-id-type="pmid">21943608</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>MJM</given-names></name><name><surname>Deutch</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Organization of afferents to the orbitofrontal cortex in the rat</article-title><source>Journal of Comparative Neurology</source><volume>526</volume><fpage>1498</fpage><lpage>1526</lpage><pub-id pub-id-type="doi">10.1002/cne.24424</pub-id><pub-id pub-id-type="pmid">29524205</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namboodiri</surname> <given-names>VMK</given-names></name><name><surname>Otis</surname> <given-names>JM</given-names></name><name><surname>van Heeswijk</surname> <given-names>K</given-names></name><name><surname>Voets</surname> <given-names>ES</given-names></name><name><surname>Alghorazi</surname> <given-names>RA</given-names></name><name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-cell activity tracking reveals that orbitofrontal neurons acquire and maintain a long-term memory to guide behavioral adaptation</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1110</fpage><lpage>1121</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0408-1</pub-id><pub-id pub-id-type="pmid">31160741</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neiman</surname> <given-names>T</given-names></name><name><surname>Loewenstein</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reinforcement learning in professional basketball players</article-title><source>Nature Communications</source><volume>2</volume><elocation-id>569</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1580</pub-id><pub-id pub-id-type="pmid">22146388</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nogueira</surname> <given-names>R</given-names></name><name><surname>Abolafia</surname> <given-names>JM</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Balaguer-Ballester</surname> <given-names>E</given-names></name><name><surname>Sanchez-Vives</surname> <given-names>MV</given-names></name><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Lateral orbitofrontal cortex anticipates choices and integrates prior with current information</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>14823</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms14823</pub-id><pub-id pub-id-type="pmid">28337990</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Range-adapting representation of economic value in the orbitofrontal cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>14004</fpage><lpage>14014</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3751-09.2009</pub-id><pub-id pub-id-type="pmid">19890010</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neurobiology of economic choice: a good-based model</article-title><source>Annual Review of Neuroscience</source><volume>34</volume><fpage>333</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-061010-113648</pub-id><pub-id pub-id-type="pmid">21456961</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neuronal origins of choice variability in economic decisions</article-title><source>Neuron</source><volume>80</volume><fpage>1322</fpage><lpage>1336</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.013</pub-id><pub-id pub-id-type="pmid">24314733</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The orbitofrontal cortex and the computation of subjective value: consolidated concepts and new perspectives</article-title><source>Annals of the New York Academy of Sciences</source><volume>1239</volume><fpage>130</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2011.06262.x</pub-id><pub-id pub-id-type="pmid">22145882</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickens</surname> <given-names>CL</given-names></name><name><surname>Saddoris</surname> <given-names>MP</given-names></name><name><surname>Setlow</surname> <given-names>B</given-names></name><name><surname>Gallagher</surname> <given-names>M</given-names></name><name><surname>Holland</surname> <given-names>PC</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Different roles for orbitofrontal cortex and basolateral amygdala in a reinforcer devaluation task</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>11078</fpage><lpage>11084</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-35-11078.2003</pub-id><pub-id pub-id-type="pmid">14657165</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname> <given-names>JP</given-names></name><name><surname>Price</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The organization of the thalamocortical connections of the mediodorsal thalamic nucleus in the rat, related to the ventral forebrain-prefrontal cortex topography</article-title><source>The Journal of Comparative Neurology</source><volume>323</volume><fpage>167</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1002/cne.903230204</pub-id><pub-id pub-id-type="pmid">1401255</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roesch</surname> <given-names>MR</given-names></name><name><surname>Taylor</surname> <given-names>AR</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Encoding of time-discounted rewards in orbitofrontal cortex is independent of value representation</article-title><source>Neuron</source><volume>51</volume><fpage>509</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.06.027</pub-id><pub-id pub-id-type="pmid">16908415</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudebeck</surname> <given-names>PH</given-names></name><name><surname>Murray</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The orbitofrontal oracle: cortical mechanisms for the prediction and evaluation of specific behavioral outcomes</article-title><source>Neuron</source><volume>84</volume><fpage>1143</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.049</pub-id><pub-id pub-id-type="pmid">25521376</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname> <given-names>MF</given-names></name><name><surname>Noonan</surname> <given-names>MP</given-names></name><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Frontal cortex and reward-guided learning and decision-making</article-title><source>Neuron</source><volume>70</volume><fpage>1054</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.014</pub-id><pub-id pub-id-type="pmid">21689594</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rustichini</surname> <given-names>A</given-names></name><name><surname>Conen</surname> <given-names>KE</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Optimal coding and neuronal adaptation in economic decisions</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>1208</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01373-y</pub-id><pub-id pub-id-type="pmid">29084949</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saez</surname> <given-names>RA</given-names></name><name><surname>Saez</surname> <given-names>A</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Salzman</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct roles for the amygdala and orbitofrontal cortex in representing the relative amount of expected reward</article-title><source>Neuron</source><volume>95</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.012</pub-id><pub-id pub-id-type="pmid">28683271</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Chiba</surname> <given-names>AA</given-names></name><name><surname>Gallagher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Orbitofrontal cortex and basolateral amygdala encode expected outcomes during learning</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>155</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1038/407</pub-id><pub-id pub-id-type="pmid">10195132</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Chiba</surname> <given-names>AA</given-names></name><name><surname>Gallagher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural encoding in orbitofrontal cortex and basolateral amygdala during olfactory discrimination learning</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>1876</fpage><lpage>1884</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-05-01876.1999</pub-id><pub-id pub-id-type="pmid">10024371</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Setlow</surname> <given-names>B</given-names></name><name><surname>Saddoris</surname> <given-names>MP</given-names></name><name><surname>Gallagher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Encoding predicted outcome and acquired value in orbitofrontal cortex during cue sampling depends upon input from basolateral amygdala</article-title><source>Neuron</source><volume>39</volume><fpage>855</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00474-4</pub-id><pub-id pub-id-type="pmid">12948451</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname> <given-names>BB</given-names></name><name><surname>Constantinople</surname> <given-names>CM</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sources of noise during accumulation of evidence in unrestrained and voluntarily head-restrained rats</article-title><source>eLife</source><volume>4</volume><elocation-id>e11308</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11308</pub-id><pub-id pub-id-type="pmid">26673896</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stalnaker</surname> <given-names>TA</given-names></name><name><surname>Cooch</surname> <given-names>NK</given-names></name><name><surname>McDannald</surname> <given-names>MA</given-names></name><name><surname>Liu</surname> <given-names>TL</given-names></name><name><surname>Wied</surname> <given-names>H</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal neurons infer the value and identity of predicted outcomes</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>3926</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms4926</pub-id><pub-id pub-id-type="pmid">24894805</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stalnaker</surname> <given-names>TA</given-names></name><name><surname>Cooch</surname> <given-names>NK</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>What the orbitofrontal cortex does not do</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>620</fpage><lpage>627</lpage><pub-id pub-id-type="doi">10.1038/nn.3982</pub-id><pub-id pub-id-type="pmid">25919962</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steiner</surname> <given-names>AP</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The road not taken: neural correlates of decision making in orbitofrontal cortex</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>131</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00131</pub-id><pub-id pub-id-type="pmid">22973189</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steiner</surname> <given-names>AP</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Behavioral and neurophysiological correlates of regret in rat decision-making on a neuroeconomic task</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>995</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1038/nn.3740</pub-id><pub-id pub-id-type="pmid">24908102</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolyarova</surname> <given-names>A</given-names></name><name><surname>Izquierdo</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Complementary contributions of basolateral amygdala and orbitofrontal cortex to value learning under uncertainty</article-title><source>eLife</source><volume>6</volume><elocation-id>e27483</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27483</pub-id><pub-id pub-id-type="pmid">28682238</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolias</surname> <given-names>AS</given-names></name><name><surname>Ecker</surname> <given-names>AS</given-names></name><name><surname>Siapas</surname> <given-names>AG</given-names></name><name><surname>Hoenselaar</surname> <given-names>A</given-names></name><name><surname>Keliris</surname> <given-names>GA</given-names></name><name><surname>Logothetis</surname> <given-names>NK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Recording chronically from the same neurons in awake, behaving primates</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>3780</fpage><lpage>3790</lpage><pub-id pub-id-type="doi">10.1152/jn.00260.2007</pub-id><pub-id pub-id-type="pmid">17942615</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visscher</surname> <given-names>KM</given-names></name><name><surname>Kahana</surname> <given-names>MJ</given-names></name><name><surname>Sekuler</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Trial-to-trial carryover in auditory short-term memory</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>35</volume><fpage>46</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1037/a0013412</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallis</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Orbitofrontal cortex and its contribution to decision-making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>31</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.30.051606.094334</pub-id><pub-id pub-id-type="pmid">17417936</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilke</surname> <given-names>A</given-names></name><name><surname>Barrett</surname> <given-names>HC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The hot hand phenomenon as a cognitive adaptation to clumped resources</article-title><source>Evolution and Human Behavior</source><volume>30</volume><fpage>161</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/j.evolhumbehav.2008.11.004</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>AH</given-names></name><name><surname>Kim</surname> <given-names>TH</given-names></name><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Vyas</surname> <given-names>S</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Schnitzer</surname> <given-names>M</given-names></name><name><surname>Kolda</surname> <given-names>TG</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Unsupervised discovery of demixed, Low-Dimensional neural dynamics across multiple timescales through tensor component analysis</article-title><source>Neuron</source><volume>98</volume><fpage>1099</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.015</pub-id><pub-id pub-id-type="pmid">29887338</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Takahashi</surname> <given-names>YK</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal cortex as a cognitive map of task space</article-title><source>Neuron</source><volume>81</volume><fpage>267</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.005</pub-id><pub-id pub-id-type="pmid">24462094</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sequential effects: superstition or rational behavior?</article-title><source>Advances in Neural Information Processing Systems</source><volume>21</volume><fpage>1873</fpage><lpage>1880</lpage><pub-id pub-id-type="pmid">26412953</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmermann</surname> <given-names>J</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name><name><surname>Louie</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiple timescales of normalized value coding underlie adaptive choice behavior</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3206</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05507-8</pub-id><pub-id pub-id-type="pmid">30097577</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.49744.015</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Salinas</surname><given-names>Emilio</given-names> </name><role>Reviewer</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Izquierdo</surname><given-names>Alicia</given-names> </name><role>Reviewer</role><aff><institution>University of California, Los Angeles</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Orbitofrontal cortex promotes trial-by-trial learning of risky, but not spatial, biases&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, including Emilio Salinas as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Alicia Izquierdo (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Constantinople et al. study sequential biases, or the influence of past experience, on decision making. They point out a shortcoming in many similar investigations: that choice options are fixed in space and therefore make it impossible to study reward history effects independent of spatial information. Here, rats learn to combine reward probability with reward amount in a novel, two-alternative forced-choice task, and exhibit two notable effects: (1) the classic &quot;win-stay&quot; and &quot;lose-switch&quot; biases in favor of previously rewarded or against previously unrewarded locations, and (2) a preference toward the risky (low-probability) option following a previously rewarded, risky choice. In other words, when the rat gambles and wins, it is more likely to gamble again. Electrophysiology and optogenetics reveal that OFC activity encodes the history of previous rewards, the preference for risk, and the left/right choices. And somewhat surprisingly, when OFC is inactivated during the choice period of trial j, the preference for risk in trial j+1 essentially disappears, whereas the spatial bias (win-stay/lose-switch) is unchanged. This is an interesting study that provides nuanced new information about OFC contributions to decision making.</p><p>Essential revisions:</p><p>1) Revise some of the Introduction to include a narrower set of studies as the basis for these experiments. For example, currently there is cited evidence on mOFC (Bradfield et al., Neuron, 2015) in unobservable outcome encoding, yet there is additional (and growing) evidence for functional dissociations of rat mOFC from lOFC (Izquierdo, 2017) as is presently studied here; see most recent relevant example of this by Hervig et al., 2019. Do authors attribute this specific function to lOFC or is it also possibly mediated by other subregions of OFC? I also found the conceptual connections of the present work on the influence of reward history/statistics with the economic decision making literature in the Introduction rather loose. What about this task makes it an economic decision making task?</p><p>2) During the cue period there was multimodal signaling of magnitude (click rate, auditory) and probability (light flashes, visual). Authors may wish to consider how these complex, compound stimuli experiences may change the involvement of OFC over the entire session and across sessions, particularly given that these are longitudinal experiments. For example, are these different reward attributes represented in an orthogonal way in OFC, and do they change over time (from early vs. late learning)? There is evidence of this in nonhuman primate PFC (Hunt et al., 2018) and the contrast could be interesting. Relatedly, authors could discuss if/how other regions (e.g. ACC, M2) in rat may multiplex these reward attributes and contribute to choice and action selection. Or is the authors' stance that OFC is doing this? Please clarify.</p><p>Figures 3JD,E, 4J and L5B,C3) The viral expression photomicrograph looks well-focused mostly on lateral orbital but I also see expression in ventral orbital, and perhaps even in M2. It may be more thorough to show a multi-coronal section reconstruction at different AP levels of this viral spread and correlate positioning to behavioral effects.</p><p>4) The bias for risk is quite small; if I understood correctly, it amounts to an average change in choice probability of 0.02, which is about 10 times smaller than the average lose-switch bias (Figure 1F, H). This is consistent with the much weaker coding of risk bias versus spatial bias (Figure 4B, F). This is fine, it is what it is, but the authors should mention this difference a bit more explicitly. Initially, it is surprising that the inactivation removes the risk bias but leaves intact the spatial bias, given how important the latter seems. The explanation offered in the Discussion (&quot;We found that perturbation effects…&quot;) is perfectly reasonable, but the size difference could be pointed out to emphasize that there is still a bit of a mystery to be solved there, i.e., why is the spatial bias so strongly represented in OFC, if its primary function is not to enforce it?</p><p>Related to this, the units of the risky bias change. In Figure 1F, G, it is just the actual change in probability, whereas later on (Figures 3E, 5C) it is expressed as a percentage, but a percentage of what? Wouldn't it be clearer if the numbers indicated the raw difference in probability, as in Figure 1F, G, even if they were small? By the way, the caption of Figure 3E currently describes the units of the risk bias as a &quot;difference in probability,&quot; not as a percentage.</p><p>5) If I understand correctly, the trial factor in the TCA decomposition represents the gain of each trial. Doesn't this factor, and thus the result in Figure 2G, depend on the number of recorded neurons? It would be useful to say something about this in the Materials and methods, because the limited number of recorded neurons might underestimate the correlation between trial factor and reward history. Also, the significance of the correlations might depend on the number of recorded neurons, no?</p><p>6) Results subsection “Disrupting lOFC during the choice report eliminated the risky win-stay bias”, first paragraph: &quot;and the majority of those units were not selective for left/right choice.&quot; This statement seems incorrect. Figure 4—figure supplement 1 shows that 54 neurons were not selective for side, whereas 47+27=74 <italic>were</italic> selective.</p><p>7) Another point concerns the OFC and timing. There are now at least 2 studies showing that rodent OFC may be important in reinforcement timing (Bakhurin et al., J Neurosci, 2017; Stolyarova and Izquierdo, 2017). Specifically, the latter reported evidence that OFC lesions reduce the animal's ability to represent a detailed delay distribution of reward delivery times, acquired over longitudinal experience (as in the present study). Perhaps I missed this, but have authors considered if/how the time window of the cue period impacts strategy/performance during the reporting period? It would be good to know that there are no differences in choice reporting that can be attributed to a failure in representing short (2.6 s) vs. long (3.4 s) cue periods. Even if this were the case, it could help address the possibility that OFC is recruited to representing the variance of a temporal quantity. Relatedly, I'm not clear on why 2.6-3.35 sec range was chosen, and 4 sec range for photoinhibition imposed, can authors provide a rationale or clarify?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.49744.016</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Revise some of the Introduction to include a narrower set of studies as the basis for these experiments. For example, currently there is cited evidence on mOFC (Bradfield et al., Neuron, 2015) in unobservable outcome encoding, yet there is additional (and growing) evidence for functional dissociations of rat mOFC from lOFC (Izquierdo, 2017) as is presently studied here; see most recent relevant example of this by Hervig et al., 2019. Do authors attribute this specific function to lOFC or is it also possibly mediated by other subregions of OFC? I also found the conceptual connections of the present work on the influence of reward history/statistics with the economic decision making literature in the Introduction rather loose. What about this task makes it an economic decision making task?</p></disp-quote><p>We thank the reviewer for this comment. We have rewritten the Introduction, including a discussion of the different subdivisions of OFC. We have removed the Bradfield reference, and cited the papers the reviewer suggested. We have also removed the section of the Introduction that discussed economic decision-making w.r.t. OFC. We have cut and pasted some of the new text from the revised Introduction below:</p><p>“​The OFC is not a monolithic structure: in rats, subdivisions (e.g., ventral orbital area, lateral orbital area, agranular insula) are characterized by distinct efferent and afferent projections and, presumably as a consequence, there is growing evidence that these subdivisions make distinct functional contributions to behavior ​(Dalton et al., 2016; Groeneweggen, 1988; Hervig et al., 2019; Izquierdo, 2017; Murphy and Deutch, 2018; Ray and Price, 1992). Based on connectivity, the rat lOFC (including lateral orbital and agranular insular areas) is thought to be homologous to the central-lateral OFC of monkeys (Heilbronner et al., 2016; Izquierdo, 2017; Stalnaker et al., 2015), although differences have been observed in these areas across species, for example in neural dynamics following reversal learning (Morrison et al., 2011; Schoenbaum et al., 1999).”</p><disp-quote content-type="editor-comment"><p>2) During the cue period there was multimodal signaling of magnitude (click rate, auditory) and probability (light flashes, visual). Authors may wish to consider how these complex, compound stimuli experiences may change the involvement of OFC over the entire session and across sessions, particularly given that these are longitudinal experiments. For example, are these different reward attributes represented in an orthogonal way in OFC, and do they change over time (from early vs. late learning)? There is evidence of this in nonhuman primate PFC (Hunt et al., 2018) and the contrast could be interesting. Relatedly, authors could discuss if/how other regions (e.g. ACC, M2) in rat may multiplex these reward attributes and contribute to choice and action selection. Or is the authors' stance that OFC is doing this? Please clarify.</p></disp-quote><p>We thank the reviewer for raising this thoughtful question. We are particularly interested in whether the different reward attributes in this task are represented in an orthogonal way in OFC. Due to the large choice set (each panel in Figure 1E corresponds to a unique trial type) and limited data, however, addressing this question with our dataset is non-trivial. We are currently developing more sophisticated analytical tools to reveal how neurons in OFC represent these different reward attributes, but this is an ongoing research effort that we view as being outside the scope of the present manuscript. We hope to have a thorough answer for the reviewer in a future manuscript.</p><p>We have modified the Discussion to cite recent evidence suggesting that the OFC may be important for learning of action values, but does not participate in action selection or choice per se. At the reviewer’s suggestion we now reference Hunt et al. (2018). We have included the following text in the revised Discussion:</p><p><bold>“</bold>​This study used sensory stimuli (visual flashes, auditory clicks) to convey information about reward options to the animal. […] An intriguing direction for future research would be to record neural activity in OFC as animals learn the associations between sensory stimuli and reward attributes, to characterize the evolution of dynamics in OFC from early to late in training.”</p><disp-quote content-type="editor-comment"><p>3) The viral expression photomicrograph looks well-focused mostly on lateral orbital but I also see expression in ventral orbital, and perhaps even in M2. It may be more thorough to show a multi-coronal section reconstruction at different AP levels of this viral spread and correlate positioning to behavioral effects.</p></disp-quote><p>We thank the reviewer for this comment. We intentionally made large virus injections, because we reasoned that the spread of light from the fiber tip (which our control experiments have shown to be approximately 1mm) would determine and limit the inactivated area. The photomicrograph shown in the main and supplementary figure was selected because it was possible to see the track of the fiber optic in this image (Figure 3—figure supplement 1E). Unfortunately, this is not representative: because we used relatively small optic fibers (50​μ​m core, compared to 200​μ​m or 400​μ​m core used by most labs), in most cases, the fibers did not produce visible damage in the tissue.</p><p>While there may have been some viral spread to M2, the optogenetic effect we observed occurred on trials <italic>subsequent</italic>​ to optogenetic perturbation. Moreover, in 11/13 rats, we did not observe any significant change in choice latencies during photoinhibition (i.e., the time from leaving the center poke to poking in the side port, which occurred when the laser was on). Together, these data suggest that the behavioral effect we observed was not due to off-target inhibition of M2. This reasoning is included in the Results section of the manuscript.</p><p>We have now included an additional photomicrograph (Figure 2—figure supplement 1D) showing the location of electrolytic lesions made by tetrodes in one of our rats used for electrophysiology. We hope this provides additional information and confidence in our ability to target LO/AI.</p><disp-quote content-type="editor-comment"><p>4) The bias for risk is quite small; if I understood correctly, it amounts to an average change in choice probability of 0.02, which is about 10 times smaller than the average lose-switch bias (Figure 1F, H). This is consistent with the much weaker coding of risk bias versus spatial bias (Figure 4B, F). This is fine, it is what it is, but the authors should mention this difference a bit more explicitly. Initially, it is surprising that the inactivation removes the risk bias but leaves intact the spatial bias, given how important the latter seems. The explanation offered in the Discussion (&quot;We found that perturbation effects…&quot;) is perfectly reasonable, but the size difference could be pointed out to emphasize that there is still a bit of a mystery to be solved there, i.e., why is the spatial bias so strongly represented in OFC, if its primary function is not to enforce it?</p></disp-quote><p>We thank the reviewer for raising this issue. We have attempted to more explicitly address the unequal magnitude of the spatial and risky biases, by including the following text in the Results section:</p><p>“It is notable, however, that the magnitude of rats’ spatial win-stay/lose-switch biases was much larger than the magnitude of their risky win-stay biases (Figure 1F, H).”</p><p>And in the Discussion paragraph:</p><p>“This raises an intriguing question: why are these variables so strongly represented in lOFC if the animal appears to not be using those representations to guide behavior?”</p><disp-quote content-type="editor-comment"><p>Related to this, the units of the risky bias change. In Figure 1F, G, it is just the actual change in probability, whereas later on (Figures 3E, 5C) it is expressed as a percentage, but a percentage of what? Wouldn't it be clearer if the numbers indicated the raw difference in probability, as in Figure 1F, G, even if they were small? By the way, the caption of Figure 3E currently describes the units of the risk bias as a &quot;difference in probability,&quot; not as a percentage.</p></disp-quote><p>We thank the reviewer for this comment, we have changed the figures so that they are all in units of Δprobability.</p><disp-quote content-type="editor-comment"><p>5) If I understand correctly, the trial factor in the TCA decomposition represents the gain of each trial. Doesn't this factor, and thus the result in Figure 2G, depend on the number of recorded neurons? It would be useful to say something about this in the Materials and methods, because the limited number of recorded neurons might underestimate the correlation between trial factor and reward history. Also, the significance of the correlations might depend on the number of recorded neurons, no?</p></disp-quote><p>We thank the reviewer for raising important concerns about our methods. The reviewer is correct that the trial factor in the TCA decomposition is a gain of each trial. This trial factor and the temporal factor depend on the number of recorded neurons only in the sense that if neurons exhibit heterogeneous responses during behavior, recording more neurons could sample different dynamics. Our estimate of the correlation between trial factor and reward history is the noisiest for sessions with a small number of neurons, as single neuron dynamics have a bigger effect. However, we find no systematic bias in our estimate of the correlation with reward history and the number of neurons in each session (Figure 2—figure supplement 2I). We have added the following text to the manuscript:</p><p>“​We note that there was no systematic relationship between the correlation of rats’ reward history and the trial factors, and the number of simultaneously recorded neurons in each session (Figure 2—figure supplement 2H, I).”</p><disp-quote content-type="editor-comment"><p>6) Results subsection “Disrupting lOFC during the choice report eliminated the risky win-stay bias”, first paragraph: &quot;and the majority of those units were not selective for left/right choice.&quot; This statement seems incorrect. Figure 4—figure supplement 1 shows that 54 neurons were not selective for side, whereas 47+27=74 were selective.</p></disp-quote><p>We thank the reviewer for catching this incorrect statement. We have removed that text from the manuscript.</p><disp-quote content-type="editor-comment"><p>7) Another point concerns the OFC and timing. There are now at least 2 studies showing that rodent OFC may be important in reinforcement timing (Bakhurin et al., J Neurosci, 2017; Stolyarova and Izquierdo, 2017). Specifically, the latter reported evidence that OFC lesions reduce the animal's ability to represent a detailed delay distribution of reward delivery times, acquired over longitudinal experience (as in the present study). Perhaps I missed this, but have authors considered if/how the time window of the cue period impacts strategy/performance during the reporting period? It would be good to know that there are no differences in choice reporting that can be attributed to a failure in representing short (2.6 s) vs. long (3.4 s) cue periods. Even if this were the case, it could help address the possibility that OFC is recruited to representing the variance of a temporal quantity. Relatedly, I'm not clear on why 2.6-3.35 sec range was chosen, and 4 sec range for photoinhibition imposed, can authors provide a rationale or clarify?</p></disp-quote><p>We thank the reviewer for raising this important issue. Trial durations reflect aspects of the sensory stimuli we used. Specifically, on each trial, one port offered a certain reward, which in most versions of the task corresponded to presentation of 10 flashes from that side. Flashes occurred in 250ms bins, to avoid a phenomenon known as “flicker fusion,” or the perception of rapid intermittent flashes as continuous illumination. In rats, flicker fusion is thought to occur when subsequent flashes are presented within 50ms or less, based on evoked-related potential measurements from the scalp. 250ms was chosen because it is safely outside that window; we used similar inter-flash intervals in our previous studies of perceptual decision-making (Scott et al., 2015). 250ms windows x 10 flashes imposes a minimum trial duration of 2.5 seconds. There was also a pre-flash and post-flash delay period, both of which were variable. We introduced this variability so that the various task events, including onset of the presentation of the flashes and clicks, were not perfectly correlated and could be independently related to behavior/neural responses. Requiring rats to maintain fixation by keeping their nose in a central port becomes challenging with longer durations; therefore, we did not extend the range to be much greater than the duration required to account for 10 flashes and these two delay periods.</p><p>We happened to perform some of the electrophysiological recordings first, and noticed that most of the encoding of left/right choice and reward in the inter-trial interval had ceased by 4 seconds after rats left the center port (Figure 4F). This observation motivated our choice of photoinhibiting for 4 seconds, triggered when rats left the center port.</p><p>To address the reviewer’s comment, we separately analyzed our optogenetic data for trials with short (&lt;3 seconds) and longer (&gt;3 seconds) durations. We found that photoinhibition during the choice report eliminated the risky win-stay bias regardless of trial duration (p=0.07, following short trials, p = 0.10 for long trials, one-way ANOVA comparing safe choices following safe or risky rewards). We note that, although the trial durations were variable, they spanned a narrow range compared to the reward delay durations (mean of 5-20 seconds) in Stolyarova and Izquierdo (2017). Bakhurin et al. (2017) used shorter reward delays (2.5 s), but in a Pavolivian conditioning paradigm, in which a conditioned stimulus predicted a reward 2.5 s later. In our task, the rats tended to choose the side offering the greater expected value, and so were using the sensory stimuli on each trial to inform that decision. Therefore, when they entered the center poke, they presumably were accumulating sensory evidence to obtain information about reward options on each side; not merely estimating elapsed time as in Bakhurin et al. Finally, once the rat was free to leave the center poke, there was no variability in reward timing imposed by the experimenter: as soon as the rat entered the side poke, he received a water reward 100ms later (or an immediate auditory cue that indicated reward omission).</p><p>Therefore, we feel that our task design and existing dataset are not well-suited to address the potential role for the OFC in representing the variance of a temporal quantity (although we do not view our data as being inconsistent with this hypothesis). This is an interesting topic for future research on the OFC, especially given the intriguing results in Bakhurin et al. (2017) and Stolyarova and Izquierdo (2017).</p></body></sub-article></article>