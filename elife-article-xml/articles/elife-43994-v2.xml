<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">43994</article-id><article-id pub-id-type="doi">10.7554/eLife.43994</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Decoupling sensory from decisional choice biases in perceptual decision making</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-61625"><name><surname>Linares</surname><given-names>Daniel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7473-4184</contrib-id><email>danilinares@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-113097"><name><surname>Aguilar-Lleyda</surname><given-names>David</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6963-4069</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-62071"><name><surname>López-Moliner</surname><given-names>Joan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5040-8889</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Institut d’Investigacions Biomediques August Pi i Sunyer (IDIBAPS)</institution><addr-line><named-content content-type="city">Barcelona</named-content></addr-line><country>Spain</country></aff><aff id="aff2"><label>2</label><institution>Centre d’Économie de la Sorbonne (CNRS &amp; Université Paris 1 Panthéon-Sorbonne)</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">VISCA Group, Department of Cognition, Development and Psychology of Education, Institut de Neurociències</institution><institution>Universitat de Barcelona</institution><addr-line><named-content content-type="city">Barcelona</named-content></addr-line><country>Spain</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="editor"><name><surname>Stüttgen</surname><given-names>Maik C</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Mainz</institution><country>Germany</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>03</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e43994</elocation-id><history><date date-type="received" iso-8601-date="2018-11-28"><day>28</day><month>11</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-03-23"><day>23</day><month>03</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Linares et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Linares et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-43994-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.43994.001</object-id><p>The contribution of sensory and decisional processes to perceptual decision making is still unclear, even in simple perceptual tasks. When decision makers need to select an action from a set of balanced alternatives, any tendency to choose one alternative more often—choice bias—is consistent with a bias in the sensory evidence, but also with a preference to select that alternative independently of the sensory evidence. To decouple sensory from decisional biases, here we asked humans to perform a simple perceptual discrimination task with two symmetric alternatives under two different task instructions. The instructions varied the response mapping between perception and the category of the alternatives. We found that from 32 participants, 30 exhibited sensory biases and 15 decisional biases. The decisional biases were consistent with a criterion change in a simple signal detection theory model. Perceptual decision making, thus, even in simple scenarios, is affected by sensory and decisional choice biases.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.43994.002</object-id><title>eLife digest</title><p>Imagine that every day, you split a chocolate bar into two and offer one half to your friend. Even though you take care to divide the bar into equal pieces, your friend nearly always chooses the left half. Why is that? One possibility is that sensory bias in her visual system makes her perceive the left half of the bar to be larger than the right. But it is also possible that she does not see any difference between the two halves. Instead she simply decides to pick the left half because she prefers doing so.</p><p>The above example illustrates a key problem in studying perception. When asked to make a decision where there is no obviously correct answer such as deciding whether a painting is hanging perfectly straight people typically respond one way more often than the other. But does this response bias reflect biased perception or biased decision making?</p><p>Linares et al. have designed an experiment to tease apart these alternatives. Healthy volunteers had to decide whether gratings were tilted slightly upward or slightly downward. Almost all volunteers showed biases in their choice behavior in one of the two directions. To decouple sensory biases from ‘decisional’ biases, the volunteers had to press a particular key to select ‘upward’ on some trials, but ‘downward’ on others. This would not affect responding if the volunteers showed a decisional bias to press a key. But it would affect responding if the volunteers showed a sensory bias. The results revealed that both sensory and decisional biases influenced the volunteers’ choice behavior. However, sensory biases were more common.</p><p>People diagnosed with psychiatric disorders like schizophrenia often respond differently on perceptual tasks compared to healthy volunteers. Future studies should investigate whether this difference results from altered perception or altered decision making. This information could help narrow down the neural circuits affected by these disorders.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>perception</kwd><kwd>discrimination</kwd><kwd>choice biases</kwd><kwd>signal detection theory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010552</institution-id><institution>Departament de Salut, Generalitat de Catalunya</institution></institution-wrap></funding-source><award-id>SLT002/16/00338</award-id><principal-award-recipient><name><surname>Linares</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>Catalan Government</institution></institution-wrap></funding-source><award-id>2017SGR-48</award-id><principal-award-recipient><name><surname>López-Moliner</surname><given-names>Joan</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008062</institution-id><institution>Fundación Alicia Koplowitz</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Linares</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>Project AEI/Feder, UE</institution></institution-wrap></funding-source><award-id>PSI2017-83493R</award-id><principal-award-recipient><name><surname>López-Moliner</surname><given-names>Joan</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010552</institution-id><institution>Departament de Salut, Generalitat de Catalunya</institution></institution-wrap></funding-source><award-id>SLT006/17/00362</award-id><principal-award-recipient><name><surname>Linares</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Perceptual decision making, even in simple scenarios, is affected by sensory and decisional choice biases.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>You ask a friend about the tilt of a canvas that is perfectly horizontal and she says that the top right corner is <italic>up</italic>. What causes her inaccuracy? One possibility is that her sensory representation is biased and she perceives the canvas tilted. Another possibility, however, is that under uncertainty about the orientation of the canvas, she prefers to choose <italic>up</italic> over <italic>down</italic>. This situation exemplifies a major problem in the study of perception: perceptual decisions not only depend on the sensory evidence, but also on decisional components (<xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>).</p><p>When a decision maker needs to select an action from a set of alternatives, the tendency to choose one alternative over the others is known as choice bias (<xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>). Choice biases occur in perceptual tasks even in simple scenarios like the one described above, in which the stimuli carry similar levels of signal relative to a neutral point (<xref ref-type="bibr" rid="bib31">Newsome and Paré, 1988</xref>; <xref ref-type="bibr" rid="bib26">Mareschal and Clifford, 2012</xref>; <xref ref-type="bibr" rid="bib17">Jazayeri and Movshon, 2007</xref>; <xref ref-type="bibr" rid="bib28">Milner et al., 1992</xref>; <xref ref-type="bibr" rid="bib44">Tadin et al., 2003</xref>).</p><p>Choice biases are extensively studied in relation to how current decisions are influenced by previous decisions, what is known as <italic>choice history biases</italic> (<xref ref-type="bibr" rid="bib1">Abrahamyan et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Akaishi et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Fründ et al., 2014</xref>; <xref ref-type="bibr" rid="bib45">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib9">Fischer and Whitney, 2014</xref>; <xref ref-type="bibr" rid="bib4">Braun et al., 2018</xref>; <xref ref-type="bibr" rid="bib42">St John-Saaltink et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Fritsche et al., 2017</xref>; <xref ref-type="bibr" rid="bib16">Hermoso-Mendizabal et al., 2019</xref>). Depending on the perceptual scenario, people tend to repeat their previous choice (<xref ref-type="bibr" rid="bib2">Akaishi et al., 2014</xref>; <xref ref-type="bibr" rid="bib4">Braun et al., 2018</xref>), alternate between choices (<xref ref-type="bibr" rid="bib10">Fritsche et al., 2017</xref>) or idiosyncratically repeat or alternate (<xref ref-type="bibr" rid="bib45">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib1">Abrahamyan et al., 2016</xref>). Whether choice history biases reflect a bias in the sensory evidence or in the decision process is under debate (<xref ref-type="bibr" rid="bib2">Akaishi et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Fischer and Whitney, 2014</xref>; <xref ref-type="bibr" rid="bib42">St John-Saaltink et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Fritsche et al., 2017</xref>).</p><p>Unlike choice history biases, some choice biases are related to the overall idiosyncratic tendency to choose one alternative over the others, not conditioned by the previous choices. We will refer to these as global choice biases. The existence of these biases is acknowledged (<xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>; <xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>; <xref ref-type="bibr" rid="bib29">Morgan et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib34">Peters et al., 2016</xref>) and they are included in current models of perceptual decision making (<xref ref-type="bibr" rid="bib1">Abrahamyan et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Akaishi et al., 2014</xref>; <xref ref-type="bibr" rid="bib45">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib4">Braun et al., 2018</xref>; <xref ref-type="bibr" rid="bib16">Hermoso-Mendizabal et al., 2019</xref>), but whether they reflect sensory or decisional processes has not been, to our knowledge, assessed (we searched in Google Scholar several times, last one on February 2019, the following keywords: choice biases, response biases, motor biases, perceptual biases and sensory biases; we identified the relevant articles and searched within the references cited; we also tracked the articles that cited the relevant articles). The problem to identify their origin is that, in standard perceptual paradigms, the tendency to choose one alternative more often is consistent with a biased sensory representation, but also with a bias in the decision process (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>). Here, to disentangle the contribution of sensory and decisional processes to global choice bias, we measured choice behavior in a simple common perceptual discrimination task with two symmetric alternatives, but under two different task instructions. The instructions varied the response mapping between perception and the category of the alternatives.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>In Experiment 1, the orientation of a grating centered on a fixation point was chosen randomly on each trial from a range centered around the horizontal orientation. Seventeen participants judged whether the grating was pointing down or up (by pressing the <italic>down</italic> or <italic>up</italic> arrow keys on a keyboard) relative to a reference that we asked participants to imagine placed on the right at the same height of the fixation point (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; later we will discuss <xref ref-type="fig" rid="fig1">Figure 1B</xref>). <italic>Down</italic> and <italic>up</italic> choices correspond to clockwise and counterclockwise orientations relative to horizontal.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.43994.003</object-id><label>Figure 1.</label><caption><title>Symmetric task in Experiment 1.</title><p>(<bold>A</bold>) Illustration of a trial in which the participant was asked to imagine a reference on the right (the green dotted circumference was not displayed during the experiment; in Materials and methods we described the exact message displayed on the screen). (<bold>B</bold>) Illustration of a trial in which the participant was asked to imagine a reference on the left. (<bold>C–F</bold>) Choice behavior for four representative participants. (<bold>G</bold>) Decisional and sensory biases. For each participant, the circles correspond to the gratings presented around the horizontal orientation (<xref ref-type="fig" rid="fig1">Figure 1A–B</xref>) and the triangles to the gratings presented around the vertical orientation (illustrations of the stimuli not shown). The color indicates the best model assessed using likelihood ratio tests (see Materials and methods). (<bold>H</bold>) Across participants, the absolute value of the sensory and the decisional biases was significantly different (t(33) = 4.8, p=3.1×10<sup>−5</sup>). The crossbars display the mean and the 95% t-test confidence intervals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43994.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Choice behavior in the symmetric task for all participants in Experiment 1.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43994.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Choice behavior in the symmetric task for all participants in Experiment 1.</title><p>(<bold>A</bold>) Choice behavior for the one reference per block and two references per block conditions for all participants in Experiment 2. (<bold>B</bold>) Decisional and sensory biases for each participant. The color indicates the best model. (<bold>C</bold>) Across the participants of Experiment 2, a two-way repeated measures ANOVA for the absolute value of the biases indicated no significant effect of number of references per block (one reference per block or two references per block; (F(1,14) = 3.7; p=0.073), a significant effect of the type of biases (sensory or decisional; F(1,14) = 8.7; p=0.010) and no significant interaction (F(1,14) = 3.6; p=0.078). The graph shows the biases from Experiment 1 (also shown in <xref ref-type="fig" rid="fig1">Figure 1H</xref>) and Experiment 2 (collapsed across number of references per block). The crossbars display the mean and the 95% t-test confidence intervals. For Experiment 2, the sensory and the decisional biases is significantly different (t(29) = 3.13, p=0.0040). Across experiments, the sensory biases is not significantly different (t(47) = 0.92, p=0.3619), but the decisional biases is significantly different (t(44) = 2.0, p=0.048).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig1-figsupp2-v2.tif"/></fig></fig-group><p>We first describe the results of four representative participants that illustrate the four types of choice behaviors that we found (<xref ref-type="fig" rid="fig1">Figure 1C–F</xref>). The crosses in <xref ref-type="fig" rid="fig1">Figure 1C–F</xref> show the probability of clockwise responses (pressing the <italic>down</italic> key) as a function of the orientation of the grating and the curves show the psychometric fits (see <italic>Models;</italic> <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> shows the results for all participants). Participant 12 (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) did not show asymmetries in choice behavior—no global choice bias was present (to see how we assessed that the bias was not significant, see Materials and methods). Participant 2 (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) and 4 (<xref ref-type="fig" rid="fig1">Figure 1F</xref>) had a tendency to give a response consistent with clockwise orientation (pressing the <italic>down</italic> key)—that shifts the psychometric curve leftwards— and participant 9 (<xref ref-type="fig" rid="fig1">Figure 1E</xref>) had a tendency to give a response consistent with counterclockwise orientation (pressing the <italic>up</italic> key)—that shifts the psychometric curve rightwards.</p><p>The biases could reflect that the perceived horizontality of the grating corresponds to different orientations for different participants (sensory bias) or that under uncertainty participants had a tendency to select either the down or up alternative (decisional bias). It could also be that biases include a sensory and a decisional component.</p><p>To decouple these possibilities, in other trials intermixed with the trials just described we presented the same stimuli but asked participants whether the grating was pointing down or up relative to a reference that now we asked them to imagine on the <italic>left</italic> (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This variation in the instructions was easy for the participants to understand and effectively reversed the mapping between perception and the category of the alternatives. We did not display the reference to keep the stimuli identical across locations of the reference. For the left reference, <italic>down</italic> choices correspond to counterclockwise orientations relative to horizontal and <italic>up</italic> choices to clockwise. If the bias is of sensory origin, the probability of choosing an alternative consistent with clockwise orientation (asterisks in <xref ref-type="fig" rid="fig1">Figure 1C-F</xref> ) should not depend on where the reference was imagined (right or left). This is the choice behavior that participant 2 exhibited (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Notice that the similar pattern of clockwise responses for the two locations of the reference indicates that the participant reversed the frequency of pressing the <italic>down</italic> and <italic>up</italic> keys. If the bias is decisional, the probability of choosing an alternative consistent with clockwise orientation for the left reference should be shifted symmetrically relative to 0 deg (see <italic>Models</italic>). This is the choice behavior of participant 9 (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). In this case, the participant had a tendency to press more often the <italic>up</italic> key independently of the location of the reference. If sensorial and decisional biases contribute, the probability of choosing an alternative consistent with clockwise orientation should be shifted, but not symmetrically. This is the choice behavior of participant 4 (<xref ref-type="fig" rid="fig1">Figure 1F</xref>).</p><p>For each participant, we quantified the magnitude of the sensory and decisional biases (illustrated for participant 4 using arrows, <xref ref-type="fig" rid="fig1">Figure 1F</xref>, see <italic>Models</italic>). <xref ref-type="fig" rid="fig1">Figure 1G</xref> shows, for each participant, the magnitude of the decisional bias against the magnitude of the sensory bias and which is the bias model that better describes the data (see Models and Materials and methods). For each participant, two data points are plotted. The circles correspond to the trials just described, in which the grating was presented around the horizontal orientation. The triangles correspond to other trials—intermixed with the previous ones—in which the grating was presented around the vertical orientation (in this case, participants judged the orientation using the <italic>right</italic> and <italic>left</italic> keys relative to a reference that we asked participants to image on top or at the bottom). Most participants showed significant biases. About half of the participants showed biases consistent with only a sensory origin and about half showed decisional biases mostly combined with sensory biases (although two participants showed biases consistent with only a decisional origin). Across participants, the absolute value of the magnitude biases was larger (about 3 times larger) for the sensory biases than for the decisional biases, indicating that the sensory biases dominated (<xref ref-type="fig" rid="fig1">Figure 1H</xref>).</p><p>The slope of the psychometric fits provides a measure of precision. This precision affects the significance level of the biases. For example, for participant 7 (performing orientation judgments around the vertical; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), the slope is not very steep. This imprecision explains why the estimated biases for this participant, despite being of certain magnitude (the gray triangle more rightwards and upwards in <xref ref-type="fig" rid="fig1">Figure 1G</xref>), are not statistically significant.</p><p>The task described could be considered symmetric because the evidence supporting clockwise or counterclockwise choices should be similar when the stimulus has the same magnitude but different sign relative to the neutral point. Given this symmetry, it could be argued that what we have described as sensory biases might be a more complex form of decisional biases than the one we tested: participants might not prefer the <italic>down</italic> or <italic>up</italic> alternative (or <italic>right</italic> and <italic>left</italic>), but instead biased to choose the alternative consistent with clockwise or counterclockwise orientation. In this case, the sensory biases that we found should not remain when the same stimuli are presented, but the task has two choices unrelated to the clockwise and counterclockwise alternatives. To assess this prediction, in some other trials—intermixed with the previous trials—we asked participants to imagine a reference on the right or on the left (or bottom and top) and perform a two-alternative asymmetric choice task that consisted in indicating whether the grating was aligned or not with the imagined reference (<xref ref-type="fig" rid="fig2">Figure 2A–B</xref>).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.43994.006</object-id><label>Figure 2.</label><caption><title>Asymmetric task in Experiment 1.</title><p>(<bold>A</bold>) Illustration of a trial in which the participant was asked to imagine a reference on the right. (<bold>B</bold>) Illustration of a trial in which the participant was asked to imagine a reference on the left. (<bold>C–F</bold>) Choice behavior for four representative participants. (<bold>G</bold>) Decisional and sensory biases. (<bold>H</bold>) Across participants, the absolute value of the sensory and the decisional biases was significantly different (t(31) = 5.4, p=6.0×10<sup>−6</sup>). The crossbars display the mean and the 95% t-test confidence intervals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.43994.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Choice behavior in the asymmetric task for all participants in Experiment 1.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig2-figsupp1-v2.tif"/></fig></fig-group><p>To illustrate the choice behaviors on this task, we first describe the results of four representative participants (<xref ref-type="fig" rid="fig2">Figure 2C–F</xref>). The symbols in <xref ref-type="fig" rid="fig2">Figure 2C–F</xref> show the probability of responding <italic>aligned</italic> as a function of the orientation of the grating and the curves show the psychometric fits for the two possible locations of the reference (see <italic>Supplementary Models;</italic> <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> shows the results for all participants). The arrows in <xref ref-type="fig" rid="fig2">Figure 2F</xref> illustrates the estimation of the magnitude of the sensory and decisional bias (see <italic>Supplementary Models</italic>). For participant 14 (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), the probability of responding <italic>aligned</italic> was centered around 0 and did not depend on the location of the reference (no bias). For participant 3 (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), the probability of responding <italic>aligned</italic> was not centered around 0, but did not depend on the location of the reference (sensory bias). For participant 1 (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), the probability of responding <italic>aligned</italic> was not centered around 0 and depended on the location of the reference, but the tendency to respond <italic>aligned</italic> more often for one location did not affect where the psychometric fit was centered (sensory bias with a symmetric decisional bias, see <italic>Supplementary Models</italic>). Finally, for participant 16 (<xref ref-type="fig" rid="fig2">Figure 2F</xref>), the probability of responding <italic>aligned</italic> was not centered around 0 and depended on the location of the reference, but in this case this tendency affected where the psychometric fits were centered (sensory bias with an asymmetric decisional bias, see <italic>Supplementary Models</italic>).</p><p><xref ref-type="fig" rid="fig2">Figure 2G</xref> shows, for each participant and overall orientation of the grating (horizontal or vertical), the magnitude of the decisional bias against the magnitude of the sensory bias and which is the bias model that better describes the data (see Materials and methods). Most participants showed significant biases that include sensory and decisional biases. It has been suggested that asymmetric tasks are less prone to decisional biases than symmetric tasks (<xref ref-type="bibr" rid="bib39">Schneider and Komlos, 2008</xref>; but see <xref ref-type="bibr" rid="bib3">Anton-Erxleben et al., 2010</xref>). We did find less groups with significant decisional biases (the asymmetric ones, <xref ref-type="fig" rid="fig2">Figure 2F</xref>) for the asymmetric task (five fits; <xref ref-type="fig" rid="fig2">Figure 2G</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) than for the symmetric task (eight fits; <xref ref-type="fig" rid="fig1">Figure 1G</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), but the difference was not significant (χ<sup>2</sup> (1)=0.52, p=0.47). Across participants, the absolute value of the magnitude of the biases was larger (about four times larger) for the sensory biases than for the decisional biases, indicating that the sensory biases dominated (<xref ref-type="fig" rid="fig1">Figure 1H</xref>).</p><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> shows that, within participants, the sensory biases estimated from the asymmetric task are very similar to those estimated from the symmetric task. This shows that what we described as sensory biases for the symmetric task had indeed a sensory origin, and not a complex form of decisional biases. We also found a good agreement, within participants, between the sensory biases for the horizontal grating and the vertical grating for the two tasks (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). This suggests that the sensory biases are consistent with a clockwise or counterclockwise global perceptual rotation of the stimulus.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.43994.008</object-id><label>Figure 3.</label><caption><title>Sensory biases across tasks and orientations.</title><p>(<bold>A</bold>) Across participants, the sensory biases estimated from the symmetric task correlated with the sensory biases estimated from the asymmetric task (r(30) = 0.81, p=2.7×10<sup>−8</sup>). The color of the triangles indicates the model that best fit the data. The black line corresponds to a simple linear regression fit. To compare the symmetric and the asymmetric task with the counterparts in the temporal domain (see final paragraph of the Discussion), we also calculated the correlation of the biases across tasks using only one reference for each pair of coupled references (bottom or left; r(30) = 0.77, p=2.3×10<sup>−7</sup>). In this case, we estimated the bias for the symmetric task as the orientation for which the probability of clockwise responses was 50% and for the asymmetric task as the orientation for which the probability was maximum. (<bold>B</bold>) Across participants, the sensory biases estimated using the horizontal grating correlated with the sensory biases estimated using the vertical grating for the symmetric (r(15) = 0.67, p=0.0030) and the asymmetric task (r(15) = 0.60, p=0.015). The lines correspond to simple linear regression fits.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-43994-fig3-v2.tif"/></fig><p>Across trials we intermixed four locations of the reference and two tasks (symmetric and asymmetric) that required pressing different keys. These high demands on participants might have minimized decisional biases. To test whether the task demands influenced the proliferation of decisional biases, in Experiment 2, for 16 new participants, we repeated the symmetric task using two references (Top and Bottom) that could be blocked in two ways. In some blocks of trials the two references were mixed across trials and participants, thus, needed to establish a mapping between perception and the category of the alternatives on each trial. In some other blocks, only one reference was presented on each block (on different blocks, the reference changed) and participants did not need to update the response mapping on each trial. Consistent with Experiment 1, we found that participants exhibited significant sensory and decisional biases, but we did not find significant differences in decisional biases between the two blocking conditions (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). We found, however, that the decisional biases in Experiment 2 were larger than in Experiment 1 (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), which suggests that very high demands on the task like those in Experiment 1 can reduce the proliferation of decisional biases.</p><p>Taking into account Experiment 1 and 2, we have found that from the 32 participants, 30 (94%) had significant global choice biases. From these 30, the sensory contribution was significant in all of them (that is, 94% of participants had sensory bias) and the decisional contribution was significant in 15 (that is, 47% of participants had decisional biases).</p><sec id="s2-1"><title>Models</title><p>On a given trial of the symmetric task (the model for the asymmetric task is described in <italic>Supplementary Models</italic>) a grating with orientation <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> that could be clockwise or counterclockwise, is presented and the participant decides whether its orientation is consistent with clockwise <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> or counterclockwise <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> orientation. A simple standard signal detection theory (SDT) model assumes that: (1) the sensory evidence <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> associated to the stimulus is a random variable normally distributed with variance <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> centered on <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is clockwise and centered on <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is counterclockwise; (2) to make choices, the participant sets a criterion <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, computes the log likelihood ratio <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> under the hypothesis that <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the hypothesis that <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>and chooses the action <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> .</p><p>In standard SDT models the origin and scale of the sensory evidence is arbitrary (<xref ref-type="bibr" rid="bib47">Wickens, 2001</xref>; <xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>). A typical choice is (<xref ref-type="bibr" rid="bib47">Wickens, 2001</xref>; <xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>)<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mspace width="2em"/><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mspace width="2em"/><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula>which results in <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> . That is, one can use directly the evidence as a decision variable and choose <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib47">Wickens, 2001</xref>; <xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>).</p><p>The probability of choosing clockwise when <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is clockwise is<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the standard cumulative normal function. To relate this probability to the magnitude of the stimulus, this standard SDT could be extended to include how the stimulus is transduced into sensory evidence (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib38">Schneider and Bavelier, 2003</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>; <xref ref-type="bibr" rid="bib39">Schneider and Komlos, 2008</xref>). Adding the transduction provides a meaningful origin and scale to the sensory evidence. Assuming that the transduction is linear<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>the probability of choosing clockwise as a function of <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> becomes<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Where<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>b</mml:mi><mml:mi>a</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mspace width="2em"/><mml:msub><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mspace width="2em"/><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">a</mml:mi></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>which corresponds to a psychometric function centered on <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with slope given by <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Consider the trials in which the grating is presented in orientations around the horizontal orientation and the reference is on the right (the reasoning that follows also holds for vertical orientations). If the orientation of the grating can take <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> different values, each value is presented <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> times and <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number of times that the participant pressed the <italic>down</italic> key (clockwise), then the probability density function that defines statistical model for these trials is<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Given that <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> depends on <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, it is not possible to distinguish sensory from decisional biases (<xref ref-type="bibr" rid="bib48">Witt et al., 2015</xref>; <xref ref-type="bibr" rid="bib39">Schneider and Komlos, 2008</xref>; <xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>).</p><p>Consider now the trials for the left reference. A criterion <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> associated to a bias to choose responses consistent with clockwise orientation for the right reference corresponds to a criterion <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for the left reference. The statistical model that incorporates responses for the two locations of the reference is<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2em"/><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>and the index <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> larger than <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> refers to the trials for the left reference. Now, by fitting two psychometric functions conjointly, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are not degenerated and could be estimated. This is the exact model that we fitted for 17 of the 34 groups (17 participants that discriminate orientations around the horizontal and the vertical orientation in Experiment 1). For the rest of the groups, we also fitted this basic model, but adding some extra features that significantly improved the quality of the fit (using likelihood ratio tests, see Materials and methods).</p><p>The first feature is related to the variability of the sensory evidence <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The basic model considers that this variability does not depend on where the participants imagined the reference, which results in the two psychometric functions having the same slope. We found this to be the case in 28 of the 34 fits, but in six groups we found that considering different variabilities (<inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) for the two locations of the reference was better. It might be that orienting attention to different parts of the visual field might change the uncertainty in the sensory evidence for some participants.</p><p>The other feature that we added consisted in adding lapses, which are responses that are incorrect independently of the sensory evidence (<xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>; <xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>). This might occur, for example, when the participant misses the stimulus because of blinking or a loss of attention. To incorporate lapses into the basic model, <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> need to be replaced by <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> by <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>). From the 34 groups, adding lapses improved the fit in 14 cases. From those, three fits required the four lapse parameters, 4 fits required two lapse parameters (one for each psychometric function, <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> ; <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>) and 7 fits required one lapse rate (<inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>). Importantly, including a lapse rate parameter <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> placed on the right asymptote for the right reference<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>and placed on the left asymptote for the left reference<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>did not improve significantly the fit for any group, which indicates that decisional biases cannot be explained by a tendency of participants to select one alternative completely independently of the sensory evidence.</p><p>Perceptual tasks with two symmetric alternatives have been also modeled using a high threshold model, called the indecision model (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>). This model is similar to the SDT model described, but divides the sensory axis in three regions delimited by <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. When the sensory evidence is lower than <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> the participant chooses <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and when is larger than <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, chooses <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Critically, when the sensory evidence lies between <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>—called interval of uncertainty—the model assumes that the observer is undecided and guesses the response (choosing <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with probability <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). The probability of choosing clockwise when <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is clockwise and the reference is on the right is<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ξ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For the left reference, assuming that <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> do not change, <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> should be replaced by <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. We fitted this model to the 19 groups with significant decisional biases and found that for all of them (except for participant eight for the vertical condition in Experiment 1) the SDT model was better using the Akaike information criterion (<xref ref-type="bibr" rid="bib5">Burnham and Anderson, 2004</xref>). Given that the indecision model has two parameters more than the SDT model (<inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is replaced by <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is introduced), we also compared the SDT model to a simplified version of the indecision model with symmetric boundaries <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>). In this case, the SDT model was better for all the groups.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We showed that, in a simple discrimination task with two symmetric alternatives, most people exhibit idiosyncratic global choice biases. Changing the stimulus-response mapping and testing a task with two asymmetric alternatives, we found that these biases reflect biases in the sensory evidence and in the decisional process. Specifically, about half of the participants showed biases consistent with only a sensory origin and about half of the participant biases with a contribution of sensory and decisional biases. We also found that a very few participants exhibited biases consistent with only a decisional origin. Across participants, the magnitude of the sensory bias was about three times as larger as the magnitude of the decisional bias.</p><p>Our findings suggest that if a person has a bias to report that a perfectly horizontal canvas is tilted towards a given direction, it is likely that the largest contribution to the bias has a sensory origin. To our knowledge, these idiosyncratic sensory biases have not been linked to asymmetries in the neural representation of the stimulus. Possible asymmetries include a difference in the number of neurons tuned to clockwise and counterclockwise orientation if the decoding is of the population-vector type or a difference in the gain of neurons tuned to clockwise and counterclockwise orientation for more general decoding schemes (<xref ref-type="bibr" rid="bib8">Dayan and Abbott, 2001</xref>; <xref ref-type="bibr" rid="bib40">Schwartz et al., 2007</xref>). More recently, it has been proposed that the asymmetries could also emerge from the dynamics of competing neural networks (<xref ref-type="bibr" rid="bib21">Lebovich et al., 2018</xref>). Importantly, for these asymmetries to bias perception, the downstream decoding mechanisms should have not been calibrated with the environmental property to compensate the asymmetries (decoding ambiguity; <xref ref-type="bibr" rid="bib40">Schwartz et al., 2007</xref>).</p><p>An SDT model, in which the sensory biases were included as an intercept term in a linear transduction of the stimuli (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib38">Schneider and Bavelier, 2003</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>; <xref ref-type="bibr" rid="bib39">Schneider and Komlos, 2008</xref>) and decisional biases correspond to a shift in the criterion, fitted well the choice behavior of the participants. A model in which participants have a tendency to choose one alternative independently of the magnitude of the sensory evidence did not fit well the data; it rather predicts an asymmetry on the lapse rate across locations of the reference that was not observed. Finally, a model (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>) in which participants guess when the sensory evidence lies within some uncertainty range was not parsimonious: first, to fit the data for the participants with pure sensory biases, the model needs that participants, when uncertain, guess the two alternatives equally often; second, for the participants with decisional biases, we found that the SDT model provided a better fit.</p><p>Perceptual discrimination with two symmetric alternatives are often regarded as Type 1 tasks, tasks for which the responses could be designated as correct or incorrect (<xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>). If a stimulus has positive signal (for example, rightward motion) relative to a neutral point (no net motion), but the decision-maker chooses the alternative consistent with negative signal (leftward motion), the response is considered an error. In this case, a psychometric function of the proportion of correct responses as a function of the unsigned signal is often fitted, and precision is estimated as the amount of signal that is required to reach a certain level of correct responses. Our results, however, suggest that in some cases a positive signal might be perceived consistently as a negative signal (sensory bias). Consequently, it might be inappropriate to consider these responses as errors and, in case feedback is given, provide a negative reward. Our results suggest, thus, that perceptual discrimination tasks with two symmetric alternatives might be better regarded as Type 2 tasks, tasks for which there are not correct and incorrect responses (<xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>; <xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>). Accordingly, the psychometric function that should be fitted is the proportion of times that a category was selected (for example, rightward motion) as a function of the signed signal, and precision should be estimated using the slope of the psychometric function (<xref ref-type="bibr" rid="bib14">Gold and Ding, 2013</xref>).</p><p>Discrimination tasks with two symmetric alternatives are commonly used to assess how perception is affected by contextual cues (<xref ref-type="bibr" rid="bib6">Carrasco et al., 2004</xref>; <xref ref-type="bibr" rid="bib40">Schwartz et al., 2007</xref>), but in some scenarios it is unclear whether the context influences perception or biases decisions (<xref ref-type="bibr" rid="bib7">Carrasco, 2011</xref>; <xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib29">Morgan et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Störmer et al., 2009</xref>; <xref ref-type="bibr" rid="bib37">Schneider, 2011</xref>; <xref ref-type="bibr" rid="bib3">Anton-Erxleben et al., 2010</xref>; <xref ref-type="bibr" rid="bib19">Jogan and Stocker, 2012</xref>; <xref ref-type="bibr" rid="bib27">Mather and Sharman, 2015</xref>). Our results indicate that, even when the symmetry of the task is not broken by the context, half of the participants exhibit decisional biases. This suggests that to reliably estimate sensory biases in the presence of contextual cues, it might be better to use manipulations of the stimulus-response mapping like the one that we used or tasks for which the potential contribution of decisional biases is reduced or eliminated (<xref ref-type="bibr" rid="bib19">Jogan and Stocker, 2012</xref>; <xref ref-type="bibr" rid="bib32">Patten and Clifford, 2015</xref>; <xref ref-type="bibr" rid="bib30">Morgan, 2014</xref>).</p><p>The perceptual discrimination task with two symmetric alternatives that we have used is also known as the method of single stimuli (<xref ref-type="bibr" rid="bib29">Morgan et al., 2012</xref>) In this method, the decision-maker is asked to categorize the signal presented against an internal absolute reference that corresponds to a natural neutral point that the decision-maker possibly has learnt during her life (<xref ref-type="bibr" rid="bib29">Morgan et al., 2012</xref>)—verticality or horizontality in our case. The sensory biases that we have measured are deviations from this internal reference. In the non-symmetric version of this task, the Yes-No task (<xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>; <xref ref-type="bibr" rid="bib47">Wickens, 2001</xref>), the decision-maker decides, for example, whether a dim light is present or absent. For this task, decision-makers have also idiosyncratic tendencies to report that the signal is present or absent (<xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>). Given that, in this task, there is no natural neutral point, it is harder to assess whether these tendencies reflect differences in the strength that each decision-maker perceives or differences in how conservatively they report that the signal is present or absent (<xref ref-type="bibr" rid="bib18">Jin and Glickfeld, 2018</xref>). Another popular task to assess perception is the two alternative forced choice task (<xref ref-type="bibr" rid="bib15">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib47">Wickens, 2001</xref>; <xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>). In this task, two stimuli are presented in a random order—for example, a vertical grating and a grating slightly tilted clockwise—and the decision-maker decides in which interval the grating was more tilted clockwise. This task assesses the precision to discriminate similar orientations, but cannot measure sensory biases from verticality: a bias of the decision-maker to perceive orientations clockwise will affect the stimuli presented in the two intervals in the same direction without affecting the selection of the interval with the more tilted stimulus.</p><p>To facilitate that participants internalize two different associations between perception and the responses, we asked them to compare the orientation of the stimulus to a reference imagined in two different locations. Given that the reference was not physically present, we think, however, that it is likely that participants were performing judgments of absolute orientation relative to an internal point of horizontality (or verticality). As we found evidence that the sensory biases were consistent with a global perceptual rotation, if participants were performing judgments of relative orientation between the stimulus and the reference—instead of judgments of absolute orientation—then sensory biases should not be expected, as both the stimulus and the reference should be biased in the same direction.</p><p>We found a good agreement between the sensory biases estimated from the symmetric and the asymmetric task. We also found a good agreement between tasks when the biases were estimated taking into account only one localization of the reference, and thus for which it was not possible to assess the contribution of sensory and decisional biases (see legend for <xref ref-type="fig" rid="fig3">Figure 3A</xref>). This is expected given the large contribution of sensory biases to the total magnitude of the biases. This agreement across tasks contrasts with the disagreement found between the analogous tasks in the temporal domain. In the temporal domain, the analogous to the symmetric task is the temporal order judgment. Given, for example, an auditory and a visual event presented at some asynchrony, the task is to report whether the auditory or the visual event is perceived first. The location parameter of the psychometric fit for the proportion of ‘auditory perceived first’ responses as a function of the asynchrony provides a measure of the bias. The asymmetric task is the simultaneity judgment, in which is necessary to report whether the auditory and the visual event were perceived simultaneously. In this case, the bias is estimated as the asynchrony for which the proportion of simultaneous responses is maximum. It has been shown that the biases estimated from these two tasks do not agree (<xref ref-type="bibr" rid="bib25">Love et al., 2013</xref>; <xref ref-type="bibr" rid="bib23">Linares and Holcombe, 2014</xref>; <xref ref-type="bibr" rid="bib46">van Eijk et al., 2008</xref>), which suggests that decision making for time perception might be more affected by decisional biases (<xref ref-type="bibr" rid="bib23">Linares and Holcombe, 2014</xref>; <xref ref-type="bibr" rid="bib41">Shore et al., 2001</xref>; <xref ref-type="bibr" rid="bib38">Schneider and Bavelier, 2003</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>The study was approved by the ethical committee of the University of Barcelona and followed the requirements of the Helsinki convention. The participants, who did not know the hypothesis of the experiments, provided written consent to perform the experiments. Twenty-one participants were recruited for Experiment 1 and sixteen for Experiment 2.</p></sec><sec id="s4-2"><title>Stimuli and tasks</title><p>Stimuli were generated using PsychoPy (<xref ref-type="bibr" rid="bib33">Peirce, 2007</xref>), displayed on a Sony G520 CRT screen (40 cm width and 30 cm height; 60 Hz refresh rate) and viewed from a distance of 57 cm in a dark room. They consisted in a Gabor patch (standard deviation (sd) of the Gaussian envelope: 1.33 degrees of visual angle (dva); maximum luminance: 79 cd/m<sup>2</sup>) and a red Gaussian blob (sd: 0.1 dva; maximum luminance: 19 cd/m<sup>2</sup>) on top of it that participants were asked to fixate during the experiment. Stimuli were presented against a uniform circular grey background (diameter: 25 dva; luminance: 43 cd/m<sup>2</sup>) that was displayed in a black background (luminance: 0.2 cd/m<sup>2</sup>). The verticality of the Gabor was calibrated using a pendulum.</p><sec id="s4-2-1"><title>Experiment 1</title><p>Participants performed 6 blocks of 360 trials. In each block, eight conditions were randomly intermixed across trials. On each trial, before the Gabor was presented, a text message informed participants about the condition. A <italic>right: up or down?</italic> message instructed participants to imagine a reference on the right (at the same height of the fixation point) and respond whether the Gabor was pointing down (clockwise) or up (counterclockwise) relative to it. A <italic>left: up or down?</italic> message instructed participants to imagine a reference on the left and respond whether the Gabor was pointing down (counter-clockwise) or up (clockwise). For these conditions, the orientation of the Gabor was chosen randomly from a range centred around horizontal orientation (from −2 to 2 deg in steps of 0.5 deg) according to the method of constant stimuli (<xref ref-type="bibr" rid="bib20">Kingdom and Prins, 2016</xref>). The <italic>up: right or left?</italic> and the <italic>down: right or left?</italic> messages provided parallel instructions for imaginary references on top and at the bottom. For these conditions the orientation was centered around vertical orientation. Participants used the arrow keys to respond. A <italic>right?</italic> message instructed participants to imagine a reference on the right and respond whether the Gabor was aligned with it (pressing <italic>m</italic> key) or not (pressing <italic>n</italic> key). A <italic>left?</italic>, <italic>up?</italic> and <italic>down?</italic> provided parallel instructions for references in other locations. The messages were available until participants pressed the spacebar. The Gabor was presented for 100 ms, 500 ms after the keypress.</p></sec><sec id="s4-2-2"><title>Experiment 2</title><p>Experiment 2 was like Experiment 1, but included only the symmetric task and orientations around vertical. Participants performed 4 blocks of 270 trials. Half of the participants performed first two blocks in which they were asked to imagined the reference always in the same location within a block and, then, two blocks in which they were asked to imagine the reference at one location that changed randomly across trials. For the other half of participants, the block order was inverted.</p></sec></sec><sec id="s4-3"><title>Instructions</title><p>Before the experiments, to facilitate the understanding of the instructions, a reference (a green gaussian luminance profile; sd: 0.1 dva; maximum luminance: 29 cd/m<sup>2</sup>) was displayed for 5 to 10 trials at the corresponding cardinal location at a distance of 6 dva from the center of the fixation point.</p></sec><sec id="s4-4"><title>Analysis</title><p>The data and the code to do the statistical analysis and create the figures is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/danilinares/2018LinaresAguilarLopezmoliner">https://github.com/danilinares/2018LinaresAguilarLopezmoliner</ext-link> (<xref ref-type="bibr" rid="bib22">Linares, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/2018LinaresAguilarLopezmoliner">https://github.com/elifesciences-publications/2018LinaresAguilarLopezmoliner</ext-link>). The model fitting, goodness of fit and model selection (likelihood ratio test and Akaike information criterion) was performed using the R package <italic>quickspy</italic> (<xref ref-type="bibr" rid="bib24">Linares and López-Moliner, 2016</xref>), which under the development version allows fitting several psychometric functions conjointly.</p><sec id="s4-4-1"><title>Experiment 1 (symmetric task)</title><p>For four of the twenty-one participants, a preliminary analysis revealed that the responses were inverted or not modulated by the orientation of the grating and were not analyzed further. For each participant and condition of overall orientation (horizontal or vertical), we fitted the model in <xref ref-type="disp-formula" rid="equ8">Equation (8)</xref> with all the extra features (2 slopes and four lapses, see <italic>Models</italic>; parameters: <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> , <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>) using maximum likelihood estimation. Then, using consecutive likelihood ratio tests performed using the <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> distribution and a significance level of 0.05 (<xref ref-type="bibr" rid="bib36">Prins and Kingdom, 2018</xref>), we reduced model complexity to select for each participant and condition of orientation the simplest model that captured the data and incorporated at least the parameters <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The first two parameters correspond to the sensory and decisional biases plotted in <xref ref-type="fig" rid="fig1">Figure 1G</xref>. To assess, for each participant and condition of orientation, which was the best bias model, we performed further likelihood ratio tests with simpler models. The best bias model was described as <italic>Sensory bias</italic> if a simpler model with <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> provided a better fit; <italic>Decisional bias</italic> if a model with <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> was better; <italic>No bias</italic> if a model with <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> was better; and <italic>Sensory + decisional bias</italic> if the complexity of the original model could not be further reduced. When we compared the models with lapse parameters with the models without lapses, we used a lapse rate of 0.01 instead of zero because this resulted in better fits (<xref ref-type="bibr" rid="bib35">Prins, 2012</xref>).</p></sec><sec id="s4-4-2"><title>Experiment 1 (asymmetric task)</title><p>For one of the participants that could perform the symmetric task, the responses were not modulated by the orientation of the grating for the asymmetric task and the data was not analyzed. To estimate sensory and decisional biases and assess which bias model was better, we used the same procedure described for the symmetric task.</p></sec><sec id="s4-4-3"><title>Experiment 2</title><p>The data were analyzed as it is described for the symmetric task in Experiment 1.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgments</title><p>The research was funded by the Departament de Salut of the Generalitat de Catalunya (PERIS-ICT Ref: SLT002/16/00338; PERIS Ref: SLT006/17/00362), the Catalan government (Ref: 2017SGR-48), the Fundación Alicia Koplowitz, project Ref: PSI2017- 83493 R, AEI/Feder, UE and CERCA Programme / Generalitat de Catalunya . Part of this work was developed at the building Centro Esther Koplowitz, Barcelona. We thank João Barbosa, Albert Compte and Genís Prat for comments on the manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Software, Funding acquisition, Methodology, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by the ethical committee of the University of Barcelona (IRB00003099) and followed the requirements of the Helsinki convention. The participants, who did not know the hypothesis of the experiments, provided written consent to perform the experiments.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.43994.009</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-43994-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The data and the code to do the statistical analysis and create the figures is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/danilinares/2018LinaresAguilarLopezmoliner">https://github.com/danilinares/2018LinaresAguilarLopezmoliner</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/2018LinaresAguilarLopezmoliner">https://github.com/elifesciences-publications/2018LinaresAguilarLopezmoliner</ext-link>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abrahamyan</surname> <given-names>A</given-names></name><name><surname>Silva</surname> <given-names>LL</given-names></name><name><surname>Dakin</surname> <given-names>SC</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Gardner</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptable history biases in human perceptual decisions</article-title><source>PNAS</source><volume>113</volume><fpage>E3548</fpage><lpage>E3557</lpage><pub-id pub-id-type="doi">10.1073/pnas.1518786113</pub-id><pub-id pub-id-type="pmid">27330086</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaishi</surname> <given-names>R</given-names></name><name><surname>Umeda</surname> <given-names>K</given-names></name><name><surname>Nagase</surname> <given-names>A</given-names></name><name><surname>Sakai</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Autonomous mechanism of internal choice estimate underlies decision inertia</article-title><source>Neuron</source><volume>81</volume><fpage>195</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.018</pub-id><pub-id pub-id-type="pmid">24333055</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anton-Erxleben</surname> <given-names>K</given-names></name><name><surname>Abrams</surname> <given-names>J</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evaluating comparative and equality judgments in contrast perception: attention alters appearance</article-title><source>Journal of Vision</source><volume>10</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1167/10.11.6</pub-id><pub-id pub-id-type="pmid">20884501</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname> <given-names>A</given-names></name><name><surname>Urai</surname> <given-names>AE</given-names></name><name><surname>Donner</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Adaptive history biases result from Confidence-Weighted accumulation of past choices</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2418</fpage><lpage>2429</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2189-17.2017</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burnham</surname> <given-names>KP</given-names></name><name><surname>Anderson</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multimodel inference: understanding AIC and BIC in model selection</article-title><source>Sociological Methods &amp; Research</source><volume>33</volume><fpage>261</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.1177/0049124104268644</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrasco</surname> <given-names>M</given-names></name><name><surname>Ling</surname> <given-names>S</given-names></name><name><surname>Read</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Attention alters appearance</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>308</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1038/nn1194</pub-id><pub-id pub-id-type="pmid">14966522</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visual attention: the past 25 years</article-title><source>Vision Research</source><volume>51</volume><fpage>1484</fpage><lpage>1525</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.04.012</pub-id><pub-id pub-id-type="pmid">21549742</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Theoretical Neuroscience</source><volume>806</volume><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname> <given-names>J</given-names></name><name><surname>Whitney</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Serial dependence in visual perception</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>738</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1038/nn.3689</pub-id><pub-id pub-id-type="pmid">24686785</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsche</surname> <given-names>M</given-names></name><name><surname>Mostert</surname> <given-names>P</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Opposite Effects of Recent History on Perception and Decision</article-title><source>Current Biology</source><volume>27</volume><fpage>590</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.01.006</pub-id><pub-id pub-id-type="pmid">28162897</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fründ</surname> <given-names>I</given-names></name><name><surname>Wichmann</surname> <given-names>FA</given-names></name><name><surname>Macke</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Quantifying the effect of intertrial dependence on perceptual decisions</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1167/14.7.9</pub-id><pub-id pub-id-type="pmid">24944238</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>García-Pérez</surname> <given-names>MA</given-names></name><name><surname>Alcalá-Quintana</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Shifts of the psychometric function: distinguishing bias from perceptual effects</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>66</volume><fpage>319</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1080/17470218.2012.708761</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>García-Pérez</surname> <given-names>MA</given-names></name><name><surname>Peli</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The bisection point across variants of the task</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>76</volume><fpage>1671</fpage><lpage>1697</lpage><pub-id pub-id-type="doi">10.3758/s13414-014-0672-9</pub-id><pub-id pub-id-type="pmid">24811039</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Ding</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How mechanisms of perceptual decision-making affect the psychometric function</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>98</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.05.008</pub-id><pub-id pub-id-type="pmid">22609483</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>DM</given-names></name><name><surname>Swets</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><volume>888</volume><publisher-loc>New York</publisher-loc><publisher-name>American Psychological Association</publisher-name></element-citation></ref><ref id="bib16"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hermoso-Mendizabal</surname> <given-names>A</given-names></name><name><surname>Hyafil</surname> <given-names>A</given-names></name><name><surname>Rueda-Orozco</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Response outcomes gate the impact of expectations on perceptual decisions</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/433409</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname> <given-names>M</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A new perceptual illusion reveals mechanisms of sensory decoding</article-title><source>Nature</source><volume>446</volume><fpage>912</fpage><lpage>915</lpage><pub-id pub-id-type="doi">10.1038/nature05739</pub-id><pub-id pub-id-type="pmid">17410125</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jin</surname> <given-names>M</given-names></name><name><surname>Glickfeld</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Contribution of sensory encoding to measured bias</article-title><source>BioRxiv</source><pub-id pub-id-type="doi">10.1101/444430</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jogan</surname> <given-names>M</given-names></name><name><surname>Stocker</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A new 2afc method for the comparison of stimuli that differ along multiple stimulus dimensions</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>619</elocation-id><pub-id pub-id-type="doi">10.1167/12.9.619</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kingdom</surname> <given-names>FAA</given-names></name><name><surname>Prins</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Psychophysics: A Practical Introduction</source><publisher-name>Elsevier Science</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lebovich</surname> <given-names>L</given-names></name><name><surname>Darshan</surname> <given-names>R</given-names></name><name><surname>Lavi</surname> <given-names>Y</given-names></name><name><surname>Hansel</surname> <given-names>D</given-names></name><name><surname>Loewenstein</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Idiosyncratic choice bias in decision tasks naturally emerges from neuronal network dynamics</article-title><source> arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.07193">https://arxiv.org/abs/1803.07193</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Linares</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Data and Code for 'Decoupling Sensory From Decisional Choice Biases in Perceptual Decision Making'</source><version designator="3e48e64">3e48e64</version><publisher-name>GitHub</publisher-name><ext-link ext-link-type="uri" xlink:href="https://github.com/danilinares/2018LinaresAguilarLopezmoliner">https://github.com/danilinares/2018LinaresAguilarLopezmoliner</ext-link></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linares</surname> <given-names>D</given-names></name><name><surname>Holcombe</surname> <given-names>AO</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Differences in perceptual latency estimated from judgments of temporal order, simultaneity and duration are inconsistent</article-title><source>I-Perception</source><volume>5</volume><fpage>559</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1068/i0675</pub-id><pub-id pub-id-type="pmid">26034565</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linares</surname> <given-names>D</given-names></name><name><surname>López-Moliner</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Quickpsy: an R package to fit psychometric functions for multiple groups</article-title><source>The R Journal</source><volume>8</volume><fpage>122</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.32614/RJ-2016-008</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname> <given-names>SA</given-names></name><name><surname>Petrini</surname> <given-names>K</given-names></name><name><surname>Cheng</surname> <given-names>A</given-names></name><name><surname>Pollick</surname> <given-names>FE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A psychophysical investigation of differences between synchrony and temporal order judgments</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e54798</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0054798</pub-id><pub-id pub-id-type="pmid">23349971</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mareschal</surname> <given-names>I</given-names></name><name><surname>Clifford</surname> <given-names>CW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dynamics of unconscious contextual effects in orientation processing</article-title><source>PNAS</source><volume>109</volume><fpage>7553</fpage><lpage>7558</lpage><pub-id pub-id-type="doi">10.1073/pnas.1200952109</pub-id><pub-id pub-id-type="pmid">22529393</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname> <given-names>G</given-names></name><name><surname>Sharman</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decision-level adaptation in motion perception</article-title><source>Royal Society Open Science</source><volume>2</volume><elocation-id>150418</elocation-id><pub-id pub-id-type="doi">10.1098/rsos.150418</pub-id><pub-id pub-id-type="pmid">27019726</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milner</surname> <given-names>AD</given-names></name><name><surname>Brechmann</surname> <given-names>M</given-names></name><name><surname>Pagliarini</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>To halve and to halve not: an analysis of line bisection judgements in normal subjects</article-title><source>Neuropsychologia</source><volume>30</volume><fpage>515</fpage><lpage>526</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(92)90055-Q</pub-id><pub-id pub-id-type="pmid">1641116</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname> <given-names>M</given-names></name><name><surname>Dillenburger</surname> <given-names>B</given-names></name><name><surname>Raphael</surname> <given-names>S</given-names></name><name><surname>Solomon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Observers can voluntarily shift their psychometric functions without losing sensitivity</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>74</volume><fpage>185</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.3758/s13414-011-0222-7</pub-id><pub-id pub-id-type="pmid">22033949</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A bias-free measure of retinotopic tilt adaptation</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/4.1.7</pub-id><pub-id pub-id-type="pmid">24403393</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Paré</surname> <given-names>EB</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A selective impairment of motion perception following lesions of the middle temporal visual area (MT)</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>2201</fpage><lpage>2211</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-06-02201.1988</pub-id><pub-id pub-id-type="pmid">3385495</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patten</surname> <given-names>ML</given-names></name><name><surname>Clifford</surname> <given-names>CW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A bias-free measure of the tilt illusion</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.1167/15.15.8</pub-id><pub-id pub-id-type="pmid">26575194</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peirce</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>PsychoPy--psychophysics software in python</article-title><source>Journal of Neuroscience Methods</source><volume>162</volume><fpage>8</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id><pub-id pub-id-type="pmid">17254636</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname> <given-names>MA</given-names></name><name><surname>Ro</surname> <given-names>T</given-names></name><name><surname>Lau</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Who's afraid of response bias?</article-title><source>Neuroscience of Consciousness</source><volume>2016</volume><elocation-id>niw001</elocation-id><pub-id pub-id-type="doi">10.1093/nc/niw001</pub-id><pub-id pub-id-type="pmid">27499928</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The psychometric function: the lapse rate revisited</article-title><source>Journal of Vision</source><volume>12</volume><fpage>25</fpage><pub-id pub-id-type="doi">10.1167/12.6.25</pub-id><pub-id pub-id-type="pmid">22715196</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prins</surname> <given-names>N</given-names></name><name><surname>Kingdom</surname> <given-names>FAA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Applying the Model-Comparison approach to test specific research hypotheses in psychophysical research using the palamedes toolbox</article-title><source>Frontiers in Psychology</source><volume>9</volume><elocation-id>1250</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2018.01250</pub-id><pub-id pub-id-type="pmid">30083122</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Attention alters decision criteria but not appearance: a reanalysis of Anton-Erxleben, Abrams, and Carrasco (2010)</article-title><source>Journal of Vision</source><volume>11</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/11.13.7</pub-id><pub-id pub-id-type="pmid">22072727</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname> <given-names>KA</given-names></name><name><surname>Bavelier</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Components of visual prior entry</article-title><source>Cognitive Psychology</source><volume>47</volume><fpage>333</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/S0010-0285(03)00035-5</pub-id><pub-id pub-id-type="pmid">14642288</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname> <given-names>KA</given-names></name><name><surname>Komlos</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Attention biases decisions but does not alter appearance</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1167/8.15.3</pub-id><pub-id pub-id-type="pmid">19146287</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>O</given-names></name><name><surname>Hsu</surname> <given-names>A</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Space and time in visual context</article-title><source>Nature Reviews Neuroscience</source><volume>8</volume><fpage>522</fpage><lpage>535</lpage><pub-id pub-id-type="doi">10.1038/nrn2155</pub-id><pub-id pub-id-type="pmid">17585305</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shore</surname> <given-names>DI</given-names></name><name><surname>Spence</surname> <given-names>C</given-names></name><name><surname>Klein</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Visual prior entry</article-title><source>Psychological Science</source><volume>12</volume><fpage>205</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00337</pub-id><pub-id pub-id-type="pmid">11437302</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>St John-Saaltink</surname> <given-names>E</given-names></name><name><surname>Kok</surname> <given-names>P</given-names></name><name><surname>Lau</surname> <given-names>HC</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Serial dependence in perceptual decisions is reflected in activity patterns in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>6186</fpage><lpage>6192</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4390-15.2016</pub-id><pub-id pub-id-type="pmid">27277797</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Störmer</surname> <given-names>VS</given-names></name><name><surname>McDonald</surname> <given-names>JJ</given-names></name><name><surname>Hillyard</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cross-modal cueing of attention alters appearance and early cortical processing of visual stimuli</article-title><source>PNAS</source><volume>106</volume><fpage>22456</fpage><lpage>22461</lpage><pub-id pub-id-type="doi">10.1073/pnas.0907573106</pub-id><pub-id pub-id-type="pmid">20007778</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tadin</surname> <given-names>D</given-names></name><name><surname>Lappin</surname> <given-names>JS</given-names></name><name><surname>Gilroy</surname> <given-names>LA</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Perceptual consequences of centre-surround antagonism in visual motion processing</article-title><source>Nature</source><volume>424</volume><fpage>312</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1038/nature01800</pub-id><pub-id pub-id-type="pmid">12867982</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urai</surname> <given-names>AE</given-names></name><name><surname>Braun</surname> <given-names>A</given-names></name><name><surname>Donner</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title><source>Nature Communications</source><volume>8</volume><fpage>14637</fpage><pub-id pub-id-type="doi">10.1038/ncomms14637</pub-id><pub-id pub-id-type="pmid">28256514</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Eijk</surname> <given-names>RL</given-names></name><name><surname>Kohlrausch</surname> <given-names>A</given-names></name><name><surname>Juola</surname> <given-names>JF</given-names></name><name><surname>van de Par</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Audiovisual synchrony and temporal order judgments: effects of experimental method and stimulus type</article-title><source>Perception &amp; Psychophysics</source><volume>70</volume><fpage>955</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.3758/PP.70.6.955</pub-id><pub-id pub-id-type="pmid">18717383</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wickens</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Elementary Signal Detection Theory</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195092509.001.0001</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witt</surname> <given-names>JK</given-names></name><name><surname>Taylor</surname> <given-names>JE</given-names></name><name><surname>Sugovic</surname> <given-names>M</given-names></name><name><surname>Wixted</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Signal detection measures Cannot distinguish perceptual biases from response biases</article-title><source>Perception</source><volume>44</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1068/p7908</pub-id><pub-id pub-id-type="pmid">26562253</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Supplementary models</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.43994.010</object-id><p>A simple SDT model for the asymmetric task divides the sensory axis in 3 regions delimited by <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. When the sensory evidence is lower than <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> or larger than <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the participant responds not aligned. When the sensory evidence lies between <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the participant responds aligned—in contrast to the indecision model (<xref ref-type="bibr" rid="bib12">García-Pérez and Alcalá-Quintana, 2013</xref>; <xref ref-type="bibr" rid="bib13">García-Pérez and Peli, 2014</xref>), there is not guesses in this case. The probability of choosing aligned when <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is clockwise is<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mtext>aligned</mml:mtext><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:msqrt></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>b</mml:mi><mml:mi>a</mml:mi></mml:mfrac><mml:mspace width="2em"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>a</mml:mi></mml:mfrac><mml:mspace width="2em"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>a</mml:mi></mml:mfrac><mml:mspace width="2em"/><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>a</mml:mi></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The model assumes that for one of the references (right) the criteria are symmetric <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, but not for the other reference (left). The statistical model that incorporates the two locations of the reference is thus<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>n</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number of times that the participant responds <italic>aligned</italic> and<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Ψ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This was the best model for 5 or the 32 groups (likelihood ratio tests, see Materials and methods). For two groups, assuming symmetric criteria also for the left reference <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> provided a better fit. For 24 groups, assuming the same symmetric criteria for the two locations of the reference <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was better. Finally, for one group, the best fit resulted from replacing <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> by <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43994.012</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Stüttgen</surname><given-names>Maik C</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Mainz</institution><country>Germany</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Merfeld</surname><given-names>Daniel</given-names> </name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editors’ note: a previous version of this study was rejected after peer review, but the authors submitted for reconsideration. The first decision letter after peer review is shown below.]</p><p>Thank you for submitting your work entitled &quot;Humans do not evidence choice biases in simple discrimination tasks&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Maik C Stüttgen as the Reviewing Editor and Sabine Kastner as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Daniel Merfeld (Reviewer #2).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>While the two reviewers and the reviewing editor agree that your experiments are both interesting and well described, they do not think that the paper attains the significance required for publication in <italic>eLife</italic>. Beyond the issues raised in the two original reviews, a few other concerns were identified.</p><p>First, the statement &quot;humans do not evidence choice bias in a simple perceptual task&quot; may be too general. While choice bias may be (nearly) absent in the present instantiation of the task, this may not be the case in other instantiations. The experimental procedure was rather complex, having 8 conditions intermixed in which reference stimuli had to be imagined on the left or right or top or bottom of the actual stimulus, and the response had to be selected with either the arrow keys or keys m and n (four conditions each). It was noted that the high demands of the task require subjects to deliberate more intensely than in more simple versions of the task (with e.g. one reference stimulus throughout). In a similar vein, motor biases may appear with further practice on the task.</p><p>Second, some claims are based on the absence of statistically significant effects. Demonstration of sufficient statistical power to detect moderate or small shifts in the curves are required to distinguish absence of evidence from evidence of absence, especially since, due to the large number of conditions, only a handful of trials were collected for each psychophysical curve.</p><p>Third, measuring or controlling perceptual biases is readily done using 2AFC, and it is unclear why one would use the method of single stimuli when response bias is an issue.</p><p><italic>Reviewer #1:</italic> </p><p>The manuscript describes a clever experimental technique for measuring motor biases in a prototypical psychophysical task. Measurements on 6 subjects suggest that motor biases are minor, and therefore that measured biases may have a sensory origin.</p><p>The manuscript is clear and readable, and the methods are sound. What I'm not sure about is whether the conclusion will come as a surprise to psychophysicists. However, I'm not completely in touch with the current state of the literature, having moved to a different research area, and my opinion is only worth so much.</p><p>The basic question is the following: in a task where subjects need to indicate the orientation of the target, the usual protocol is to have them press key A if the stimulus appears clockwise and key B if the stimulus appears counterclockwise. Typically we'd vary the orientation of the target, and fit a psychometric function. If we find that the point of subject equality is not at 0°, then we'd conclude that the subject's perception isn't veridical, i.e. that there's a bias in their perception of orientation.</p><p>The conclusion isn't completely bullet-proof since it could be that subjects just have a preference for one key over the other, independently of the stimulus (motor bias). My guess would be that most researchers wouldn't worry too much because:a) it's unlikely to be an overwhelming preference;b) usually it's a <italic>change</italic> in bias that's of interest (i.e. a shift in the PSE according to a certain experimental manipulation, for example by changing the contrast or the context), not an absolute level;c) the issue can be worked around completely by switching to a 2AFC design (where two stimuli are displayed, and the subject indicates which one is more tilted).</p><p>What the authors provide is a clever way of measuring the amount by which subjects do prefer key A over key B. They use to show that this bias is probably small, which I don't think would come as a surprise. They argue that the remaining bias is sensory in origin, which is fair enough.</p><p>So far what I see in this manuscript is mostly a methodological contribution. To give it a bit more content, the authors could go in at least two directions. One is to show that they can measure <italic>interesting</italic> motor biases. These do occur: I've seen mouse experiments where mice were much more willing to pull than to push a lever (or vice-versa, can't recall). Another example is that humans seem to prefer making eye movements along cardinal directions than non-cardinal ones, or at least that's what we see in free-viewing tasks.</p><p>An alternative direction is to use the methodology to actually say something interesting about sensory biases, which seems like a very interesting topic.</p><p>To sum up, at least from my point of view, the methodology is highly interesting but the data are a bit underwhelming.</p><p><italic>Reviewer #2:</italic> </p><p>This paper aims to resolve long-standing debate of identifying the source of the bias in perceptual decision-making. Here, authors manipulated the alignment between the choice categorical organization and sensory bias in order to observe each sources’ contribution to the total output bias. For instance, in the first experiment the results showed that the total bias remained the same after flipping the categorical organization while maintaining the sensory stimulus identical, thereby indicating that the primary contributor to the total bias is sensory in origin. Here, both of the choice category and sensory stimulus were symmetric (clockwise-anticlockwise). Furthermore, the second experiment was performed in order to confirm that the total bias originates from sensory bias by utilizing the asymmetric choice categories (aligned-not aligned). The results from the second experiment showed the total bias that were highly correlated with the total bias found from the first experiment, corroborating the findings from the first experiment, that the total bias is predominantly determined by the sensory bias.</p><p>The manuscript is very well written, and the finding has high scientific significance. In fact, given such clear demonstration, it seems surprising that there are no papers reporting the same or similar findings in the literature. Since this is not our primary expertise, we hope that other reviewers can confirm that this is not addressed in the literature. Obviously, we cannot ask the authors &quot;prove&quot; that no such previous reports exist but we do ask what steps the authors have taken to identify any such prior reports.</p><p>We are aware of a few recent studies showing previous stimuli impacting bias – these are sometimes referred to as after-effects. While not proving a sensory source of bias, such findings are certainly suggestive. We suggest that this be considered in the Discussion. We provide a few recent citations below but suspect that there are many other such &quot;after-effect&quot; papers in the literature.</p><p>Crane, B. T. (2012). Roll aftereffects: influence of tilt and inter-stimulus interval. Exp Brain Res, 223(1), 89-98. doi:10.1007/s00221-012-3243-0</p><p>Crane, B. T. (2012). Fore-aft translation aftereffects. Exp Brain Res, 219(4), 477-487. doi:10.1007/s00221-012-3105-9</p><p>Crane, B. T. (2012). Limited interaction between translation and visual motion aftereffects in humans. Exp Brain Res. doi:10.1007/s00221-012-3299-x</p><p>Coniglio, A. J., and Crane, B. T. (2014). Human Yaw Rotation Aftereffects with Brief Duration Rotations Are Inconsistent with Velocity Storage. J Assoc Res Otolaryngol. doi:10.1007/s10162-013-0438-4</p><p>[Editors’ note: what now follows is the decision letter after the authors submitted for further consideration.]</p><p>Thank you for submitting your article &quot;Decoupling sensory from decisional choice biases in perceptual decision making&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Daniel Merfeld (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>The present manuscript constitutes a substantially overhauled resubmission of a paper reviewed and rejected at <italic>eLife</italic> two and a half years ago. In the meantime, the authors have increased their sample size and added a second experiment, following the reviewers' advice. In consequence, results and conclusions and, accordingly, the title of the manuscript have changed. The reviewers agree that the reported experiments provide a highly interesting approach to the question of how perceptual and decisional biases can be disentangled. The manuscript itself is clear, engaging, and the results are interesting.</p><p>The conclusions have shifted from the earlier study with the addition of new subjects/studies. Using a clever and novel design (as acknowledged during the first set of reviews), the current manuscript reports that both sensory and decisional biases contribute during perceptual decision making, confirming the predominant assumption of both of these bias sources contributing to decision making. The magnitude of the perceptual bias is much larger than that of the decisional bias.</p><p>Essential revisions:</p><p>1) The authors employ the method of single stimuli. Approaches addressing both sources of bias have been proposed before with respect to 2AFC/2IFC (as mentioned in the manuscript). Although the manuscript contains some sentences contrasting these approaches, the added value of the present approach over previous ones did not become quite clear. It seems that the authors' approach is well-suited to quantify bias relative to an internal parameter such as the subjective visual vertical, while 2AFC allows to quantify relative changes in bias (e.g. between two conditions). Please expand on this issue in the revision.</p><p>Relatedly, one reviewer suggested that the authors should document in the Discussion the searches they performed and the search approach used to verify the absence of earlier contributions to the separation.</p><p>2) The authors have gone to great lengths to separate the two sources of bias, but after succeeding, they surprisingly ignore one of their main findings, which is that the magnitude of the decisional bias is considerably smaller than that of the sensory bias, which is currently not discussed at all but certainly deserves some treatment.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.43994.013</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the author responses to the first round of peer review follow.]</p><p>Thank you for considering our new manuscript to <italic>eLife</italic>. We also thank the reviewers for the analysis of the strengths and weaknesses of our previous study. Motivated by their comments, the new study has a total sample that is more than five times the size of the original one, including a newly conducted experiment. Consistent with our previous study, we found that most participants exhibited sensory biases. Unexpectedly, we found that about half of the participants also exhibited decisional biases, which were consistent with a signal detection theory model. Overall, we think that the new study makes a more clear significant contribution than our previous study to the field of perceptual decision making. What follows is a point-by-point response to the comments issued by the reviewers in our first submission.</p><disp-quote content-type="editor-comment"><p>While the two reviewers and the reviewing editor agree that your experiments are both interesting and well described, they do not think that the paper attains the significance required for publication in eLife. Beyond the issues raised in the two original reviews, a few other concerns were identified.</p><p>First, the statement &quot;humans do not evidence choice bias in a simple perceptual task&quot; may be too general. While choice bias may be (nearly) absent in the present instantiation of the task, this may not be the case in other instantiations. The experimental procedure was rather complex, having 8 conditions intermixed in which reference stimuli had to be imagined on the left or right or top or bottom of the actual stimulus, and the response had to be selected with either the arrow keys or keys m and n (four conditions each). It was noted that the high demands of the task require subjects to deliberate more intensely than in more simple versions of the task (with e.g. one reference stimulus throughout). In a similar vein, motor biases may appear with further practice on the task.</p></disp-quote><p>Motivated by the concern on statistical power raised by the reviewers (see below), we increased the sample size of the original experiment (Experiment 1) from 6 to 17 participants. Given that we now found decisional biases for many participants, we agree that our previous statement was too general.</p><p>In relation to the task demands, the concerns expressed by the reviewers encouraged us to conduct a new experiment (Experiment 2, 16 new participants) in which we manipulated the demands of the task (low and high). Like in Experiment 1, we found that many participants showed decisional biases. The manipulation of the demands of the task did not affect the proliferation of decisional biases, but we did find that in Experiment 2 there were more decisional biases than in Experiment 1. Given that the demands of the task in Experiment 1 were higher than the high demands in Experiment 2, we conclude that the demands of the task have some influence on the proliferation of decisional biases.</p><disp-quote content-type="editor-comment"><p>Second, some claims are based on the absence of statistically significant effects. Demonstration of sufficient statistical power to detect moderate or small shifts in the curves are required to distinguish absence of evidence from evidence of absence, especially since, due to the large number of conditions, only a handful of trials were collected for each psychophysical curve.</p></disp-quote><p>We agree that statistical power was an issue. Indeed, in the new study, by increasing the sample of participants, we were able to measure statistically significant decisional biases in many participants. Interestingly, we did not need to increase the number of trials to measure robust decisional biases.</p><disp-quote content-type="editor-comment"><p>Third, measuring or controlling perceptual biases is readily done using 2AFC, and it is unclear why one would use the method of single stimuli when response bias is an issue.</p></disp-quote><p>Choice biases could be controlled using a 2AFC task. But a 2AFC task, at least in the standard implementation, is a performance task that, contrary to the task with a single stimulus, cannot measure some aspects of appearance, like the sensory biases that we measured in the study. The equivalent 2AFC to our symmetric task would be a task in which two gratings are presented and the participant needs to choose which one is tilted more clockwise. Using this task one can measure the discrimination power of the participant, but not whether the perceived verticality for the participant is biased.</p><p>More elaborated versions of the 2AFC could control decisional biases if the aim is to measure sensory biases (references provided in the Discussion), and we indeed encouraged its use given that we found that decisional biases appear even in discrimination tasks that are perfectly symmetric. In addition, our study describes methods to control for decisional biases using the method of single stimuli.</p><p>We think, however, that although controlling biases is a very important aspect in the study of perception, it is also important to characterize choice biases, as they are an integral component of the perceptual decision making process.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The manuscript describes a clever experimental technique for measuring motor biases in a prototypical psychophysical task. Measurements on 6 subjects suggest that motor biases are minor, and therefore that measured biases may have a sensory origin.</p><p>The manuscript is clear and readable, and the methods are sound. What I'm not sure about is whether the conclusion will come as a surprise to psychophysicists. However, I'm not completely in touch with the current state of the literature, having moved to a different research area, and my opinion is only worth so much.</p></disp-quote><p>After largely increasing the sample size in the new study, our previous conclusion that decisional biases did not affect perceptual decision making has changed. Now, we did find decisional biases for many participants.</p><disp-quote content-type="editor-comment"><p>The basic question is the following: in a task where subjects need to indicate the orientation of the target, the usual protocol is to have them press key A if the stimulus appears clockwise and key B if the stimulus appears counterclockwise. Typically we'd vary the orientation of the target, and fit a psychometric function. If we find that the point of subject equality is not at 0°, then we'd conclude that the subject's perception isn't veridical, i.e. that there's a bias in their perception of orientation.</p><p>The conclusion isn't completely bullet-proof since it could be that subjects just have a preference for one key over the other, independently of the stimulus (motor bias). My guess would be that most researchers wouldn't worry too much because:a) it's unlikely to be an overwhelming preference;</p></disp-quote><p>In the new study, we found that for many participants the idiosyncratic preferences contributed significantly to the bias.</p><disp-quote content-type="editor-comment"><p>b) usually it's a change in bias that's of interest (i.e. a shift in the PSE according to a certain experimental manipulation, for example by changing the contrast or the context), not an absolute level;</p></disp-quote><p>We agree that very often it is the change in the bias that is of interest, but we also think that to understand perceptual decision making, it is important to understand the decisional components. Our study shows, for example, that decisional biases are not caused by guessing neither in the form of ​<italic>wild</italic>​ guessing independently of the sensory evidence nor in the form of guessing restricted to an uncertainty range.</p><disp-quote content-type="editor-comment"><p>c) the issue can be worked around completely by switching to a 2AFC design (where two stimuli are displayed, and the subject indicates which one is more tilted).</p></disp-quote><p>Please, see our response to the third general concern.</p><disp-quote content-type="editor-comment"><p>What the authors provide is a clever way of measuring the amount by which subjects do prefer key A over key B. They use to show that this bias is probably small, which I don't think would come as a surprise. They argue that the remaining bias is sensory in origin, which is fair enough.</p><p>So far what I see in this manuscript is mostly a methodological contribution. To give it a bit more content, the authors could go in at least two directions. One is to show that they can measure interesting motor biases. These do occur: I've seen mouse experiments where mice were much more willing to pull than to push a lever (or vice-versa, can't recall). Another example is that humans seem to prefer making eye movements along cardinal directions than non-cardinal ones, or at least that's what we see in free-viewing tasks.</p><p>An alternative direction is to use the methodology to actually say something interesting about sensory biases, which seems like a very interesting topic.</p><p>To sum up, at least from my point of view, the methodology is highly interesting but the data are a bit underwhelming.</p></disp-quote><p>We think that this concern is addressed in the new study because, in contrast to the previous study, we did find decisional biases. We also revealed that those were consistent with a simple signal detection theory model, but not with two guessing strategies.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] The manuscript is very well written, and the finding has high scientific significance. In fact, given such clear demonstration, it seems surprising that there are no papers reporting the same or similar findings in the literature. Since this is not our primary expertise, we hope that other reviewers can confirm that this is not addressed in the literature. Obviously, we cannot ask the authors &quot;prove&quot; that no such previous reports exist but we do ask what steps the authors have taken to identify any such prior reports.</p></disp-quote><p>As we describe in the new Introduction of the manuscript, we think that the existence of global choice biases in perceptual discrimination tasks is acknowledged and they are incorporated in current models of decision making, but we could not find evidence for a disentanglement of the sensory and decisional components in the literature.</p><disp-quote content-type="editor-comment"><p>We are aware of a few recent studies showing previous stimuli impacting bias – these are sometimes referred to as after-effects. While not proving a sensory source of bias, such findings are certainly suggestive. We suggest that this be considered in the Discussion. We provide a few recent citations below but suspect that there are many other such &quot;after-effect&quot; papers in the literature.</p><p>Crane, B. T. (2012). Roll aftereffects: influence of tilt and inter-stimulus interval. Exp Brain Res, 223(1), 89-98. doi:10.1007/s00221-012-3243-0</p><p>Crane, B. T. (2012). Fore-aft translation aftereffects. Exp Brain Res, 219(4), 477-487. doi:10.1007/s00221-012-3105-9</p><p>Crane, B. T. (2012). Limited interaction between translation and visual motion aftereffects in humans. Exp Brain Res. doi:10.1007/s00221-012-3299-x</p><p>Coniglio, A. J., and Crane, B. T. (2014). Human Yaw Rotation Aftereffects with Brief Duration Rotations Are Inconsistent with Velocity Storage. J Assoc Res Otolaryngol. doi:10.1007/s10162-013-0438-4</p></disp-quote><p>In the Discussion, we include a paragraph about how contextual cues including after-effects affects choice behavior in discrimination tasks. We include the following references about after-effects: Schwartz et al., 2007, Mather et al., 2015, Morgan et al., 2014 and Patten et al., 2015.</p><p>[Editors' note: the author responses to the re-review follow.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The authors employ the method of single stimuli. Approaches addressing both sources of bias have been proposed before with respect to 2AFC/2IFC (as mentioned in the manuscript). Although the manuscript contains some sentences contrasting these approaches, the added value of the present approach over previous ones did not become quite clear. It seems that the authors' approach is well-suited to quantify bias relative to an internal parameter such as the subjective visual vertical, while 2AFC allows to quantify relative changes in bias (e.g. between two conditions). Please expand on this issue in the revision.</p></disp-quote><p>We included a paragraph in the Discussion pointing out the differences between the method of single stimuli and the 2AFC. We also add a comparison between the method of single stimuli and the Yes-No method, which is another popular method to measure perception.</p><disp-quote content-type="editor-comment"><p>Relatedly, one reviewer suggested that the authors should document in the Discussion the searches they performed and the search approach used to verify the absence of earlier contributions to the separation.</p></disp-quote><p>We included this information in a footnote in the Introduction:</p><p>“We searched using the following keywords: choice biases, response biases, motor biases, perceptual biases and sensory biases; we identified the relevant articles and searched within the references cited; we also tracked the articles that cited the relevant articles.”</p><p>Nevertheless, given that we think that our method for searching is quite standard, we are not sure whether adding this information is very helpful.</p><p>Going through the literature again, we have found the following references that we cite in the new version of the manuscript:</p><p>We cited Witt et al., 2015, in the Models section because it makes the point that SDT cannot distinguish sensory and decisional biases (when the response mapping is not manipulated).</p><p>We cited Hermoso-Mendizabal et al., 2019, in the Introduction because proposes a model of perceptual decision-making that includes a parameter for the global bias for each individual.</p><disp-quote content-type="editor-comment"><p>2) The authors have gone to great lengths to separate the two sources of bias, but after succeeding, they surprisingly ignore one of their main findings, which is that the magnitude of the decisional bias is considerably smaller than that of the sensory bias, which is currently not discussed at all but certainly deserves some treatment.</p></disp-quote><p>In the new version of the manuscript, we include this finding in the first paragraph of the Discussion, pointing also out that the magnitude of the sensory bias was about three times larger than the magnitude of the decisional bias. We also wrote a new paragraph in the Discussion (the second paragraph) in which we provide an answer to the example presented in the Introduction and discuss possible computational mechanisms that could explain the sensory biases.</p></body></sub-article></article>