<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">05652</article-id><article-id pub-id-type="doi">10.7554/eLife.05652</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Distinct cortical codes and temporal dynamics for conscious and unconscious percepts</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-21872"><name><surname>Salti</surname><given-names>Moti</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23346"><name><surname>Monto</surname><given-names>Simo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23370"><name><surname>Charles</surname><given-names>Lucie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23371"><name><surname>King</surname><given-names>Jean-Remi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23349"><name><surname>Parkkonen</surname><given-names>Lauri</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-23374"><name><surname>Dehaene</surname><given-names>Stanislas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Cognitive Neuroimaging Unit</institution>, <institution>Institut National de la Santé et de la Recherche Médicale</institution>, <addr-line><named-content content-type="city">Gif sur Yvette</named-content></addr-line>, <country>France</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Neurospin center</institution>, <institution>Institut d'Imagerie Biomédicale</institution>, <addr-line><named-content content-type="city">Gif sur Yvette</named-content></addr-line>, <country>France</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Brain and Cognitive Sciences</institution>, <institution>Ben-Gurion University of the Negev</institution>, <addr-line><named-content content-type="city">Beer-Sheva</named-content></addr-line>, <country>Israel</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Zlotowski Center for Neuroscience</institution>, <institution>Ben-Gurion University of the Negev</institution>, <addr-line><named-content content-type="city">Beer-Sheva</named-content></addr-line>, <country>Israel</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Department of Neuroscience and Biomedical Engineering</institution>, <institution>Aalto University School of Science</institution>, <addr-line><named-content content-type="city">Espoo</named-content></addr-line>, <country>Finland</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Attention and Cognitive Control Lab Department of Experimental Psychology</institution>, <institution>University of Oxford</institution>, <addr-line><named-content content-type="city">Oxford</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff7"><label>7</label><institution>Collège de France</institution>, <addr-line><named-content content-type="city">Paris</named-content></addr-line>, <country>France</country></aff><aff id="aff8"><label>8</label><institution>University of Paris-Sud</institution>, <addr-line><named-content content-type="city">Orsay</named-content></addr-line>, <country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-6815"><name><surname>Johansen-Berg</surname><given-names>Heidi</given-names></name><role>Reviewing editor</role><aff><institution>University of Oxford</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>motisalti@gmail.com</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>21</day><month>05</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>4</volume><elocation-id>e05652</elocation-id><history><date date-type="received"><day>08</day><month>12</month><year>2014</year></date><date date-type="accepted"><day>20</day><month>05</month><year>2015</year></date></history><permissions><copyright-statement>© 2015, Salti et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Salti et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-05652-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.05652.001</object-id><p>The neural correlates of consciousness are typically sought by comparing the overall brain responses to perceived and unperceived stimuli. However, this comparison may be contaminated by non-specific attention, alerting, performance, and reporting confounds. Here, we pursue a novel approach, tracking the neuronal coding of consciously and unconsciously perceived contents while keeping behavior identical (blindsight). EEG and MEG were recorded while participants reported the spatial location and visibility of a briefly presented target. Multivariate pattern analysis demonstrated that considerable information about spatial location traverses the cortex on blindsight trials, but that starting ≈270 ms post-onset, information unique to consciously perceived stimuli, emerges in superior parietal and superior frontal regions. Conscious access appears characterized by the entry of the perceived stimulus into a series of additional brain processes, each restricted in time, while the failure of conscious access results in the breaking of this chain and a subsequent slow decay of the lingering unconscious activity.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.001">http://dx.doi.org/10.7554/eLife.05652.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.05652.002</object-id><title>eLife digest</title><p>Our senses constantly receive information from the world around us, but we consciously perceive only a small portion of it. Nonetheless, even stimuli that are not consciously perceived are registered in our brain and influence our behavior. This is known as unconscious perception.</p><p>Researchers disagree about how brain activity differs during conscious and unconscious perception. Some think that both consciously and unconsciously perceived objects are processed in the same way in the brain, but that the brain is more active during conscious perception. Others think that different neurons process the information in different types of perception.</p><p>Salti et al. have now investigated this issue. While recording participants' brain activity, a line was briefly presented in one of eight different possible locations on a screen. The line was masked so it would be consciously perceived in roughly half of the presentations. Participants had to report the location of the line and then say whether they had seen it or had merely guessed its location. Even when they reported that they were guessing, participants identified the location of the line better than by chance, indicating unconscious perception on ‘guess’ trials. This enabled Salti et al. to compare how the brain encodes consciously perceived and unconsciously perceived stimuli.</p><p>Unlike previous studies in which the brain activity associated with ‘seen’ and ‘unseen’ stimuli was compared, Salti et al. used a different approach to extract the neural activity underlying consciousness. A classifying algorithm was trained on a subset of the data to recognize from the recorded brain activity where on the screen a line had appeared. Applying this algorithm to the remaining data revealed the dynamics of stimulus encoding. Consciously and unconsciously perceived stimuli are encoded by the same neural responses for about a quater of a second. From this point on, consciously perceived stimuli benefit from a series of additional brain processes, each restricted in time. For unconsciously perceived stimuli, this chain of processing breaks and a slow decay of encoding is observed.</p><p>Salti et al., therefore, conclude that conscious perception is represented differently to unconscious perception in the brain and produces more extensive and structured brain activity. Future work will focus on understanding these differences in neural coding and their contribution to the interplay between conscious and unconscious perception.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.002">http://dx.doi.org/10.7554/eLife.05652.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>conscious perception</kwd><kwd>neuroimaging</kwd><kwd>MEG</kwd><kwd>EEG</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003135</institution-id><institution>Fondation Fyssen</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Salti</surname><given-names>Moti</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council (ERC)</institution></institution-wrap></funding-source><award-id>NeuroConsc</award-id><principal-award-recipient><name><surname>Dehaene</surname><given-names>Stanislas</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006021</institution-id><institution>Direction Générale de l'Armement</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>King</surname><given-names>Jean-Remi</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.3</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Stimuli are encoded differently in the brain when perceived consciously and unconsciously; for conscious perception, the representations are stronger in certain brain regions and they display more complex dynamics.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The scientific investigation of consciousness divides into two major branches (<xref ref-type="bibr" rid="bib27">Koch, 2004</xref>; <xref ref-type="bibr" rid="bib11">Dehaene et al., 2014</xref>). The first branch, which studies the ‘state of consciousness’, focuses on general vigilance or a person's ability to perceive, interact, and communicate with the environment, by examining the regulation of sleep and waking, and their pathological disruption by coma, epilepsy, and sleep disorders (<xref ref-type="bibr" rid="bib35">Laureys et al., 2004</xref>). The second branch of inquiry, which studies ‘access to consciousness’, focuses on the processes that make a specific content subjectively experienced—what differences in brain activity distinguish conscious vs unattended or subliminal stimuli (<xref ref-type="bibr" rid="bib10">Dehaene et al., 2006</xref>). To a large extent, both endeavors rely on characterization of the neural activity that underlies the conscious state or conscious perception, and they are traditionally approached in a similar manner (<xref ref-type="bibr" rid="bib6">Dehaene and Changeux, 2011</xref>). In order to examine the neuronal processes that underlie conscious states, the neuronal activity associated with one state of consciousness (e.g., sleep) is compared to another (e.g., awake). Similarly, in order to extract the neural correlates of conscious perception, threshold-level stimuli are presented to the subject such that they are sometimes consciously perceived and sometimes not. Trials are then sorted according to their subjective perception (‘Seen’ or ‘Unseen’), and the neurophysiological signatures associated with these categories are contrasted to extract the correlates of consciousness perception.</p><p>Such paradigms have yielded convergent findings (<xref ref-type="bibr" rid="bib27">Koch, 2004</xref>; <xref ref-type="bibr" rid="bib6">Dehaene and Changeux, 2011</xref>; <xref ref-type="bibr" rid="bib11">Dehaene et al., 2014</xref>), but they have also been criticized on several grounds (<xref ref-type="bibr" rid="bib1">Aru et al., 2012</xref>). First, differences in neural activity may stem from physical differences in the stimuli. To control this, many experiments now employ identical stimuli and rely on participants' subjective reports to differentiate seen and unseen conditions. Even then, stimuli also differ in their depth of processing: performance is typically much higher for conscious trials (<xref ref-type="bibr" rid="bib33">Lau and Passingham, 2006</xref>), and several operations may only be feasible in the conscious state (<xref ref-type="bibr" rid="bib51">Sackur and Dehaene, 2009</xref>; <xref ref-type="bibr" rid="bib32">De Lange et al., 2011</xref>). The main effect of seen vs unseen trials may, therefore, reveal processing differences unrelated to the actual cerebral encoding of a conscious or unconscious stimulus, and reflecting solely, the operations that precede follow or even coincide with conscious access (<xref ref-type="bibr" rid="bib1">Aru et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Pitts et al., 2012</xref>; <xref ref-type="bibr" rid="bib16">Frässle et al., 2014</xref>; <xref ref-type="bibr" rid="bib46">Pitts et al., 2014</xref>).</p><p>Another limitation is that these paradigms do not isolate the brain mechanisms underlying the conscious representation of a specific content (<xref ref-type="bibr" rid="bib22">Haynes, 2009</xref>). The broad contrast between brain activity on ‘seen’ vs ‘unseen’ trials may include generic processes of attention, alerting, or reporting that should be carefully kept distinct from the more limited set of processes that represent the current mental content. For instance, the late P3 component of event-related potentials, which is a frequent signature of conscious perception (<xref ref-type="bibr" rid="bib6">Dehaene and Changeux, 2011</xref>), has been proposed to reflect either a non-specific alerting effect arising from noradrenergic neurons of the locus coeruleus (<xref ref-type="bibr" rid="bib41">Nieuwenhuis et al., 2005</xref>) or the activation of generic reporting processes unnecessary to conscious perception itself (<xref ref-type="bibr" rid="bib45">Pitts et al., 2012</xref>, <xref ref-type="bibr" rid="bib47">2014</xref>). To resolve this issue, it is necessary to identify which patterns of brain activity, unique to conscious trials, faithfully encode the contents of subjective experience and to separate them from other non-specific brain responses (<xref ref-type="bibr" rid="bib22">Haynes, 2009</xref>).</p><p>The presence or absence of additional information is a crucial feature that separates major theories of conscious access. Some theories propose that subjective experience emerges from a generic pattern of brain activity without any stimulus-specific change (<xref ref-type="bibr" rid="bib34">Lau and Rosenthal, 2011</xref>). According to these models, the cognitive representation of a stimulus is built during unconscious perception, and the additional activity that gives rise to consciousness tags it as ‘perceived’ but adds no perceptual or coding benefit. Conversely, other models (<xref ref-type="bibr" rid="bib9">Dehaene et al., 2003</xref>, <xref ref-type="bibr" rid="bib10">2006</xref>) suggest that conscious perception relies on a massive amplification and cortical broadcasting of stimulus-specific information. The Global Neuronal Workspace (GNW) model asserts that perceptual stages may unfold identically on conscious and non-conscious trials, but that, when a stimulus gains access to consciousness, stimulus-specific information is amplified and re-encoded in additional areas, including a prefrontal–parietal network. This ‘workspace’ maintains the information online and dispatches it to additional processors, thus making the stimulus reportable. This view predicts that, ceteris paribus, additional stimulus information should be present on conscious trials. Finally, theories that associate conscious perception with posterior visual loops (<xref ref-type="bibr" rid="bib30">Lamme, 2006</xref>) or with the integration of information into a coherent whole (<xref ref-type="bibr" rid="bib42">Oizumi et al., 2014</xref>) are agnostic with respect to this issue: although greater reverberation or integration may cause an amplification of neuronal activity, (<xref ref-type="bibr" rid="bib14">Fahrenfort et al., 2012</xref>) it could also, on the contrary, lead to diminished or sparser activity due to the greater predictability of the distributed brain signals being integrated (<xref ref-type="bibr" rid="bib17">Friston, 2005</xref>).</p><p>In summary, for both empirical and theoretical reasons, it is essential to study the temporal propagation of conscious vs unconscious information in the brain and to probe the presence of additional stimulus-specific cortical codes on seen trials relative to unseen trials, while excluding any difference in perception and behavior. To fulfill this demanding agenda, we used time-resolved MEG and EEG recordings to track the internal representation of a flashed stimulus under visible and invisible conditions. This strategy was made possible by advances in multivariate decoding, which can detect stimulus-specific information in brain activity, and evaluate its localization (<xref ref-type="bibr" rid="bib23">Kamitani and Tong, 2005</xref>; <xref ref-type="bibr" rid="bib21">Haynes and Rees, 2006</xref>; <xref ref-type="bibr" rid="bib22">Haynes, 2009</xref>) and its time course (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>). We chose visual location as the decoded parameter of the stimulus, because multiple macroscopic retinotopic maps are present throughout the human brain, including the frontal lobe (<xref ref-type="bibr" rid="bib53">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib20">Hagler and Sereno, 2006</xref>), and therefore, the full cortical processing stream of this parameter should be more easily decodable than other more microscopic parameters, such as object identity. To further address the concern of differences in processing depth, we placed ourselves under ‘blindsight’ conditions by asking subjects to perform a forced-choice location task in which performance was excellent even on subjectively invisible trials. Selecting only the correct trials allowed us to compare visible and invisible trials with identical stimuli and responses (<xref ref-type="bibr" rid="bib31">Lamy et al., 2009</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We recorded Magnetoencephalography (MEG) and Electroencephalography (EEG) while presenting the subjects with a tilted line segment at one of eight possible locations arranged circularly around the fixation point. The target was followed by a mask whose contrast was adjusted individually for each participant to ensure conscious perception on roughly half of the trials. In each trial, participants provided three separate behavioral responses: 1) an immediate forced-choice localization of the target, 2) whether their first response was correct or not, and 3) whether they saw the target or not (see <xref ref-type="fig" rid="fig1">Figure 1A</xref> and ‘Materials and methods’). Participants were instructed to report the target as unseen only if they had no perception at all regarding its location. If they did not see the target they were asked to guess its location (response 1).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.05652.003</object-id><label>Figure 1.</label><caption><title>Experimental design and behavioral results.</title><p>(<bold>A</bold>). Sequence of events presented on a trial. Subjects attempted to localize a brief target, which could appear at one of eight locations. Mask contrast was adjusted to ensure ∼50% of unseen trials. On 1/9 of trials, the target slide was replaced by a blank slide (target-absent trial). (<bold>B</bold>) Behavioral confusion matrices describing the distribution of responses for each spatial location when target was seen (left matrix) or unseen (right matrix). A strong diagonal on unseen trials indicates blindsight.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.003">http://dx.doi.org/10.7554/eLife.05652.003</ext-link></p></caption><graphic xlink:href="elife-05652-fig1-v2.tif"/></fig></p><p>Behaviorally, subjects reported seeing 62.4 ± 3.62% (mean ± sem) of presented targets, and the accuracy (i.e., reporting the correct location) in these trials was 86.6 ± 2.54%. Performance in the unseen trials was 50.7 ± 6.4% correct, the way higher than the chance level of 12.5% (t(11) = 5.73, p &lt;0 0.001), indicating blindsight. At all eight stimulated locations, the dominant response was to correctly point to that location, even on unseen trials (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Those ‘unseen–correct’ trials thus provide a minimal contrast with ‘seen–correct’ trials. Mean localization Respone Times (RTs) were 812.2 ± 44 ms. Localization RTs for different critical conditions were as follow: 701.4 ± 35 ms for ‘Seen–Correct’ trials, 878.1 ± 78 ms for ‘Unseen–Correct’ trials, and 1110 ± 101 ms for ‘Unseen-incorrect’ trials.</p><sec id="s2-1"><title>Time course of location decoding</title><p>To track the cortical representation of the target location through time, we trained multivariate pattern classifiers separately at every time sample to predict the target location from the recorded brain signals (see ‘Materials and methods’). For each time sample, we extracted classifiers' calibrated posterior probabilities (<xref ref-type="bibr" rid="bib48">Platt, 1999</xref>) associated with the eight spatial locations. We first trained the classifiers on all trials, regardless of participants' responses. <xref ref-type="fig" rid="fig2">Figure 2A</xref> depicts the classifiers' assigned probability for the correct target location as a function of time. Four stages could be distinguished (this division will be used throughout our analyses). In a first stage (0–115 ms post stimulus), classification probability was at chance (0.1251 ± 0.0001; mean ± sem), t &lt; 1. From 115 to 162 ms, decoding probability rose above chance and peaked sharply at 147 ms post stimuli (0.141 ± 0.0028), t(11) = 5.9, p &lt; 0.0001. Then came a transition period (162–271 ms) with reduced but still significant decoding (0.137 ± 0.0023), t(11) = 5.48, p &lt; 0.0001. Finally, in a fourth stage (271–800 ms), decoding probability rose again and remained above chance for about 500 ms (0.157 ± 0.0083), t(11) = 3.8, p &lt; 0.0001.<fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.05652.004</object-id><label>Figure 2.</label><caption><title>Time course of location information.</title><p>(<bold>A</bold>). Average posterior probability of a correct classification of target location, as a function of time. Chance = 12.5% (1/8). Decoding confusion matrices are shown at the two decoding peaks. (<bold>B</bold>) Same data sorted as a function of subjective visibility (seen/unseen) and objective localization performance (correct/incorrect). The lower part shows the time course of average classifier probability as a function of distance between the decoded and actual target location.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.004">http://dx.doi.org/10.7554/eLife.05652.004</ext-link></p></caption><graphic xlink:href="elife-05652-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.005</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Event-Related Fields and potentials for ‘Seen–Correct’ vs ‘Unseen–Correct’.</title><p>ERF and ERP components time windows were determined according to the global field power (upper panel). Two time windows were chosen; on each time window, cluster analysis was performed. In the 296–332 ms time window, Magnetometers showed a significant cluster (p = 0.025). EEG electrodes exhibited a significant cluster on the 300–600 ms time window p = 0.02.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.005">http://dx.doi.org/10.7554/eLife.05652.005</ext-link></p></caption><graphic xlink:href="elife-05652-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Event-Related Fields and potentials for ‘UnSeen–Correct’ vs ‘Unseen–InCorrect’.</title><p>ERF and ERP components time windows were determined according to the global field power (upper panel). Two time windows were chosen; on each time window, cluster analysis was performed. No significant differences were found.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.006">http://dx.doi.org/10.7554/eLife.05652.006</ext-link></p></caption><graphic xlink:href="elife-05652-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.007</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Classifying visibility.</title><p>The black line portrays the mean classification probability of classifier trained to classify ‘Seen–Correct’ and ‘Unseen–Correct’. The lighter line portrays classifier trained on the dataset with shuffled classes. In the 270–800 ms time window, mean classification probability (0.503 ± 0.001) was slightly higher than chance (0.5) t(11) = 2.45, p = 0.03. Shuffled trials classification probability (0.498 ± 0.001) did not differ from chance t(11) = 2.11, p = 0.057.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.007">http://dx.doi.org/10.7554/eLife.05652.007</ext-link></p></caption><graphic xlink:href="elife-05652-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.008</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Controls for eye movements and motor-based decoding.</title><p>(<bold>A</bold>) Average posterior probability of a correct classification of target location, across time, separately for ‘Seen–Correct’ and ‘Unseen–Correct’ trials, for classifiers trained on EOG channels only. Eye-based decoding is much lower than with the full set of sensors and, crucially, does not differentiate seen and unseen trials. Classification rose above chance 256 ms post stimuli and went back to chance 1000 ms post stimuli. Importantly, within this time frame, classification for ‘Seen–Correct’ (0.135 ± 0.001) and ‘Unseen–Correct’ (0.134 ± 0.001) did not differ <italic>t</italic>(11) &lt; 1. (<bold>B</bold>) Average posterior probability of a correct classification of the manual response on target-absent trials, across time. Classifiers were trained on target's location in valid trials and tested on responses in absent trials. A flat curve indicates that target location decoding reported in the results section did not rely on motor preparation and execution information.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.008">http://dx.doi.org/10.7554/eLife.05652.008</ext-link></p></caption><graphic xlink:href="elife-05652-fig2-figsupp4-v2.tif"/></fig></fig-group></p></sec><sec id="s2-2"><title>Decoding on seen and unseen trials</title><p>We next examined how classifier performance varied with the subject's report and performance (See <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Our behavioral procedure allowed us to differentiate between two levels of processing in the ‘Unseen’ category: ‘Unseen–Correct’ trials where the response contained genuine location information, and ‘Unseen-Incorrect’ in which it did not. Remarkably, even in the latter trials, where behavioral evidence did not indicate any processing of stimuli, posterior probabilities for decoding spatial information were higher than chance even in the latest time window (0.143 ± 0.005), t(11) = 3.37, p &lt; 0.01. This result is striking for two reasons; first, it allows us to broaden the concept of blindsight as observed in V1 lesioned patients (<xref ref-type="bibr" rid="bib63">Weiskrantz, 1996</xref>) and monkeys (<xref ref-type="bibr" rid="bib5">Cowey and Stoerig, 1995</xref>) or induced in normal subjects (<xref ref-type="bibr" rid="bib31">Lamy et al., 2009</xref>). In blindsight, above-chance forced-choice behavior indicates that the observer perceived the stimuli, even though he denies any subjective perception. Here we can see that, even when subjects fail to perform the forced-choice task, their brain still perceived and retained the spatial information. Although unconscious perception is considered as transient and short-lived (<xref ref-type="bibr" rid="bib50">Rossetti, 1998</xref>), here we see that even with the lowest end of perception, spatial information is encoded for up to 800 ms.</p><p>Nonetheless, the dynamics of classification probability associated with ‘Unseen–Correct’ and ‘Unseen-Incorrect’ were not identical; they shared the same classification probability for the first three stages but diverged in the fourth stage (271–800 ms) where the mean classification probability was higher for ‘Unseen–Correct’ (0.155 ± 0.009) than for ‘Unseen–Incorrect’ (0.143 ± 0.005). These results indicate, unsurprisingly perhaps, that additional information about location is available in the brain on trials in which subjects responded correctly than in trials in which they did not.</p><p>The main aim of this paper was to track the temporal dynamics of neuronal encoding of consciously and unconsciously perceived spatial information, that is, the differences between ‘Seen–Correct’ and ‘Unseen–Correct’, which were strictly identical in terms of both stimuli and responses. ‘Seen–Correct’ and ‘Unseen–Correct’ trials did not differ in classification probability during the first three stages but diverged only during the fourth stage (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Mean classification probability between 272–800 ms was higher for ‘Seen–Correct’ trials (0.162 ± 0.009) than for ‘Unseen–Correct’ (0.155 ± 0.009), t(11) = 2.93, p = 0.014. This difference survived correction for correct responses produced by chance (<xref ref-type="bibr" rid="bib31">Lamy et al., 2009</xref>) in the ‘Unseen–Correct’ condition. Classification was higher for ‘Seen–Correct’ trials (0.162 ± 0.009) than for ‘Unseen–Correct<sub>ChanceCorrected</sub>’ (0.157 ± 0.009), t(11) = 2.93, p = 0.029 (one-tailed).</p></sec><sec id="s2-3"><title>Relation to previous findings from event-related responses</title><p>Our fourth time window, where significantly improved location decoding was observed on seen compared to unseen trials, corresponds to the timing of N2 and especially P3 event-related potentials, which several past studies using the traditional contrast of ‘Seen’ vs ‘Unseen’ unseen trials have associated to conscious perception (see <xref ref-type="bibr" rid="bib6">Dehaene and Changeux, 2011</xref> for review). To examine whether our study replicated those findings, we compared the event related potentials (ERP) - event related fields (ERF) signatures of our critical conditions (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). We tracked the components by computing Global Field Power and applied cluster analysis across channels. While the ‘Unseen–Correct’ vs ‘Unseen-Incorrect’ did not yield any significant difference in evoked responses, the ‘Seen–Correct’ vs ‘Unseen–Correct’ did: MEG magnetometers showed different activities in the N2 time window, while EEG electrodes showed a difference in the P3 time window, with the appropriate topography (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Thus, these late events again appear as correlates of conscious perception. Unsurprisingly, ERP-ERF analysis revealed a slightly different temporal pattern than the dynamics revealed with the multivariate classification, because the former corresponds to a search for generic brain states allowing or not allowing content to access consciousness, while the latter corresponds to a search for brain states encoding a specific consciously perceived content.</p><p>Training a classifier to use those event-related responses in order to separate ‘Seen–Correct’ vs ‘Unseen–Correct’ trials yielded a modest but significant classification success, again based on the late part of the epoch (see <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Our results suggest that, in the present experiment, M/EEG recordings are dominated by content-specific information about location, both on seen and on unseen trials, while it is more difficult to train a generic decoder for seen/unseen trials that cuts across all such contents. It also should be noted that this experiment was not optimally designed for such an analysis. In order to restrict classifier to using attributes that are related exclusively to visibility and not to stimuli location, we equated the number of trials representing specific stimulus location in the ‘Seen–Correct’ and the ‘Unseen–Correct’ location. This reduced the number of trials on which decoder was trained on and affected classification results.</p></sec><sec id="s2-4"><title>Controls for hand and eye movements</title><p>Because there was a fixed mapping between stimulus location and motor responses (made using four fingers of each hand), the decoding of location could conceptually be based on conscious motor codes. To evaluate this possibility, we performed a control analysis in which we applied the decoder to target absent trials in which no stimulus appeared, but subjects still had to produce a response. Classification of subjects' responses in these trials was at chance, indicating that the previous decoder focused strictly on stimulus-based location information (see <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). Although it remains possible that conscious response planning modulates the late stages of location processing, several aspects of our experiments argue against a contribution of motor codes to our results. In terms of experimental design, our main analyses focused on trials in which the decoder was trained to extract the objective location of the target on all trials, errors included. Thus, the above-chance extraction of the objective target location on ‘Unseen-Incorrect’ trials is not likely to reflect motor code, nor can the improved classification performance for ‘Seen–Correct’ over ‘Unseen–Correct’, since those trials involve exactly the same stimuli and responses.</p><p>Another control analysis evaluated the role of microsaccades. Although eye movements were carefully removed with principal component analysis (PCA), it could be suggested that residual ocular activity in the MEG/EEG (MEEG) signal governed the classification of spatial location. Residual eye movement artifacts, if present, should primarily affect the anterior eye channels. To test this possibility, we examined the dynamics of classification on electro-oculograms (EOG) channels alone. Classification revealed a different temporal pattern of classification that was observed with the full MEEG classification: above-chance location decoding started only around 250 ms, remained much lower that with the whole data set (∼14%, where chance = 12.5%), and crucially, did not discriminate between the seen and unseen trials (see <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>), suggesting that eye movements did not play a dominant role in the above decoding results. Source localization (see below) is also incompatible with a single eye movement artifact.</p></sec><sec id="s2-5"><title>Asymmetrical generalization of decoding</title><p>Our basic analysis indicated that consciously perceived stimuli are coded more reliably than unconscious ones, but the nature of this difference could not be completely appreciated from this analysis. ‘Seen–Correct’ trials were more numerous than ‘Seen-incorrect’ trials, and this factor alone could perhaps explain why they were more efficiently decoded. In this case, if conscious and unconscious codes differ, then training specifically on unconscious trials should revert the pattern and yield better decoding on unseen compared to seen trials. The GNW model (<xref ref-type="bibr" rid="bib9">Dehaene et al., 2003</xref>), however, makes a different prediction concerning the asymmetry of decoding on seen and unseen trials. Specifically, the model predicts that all the processing stages present on unseen trials should continue to be observed on seen trials, while the converse should not be true: on seen trials, there should be brain activity encoding the perceived stimulus within the GNW and not present on unseen trials.</p><p>We examined these two options by testing for cross-condition generalization: we trained the decoder on a subset of trials (either the unseen–correct trials, or the seen–correct trials) and then tested for generalization, either to left-out trials within the same category or to trials belonging to the other category. One technical difficulty was that, since the experimental conditions were defined by subjects' responses, the number of trials at each location was no longer balanced within each of these conditions, and this imbalance affected the pre-stimulus bias of the 8-category classifier as well as its capacity to generalize. To address this problem, we turned to a simpler binary classifier, which was trained to simply sort the stimuli into left-hemifield vs right-hemifield stimuli. Within each subject, we matched the number of trials in these two classes and also selected equal numbers of seen–correct and unseen–correct trials. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows that this binary decoder, now operating with a chance level of 50%, still performed above chance with approximately the same time course as the 8-location decoder.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.05652.009</object-id><label>Figure 3.</label><caption><title>Asymmetrical cross-condition generalization.</title><p>A classifier trained in one condition and then tested on new data either from the same condition or the other condition (e.g. trained on ‘Seen–Correct’ trials and tested on new ‘Seen–Correct’ trials and ‘Unseen–Correct’ trials). To equalize the number of trials, the classifier was trained to discriminate left- vs right-hemifield targets, hence chance = 50%.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.009">http://dx.doi.org/10.7554/eLife.05652.009</ext-link></p></caption><graphic xlink:href="elife-05652-fig3-v2.tif"/></fig></p><p>The end result demonstrated the predicted asymmetry. When trained on ‘Unseen–Correct’ trials, classification generalized identically to ‘Seen–Correct’ trials, but when trained on ‘Seen–Correct’ trials, classification performance dropped when tested on ‘Unseen–Correct’ (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This effect was apparent in two time windows, the third time window (178–225 ms; average classification probability for ‘Seen–Correct’ = 0.526 ± 0.0064; for ‘Unseen–Correct’ = 0.515 ± 0.005; t(11) = 2.8, p = 0.017), and the fourth late time window (272–800 ms; ‘Seen–Correct’ = 0.575 ± 0.017; ‘Unseen–Correct’ = 0.547 ± 0.016; t(11) = 2.44, p = 0.032). These analyses indicate that seen–correct trials contained the same decodable stimulus information as unseen–correct trials, plus additional information unique to conscious trials.</p></sec><sec id="s2-6"><title>Decoding cortical sources</title><p>The GNW model predicts that the additional information associated with conscious representation should be jointly encoded in a network of distributed prefrontal and parietal regions. In order to assess the contribution of these brain areas to the encoding of consciously perceived contents, we modeled the brain activity in 68 regions of interest covering the whole cortex (See ‘Materials and methods’) and re-trained our decoders using just the distributed source signals from these regions. The results with eight output classes (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) confirmed the existence of two main stages: an early one (∼100–200 ms) where location information was essentially confined to occipital, ventral visual, and lateral and mesial parietal regions, and a later one (&gt;250 ms) where it became highly distributed to multiple cortical areas, particularly in prefrontal and anterior cingulate cortex (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). To avoid an unnecessary increase in the number of statistical tests, we confined the subsequent analyses of seen and unseen trials, to four a priori regions of interest covering all areas of the dorsal visual pathway containing retinotopic maps for location (<xref ref-type="bibr" rid="bib53">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib20">Hagler and Sereno, 2006</xref>): pericalcarine, superior parietal cortex, rostral medial frontal cortex, and superior-lateral frontal cortex. We then repeated the generalization across conditions and procedures. This region-based decoding revealed the activation of successive spatial codes (<xref ref-type="fig" rid="fig4">Figure 4</xref>): both pericalcarine and superior parietal cortices contained decodable information as early as 115 ms post stimuli ([0.519 ± 0.005], t(11) = 3.82 p = 0.0028 and [0.516 ± 0.003], t(11) = 4.52 p &lt; 0.0001, respectively). The two frontal areas revealed a more delayed pattern as the curve associated with superior frontal cortex showed first above-chance decoding only after 194 ms (0.504 ± 0.001), t(11) = 2.33 p = 0.0396 and rostral medial frontal as late as 365 ms.<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.05652.010</object-id><label>Figure 4.</label><caption><title>Source-based decoding and cross-condition generalization.</title><p>Classifiers were trained as in <xref ref-type="fig" rid="fig3">Figure 3</xref>, but using a restricted subset of cortical sources: pericalcarine (<bold>A</bold>), superior parietal (<bold>B</bold>), rostro-medial frontal (<bold>C</bold>), or superior frontal (<bold>D</bold>). Note, how asymmetrical cross-condition generalization (right columns, same format as <xref ref-type="fig" rid="fig3">Figure 3</xref>) successively arises in visual cortex, then superior parietal, and superior frontal regions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.010">http://dx.doi.org/10.7554/eLife.05652.010</ext-link></p></caption><graphic xlink:href="elife-05652-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.011</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Time course of location information for the different cortical sources.</title><p>Average posterior probability of a correct classification of target location, as a function of time for in 68 regions of interest. Chance = 12.5% (1/8).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.011">http://dx.doi.org/10.7554/eLife.05652.011</ext-link></p></caption><graphic xlink:href="elife-05652-fig4-figsupp1-v2.tif"/></fig></fig-group></p><p>Only two of the chosen regions, superior frontal and superior parietal cortices, demonstrated the asymmetry between seen and unseen trials obtained with sensor-based decoding. In both cases, when trained on activity restricted to the superior frontal regions, a complete generalization obtained when trained on ‘Unseen–Correct’ but when trained on ‘Seen–Correct’ trials, decoding probability dropped for ‘Unseen–Correct’ in the fourth time window. Classification probability was significantly higher for ‘Seen–Correct’ (0.552 ± 0.017) than for the ‘Unseen–Correct’ trials (0.541 ± 0.017), t(11) = 2.35, p = 0.038. In the superior parietal cortex, when trained on ‘Unseen–Correct’ trials, asymmetry was apparent in all time windows: classifiers generalize completely for ‘Seen–Correct’ trials (<xref ref-type="fig" rid="fig4">Figure 4</xref>) but when trained on ‘Seen–Correct’ trials and tested on ‘Unseen–Correct’, posterior probabilities dropped. In the second window classification, probability was significantly higher for ‘Seen–Correct’ (0.534 ± 0.007) than for the ‘Unseen–Correct’ trials (0.525 ± 0.006), t(11) = 2.5, p = 0.026. In the third time window, ‘Seen–Correct’ decoding probability was higher than ‘Unseen–Correct’ ([0.537 ± 0.008] [0.523 ± 0.01], t(11) = 2.3, p = 0.036). This pattern was kept in the fourth time window, as ‘Seen–Correct’ decoding probability (0.559 ± 0.011) was higher than ‘Unseen–Correct’ decoding probability (0.545 ± 0.01), t(11) = 3.9, p = 0.002.</p><p>These findings go beyond the distinction of conscious and unconscious processing and allow us to demonstrate a representation of stimulus location outside visual areas. Above-chance classification could be achieved in all regions, including superior parietal, rostral middle frontal, and superior frontal regions, supporting the prior finding that these regions contain retinotopic maps (<xref ref-type="bibr" rid="bib53">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib20">Hagler and Sereno, 2006</xref>). Importantly, however, our results show that there is no specific region uniquely dedicated to the encoding of consciously perceived information. Instead, a better encoding on seen trials is obtained in the same overall sectors of the superior parietal cortex and superior frontal cortex that also contain location information on unseen–correct trials (i.e., blindsight trials). Again, the key difference is asymmetrical generalization, indicating the presence of superior encoding of spatial information on seen trials, only in dorsal parietal and frontal regions. This pattern primarily occurs in the late time window (beyond 270 ms), but it is already present at early stages of processing in the superior parietal cortex.</p></sec><sec id="s2-7"><title>Generalization across time</title><p>According to the GNW model, conscious access corresponds to an amplification and broadcasting of the selected information. Conscious processing is, therefore, predicted to consist in a series of information-processing stages, each associated with the settling of brain activity into a temporary metastable state (stable for a duration of ∼100–300 ms), which allows the information to be flexibly transmitted to the appropriate specialized processors (<xref ref-type="bibr" rid="bib11">Dehaene et al., 2014</xref>). The series of processing stages may differ as a function of task demands and may include verbal report (<xref ref-type="bibr" rid="bib16">Frässle et al., 2014</xref>), executive control (<xref ref-type="bibr" rid="bib61">Van Gaal et al., 2010</xref>), or meta-cognitive evaluation (<xref ref-type="bibr" rid="bib4">Charles et al., 2014</xref>). On unconscious trials, the accumulation of incoming activation would fail to attain the critical threshold level needed to trigger such a discrete series of stages (‘failed ignition’), and the unconscious information would, therefore, decay over a period of a few hundreds of milliseconds (<xref ref-type="bibr" rid="bib7">Dehaene and Naccache, 2001</xref>).</p><p>To evaluate those predictions concerning the dynamics and transient stability of internal codes, we used the temporal generalization method (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>). This method consists in probing if a classifier trained at a certain time point <italic>t</italic> can generalize to other time points, <italic>t′</italic>. If the representation is stable, the classifier should remain efficient even if applied at a different latency. If, however, the information is successively re-encoded in a series of different brain systems, then we should see a failure of generalization beyond a certain temporal duration (i.e., away from the diagonal where <italic>t</italic> = <italic>t′</italic>) (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>). We, therefore, quantified the endurance of conscious and unconscious representations by training and testing classifiers on all pairs of time samples (<italic>t,t′</italic>). To measure a classifier's durability independently of classification efficacy, we defined Classification Endurance (CE), as the number of samples forward and backward in time, for which decoding performance remained above 50% of its level at the original training time (t = t′)—that is, the decoder's half-life time.</p><p>Matrices of temporal generalization (<xref ref-type="fig" rid="fig5">Figure 5</xref>) indicated that, up to 272 ms, decoding was narrowly restricted to the diagonal for both seen and unseen trials, suggesting a fast-changing chain of perceptual processes (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>) consistent with a feedforward propagation of unconscious location information. Beyond this point and up to ∼800 ms post stimulus, classifiers generalized to a wider neighborhood of latencies, consistent with the entry of information into evidence accumulation systems with longer time constants. The generalization pattern was examined using an analysis of variance conducted on CE in the 272–800-ms time window with factors of Visibility (Seen/Unseen), Direction (Forward/Backward in time), and Timeframe (5 successive time windows) (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for statistics). All main effects and their interactions were significant. On average, CE was larger for generalization forward than for generalization backward and also increased in time. We were mainly interested in the different generalization patterns of the ‘Seen–Correct’ and ‘Unseen–Correct’ trials. Surprisingly, generalization was more extended in time for unseen trials. Forward generalization showed a larger CE in unseen trials compared to seen trials (mean = 382 ms vs 201 ms, p &lt; 0.005), and the same pattern was apparent for backward generalization to a lesser extent (mean = 159 ms vs 78 ms, p &lt; 0.05) (see <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> for statistics). Furthermore, in the forward direction, these differences interacted with time. Forward CE was constant in seen trials, while for the unseen trials, it was linearly decreasing with time. Backward CE did not differ for seen and unseen trials, but increased steadily as a function of time (see <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref> for statistics).<fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.05652.012</object-id><label>Figure 5.</label><caption><title>Generalization of location decoding over time.</title><p>8-location classifiers trained at a specific time were then tested on data from all other time points. (<bold>A</bold>) Average classification probability as a function of testing time for each training time (the diagonal, where testing time = training time, gives the curve for classical decoder performance over time). (<bold>B</bold>) Same information plotted as a function of temporal distance from training time (positive or negative), with asterisks indicating the Classification Endurance (CE) measure. (<bold>C</bold>) Tentative model of a sequence of brain activations, which could yield the observed generalization matrices.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.012">http://dx.doi.org/10.7554/eLife.05652.012</ext-link></p></caption><graphic xlink:href="elife-05652-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.013</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Analysis of variance (ANOVA) on Classification Endurance (CE).</title><p>The table gives the statistics and significance values for the main effects of Visibility (Seen–Correct vs Unseen–Correct), Direction of generalization (forward, backward), and Timeframe (5 levels), as well as their interactions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.013">http://dx.doi.org/10.7554/eLife.05652.013</ext-link></p></caption><graphic xlink:href="elife-05652-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.014</object-id><label>Figure 5—figure supplement 2.</label><caption><title>ANOVAs on CE with factors of Visibility (Seen–Correct vs Unseen–Correct) and Timeframe (5 levels), separately for forward and backward generalization.</title><p>(<bold>A</bold>) Forward generalization (<bold>B</bold>) Backward generalization.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.014">http://dx.doi.org/10.7554/eLife.05652.014</ext-link></p></caption><graphic xlink:href="elife-05652-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.05652.015</object-id><label>Figure 5—figure supplement 3.</label><caption><title>Significance Values of the Effect of Timeframe (5 levels) for forward and backward generalization in Seen and unseen trials.</title><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.05652.015">http://dx.doi.org/10.7554/eLife.05652.015</ext-link></p></caption><graphic xlink:href="elife-05652-fig5-figsupp3-v2.tif"/></fig></fig-group></p><p><xref ref-type="fig" rid="fig5">Figure 5C</xref> shows a possible theoretical interpretation consistent with those results. The high level of decoding observed on seen trials, over a long time window of ∼270–800 ms, combined with a low level of off-diagonal temporal generalization beyond a fixed horizon of ∼160 ms, implies that a conscious location is successively encoded by a series of about four distinct stages, each terminating relatively sharply after a processing duration of ∼160 ms. Conversely, the lower decoding level and longer endurance observed for unconsciously perceived stimuli indicate that they do not enter into the same processing chain. The square pattern of the temporal generalization matrix on unseen trials (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) suggests that unconscious information lingers in a single representational state, which decays slowly over time, thus yielding a paradoxically longer endurance than on seen trials in the forward direction. All of these findings are consistent with the above predictions as well as with earlier decoding results indicating a chain of additional processing stages unique to conscious trials (<xref ref-type="bibr" rid="bib4">Charles et al., 2014</xref>). They suggest that conscious access can be described as the entry of information into a dynamic routing system (<xref ref-type="bibr" rid="bib51">Sackur and Dehaene, 2009</xref>; <xref ref-type="bibr" rid="bib11">Dehaene et al., 2014</xref>) in which information is stabilized, transferred to a processor, exploited in a determined time, and then transferred again to the next stage. As described in accumulation-of-evidence models of decision making (<xref ref-type="bibr" rid="bib55">Shadlen and Kiani, 2011</xref>), a failure to attain a threshold-level activation at one of these stages cuts the process short, prevents the attainment of a conscious-level representation, and causes the information to linger and decay.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Previous experiments exploring the signatures of conscious access have primarily contrasted the overall brain activity evoked by perceived and unperceived stimuli. However, this comparison may be contaminated by non-specific attention, alerting, performance, and reporting confounds. The quest for brain mechanisms of consciousness implies an isolation of neural populations that encodes the details of subjective experience (<xref ref-type="bibr" rid="bib22">Haynes, 2009</xref>). As an effort in this direction, we applied multivariate decoding techniques in order to track the neural encoding of a conscious or unconscious representation of stimulus location through time. To control over stimulus and performance confounds, we capitalized on the blindsight phenomenon and selectively analyzed a large fraction of trials with identical stimuli and accurate responses, which differed only in subjective reports of seeing or not seeing the stimulus.</p><p>The results revealed that (1) the location of a briefly flashed stimulus can be accurately decoded from MEG and EEG signals for up to 800 ms, whether or not the stimulus is seen. This finding is coherent with the existence of multiple spatial maps in occipital, parietal, and frontal cortex (<xref ref-type="bibr" rid="bib53">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib20">Hagler and Sereno, 2006</xref>). (2) Seen and unseen stimuli are initially encoded identically, but after ∼270 ms, the information is selectively amplified on ‘seen’ trials. This observation replicates and extends earlier observations with seen and unseen words, digits and pictures during masking (<xref ref-type="bibr" rid="bib12">Del Cul et al., 2007</xref>; <xref ref-type="bibr" rid="bib15">Fisch et al., 2009</xref>), and the attentional blink (<xref ref-type="bibr" rid="bib54">Sergent et al., 2005</xref>). (3) Asymmetrical generalization indicates that shared spatial codes are active on unconscious and conscious trials, but that conscious trials also contain additional neural codes for stimulus location that are absent or weaker on unconscious trials. Source localization traces those conscious codes to superior parietal and superior frontal cortex. While the present method does not allow us to decide whether the difference is quantitative (the same codes are activated more strongly) or qualitative (additional neural codes are recruited), they are convergent with the prior observation that, of the many maps for space in the cortex, superior parietal and frontal maps are selectively amplified by attention, while earlier retinotopic maps are activated in an automatic manner (<xref ref-type="bibr" rid="bib52">Saygin and Sereno, 2008</xref>). (4) The dynamics of cortical coding, as revealed by temporal generalization matrices (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>), also differs on seen and unseen trials: conscious information undergoes a series of representational transformations, such that each decoder fails to generalize beyond ∼160 ms, while unconscious information, although weaker, generalizes over a longer period.</p><p>The latter finding fits with earlier observations that only conscious stimuli can be passed through a series of discrete information-processing stages (<xref ref-type="bibr" rid="bib51">Sackur and Dehaene, 2009</xref>; <xref ref-type="bibr" rid="bib32">De Lange et al., 2011</xref>; <xref ref-type="bibr" rid="bib4">Charles et al., 2014</xref>). The observed characteristic peak-to-end duration of about 160 ms is also compatible with the finding that conscious percepts tend to be locked to an ongoing theta (∼4<italic>–</italic>7 Hz) or high delta (∼1<italic>–</italic>3 Hz) rhythm (<xref ref-type="bibr" rid="bib39">Melloni et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Doesburg et al., 2009</xref>; <xref ref-type="bibr" rid="bib40">Nakatani et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Sitt et al., 2014</xref>), which is also the frequency range of slow positive event-related potentials, such as the P3. Doesburg et al. found that perceptual switching in a binocular rivalry paradigm corresponds to the emergence of synchronized gamma rhythm embedded in theta envelope (<xref ref-type="bibr" rid="bib13">Doesburg et al., 2009</xref>). In an attentional blink paradigm, the synchrony of fast oscillations (beta and gamma) with slow activity (theta and high delta) increased with practice, in parallel to improved stimulus visibility (<xref ref-type="bibr" rid="bib40">Nakatani et al., 2014</xref>). Theta activity was also shown to be higher on visible trials compared to invisible trials in a masking paradigm (<xref ref-type="bibr" rid="bib39">Melloni et al., 2007</xref>) and was successfully used to classify conscious vs vegetative patients (<xref ref-type="bibr" rid="bib58">Sitt et al., 2014</xref>). It thus seems plausible that conscious information is able to enter into a series of computational stages that are betrayed by a series of theta- or delta-like peaks (<xref ref-type="bibr" rid="bib8">Dehaene and Sigman, 2012</xref>). Conversely, unconscious information fails to be sequentially dispatched to the successive steps of a serial task and, therefore, remains blocked within a fixed representational state, where it slowly decays. Behavioral priming studies confirm that unconscious information lingers at detectable levels for hundreds of milliseconds (<xref ref-type="bibr" rid="bib19">Greenwald et al., 1996</xref>) or even seconds (<xref ref-type="bibr" rid="bib59">Soto et al., 2011</xref>).</p><p>Our results are incompatible with theories that postulate identical codes for conscious and unconscious information, which would only be distinguished by second-order metacognitive tags (<xref ref-type="bibr" rid="bib33">Lau and Passingham, 2006</xref>). They fit with theories that postulate that a conscious episode is distinguished by an amplification of incoming sensory information, possibly through reverberating loops (<xref ref-type="bibr" rid="bib30">Lamme, 2006</xref>), and its distributed representation in multiple distinct regions including parietal and prefrontal cortices (<xref ref-type="bibr" rid="bib7">Dehaene and Naccache, 2001</xref>; <xref ref-type="bibr" rid="bib10">Dehaene et al., 2006</xref>). These results are highly convergent with intracranial local-field potentials and single-neuron recordings during binocular rivalry and continuous flash suppression (<xref ref-type="bibr" rid="bib56">Sheinberg and Logothetis, 1997</xref>; <xref ref-type="bibr" rid="bib29">Kreiman et al., 2002</xref>; <xref ref-type="bibr" rid="bib44">Panagiotaropoulos et al., 2012</xref>), which indicate that late neural discharges in higher cortical areas reflect which of two rivaling images are subjectively perceived. In the case of object identity, decodable neural activity is found in inferior and anterior temporal cortex (<xref ref-type="bibr" rid="bib56">Sheinberg and Logothetis, 1997</xref>; <xref ref-type="bibr" rid="bib29">Kreiman et al., 2002</xref>) but also in prefrontal cortex (<xref ref-type="bibr" rid="bib44">Panagiotaropoulos et al., 2012</xref>) as reported here. Thus, this region appears at the confluence of conscious perception of object identity and location, making it a primary candidate for the integrated perception of a unified conscious scene or event (<xref ref-type="bibr" rid="bib42">Oizumi et al., 2014</xref>).</p><p>While numerous previous studies have compared brain activity evoked by ‘seen’ and ‘unseen’ stimuli, the advantage of the present study is to specifically pursue the neural dynamics underlying a specific conscious content (stimulus location). Figuratively speaking, one may say that previous studies have extracted the ‘canvas’ on which conscious perception is painted, while our approach is aimed at extracting the ‘painting’ itself. Nevertheless, this approach suffers from several limitations. One of them is the low level of decodability achieved: single-trial EEG and MEG responses have a low signal-to-noise ratio, which limits our inferences and would not afford, for instance, a reliable brain–computer interface. Another limit of our design is that it reduces the rich experience associated with conscious perception to a single feature of a very lean stimulus, presented at threshold, which is the sole focus of attention and which is reported on every trial. Whether the present results would generalize to broader real-life situations, especially in the absence of an overt report is an important question for further research. Some recent experiments suggest that removing the need to report radically reduces the neurophysiological correlates of conscious perception, including the P3b component of event-related potentials, leaving only a posterior mid-latency component (<xref ref-type="bibr" rid="bib45">Pitts et al., 2012</xref>, <xref ref-type="bibr" rid="bib47">2014a</xref>, <xref ref-type="bibr" rid="bib46">2014b</xref>; <xref ref-type="bibr" rid="bib16">Frässle et al., 2014</xref>). However, many of those experiments involved a dual task, which is known to delay and dilute late ERPs (<xref ref-type="bibr" rid="bib57">Sigman and Dehaene, 2008</xref>) and to distort conscious access (<xref ref-type="bibr" rid="bib38">Marti et al., 2010</xref>). It might be preferable to adopt a ‘passive attentive’ paradigm involving mere attention without report. In such an auditory paradigm, late ERPs including the P3b component were again found to contain decodable information about the conscious percept (<xref ref-type="bibr" rid="bib62">Wacongne et al., 2011</xref>; <xref ref-type="bibr" rid="bib26">King et al., 2013</xref>). A correlation of late neurophysiological activity with perceptibility was also obtained in a variety of neurophysiological studies of human visual perception (<xref ref-type="bibr" rid="bib49">Quiroga et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Kouider et al., 2013</xref>) or rodent tactile perception (<xref ref-type="bibr" rid="bib1a">Manita et al., 2015</xref>). With due caution, we, therefore, hypothesize that the neurophysiological correlates of conscious perception uncovered here might be generalized to other experimental conditions.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>17 right-handed healthy adults (10 men, 19–30 years of age) with no history of neurological or psychiatric disorders participated the study. This study was ethically approved by CPP IDF 7 under the reference CPP 08 021. All participants reported normal or corrected-to-normal visual acuity. The data of 5 subjects were excluded due to failure in calibration, and these observers reported more than 85% of the target trials as seen (even with maximum masking contrast). The intensity values to which subjects were calibrated ranged from 0 to 227, mean 131.46 (SE = 19.76).</p></sec><sec id="s4-2"><title>Stimuli and apparatus</title><p>The target stimulus was a line segment subtending a visual angle of 0.33°, tilted by 45° to the left. On target-present trials, the target was randomly presented at one of the eight possible locations. The potential locations were allocated on the outline of an imaginary circle centered at the fixation point with a radius of 2.85° of visual angle. Target locations were separated by radial angles of 45° with an offset of 22.5° from the meridians. The mask comprised crosses, each subtending 0.5° of visual angle, always present at all the eight possible locations. The fixation cross subtended 0.15° of visual angle. On target-absent trials, only the mask was displayed. All stimuli but the mask were black on white background; mask contrast was determined individually for each subject in a calibration phase. Stimuli were generated offline using Matlab (MathWorks, Natick, MA), and their presentation was controlled using the Psychtoolbox package for Matlab (<xref ref-type="bibr" rid="bib2">Brainard, 1997</xref>). Stimuli were presented with a Panasonic PT D7700E-K video projector (refresh rate 60 Hz) to a backprojection screen inside the magnetically shielded at a distance of 1 m from the eyes of the subject. Behavioral responses were collected with two 5-button cylindrical fiber optic response pads (‘fORP’; Current Designs Inc., Philadelphia, PA).</p></sec><sec id="s4-3"><title>Experimental procedure</title><p>At the beginning of each trial, as an alerting signal, the fixation point was magnified twofold for 100 ms and then reverted to its normal size (fixation was present throughout the trial). 800 ms later, the target was presented for 2 screen refresh cycles (∼33 ms). The mask followed immediately and remained on the screen for 400 ms. A blank screen was presented for at least 1500 ms or until the first response (retention period). Then, two consecutive images prompting the second and third responses were presented until response. A new trial began 500 ms after the third response (see <xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><p>As noted, three responses were collected on each trial. First, participants were required to produce a speeded forced-choice response to the location of the target. The second response was a second-order response, reporting whether the participants thought that their first response was correct or incorrect. With the third response, participants had to indicate whether they had seen the target or merely guessed its location.</p><p>Because of the procedure's high task demand, the experiment was designed in a way that enabled participants to adapt to it. We introduced responses in a gradual way, using a slide that explained the nature of the specific response and a movie that illustrated the corresponding keys. The experiment started with a description of the localization task, which was immediately practiced during an eight-trial practice block. In this block, the mask contrast was set to zero, so targets were completely visible, and participants had to correctly respond with the designated response-pad buttons. A correct response turned the target's color to green and an incorrect response turned it to red.</p><p>Next, participants were introduced to the second-order response and performed another training block with three objectives: first, to continue the gradual adaptation to the task; second, to ensure a fast, automatic response; third, to make sure that subjects complied with the task and caught their occasional errors. In the training phase, the target was completely visible once again, and subjects had to report its location and whether they made an error with their first response. Average localization performance (RTs and accuracy) and average second-order report accuracy were calculated every 5 trials. If the participant localized the target correctly in all five trials, or his/hers average RT was above 800 ms, a slide appeared before the next training block encouraging him/her to respond faster. On the other hand, if the participant localized the target correctly in less than four trials, the slide prompted him/her to respond slower. If participant's second-order report was correct in less than four of the trials, then the slide urged the participant to be more accurate with his/her second-order report. Training ended after 16 blocks or if the average performance during the last 4 blocks had reached specific criteria of localization performance between 85% and 95%, average RT below 800 ms and the second-order report correct in more than 90% of trials.</p><p>Following the training, participants were introduced to the subjective visibility response and started a calibration phase. The calibration phase was designed to determine the mask contrast that would yield an approximately equal number of trials in which the target stimulus would be seen or not seen (a 50% detection threshold). A trial was considered as a ‘Seen’ trial if the participant reported that he/she had seen the target and had correctly localized it, or if he/she reported the target as seen, failed to correctly localize it, but detected the error. We used a modified version of the threshold estimation procedure described by Levitt (<xref ref-type="bibr" rid="bib36">Levitt, 1971</xref>), changing mask contrast according to participant's ‘Seen’ trials proportion in a block. We manipulated contrast by adjusting the pixel intensity values in a unified fashion. Initial intensity was set to 230 (range 0–255). The number of trials in each block increased as calibration persisted, so the first two blocks comprised four trials, the third block six trials, the forth eight trials, and from the fifth block on, all blocks comprised ten trials. The change in Red Green Blue (RGB) values was determined by the proportion of seen trials in a block, and the number of calibration blocks that participant had already completed. The maximal possible change after a single block was 80. This kind of change was applied when the proportion of seen trials was either 1 or 0. However, this maximal value decreased as the number of blocks participant has completed increased. The stopping rule for the calibration was that RGB change was smaller than 1.5, or subjects had completed 80 trials.</p><p>After mask contrast was determined, participant started the experimental phase where the contrast was fixed. The experimental phase was similar to the calibration phase with the following changes: it included 540 trials divided into 6 blocks, 1/9 of these trials were catch trials.</p></sec><sec id="s4-4"><title>MEG/EEG acquisition</title><p>MEG and EEG data were low-pass filtered at 330 Hz and recorded simultaneously at 1000-Hz sampling rate with a 306-channel Elekta Neuromag MEG system (Elekta Oy, Helsinki, Finland), which comprises 102 triple sensors (each with two orthogonal planar gradiometers and one magnetometer) in a helmet-shaped array. Four head position indicator coils were placed on the scalp of the subject, and their locations were digitized with respect to anatomical landmarks prior to the MEG recording. By briefly energizing the coils, the head position was measured at the beginning of each block. EEG signal was recorded from 60 electrodes that were referenced to the nose. The ground electrode was on the clavicle bones. Horizontal and vertical EOG and electrocardiogram (ECG) were also recorded for offline rejection of eye movements and cardiac artifacts.</p></sec><sec id="s4-5"><title>Preprocessing</title><p>Acquired data were processed with the MaxFilter software package (Elekta Oy) that implements the Signal Space Separation (SSS) method (<xref ref-type="bibr" rid="bib60">Taulu et al., 2004</xref>) to suppress ambient magnetic interference. Gradiometers and magnetometers with amplitudes continuously exceeding 3000 fT/cm and 3000 fT, respectively, were marked as bad channels and were interpolated by SSS. Eye blinks, eye movements, and cardiac activity were detected on the EOG and ECG channels, and to suppress these artifacts, data were averaged with respect to the onset of each artifact separately, and PCA was used to determine the dominant components of these artifacts in the MEG/EEG signals. One to three components were removed according to visual inspection.</p><p>Using Fieldtrip software (<xref ref-type="bibr" rid="bib43">Oostenveld et al., 2011</xref>), continuous data were low-pass filtered at 30 Hz and cut to 2.5-s epochs starting 500 ms before the stimulus onset. Data were downsampled to 64 Hz. EEG data from one subject were omitted due to technical problems. Thus, data from 12 subjects were analyzed, with one subject missing EEG data.</p><p>To combine data from MEG magnetometer and planar gradiometers as well as from EEG channels, a normalization procedure was first applied; the baseline standard deviation was estimated for each channel using all the trials in the experiment, and then all the samples were divided by this standard deviation to yield a z-score, which was entered in the classification algorithm.</p></sec><sec id="s4-6"><title>Classification</title><p>We used a multivariate classification procedure to characterize the temporal dynamics of information processing when the stimulus was perceived consciously vs unconsciously. A distinct classifier was trained for each subject and for each time sample, using the data from all sensors. In all analyses, we employed a linear support vector machine (SVM) algorithm (with cost parameter C = 1) that was complemented with a continuous output method providing for each sample tested the probability of belonging to each of the possible classes (i.e., spatial locations) (<xref ref-type="bibr" rid="bib48">Platt, 1999</xref>). Classification was done with the package libsvm (<xref ref-type="bibr" rid="bib3">Chang and Lin, 2011</xref>). The data were randomly divided into 15 non-overlapping folds; the classifier was trained on fourteenfolds and tested on the one that was left out; this procedure was repeated 15 times for each time sample, so all fifteenfolds were eventually used for testing.</p><p>In the first analysis, the classifier was trained on all the data (except of the test data) and eight output classes (locations). The general classification probability for the correct location was then split according to participants' subjective reports of visibility and their performance in the forced-choice task.</p><p>The second analysis was aimed at examining cross-condition generalization, that is, whether the features that are used to decode spatial location in one condition of visibility are the same as those used in the other. Since the experimental conditions were defined by subjects' responses, the number of trials at each location was no longer balanced within each of these conditions, and this imbalance affected the pre-stimulus bias of the 8-category classifier as well as its capacity to generalize. To address this problem, we turned to a simpler binary classifier, which was trained to simply sort the stimuli into left-hemifield vs right-hemifield stimuli. Within each subject, we matched the number of trials in these two classes and also selected equal numbers of seen–correct and unseen–correct trials. Similarly to the previous analysis, for each perceptual condition, the data were divided into fifteenfolds; the classifier was trained on 14 and tested on the one left out and additionally on the converse perceptual condition.</p><p>A third analysis aimed to find out in which cortical regions the processing of seen and unseen stimuli differed. We tested the roles of each region by running decoding analyses separately on sources confined to this region.</p><p>We first parceled the cortex into 68 regions with FreeSurfer (Desikan–Killiany atlas). This parcellation is based on cortical curvature patterns that are estimated from individual MRI surface reconstructions. While these are large regions, the precision of MEG source reconstruction, combined with the requirements of the decoding approach, does not afford a very small focus. Smaller regions generally did not contain enough reconstructed dipoles with distinctive information to support accurate decoding. Neuronal current sources underlying single-trial MEG and EEG signals were estimated using linear minimum-norm estimates with fixed cortical source orientations. A three-layer volume conductor model based on individual head geometry was used in the forward computations (MNE-Suite [<xref ref-type="bibr" rid="bib18">Gramfort et al., 2014</xref>] Matlab toolbox). Noise covariance was estimated from the baseline periods of all accepted trials. We then ran an individual decoding analysis for each of the 68 regions. The estimated current distribution within a ROI at a given latency was fed to the same SVM analyses as for the sensor-level data. The results with eight output classes confirmed the existence of early focal and late distributed location-coding stages (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). To avoid an unnecessary increase in the number of statistical tests, we confined the subsequent analyses of seen and unseen trials, to four a priori regions of interest: pericalcarine, superior parietal cortex, rostral medial frontal cortex, and superior-lateral frontal cortex. In the latter case, the decoder outputs were calibrated class probabilities for ‘Seen–Correct’ and ‘Unseen–Correct’ classes after 10-fold cross-validation.</p><p>The fourth type of analysis aimed to test the stability over time. As in the first analysis, data from all trials were used to train classifiers at each time point ranging from 200 ms before to 1500 ms after the target and then test generalization to every other time point, as described in (<xref ref-type="bibr" rid="bib24">King and Dehaene, 2014</xref>; <xref ref-type="bibr" rid="bib25">King et al., 2014</xref>).</p><p>Two additional control analyses were conducted. First, we used cross-condition generalization to ensure that the classification performance was not derived from brain activity related to response selection but instead from neural activity related to perceptual processes. Therefore, we trained classifiers on the perceptual conditions and tested them on catch trials where the target was absent, but that were labeled according to the location of the participants' responses (8 possibilities). A second analysis was aimed to check whether superior posterior decoding probability for the ‘Seen–Correct’ correct trials rose from eye movements. To this aim, we fed the same classifier solely with EOG data, namely horizontal and vertical electro-oculograms.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors express their gratitude to the UNICOG Consciousness team (Sebastien Marti, Aaron Schurger and Jaco Sitt) for their advice and insights and to NeuroSpin's support teams, particularly the LBIOM team for subject recruitment and the MEG team (Virginie van Wassenhove, Marco Buiatti, Leila Rogeaux) for data acquisition and analysis. Supported by INSERM, CEA, Collège de France, Fyssen grant to MS, DGA to JRK, an ERC grant ‘NeuroConsc’ to SD, Foundation Bettencourt-Schueller and the Roger de Spoelberch Foundation.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>MS, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>SM, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>J-RK, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>LC, Acquisition of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>LP, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con6"><p>SD, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by the by CPP IDF under the reference CPP 08 021. All subjects gave written informed consent and consent to publish before participating in the study.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aru</surname><given-names>J</given-names></name><name><surname>Bachmann</surname><given-names>T</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><year>2012</year><article-title>Distilling the neural correlates of consciousness</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>36</volume><fpage>737</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2011.12.003</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year>1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Lin</surname><given-names>CJ</given-names></name></person-group><year>2011</year><article-title>LIBSVM: a library for support vector machines</article-title><source>ACM Transactions on Intelligent Systems and Technology</source><volume>2</volume><fpage>27</fpage><pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charles</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2014</year><article-title>Decoding the dynamics of action, intention, and error detection for conscious and subliminal stimuli</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>1158</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2465-13.2014</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowey</surname><given-names>A</given-names></name><name><surname>Stoerig</surname><given-names>P</given-names></name></person-group><year>1995</year><article-title>Blindsight in monkeys</article-title><source>Nature</source><volume>373</volume><fpage>247</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/373247a0</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Lange</surname><given-names>FP</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2011</year><article-title>How awareness changes the relative weights of evidence during human decision-making</article-title><source>PLOS Biology</source><volume>9</volume><fpage>e1001203</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.1001203</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><year>2011</year><article-title>Experimental and theoretical approaches to conscious processing</article-title><source>Neuron</source><volume>70</volume><fpage>200</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.03.018</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Sergent</surname><given-names>C</given-names></name></person-group><year>2006</year><article-title>Conscious, preconscious, and subliminal processing: a testable taxonomy</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>204</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.03.007</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Charles</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name></person-group><year>2014</year><article-title>Toward a computational theory of conscious processing</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>76</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.12.005</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name></person-group><year>2001</year><article-title>Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework</article-title><source>Cognition</source><volume>79</volume><fpage>1</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(00)00123-2</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name></person-group><year>2012</year><article-title>From a single decision to a multi-step algorithm</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>937</fpage><lpage>945</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.05.006</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Sergent</surname><given-names>C</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><year>2003</year><article-title>A neuronal network model linking subjective reports and objective physiological data during conscious perception</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>100</volume><fpage>8520</fpage><lpage>8525</lpage><pub-id pub-id-type="doi">10.1073/pnas.1332574100</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Cul</surname><given-names>A</given-names></name><name><surname>Baillet</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2007</year><article-title>Brain dynamics underlying the nonlinear threshold for access to consciousness</article-title><source>PLOS Biology</source><volume>5</volume><fpage>e260</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0050260</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doesburg</surname><given-names>SM</given-names></name><name><surname>Green</surname><given-names>JJ</given-names></name><name><surname>McDonald</surname><given-names>JJ</given-names></name><name><surname>Ward</surname><given-names>LM</given-names></name></person-group><year>2009</year><article-title>Rhythms of consciousness: binocular rivalry reveals large-scale oscillatory network dynamics mediating visual perception</article-title><source>PLOS One</source><volume>4</volume><fpage>e6142</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0006142</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Snijders</surname><given-names>TM</given-names></name><name><surname>Heinen</surname><given-names>K</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name><name><surname>Scholte</surname><given-names>HS</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name></person-group><year>2012</year><article-title>Neuronal integration in visual cortex elevates face category tuning to conscious face perception</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>109</volume><fpage>21504</fpage><lpage>21509</lpage><pub-id pub-id-type="doi">10.1073/pnas.1207414110</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisch</surname><given-names>L</given-names></name><name><surname>Privman</surname><given-names>E</given-names></name><name><surname>Ramot</surname><given-names>M</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Nir</surname><given-names>Y</given-names></name><name><surname>Kipervasser</surname><given-names>S</given-names></name><name><surname>Andelman</surname><given-names>F</given-names></name><name><surname>Neufeld</surname><given-names>MY</given-names></name><name><surname>Kramer</surname><given-names>U</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year>2009</year><article-title>Neural “ignition”: enhanced activation linked to perceptual awareness in human ventral stream visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>562</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.001</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frässle</surname><given-names>S</given-names></name><name><surname>Sommer</surname><given-names>J</given-names></name><name><surname>Jansen</surname><given-names>A</given-names></name><name><surname>Naber</surname><given-names>M</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><year>2014</year><article-title>Binocular rivalry: frontal activity relates to introspection and action but not to perception</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>1738</fpage><lpage>1747</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4403-13.2014</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year>2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>D</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year>2014</year><article-title>MNE software for processing MEG and EEG data</article-title><source>Neuroimage</source><volume>86</volume><fpage>446</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.027</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwald</surname><given-names>AG</given-names></name><name><surname>Draine</surname><given-names>SC</given-names></name><name><surname>Abrams</surname><given-names>RL</given-names></name></person-group><year>1996</year><article-title>Three cognitive markers of unconscious semantic activation</article-title><source>Science</source><volume>273</volume><fpage>1699</fpage><lpage>1702</lpage><pub-id pub-id-type="doi">10.1126/science.273.5282.1699</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hagler</surname><given-names>DJ</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year>2006</year><article-title>Spatial maps in frontal and prefrontal cortex</article-title><source>Neuroimage</source><volume>29</volume><fpage>567</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.08.058</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haynes</surname><given-names>JD</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year>2006</year><article-title>Decoding mental states from brain activity in humans</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>523</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1038/nrn1931</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year>2009</year><article-title>Decoding visual consciousness from human brain signals</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>194</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.02.004</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamitani</surname><given-names>Y</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year>2005</year><article-title>Decoding the visual and subjective contents of the human brain</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>679</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1038/nn1444</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Schurger</surname><given-names>A</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2014</year><article-title>Two distinct dynamic modes subtend the detection of unexpected sounds</article-title><source>PLOS One</source><volume>9</volume><fpage>e85791</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0085791</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Faugeras</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Schurger</surname><given-names>A</given-names></name><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>Sitt</surname><given-names>JD</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2013</year><article-title>Single-trial decoding of auditory novelty responses facilitates the detection of residual consciousness</article-title><source>Neuroimage</source><volume>83</volume><fpage>726</fpage><lpage>738</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.013</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year>2004</year><source>The quest for consciousness: a neurobiological approach</source><publisher-loc>New York</publisher-loc><publisher-name>Roberts &amp; co</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kouider</surname><given-names>S</given-names></name><name><surname>Stahlhut</surname><given-names>C</given-names></name><name><surname>Gelskov</surname><given-names>SV</given-names></name><name><surname>Barbosa</surname><given-names>LS</given-names></name><name><surname>Dutat</surname><given-names>M</given-names></name><name><surname>De Gardelle</surname><given-names>V</given-names></name><name><surname>Christophe</surname><given-names>A</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name></person-group><year>2013</year><article-title>A neural marker of perceptual consciousness in infants</article-title><source>Science</source><volume>340</volume><fpage>376</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1126/science.1232509</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year>2002</year><article-title>Single-neuron correlates of subjective vision in the human medial temporal lobe</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>99</volume><fpage>8378</fpage><lpage>8383</lpage><pub-id pub-id-type="doi">10.1073/pnas.072194099</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VA</given-names></name></person-group><year>2006</year><article-title>Towards a true neural stance on consciousness</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>494</fpage><lpage>501</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.09.001</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamy</surname><given-names>D</given-names></name><name><surname>Salti</surname><given-names>M</given-names></name><name><surname>Bar-Haim</surname><given-names>Y</given-names></name></person-group><year>2009</year><article-title>Neural correlates of subjective awareness and unconscious processing: an ERP study</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>1435</fpage><lpage>1446</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21064</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>HC</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year>2006</year><article-title>Relative blindsight in normal observers and the neural correlate of visual consciousness</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>103</volume><fpage>18763</fpage><lpage>18768</lpage><pub-id pub-id-type="doi">10.1073/pnas.0607716103</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>H</given-names></name><name><surname>Rosenthal</surname><given-names>D</given-names></name></person-group><year>2011</year><article-title>Empirical support for higher-order theories of conscious awareness</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>365</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.05.009</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laureys</surname><given-names>S</given-names></name><name><surname>Owen</surname><given-names>AM</given-names></name><name><surname>Schiff</surname><given-names>ND</given-names></name></person-group><year>2004</year><article-title>Brain function in coma, vegetative state, and related disorders</article-title><source>Lancet Neurology</source><volume>3</volume><fpage>537</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1016/S1474-4422(04)00852-X</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>H</given-names></name></person-group><year>1971</year><article-title>Transformed up-down methods in psychoacoustics</article-title><source>The Journal of the Acoustical Society of America</source><volume>49</volume><fpage>467</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1121/1.1912375</pub-id></element-citation></ref><ref id="bib1a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manita</surname><given-names>S</given-names></name><name><surname>Suzuki</surname><given-names>T</given-names></name><name><surname>Homma</surname><given-names>C</given-names></name><name><surname>Matsumoto</surname><given-names>T</given-names></name><name><surname>Odagawa</surname><given-names>M</given-names></name><name><surname>Yamada</surname><given-names>K</given-names></name><name><surname>Ota</surname><given-names>K</given-names></name><name><surname>Matsubara</surname><given-names>C</given-names></name><name><surname>Inutsuka</surname><given-names>A</given-names></name><name><surname>Sato</surname><given-names>M</given-names></name><name><surname>Ohkura</surname><given-names>M</given-names></name><name><surname>Yamanaka</surname><given-names>A</given-names></name><name><surname>Yanagawa</surname><given-names>Y</given-names></name><name><surname>Nakai</surname><given-names>J</given-names></name><name><surname>Hayashi</surname><given-names>Y</given-names></name><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Murayama</surname><given-names>M</given-names></name></person-group><year>2015</year><article-title>A top-down cortical circuit for accurate sensory perception</article-title><source>Neuron</source><volume>86</volume><fpage>1304</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.006</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2010</year><article-title>Mapping introspection's blind spot: reconstruction of dual-task phenomenology using quantified introspection</article-title><source>Cognition</source><volume>115</volume><fpage>303</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2010.01.003</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melloni</surname><given-names>L</given-names></name><name><surname>Molina</surname><given-names>C</given-names></name><name><surname>Pena</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>D</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Rodriguez</surname><given-names>E</given-names></name></person-group><year>2007</year><article-title>Synchronization of neural activity across cortical areas correlates with conscious perception</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>2858</fpage><lpage>2865</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4623-06.2007</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakatani</surname><given-names>C</given-names></name><name><surname>Raffone</surname><given-names>A</given-names></name><name><surname>van Leeuwen</surname><given-names>C</given-names></name></person-group><year>2014</year><article-title>Efficiency of conscious access improves with coupling of slow and fast neural oscillations</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1168</fpage><lpage>1179</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00540</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Gilzenrat</surname><given-names>MS</given-names></name><name><surname>Holmes</surname><given-names>BD</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>2005</year><article-title>The role of the locus coeruleus in mediating the attentional blink: a neurocomputational theory</article-title><source>Journal of Experimental Psychology. General</source><volume>134</volume><fpage>291</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.134.3.291</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oizumi</surname><given-names>M</given-names></name><name><surname>Albantakis</surname><given-names>L</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year>2014</year><article-title>From the phenomenology to the mechanisms of consciousness: integrated information theory 3.0</article-title><source>PLOS Computational Biology</source><volume>10</volume><fpage>e1003588</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003588</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><year>2011</year><article-title>FieldTrip:open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><fpage>156869</fpage><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panagiotaropoulos</surname><given-names>TI</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year>2012</year><article-title>Neuronal discharges and gamma oscillations explicitly reflect visual consciousness in the lateral prefrontal cortex</article-title><source>Neuron</source><volume>74</volume><fpage>924</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.013</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitts</surname><given-names>MA</given-names></name><name><surname>Martinez</surname><given-names>A</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name></person-group><year>2012</year><article-title>Visual processing of contour patterns under conditions of inattentional blindness</article-title><source>Journal of Cognitive Neuroscience</source><volume>24</volume><fpage>287</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00111</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitts</surname><given-names>MA</given-names></name><name><surname>Metzler</surname><given-names>S</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name></person-group><year>2014a</year><article-title>Isolating neural correlates of conscious perception from neural correlates of reporting one's perception</article-title><source>Frontiers in Psychology</source><volume>5</volume><fpage>1078</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2014.01078</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitts</surname><given-names>MA</given-names></name><name><surname>Padwal</surname><given-names>J</given-names></name><name><surname>Fennelly</surname><given-names>D</given-names></name><name><surname>Martínez</surname><given-names>A</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name></person-group><year>2014b</year><article-title>Gamma band activity and the P3 reflect post-perceptual processes, not visual awareness</article-title><source>Neuroimage</source><volume>101</volume><fpage>337</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.07.024</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Platt</surname><given-names>JC</given-names></name></person-group><year>1999</year><article-title>Fast training of support vector machines using sequential minimal optimization</article-title><source>Advances in kernel methods</source><publisher-name>MIT press</publisher-name><fpage>185</fpage><lpage>208</lpage></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Mukamel</surname><given-names>R</given-names></name><name><surname>Isham</surname><given-names>EA</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year>2008</year><article-title>Human single-neuron responses at the threshold of conscious recognition</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>105</volume><fpage>3599</fpage><lpage>3604</lpage><pub-id pub-id-type="doi">10.1073/pnas.0707043105</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossetti</surname><given-names>Y</given-names></name></person-group><year>1998</year><article-title>Implicit short-lived motor representations of space in brain damaged and healthy subjects</article-title><source>Consciousness and Cognition</source><volume>7</volume><fpage>520</fpage><lpage>558</lpage><pub-id pub-id-type="doi">10.1006/ccog.1998.0370</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2009</year><article-title>The cognitive architecture for chaining of two mental operations</article-title><source>Cognition</source><volume>111</volume><fpage>187</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2009.01.010</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saygin</surname><given-names>AP</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year>2008</year><article-title>Retinotopy and attention in human occipital, temporal, parietal, and frontal cortex</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>2158</fpage><lpage>2168</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm242</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name></person-group><year>1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1126/science.7754376</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergent</surname><given-names>C</given-names></name><name><surname>Baillet</surname><given-names>S</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2005</year><article-title>Timing of the brain events underlying access to consciousness during the attentional blink</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1391</fpage><lpage>1400</lpage><pub-id pub-id-type="doi">10.1038/nn1549</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year>2011</year><article-title>Consciousness as a decision to engage</article-title><person-group person-group-type="editor"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Christen</surname><given-names>Y</given-names></name></person-group><source>Characterizing Consciousness: From Cognition to the Clinic?</source><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer Verlag</publisher-name><fpage>27</fpage><lpage>46</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinberg</surname><given-names>DL</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year>1997</year><article-title>The role of temporal cortical areas in perceptual organization</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>94</volume><fpage>3408</fpage><lpage>3413</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.7.3408</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2008</year><article-title>Brain mechanisms of serial and parallel processing during dual-task performance</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>7585</fpage><lpage>7598</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0948-08.2008</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sitt</surname><given-names>JD</given-names></name><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Faugeras</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name></person-group><year>2014</year><article-title>Large scale screening of neural signatures of consciousness in patients in a vegetative or minimally conscious state</article-title><source>Brain</source><volume>137</volume><fpage>2258</fpage><lpage>2270</lpage><pub-id pub-id-type="doi">10.1093/brain/awu141</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soto</surname><given-names>D</given-names></name><name><surname>Mantyla</surname><given-names>T</given-names></name><name><surname>Silvanto</surname><given-names>J</given-names></name></person-group><year>2011</year><article-title>Working memory without consciousness</article-title><source>Current Biology</source><volume>21</volume><fpage>R912</fpage><lpage>R913</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.09.049</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Kajola</surname><given-names>M</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name></person-group><year>2004</year><article-title>Suppression of interference and artifacts by the signal space separation method</article-title><source>Brain Topography</source><volume>16</volume><fpage>269</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1023/B:BRAT.0000032864.93890.f9</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Gaal</surname><given-names>S</given-names></name><name><surname>Lamme</surname><given-names>VA</given-names></name><name><surname>Fahrenfort</surname><given-names>JJ</given-names></name><name><surname>Ridderinkhof</surname><given-names>KR</given-names></name></person-group><year>2010</year><article-title>Dissociable brain mechanisms underlying the conscious and unconscious control of behavior</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>91</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21431</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Labyt</surname><given-names>E</given-names></name><name><surname>van Wassenhove</surname><given-names>V</given-names></name><name><surname>Bekinschtein</surname><given-names>T</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year>2011</year><article-title>Evidence for a hierarchy of predictions and prediction errors in human cortex</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>108</volume><fpage>20754</fpage><lpage>20759</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117807108</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiskrantz</surname><given-names>L</given-names></name></person-group><year>1996</year><article-title>Blindsight revisited</article-title><source>Current Opinion in Neurobiology</source><volume>6</volume><fpage>215</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(96)80075-4</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.05652.016</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Johansen-Berg</surname><given-names>Heidi</given-names></name><role>Reviewing editor</role><aff><institution>University of Oxford</institution>, <country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled “Distinct cortical codes and temporal dynamics for conscious and unconscious percepts” for consideration at <italic>eLife</italic>. Your article has been favorably evaluated by Eve Marder (Senior editor), two reviewers, and Heidi Johansen-Berg, who is a member of our Board of Reviewing Editors.</p><p>The Reviewing editor and the reviewers discussed their comments before we reached this decision, and the Reviewing editor has assembled the following comments to help you prepare a revised submission.</p><p>All reviewers found the study well designed and carefully analysed. All reviewers felt the paper was a valuable addition to the literature and offered several advantages relative to prior work in this field. The following specific issues raised by reviewers should be addressed in a revision:</p><p>Essential points:</p><p>1) It would be useful to relate the decoding strategies used here to previous studies that used more traditional approaches to data analysis. For example, the authors could include a figure in which ERFs and ERPs are compared across the three main conditions (seen-correct, unseen-correct, unseen-incorrect). Specifically, it is worth reporting whether the difference between seen and unseen decoding accuracies observed in the late time period (&lt;270 ms) corresponds to the N2-P3 waves reported in previous studies.</p><p>2) Unless we are missing something, the authors did not run any analyses in which multivariate decoding was used to classify seen vs. unseen responses. Of the many analyses reported, a difference in accuracy in decoding stimulus location was found for seen vs. unseen trials, but both were above chance. Was a classifier ever directly used to discriminate seen vs. unseen trials?</p><p>3) Perhaps the late activity involves online conscious control of the speeded hand-movement response rather than conscious perception? We recognize that the authors have included a control in which no stimulus is present and responses are made. However, that control does not fully address the potential concern. Would the authors predict similar late-stage decoding of stimulus location if a 500 ms stimulus was presented (so as to be obviously seen) and subjects were not required to make any responses? This requires additional discussion.</p><p>4) It is not clear from the Methods section how EEG and MEG data were separately analyzed or combined in the multivariate decoding. For example, <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows “decoding location from MEG/EEG”, implying that signals from both were utilized in the decoding. More details regarding how these signals were separately analyzed or combined should be provided in the Methods section.</p><p>5) The authors should report reaction times for the speeded location identification response.</p><p>The authors may choose to comment on the following discussion points in a revision:</p><p>1) The authors make several well-informed predictions based on current theories or previous evidence, and the data appear to support these predictions. However, strong claims are often made based on very small effects. The authors should acknowledge this and should comment on the need for caution in interpreting a 1% difference in decoding accuracy between seen versus unseen trials. It would also be helpful to comment on why decoding accuracies were only just barely (though significantly) above chance to begin with.</p><p>2) If the late activity (270-800 ms) corresponds to conscious perception, the authors should consider explaining why the neural events underlying the conscious experience of a 33 ms line stimulus last 16 times longer (530 ms). Isn't it more intuitive that the conscious experience (and associated neural events) of a very brief stimulus would be correspondingly very brief?</p><p>3) Please provide more discussion of the finding that conscious representations seem to have a fixed duration of 160 ms which then gives rise to a new cycle, while unconscious representations decay slowly. If the authors could discuss this phenomena more extensively (e.g., do neural oscillations play a role? Does it reflect engagement of successive brain areas?), it would shed light on the mechanism behind this novel and interesting finding.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.05652.017</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>1) It would be useful to relate the decoding strategies used here to previous studies that used more traditional approaches to data analysis. For example, the authors could include a figure in which ERFs and ERPs are compared across the three main conditions (seen-correct, unseen-correct, unseen-incorrect). Specifically, it is worth reporting whether the difference between seen and unseen decoding accuracies observed in the late time period (&lt;270ms) corresponds to the N2-P3 waves reported in previous studies</italic>.</p><p>The objective of our study was to go beyond existing data on the neural correlates of conscious perception, specifically by attempting to decode the neural dynamics of a specific content, both when it is consciously perceived and when it is processed non-consciously. This is the reason why we did not initially include the basic ERFs and ERPs for the three conditions. We agree, however, that this is important background information. Therefore, we have now included this information in the paper. The results indeed demonstrate classic differences in the N2 and P3 waves in ERPs, and the corresponding events in ERFs. We have added a specific subsection on this topic to the Results section (“Relation to previous findings from event-related responses”).</p><p><underline>“</underline>Our fourth time window, where significantly improved location decoding was observed on seen compared to unseen trials […] the latter corresponds to a search for brain states encoding a specific consciously perceived content.”</p><p><italic>2) Unless we are missing something, the authors did not run any analyses in which multivariate decoding was used to classify seen vs. unseen responses. Of the many analyses reported, a difference in accuracy in decoding stimulus location was found for seen vs. unseen trials, but both were above chance. Was a classifier ever directly used to discriminate seen vs</italic>. <italic>unseen trials?</italic></p><p>Again, this was not the primary goal of our study. Numerous previous studies have studied the neural signatures of “Seen” and “Unseen” stimuli, but they were not able to identify the neural activity directly related to consciously perceived contents. Here we tried to pursue the neural dynamics underlying consciously perceived contents. Figuratively speaking, the old approaches have extracted the “canvas” on which conscious perception was painted while our approach is aimed at extracting the “painting” itself. We agree, however, that it is also useful to have additional information on the capacity to decode seen and unseen trials from M/EEG data. This information is now included in the paper (in the subsection headed “Relation to previous findings from event-related responses”):</p><p>”Training a classifier to use those event-related responses in order to separate “Seen-Correct” versus “Unseen-Correct” trials yielded a modest but significant classification success […]. This reduced the number of trials on which decoder was trained on and affected classification results.”</p><p><italic>3) Perhaps the late activity involves online conscious control of the speeded hand-movement response rather than conscious perception? We recognize that the authors have included a control in which no stimulus is present and responses are made. However, that control does not fully address the potential concern. Would the authors predict similar late-stage decoding of stimulus location if a 500ms stimulus was presented (so as to be obviously seen) and subjects were not required to make any responses? This requires additional discussion</italic>.</p><p>Two valid points were raised here. The first point is the hypothesis that the late stage of the classification could reflect conscious response planning. We believe that our control, decoding target-absent trials, does address this concern, but we have added two arguments to support our claim that the decoding difference is related to conscious perception and not to conscious motor preparation (see subsection headed “Controls for hand and eye movements”). The revised paragraph now reads:</p><p>“Although it remains possible that conscious response planning modulates the late stages of location processing, several aspects of our experiments argue against a contribution of motor codes to our results. […] Nor can the improved classification performance for “Seen-Correct” over “Unseen-Correct”, since those trials involve exactly the same stimuli and responses.”</p><p>The second point concerns the generality of our results outside the specific experimental environment and task. In real-life situations, conscious contents are richer, continuous and do not necessarily require a report. The experimental design here used a very lean stimulus. Only one of its features (location) was of relevance to the participants, who had to explicitly report it and its visibility. Generalization beyond the experimental situation should consider whether the dynamics revealed here could be generalized to other features of the same stimuli, to other stimuli and to other tasks, including passive viewing. Here we set a methodological and theoretical framework and establish preliminary results. Obviously, a lot of additional work is needed to address these points of concern. We have added a final paragraph to the Discussion where we discuss the limits of our findings and argue, cautiously, that similar dynamics would be found if we had used clearly visible stimuli without any overt response. We base this conclusion on parallels with other experiments, for instance using the auditory local-global paradigm, where similar findings of a late activity correlated with conscious perception was observed even in the absence of any overt report. We do note, however, that there is a current debate in the literature concerning this very issue. A discussion of those points has been added in the final paragraph:</p><p>“While numerous previous studies have compared brain activity evoked by “seen” and “unseen” stimuli, the advantage of the present study is to specifically pursue the neural dynamics underlying a specific conscious content (stimulus location). […] With due caution, we therefore hypothesize that the neurophysiological correlates of conscious perception uncovered here might generalized to other experimental conditions.”</p><p><italic>4) It is not clear from the Methods section how EEG and MEG data were separately analyzed or combined in the multivariate decoding. For example,</italic> <xref ref-type="fig" rid="fig2"><italic>Figure 2A</italic></xref> <italic>shows “decoding location from MEG/EEG”, implying that signals from both were utilized in the decoding. More details regarding how these signals were separately analyzed or combined should be provided in the Methods section</italic>.</p><p>All of our decoding was based on combined MEG and EEG signals. We have added a precise description of our methods in the subsection “Preprocessing” of the Materials and methods:</p><p>“…To combine data from MEG magnetometer and planar gradiometer as well as from EEG channels, a normalization procedure was first applied; the baseline standard deviation was estimated for each channel using all the trials in the experiment and then all the samples were divided by this std to yield a z-score which was entered in the classification algorithm”.</p><p><italic>5) The authors should report reaction times for the speeded location identification response</italic>.</p><p>We reported the reaction times in the previous version in the Materials and methods section. We now moved it to the Results section:</p><p>“Mean localization RTs were 812.2±44 ms. Localization RTs for different critical conditions were as follow: 701.4±35 ms for “Seen-Correct” trials, 878.1±78 ms for “Unseen-Correct” trials and 1110±101 ms for “Unseen-incorrect” trials.”</p><p><italic>The authors may choose to comment on the following discussion points in a revision</italic>:</p><p><italic>1) The authors make several well-informed predictions based on current theories or previous evidence, and the data appear to support these predictions. However, strong claims are often made based on very small effects. The authors should acknowledge this and should comment on the need for caution in interpreting a 1% difference in decoding accuracy between seen versus unseen trials. It would also be helpful to comment on why decoding accuracies were only just barely (though significantly) above chance to begin with</italic>.</p><p>We agree and have toned down our claims whenever possible, particularly in an additional final paragraph of the Discussion, pointing to the limitations of our study. It is important to note that we are decoding single-trial responses. It is well-known that the signal-to-noise ratio in EEG and MEG is quite low, owing to a superimposition of ongoing spontaneous activity whose intensity can be more than ten times larger than evoked activity. Thus, the absolute decoding level is necessarily low. Our argument is not based on an absolute level of decoding (unlike, say, experiments that aim at efficient brain–computer interfaces), but on the mere presence of differentially decodable information, even if it remains at a low level.</p><p><italic>2) If the late activity (270-800ms) corresponds to conscious perception, the authors should consider explaining why the neural events underlying the conscious experience of a 33ms line stimulus last 16 times longer (530ms)</italic>. <italic>Isn't it more intuitive that the conscious experience (and associated neural events) of a very brief stimulus would be correspondingly very brief?</italic></p><p>We disagree with this intuition. Although the stimulus is brief, its internal representation may be long-lasting. There is considerable evidence that even a brief sensory event may cause an entire series of brain activations, lasting way beyond the duration of the stimulus. The vast majority of theories of consciousness, including Global Neuronal Workspace theory, acknowledge that there is a tight relation between conscious perception and working memory. Even briefly presented stimuli, if conscious, must remain efficiently coded and “meta-stable” for a duration long enough to allow reportability long after the stimulus is gone. Indeed, a direct relation between conscious perception and long-lasting metastability has been demonstrated in previous research. See for instance the following two papers:</p><p>King, J.-R., Gramfort, A., Schurger, A., Naccache, L., &amp; Dehaene, S. (2014). Two distinct dynamic modes subtend the detection of unexpected sounds. PloS One, 9(1), e85791. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1371/journal.pone.0085791">http://doi.org/10.1371/journal.pone.0085791</ext-link></p><p>Schurger, A., Sarigiannidis, I., Naccache, L., Sitt, J. D., &amp; Dehaene, S. (2015). Cortical activity is more stable when sensory stimuli are consciously perceived. Proceedings of the National Academy of Sciences of the United States of America, 112(16), E2083–2092. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1073/pnas.1418730112">http://doi.org/10.1073/pnas.1418730112</ext-link></p><p><italic>3) Please provide more discussion of the finding that conscious representations seem to have a fixed duration of 160ms which then gives rise to a new cycle, while unconscious representations decay slowly. If the authors could discuss this phenomena more extensively (e.g., do neural oscillations play a role? Does it reflect engagement of successive brain areas?), it would shed light on the mechanism behind this novel and interesting finding</italic>.</p><p>We agree that this rough duration of 160ms is a very interesting finding. We have added some discussion of its potential relation to theta frequencies, as the observed duration of successive conscious stages is compatible with a nearly rhythmic succession of processing stages at this frequency. We now cite several publications that have demonstrated a tight correlation between theta oscillations and conscious perception. A discussion of this point has been added to the Discussion:</p><p>“The observed characteristic peak-to-end duration of about 160ms is also compatible with the finding that conscious percepts tend to be locked to an ongoing theta (∼4–7 Hz) or high delta (∼1–3 Hz) rhythm […]. It thus seems plausible that conscious information is able to enter into a series of computational stages that are betrayed by a series of theta- or delta-like peaks (<xref ref-type="bibr" rid="bib8">Dehaene and Sigman, 2012</xref>).”</p></body></sub-article></article>