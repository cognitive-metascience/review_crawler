<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">14188</article-id><article-id pub-id-type="doi">10.7554/eLife.14188</article-id><article-categories><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Ecology</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Place recognition using batlike sonar</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-48849"><name><surname>Vanderelst</surname><given-names>Dieter</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8049-5178</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="data-ro1"/></contrib><contrib contrib-type="author" id="author-49062"><name><surname>Steckel</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="data-ro1"/></contrib><contrib contrib-type="author" id="author-49063"><name><surname>Boen</surname><given-names>Andre</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3489-5063</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="data-ro1"/></contrib><contrib contrib-type="author" id="author-49060"><name><surname>Peremans</surname><given-names>Herbert</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="data-ro1"/></contrib><contrib contrib-type="author" id="author-31100"><name><surname>Holderied</surname><given-names>Marc W</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">School of Biological Sciences</institution>, <institution>University of Bristol</institution>, <addr-line><named-content content-type="city">Bristol</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Active Perception Lab</institution>, <institution>University of Antwerp</institution>, <addr-line><named-content content-type="city">Antwerp</named-content></addr-line>, <country>Belgium</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Constrained Systems Lab, Faculty of Applied Engineering</institution>, <institution>University of Antwerp</institution>, <addr-line><named-content content-type="city">Antwerp</named-content></addr-line>, <country>Belgium</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Eichenbaum</surname><given-names>Howard</given-names></name><role>Reviewing editor</role><aff id="aff4"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>dieter.vanderelst@uantwerpen.be</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>02</day><month>08</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e14188</elocation-id><history><date date-type="received"><day>04</day><month>01</month><year>2016</year></date><date date-type="accepted"><day>20</day><month>06</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Vanderelst et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Vanderelst et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-14188-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.14188.001</object-id><p>Echolocating bats have excellent spatial memory and are able to navigate to salient locations using bio-sonar. Navigating and route-following require animals to recognize places. Currently, it is mostly unknown how bats recognize places using echolocation. In this paper, we propose template based place recognition might underlie sonar-based navigation in bats. Under this hypothesis, bats recognize places by remembering their echo signature - rather than their 3D layout. Using a large body of ensonification data collected in three different habitats, we test the viability of this hypothesis assessing two critical properties of the proposed echo signatures: (1) they can be uniquely classified and (2) they vary continuously across space. Based on the results presented, we conclude that the proposed echo signatures satisfy both criteria. We discuss how these two properties of the echo signatures can support navigation and building a cognitive map.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.001">http://dx.doi.org/10.7554/eLife.14188.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.14188.002</object-id><title>eLife digest</title><p>Bats produce loud calls and listen to the returning echoes to find their way around. This process, known as echolocation, is sometimes described as 'seeing with sound'. The way bats perceive the world through echolocation, however, is fundamentally different from how we experience it through vision. Echolocation provides much less information about the world than vision does, but despite this, bats are agile navigators and hunters.</p><p>It is not clear how bats navigate so well without much information. In particular, researchers would like to know how echolocating bats recognize the places that they regularly visit while foraging and navigating. When we visually recognize places, we identify and localize the various objects making up the scene. But echolocation is unlikely to provide enough information to allow bats to identify and localize the objects in a particular place.</p><p>To investigate how bats recognize places, Vanderelst et al. built an artificial bat: a device that contained ultrasonic microphones to act like the bat’s ears and an ultrasonic speaker to act like the bat’s mouth. The artificial bat device was then used to collect echoes from different locations in real bat habitats.</p><p>Processing the echoes using machine-learning techniques showed that the echoes that returned from each location were different enough for a computer to recognize the location. By using a simplified version of the echoes, Vanderelst et al. also showed that the locations could be recognized even if there was not enough information to identify specific objects or vegetation at the site. This suggests that bats do not simply use echolocation to recreate the three-dimensional layout of a location, as some researchers have proposed.</p><p>While much remains to be learned about how bats use echolocation for navigation, future work that teases out bat navigation strategies might help us to build robots that can navigate using similar tactics.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.002">http://dx.doi.org/10.7554/eLife.14188.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>bats</kwd><kwd>chiroptera</kwd><kwd>echolocation</kwd><kwd>navigation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>Marie Curie IEF PIEF-GA-2012-326939</award-id><principal-award-recipient><name><surname>Vanderelst</surname><given-names>Dieter</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003130</institution-id><institution>Fonds Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Vanderelst</surname><given-names>Dieter</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Echolocating bats may recognize locations in the environment (and navigate to them) by remembering the specific echo signature of those locations.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Echolocating bats have excellent spatial memory (<xref ref-type="bibr" rid="bib2">Barchi et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Holland, 2007</xref>; <xref ref-type="bibr" rid="bib15">Geva-Sagiv et al., 2015</xref>) and are able to navigate to salient locations like roosts, foraging grounds and drinking places (<xref ref-type="bibr" rid="bib45">Schnitzler et al., 2003</xref>). Experimental results obtained using both <italic>Phyllostomus hastatus</italic> and <italic>Rousettus aegyptiacus</italic> suggest that long distance navigation and migration seem to be supported mainly by visual cues (<xref ref-type="bibr" rid="bib62">Tsoar et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Holland, 2007</xref>). However, when displaced by less than about 15 km, both <italic>Myotis</italic> spp. and <italic>Phyllostomus hastatus</italic> deprived of sight have been found to successfully return to their roost (<xref ref-type="bibr" rid="bib56">Stones and Branick, 1969</xref>; <xref ref-type="bibr" rid="bib71">Williams et al., 1966</xref>). This shows that navigation in bats can be supported by echolocation as well as vision. Navigating and route-following require animals to recognize places (<xref ref-type="bibr" rid="bib10">Franz and Mallot, 2000)</xref>. Currently, it is largely unknown how bats recognize places using echolocation (<xref ref-type="bibr" rid="bib45">Schnitzler et al., 2003</xref>) and different mechanisms are possible (<xref ref-type="bibr" rid="bib15">Geva-Sagiv et al., 2015</xref>).</p><sec id="s1-1"><title>Model based place recognition</title><p>One possible mechanism for sonar based recognition of places is to localize and classify the individual objects in the scene observed from that place is composed of <xref ref-type="bibr" rid="bib32">(Lewicki et al., 2014)</xref>. Under this assumption, bats would reconstruct a (presumably, 3D) model of the layout of a given place and match this with a set of previously stored representations, e.g. (<xref ref-type="bibr" rid="bib2">Barchi et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Moss and Surlykke, 2001</xref>; <xref ref-type="bibr" rid="bib45">Schnitzler et al., 2003</xref>). In other words, this mechanism implies that bats reconstruct a mental image of the environment from the echoes and use this to recognize a previously visited place.</p><p>Under favourable conditions, extracting a description of a set of localized objects from the echoes is possible as the position, shape, size and texture of objects are all encoded in the binaural spectra of the echoes, e.g. (<xref ref-type="bibr" rid="bib39">Reijniers et al., 2010</xref>; <xref ref-type="bibr" rid="bib42">Schmidt, 1988</xref>; <xref ref-type="bibr" rid="bib68">Von Helversen and Von Helversen, 2003</xref>; <xref ref-type="bibr" rid="bib38">Peremans et al., 2012</xref>; <xref ref-type="bibr" rid="bib72">Wotton and Simmons, 2000</xref>; <xref ref-type="bibr" rid="bib51">Simon et al., 2011</xref>; <xref ref-type="bibr" rid="bib14">Genzel and Wiegrebe, 2013</xref>). However, a number of limitations of bio-sonar render it uncertain whether bats are able to apply such a place recognition strategy. Low signal-to-noise ratio obscures echo spectra (<xref ref-type="bibr" rid="bib39">Reijniers et al., 2010</xref>). Moreover, ambiguity of cues is introduced by concurrently encoding in the spectral cues both location and other properties of objects. For example, a spectral notch could be introduced by either the head related transfer function (encoding the object’s location) or the transfer function of the reflector (encoding the object’s shape). This complicates extracting both object properties and object positions. Reconstructing the 3D position of objects is further complicated by the fact that, compared to vision, sonar has a limited field of view (<xref ref-type="bibr" rid="bib58">Surlykke et al., 2009</xref>), a low update rate (<xref ref-type="bibr" rid="bib29">Kleeman and Kuc, 2008</xref>; <xref ref-type="bibr" rid="bib38">Peremans et al., 2012</xref>) and a limited range (<xref ref-type="bibr" rid="bib55">Stilz and Schnitzler, 2012</xref>). While most of these limitations to reconstructing the layout of objects could potentially be addressed by integrating information across calls, this would entail both time and complexity penalties.</p><p>In addition, the capacity for reconstructing the 3D layout of objects is limited by the finite temporal resolution of the bat’s auditory system. The temporal integration in the auditory system severely limits the spatial resolution of biosonar and introduces interference between echoes. In a psychophysical experiment, <xref ref-type="bibr" rid="bib69">Wiegrebe and Schmidt (1996)</xref> observed a temporal integration constant of about 200 <italic>μ</italic>s in <italic>Megaderma lyra</italic>. Simmons and colleagues (<xref ref-type="bibr" rid="bib49">Simmons et al., 1989</xref>) derived an integration constant of about 200–400 <italic>μ</italic>s for the bat <italic>Eptesicus fuscus</italic>. Echoes from objects separated in time by less than the response time of the auditory filters will be integrated (<xref ref-type="bibr" rid="bib49">Simmons et al., 1989</xref>), thereby limiting bats’ ability to resolve the objects’ locations and properties.</p><p>The limitations imposed by temporal integration can be appreciated by considering the volume of space across which echoes are integrated by the sonar system. This volume can be appropriately described as a section of a spherical shell. The thickness of the shell is determined by the temporal integration of the hearing apparatus. The opening angle of the section is determined by the directionality of the sonar system. Hence, the integrated volume increases rapidly for larger distances from the bat (See <xref ref-type="fig" rid="fig1">Figure 1</xref> and equation therein). For example, at a distance of 7.8 meters, an echolocation system with a beamwidth of 45 degrees is estimated to integrate the echoes originating from a volume of over 1 m<sup>3</sup>. At the same distance, a system with a functional beamwidth of 60 degrees integrates echoes from a volume of about 2 m<sup>3</sup>. Echoes originating from reflectors within this volume will be integrated and it is not clear that they will be perceived as individual echoes (<xref ref-type="bibr" rid="bib11">Geberl, 2013</xref>). Indeed, in general, this volume will contain multiple reflectors. This is especially true when the scene contains complex objects such as leafy trees or bushes (See <xref ref-type="bibr" rid="bib77">Yovel et al., 2008</xref> for examples of echo trains returning from vegetation).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.003</object-id><label>Figure 1.</label><caption><title>Integration volume as a function of distance.</title><p>The integration volume calculated for different beamwidths <inline-formula><mml:math id="inf1"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> as a function of distance from the bat. The integration volume is approximated as a section of a spherical shell. The opening angle of the section is given by the beam width <inline-formula><mml:math id="inf2"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>. The thickness of the shell <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula> is given by the temporal integration of the sonar system. The temporal integration of the sonar system has been assumed to be 200 <italic>μ</italic>s yielding an integration distance (i.e. thickness of the shell) of about 0.034 m.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.003">http://dx.doi.org/10.7554/eLife.14188.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig1-v1"/></fig></p><p>Finally, it should be noted that the integration constant used to compute the volume of the sphere represents a very conservative upper boundary for the temporal resolution of the auditory system. Indeed, non-simultaneous masking effects have been found to extend for substantially longer intervals than the integration time (both in bats and humans [<xref ref-type="bibr" rid="bib36">Moore, 2012</xref>]). For example, <xref ref-type="bibr" rid="bib11">Geberl (2013)</xref> found non-simultaneous masking in <italic>Phyllostomus discolor</italic> for temporal separation between echoes up to 6 ms.</p><p>Some theoretical mechanisms, e.g. (<xref ref-type="bibr" rid="bib9">Fontaine and Peremans, 2009</xref>; <xref ref-type="bibr" rid="bib34">Matsuo et al., 2004</xref>; <xref ref-type="bibr" rid="bib41">Saillant et al., 1993</xref>), have been proposed that would allow bats to extract environment impulse responses from signals composed of multiple closely spaced echo signals. However, none of them have been unequivocally proven to be exploited by bats. Moreover, so far, these mechanisms have only been tested using simple artificially generated echo trains. To the best of our knowledge, no algorithm has proven to be able to reconstruct the impulse response of a realistically complex reflector such as vegetation.</p><p><xref ref-type="bibr" rid="bib18">Grunwald et al. (2004)</xref> reported that bats can discriminate between echoes with different impulse response statistics. This shows that the auditory periphery of the bat retains sufficient information to allow responding to the stochastic properties of the underlying impulse responses. However, this does not necessarily imply that bats can reconstruct the impulse response from the echoes, which is required to be able to reconstruct the 3D layout of a scene from the echoes.</p><p>In summary, inherent limitations of biosonar, including (1) the dependence on ambiguous spectral cues for both object localization and classification and (2) the finite temporal resolution of the auditory system, render it unlikely that an explicit 3D representation of a complex scene is available to a cruising bat – and that such a representation is used to recognize places.</p><p>As the capacity for recognizing places is nevertheless a necessary requirement for any navigation strategy, we propose an alternative mechanism, taking into account these limitations, to explain how echolocating bats might navigate.</p></sec><sec id="s1-2"><title>Template based place recognition</title><p>Instead of attempting to reconstruct the position, shape and identity of objects from the cochlear output, we propose the cochlear output to be used directly, extending the template based approach described by <xref ref-type="bibr" rid="bib70">Wiegrebe (2008)</xref>. Under this hypothesis, bats are assumed to match the output of the cochlea to a set of stored templates, i.e., classifying the echo signature as one of a set of memorized echo signatures each one recorded at a previously visited place. This approach obviates the need for complex reconstruction algorithms extracting 3D spatial information from the echo signals at the two ears. As it uses the sensory input directly, our approach to place recognition is analogous to the view-based place recognition that is thought to underlie visual navigation in insects (<xref ref-type="bibr" rid="bib78">Zeil et al., 2003</xref>; <xref ref-type="bibr" rid="bib10">Franz and Mallot, 2000</xref>).</p><p>In addition to circumventing the computationally hard problem of deriving a 3D spatial representation from complex echo signals, echo templates have been shown to be very discriminative. <xref ref-type="bibr" rid="bib30">Kuc (1997)</xref> showed a bio-mimetic sonar device to be capable of detecting which side of a coin was up using very simple echo templates. Their computational simplicity and discriminative power have led sonar based templates being used to recognize places in robotic navigation algorithms before, e.g. (<xref ref-type="bibr" rid="bib33">Mataric and Brooks, 1990</xref>; <xref ref-type="bibr" rid="bib54">Steckel and Peremans, 2013</xref>; <xref ref-type="bibr" rid="bib31">Kuipers, 2000</xref>). However, to the best of our knowledge, no study has looked at the properties of sonar templates accessible to bats operating in complex habitats. Indeed, robotic studies using sonar templates have all been carried out in artificial man-made environments. Moreover, these studies have used emitters, receivers and processing methods that are not necessarily biologically plausible. For example, robots typically (<xref ref-type="bibr" rid="bib29">Kleeman and Kuc, 2008</xref>) use a ring of sonar ranging devices (<xref ref-type="bibr" rid="bib33">Mataric and Brooks, 1990</xref>; <xref ref-type="bibr" rid="bib31">Kuipers, 2000</xref>), each with a limited field of view (<xref ref-type="bibr" rid="bib53">Steckel and Peremans, 2012</xref>), that extract the delay of the first echo.</p><p>In this paper, using ensonification data, we derive templates from many echo trains from natural habitats. In contrast to most robotic studies, we collect and process the echo data in a biologically plausible way. Next, we assess the viability of our hypothesis by evaluating whether the derived templates are sufficient to support place recognition. Indeed, the viability of a template-based approach to place recognition depends on the following two properties of the templates:</p><list list-type="order"><list-item><p>Templates must allow for unique classification for places to be recognizable. In other words, templates must encode specific locations and orientations of the bat in space. If templates can not be uniquely classified, they can not be used to recognize previously visited places.</p></list-item><list-item><p>Templates should vary smoothly as a function of the bat’s location and orientation. The dissimilarity between templates should increase monotonically over a relevant (non-trivially small) distance and angle. This allows the bat to recognize (that it is near) a place even if it is not exactly in the same location or orientation it was before.</p></list-item></list><p>In this paper, we test whether these conditions are satisfied by collecting many cochlear templates as they could be perceived by bats. In the discussion, we argue that, by satisfying these two criteria, the templates can support navigation. In addition, we discuss how the templates could support the acquisition of a cognitive map.</p></sec></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><p>All data and computer scripts are available from Zenodo (<xref ref-type="bibr" rid="bib66">Vanderelst et al., 2016</xref>).</p><sec id="s2-1"><title>Ensonification</title><p>A custom ensonification device consisting of 31 Knowles FG series microphones (<xref ref-type="bibr" rid="bib53">Steckel and Peremans, 2012</xref>) and a Senscomp (<ext-link ext-link-type="uri" xlink:href="http://www.senscomp.com/ultrasonic-sensors/series-7000-sensors.php">http://www.senscomp.com/ultrasonic-sensors/series-7000-sensors.php)</ext-link> Series 7000 ultrasonic speaker was used (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). The speaker produces about 106 <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> at 50 kHz and 1 meter distance. The device was mounted on a pan tilt system (PTU-E46, FLIR, Goleta, CA) allowing us to rotate the device from −150 to 150 degrees in azimuth and from −25 to 40 degrees in elevation. The pan tilt system moved the ensonification device through the full extent of its mechanical range in 31 steps of 10 degrees in azimuth and 7 steps of 10.8 degrees in elevation The positional error of the pan tilt system is less than 0.1 degrees.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.004</object-id><label>Figure 2.</label><caption><title>Close up of the ensonification device.</title><p>At the front of the device the array of 31 microphones (Knowles FG series) can be seen. The Senscomp Series 7000 ultrasonic speaker is located above this array.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.004">http://dx.doi.org/10.7554/eLife.14188.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig2-v1"/></fig></p><p>At each azimuth and elevation direction, three measurements were gathered. The data capture and storage was handled by a single-board computer integrated into the ensonification device. The single board computer controlling the data collection also controlled the pan tilt system through a serial interface cable. The single-board computer was wirelessly connected to a laptop enabling us to start and monitor the data collection. A hyperbolic frequency modulated pulse sweeping from 100 to 40 kHz in 1 ms was emitted. This frequency range was limited by the frequency response of the emitter and the electronics. The recording of the echoes was started at the onset of the emission and ends 34 ms later. The duration of the recording time window was limited by the on-board memory of the data acquisition system. The sampling rate was 219 kSamples/s.</p><p>Data was collected at three different sites (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). The structure of the data is depicted in <xref ref-type="fig" rid="fig3">Figure 3</xref>. First, twelve positions in St. Andrews Park (Bristol, UK, 51:27:15.772N, 2:36:52.996W) were selected for ensonification. To ensure the data represented different densities of clutter bats might operate in, four open, four semi-cluttered and four cluttered locations were selected. The data collected at St. Andrews Park consisted of 7812 (12 positions × 217 directions × 3 repeats) echo trains at each of the 31 microphones. Second, data was collected in a park in Midreshet Ben Gurion, Israel (30:50:53.318N, 34:46:54.174E). At this site, bats use an artificial corridor lined with boulders as part of their commuting route. In this corridor, the ensonification device was placed at 50 positions along a straight line spaced 20 cm apart. The line approximately ran along the centre of the corridor. At each of the 50 positions, three measurements for each of the 217 directions were collected yielding 32,550 echo trains (50 positions × 217 directions × 3 repeats) at each of the 31 microphones. Finally, data was collected at Royal Fort Gardens (Bristol, UK, 51:27:26.417N, 2:36:4.619W). At this third site, 40 positions spaced 25 cm apart along a 10 meter line were sampled yielding 26,040 echo trains (40 positions × 217 directions × 3 repeats) at each of the 31 microphones. In total, 66,402 echo trains for each of the 31 microphones were used in this paper, resulting in a data set consisting of a total of 2,058,462 echo trains.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.005</object-id><label>Figure 3.</label><caption><title>Illustration of the data collected.</title><p>Three data sets were collected (corresponding with three field sites). First, at St Andrews park, the ensonification device was placed at twelve different locations in habitats with varying levels of clutter (Open, Semi Cluttered, and Cluttered). At each of the twelve positions, echo trains from 217 azimuth and elevation directions were collected. At the Israel and Royal Fort Gardens site, the ensonification device was placed at 50 and 40 positions along a straight line, respectively. At each of the 50 (spaced 20 cm apart) or 40 (spaced 25 cm apart) positions, echo trains from 217 azimuth and elevation directions were collected.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.005">http://dx.doi.org/10.7554/eLife.14188.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig3-v1"/></fig></p><p>At both St. Andrews park and the Israel site data was collected at an approximate height of about 3 meters. In the case of St. Andrews park, overhanging vegetation sometimes restricted the device to be raised to this level. If so, the device was raised as high as possible. In the Royal Fort Park, all data was collected at a height of about 2 meters.</p></sec><sec id="s2-2"><title>Template construction</title><p>Templates were derived from the data collected at each of the three sites. The data for each of the 12, 50 and 40 positions in each data set were processed in the same manner. The method used in constructing the templates is summarized in algorithm 1.</p><sec id="s2-2-1"><title>Algorithm 1: The template construction process</title><p>For each position, the data consisted of 20,181 echo trains collected from 217 azimuth and elevation directions. At each azimuth and elevation direction, 3 measurements were taken using 31 microphones (217 directions × 31 microphones × 3 repeats = 20,181). Step 1: Each of the 20,181 echo trains was filtered using a model of the bat’s auditory periphery. This model returns a cochleogram. Step 2: The first 5.8 ms were set to zero to avoid the pick up of the emitted signal to be processed. Step 3: The cochleograms returned by the model of the auditory periphery were averaged across frequency and the 31 microphones. This resulted in 3 (corresponding to the 3 r) templates for each of the 217 azimuths &amp; elevation directions. At this point, the data consisted of 651 templates, corresponding to 3 repeats for each of the 217 directions. Step 4: To obtain a realistic directionality, the templates were averaged across 9 neighboring azimuth and elevation directions (See <xref ref-type="fig" rid="fig4">Figure 4</xref> for a depiction of the resulting virtual directionality). Step 5: The templates were sampled at an interval of 350 <italic>μ</italic>s. Step 6: Finally, templates were averaged across the 3 repeats to obtain a single template for each of the 217 directions.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.006</object-id><label>Figure 4.</label><caption><title>Comparison of the simulated beamwidth and the virtual beamwidth of the ensonification device.</title><p>Comparison of the simulated beamwidth of <italic>M. daubentonii</italic> (panel <bold>a</bold>) (<xref ref-type="bibr" rid="bib58">Surlykke et al., 2009</xref>) across the range 40 to 100 kHz and the virtual beamwidth of the ensonification device after averaging across 3 neighbouring directions based on the theoretical emission pattern of the Senscomp emitter (panel <bold>b</bold>). Panel <bold>c</bold> depicts the difference between the beamwidth of <italic>M. daubentonii</italic> and the virtual beam. Note that for the beam of <italic>M. daubentonii</italic> the emission and hearing directionality were combined.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.006">http://dx.doi.org/10.7554/eLife.14188.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig4-v1"/></fig></p><list list-type="order"><list-item><p><bold>Input: Data for a single position: 20,181 echo trains</bold></p></list-item><list-item><p>Step 1: Cochlear model and dechirping</p></list-item><list-item><p>Step 2: Set first 5.8 ms to zero</p></list-item><list-item><p>Step 3: Average across frequencies and microphones</p></list-item><list-item><p><bold>Intermediate result: 651 templates</bold> (217 templates × 3 repeats = 651)</p></list-item><list-item><p>Step 4: Average across 3 × 3 neighbouring directions</p></list-item><list-item><p>Step 5: Sampling at 350 <italic>μ</italic>s</p></list-item><list-item><p>Step 6: Average across 3 repeats</p></list-item><list-item><p><bold>Output: 217 Templates</bold></p></list-item></list><p>All 2,058,462 echo trains (217 directions × 3 repeats × 31 microphones × 102 positions) were individually filtered using a model of the bats’ auditory periphery similar to the one proposed by <xref ref-type="bibr" rid="bib70">Wiegrebe (2008)</xref> to simulate the peripheral hearing system of the bat <italic>Phyllostomus discolor</italic>. In brief, the model consists of a Gammatone filterbank with central frequencies ranging from 30 kHz to 100 kHz in steps of 5 kHz. Subsequently, each channel is exponentially compressed (using an exponent value of 0.4) and low-pass filtered (1 kHz cut-off, 12 dB slope per octave). The cochleogram returned by the model was dechirped by shifting each frequency channel in time (zero-padding at the end) such that the maximum activation, corresponding to the pick up of the emitted signal, is aligned across frequency channels. The first 5.8 ms (corresponding to about 1 m) of the data in each frequency channel were set to zero to avoid including the pick up of the emitted signal or any lingering decay thereof in the analysis. In the model formulated by <xref ref-type="bibr" rid="bib70">Wiegrebe (2008)</xref> a similar operation is performed by means of a channel-wise normalized autocorrelation between call and echoes. However, <xref ref-type="bibr" rid="bib70">Wiegrebe (2008)</xref> worked with simulated calls and echoes. In contrast, in our real measurements, the emission of the pulse saturated the microphones. Hence, we did not have the picked up call available to perform the autocorrelation with. Therefore, we approximated the autocorrelation step in Wiegrebe’s model (<xref ref-type="bibr" rid="bib70">Wiegrebe, 2008</xref>) by the dechirping operation described above. Both approaches would result in similar templates.</p><p>The resulting cochleograms were averaged across frequencies and the 31 microphones. Hence, the templates used in this paper did not include spectral information. Omitting spectral information reduced the computational complexity of subsequent computations. More importantly, omitting spectral information simplifies the template mechanism (1) making it robust against variations in call design and (2) shows the same mechanism could be used by CF/FM bats as well (see Discussion).</p><p>The beam of the emitter used was more narrow than the typically combined hearing and emission directionality of bats, e.g. (<xref ref-type="bibr" rid="bib63">Vanderelst et al., 2010</xref>; <xref ref-type="bibr" rid="bib26">Jakobsen et al., 2013</xref>). Therefore, templates were averaged across 3 neighbouring directions of the pan tilt system in elevation and azimuth to approximate the broader directional sensitivity of bats. Using the theoretical beam directionality of the Senscomp ultrasonic emitter, we estimated the resulting beamwidth employed in this paper to have a 3 dB opening angle of 20 degrees at 55 kHz. <xref ref-type="fig" rid="fig4">Figure 4</xref> compares the resulting virtual beamwidth of the ensonification device with the simulated beamwidth of the bat <italic>Myotis daubentonii</italic> (<xref ref-type="bibr" rid="bib26"><xref ref-type="bibr" rid="bib26">Jakobsen et al., 2013</xref></xref>; <xref ref-type="bibr" rid="bib64">Vanderelst and De Mey, 2008</xref>). From this plot, it is clear that the virtual beam employed in this paper is somewhat more homogeneous than that of actual bats. Nevertheless, the directivity indices of <italic>M. daubentonii</italic> and the virtual beam were very similar (about 14 and 15 <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> respectively, <xref ref-type="fig" rid="fig4">Figure 4</xref>). In a next step, the templates were downsampled to a sampling rate of 2.8 kHz, corresponding to a temporal integration interval of 350 <italic>μ</italic>s. The integration time of the model of <xref ref-type="bibr" rid="bib70">Wiegrebe (2008)</xref> is slightly less than 350 <inline-formula><mml:math id="inf6"><mml:mi>μ</mml:mi></mml:math></inline-formula>s.</p><p>Finally, templates were averaged across the three repeats resulting in 217 templates, corresponding to the 217 azimuth and elevation directions for a single location. One template was obtained for each of the 217 directions for each of the 12, 50 or 40 locations at the three respective sites (see <xref ref-type="fig" rid="fig5">Figure 5</xref>) resulting in a total of 22,134 templates for use in the remainder of the paper.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.007</object-id><label>Figure 5.</label><caption><title>Example of the templates using the St Andrews data.</title><p>(<bold>a</bold>) 360 degree panoramic view of one of the locations in St Andrews park which was ensonified (Semi cluttered 3). (<bold>b</bold>–<bold>d</bold>) Examples of three templates from three different azimuth and elevation directions. The assumed noise <inline-formula><mml:math id="inf7"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> on the templates is shown by the shaded areas.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.007">http://dx.doi.org/10.7554/eLife.14188.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig5-v1"/></fig></p></sec></sec><sec id="s2-3"><title>Template classification</title><p>The classification performance was determined for templates obtained at the St Andrews site. Estimating the probability of correct classification requires the introduction of a noise model. We introduced both a noise floor and stochastic noise on the templates.</p><sec id="s2-3-1"><title>Noise floor</title><p>Even in the absence of reflectors returning an echo, the internal noise of the ensonification device resulted in non-zero values for the templates. To avoid template values below the noise threshold of the device to contribute to the classification performance of the templates, we assessed the template values resulting from measurements taken in absence of any reflector, i.e. the device was pointed upwards in open spaces. These measurements were converted to templates in the same way as described above. The maximum template value obtained from these measurements was taken as the noise threshold <inline-formula><mml:math id="inf8"><mml:msub><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math></inline-formula>. Any value in the templates below <inline-formula><mml:math id="inf9"><mml:msub><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math></inline-formula> was set to <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math></inline-formula> as that value did not contain any information about the environment beyond the fact that no echo signal was present.</p></sec><sec id="s2-3-2"><title>Stochastic noise</title><p>We assume each sample of the templates to be subject to independent Gaussian noise with variance <inline-formula><mml:math id="inf11"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>. The value of <inline-formula><mml:math id="inf12"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> was derived using a procedure similar to that used by <xref ref-type="bibr" rid="bib8">Dau et al. (1996)</xref>. This is, we determine the value <inline-formula><mml:math id="inf13"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> that allows discriminating two templates corresponding to two single echo signals differing by 2 dB in intensity (at the 75% correctness criterion). In other words, we assume that the just-noticeable echo intensity difference in bats is 2 dB. Based on the evidence we could find, a just-noticeable-difference of 2 dB is a conservative estimate of the intensity discrimination ability of bats (<xref ref-type="bibr" rid="bib50">Simmons and Vernon, 1971</xref>; <xref ref-type="bibr" rid="bib61">Suthers, 1965</xref>). The noise floor and stochastic noise are illustrated in <xref ref-type="fig" rid="fig5">Figure 5</xref> by plotting them together with a number of selected templates.</p></sec><sec id="s2-3-3"><title>Template classification performance</title><p>Using the noise level <inline-formula><mml:math id="inf14"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, we calculated the probability <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM3">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for each template <inline-formula><mml:math id="inf16"><mml:mi>i</mml:mi></mml:math></inline-formula> to be correctly classified. This can be expressed as,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM4">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf17"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> a measurement originating from the same direction and location as template <inline-formula><mml:math id="inf18"><mml:mi>i</mml:mi></mml:math></inline-formula> but each sample corrupted with noise (<inline-formula><mml:math id="inf19"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>). Therefore, <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> can be read as the probability of correctly classifying measurement <inline-formula><mml:math id="inf20"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> as originating from template <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> given the noise level <inline-formula><mml:math id="inf22"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>.</p><p><inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM11">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is given by the probability that the distance between <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> is smaller than the distance between <inline-formula><mml:math id="inf26"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> and any other stored template <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>. Formally,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf28"><mml:mi>d</mml:mi></mml:math></inline-formula> defined as the Mahalanobis distance between template <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and measurement <inline-formula><mml:math id="inf30"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub id="XM33"><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup id="XM34"><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM35"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM36"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf31"><mml:mi>Q</mml:mi></mml:math></inline-formula> a diagonal matrix with <inline-formula><mml:math id="inf32"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> as diagonal elements.</p><p>We estimated <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM37">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using a Monte Carlo approach whereby we generated measurements <inline-formula><mml:math id="inf34"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> by adding normally distributed noise to template <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>. We calculated the distance between the generated measurement and all templates. <inline-formula><mml:math id="inf36"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM38">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was calculated by observing the proportion of generated measurements <inline-formula><mml:math id="inf37"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> that had a smaller distance to <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> than to any other <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>. We generated at between 100 and 1000 replications of <inline-formula><mml:math id="inf40"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> for every template. The process of estimating <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM39">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was stopped when the estimate converged and changes to <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM40">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> were smaller than 0.01.</p><p>In addition to the probability of correct classification we calculated the average angular error <inline-formula><mml:math id="inf43"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> as<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>c</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM49">c</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM50">i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the great circle distance (i.e. angular separation) between the positions corresponding with templates <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>T</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>.</p></sec></sec><sec id="s2-4"><title>Quantifying template continuity</title><sec id="s2-4-1"><title>Angular catchment distance</title><p>To quantify how smoothly templates change across angles in the St Andrews data set, we calculated the dissimilarity between templates as a function of the angular separation between them. We used the previously defined distance <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub id="XM51"><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub id="XM52"><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to calculate the dissimilarity between templates <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>.</p><p>For each of the 12 positions <inline-formula><mml:math id="inf50"><mml:mi>x</mml:mi></mml:math></inline-formula>, we calculated the average dissimilarity between template <inline-formula><mml:math id="inf51"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>x</mml:mi><mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></inline-formula> for direction <inline-formula><mml:math id="inf52"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> and every other template <inline-formula><mml:math id="inf53"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula> with an angular separation of <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:math></inline-formula>. The angular catchment distance for each of the 12 positions <inline-formula><mml:math id="inf55"><mml:mi>x</mml:mi></mml:math></inline-formula> was defined as the angular distance <inline-formula><mml:math id="inf56"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:math></inline-formula> over which the dissimilarity between the templates increased monotonically, in accordance with <xref ref-type="bibr" rid="bib78">Zeil et al., 2003</xref>.</p></sec><sec id="s2-4-2"><title>Linear catchment distance</title><p>Template continuity in the Israel and Royal Fort Gardens data sets was quantified in a similar way. We calculated the distance along the corridor over which the dissimilarity (i.e. Mahalanobis distance, <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) between templates increased monotonically. For each of the 217 directions <inline-formula><mml:math id="inf57"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> and 40 or 50 positions <inline-formula><mml:math id="inf58"><mml:mi>x</mml:mi></mml:math></inline-formula>, the dissimilarity between the template <inline-formula><mml:math id="inf59"><mml:msubsup><mml:mi>T</mml:mi><mml:mi>x</mml:mi><mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></inline-formula> and each template <inline-formula><mml:math id="inf60"><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></inline-formula> at a different location <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (but same direction <inline-formula><mml:math id="inf62"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>) was calculated using <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>. Next, the linear catchment distance for every position <inline-formula><mml:math id="inf63"><mml:mi>x</mml:mi></mml:math></inline-formula> was taken as the average distance <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> over which the dissimilarity increased monotonically. To allow for the noisy character of the data, we used a 1% threshold. This is, we considered dissimilarity to increase monotonically if any decrease, if present, in dissimilarity was less than 1% of the median dissimilarity found between all pairs of templates in our data set. In addition, we required the dissimilarity to be at least 10% of the median dissimilarity between all pairs of templates in our data. This prevented trivial increases in dissimilarity from being taken into account. Finally, we took the median catchment distance across all positions <inline-formula><mml:math id="inf65"><mml:mi>x</mml:mi></mml:math></inline-formula> for each of the 217 directions <inline-formula><mml:math id="inf66"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>.</p></sec></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Template classification</title><p>The probability of correct classification for each of the 217 directions for the 12 positions in the St. Andrews data set is plotted in <xref ref-type="fig" rid="fig6">Figure 6</xref>. For the Open environments, the probability of correct classification was very low (i.e. <inline-formula><mml:math id="inf67"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). In contrast, for the Semi cluttered and the Cluttered environments the number of templates that could be recognized with a high probability increased. The fourth Semi cluttered environment was an outlier. The classification probabilities for this position were very low. Physically, this environment might have resembled an Open environment. The branches of the large coniferous tree, the major feature at this position, did not reach low enough for them to generate echoes. <xref ref-type="fig" rid="fig6">Figure 6</xref> also depicts the angular error <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> for each of the 217 directions in the 12 positions. These results mirror those for the probability of classification showing large errors in the open conditions and small errors in the cluttered positions.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.008</object-id><label>Figure 6.</label><caption><title>Template classification performance.</title><p>Left: Panoramic views taken at the 12 positions. Middle: Probability (<inline-formula><mml:math id="inf69"><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula>) for each of the 12 St Andrews positions as a function of azimuth and elevation. right: Angular error (<inline-formula><mml:math id="inf70"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>) for each of the 12 St Andrews positions as a function of azimuth and elevation.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.008">http://dx.doi.org/10.7554/eLife.14188.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig6-v1"/></fig></p><p>In an additional analysis, we confirmed that only few confusions occurred between templates from different positions. This is, the probability <inline-formula><mml:math id="inf71"><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> for a given template did not decrease markedly (<inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mover><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>∼</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) when allowing for confusion between a given template (corresponding to one position at one azimuth and elevation direction) and templates taken from other positions (at the same or at a different angle).</p></sec><sec id="s3-2"><title>Template continuity</title><sec id="s3-2-1"><title>Angular catchment area</title><p>Using the St. Andrews data, we assessed the angular catchment area for templates by assessing the increase in dissimilarity between templates as a function of angular separation (<xref ref-type="fig" rid="fig7">Figure 7</xref>). For the templates collected in the Open habitats, we observed virtually no increase in dissimilarity as a function of separation angle. In contrast, for the Semi Cluttered and the Cluttered habitats, there was a tendency for the dissimilarity to increase as a function of angular separation (except for Semi Cluttered 4). The angular separation at which the dissimilarity leveled off varied across habitats and habitat types. However, angular catchment areas up to about 90 degrees (Semi 3) and 150 degrees (Cluttered 2) were found. This indicates that, on average, the dissimilarity between templates is a monotonic function of angular separation over a wide range of separation angles.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.009</object-id><label>Figure 7.</label><caption><title>Evaluation of the angular catchment areas using the St Andrews data.</title><p>Left column: Examples of the dissimilarity between a reference template and the other 216 directions for an Open, a Semi Cluttered, and a Cluttered habitat. The direction of the reference template (azimuth 0° &amp; elevation −7°) is indicated by a white dot. The dissimilarity between the reference template and all other templates is depicted by the contour plots. Right: the average dissimilarity between templates as a function of the angular separation in each of the Open, Semi cluttered and Cluttered habitats. The mean dissimilarity as a function of the angular separation for each of the three types of habitats is indicated by a black dotted line. A horizontal black line indicates the average dissimilarity between randomly selected templates. The dissimilarity between unrelated templates serves as a baseline against which the dissimilarity as a function of angular separation can be compared (<xref ref-type="bibr" rid="bib16">Greif and Siemers, 2010)</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.009">http://dx.doi.org/10.7554/eLife.14188.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig7-v1"/></fig></p></sec><sec id="s3-2-2"><title>Linear catchment distance</title><p><xref ref-type="fig" rid="fig8">Figures 8a–f</xref> and <xref ref-type="fig" rid="fig9">9a–f</xref> illustrate the process of assessing the continuity of the Israel and Royal Fort Gardens data sets respectively. In both figures, panels c and f show the linear catchment distances for the templates for two selected azimuth &amp; elevation directions. The plots illustrate the variability in the linear catchment distances across templates with values ranging from approximately 0 to 3.5 m.<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.010</object-id><label>Figure 8.</label><caption><title>Catchment distance for the Israel site.</title><p>Illustration of the process of finding the catchment distance for the Israel data and the median catchment distance as a function of direction. (<bold>a</bold>) Templates for ensonification direction −20<inline-formula><mml:math id="inf73"><mml:msup><mml:mi/><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula>° azimuth and −10° elevation as a function of the position (i.e. 0 to 10 m). (<bold>b</bold>) The pairwise dissimilarity between the templates in panel (<bold>a</bold>) as a function of the displacement between the templates. (<bold>c</bold>) For each position, a linear catchment distance was calculated. This was done by finding the template separation interval across which the distance increased monotonically. (<bold>c</bold>) The resulting catchment distances for the data in panel (<bold>b</bold>). (<bold>d</bold>), (<bold>e</bold>), (<bold>f</bold>) similar but for azimuth direction 40° and 10° elevation. (<bold>g</bold>) The median catchment distance for each of the 217 azimuth and elevation directions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.010">http://dx.doi.org/10.7554/eLife.14188.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig8-v1"/></fig><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.011</object-id><label>Figure 9.</label><caption><title>Catchment distance for the Royal Fort Gardens data.</title><p>Similar as <xref ref-type="fig" rid="fig8">Figure 8</xref> but for the Royal Fort Gardens data set.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.011">http://dx.doi.org/10.7554/eLife.14188.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig9-v1"/></fig></p><p>In the Israel data, across all positions and directions, the catchment distances rangedup to 6.6 meter. In the Royal Fort Gardens data set, we found catchment distances up to 2.5 meter. Across both data sets the average catchment distance was 0.89 meter (sd: 0.61), see <xref ref-type="fig" rid="fig10">Figure 10a</xref>. A Wilcoxon rank sum test confirmed that the linear catchment distances for the Israel data were larger than for the Royal Fort Gardens data (<inline-formula><mml:math id="inf74"><mml:mrow><mml:mrow id="XM53"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mn>52.3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow id="XM54"><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Panels g in <xref ref-type="fig" rid="fig8">Figures 8</xref> and <xref ref-type="fig" rid="fig9">9</xref> depict the median linear catchment distance as a function of azimuth and elevation.<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.012</object-id><label>Figure 10.</label><caption><title>Linear attractor distances.</title><p>(<bold>a</bold>) Histogram of the linear attractor sizes for both the Israel and Royal Fort Gardens data set. (<bold>b</bold>) Plot showing the proportion of templates with a linear attractor distance larger than a given value.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.012">http://dx.doi.org/10.7554/eLife.14188.012</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig10-v1"/></fig></p><p>We confirmed that for both the Royal Fort Gardens data set and the Israel data set the probability of correct classification was high. The average probabilities <inline-formula><mml:math id="inf75"><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> were 0.82 (sd: 0.21) and 0.99 (sd: 0.03) for the Israel and Royal Fort Gardens data sets, respectively. A Wilcoxon rank sum test confirmed that the templates in the Royal fort gardens were easier to classify correctly. (<inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow id="XM55"><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>95.2</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow id="XM56"><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). The difference in the distribution of <inline-formula><mml:math id="inf77"><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> for both data sets can also be appreciated from inspecting <xref ref-type="fig" rid="fig11">Figure 11</xref>.<fig id="fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.013</object-id><label>Figure 11.</label><caption><title>Probability of correct classificaiton as a function of the linear catchement distance.</title><p>2D histograms of the probability of correct classification <inline-formula><mml:math id="inf78"><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> versus the linear catchment distances for the templates in the Israel (left) and Royal fort (right) data sets.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.013">http://dx.doi.org/10.7554/eLife.14188.013</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig11-v1"/></fig></p><p>We calculated the correlation between the linear catchment distance and the probability of correct classification. We found <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.18</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (95% C.I.: ±0.02, <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>) and <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula> (95% C.I.: ±0.02, <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≫</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) in the Israel and Royal Fort Gardens data set, respectively. When pooling the data for both sets, a negative correlation between the linear catchment distance and the probability of correct classification was found (<inline-formula><mml:math id="inf83"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.32</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% C.I.: ±0.01, <inline-formula><mml:math id="inf84"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>). The relationship between the probability of correct classification and the linear catchment distance is also depicted in <xref ref-type="fig" rid="fig11">Figure 11</xref> by means of 2D histograms.</p></sec></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><sec id="s4-1"><title>Template properties</title><p>In this paper, we propose template based place recognition might underlie sonar-based navigation in bats. Under this hypothesis, bats would recognize places by remembering their echo signature - rather than their 3D layout. Using ensonification data, we assessed the viability of this alternative hypothesis regarding bat navigation by assessing two critical properties of the templates: (1) unique classification of templates and (2) template continuity. In the following, we discuss our findings regarding these two properties.</p><sec id="s4-1-1"><title>Template classification</title><p>The data show that the templates, as constructed in the paper, can be reliably classified, even using a system with a dynamic range smaller than a bat’s (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The typical emission levels of bats are substantially higher (reaching 140 dB<inline-formula><mml:math id="inf85"><mml:msub><mml:mi/><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at 10 cm for a wide frequency range [<xref ref-type="bibr" rid="bib23">Holderied et al., 2005</xref>; <xref ref-type="bibr" rid="bib59">Surlykke and Kalko, 2008</xref>]) than the emission levels for our speaker (maximally 126 dB<inline-formula><mml:math id="inf86"><mml:msub><mml:mi/><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at 50 kHz and 10 cm). Moreover, FM bats have been shown to have hearing thresholds as low as 0 dB<inline-formula><mml:math id="inf87"><mml:msub><mml:mi/><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib20">Hoffmann et al., 2008</xref>). In contrast, the Knowles FG series microphones used in the paper have an estimated self-noise level of about 25 dB<inline-formula><mml:math id="inf88"><mml:msub><mml:mi/><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib1">Avisoft Bioacoustics, 2015</xref>).</p><p>The finding that templates can be readily classified is in agreement with the results of robotic studies that have shown that sonar templates can be used to recognize locations and viewpoints, e.g., (<xref ref-type="bibr" rid="bib54">Steckel and Peremans, 2013</xref>; <xref ref-type="bibr" rid="bib33">Mataric and Brooks, 1990</xref>; <xref ref-type="bibr" rid="bib31">Kuipers, 2000</xref>). By definition, the probability to correctly classify a template depends on the ratio of its systematic variation compared to its random variability. Hence, lacking systematic variation, templates collected in Open habitats could not be classified. As expected, in the absence of diagnostic echoes place recognition is impossible.</p><p>It is important to stress that the templates could be correctly classified, even though they did not preserve spectral information. Indeed, the templates were constructed by averaging the cochleograms over the frequencies thereby removing spectral cues (Algorithm 1, step 3). In addition, dechirping of the spectrograms (Algorithm 1, step 1) makes the templates largely independent from call duration. This has two implications. First, navigation by templates as proposed here does not depend heavily on call design. Indeed, the spectral and temporal aspects of bats’ calls can vary from call to call, e.g. (<xref ref-type="bibr" rid="bib60">Surlykke and Moss, 2000</xref>; <xref ref-type="bibr" rid="bib28">Kalko, 1995</xref>). By using descriptors of the environment that do not depend critically on call design a bat could navigate the same environment largely independent of the call used. A second implication is that template based navigation should also be feasible for bats using narrowband calls. For example, Rhinolophidae use long narrowband calls preceded and/or followed by a short frequency sweep (<xref ref-type="bibr" rid="bib43">Schnitzler and Denzinger, 2011</xref>). The frequency range of these sweeps is limited compared to the sweeps used by bats using frequency modulated calls. Nevertheless, Rhinolophidae have specialized in hunting under cluttered circumstances and face rather challenging navigation tasks (<xref ref-type="bibr" rid="bib45">Schnitzler et al., 2003</xref>; <xref ref-type="bibr" rid="bib44">Schnitzler and Kalko, 2001</xref>). A mechanism for recognizing places that does not rely on spectral cues makes for a more plausible candidate for explaining how these bats can find their way using calls with a limited bandwidth.</p></sec><sec id="s4-1-2"><title>Template continuity</title><p>We assessed both the angular (St Andrews data, <xref ref-type="fig" rid="fig7">Figure 7</xref>) and linear (Israel and Royal Fort Gardens data, <xref ref-type="fig" rid="fig8">Figures 8</xref>,<xref ref-type="fig" rid="fig9">9</xref>) catchment areas. We found the dissimilarity between templates to increase monotonically for angular separations up to about 50 and 150 degrees in the Semi Cluttered and Cluttered habits respectively. In addition, on average, the dissimilarity between templates increases monotonically for up about 0.89 m of linear separation (see <xref ref-type="fig" rid="fig10">Figure 10a</xref>).</p><p>Whether these catchment areas are sufficiently large to be functional remains to be tested. However, the linear catchment distances reported here are similar in size to those likely to be experienced by insects using vision based homing. Zeil et al. (<xref ref-type="bibr" rid="bib78">Zeil et al., 2003</xref>; <xref ref-type="bibr" rid="bib57">Stürzl and Zeil, 2007</xref>) collected large sets of panoramic images spaced 10 cm apart in outdoor environments. They calculated the dissimilarity between images as a function of the spacing. They found that linear catchment distances do not exceed 1 m. The catchment distances reported here are also substantially larger than those found in a robotic experiment by <xref ref-type="bibr" rid="bib54">Steckel and Peremans (2013)</xref>. These authors collected sonar based templates in an office environment by driving around a robot equipped with a biomimetic sonar system. They found that displacing the robot by about 14 cm or 20 degrees resulted in leaving the current template’s catchment area. In spite of these small catchment areas, they successfully derived a map of the office using the templates. Hence, successful navigation seems to be possible with catchment areas that are smaller than those found in this paper.</p><p>In addition, the results regarding the angular and linear catchment distances dovetail with the echolocation behaviour of bats as recorded under field conditions. For many templates, the linear catchment distances are larger than the distance bats seem to cover between calls. <xref ref-type="bibr" rid="bib46">Seibert et al. (2013)</xref> reported a maximum flight speed of about 6 m/s for commuting <italic>Pipistrellus pipistrellus</italic> across several field conditions. The bats maintained pulse rates higher than 10 Hz. Similar pulse rates and flight speeds were reported for commuting <italic>Myotis dasycneme</italic> (<xref ref-type="bibr" rid="bib67">Verboom et al., 1999</xref>; <xref ref-type="bibr" rid="bib3">Britton et al., 1997</xref>). Finally, commuting <italic>Myotis mystacinus</italic> were found to adopt flight speeds well below 10 ms<sup>−1</sup> whilst maintaining pulse rates higher than 10 Hz (<xref ref-type="bibr" rid="bib22">Holderied et al., 2006</xref>). In summary, pulse rates higher than 10 Hz seem to be the trend across bat species (<xref ref-type="bibr" rid="bib48">Siemers et al., 2001</xref>) while flight speeds above 10 ms<sup>−1</sup> are rare (<xref ref-type="bibr" rid="bib21">Holderied, 2001</xref>).</p><p>Even a (low) pulse rate of 10 Hz and a (high) flight speed of 10 m/s results in sampling the environment at 1 m intervals. In our data, a substantial portion of templates (about 64%, <xref ref-type="fig" rid="fig10">Figure 10b</xref>) had a catchment diameter larger than 1 m . Note that the diameter of a catchment area is twice the catchment distance. Therefore, in our data catchment diameters are on average 1.77 m wide (i.e., 2 × 0.89 m). A bat flying through the environment and calling at 10 Hz will always sample the template’s catchment region if its diameter is larger than 1 m. Such a template could act as a reliable signpost en route to the bat’s destination.</p><p>When flying at commuting speeds, bats maintain a low angular velocity. <xref ref-type="bibr" rid="bib21">Holderied (2001)</xref> showed that commuting bats adapt the curvature of their flight path in function of the current flight speed. Even at 5 ms, he found bats to restrict their angular velocity to about 280 deg/s. At a call rate of 10 Hz, this implies a change in direction of about 28 degrees per call. At 10 ms<sup>−1</sup>, this reduces to about 6 degrees per call. Hence, the changes in the orientation of a commuting bat between calls seem to be less than the angular catchment distances found here. Active scanning would result in larger changes in gaze direction. In a study quantifying the scanning behaviour of <italic>Pipistrellus pipistrellus</italic> in the field the largest angle between subsequent call directions was found to be 51 degrees. Hence, this study suggests that, even while actively scanning, bats tend to change the direction of their beam by less than the angular catchment distances of templates in cluttered and semi-cluttered environments. In summary, it seems that the angular spatial sample rate maintained by bats is higher than the average angular catchment distances of templates.</p><p>We conclude that the spatial separation of successive calls of bats tends to be less than the size of the catchment areas reported here. In addition, successful navigation is possible with even smaller catchment areas (<xref ref-type="bibr" rid="bib78">Zeil et al., 2003</xref>; <xref ref-type="bibr" rid="bib57">Stürzl and Zeil, 2007</xref>; <xref ref-type="bibr" rid="bib54">Steckel and Peremans, 2013</xref>). Therefore, we propose that the linear and rotational catchment areas reported here are not trivial and are functionally relevant.</p><p>The template continuity observed in the current data sets is a consequence of both the beam width and the temporal integration in the model of the auditory periphery. As mentioned in the introduction (<xref ref-type="fig" rid="fig1">Figure 1</xref>), both parameters determine the volume of space across which echoes are integrated. Wider beams and longer temporal integration result in templates that vary more smoothly with orientation and position in space. For an account of bat navigation that assumes bats to reconstruct a 3D model from an echo train the beam width and temporal integration constitute limitations of the echolocation system by reducing its resolution. In contrast, for a template based approach wider beams and longer integration times are not necessarily a problem. In contrast, these factors might facilitate navigation. As such, the finding that different bat species actively control their emission beams to converge on nearly the same field of view (<xref ref-type="bibr" rid="bib26">Jakobsen et al., 2013</xref>) could indicate that bats perform an optimal spatial smoothing while navigating the environment. Note that, as shown by these authors, optimal fields of view are task and habitat depending resulting in different trade-offs between beam range and width with corresponding linear and angular catchment area sizes.</p><p>In summary, we tentatively conclude that the templates satisfy both criteria as put forward in the introduction, i.e. they must allow for unique classification and be sufficiently continuous.</p></sec></sec><sec id="s4-2"><title>Differences between sites: possible trade-offs for navigating bats</title><p>The Royal Fort Gardens data set resulted in significantly smaller linear catchment distances (<xref ref-type="fig" rid="fig8">Figures 8</xref>,<xref ref-type="fig" rid="fig9">9</xref>,<xref ref-type="fig" rid="fig11">11</xref>). On the other hand, the average probability of correct classification was significantly higher in the Royal Fort Gardens data set (<xref ref-type="fig" rid="fig10">Figure 1</xref>). The difference in layout between the two sites can be appreciated from inspecting <xref ref-type="fig" rid="fig3">Figure 3</xref>. The Israel site was a more open habitat than the Royal fort site, where the reflecting foliage was closer to the ensonification device than the rocks at the Royal fort site. In addition, the rocks at the Israel site (in spite of being farther away) resulted in stronger echoes than the foliage at the Royal fort site (compare panels a &amp; d in <xref ref-type="fig" rid="fig8">Figures 8</xref>,<xref ref-type="fig" rid="fig9">9</xref>).</p><p>The larger linear catchment distances for the Israel data suggests that navigation by means of templates is facilitated by (strong) echoes originating from distant reflectors. Distant reflectors move more slowly through the bat’s ’field of view’, i.e., they undergo a smaller degree of motion parallax. As our data shows, this results in templates with larger catchment distances. This might facilitate navigation. On the other hand, the Royal Fort Gardens data suggest that the higher motion parallax for closer reflectors results in a better template classification. Indeed, closer reflectors change more abruptly when moving through space. This seems to result in templates that are easier to classify – at the cost of smaller linear catchment distances. In short, our data reveals a trade-off between the linear catchment distance size and the probability of correct classification of a template. The existence of this trade-off is confirmed by the negative correlation we found between the linear catchment distance size and the probability of correct classification.</p><p>Hence, our results suggest that navigating bats should maintain a preferred distance to foliage and other reflectors. Indeed, keeping a larger distance would reduce the average object motion parallax and result in larger linear catchment distances. On the other hand, keeping a larger distance would reduce the probability of correctly classifying templates. In addition, flying further away from objects will, in general, result in weaker echoes (in our Israel data this effect has been offset by the strong echoes returned by the rocks). Therefore, our template theory of navigation predicts navigation would be facilitated by keeping a distance from reflectors that balances the opposing effects of motion parallax on the templates’ linear catchment distance and probability of correct classification.</p></sec><sec id="s4-3"><title>Using templates for mapping</title><p>Whilst successful navigation does not require a map-like representation, e.g. (<xref ref-type="bibr" rid="bib7">Cruse and Wehner, 2011</xref>; <xref ref-type="bibr" rid="bib5">Cheung et al., 2014</xref>; <xref ref-type="bibr" rid="bib19">Hesslow, 2012</xref>; <xref ref-type="bibr" rid="bib6">Collett et al., 2013</xref>), it is likely that bats use some sort of cognitive map (<xref ref-type="bibr" rid="bib15">Geva-Sagiv et al., 2015</xref>). However, to the best of our knowledge, the use of such a map has not been demonstrated experimentally (<xref ref-type="bibr" rid="bib24">Holland, 2007</xref>). Nevertheless, indirect evidence for the existence of a cognitive map, integrating echolocation information if available, is the finding of grid and place cells in bats (<xref ref-type="bibr" rid="bib76">Yartsev et al., 2011</xref>; <xref ref-type="bibr" rid="bib75">Yartsev and Ulanovsky, 2013</xref>) and bats’ ability to remember flight routes in a completely dark room (<xref ref-type="bibr" rid="bib2">Barchi et al., 2013</xref>).</p><p>Building and maintaining a cognitive map based on sonar templates would require the successful completion of three subtasks: (1) exploring the environment and building a library of templates, (2) integrating the templates into a map-like representation, (3) deriving motor plans from this representation that take the bat from its current location to a desired position. So far, knowledge about how bats could address these challenges is very sparse. However, work has begun on each of these components. Below, we review this work and outline a potential strategy for constructing a cognitive map using the templates as proposed in this paper.</p><sec id="s4-3-1"><title>Exploring</title><p><xref ref-type="bibr" rid="bib65">Vanderelst et al. (2015)</xref> proposed an algorithm for obstacle avoidance in bats that relies on a very simple, yet robust, mechanism comparing the loudness of the onset of the echoes at the left and right ear and turning away from the side receiving the loudest echo. As shown by the simulation results presented by <xref ref-type="bibr" rid="bib65">Vanderelst et al. (2015)</xref>, this simple obstacle avoidance algorithm is able to steer the bat away from obstacles in both planar and true 3D environments. Furthermore, while it contains a stochastic component this obstacle avoidance behaviour still constrains the movement through the environment causing the bat to follow a limited set of routes through a given environment. The results presented here on the sizes of the catchment areas indicate that any sensorimotor strategy that causes the bats to repeatedly visit approximately the same sites will allow them to explore their environment while building a library of templates describing this environment. Hence, this obstacle avoidance mechanism but also other environment driven guidance behaviours (<xref ref-type="bibr" rid="bib15">Geva-Sagiv et al., 2015</xref>), e.g. edge following (<xref ref-type="bibr" rid="bib33">Mataric and Brooks, 1990</xref>; <xref ref-type="bibr" rid="bib67">Verboom et al., 1999</xref>; <xref ref-type="bibr" rid="bib22">Holderied et al., 2006</xref>), that make the bats follow a restricted set of routes through the environment while exploring, could support a template based description of the environment.</p></sec><sec id="s4-3-2"><title>Building the map</title><p>Recent work in robotics has offered a suggestion about how bats could integrate templates into a map of the environment. <xref ref-type="bibr" rid="bib54">Steckel and Peremans (2013)</xref> proposed the BatSLAM algorithm to integrate odometry, also called path integration, and templates into a semi-metric map of the environment. BatSLAM is a bio-inspired sonar navigation algorithm, derived from RatSLAM (<xref ref-type="bibr" rid="bib35">Milford et al., 2004</xref>), mirroring the basic functionality of the mammalian hippocampus. In brief, the algorithm directly uses the spectrogram of the echoes as a template to recognize distinct places. The odometry is used to estimate the relative position of different locations labelled by their respective spectrograms. The algorithm averages across measurements of the very noisy odometry for different travels between the same locations. Finally, agreement between conflicting information is sought by applying a relaxation algorithm. The outcome of this process is a graph-like representation of the relative locations of different recognizable places (see <xref ref-type="fig" rid="fig12">Figure 12</xref>). Details of the mapping algorithm have been presented by <xref ref-type="bibr" rid="bib54">Steckel and Peremans (2013)</xref> and <xref ref-type="bibr" rid="bib73">Wyeth and Milford (2009)</xref>. In summary, BatSLAM, and similar algorithms (<xref ref-type="bibr" rid="bib17">Grisetti et al., 2010</xref>), offer biologically plausible suggestions of how bats can integrate templates and odometry into a semi-metric map of the environment.<fig id="fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.14188.014</object-id><label>Figure 12.</label><caption><title>Conceptual sketch of an environment and a map.</title><p>The blue circles represent templates and their catchment areas. The white lines between them represent directions and distances between template locations inferred from odometry, thereby forming a graph-like representation of space. A bat navigating this map (represented by the grey arrow) can use the templates as sign posts at which it reorients itself. Having recognized a particular template (catchment area) the bat knows where it is and approximately which direction it should fly in to arrive at any of the other template locations. Notice that the (catchment areas of) the templates do not cover the complete space.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.14188.014">http://dx.doi.org/10.7554/eLife.14188.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-14188-fig12-v1"/></fig></p><p>Furthermore, we would like to point out that the way such a template based map of the environment is built could also explain the tendency of bats to rely on prominent reflectors or landscape elements as landmarks to guide their navigation (<xref ref-type="bibr" rid="bib67">Verboom et al., 1999</xref>; <xref ref-type="bibr" rid="bib27">Jensen et al., 2005</xref>). This might occur through two different but converging mechanisms. First, prominent reflectors often result in idiosyncratic and thus highly classifiable templates. As BatSLAM uses recognition of previously visited places to drive the relaxation algorithm, the places associated with such templates will act as anchor points for the graph-like map. Indeed, if a place is highly recognizable odometric errors occurring along the various routes that pass through this place will be easier to remove by the relaxation process. Consequently, the metric positions of the routes passing through this place will be defined more precisely relative to the other important places represented in the map, such as start and goal position. A path planner considering this a desirable property would then preferentially generate routes passing through the catchment area associated with this prominent reflector. In our data, highly recognizable templates in the semi-cluttered environments coincided with the locations of shrubs and trees, suggesting their possible use as landmarks. Secondly, prominent reflectors often generate strong echoes making them detectable from a long distance and resulting in the corresponding templates to have large catchment areas (For example, in this paper, the rocks at the Isreal site, <xref ref-type="fig" rid="fig8">Figures 8</xref>,<xref ref-type="fig" rid="fig9">9</xref>,<xref ref-type="fig" rid="fig10">10</xref>).</p><p>The extent of the catchment area of a template is positively correlated with the probability that this template will be observed and stored in the map during the exploration of the environment. By biasing the templates included in the map, this mechanism would again bias a planner to generate routes passing through the catchment areas of prominent reflectors. In our data, the linear catchment distances were found to be larger in the Israeli corridor of boulders than in the corridor of vegetation in Royal Fort Gardens, suggesting a possible preference for the use of the former as landmarks. We conclude that a navigation strategy relying on a template based map would show a natural preference for routes including prominent landscape features. Hence, we propose that the use of landmarks might be an emergent feature of a mapping strategy recognizing locations using templates (<xref ref-type="bibr" rid="bib74">Wystrach et al., 2011</xref>).</p></sec><sec id="s4-3-3"><title>Using the map</title><p>Using the map requires planning a route and executing it. Of these, planning is the least challenging (<xref ref-type="bibr" rid="bib4">Brooks, 1991</xref>). Many algorithms (<xref ref-type="bibr" rid="bib31">Kuipers, 2000</xref>; <xref ref-type="bibr" rid="bib40">Russell and Norvig, 1995</xref>) have been proposed that allow agents to plan a route given a graph-like network of locations and routes between them. Executing the generated plan requires adequate motor control and is a more difficult problem (<xref ref-type="bibr" rid="bib4">Brooks, 1991</xref>). To the best of our knowledge, no work has been done on how bats select, initiate and execute appropriate sensor-motor loops to use the map to navigate to desired locations (i.e. step 3 in the challenges listed above). In contrast, robotic studies have extensively addressed the issues regarding the execution of a planned sequence of actions (<xref ref-type="bibr" rid="bib31">Kuipers, 2000</xref>; <xref ref-type="bibr" rid="bib47">Siciliano and Khatib, 2008</xref>). We propose that an integrated model of bat navigation could draw inspiration from the solutions derived in this field.</p></sec></sec><sec id="s4-4"><title>3D object layout versus template-based scene representation</title><p>In this paper, we have proposed that bats recognize places by remembering their echo signature - rather than their 3D layout. It could be argued that, since bats have been shown to be capable of recognizing objects, they could very well use that same capability to recognize scenes based on the 3D object layout. However, we would like to point out that the behaviour of bats in recognition experiments differs from that of cruising/navigating bats. In recognition experiments, bats typically ensonify the same object from different directions as part of an active object-centred exploration process, e.g. (<xref ref-type="bibr" rid="bib13">Genzel et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Geipel et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Simon et al., 2006</xref>). Cruising/navigating bats, on the other hand, fly by objects along their flight path resulting in a more accidental, i.e. less object-centred, and less extensive series of observations of those objects. Such a fly-by mode of echolocation is well suited to the proposed template-based strategy as it requires local ’snapshots’ only. Also, we would like to argue that even in the object recognition experiments bats might not be building a 3D reconstruction of the object. They might instead be looking for diagnostic acoustic cues, e.g. spectral cues as hypothesized in the study by <xref ref-type="bibr" rid="bib52">Simon et al. (2006)</xref>. Such an account of object recognition would be easily integrated with our template-based account of place recognition. One possible way the two might interact is that the template-based place descriptors would be used to build a map first and then later (or possibly in parallel) ’landmarks’, i.e. uniquely identified objects, would be associated with places on the map.</p><p>Hence, while we agree that a 3D place description -were it to exist- would be more general and easier to change, we believe it still remains to be proven that such a description is actually built by bats in a navigation context. Indeed, it is our hypothesis that bats would be driven towards an alternative, template based, mechanism either by the inability of their sonar systems to reconstruct a 3D layout of the environment or, if a 3D layout of the environment could be inferred from the echoes, by the associated much higher computational burden placed upon their limited cognitive resources.</p><p>To produce direct evidence that would allow choosing between the two alternatives, we suggest future experiments might be set up to test the prediction by the template based place recognition mechanism advocated here that bats would not be able to distinguish between scenes if their 3D layout is different while their resulting template is similar. Therefore, behavioural evidence in favour of our approach would consist of bats failing to distinguish complex scenes giving rise to many echoes, i.e. with a similar complexity of their natural habitats, that result in the same template, essentially a low-pass filtered range-intensity profile. To test this, one could generate echoes from a complex virtual scene and its mirror image. These should result in the same template whereas a 3D model account predicts bats should be able to distinguish between the two scenes. Alternatively and possibly more straightforward to test, the 3D model account predicts bats would be able to recognize echoes coming from rotated versions of the same underlying scene. The template approach predicts that bats would be unable to make such generalizations for larger rotations, i.e. once the measured template would fall outside the catchment area of the stored template.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Dr. Noam Josef, Gabriella Scatà and Professor Carmi Corine (Ben-Gurion University of the Negev) for their help with data collection in Israel. We thank Rayssa Motta do Nascimento and Ivan Cardoso (Universidade Federal do Rio de Janeiro) for their help with data collection St Andrews park. We thank Sam Riches (University of Bristol) for his help in collecting data at the Royal Park site. Dieter Vanderelst was funded in part by a Postdoctoral Marie Curie Fellowship and by a postdoctoral fellowship from the Research Foundation Flanders.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>DV, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>JS, Conception and design, Acquisition of data, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con3"><p>AB, Conception and design, Acquisition of data</p></fn><fn fn-type="con" id="con4"><p>HP, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>MWH, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="data-ro1" source-id="http://dx.doi.org/10.5281/zenodo.58579" source-id-type="uri"><collab>Dieter Vanderelst</collab><x>,</x> <collab>Jan Steckel</collab><x>,</x> <collab>Andre Boen</collab><x>,</x> <collab>Ma</collab><x>,</x> <collab>Herbert Peremans</collab><x>,</x> <year>2016</year><x>,</x><source>Data and Computer scripts for 'Place recognition using batlike sonar'</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5281/zenodo.58579">http://dx.doi.org/10.5281/zenodo.58579</ext-link><x>,</x> <comment>Publicly available from the Zenodo website (accession no: 58579)</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="software"><source>Avisoft Bioacoustics</source><year iso-8601-date="2015">2015</year><uri xlink:href="http://www.ultrasoundgate.com/KnowlesFG.htm">http://www.ultrasoundgate.com/KnowlesFG.htm</uri></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barchi</surname><given-names>JR</given-names></name><name><surname>Knowles</surname><given-names>JM</given-names></name><name><surname>Simmons</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial memory and stereotypy of flight paths by big brown bats in cluttered surroundings</article-title><source>Journal of Experimental Biology</source><volume>216</volume><fpage>1053</fpage><lpage>1063</lpage><pub-id pub-id-type="doi">10.1242/jeb.073197</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britton</surname><given-names>ARC</given-names></name><name><surname>Jones</surname><given-names>G</given-names></name><name><surname>Rayner</surname><given-names>JMV</given-names></name><name><surname>Boonman</surname><given-names>AM</given-names></name><name><surname>Verboom</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Flight performance, echolocation and foraging behaviour in pond bats, Myotis dasycneme (Chiroptera: Vespertilionidae)</article-title><source>Journal of Zoology</source><volume>241</volume><fpage>503</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7998.1997.tb04842.x</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>R.a</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Intelligence without representation</article-title><source>Artificial Intelligence</source><volume>47</volume><fpage>139</fpage><lpage>159</lpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheung</surname><given-names>A</given-names></name><name><surname>Collett</surname><given-names>M</given-names></name><name><surname>Collett</surname><given-names>TS</given-names></name><name><surname>Dewar</surname><given-names>A</given-names></name><name><surname>Dyer</surname><given-names>F</given-names></name><name><surname>Graham</surname><given-names>P</given-names></name><name><surname>Mangan</surname><given-names>M</given-names></name><name><surname>Narendra</surname><given-names>A</given-names></name><name><surname>Philippides</surname><given-names>A</given-names></name><name><surname>Stürzl</surname><given-names>W</given-names></name><name><surname>Webb</surname><given-names>B</given-names></name><name><surname>Wystrach</surname><given-names>A</given-names></name><name><surname>Zeil</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Still no convincing evidence for cognitive map use by honeybees</article-title><source>PNAS</source><volume>111</volume><fpage>E4396</fpage><lpage>E4397</lpage><pub-id pub-id-type="doi">10.1073/pnas.1413581111</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collett</surname><given-names>M</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Collett</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial memory in insect navigation</article-title><source>Current Biology</source><volume>23</volume><fpage>R789</fpage><lpage>800</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.07.020</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruse</surname><given-names>H</given-names></name><name><surname>Wehner</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>No need for a cognitive map: decentralized memory for insect navigation</article-title><source>PLoS Computational Biology</source><volume>7</volume><elocation-id>e1002009</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002009</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dau</surname><given-names>T</given-names></name><name><surname>Püschel</surname><given-names>D</given-names></name><name><surname>Kohlrausch</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A quantitative model of the &quot;effective&quot; signal processing in the auditory system. I. Model structure</article-title><source>The Journal of the Acoustical Society of America</source><volume>99</volume><fpage>3615</fpage><lpage>3622</lpage><pub-id pub-id-type="doi">10.1121/1.414959</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontaine</surname><given-names>B</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Determining biosonar images using sparse representations</article-title><source>The Journal of the Acoustical Society of America</source><volume>125</volume><fpage>3052</fpage><lpage>3059</lpage><pub-id pub-id-type="doi">10.1121/1.3101485</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franz</surname><given-names>MO</given-names></name><name><surname>Mallot</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Biomimetic robot navigation</article-title><source>Robotics and Autonomous Systems</source><volume>30</volume><fpage>133</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/S0921-8890(99)00069-X</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Geberl</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial and temporal resolution of bat sonar</article-title><source>Ph.D. Thesis</source><publisher-name>Ludwig-Maximilians-Universität München</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geipel</surname><given-names>I</given-names></name><name><surname>Jung</surname><given-names>K</given-names></name><name><surname>Kalko</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Perception of silent and motionless prey on vegetation by echolocation in the gleaning bat Micronycteris microtis</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>280</volume><elocation-id>20122830</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2012.2830</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Genzel</surname><given-names>D</given-names></name><name><surname>Geberl</surname><given-names>C</given-names></name><name><surname>Dera</surname><given-names>T</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Coordination of bat sonar activity and flight for the exploration of three-dimensional objects</article-title><source>Journal of Experimental Biology</source><volume>215</volume><fpage>2226</fpage><lpage>2235</lpage><pub-id pub-id-type="doi">10.1242/jeb.064535</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Genzel</surname><given-names>D</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Size does not matter: size-invariant echo-acoustic object classification</article-title><source>Journal of Comparative Physiology A</source><volume>199</volume><fpage>159</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1007/s00359-012-0777-3</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geva-Sagiv</surname><given-names>M</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Yovel</surname><given-names>Y</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatial cognition in bats and rats: from sensory acquisition to multiscale maps and navigation</article-title><source>Nature Reviews Neuroscience</source><volume>16</volume><fpage>94</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/nrn3888</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greif</surname><given-names>S</given-names></name><name><surname>Siemers</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Innate recognition of water bodies in echolocating bats</article-title><source>Nature Communications</source><volume>1</volume><elocation-id>107</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1110</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grisetti</surname><given-names>G</given-names></name><name><surname>Kummerle</surname><given-names>R</given-names></name><name><surname>Stachniss</surname><given-names>C</given-names></name><name><surname>Burgard</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A Tutorial on Graph-Based SLAM</article-title><source>IEEE Intelligent Transportation Systems Magazine</source><volume>2</volume><fpage>31</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1109/MITS.2010.939925</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grunwald</surname><given-names>JE</given-names></name><name><surname>Schörnich</surname><given-names>S</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Classification of natural textures in echolocation</article-title><source>PNAS</source><volume>101</volume><fpage>5670</fpage><lpage>5674</lpage><pub-id pub-id-type="doi">10.1073/pnas.0308029101</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesslow</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The current status of the simulation theory of cognition</article-title><source>Brain Research</source><volume>1428</volume><fpage>71</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2011.06.026</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>S</given-names></name><name><surname>Baier</surname><given-names>L</given-names></name><name><surname>Borina</surname><given-names>F</given-names></name><name><surname>Schuller</surname><given-names>G</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name><name><surname>Firzlaff</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Psychophysical and neurophysiological hearing thresholds in the bat Phyllostomus discolor</article-title><source>Journal of Comparative Physiology A</source><volume>194</volume><fpage>39</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1007/s00359-007-0288-9</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Holderied</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Akustische flugbahnverfolgung von fledermäusen: artvergleich des verhaltens beim suchflug und richtcharakteristik der schallabstrahlung</article-title><source>Ph.D. Thesis</source><publisher-name>Friedrich-Alexander-Universität Erlangen-Nürnberg</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holderied</surname><given-names>MW</given-names></name><name><surname>Jones</surname><given-names>G</given-names></name><name><surname>von Helversen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Flight and echolocation behaviour of whiskered bats commuting along a hedgerow: range-dependent sonar signal design, Doppler tolerance and evidence for 'acoustic focussing'</article-title><source>Journal of Experimental Biology</source><volume>209</volume><fpage>1816</fpage><lpage>1826</lpage><pub-id pub-id-type="doi">10.1242/jeb.02194</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holderied</surname><given-names>MW</given-names></name><name><surname>Korine</surname><given-names>C</given-names></name><name><surname>Fenton</surname><given-names>MB</given-names></name><name><surname>Parsons</surname><given-names>S</given-names></name><name><surname>Robson</surname><given-names>S</given-names></name><name><surname>Jones</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Echolocation call intensity in the aerial hawking bat Eptesicus bottae (Vespertilionidae) studied using stereo videogrammetry</article-title><source>Journal of Experimental Biology</source><volume>208</volume><fpage>1321</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1242/jeb.01528</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Orientation and navigation in bats: known unknowns or unknown unknowns?</article-title><source>Behavioral Ecology and Sociobiology</source><volume>61</volume><fpage>653</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1007/s00265-006-0297-7</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jakobsen</surname><given-names>L</given-names></name><name><surname>Brinkløv</surname><given-names>S</given-names></name><name><surname>Surlykke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intensity and directionality of bat echolocation signals</article-title><source>Frontiers in Physiology</source><volume>4</volume><elocation-id>89</elocation-id><pub-id pub-id-type="doi">10.3389/fphys.2013.00089</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jakobsen</surname><given-names>L</given-names></name><name><surname>Ratcliffe</surname><given-names>JM</given-names></name><name><surname>Surlykke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Convergent acoustic field of view in echolocating bats</article-title><source>Nature</source><volume>493</volume><fpage>93</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1038/nature11664</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>ME</given-names></name><name><surname>Moss</surname><given-names>CF</given-names></name><name><surname>Surlykke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Echolocating bats can use acoustic landmarks for spatial orientation</article-title><source>Journal of Experimental Biology</source><volume>208</volume><fpage>4399</fpage><lpage>4410</lpage><pub-id pub-id-type="doi">10.1242/jeb.01901</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalko</surname><given-names>EKV</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Insect pursuit, prey capture and echolocation in pipestirelle bats (Microchiroptera)</article-title><source>Animal Behaviour</source><volume>50</volume><fpage>861</fpage><lpage>880</lpage><pub-id pub-id-type="doi">10.1016/0003-3472(95)80090-5</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kleeman</surname><given-names>L</given-names></name><name><surname>Kuc</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Springer Handbook of Sensing</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuc</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Biomimetic sonar differentiates coin head from tail</article-title><source>The Journal of the Acoustical Society of America</source><volume>101</volume><elocation-id>3198</elocation-id><pub-id pub-id-type="doi">10.1121/1.419348</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuipers</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The Spatial Semantic Hierarchy</article-title><source>Artificial Intelligence</source><volume>119</volume><fpage>191</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/S0004-3702(00)00017-5</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewicki</surname><given-names>MS</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Surlykke</surname><given-names>A</given-names></name><name><surname>Moss</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Scene analysis in the natural environment</article-title><source>Frontiers in Psychology</source><volume>5</volume><elocation-id>199</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00199</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mataric</surname><given-names>MJ</given-names></name><name><surname>Brooks</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Learning a distributed map representation based on navigation behaviors</article-title><source>Proceedings of 1990 USA Japan Symposium on Flexible Automation</source><fpage>499</fpage><lpage>506</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matsuo</surname><given-names>I</given-names></name><name><surname>Kunugiyama</surname><given-names>K</given-names></name><name><surname>Yano</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>An echolocation model for range discrimination of multiple closely spaced objects: transformation of spectrogram into the reflected intensity distribution</article-title><source>The Journal of the Acoustical Society of America</source><volume>115</volume><fpage>920</fpage><lpage>928</lpage><pub-id pub-id-type="doi">10.1121/1.1642626</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Milford</surname><given-names>MJ</given-names></name><name><surname>Wyeth</surname><given-names>GF</given-names></name><name><surname>Prasser</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>RatSLAM: a hippocampal model for simultaneous localization and mapping</article-title><conf-name>IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004</conf-name><volume>1</volume><fpage>403</fpage><lpage>408</lpage></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>An Introduction to the Psychology of Hearing</source><publisher-name>Brill</publisher-name></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moss</surname><given-names>CF</given-names></name><name><surname>Surlykke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Auditory scene analysis by echolocation in bats</article-title><source>The Journal of the Acoustical Society of America</source><volume>110</volume><fpage>2207</fpage><lpage>2226</lpage><pub-id pub-id-type="doi">10.1121/1.1398051</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Peremans</surname><given-names>H</given-names></name><name><surname>Mey</surname><given-names>FD</given-names></name><name><surname>Schillebeeckx</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2012">2012</year><chapter-title>Man-made versus biological in-air sonar systems</chapter-title><source>Frontiers in Sensing</source><fpage>195</fpage><lpage>206</lpage></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reijniers</surname><given-names>J</given-names></name><name><surname>Vanderelst</surname><given-names>D</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Morphology-induced information transfer in bat sonar</article-title><source>Physical Review Letters</source><volume>105</volume><elocation-id>148701</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.105.148701</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>S</given-names></name><name><surname>Norvig</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Artificial Intelligence: A Modern Approach</source><publisher-loc>Egnlewood Cliffs</publisher-loc><publisher-name>Prentice-Hall</publisher-name></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saillant</surname><given-names>PA</given-names></name><name><surname>Simmons</surname><given-names>JA</given-names></name><name><surname>Dear</surname><given-names>SP</given-names></name><name><surname>McMullen</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A computational model of echo processing and acoustic imaging in frequency-modulated echolocating bats: the spectrogram correlation and transformation receiver</article-title><source>The Journal of the Acoustical Society of America</source><volume>94</volume><fpage>2691</fpage><lpage>2712</lpage><pub-id pub-id-type="doi">10.1121/1.407353</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Evidence for a spectral basis of texture perception in bat sonar</article-title><source>Nature</source><volume>331</volume><fpage>617</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1038/331617a0</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnitzler</surname><given-names>H-U</given-names></name><name><surname>Denzinger</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Auditory fovea and Doppler shift compensation: adaptations for flutter detection in echolocating bats using CF-FM signals</article-title><source>Journal of Comparative Physiology A</source><volume>197</volume><fpage>541</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1007/s00359-010-0569-6</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnitzler</surname><given-names>H-U</given-names></name><name><surname>Kalko</surname><given-names>EKV</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Echolocation by Insect-Eating Bats</article-title><source>BioScience</source><volume>51</volume><fpage>557</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1641/0006-3568(2001)051[0557:EBIEB]2.0.CO;2</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnitzler</surname><given-names>H-U</given-names></name><name><surname>Moss</surname><given-names>CF</given-names></name><name><surname>Denzinger</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>From spatial orientation to food acquisition in echolocating bats</article-title><source>Trends in Ecology &amp; Evolution</source><volume>18</volume><fpage>386</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1016/S0169-5347(03)00185-X</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seibert</surname><given-names>AM</given-names></name><name><surname>Koblitz</surname><given-names>JC</given-names></name><name><surname>Denzinger</surname><given-names>A</given-names></name><name><surname>Schnitzler</surname><given-names>HU</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Scanning behavior in echolocating common pipistrelle bats (Pipistrellus pipistrellus)</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e60752</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0060752</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Siciliano</surname><given-names>B</given-names></name><name><surname>Khatib</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Springer Handbook of Robotics</source><publisher-name>Springer Science &amp; Business Media</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siemers</surname><given-names>BM</given-names></name><name><surname>Kalko</surname><given-names>EK</given-names></name><name><surname>Schnitzler</surname><given-names>H-U</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Echolocation behavior and signal plasticity in the Neotropical bat Myotis nigricans (Schinz, 1821) (Vespertilionidae): a convergent case with European species of Pipistrellus ?</article-title><source>Behavioral Ecology and Sociobiology</source><volume>50</volume><fpage>317</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1007/s002650100379</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simmons</surname><given-names>JA</given-names></name><name><surname>Freedman</surname><given-names>EG</given-names></name><name><surname>Stevenson</surname><given-names>SB</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Wohlgenant</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Clutter interference and the integration time of echoes in the echolocating bat, Eptesicus fuscus</article-title><source>The Journal of the Acoustical Society of America</source><volume>86</volume><fpage>1318</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1121/1.398693</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simmons</surname><given-names>JA</given-names></name><name><surname>Vernon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Echolocation: discrimination of targets by the bat, Eptesicus fuscus</article-title><source>Journal of Experimental Zoology</source><volume>176</volume><fpage>315</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1002/jez.1401760307</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>R</given-names></name><name><surname>Holderied</surname><given-names>MW</given-names></name><name><surname>Koch</surname><given-names>CU</given-names></name><name><surname>von Helversen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Floral acoustics: conspicuous echoes of a dish-shaped leaf attract bat pollinators</article-title><source>Science</source><volume>333</volume><fpage>631</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1126/science.1204210</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>R</given-names></name><name><surname>Holderied</surname><given-names>MW</given-names></name><name><surname>von Helversen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Size discrimination of hollow hemispheres by echolocation in a nectar feeding bat</article-title><source>Journal of Experimental Biology</source><volume>209</volume><fpage>3599</fpage><lpage>3609</lpage><pub-id pub-id-type="doi">10.1242/jeb.02398</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steckel</surname><given-names>J</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A novel biomimetic sonarhead using beamforming technology to mimic bat echolocation</article-title><source>IEEE Transactions on Ultrasonics, Ferroelectrics and Frequency Control</source><volume>59</volume><fpage>1369</fpage><lpage>1377</lpage><pub-id pub-id-type="doi">10.1109/TUFFC.2012.2337</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steckel</surname><given-names>J</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>BatSLAM: Simultaneous localization and mapping using biomimetic sonar</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e54076</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0054076</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stilz</surname><given-names>WP</given-names></name><name><surname>Schnitzler</surname><given-names>HU</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Estimation of the acoustic range of bat echolocation for extended targets</article-title><source>The Journal of the Acoustical Society of America</source><volume>132</volume><fpage>1765</fpage><lpage>1775</lpage><pub-id pub-id-type="doi">10.1121/1.4733537</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stones</surname><given-names>RC</given-names></name><name><surname>Branick</surname><given-names>LP</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Use of Hearing in Homing by Two Species of Myotis Bats</article-title><source>Journal of Mammalogy</source><volume>50</volume><fpage>157</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.2307/1378657</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stürzl</surname><given-names>W</given-names></name><name><surname>Zeil</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Depth, contrast and view-based homing in outdoor scenes</article-title><source>Biological Cybernetics</source><volume>96</volume><fpage>519</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1007/s00422-007-0147-3</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surlykke</surname><given-names>A</given-names></name><name><surname>Boel Pedersen</surname><given-names>S</given-names></name><name><surname>Jakobsen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Echolocating bats emit a highly directional sonar sound beam in the field</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>276</volume><fpage>853</fpage><lpage>860</lpage><pub-id pub-id-type="doi">10.1098/rspb.2008.1505</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surlykke</surname><given-names>A</given-names></name><name><surname>Kalko</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Echolocating bats cry out loud to detect their prey</article-title><source>PLoS One</source><volume>3</volume><elocation-id>e2036</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0002036</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surlykke</surname><given-names>A</given-names></name><name><surname>Moss</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Echolocation behavior of big brown bats, Eptesicus fuscus, in the field and the laboratory</article-title><source>The Journal of the Acoustical Society of America</source><volume>108</volume><fpage>2419</fpage><lpage>2429</lpage><pub-id pub-id-type="doi">10.1121/1.1315295</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suthers</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Acoustic orientation by fish-catching bats</article-title><source>Journal of Experimental Zoology</source><volume>158</volume><fpage>319</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1002/jez.1401580307</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsoar</surname><given-names>A</given-names></name><name><surname>Nathan</surname><given-names>R</given-names></name><name><surname>Bartan</surname><given-names>Y</given-names></name><name><surname>Vyssotski</surname><given-names>A</given-names></name><name><surname>Dell'Omo</surname><given-names>G</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale navigational map in a mammal</article-title><source>PNAS</source><volume>108</volume><fpage>E718</fpage><lpage>E724</lpage><pub-id pub-id-type="doi">10.1073/pnas.1107365108</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderelst</surname><given-names>D</given-names></name><name><surname>De Mey</surname><given-names>F</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name><name><surname>Geipel</surname><given-names>I</given-names></name><name><surname>Kalko</surname><given-names>E</given-names></name><name><surname>Firzlaff</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>What noseleaves do for FM bats depends on their degree of sensorial specialization</article-title><source>PLoS One</source><volume>5</volume><elocation-id>e11893</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0011893</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Vanderelst</surname><given-names>D</given-names></name><name><surname>De Mey</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>ChiRoPing deliverable d.1.1.13d-printed heads from 4 species of bats</article-title><uri xlink:href="http://www.chiroping.org/miscdocs/deliverables/D1-1-1.pdf">http://www.chiroping.org/miscdocs/deliverables/D1-1-1.pdf</uri></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderelst</surname><given-names>D</given-names></name><name><surname>Holderied</surname><given-names>MW</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensorimotor Model of Obstacle Avoidance in Echolocating Bats</article-title><source>PLoS Computational Biology</source><volume>11</volume><elocation-id>e1004484</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004484</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Vanderelst</surname><given-names>D</given-names></name><name><surname>Steckel</surname><given-names>J</given-names></name><name><surname>Boen</surname><given-names>A</given-names></name><name><surname>Holderied</surname><given-names>M</given-names></name><name><surname>Peremans</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Data and Computer scripts for 'Place recognition using batlike sonar'</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.58579</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verboom</surname><given-names>B</given-names></name><name><surname>Boonman</surname><given-names>AM</given-names></name><name><surname>Limpens</surname><given-names>HJGA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Acoustic perception of landscape elements by the pond bat (Myotis dasycneme)</article-title><source>Journal of Zoology</source><volume>248</volume><fpage>59</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7998.1999.tb01022.x</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Helversen</surname><given-names>D</given-names></name><name><surname>von Helversen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Object recognition by echolocation: a nectar-feeding bat exploiting the flowers of a rain forest vine</article-title><source>Journal of Comparative Physiology. A, Neuroethology, Sensory, Neural, and Behavioral Physiology</source><volume>189</volume><fpage>327</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1007/s00359-003-0405-3</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiegrebe</surname><given-names>L</given-names></name><name><surname>Schmidt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Temporal integration in the echolocating bat, Megaderma lyra</article-title><source>Hearing Research</source><volume>102</volume><fpage>35</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(96)00139-6</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>An autocorrelation model of bat sonar</article-title><source>Biological Cybernetics</source><volume>98</volume><fpage>587</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0216-2</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>TC</given-names></name><name><surname>Williams</surname><given-names>JM</given-names></name><name><surname>Griffin</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>The homing ability of the neotropical bat Phyllostomus Hastatus, with evidence for visual orientation</article-title><source>Animal Behaviour</source><volume>14</volume><fpage>468</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1016/S0003-3472(66)80047-7</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wotton</surname><given-names>JM</given-names></name><name><surname>Simmons</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Spectral cues and perception of the vertical position of targets by the big brown bat, Eptesicus fuscus</article-title><source>The Journal of the Acoustical Society of America</source><volume>107</volume><fpage>1034</fpage><lpage>1041</lpage><pub-id pub-id-type="doi">10.1121/1.428283</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyeth</surname><given-names>G</given-names></name><name><surname>Milford</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial cognition for robots</article-title><source>IEEE Robotics &amp; Automation Magazine</source><volume>16</volume><fpage>24</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1109/MRA.2009.933620</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wystrach</surname><given-names>A</given-names></name><name><surname>Beugnon</surname><given-names>G</given-names></name><name><surname>Cheng</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Landmarks or panoramas: what do navigating ants attend to for guidance?</article-title><source>Frontiers in Zoology</source><volume>8</volume><elocation-id>21</elocation-id><pub-id pub-id-type="doi">10.1186/1742-9994-8-21</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representation of three-dimensional space in the hippocampus of flying bats</article-title><source>Science</source><volume>340</volume><fpage>367</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1126/science.1235338</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells without theta oscillations in the entorhinal cortex of bats</article-title><source>Nature</source><volume>479</volume><fpage>103</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nature10583</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yovel</surname><given-names>Y</given-names></name><name><surname>Franz</surname><given-names>MO</given-names></name><name><surname>Stilz</surname><given-names>P</given-names></name><name><surname>Schnitzler</surname><given-names>HU</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Plant classification from bat-like echolocation signals</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000032</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000032</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeil</surname><given-names>J</given-names></name><name><surname>Hofmann</surname><given-names>MI</given-names></name><name><surname>Chahl</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Catchment areas of panoramic snapshots in outdoor scenes</article-title><source>Journal of the Optical Society of America A</source><volume>20</volume><fpage>450</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.20.000450</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.14188.017</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Eichenbaum</surname><given-names>Howard</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your work entitled &quot;Place recognition using batlike bio-sonar&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>All the reviewers felt there was considerable merit in the study but at the same time had a diversity of major concerns about the some of the assumptions, analyses, and conclusions. The specific comments are provided in detail below.</p><p><italic>Reviewer #1:</italic></p><p>This article addresses an interesting hypothesis concerning place recognition in biosonar. The authors suggest that to recognize certain locations echolocating bats might employ place templates based on a specific echo signature rather than the 3 dimensional layout of the echo-acoustic scene. By assessing templates' discriminability and continuity independent of the spectral content of the ensonifying signal the proposed model was able to reliably recognize locations allowing which they claim can be sufficient for a successful navigation and orientation in an echo-acoustic environment. Yet, while this paper is intriguing, it might also be pushing the interpretation a little bit too far and should be considered in the larger scope of knowledge about bats, their navigation abilities and what is known so far regarding the link between their neural circuits and echolocation.</p><p>The paper refers to &quot;bat echolocation&quot; but different bats have evolved <italic>very</italic> different echolocation strategies to navigate in their environments. Previous studies, also using artificial machines, have shown the capacity of bat-like sonar pulses to extract useful information about the environment, the leap towards suggesting that bats maintain a remarkably large library of pulse signatures to navigate in 3D rather than a memory of a 3D layout (perhaps in the hippocampal formation) is not well supported. From an etiological perspective it is unclear what would drive the system to prefer sonar-based place recognition over 3D spatial memory of the environment as that seems much less of an efficient recognition mechanism and one that is much less easily generalizable and amenable to changes in the environment. The authors also argue in the Discussion that &quot;indirect evidence of a cognitive map exist through findings of grid-cells and place-cells in bats&quot; but in fact those finding are contradicting their claim because those studies have shown that place/grid-cells can exist in the complete absence of echolocation, thus arguing echolocation is not, in fact, necessary for the formation of spatial maps in the hippocampal formation. Nonetheless the paper and the proposed hypothesis in intriguing albeit unlikely capturing the true nature of bat 3D navigation.</p><p>Specific comments:</p><p>In the second paragraph of the subsection “Model based place recognition”: The authors state that during ensonification of an object spectral cues are generated which encode both location of the object but also general object properties. This induces conflicting information concerning position and shape. This is certainly true but what the authors fail to mention is that bats – along with most mammals – have very flexible and most often disproportionally large ears. This allows them to rapidly move their ears independent of their head and therefore still keeps the outgoing ensonification signal directed toward the object of interest. These rapid ear movements introduce dynamic binaural cues relevant for horizontal object localization but more importantly here also relevant for elevation estimation. Efferent feedback signals encode the ears' position, which is integrated in the evaluation of the incoming echoes. This allows for a better localization performance and thereby can reduce possible conflicts of object shape and position.</p><p>In the third paragraph of the subsection “Model based place recognition”: I do not quite agree that spectral cues are degraded when echoes from certain points are temporally integrated due to properties of the auditory system. In fact, distinct spectral cues are generated when temporally peaks are integrated, allowing for object recognition through spectral peak or notch detection (shown in many previous studies). Objects are therefore distinguishable through distinct temporal peaks or when not temporally resolvable through their spectral cues and notches. At the neural level, the work by Jim Simmons further supports this statement. Furthermore, integration can occur at later stages of processing beyond the auditory cortex. While a large fraction of neurophysiological studies have focused on the bat A1, there are many subsequent stages of processing that could lead to a coherent perception of the bat's location in 3D, including the hippocampal formation, basal ganglia, frontal cortex, colliculus, etc.</p><p>In the second paragraph of the subsection “Ensonification”: Why was the employed pulse only ranged down to 40 kHz? More echo-acoustic information could have been extracted in lower frequency ranges that could still be perceived by echolocating bats (see publications concerning bat audiograms – albeit the authors do not consider the differences of bat echolocation signals across species). Especially the open space locations might be more reliably recognized by employing lower frequencies that have longer travel times with less atmospheric attenuation.</p><p>In the last paragraph of the subsection “Template Construction”: It states that the templates were subsampled at a rate of 350 μs, a rate &quot;slightly larger than the integration time of the model of Wiegrebe&quot;. Is subsampling an appropriate way to compensate for integration time? As I understand it, within the integration window accumulated information introduces masking because multiple echoes introduced within that time will be &quot;combined&quot; or considered together (integrated). It seems to me that subsampling would be less akin to integration and more akin to a &quot;refractory period&quot; in which only one echo within the window is taken into consideration, after which no echoes are considered until the end of the window. Would averaging the samples within each 350 μs block be a more appropriate approximation of integration time?</p><p>In the first paragraph of the subsection “Template properties”: I was missing a discussion on object recognition based on echolocation sequencing. The authors only state that this is not necessary when employing their model based on echo signature rather than 3D layout. But many studies have shown that bats do indeed integrate sequences of echoes and can thereby reliably discriminate and classify objects.</p><p>In the second paragraph of the subsection “Template properties”: the proposed model failed to recognize the echo signatures of the Open environment. The authors state that this is due to the missing diagnostic echoes. Many bat species travel in higher open spaces and still are able to reliably orient themselves. What do the authors propose how bats navigate instead in such an echo-acoustic situation?</p><p>In the third paragraph of the subsection “Using templates for mapping”: The authors state that an obstacle avoidance mechanism and other guidance behaviors together with the suggested place recognition template model would allow bats following a restricted set of routes to successfully navigate through their environment. But often new obstacles might come in place disrupting the known echo-acoustic scene. Would the model still be able to reliably recognize the template? It would be interesting by how much echo signature recognition would be disrupted by inserting or deleting temporal characteristics of the templates or by phase warping parts of the signal.</p><p>Etiology: In the Abstract and Introduction the authors note that long-distance navigation (Tsoar et al., 2011) requires vision while displaced bats can find their way home from within 15 km by sound (Stones and Branick, 1969 and Williams, Williams and Griffin, 1966). However, the studies cited for these two pieces of evidence refer to distinct species of bats that arose from separate lineages. <italic>Rousettus aegyptiacus</italic> (Tsoar et al., 2011) is a fruit- eating megabat belonging to the same clade as flying foxes and other fruit bats that rely exclusively on vision. It is the only member of its clade to have evolved echolocation in the form of tongue clicks, which are not as sophisticated as the laryngeal echolocation used by microbats, the clade that contains all other echolocating bats including those used in citations [Stones and Branick, 1969] and [Williams, Williams and Griffin, 1966] (<italic>Myotis spp.</italic> and <italic>Phyllostomus hastatus</italic>). The diets and environments of the three species are also quite different. Because the animals evolved to address different environmental pressures it is somewhat misleading to omit the species names in the text, as the findings of one study may not generalize to the species used in the others. The paper never states what genus or even family of bat is most closely modeled by the ensonification device, which is important because many bats have different types of echolocation and foraging strategies. Specifically, which species provided the model for the hyperbolic simulated pulse? Are bats that use calls resembling the simulated pulse found in all three areas ensonified in this study? At what height was the ensonification device placed? Was this the approximate height that bats living in the area might be expected to fly?</p><p>Additional data files and statistical comments:</p><p>The authors offer to make the data available and I think this is wonderful. The analysis overall seems appropriate.</p><p><italic>Reviewer #2:</italic></p><p>The current paper uses a combination of biophysical measurements and simulations to present a theoretical framework on how bats may navigate by the auditory analysis of self-generated sounds. Specifically, the authors derive echo-acoustic signatures, templates, from the echoes of their ensonifications and test the extent to which these templates carry information in terms of discriminability and smoothness. The authors hypothesise that templates must be discriminable from each other to meaningfully encode a position and/or orientation within a habitat and it must vary monotonously over a certain range of rotation or translation to be considered as 'smooth'.</p><p>Overall the scientific approach is very well conceived and executed. The biophysical measurements are clearly motivated and described and the simulation approach is also well justified. The manuscript would benefit, however, from a more precise wording and better justification of some of the simulation assumptions.</p><p>Following are specific comments, in order of appearance, not importance.</p><p>In the fourth paragraph of the subsection “Model based place recognition”: The definition and implementation of temporal integration is misleading: temporal integration as a peripheral auditory limitation is (i) a feature of the Gammatone filter bank, determined by the duration of the filter impulse responses and (ii) a feature of the low-pass filtering (cutoff frequency not specified in the current paper) applied after compression. The first integration stage is not really a limit of temporal resolution; it only means that shorter events are recoded onto the frequency axis by the filter bank. The second integration is, I guess, already of a similar order as the 350 µs integration interval applied later. The authors should clarify implicit and explicit integration stages in their model.</p><p>In point 1 of the third paragraph of the subsection “Template based place recognition”: The authors use the words 'identify', 'discriminate', 'distinguish' and 'recognize' interchangeably. In psychophysics, (e.g. of object perception) these are quite different levels of perception and so the authors should stick to that expression that matches their simulation, namely discrimination. For identification, for example, discrimination and classification are seen as prerequisites; see e.g. the chapters on object perception in toothed whales in the book by Whitlow Au.</p><p>In point 2 of the third paragraph of the subsection “Template based place recognition”: rework definition of smoothness. Only later it becomes clear the monotonicity is required.</p><p>In the second paragraph of the subsection “Template Construction”: provide values for compression and low-pass filtering.</p><p>In the third paragraph of the subsection “Template Construction”: What is the directionality of the emitting system? If you average cochleograms across microphones, this is quite different than averaging the waveforms. The latter would produce strong directionality but what does averaging the cochleograms produce? This is very unphysiological! Shouldn't you have used the 31 mics like a phased array to thereby impose a bat HRTF on the data?</p><p>In the second paragraph of the subsection “Template Construction”: the dechirping appears to be functionally similar to channel wise normalized autocorrelation in Wiegrebe (2008). Why do you deviate from that model here?</p><p>In the first paragraph of the subsection “Quantifying discriminability”: you cannot equalize acoustic noise of mics with noise in the template because of non-linear processing (half-wave rectification and compression) in between.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref>: considering that you have unknown emission directionality the comparison with real bats appears not meaningful.</p><p><xref ref-type="fig" rid="fig6">Figure 6</xref>: panoramic view!</p><p>In the third paragraph of the subsection “Template properties”: CF bats temporal resolution in the CF part however would be very bad (about equal to call duration, 50 ms!) so CF part is not usable, right?</p><p><italic>Reviewer #3:</italic></p><p>In this manuscript, the authors distinguish between two hypotheses of echolocation-based navigation in bats: model-based place recognition, in which echo cues underlie 3D reconstruction of a scene, vs. template-based recognition, in which a scene is represented directly from cochlear input. The manuscript proposes the viability of the template model, based on analyzing templates constructed from a large body of real-world ensonification data. The criteria for template viability were that a place template had to be discriminable from others, and that it was continuous, i.e. more similar to templates of nearby vs. distant locations. Simulated classification results (using Mahalanobis distance as a discrimination metric) were generally consistent with the clutter of the scenes surveyed. In open spaces with few landmarks, performance was low; in more cluttered spaces performance was high. Additionally, discriminable scenes tended to be continuous. Finally, the authors discuss their results in the context of constructing cognitive maps that can guide mesoscale navigation in bats.</p><p>I enjoyed reading the paper and think it should be published. The analyses generally seem sound and carefully performed. Very few statistics are used in the paper; in some places a more formal analysis might lend weight to the results and interpretations. If I am reading the methods correctly, 3 replicate measurements were used to estimate noise at each position, which strikes me as a low number from which to estimate a distribution, whereas the Wiegrebe model used 20.</p><p>As an experimentalist I would want to know to what extent bats actually behave in the ways predicted by the reported discrimination probabilities and catchment sizes. For example, the Wiegrebe paper that inspired the model did include some comparisons of <italic>P. discolor</italic> behavior against model predictions. Still, this paper sets the stage nicely for such an evaluation and provides a method for predicting navigation behaviors in a given environment. (I am less convinced that it provides a basis for rejecting object-based navigation mechanisms, which seemed to be an implied aim of the manuscript.)</p><p>The authors argue that inherent limitations of biosonar (spectral ambiguity, integration time) make it unlikely that 3D representation of a scene is available to a cruising bat, and that such a representation is therefore unavailable to recognize places. The bases for this argument are plausible, but stop short of ruling out explicit object layout reconstruction as a navigational cue. After all, bats do perform object recognition and localization. Integrating across multiple echo calls, for example, might allow an echolocating bat to ameliorate the spatial blur imposed by the integration time described in the paper. In this vein, the authors might also elaborate on object recognition vs. place recognition &quot;modes&quot; of echolocation. If object-recognition mechanisms are not part of template-based navigation strategy, is there a tradeoff between navigation and object perception performance?</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.14188.018</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>All the reviewers felt there was considerable merit in the study but at the same time had a diversity of major concerns about the some of the assumptions, analyses, and conclusions. The specific comments are provided in detail below.</italic></p><p><italic>Reviewer #1:</italic></p><p><italic>[…] Yet, while this paper is intriguing, it might also be pushing the interpretation a little bit too far and should be considered in the larger scope of knowledge about bats, their navigation abilities and what is known so far regarding the link between their neural circuits and echolocation.</italic> </p><p><italic>The paper refers to &quot;bat echolocation&quot; but different bats have evolved very different echolocation strategies to navigate in their environments.</italic> </p><p>The reviewer is right in pointing out that different bat species have evolved different echolocation strategies. However, we believe that the mechanism for place recognition we suggest is general enough to be accessible to most (if not all) echolocating bats. Indeed, as we also point out in the paper, the templates are semi-independent from call duration and frequency content due to the dechirping and averaging across frequencies.</p><p><italic>Previous studies, also using artificial machines, have shown the capacity of bat-like sonar pulses to extract useful information about the environment, the leap towards suggesting that bats maintain a remarkably large library of pulse signatures to navigate in 3D rather than a memory of a 3D layout (perhaps in the hippocampal formation) is not well supported. From an etiological perspective it is unclear what would drive the system to prefer sonar-based place recognition over 3D spatial memory of the environment as that seems much less of an efficient recognition mechanism and one that is much less easily generalizable and amenable to changes in the environment.</italic> </p><p>We agree that a number of studies have shown that useful information can be extracted using echolocation. However, the critical point is that no algorithm has shown to be able to reconstruct the 3D layout of the environment from a limited number of incoming echoes – once the scene consists of more than a few (artificial) reflectors. This can be understood by noting that building a 3D description of the environment is an instance of an inverse problem. As such, it comes with all the problems associated with solving inverse problems, i.e. solution methods are ill-posed unless additional relevant constraints can be applied. None of the few regularized solution methods that have been described in the literature (see below: Matsuo, Fontaine, Buck) have been applied to sonar measurements from natural bat environments. A recent study by Dias (see below for reference) found it impossible to reconstruct the layout of a scene consisting of three reflectors.</p><p>We conclude that it is still very much an open question whether a 3D description of a natural environment can indeed be constructed from the bat's sonar measurements. Hence, while we agree that a 3D description – were it to exist – would be more general and more easy to change, we also believe it still remains to be proven that such a description is actually built by bats in a navigation context.</p><p>It is our hypothesis that either the inability of bat sonar systems to reconstruct a 3D layout of the environment would drive the bats towards an alternative mechanism or, if a 3D layout of the environment could be extracted from the echoes, the bats would still be driven towards a template based approach as inferring the 3D layout would more computational effort. Hence, our computationally less expensive approach would be preferred by evolution as it allows the bats to deal with complex environments in real time.</p><p>Ikuo Matsuo, Evaluation of the echolocation model for range estimation of multiple closely spaced objects, J. Acoust. Soc. Am., 130(2), August 2011</p><p>Bertrand Fontaine and Herbert Peremans, Determining biosonar images using sparse representations, J. Acoust. Soc. Am., 125(5), May 2009</p><p>David A. Hague, John R. Buck, and Igal Bilik, A deterministic compressive sensing model for bat biosonar, J. Acoust. Soc. Am. 132 (6), December 2012</p><p>Eduardo Tondin Ferreira Dias, Hugo Vieira Neto. A Novel Approach to Environment Mapping Using Sonar Sensors and Inverse Problems. TAROS 2015: 100-111</p><p><italic>The authors also argue in the Discussion that &quot;indirect evidence of a cognitive map exist through findings of grid-cells and place-cells in bats&quot; but in fact those finding are contradicting their claim because those studies have shown that place/grid-cells can exist in the complete absence of echolocation, thus arguing echolocation is not, in fact, necessary for the formation of spatial maps in the hippocampal formation. Nonetheless the paper and the proposed hypothesis in intriguing albeit unlikely capturing the true nature of bat 3D navigation.</italic></p><p>We certainly do not want to claim that echolocation is necessary for the formation of a spatial map. All bats will also use visual and idiothetic (and possibly even odor/magnetic field) information to build such maps if available. The only claim we make is that such maps could still be built by a bat that was born blind (and did not have access to those additional sensory cues), i.e. echolocation provides sufficient information to build such maps.</p><p><italic>Specific comments:</italic> </p><p><italic>In the second paragraph of the subsection “Model based place recognition”: The authors state that during ensonification of an object spectral cues are generated which encode both location of the object but also general object properties. This induces conflicting information concerning position and shape. This is certainly true but what the authors fail to mention is that bats – along with most mammals - have very flexible and most often disproportionally large ears. This allows them to rapidly move their ears independent of their head and therefore still keeps the outgoing ensonification signal directed toward the object of interest. These rapid ear movements introduce dynamic binaural cues relevant for horizontal object localization but more importantly here also relevant for elevation estimation. Efferent feedback signals encode the ears' position, which is integrated in the evaluation of the incoming echoes. This allows for a better localization performance and thereby can reduce possible conflicts of object shape and position.</italic> </p><p>We agree that the hypothesis presented by the reviewer might explain how bats improve their ability to analyse the layout of the scene. However, to the best of our knowledge, no experimental or computational study has shown that this behaviour allows bats to actually do so. Furthermore, it should be noted that when bats are in the air their relative position with respect to objects of interest is (rapidly) changing all the time. However, a strategy, as proposed by the reviewer, where the bat keeps its relative position to the target fixed and systematically moves its ears to disambiguate spectral cues due to shape from those due to relative position seems feasible only when both bat and target are stationary. Finally, we have studied ear motions similar to the ones described by the reviewer, i.e. those found in the Rhinolophidae, and their potential functionality in detail (see references below analyzing the localization information provided by these motions). This analysis shows that multiple closely-spaced reflectors (as opposed to a single prey target) would prevent the ear movements from introducing reliable 3D cues.</p><p>Vanderelst, Dieter, et al. &quot;Information generated by the moving pinnae of Rhinolophus rouxi: tuning of the morphology at different harmonics.&quot; PloS one6.6 (2011): e20627.</p><p>Vanderelst, Dieter, et al. &quot;Dominant glint based prey localization in horseshoe bats: a possible strategy for noise rejection.&quot; PLoS Comput Biol7.12 (2011): e1002268.</p><p><italic>In the third paragraph of the subsection “Model based place recognition”: I do not quite agree that spectral cues are degraded when echoes from certain points are temporally integrated due to properties of the auditory system. In fact, distinct spectral cues are generated when temporally peaks are integrated, allowing for object recognition through spectral peak or notch detection (shown in many previous studies). Objects are therefore distinguishable through distinct temporal peaks or when not temporally resolvable through their spectral cues and notches. At the neural level, the work by Jim Simmons further supports this statement. Furthermore, integration can occur at later stages of processing beyond the auditory cortex. While a large fraction of neurophysiological studies have focused on the bat A1, there are many subsequent stages of processing that could lead to a coherent perception of the bat's location in 3D, including the hippocampal formation, basal ganglia, frontal cortex, colliculus, etc.…</italic> </p><p>To avoid confusion about what we mean by in the third paragraph of the subsection “Model based place recognition” we have rephrased the text. We did not mean to suggest that spectral peaks and notches due to non-temporally resolvable echoes from a single reflector are causing interpretation problems, we were suggesting that if such echoes are due to more than one reflector, the resulting spectral peaks and notches complicate the interpretation of both the shape and the location of each individual reflector from that cluster of closely spaced (in terms of distance to bat) reflectors.</p><p>Again, as argued in the text, it might be possible to circumvent these interpretation problems by combining consecutive measurements from different points of view (or different pinna orientations) but only at the cost of slowing down environment perception significantly. Hence, we agree with the reviewer that while the mechanism we propose is intended to explain low-level place- recognition and therefore should be fast and effortless (in cognitive terms) this does not preclude the existence of other, slower integration mechanisms at higher cognitive levels to operate in parallel.</p><p><italic>In the second paragraph of the subsection “Ensonification”: Why was the employed pulse only ranged down to 40 kHz? More echo-acoustic information could have been extracted in lower frequency ranges that could still be perceived by echolocating bats (see publications concerning bat audiograms – albeit the authors do not consider the differences of bat echolocation signals across species). Especially the open space locations might be more reliably recognized by employing lower frequencies that have longer travel times with less atmospheric attenuation.</italic></p><p>Limiting the frequency range to 40 kHz was necessary due to the frequency response properties of the speaker used. A statement to this effect was added to the paper. It is correct that extending the frequency range to lower frequencies would have increased long-range sensitivity and could have made a difference for the open-space templates. However, this would only change what actual environments are classified with the 'open-space' label. No matter what the maximum detection range of a sonar system is, there will always be environments that do not contain reflecting features within that range. Hence, we do not think this would significantly alter the results.</p><p><italic>In the last paragraph of the subsection “Template Construction”: It states that the templates were subsampled at a rate of 350 μs, a rate &quot;slightly larger than the integration time of the model of Wiegrebe&quot;. Is subsampling an appropriate way to compensate for integration time? As I understand it, within the integration window accumulated information introduces masking because multiple echoes introduced within that time will be &quot;combined&quot; or considered together (integrated). It seems to me that subsampling would be less akin to integration and more akin to a &quot;refractory period&quot; in which only one echo within the window is taken into consideration, after which no echoes are considered until the end of the window. Would averaging the samples within each 350 μs block be a more appropriate approximation of integration time?</italic> </p><p>It seems we were not clear in explaining this aspect of the method. It should be stressed that we perform this sampling on the envelop of the output of the cochlear filter bank, i.e. after low-pass filtering (2nd order Butterworth filter with cut-off frequency 1 kHz). The sample rate is chosen in accordance with Nyquist's sampling theorem. The reason for sampling at this lower rate is to remove the correlations introduced by the integration time of the auditory system. A similar operation to extract templates for object recognition was followed by R. Kuc (see reference below). We have changed the text to make this clear (see also comment by reviewer 2).</p><p>Roman Kuc. Biomimetic sonar differentiates coin head from tail. The Journal of the Acoustical Society of America, 101:3198, 1997.</p><p><italic>In the first paragraph of the subsection “Template properties”: I was missing a discussion on object recognition based on echolocation sequencing. The authors only state that this is not necessary when employing their model based on echo signature rather than 3D layout. But many studies have shown that bats do indeed integrate sequences of echoes and can thereby reliably discriminate and classify objects.</italic> </p><p>This comment expresses the same concern as a similar one from reviewer 3 and so we repeat our reply there as well. We agree with both reviewers that bats have the ability to recognize objects. However, the behaviour of bats in recognition experiments differs from that of cruising/navigating bats. In recognition experiments, bats typically ensonify the same object from different directions as part of an active object-centered exploration process. Cruising/navigating bats on the other hand, fly by the objects along their flight path resulting in a more accidental, i.e. less object- centered, and less extensive series of observations of those objects. The proposed template-based strategy is well suited to such a fly-by mode of echolocation. Also, we would like to point out that even in the object recognition experiments bats might not be building a 3D reconstruction of the object. They might instead be looking for diagnostic acoustic cues, e.g. spectral cues as hypothesised in the study by Simon et al. Such an account of object recognition would be easily integrated with our template-based account of place recognition. One possible way the two might interact is that the template-based place descriptors would be used to build a map first and then later (or possibly in parallel) 'landmarks', i.e. uniquely identified objects, would be associated with places in the map. However, at this stage this is not much more than conjecture and we have not proposed specific mechanisms for how to do this. Hence, we prefer to keep this topic for future work.</p><p>Simon R, Holderied MW, von Helversen O. Size discrimination of hollow hemispheres by echolocation in a nectar feeding bat. J Exp Biol. 2006;209: 3599-3609. doi:10.1242/jeb.02398</p><p><italic>In the second paragraph of the subsection “Template properties”: the proposed model failed to recognize the echo signatures of the Open environment. The authors state that this is due to the missing diagnostic echoes. Many bat species travel in higher open spaces and still are able to reliably orient themselves. What do the authors propose how bats navigate instead in such an echo-acoustic situation?</italic> </p><p>As long as a bat still receives echoes from its surroundings the scheme proposed here would apply. If the higher open spaces are so high or so open that the bats do not receive any echoes from their surroundings it is clear that the proposed scheme cannot make use of echolocation input to build maps of those areas. However, in those circumstances, bats would still receive input from other sensing modalities, i.e. visual/magnetic/odor that might provide it with navigation cues in the absence of echolocation cues. A recent review paper by Geva-sagiv discusses the roles of the various sensory systems in bats in relation to the spatial resolution of the navigation task. As we have not studied those alternative sensory systems we have no evidence about the discrimination power of such templates nor about their smoothness. However, we believe it would be very interesting to collect such evidence to see whether our hypothesis still stands or not.</p><p>Geva-sagiv M, Las L, Yovel Y, Ulanovsky N. Spatial cognition in bats and rats: from sensory acquisition to multiscale maps and navigation. Nat Publ Gr. Nature Publishing Group; 2015;16: 94–108. doi:10.1038/nrn3888</p><p><italic>In the third paragraph of the subsection “Using templates for mapping”: the authors state that an obstacle avoidance mechanism and other guidance behaviors together with the suggested place recognition template model would allow bats following a restricted set of routes to successfully navigate through their environment. But often new obstacles might come in place disrupting the known echo-acoustic scene. Would the model still be able to reliably recognize the template? It would be interesting by how much echo signature recognition would be disrupted by inserting or deleting temporal characteristics of the templates or by phase warping parts of the signal.</italic> </p><p>For now, we have not dealt with the issue of changes in the environment. However, there are a number of ways this model could deal with such changes. One simple way would be to keep track of the prior probability of being currently at template X. This can be done by exploiting the fact that the bat's map would contain topological information, i.e. which templates are next to each other. So, if it is currently at Y it will expect to be in X next when executing a particular flight routine. Such a mechanism is shown to work quite well in an indoor office environment in the biologically inspired BatSLAM algorithm (see reference below). Hence, the bat could have a mechanism that recognizes template X if it is sufficiently similar to the new sensor data and rejects/replaces template X if this data differs too much from the expected template X (based on the a priori probability of being at template X).</p><p>Steckel J, Peremans H (2013) BatSLAM: Simultaneous Localization and Mapping Using Biomimetic Sonar. PLoS ONE 8(1): e54076. doi: 10.1371/journal.pone.0054076</p><p><italic>Etiology: In the Abstract and Introduction the authors note that long-distance navigation (Tsoar et al., 2011) requires vision while displaced bats can find their way home from within 15 km by sound (Stones and Branick, 1969 and Williams, Williams and Griffin, 1966). However, the studies cited for these two pieces of evidence refer to distinct species of bats that arose from separate lineages. Rousettus aegyptiacus (Tsoar et al., 2011) is a fruit- eating megabat belonging to the same clade as flying foxes and other fruit bats that rely exclusively on vision. It is the only member of its clade to have evolved echolocation in the form of tongue clicks, which are not as sophisticated as the laryngeal echolocation used by microbats, the clade that contains all other echolocating bats including those used in citations [Stones and Branick, 1969] and [Williams, Williams and Griffin, 1966] (Myotis spp. and Phyllostomus hastatus). The diets and environments of the three species are also quite different. Because the animals evolved to address different environmental pressures it is somewhat misleading to omit the species names in the text, as the findings of one study may not generalize to the species used in the others.</italic> </p><p>We agree with the reviewer that mentioning the species in the text would add to the paper's clarity. We have updated the text as such.</p><p><italic>The paper never states what genus or even family of bat is most closely modeled by the ensonification device, which is important because many bats have different types of echolocation and foraging strategies. Specifically, which species provided the model for the hyperbolic simulated pulse? Are bats that use calls resembling the simulated pulse found in all three areas ensonified in this study? At what height was the ensonification device placed? Was this the approximate height that bats living in the area might be expected to fly?</italic></p><p>As pointed out above, the mechanism proposed is quite independent from the call structure as spectro-temporal cues are removed from the templates. Hence, we do not intend the results to model any particular species. Indeed, independently of the specific echolocation or foraging strategy, the information required to build the templates would be available to every bat that ensonifies its environment at a regular rate. However, as the place-recognition mechanism is intended to make up only the basic layer of the navigation behavior bats are capable of, we agree that specific echolocation or foraging strategies that vary from one bat species to another can be built on top of this capability.</p><p>We have added a line stating the height at which the data was collected. While this is somewhat lower than the height at which bats would normally fly, we think the foliage at the level of the measurements to be representative of the foliage at higher positions in the environment.</p><p><italic>Reviewer #2:</italic></p><p><italic>Overall the scientific approach is very well conceived and executed. The biophysical measurements are clearly motivated and described and the simulation approach is also well justified. The manuscript would benefit, however, from a more precise wording and better justification of some of the simulation assumptions.</italic> </p><p><italic>Following are specific comments, in order of appearance, not importance.</italic> </p><p><italic>In the fourth paragraph of the subsection “Model based place recognition”: The definition and implementation of temporal integration is misleading: temporal integration as a peripheral auditory limitation is (i) a feature of the Gammatone filter bank, determined by the duration of the filter impulse responses and (ii) a feature of the low-pass filtering (cutoff frequency not specified in the current paper) applied after compression. The first integration stage is not really a limit of temporal resolution; it only means that shorter events are recoded onto the frequency axis by the filter bank. The second integration is I guess already of a similar order as the 350 µs integration interval applied later. The authors should clarify implicit and explicit integration stages in their model.</italic> </p><p>We agree with the reviewer about the sources of temporal integration and we have clarified the text to make clear that in our model, in accordance with the Wiegrebe model referred to, the overall temporal integration is determined predominantly by the low-pass filter of the envelop extraction step (2nd order Butterworth filter with cut-off frequency 1 kHz). As explained in our reply to reviewer 1's comment sampling at an interval of 350 µs is done to remove the correlations introduced by the integration time of the auditory system. In response to this comment and a similar comment by reviewer 1, we have now made the rationale behind the sampling clearer. The text now reads as follows:</p><p>“In a next step, the templates were sampled at a rate of 1 sample per 350 µs to remove the correlations introduced by the integration time of the auditory system. The integration time of the model of Wiegrebe is slightly less than 350 µs.”</p><p><italic>In point 1 of the third paragraph of the subsection “Template based place recognition”: the authors use the words 'identify', 'discriminate', 'distinguish' and 'recognize' interchangeably. In psychophysics, (e.g. of object perception) these are quite different levels of perception and so the authors should stick to that expression that matches their simulation, namely discrimination. For identification, for example, discrimination and classification are seen as prerequisites, see e.g. the chapters on object perception in toothed whales in the book by Whitlow Au.</italic></p><p>We thank the reviewer for pointing this out and have reworked the text to be more consistent:</p><p>We use the term 'discriminate' to talk about the template discrimination that underlies the place recognition.</p><p>We now use the term 'recognize' when talking about places that are to be recognized. In this case, the term 'discrimination' does not feel appropriate.</p><p>We use the term 'identification' in the Methods section to describe the mathematical processes. In this context, the term 'identification' is warranted as it is a technical term describing the mathematical operations.</p><p><italic>In point 2 of the third paragraph of the subsection “Template based place recognition”: rework definition of smoothness. Only later it becomes clear the monotonicity is required.</italic></p><p>The definition was updated accordingly.</p><p><italic>In the second paragraph of the subsection “Template Construction: provide values for compression and low-pass filtering.</italic> </p><p>We have added these values.</p><p><italic>In the third paragraph of the subsection “Template Construction”: What is the directionality of the emitting system? If you average cochleagrams across microphones, this is quite different than averaging the waveforms. The latter would produce strong directionality but what does averaging the cochleograms produce? This is very unphysiological! Shouldn't you have used the 31 mics like a phased array to thereby impose a bat HRTF on the data?</italic></p><p>Detailed specifications of the emitter can be found on the manufacturer's webpage: <ext-link ext-link-type="uri" xlink:href="http://www.senscomp.com/ultrasonic-sensors/series-7000-sensors.php">http://www.senscomp.com/ultrasonic-sensors/series-7000-sensors.php</ext-link></p><p>We would like to emphasize that we do not intend the averaging of cochleograms to model a specific operation in real bats. Averaging across neighboring directions is only intended to mitigate somewhat the high directionality of the speaker used for collecting the echoes. Averaging the cochleograms results in a system with the directionality as plotted in <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><p>It is true that, given an omnidirectional speaker, using the 31 microphones as a phased array would allow to approximate the directionality of any bat's echolocation system (emission + HRTF). However, as the speaker used is considerably more directional than the reception-emission apparatus of a bat such an approach would still result in an overall directivity that is considerably higher than the one for the real bat. Furthermore, as our template extraction process removes all spectral cues, approximating a specific HRTF would add very little to our results. Hence, we have preferred to focus on duplicating a realistic ensonification area by averaging the cochleograms.</p><p><italic>In the second paragraph of the subsection “Template Construction”: the dechirping appears to be functionally similar to channel wise normalized autocorrelation in Wiegrebe (2008). Why do you deviate from that model here?</italic></p><p>Both approaches would result in similar templates. In the Wiegrebe reference an autocorrelation could be performed as in the simulations the call could be 'recorded' without deformation. In contrast, in our real measurements, the emission of the pulse saturated the microphones. Hence, we did not have the picked up call available. We have added this comment to the paper.</p><p><italic>In the first paragraph of the subsection “Quantifying discriminability”: you cannot equalize acoustic noise of mics with noise in the template because of non-linear processing (half-wave rectification and compression) in between.</italic></p><p>We did not intend to say that the acoustic noise of the microphones was used directly as a measure of the noise for the templates. Hence, it seems that this section was somewhat misleading. As such we have expanded and clarified the way in which σ<sub>2</sub> was calculated.</p><p><italic><xref ref-type="fig" rid="fig5">Figure 5</xref>: considering that you have unknown emission directionality the comparison with real bats appears not meaningful.</italic></p><p>The emission directionality of the ensonification device is known as it can be reliably predicted using the directionality equations for a baffled piston. Hence, <xref ref-type="fig" rid="fig5">Figure 5</xref> takes this into account. We have updated the text to make this clear.</p><p><italic><xref ref-type="fig" rid="fig6">Figure 6</xref>: panoramic view!</italic></p><p>We have corrected the typo.</p><p><italic>In the third paragraph of the subsection “Template properties”: CF bats temporal resolution in the CF part however would be very bad (about equal to call duration, 50 ms!) so CF part is not usable, right?</italic></p><p>Yes, we assume that CF-FM bats would use the FM part of their calls. We have added this clarification.</p><p><italic>Reviewer #3:</italic></p><p><italic>[…] I enjoyed reading the paper and think it should be published. The analyses generally seem sound and carefully performed. Very few statistics are used in the paper; in some places a more formal analysis might lend weight to the results and interpretations. If I am reading the methods correctly, 3 replicate measurements were used to estimate noise at each position, which strikes me as a low number from which to estimate a distribution, whereas the Wiegrebe model used 20.</italic></p><p>Apparently, we failed to make clear the way in which the σ<sub>2</sub> was calculated. Indeed, reviewer 2 also commented on this section of the paper. Hence, we have expanded and clarified the text. In brief: we used 12 x 217 templates as input to calculate the value of σ<sub>2</sub>.</p><p><italic>As an experimentalist I would want to know to what extent bats actually behave in the ways predicted by the reported discrimination probabilities and catchment sizes. For example, the Wiegrebe paper that inspired the model did include some comparisons of P. discolor behavior against model predictions. Still, this paper sets the stage nicely for such an evaluation and provides a method for predicting navigation behaviors in a given environment. (I am less convinced that it provides a basis for rejecting object-based navigation mechanisms, which seemed to be an implied aim of the manuscript.)</italic></p><p>Our mechanism predicts that bats would not be able to distinguish between scenes if their 3D layout is different while their resulting template is similar. Therefore, behavioural evidence in favour of our approach would consist of bats failing to distinguish complex scenes made out of many echoes (i.e. with similar complexity of their natural habitats) that result in the same template, essentially a low-pass filtered range-intensity profile. To test this, one could generate echoes from a complex virtual scene and its mirror image. These should result in the same template whereas a 3D model account predicts bats should be able to distinguish between the two scenes. Alternatively, and possibly more straightforward to test, the 3D model account predicts bats would be able to recognize echoes coming from rotated versions of the same underlying scene. The template approach predicts that bats would be unable to make such generalizations for larger rotations, i.e. once the measured template would fall outside the catchment area of the stored template.</p><p><italic>The authors argue that inherent limitations of biosonar (spectral ambiguity, integration time) make it unlikely that 3D representation of a scene is available to a cruising bat, and that such a representation is therefore unavailable to recognize places. The bases for this argument are plausible, but stop short of ruling out explicit object layout reconstruction as a navigational cue. After all, bats do perform object recognition and localization. Integrating across multiple echo calls, for example, might allow an echolocating bat to ameliorate the spatial blur imposed by the integration time described in the paper. In this vein, the authors might also elaborate on object recognition vs. place recognition &quot;modes&quot; of echolocation. If object-recognition mechanisms are not part of template-based navigation strategy, is there a tradeoff between navigation and object perception performance?</italic> </p><p>This comment expresses the same concern as a similar one from reviewer 1 and so we repeat our reply here. We agree with both reviewers that bats have the ability to recognize objects. However, the behaviour of bats in recognition experiments differs from that of cruising/navigating bats. In recognition experiments, bats typically ensonify the same object from different directions as part of an active object-centered exploration process. Cruising/navigating bats on the other hand, fly by the objects along their flight path resulting in a more accidental, i.e. less object-centered, and less extensive series of observations of those objects. The proposed template-based strategy is well suited to such a fly-by mode of echolocation. Also, we would like to point out that even in the object recognition experiments bats might not be building a 3D reconstruction of the object. They might instead be looking for diagnostic acoustic cues, e.g. spectral cues as hypothesised in the study by Simon et al. Such an account of object recognition would be easily integrated with our template-based account of place recognition. One possible way the two might interact is that the template-based place descriptors would be used to build a map first and then later (or possibly in parallel) 'landmarks', i.e. uniquely identified objects, would be associated with places in the map. However, at this stage this is not much more than conjecture and we have not proposed specific mechanisms for how to do this. Hence, we prefer to keep this topic for future work.</p><p>Simon R, Holderied MW, von Helversen O. Size discrimination of hollow hemispheres by echolocation in a nectar feeding bat. J Exp Biol. 2006;209: 3599-3609. doi:10.1242/jeb.02398</p></body></sub-article></article>