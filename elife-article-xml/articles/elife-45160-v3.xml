<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">45160</article-id><article-id pub-id-type="doi">10.7554/eLife.45160</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-129401"><name><surname>Castaldi</surname><given-names>Elisa</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0327-6697</contrib-id><email>elisa.castaldi@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-80560"><name><surname>Piazza</surname><given-names>Manuela</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-130753"><name><surname>Dehaene</surname><given-names>Stanislas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-130754"><name><surname>Vignaud</surname><given-names>Alexandre</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-130755"><name><surname>Eger</surname><given-names>Evelyn</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Cognitive Neuroimaging Unit</institution><institution>CEA DRF/JOLIOT, INSERM, Université Paris-Sud, Université Paris-Saclay, NeuroSpin Center</institution><addr-line><named-content content-type="city">Gif-sur-Yvette</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Center for Mind/Brain Sciences</institution><institution>University of Trento</institution><addr-line><named-content content-type="city">Trento</named-content></addr-line><country>Italy</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">UNIRS</institution><institution>CEA DRF/JOLIOT, Université Paris-Saclay, NeuroSpin Center</institution><addr-line><named-content content-type="city">Gif-sur-Yvette</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="editor"><name><surname>Ansari</surname><given-names>Daniel</given-names></name><role>Reviewing Editor</role><aff><institution>Western University</institution><country>Canada</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>24</day><month>07</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e45160</elocation-id><history><date date-type="received" iso-8601-date="2019-01-21"><day>21</day><month>01</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-07-18"><day>18</day><month>07</month><year>2019</year></date></history><permissions><copyright-statement>© 2019, Castaldi et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Castaldi et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-45160-v3.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.45160.001</object-id><p>Humans and other animals base important decisions on estimates of number, and intraparietal cortex is thought to provide a crucial substrate of this ability. However, it remains debated whether an independent neuronal processing mechanism underlies this ‘number sense’, or whether number is instead judged indirectly on the basis of other quantitative features. We performed high-resolution 7 Tesla fMRI while adult human volunteers attended either to the numerosity or an orthogonal dimension (average item size) of visual dot arrays. Along the dorsal visual stream, numerosity explained a significant amount of variance in activation patterns, above and beyond non-numerical dimensions. Its representation was selectively amplified and progressively enhanced across the hierarchy when task relevant. Our results reveal a sensory extraction mechanism yielding information on numerosity separable from other dimensions already at early visual stages and suggest that later regions along the dorsal stream are most important for explicit manipulation of numerical quantity.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.45160.002</object-id><title>eLife digest</title><p>Numbers and the ability to count and calculate are an essential part of human culture. They are part of everyday life, featuring in calendars, computers or the weekly shop, but also in some of humanity’s biggest achievements: without them the pyramids or space travel would not exist. A precursor of sophisticated mathematical skill could reside in a simpler mental ability: the capacity to assess numerical quantities at a glance. This ‘number sense’ appears in humans in early childhood and it is also present in other animals, but it is still poorly understood.</p><p>Brain imaging techniques have identified the parts of the brain that are active when perceiving numbers or making calculations. As techniques have advanced, it has become possible to resolve fine differences in brain activity that occur when people switch their attention between different visual tasks. But how exactly does the human brain process visual information to make sense of numbers? One theory suggests that humans use visual cues, such as the size of a group of objects or how densely packed objects are, to estimate numbers. On the other hand, it is also possible that humans can sense number directly, without reference to other properties of the group being observed.</p><p>Castaldi et al. presented twenty adult volunteers with groups of dots and asked them to focus either on the number of dots or on the size of the dots during a brain scan. This approach allowed the separation of brain signals specific to number from signals corresponding to other visual cues, such as size or density of the group. The experiment revealed that brain activity changed depending on the number of dots displayed. The signal related to number became stronger when people focused on the number of dots, while signals related to other properties of the group remained unchanged. Moreover, brain signals for number were observed at the very early stages of visual processing, in the parts of the brain that receive input from the eyes first.</p><p>These results suggest that the human visual system perceives number directly, and not by processing information about the size or density of a group of objects. This finding provides insights into how human brains encode numbers, which could be important to understand disorders where number sense can be impaired leading to difficulties learning math and operating with numbers.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>7T fMRI</kwd><kwd>multivariate decoding</kwd><kwd>representational similarity analysis</kwd><kwd>number processing</kwd><kwd>dorsal visual stream</kwd><kwd>feature based attention</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-14-CE13-0020-01</award-id><principal-award-recipient><name><surname>Eger</surname><given-names>Evelyn</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The representations of information concerning the number, size, density and surface of sets of objects in a visual image are separable along the occipito-parietal cortex and independently modulated by attention.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>One largely debated theme in cognitive neuroscience is how the human brain developed the ability to perform mathematics. While mathematical skills certainly rely on the interplay of a wide range of cognitive functions (<xref ref-type="bibr" rid="bib29">De Smedt et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">Fias, 2016</xref>; <xref ref-type="bibr" rid="bib61">Iuculano and Menon, 2018</xref>), an influential theory in the field proposes that a necessary prerequisite to develop such a sophisticated uniquely human ability resides in the ‘number sense’ (<xref ref-type="bibr" rid="bib30">Dehaene, 1997</xref>). This is a phylogenetically ancient competence that enables humans and other animals to assess and mentally manipulate the approximate number of objects in sets. In humans the precision of the number sense (or ‘numerical acuity’, typically measured by visual number discrimination) sharpens with age and with the acquisition of formal mathematical education (<xref ref-type="bibr" rid="bib92">Piazza et al., 2013</xref>), and correlates with arithmetical skills throughout the life-span (<xref ref-type="bibr" rid="bib50">Halberda et al., 2008</xref>; <xref ref-type="bibr" rid="bib74">Libertus et al., 2011</xref>; <xref ref-type="bibr" rid="bib75">Libertus et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Chen and Li, 2014</xref>; <xref ref-type="bibr" rid="bib4">Anobile et al., 2016a</xref>; <xref ref-type="bibr" rid="bib7">Anobile et al., 2018</xref>). Deviations from the typical developmental trend of numerical acuity can be a symptom of developmental dyscalculia (<xref ref-type="bibr" rid="bib91">Piazza et al., 2010</xref>), a neurodevelopmental disorder that causes specific mathematical learning difficulties.</p><p>The neural substrate subtending this sense of numerical quantity is thought to be shared across species and has been linked to a network of areas in the frontal and parietal cortices sensitive to changes in numerosity since very early in life (<xref ref-type="bibr" rid="bib62">Izard et al., 2008</xref>; <xref ref-type="bibr" rid="bib57">Hyde and Spelke, 2011</xref>; see for reviews: <xref ref-type="bibr" rid="bib16">Cantlon, 2012</xref>; <xref ref-type="bibr" rid="bib28">de Hevia et al., 2017</xref>). In these areas electrophysiological recordings in monkeys identified single neurons tuned to specific numerosities of visual arrays (<xref ref-type="bibr" rid="bib81">Nieder et al., 2002</xref>; <xref ref-type="bibr" rid="bib83">Nieder and Miller, 2004</xref>; <xref ref-type="bibr" rid="bib97">Roitman et al., 2007</xref>; <xref ref-type="bibr" rid="bib82">Nieder, 2016</xref>) and fMRI studies in humans found activation in these areas to be modulated during quantity perception as well as during calculation (for reviews see: <xref ref-type="bibr" rid="bib8">Arsalidou and Taylor, 2011</xref>; <xref ref-type="bibr" rid="bib38">Eger, 2016</xref>; <xref ref-type="bibr" rid="bib94">Piazza and Eger, 2016</xref>). While the first imaging studies in humans were limited by the low spatial resolution and univariate subtraction-based analyses, fMRI adaptation and multivariate pattern analysis methods provide higher sensitivity to finer-scale activity differences (<xref ref-type="bibr" rid="bib67">Kourtzi and Grill-Spector, 2005</xref>; <xref ref-type="bibr" rid="bib84">Norman et al., 2006</xref>; <xref ref-type="bibr" rid="bib107">Tong and Pratte, 2012</xref>). These methods allowed researchers to study the representation of individual numbers by recording the distance-dependent signal release from adaptation (<xref ref-type="bibr" rid="bib89">Piazza et al., 2004</xref>), or reading out patterns of number-related activity across multiple voxels of the frontal and parietal cortex (<xref ref-type="bibr" rid="bib36">Eger et al., 2009</xref>). Moreover, population-receptive field mapping (pRF) methods identified individual locations tuned to specific numerosities arranged in spatially organized maps in the parietal cortex (<xref ref-type="bibr" rid="bib52">Harvey et al., 2013</xref>).</p><p>While these earlier findings mostly pointed at the key role of parietal and frontal areas in numerical representation, some recent studies found that it is possible to decode the number of items seen by the subjects from the fMRI activity patterns in early visual areas (<xref ref-type="bibr" rid="bib12">Bulthé et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Eger et al., 2015</xref>; <xref ref-type="bibr" rid="bib13">Bulthé et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>, but see <xref ref-type="bibr" rid="bib18">Castaldi et al., 2016</xref>). Moreover, spatially organized numerosity maps were recently claimed to extend to the occipital cortex (<xref ref-type="bibr" rid="bib55">Harvey and Dumoulin, 2017a</xref>) and early ERP components compatible with generators in early visual areas responded to variations in the numerosity of visual arrays (<xref ref-type="bibr" rid="bib87">Park et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Fornaciai et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Fornaciai and Park, 2017</xref>).</p><p>Several properties characterizing numerosity perception, such as being ratio-dependent (Weber’s law) and being susceptible to adaptation, led some authors to suggest that number is a ‘primary’ visual property of the image that is directly perceived through specialized and dedicated mechanisms (<xref ref-type="bibr" rid="bib14">Burr and Ross, 2008</xref>; <xref ref-type="bibr" rid="bib98">Ross, 2010</xref>; <xref ref-type="bibr" rid="bib5">Anobile et al., 2016b</xref>). However, in spite of dedicated efforts on modeling the extraction of numerosity from the visual image (<xref ref-type="bibr" rid="bib31">Dehaene and Changeux, 1993</xref>; <xref ref-type="bibr" rid="bib110">Verguts and Fias, 2004</xref>; <xref ref-type="bibr" rid="bib26">Dakin et al., 2011</xref>; <xref ref-type="bibr" rid="bib104">Stoianov and Zorzi, 2012</xref>; <xref ref-type="bibr" rid="bib80">Morgan et al., 2014</xref>), the detailed neural processing mechanisms used by the brain to arrive at a representation of numerosity from the visual input remain little understood, and much less understood than the ones for other basic visual features such as orientation, colour, motion, etc. Numerosity is a notoriously difficult feature to study since changes in numerosity tend to be associated with changes in other quantitative features of the sets during natural viewing conditions (e.g., more items tend to occupy a larger area, or be spaced more densely), and it appears impossible to control for all of these associated quantities at the same time. For this reason, in spite of a large body of behavioral and neuroscientific work on this topic, it still remains debated whether the available evidence supports a sensory extraction mechanism directly sensitive to numerosity. Some have argued instead that numerosity might be judged indirectly by weighing a combination of other, non-numerical, quantitative features of the stimuli (<xref ref-type="bibr" rid="bib48">Gebuis and Reynvoet, 2012</xref>; <xref ref-type="bibr" rid="bib47">Gebuis et al., 2014</xref>; <xref ref-type="bibr" rid="bib72">Leibovich et al., 2016a</xref>). For example, numerosity can be mathematically defined as the product of density (number of items per unit of area) by field area; or by the total surface area divided by mean item size. Thus, decisions on numerical quantity could be taken merely indirectly, on the basis of representations of these non-numerical properties, without numerosity being encoded directly by perceptual systems.</p><p>While this possibility is interesting, several behavioral findings argue against it: (1) the discrimination of numerosity and of one often correlated non-numerical feature (item density) follow different psychophysical laws (<xref ref-type="bibr" rid="bib5">Anobile et al., 2016b</xref>), and (2) at least for relatively small numbers of not too densely spaced items, perceptual thresholds for numerosity discrimination are typically much smaller than the ones predicted from the thresholds for density and field area together (<xref ref-type="bibr" rid="bib25">Cicchini et al., 2016</xref>), making it unlikely that estimates of numerosity are based on the latter. For what concerns the neuronal level, a few recent studies have started to directly quantify the effects of non-numerical dimensions of non-symbolic numerical stimuli (e.g. <xref ref-type="bibr" rid="bib87">Park et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Fornaciai et al., 2017</xref>; <xref ref-type="bibr" rid="bib56">Harvey and Dumoulin, 2017b</xref>; <xref ref-type="bibr" rid="bib45">Fornaciai and Park, 2018</xref>; <xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>). Those studies found that activity in earlier (occipital) or later (parietal) brain regions appeared to be linked to the numerical content of sets after taking into account effects of certain non-numerical dimensions. However, they mostly only considered the effect of one non-numerical variable at the time and compare it to that of number, without taking into account effects explained by all relevant non-numerical dimensions together. Thus, it still remains unclear to what extent activity evoked by non-symbolic numerical stimuli within early and later regions can be explained by a mechanism that encodes numerosity in itself, or by the ensemble of responses to the different non-numerical dimensions of the stimuli.</p><p>Here, we implement a new approach to separate brain signals related to numerical and non-numerical quantities and test for a neuronal mechanism directly sensitive to the numerosity of visual sets along the dorsal visual stream hierarchy. We propose that the following signatures would advocate for the existence of such a mechanism:</p><p>First, information on numerosity should be detectable in regional activity patterns after multiple important non-numerical quantities are simultaneously (and not only individually) taken into account. Second, and importantly, it should be possible to selectively amplify this numerical information depending on whether the numerical dimension of the stimuli is task relevant, similar to the attentional amplification that has been previously shown for other task-relevant primary features, such as orientation, contrast, color, direction etc. (<xref ref-type="bibr" rid="bib63">Jehee et al., 2011</xref>; <xref ref-type="bibr" rid="bib39">Ester et al., 2016</xref>). If a brain area encodes numerical information in a way that is separable from associated non-numerical dimensions, tasks involving selective attention to number should enhance the information about numerosity, without affecting the level of information on associated non-numerical dimensions. Thus, we propose that the presence of such independent attentional amplification is a key criterion in order to identify which brain areas explicitly encode information on numerosity.</p><p>On the contrary, if activity patterns could be entirely accounted for by the combination of responses to multiple non-numerical dimensions of the stimuli, no information specifically related to number should be found in the patterns of activity once accounting for the other (non-numerical) dimensions simultaneously. Furthermore, if numerosity was not directly encoded but only indirectly inferred from percepts of non-numerical properties, attentional enhancement should not occur for signals related to numerosity, but if anything, only for other properties (e.g., density and field area) that can jointly define it.</p><p>To test these predictions, we created a novel stimulus space to disentangle the contribution of numerical and non-numerical dimensions to brain activity patterns, and designed a task where attention is selectively directed towards either of two orthogonal quantitative dimensions of the visual array (number or item size). We exploited the enhanced sensitivity achieved by fMRI at ultra-high field (7 Tesla) and specific multivariate pattern analyses to simultaneously model and separate the contributions of numerical and different non-numerical quantities to fine-scale activity patterns within multiple regions defined by a probabilistic atlas based on visual topography.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We scanned twenty healthy adult volunteers while they performed two tasks on arrays of dots varying orthogonally in numerosity (6, 10, or 17 items), average item size (0.04, 0.07, or 0.12 visual square degrees - vd<sup>2</sup>) and total field area (44 or 20 vd<sup>2</sup>) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Participants alternated between a ‘number’ and a ‘size’ task in different blocks: during the ‘number’ blocks they had to direct attention to the numerosity of each sample stimulus and keep it in memory for comparison with an occasionally following match stimulus, while during ‘size’ blocks they performed the equivalent task on the average item size of the arrays (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). When a match stimulus appeared (indicated by a change in color of the fixation point), participants had to decide whether the match stimulus was larger or smaller on the attended dimension than the previous sample held in memory and to respond by button press.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.45160.003</object-id><label>Figure 1.</label><caption><title>Stimulus set and design for the fMRI experiment.</title><p>(<bold>A</bold>) Example of the full set of stimulus conditions. Arrays of six, ten or seventeen dots were created with three average item areas (0.04, 0.07 and 0.12 visual degree<sup>2</sup>) and displayed within two total field areas, enclosed by imaginary circles of 5° (TFA 1) and 7.5° (TFA 2) diameter. (<bold>B</bold>) Illustration of the trials’ temporal presentation and paradigm during scanning. At the beginning of each block, written instructions informed participants about the dimension to attend: either the numerosity or the average size of the dots arrays. Participants were instructed to keep in memory the relevant dimension of each sample trial until the following trial was shown (after a variable time interval of 3.5–5.5 s). The color of the fixation point in the upcoming trial provided further instruction: if it remained green, participants had to update their memory with the new stimulus (new sample trial), while if it turned red, participants had to compare the current stimulus (match trial) with the one kept in memory, and to indicate by button press whether the match stimulus was larger or smaller than the sample on the attended dimension. After the response a new sample stimulus appeared after at least 8 s. FMRI analyses focused on activity evoked by sample stimuli only.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45160.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Additional illustration of stimulus set.</title><p>Example of stimulus conditions showing approximately how number varies as a function of total surface area (<bold>A</bold>) and density (<bold>B</bold>). Images in (<bold>A</bold>) are taken from the small total field area set (but the same relationship between number and total surface area holds for the large total field area). Images in (<bold>B</bold>) are taken from the medium average item size (but the same relationship holds for the small and large average item size) and the gray bar links the images with same total field area, either large (left) or small (right).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig1-figsupp1-v3.tif"/></fig></fig-group><sec id="s2-1"><title>Behavioral performance and univariate fMRI activation effects</title><p>Response accuracies for comparison of match stimuli were overall high and not significantly different across tasks (86% for the number task and 85% for the average size task, t(19) = 0.46, p = 0.65), suggesting that subjects attended to the correct stimulus dimension and the difficulty was on average successfully matched across tasks (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.45160.005</object-id><label>Figure 2.</label><caption><title>Behavioral performance during scanning and univariate effects of task.</title><p>(<bold>A</bold>) The percentage of correct responses to match stimuli for the two tasks performed during scanning shows that task difficulty was successfully matched (n = 20, mean ± standard error of the mean (SEM)). (<bold>B–D</bold>) Statistical results obtained from the surface based group analysis (n = 20). The maps show the activation elicited for all sample trials during the number task (<bold>B</bold>) and the size task (<bold>C</bold>) when contrasted against the implicit baseline and against each other (<bold>D</bold>). Activation maps are thresholded at p &lt; 0.001, uncorrected for multiple comparison, and displayed on Freesurfer’s fsaverage surface with colored outlines identifying the major anatomical sulci and gyri based on the Destrieux Atlas (<xref ref-type="bibr" rid="bib41">Fischl, 2004</xref>) and white outlines the field maps IPS0-5 based on visual topography (<xref ref-type="bibr" rid="bib113">Wang et al., 2015</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig2-v3.tif"/></fig><p>We started the analysis of the functional imaging data by evaluating overall regional activation effects during both tasks. Surface-based random-effects group analysis identified similar bilateral activations in the occipito-parietal and frontal cortex during both tasks for sample stimuli against the implicit baseline where participants were just looking at the fixation point with blank screen and without performing any task (<xref ref-type="fig" rid="fig2">Figure 2B and C</xref>, thresholded at p &lt; 0.001 uncorrected). In both tasks the activity covered a wide occipito-parietal area starting from the superior occipital and transverse occipital sulci and extending throughout the intraparietal sulcus (IPS) up to the post-central sulcus.</p><p>The frontal activity mainly covered the superior frontal gyrus. The direct contrast of sample stimulus-related activity during the number versus the size task revealed no area with significantly stronger activation for either of the two, despite the uncorrected significance threshold (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Altogether, these results suggest that task difficulty was successfully matched and that under these conditions attending to different quantitative dimensions leads to equivalent overall activation of the brain regions involved in the task. Differences in overall activation level can therefore not confound the following more specific results on the within-dimension discriminability of quantitative features.</p></sec><sec id="s2-2"><title>Multivariate fMRI Pattern Analyses</title><sec id="s2-2-1"><title>Read-out of sample numerosity is modulated by task</title><p>Given that the whole brain univariate contrasts had confirmed equivalent activations across the two tasks, we further investigated, using multivariate classification, what was the degree of discriminability of activity patterns evoked by different sample numerosities across different regions of the dorsal visual stream and during the number and size task. In each subject we identified several regions of interest (ROIs) derived from a surface-based probabilistic atlas based on visual topography (<xref ref-type="bibr" rid="bib113">Wang et al., 2015</xref>), (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Within each region, we used an equivalent number of most activated voxels (in the orthogonal contrast ‘all sample stimuli &gt; baseline’) to train and test multivariate classifiers to discriminate between numerosities for each task (for the ability of the classifier to discriminate task see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> and <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref> of the Supplementary Material). <xref ref-type="fig" rid="fig3">Figure 3B</xref> shows the across-subject overlap map for the included voxels which mainly highlight the foveal portion of the different ROIs, in line with the central presentation of the dot arrays. We first compared decoding accuracies in three large regions corresponding to early, intermediate and higher-level areas (including areas from V1 to V3, from V3AB to V7 and from IPS1 to IPS5, respectively). Then, to track the presence of information discriminative of numerosity across the dorsal visual stream more in detail, we further compared the classification accuracies across seven contiguous ROIs from V1 up to IPS345 (for results concerning the intraparietal sulcus excluding those regions defined by visual topography see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A</xref> and <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4a and 4b</xref> in Supplementary Material). <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows the performance of the classifiers trained to discriminate between different numerosities as a function of task. Overall, the presented sample numerosity could be decoded significantly above chance in all the ROIs and during both the number and size task, however with important differences. When explicitly attending to numerosity, the classification accuracy gradually increased across the dorsal stream (starting to be enhanced from intermediate areas, specifically from V3AB on), and was highest in parietal areas. During the size task, when attention was not explicitly directed towards the numerical aspect of the stimuli, the different numerosities were still decodable, however the classification accuracies were reduced in intermediate and higher regions, while they remained almost unchanged in early visual areas (specifically in V1, V2 and V3).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.45160.006</object-id><label>Figure 3.</label><caption><title>ROI localization and results of multivariate classification for discrimination between numerosities as a function of the task.</title><p>(<bold>A</bold>) Color-coded ROIs defined by the probabilistic atlas are shown on the inflated brain template. (<bold>B</bold>) Across-subject overlap map of the most activated voxels in the contrast all sample &gt; baseline. For each subject the most activated voxels were selected from each ROI (outlines) and hemisphere and the color map shows the number of subjects for which a given location was selected. (<bold>C</bold>) Sample numerosities could be classified significantly above chance across all the combined (left side) and individual (right side) ROIs, both during the number (white bars) and size (gray bars) task. The classification performance is strongly modulated by task only in the intermediate and higher-level ROIs, starting from V3AB on, but not in the early areas (V1, V2 and V3). Results show mean classification accuracy across subjects (n = 20) ± standard error of the mean (SEM). Stars mark the difference across tasks, not against chance level (which is significant for all regions and tasks; see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for statistical results).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig3-v3.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45160.007</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Results of multivariate classification for discrimination between tasks.</title><p>Task (judge number vs judge size) could be classified significantly above chance in intermediate (V3AB-V7) and higher level (IPS 1–5) regions, but not in early visual areas (V1-3). ANOVA on the merged regions revealed a significant effect of ROI (F(1.42,27.07) = 6.623, p = 0.0090). The classification accuracy significantly increases when proceeding across the visual hierarchy starting to be above chance from V3AB on, but not in the early areas (V1, V2 and V3). ANOVA on the individual ROIs showed a significant main effect of ROI (F(2.67,50.79) = 11.027, p &lt; 10<sup>−4</sup>)). The bar graph shows mean classification accuracy across subjects (n = 20) ± standard error of the mean (SEM). Detailed results of the two-tailed t-tests against 0.5 (chance level) used to evaluate the significance of task classification reported in <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig3-figsupp1-v3.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45160.008</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Results for the ROI defined along IPS excluding IPS0-5.</title><p>(<bold>A</bold>) Results of multivariate classification for discrimination between numerosities during the number (white bar) and size (gray bar) task and for discrimination between tasks (blue bar). Sample numerosities could be classified significantly above chance both during the number (t-test against chance: t(19) = 8.94, p &lt; 10<sup>−6</sup>) and size (t-test against chance: t(19) = 5.87, p = 0.000001) task, and the classification performance was modulated by task (paired t-test: t(19) = 4.50, p = 0.0002). Task could also be significantly discriminated in this region (t(19) = 4.3, p = 0.0004). While number could be discriminated to a similar extent in this region and in the IPS1-5 ROI (t-test across ROIs: t(19) = 0.66, p = 0.5), classification accuracy for discrimination between tasks was significantly higher in IPS excluding IPS0-5 ROI (t-test across ROIs: t(19) = 2.39, p = 0.03). The bar graph shows mean classification accuracy across subjects (n = 20) ± standard error of the mean (SEM). P-values indicating the significance of the classification accuracy for number during different tasks and for task are reported in <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4a and 4b</xref>, respectively. (<bold>B</bold>) Beta weights obtained from the RSA multiple regression for number (black triangles), average item size (circles), total field area (TFA, diamonds), total surface area (TSA, squares) and density (red triangles) for the number and size task. Only betas for number are significantly above zero (t(19) = 5.74, p = 0.00001) during the number task, however this value dropped to just not-significant values (t(19)=1.78, p = 0.09) during the size task. Beta values for the other dimensions were never significantly different from zero. Data points show mean beta weights across subjects (n = 20) ± standard error of the mean (SEM). P-values testing the significance of the beta coefficients for each dimension are reported in <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4c</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig3-figsupp2-v3.tif"/></fig></fig-group><p>The task-driven modulation of decoding accuracies across the three major ROIs is confirmed by a significant interaction between ROI and task (F(1.69,32.11) = 9.81, p = 0.0008). For the number task, the classification accuracy progressively increased from the early visual areas (slightly above 60%) to intermediate and higher level regions where it reached almost 70% correct. Post-hoc tests showed that the classification accuracy increase in intermediate and higher areas with respect to early areas was very close to or clearly significant (p = 0.075, Cohen’s d = 0.52, and p = 0.028, Cohen’s d = 0.57 respectively). During the size task, the classification accuracy in the intermediate and higher regions dropped down to 61% and 60% respectively (yet remaining highly significantly above chance in both cases, see p-values in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). The change in classification accuracy across tasks was highly significant both for the intermediate and higher areas, (p = 0.001, Cohen’s d = 0.88 and p = 0.00001, Cohen’s d = 0.98). On the other hand, the classification accuracy in the early visual areas remained nearly constant (62%) and was not significantly modulated by task (p = 0.5).</p><p>The significant interaction between ROI and task was confirmed when testing the seven individual regions (F(4.10,77.97) = 7.17, p = 0.00005). Although the post-hoc tests did not show significant differences in classification accuracies across individual ROIs, for the number task the decoding accuracies progressively increased across the visual hierarchy and varied from slightly above 60% in the primary visual areas (V1 = 62%, V2 = 62%, V3 = 61%) up to almost 70% in the intermediate and higher ROIs (V3AB = 64%, V7 = 65%; IPS12 = 67%, IPS345 = 67%). During the size task, decoding accuracies were much reduced in intermediate and higher regions (V3AB = 58%, V7 = 58%; IPS12 = 59%, IPS345 = 58%, yet still significantly above chance in all ROIs, see p-values in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>), while they remained almost unchanged in the primary visual areas (V1 = 61%, V2 = 62%, V3 = 60%). Accordingly, the post-hoc tests indicated that the classification accuracy in individual regions significantly changed across tasks only from V3AB on (V1: p = 0.28, Cohen’s d = 0.24; V2: p = 0.83, Cohen’s d = 0.05; V3: p = 0.55, Cohen’s d = 0.14; V3AB p = 0.0002, Cohen’s d = 0.98; V7: p = 0.00003, Cohen’s d = 1.20; IPS12: p = 0.00001, Cohen’s d = 1.03; IPS345: p = 0.00005, Cohen’s d = 1.26).</p><p>In sum, multivariate classification analyses revealed that the sample numerosity presented could be read out from brain activity patterns in all ROIs tested during both tasks, although accuracy was enhanced in mid-to-higher level but not in earlier regions when number was the attended feature. However, since in this analysis activations for all sample stimuli for a given numerosity were pooled together, the decoding performance obtained could still be partly driven by features other than numerosity per se.</p></sec></sec><sec id="s2-3"><title>Multiple regression RSA to disentangle the contributions of quantitative dimensions</title><p>As a critical test of whether the representations of numerical and non-numerical features of the stimuli could be dissociated across the dorsal visual stream, we performed Representational Similarity Analysis (<xref ref-type="bibr" rid="bib68">Kriegeskorte, 2008</xref>; <xref ref-type="bibr" rid="bib69">Kriegeskorte and Kievit, 2013</xref>) which, unlike classification-based decoding, allows to assess the effect of multiple quantitative dimensions on activity patterns simultaneously. For each ROI and task, we obtained a neural representational dissimilarity matrix (neural RDM, <xref ref-type="fig" rid="fig4">Figure 4A</xref>) by computing the correlation distance between activation patterns for each possible pair of conditions. We then applied multiple regression analysis to test in how far the fMRI pattern dissimilarity structure could be explained by multiple predictor matrices reflecting the stimuli’s dissimilarity along several important quantitative dimensions: numerosity, average item size, total field area, total surface area and density (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Of note, our design orthogonally manipulating numerosity, average item size and total field area ensured that numerosity was also partly decorrelated from density and total surface area (as shown by the correlation values in the Predictor Correlation matrix, <xref ref-type="fig" rid="fig4">Figure 4B</xref>), yet not completely (correlation between number and density predictors = 0.43; between number and total surface area predictors = 0.33). Correlations between predictors in a multiple regression lead to a reduction of the unique variance attributable to each one of them, and to a greater variability of the estimated betas. An estimation of variance inflation factors (VIF) for each predictor in our case revealed that these remained reasonably low (corresponding to 1.4874, 1.1957, 1.2048, 1.3238 and 1.4591 for number, average item size, total field area, total surface area and density, respectively). By using a multiple regression approach we capitalize on the fact that the resulting beta weights reflect only the part of the variance that each one of these stimulus descriptors uniquely explained in the pattern of activity of a given ROI on top of all the others. Thus, by entering numerical and non-numerical dimensions together into a multiple regression, a significantly above zero beta for number would imply that the numerical information is contributing to the pattern of activity within a given ROI, over and above the contribution of the other non-numerical quantitative dimensions.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.45160.009</object-id><label>Figure 4.</label><caption><title>Schematic illustration of representational similarity analysis.</title><p>Neural representational dissimilarity matrices (RDM) derived from fMRI were entered into a multiple regression where predictors corresponded to five matrices describing the dissimilarities across stimulus conditions along numerical and non-numerical dimensions. (<bold>A</bold>) Example neural RDM, quantifying the correlation distance (1 – Pearson correlation) between the patterns of activity elicited by all possible pairs of stimulus conditions across voxels within a given ROI (matrix scaled between 0 and 1 for visualization purposes). Each cell represents the correlation distance between activity patterns associated with a given pair of stimulus conditions (relatively lower values indicate more similar, and higher values more dissimilar patterns, respectively). The total of 18 conditions correspond to the combinations of 3 numerosities (N1, N2 and N3 corresponding to 6, 10 and 17 dots), three average item sizes (S1, S2 and S3 corresponding to small, medium and large average item sizes) and two total field areas (TFA1 and TFA2 corresponding to small and large total field area). The labels’ colors follow changes along the numerical dimension. (<bold>B</bold>) The five dissimilarity matrices used as predictors in the multiple regression analysis represent the logarithmic distance between pairs of stimuli in terms of number, average item size, total field area, total surface area and density (all matrices scaled between 0 and 1 for visualization purposes). The correlation across these five predicted matrices is shown in the ‘predictor correlation’ matrix.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig4-v3.tif"/></fig><p><xref ref-type="fig" rid="fig5">Figure 5</xref> displays the results of the estimated beta weights for various ROIs separately for the number (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) and size tasks (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Beta weights for the effect of number independent of the other dimensions (black triangles) were generally positive and progressively explained the activity patterns better when proceeding from lower to higher-level regions when task relevant. The evolution of the numerical information across the visual stream was attenuated during the size task, yet betas remained significantly above zero in all regions (see p-values in <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). Beta weights for the non-numerical dimensions (other shapes in <xref ref-type="fig" rid="fig5">Figure 5</xref>) were pronounced predominantly in the earlier visual areas and, importantly, they appeared to be not clearly affected by task.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.45160.010</object-id><label>Figure 5.</label><caption><title>Results of the representational similarity analysis.</title><p>Beta weights obtained from the RSA multiple regression analysis for number (black triangles), average item size (circles), total field area (TFA, diamonds), total surface area (TSA, squares) and density (red triangles) for the number (<bold>A</bold>) and size (<bold>B</bold>) task. While the fMRI pattern dissimilarity in early visual areas reflected contributions of multiple properties (TFA, density, TSA, but also number on top of these), when attending to number (<bold>A</bold>) the dissimilarity matrix for number increasingly better explained the fMRI pattern dissimilarity when progressing towards higher areas of the dorsal visual stream, where the contribution of non-numerical dimensions was smaller. The dissimilarity matrix for number however, contributed much less to explain neural dissimilarity in mid- and higher-level ROIs during the size task (<bold>B</bold>). The contribution of the non-numerical dissimilarity matrices remained mostly unaffected in most of the ROIs, with only a slightly enhanced contribution of the dissimilarity matrix for density which significantly contributed to explain the neural RDMs in higher areas during the size judgments. Data points show mean beta weights across subjects (n = 20) ± standard error of the mean (SEM). P-values testing the significance of the beta coefficients for each dimension and ROI are reported in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig5-v3.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45160.011</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Results of the representational similarity analysis for a model including only number, average item size and total field area as predictors.</title><p>Beta weights obtained from the RSA multiple regression for number (black triangles), average item size (circles), total field area (TFA, diamonds) for the number (<bold>A</bold>) and size (<bold>B</bold>) task. The triple interaction between ROI, task and dimension was significant both for the three large regions: F(2.86,54.43) = 4.73, p = 0.006 as well as for the individual regions: F(4.52,85.95) = 3.34, p = 0.01. When quantifying the changes in beta weights across ROIs and tasks for each dimension separately, the interaction between these factors was close to significance for number (for the three large regions: F(1.48,28.19) = 3.49, p = 0.0569; for the individual regions: F(2.25,42.69) = 2.92, p = 0.0589). The interaction between ROI and task was significant for average item size (for the three large regions: F(1.74,33.12) = 5.32, p = 0.01; for the individual regions: F(2.70,51.22) = 3.07, p = 0.04), however the near zero beta values estimated for this dimension make this result difficult to interpret, and not significant for total field area (for the three large regions: F(1.51,28.69) = 0.22, p = 0.74; for the individual regions: F(2.87,54.47) = 0.67, p = 0.56). Data points show mean beta weights across subjects (n = 20) ± standard error of the mean (SEM). P-values indicating the significance of the beta coefficients for each dimension and ROI are reported in <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig5-figsupp1-v3.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.45160.012</object-id><label>Figure 5—figure supplement 2.</label><caption><title>Results of the representational similarity analysis for a model including all the non-numerical dimensions only (i.e. average item size, total field area, total surface area and density).</title><p>Beta weights obtained from the RSA multiple regression for average item size (circles), total field area (TFA, diamonds), total surface area (TSA, squares) and density (Density, red triangles) for the number (<bold>A</bold>) and size (<bold>B</bold>) task. The beta estimates for these non-numerical features were not differentially affected by task across ROIs, as demonstrated by the not significant triple interaction between ROI, task and dimension both for the three large regions: (F(4.12,78.24) = 1.11, p = 0.36) as well as for the individual regions (F(5.66,107.50) = 0.88, p = 0.50). However the interaction between task and dimension was significant both for the three large regions: (F(2.13,40.42) = 3.65, p = 0.03) as well as for the individual regions (F(2.07,39.39) = 3.32, p = 0.04). When quantifying the changes in beta weights across ROIs and tasks for each dimension separately, the main effect of task was significant for average item size for the three large regions (F(1,19) = 7.02, p = 0.02) and but not for the individual regions (F(1,19) = 3.97, p = 0.06), however the near zero beta values estimated for this dimension make this result difficult to interpret. The main effect of task was significant for density for the three large regions (F(1,19) = 6.69, p = 0.02) and for the individual regions (F(1,19) = 7.13, p = 0.01). The main effect of task for the other dimensions was not significant for total field area (for the three large regions: F(1,19)=0.61, p = 0.44; for the individual regions: F(1,19) = 0.51, p = 0.48) and for total surface area (for the three large regions: F(1,19) = 2.04, p = 0.17; for the individual regions: F(1,19) = 2.66, p = 0.12). Data points show mean beta weights across subjects (n = 20) ± standard error of the mean (SEM). P-values testing the significance of the beta coefficients for each dimension and ROI are reported in <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-45160-fig5-figsupp2-v3.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Quantitative dimensions are modulated by task across ROIs to different extent</title><p>To statistically test for differential modulation of the contribution of the different quantitative dimensions to activation patterns, beta weights were analyzed with repeated measure ANOVAs with ROI, task and dimension as factors. As for the classification analysis, we first focused on the three large regions corresponding to early, intermediate and higher-level areas and then further on individual ROIs from V1 up to IPS345 (for results concerning the intraparietal sulcus excluding those regions defined by the atlas based on visual topography see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref> and <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4c</xref>).</p><p>The significant triple interaction between ROI, task and dimension confirmed that the beta weights estimated for the different dimensions were differently affected by task across ROIs (for the three large regions: F(4.23, 80.40) = 3.32, p = 0.01; for the individual regions: F(6.18,117.38) = 3.06, p = 0.007). To identify which dimension was maximally driving this effect, we quantified the changes in beta weights across ROIs and tasks for each dimension separately.</p></sec><sec id="s2-5"><title>Effects of the numerical dimension</title><p>Beta values for number were the only ones showing a significant interaction between ROI and task, when comparing the three large subdivisions across the visual stream (F(1.35,25.62) = 5.97, p = 0.015). During the number task, betas for number were higher in intermediate and higher-level areas with respect to early visual areas (although only the former comparison was significant, p = 0.04, Cohen’s d = 0.70). During the size task the betas for number were significantly lower (significant difference across tasks in early: p = 0.007, Cohen’s d = 0.78; intermediate: p = 0.000001, Cohen’s d = 1.96; higher areas: p = 0.00001, Cohen’s d = 1.43) and not different across regions.</p><p>When focusing on the seven individual ROIs, the interaction between ROI and task was significant (F(2.04,38.83) = 5.29, p = 0.009). Although post-hoc tests did not identify significant differences across ROIs, linear regression showed that the increase in beta weights for number across the dorsal visual stream was significant during the number task only (F(1,5) = 14.23, p = 0.01, R<sup>2</sup> = 0.74), while during the size task betas for number were much more homogenous across ROIs (F(1,5)=2.37, p = 0.18, R<sup>2</sup> = 0.32). Indeed the difference in beta weights between the number and size task was only minor or not significant in V1 and V2, more pronounced in V3, and highly significant from V3AB on (difference across tasks: V1: p = 0.025, Cohen’s d = 0.64; V2: p = 0.13, Cohen’s d = 0.37; V3: p = 0.001, Cohen’s d = 0.91; V3AB p = 0.000001, Cohen’s d = 1.44; V7: p = 0.000008, Cohen’s d = 1.54; IPS12: p = 0.000001, Cohen’s d = 1.56; IPS345: p = 0.000112, Cohen’s d = 1.28).</p></sec><sec id="s2-6"><title>Effects of the non-numerical dimensions</title><p>Different from number, beta weights estimated for the non-numerical dimensions were not modulated by task (no significant interaction between ROIs and task, no significant main effect of task) for any of the dimensions.</p><p>Independent of the task, total field area best explained activity patterns in early visual areas, while its contribution was reduced when proceeding through intermediate to higher-level areas (significant main effect of ROIs: F(1.23, 23.29)=35.24, p = 0.000002; significant differences in beta weights between primary and intermediate or higher-level ROIs: p = 0.000155, Cohen’s d = 1.24, p = 0.000008, Cohen’s d = 1.80, respectively). Beta values were highly significantly modulated also across the different individual ROIs (main effect of ROIs: F(2.11,40.12) = 32.27, p &lt; 10<sup>−5</sup>). Indeed, activity patterns in V1, V2 and V3 were explained equally well by total field area and better than intermediate and higher regions, starting from V3AB on (all p &lt; 0.01 at least).</p><p>Total surface area also most strongly modulated pattern dissimilarity in early visual areas. The significant main effect of ROI (F(1.45,27.63) = 16.61, p = 0.000078) and the following post-hoc tests showed that beta values for this dimension in the early visual areas were significantly higher than those estimated for the intermediate (p = 0.000475, Cohen’s d = 0.76) and higher-level (p = 0.000943, Cohen’s d = 1.30) ROIs, independent of the task. Beta weights for total surface area were comparable in V1, V2 and V3 (no significant difference across these ROIs) and significantly higher than those of the others ROIs starting from V3AB/V7 on (significant main effect of ROI: F(3.13,59.42) = 13.27, p = 0.000001, comparisons across regions: all p &lt; 0.01 at least).</p><p>Density modulated early visual areas during the number task and both earlier and higher-level areas during the size task. The main effect of ROI was significant (F(1.41,26.72) = 4.05, p = 0.04), but additional post-hoc tests did not reveal any significant difference across the three large ROIs. Also at the level of individual regions the main effect of ROI was significant (F(2.55,48.55) = 4.15, p = 0.01) and the strongest difference across ROIs emerged when comparing the lowest beta weights estimated in V3AB with those obtained in V1 (p = 0.003, Cohen’s d = 1.13) and V7, IPS12 and IPS345 (p = 0.03, Cohen’s d = 0.20, p = 0.01, Cohen’s d = 0.53, p = 0.002, Cohen’s d = 0.64).</p><p>Surprisingly, effects due to average item size could not be detected in any of the ROIs tested.</p><p>In sum, while early visual areas contained independent information on multiple quantitative properties of which some explained more variance than numerosity, all regions were modulated to some extent by numerical distance over and above what was explainable by the non-numerical dimensions. Moreover, importantly, explicitly directing attention to number did enhance the representation of numerical information and did so selectively, without altering the representations of non-numerical quantities. Finally, although present starting from the earliest stages of visual analysis, the numerical information at this level was only to a minor extent modulated by task and the greatest contribution to explicit manipulation of numerical quantity was found in intermediate and higher-level regions.</p></sec><sec id="s2-7"><title>Models with reduced number of predictors</title><p>Overall, the model described in the previous sections, which takes into account multiple numerical and non-numerical dimensions simultaneously, seems to us the most appropriate way to address our main question, which concerns the contribution of numerosity to activity patterns above and beyond what can be explained by the non-numerical dimensions. However, since some correlations were present between the predictors for the different quantitative dimensions in our original model, we further explored in how far results might differ when modeling either only the orthogonal predictors (i.e. number, average item size and total field area) or only the non-numerical dimensions, some of which were correlated with number (i.e. average item size, total field area, total surface area and density). Overall the results obtained with only the orthogonal predictors (i.e. number, average item size and total field area; see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>) are rather similar to the ones obtained with the full model. Beta weights for number were positive, all along the visual hierarchy, and were attenuated during the size task, yet remaining significantly above zero in all regions (see p-values in <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>). Beta weights for average item size were almost never significant, while beta estimates for total field area were pronounced predominantly in the earlier visual areas. The most important difference with respect to the full model appears to be a somewhat higher contribution of the number predictor, especially pronounced in early visual regions. Results obtained from the model including only non-numerical dimensions were also similar to the full model (see <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> and p-values in <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>). Beta weights for average item size were around zero, those for total field area and total surface area were highest in early visual areas and then decreased with the visual hierarchy. Beta weights for density were positive both in early and in higher-level visual areas. The contributions of both total surface area and density show a tendency to be higher here compared to the full model, especially during the number task. However, in both of these analyses it remains ambiguous whether the effects observed for one given predictor are truly driven by that predictor, or potentially attributable to the unmodeled contribution of another one (in the first case, the relatively enhanced effect of number in early visual regions might actually be due to density and TSA which are not included in the model, whereas in the second case, effects attributed to density and TSA could actually be due to the unmodeled contribution of number. Only the most complete model including both numerical and non-numerical dimensions allows us to dissolve this ambiguity.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our work exploited the enhanced spatial resolution provided by ultra-high field fMRI to reveal how the human brain represents multiple quantitative dimensions of non-symbolic numerical stimuli. Furthermore, we tested whether and at what cortical level the numerical information can be represented and specifically modulated by attention independently of non-numerical visual properties of the image.</p><p>At the level of overall regional activity, attending to the numerosity or to the average size of the dots in the array recruited largely overlapping occipital and parietal areas, as also previously observed for perception and comparison of different types of quantities (<xref ref-type="bibr" rid="bib95">Pinel et al., 2004</xref>; <xref ref-type="bibr" rid="bib35">Dormal and Pesenti, 2009</xref>; <xref ref-type="bibr" rid="bib9">Borghesani et al., 2019</xref>); for a meta-analysis on other non-numerical representations see: <xref ref-type="bibr" rid="bib102">Sokolowski et al., 2017</xref>). Two previous fMRI studies have investigated task-related differences in univariate regional activity elicited by numbers of items either in the subitizing (<xref ref-type="bibr" rid="bib71">Leibovich et al., 2015</xref>) or in the estimation (<xref ref-type="bibr" rid="bib73">Leibovich et al., 2016b</xref>) range when participants attended to either the numerosity or to the total surface area of dot arrays while these dimensions varied congruently or incongruently with each other. During comparison of dot arrays within the subitizing range, the overall regional brain activity in the cingulate and right superior frontal gyrus was shown to be modulated by task order (<xref ref-type="bibr" rid="bib71">Leibovich et al., 2015</xref>). When testing larger numerosities, the activation in the right temporal parietal junction was modulated by the congruency between dimensions only when number, but not when total surface area, was the relevant dimension in a comparison task and several regions, including cingulate gyrus, anterior insula, superior frontal gyrus, orbitofrontal and inferior parietal cortex did either respond preferentially during the numerical or the non-numerical task (<xref ref-type="bibr" rid="bib73">Leibovich et al., 2016b</xref>).</p><p>While the fact that in the current experiment we do not observe significant differences between tasks at the univariate level might seem to contrast with the results by <xref ref-type="bibr" rid="bib71">Leibovich et al. (2015)</xref> and <xref ref-type="bibr" rid="bib73">Leibovich et al. (2016b)</xref>, several methodological differences are worth noting: first, the non-numerical dimensions investigated are different, being average item size in our case and total surface area in theirs. Second, in the current experiment we made the changes in number and in average item size equally discriminable and we successfully matched task difficulty as demonstrated by the equal percentage of correct responses across tasks. The numerical and non-numerical dimensions were not matched for perceptual discriminability in the studies by <xref ref-type="bibr" rid="bib71">Leibovich et al. (2015)</xref> and <xref ref-type="bibr" rid="bib73">Leibovich et al. (2016b)</xref>, leaving open the possibility that some of the differences in cortical activation may reflect the higher difficulty associated with the numerical as opposed to the non-numerical task. This possibility seems likely also because the experiments by <xref ref-type="bibr" rid="bib71">Leibovich et al. (2015)</xref> and <xref ref-type="bibr" rid="bib73">Leibovich et al. (2016b)</xref> required participants to perform a comparison on every trial, thus the measured response not only reflects the perceptual process, but also the decision/comparison component. In the current experiment instead, our contrast is related to the sample trials, where participants were only required to perceive/memorize the value on the relevant stimulus dimension, without performing a comparison (which was required only in the occasional match trials). Overall, having balanced task difficulty and excluded the contribution of the comparison process from the response, the current study found no differences between tasks at the univariate level. Only multivariate pattern analysis could detect differences in the way information along the different dimensions was encoded as a function of task in our study.</p><p>Multivariate decoding analyses showed that the sample numerosity presented could be read out from brain activity significantly above chance all along the visual stream, however with important differences across regions. When explicitly attended, the numerical information could be read out with gradually higher accuracy following an occipital-parietal gradient, up to a maximum level in the parietal cortices. The effect of attention strongly affected the accuracy of the numerical discrimination in intermediate and higher regions while leaving the accuracy in the early visual areas unaffected. The successful read-out of information related to numerosity from parietal cortices in the current experiment contrasts with some previous studies where fMRI signals discriminative of numerosity could not be detected in the parietal regions (<xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Fornaciai and Park, 2018</xref>). Differences in paradigms and sensitivity of the scanners used may account for this discrepancy. Most crucially, in those studies, participants were shown different numerosities and the task required detecting changes in the colour of the dots. Thus, participants’ attention may have not been directed to the numerosity of the visual arrays in that case, and the numerical information may have been reduced when focussing on the dots’ colour, similarly to what was observed for the size task in the current experiment. Although in the present study we could still read out numerical information even when it was irrelevant for the task, this signal may have remained undetected by less sensitive MRI scanners.</p><p>Above chance decoding of numerosity during both tasks was observed here within both the medial IPS parts organized according to visual topography, as well as more lateral/inferior IPS parts outside the visual field maps, to a similar extent. Both regions also allowed to successfully decode the task carried out by the subject, with slightly higher accuracy in the most lateral/inferior IPS part with respect to the most medial IPS part. It has been recently proposed that there might be a sub-regional specialization along the intra-parietal sulcus, with the most medial/superior regions supporting processing of physical quantities and the lateral/inferior part supporting numerical operations, such as numerical comparison and calculation (<xref ref-type="bibr" rid="bib54">Harvey et al., 2017</xref>; see also <xref ref-type="bibr" rid="bib20">Castaldi et al., 2019</xref>). Our multivariate decoding results only marginally allow us to support distinct roles for these regions, however, addressing this precise question was not an explicit aim of the present study. It remains possible that the representation of numerical information in these different subparts supports different cognitive processes which cannot be differentiated here. For example, while the pattern of activity read out from the IPS field maps might underly the perception of numerosity, the numerical information reflected by the pattern of activity of the more lateral/task-responsive regions of IPS might provide input to internal manipulations of quantity during numerical operations, but further studies are necessary to explore this possibility.</p><p>In our study the number presented could be decoded not only in parietal cortex, but already from the earliest stages of visual processing. However, since the multivariate classification analysis collapsed across the non-numerical dimensions of our stimulus set it is unclear whether the information underlying successful decoding was strictly numerical, especially in earlier regions. Some previous studies have dealt with the problem of correlations between numerical and non-numerical stimulus dimensions by controlling for non-numerical features one at the time and testing for fMRI adaptation effects, or replicability of decoding performance or layouts across conditions where individual non-numerical features where controlled for (<xref ref-type="bibr" rid="bib89">Piazza et al., 2004</xref>; <xref ref-type="bibr" rid="bib36">Eger et al., 2009</xref>; <xref ref-type="bibr" rid="bib52">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Harvey and Dumoulin, 2017a</xref>; <xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>). When the effects of non-numerical dimensions were measured directly, this was done in some studies by computing the explained variance or classification performance for each feature in isolation and comparing it to the one for number (<xref ref-type="bibr" rid="bib56">Harvey and Dumoulin, 2017b</xref>; <xref ref-type="bibr" rid="bib22">Cavdaroglu and Knops, 2019</xref>), leaving unspecified the degree to which the simultaneous contribution of several non-numerical dimensions could account for the findings (<xref ref-type="bibr" rid="bib47">Gebuis et al., 2014</xref>). Some other previous studies have taken a different approach, by modeling jointly the effects of numerosity and two non-numerical dimensions (termed ‘size in area’ and ‘spacing’) which were designed to be orthogonal to numerosity but do not necessarily constitute natural, perceptually relevant feature dimensions, but rather mathematically defined constructs (<xref ref-type="bibr" rid="bib33">DeWind et al., 2015</xref>; <xref ref-type="bibr" rid="bib87">Park et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Fornaciai and Park, 2018</xref>). This design also allowed the authors to estimate, from the combined beta weights of numerosity and the mentioned two orthogonal dimensions, which feature represented by different directions in their stimulus space most accounted for the effects in a given ERP component or brain area. However, brain signals can reflect a combination of responses to multiple quantitative dimensions, and this approach does not permit to distinguish, for example, a modulation by numerosity from two independent modulations by field area and density. In our study, on the contrary, we separated the contributions of numerical and non-numerical stimulus dimensions by applying multiple regression to representational distance matrices which allowed us to test for the extent to which numerosity could explain the pattern of activity while taking into account simultaneously the variability explained by several important natural non-numerical features. Indeed, estimating significantly above zero beta values for number implies that information about numerosity is present in the pattern of activity over and above the contributions of all the other included non-numerical features. We found that information specific to number was detectable beyond the information related to the other dimensions, and that the numerical information was gradually enhanced when progressing along the visual stream when explicitly task relevant, and less strongly represented, although still detectable, when not task-relevant. Importantly, the level of information on other quantitative but non-numerical properties of the image, such as total field area, total surface area and density, although reliably detected especially in earlier brain regions, was not altered when explicitly attending to the numerical quantity. Given that numerical information becomes available in parallel with the other features and independently selectable by attention from early processing stages on, it appears that the human visual system has the capacity to detect signals related to numerosity and separate these from other quantitative dimensions, starting from very basic visual primitives. This supports the existence of a sensory processing mechanisms from which numerosity could be derived directly, rather than making numerical judgements merely indirectly on the basis of percepts of associated non-numerical quantities. Of course, the question of why numerical judgements are nevertheless often influenced by non-numerical quantities, and how these interactions might arise from the involved neuronal populations, remains an important one that deserves further study. Here we modeled the influence of several important natural non-numerical quantitative dimensions on brain activity, though our selection is necessarily non-exhaustive. We acknowledge the fact that we cannot formally rule out that a feature of a different type than those considered by us may have contributed to the effects observed here, and our conclusions hold to the extent of the non-numerical features tested.</p><p>The enhancement of numerical information in activation patterns found here when number was the relevant stimulus dimension is extending a growing body of work on the neuronal correlates of feature-based attention. Neurophysiological studies have shown that attention to basic visual features either increases the gain or sharpens responses of neuronal populations preferentially responsive to these features in different visual areas (e.g. <xref ref-type="bibr" rid="bib109">Treue and Martínez Trujillo, 1999</xref>; <xref ref-type="bibr" rid="bib78">McAdams and Maunsell, 2000</xref>; <xref ref-type="bibr" rid="bib96">Reynolds et al., 2000</xref>; <xref ref-type="bibr" rid="bib77">Martinez-Trujillo and Treue, 2004</xref>; <xref ref-type="bibr" rid="bib27">David et al., 2008</xref>), see also: <xref ref-type="bibr" rid="bib17">Carrasco (2011)</xref> for a review). Correspondingly, fMRI decoding studies have found that directing attention to one feature dimension such as orientation, motion direction or color or to particular values within one given dimension improves the read-out of these features from brain activity in early sensory regions (<xref ref-type="bibr" rid="bib64">Kamitani and Tong, 2005</xref>; <xref ref-type="bibr" rid="bib65">Kamitani and Tong, 2006</xref>; <xref ref-type="bibr" rid="bib101">Serences and Boynton, 2007</xref>; <xref ref-type="bibr" rid="bib63">Jehee et al., 2011</xref>) but in some cases also in higher-level areas (<xref ref-type="bibr" rid="bib76">Liu et al., 2011</xref>; <xref ref-type="bibr" rid="bib39">Ester et al., 2016</xref>). According to one influential account, higher-level fronto-parietal areas such as the lateral intraparietal area (LIP) implement spatial ‘priority maps’ in which the level of activity at individual locations depends jointly on the different features of objects at these locations as well as on top-down factors such as their task relevance, associated reward, etc (<xref ref-type="bibr" rid="bib60">Itti and Koch, 2001</xref>; <xref ref-type="bibr" rid="bib106">Thompson and Bichot, 2005</xref>; <xref ref-type="bibr" rid="bib49">Gottlieb, 2007</xref>; <xref ref-type="bibr" rid="bib99">Sapountzis et al., 2018</xref>). Independent of spatial priority, LIP neurons have also been found to represent higher-level factors such as learned category membership and other non-spatial information (<xref ref-type="bibr" rid="bib46">Freedman and Assad, 2009</xref>) and to flexibly switch between encoding of different visual features, such as color or motion, depending on the task (<xref ref-type="bibr" rid="bib108">Toth and Assad, 2002</xref>; <xref ref-type="bibr" rid="bib58">Ibos and Freedman, 2014</xref>). The idea of a role for intraparietal areas as mere ‘priority maps’ or reflecting entirely flexible encoding of information on task-relevant features (without intrinsic selectivity) can insufficiently account for our results, since it would predict an equivalent amplification of the representation of average size when this is the attended feature instead of number. This is not what we observed. Our results are thus more compatible with an enhancement of the responses of neuronal populations with intrinsic selectivity to the feature numerosity in these areas (comparable to the one observed for other features in lower-level visual regions).</p><p>While the existence of individual neurons tuned to different numbers of items in intraparietal cortex is well established (<xref ref-type="bibr" rid="bib83">Nieder and Miller, 2004</xref>; <xref ref-type="bibr" rid="bib97">Roitman et al., 2007</xref>), the only electrophysiological study that recorded from neurons in the ventral intraparietal (VIP) cortex in macaque monkeys under changing task conditions (<xref ref-type="bibr" rid="bib111">Viswanathan and Nieder, 2015</xref>) found that neurons encoded numerosity to the same extent, regardless of whether the task required to attend to the number or the color of the items. This differs from our results which show a clear attentional amplification of numerosity information. Given that the human IPS 1–5 investigated in the current work is usually considered to be the equivalent of the macaque LIP/VIP complex (<xref ref-type="bibr" rid="bib66">Kastner et al., 2017</xref>), the difference between results may be due to a difference across species, but differences in paradigms and in the nature of the signal recorded in the two studies make it difficult to directly relate the two findings. For example, monkeys were trained initially with the color match to sample task, then re-trained to respond to number, thus implying comparisons across an extended time period and different context, whereas our participants switched between the two tasks within the same scanning session. In addition, it is possible that the color task with a single color per stimulus and a small number of highly distinguishable alternatives placed lower demands on attentional load compared to our average size task, therefore leaving number processing unaltered. Nevertheless, as a common denominator both studies agree on pointing to some degree of spontaneous encoding of numerosity in intraparietal areas under conditions of attention to an orthogonal stimulus dimension.</p><p>The gradual enhancement of numerosity information observed by us in the number task when progressing along the dorsal visual stream is compatible with a multi-stage process of the extraction of numerosity where attention may operate at multiple levels over which attentional enhancements accumulate. If numerosity information can be retrieved from multiple levels of the cortical hierarchy, this does not need to imply that this feature is encoded by individual neurons at all these levels, but it may be detectable by multivariate methods even if it existed only in distributed form across the population of neurons. As one speculative interpretation, the numerical information read out from early visual areas could reflect a location map (<xref ref-type="bibr" rid="bib31">Dehaene and Changeux, 1993</xref>), or the process of object segmentation where different individual items start to be separately represented, but this representation may not yet be in a form that is most easily read out for numerical discrimination. Higher areas may progressively transform and concentrate the initially distributed information onto individual neurons, which most likely constitute the base on which we operate when comparing numbers. This interpretation is in line with a recent study showing that although different numerosities could be discriminated based on the pattern of activity in early visual areas and parietal cortex, the behavioral precision of numerical discrimination was correlated with the decoding accuracy only in the latter region (<xref ref-type="bibr" rid="bib70">Lasne et al., 2019</xref>).</p><p>While earlier behavioral research suggested that the precision of numerical representation is predictive of formal arithmetic and gets refined with development and mathematical learning (<xref ref-type="bibr" rid="bib51">Halberda and Feigenson, 2008</xref>; <xref ref-type="bibr" rid="bib85">Nys et al., 2013</xref>; <xref ref-type="bibr" rid="bib90">Piazza, 2010</xref>; <xref ref-type="bibr" rid="bib91">Piazza et al., 2010</xref>; <xref ref-type="bibr" rid="bib92">Piazza et al., 2013</xref>), other recent evidence has led to a slightly different view: what might be changing with development and mathematical competence could be the ability to focus on numerical information while filtering out non-numerical dimensions during a numerical comparison task (<xref ref-type="bibr" rid="bib19">Castaldi et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Piazza et al., 2018</xref>; <xref ref-type="bibr" rid="bib103">Starr et al., 2017</xref>; <xref ref-type="bibr" rid="bib114">Wilkey et al., 2018</xref>). The influence of non-numerical dimensions on numerical judgments decreases over normotypical development and both dyscalculic children (<xref ref-type="bibr" rid="bib11">Bugden and Ansari, 2016</xref>; <xref ref-type="bibr" rid="bib93">Piazza et al., 2018</xref>; <xref ref-type="bibr" rid="bib105">Szucs et al., 2013</xref>; <xref ref-type="bibr" rid="bib114">Wilkey et al., 2018</xref>) and adults (<xref ref-type="bibr" rid="bib19">Castaldi et al., 2018</xref>) seem to be disproportionately affected by non-numerical dimensions during numerical comparison tasks. In light of these behavioral findings, it would be interesting to see whether in dyscalculic subjects, numerical information at the neuronal level is less precisely encoded overall or merely less accessible to attentional selection. It is possible that the capacity to selectively focus on the numerical information and to enhance it already from early levels of visual analysis on, as shown in the current study, is learned or emerging over development, and future studies should directly test this hypothesis.</p><p>A surprising result of the current experiment is that we could not find information about average item size in the pattern of activity in any of the regions examined, even though this feature’s perceptual discriminability was equated with the one of numerosity. This suggests that the neural mechanisms supporting average size representation may differ from those engaged during single object size analysis which has been shown to overlap partly with numerosity maps in parietal regions (<xref ref-type="bibr" rid="bib53">Harvey et al., 2015</xref>). Mechanisms for average size perception, and in general for ensemble statistics are still unclear. It has been previously suggested that average item size perception, like density perception, may rely on texture processing mechanisms rather than individual item identification (<xref ref-type="bibr" rid="bib59">Im and Halberda, 2013</xref>). Various regions along the ventral visual stream have been implicated in texture perception. In particular, adaptation studies have identified recovery of fMRI signal in the medial part of the posterior collateral sulcus that was selective for texture as opposed to color or shape of 3D irregular objects (<xref ref-type="bibr" rid="bib23">Cavina-Pratesi et al., 2010</xref>) and the parahippocampal place area (PPA) showed equal release from adaptation for object ensemble and surface textures, suggesting that ensembles and textures are processed similarly (<xref ref-type="bibr" rid="bib15">Cant and Xu, 2012</xref>). It is possible that average size is also represented in the ventral stream which was not covered here, and future studies should focus on these regions to try to detect a representation of average size. What we observed, however, was that beta weights for density obtained from RSA regression became significant in the parietal regions during the size task, suggesting that texture processing mechanisms may be automatically activated during the average size task. This interpretation, however, has to remain speculative and future studies should investigate neural mechanisms relating texture, density and average size processing.</p><p>In conclusion, with this study using high-resolution, high-field fMRI we provide direct neuroscientific evidence for a sensory processing mechanism capable of disentangling signals related to visual numerosity from the ones related to associated non-numerical quantities from early stages of cortical processing on, which can then be independently and progressively amplified across the dorsal visual stream when numerical information is explicitly task-relevant. An important goal for the future will be to better understand what are the processing steps and transformations occurring at the different levels of the cortical hierarchy that allow the human brain to isolate numerical information, for example by comparing fMRI data against computational models simulating the visual extraction of numerosity. In addition, it will be important to understand how neuronal representations of numerosity are shaped developmentally and at which cortical levels they can be perturbed to given rise to impaired behavior.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects and MRI acquisition</title><p>Twenty healthy adults with normal or corrected vision (10 males and 10 females, mean age 24 years) participated in the study. The study was approved by the regional ethics committee (CPP Ile de France VII, Hôpital de Bicêtre, No. 15–007) and all participants gave written informed consent. Sample size, although not specifically estimated prior to the study, was equal or larger than the one typically used in experiments in the field (see for examples: <xref ref-type="bibr" rid="bib36">Eger et al., 2009</xref>; <xref ref-type="bibr" rid="bib37">Eger et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Cavdaroglu et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Castaldi et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Borghesani et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Cavdaroglu and Knops, 2019</xref>; <xref ref-type="bibr" rid="bib34">DeWind et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Fornaciai and Park, 2018</xref>). Functional images were acquired on a SIEMENS MAGNETOM 7T scanner with head gradient insert (Gmax 80mT/m and slew rate 333 T/m/s) and adapted 32-channel head coil (Nova Medical, Wilmington, MA, USA) as T2*-weighted fat-saturation echo-planar image (EPI) volumes with 1.3 mm isotropic voxels using a multi-band sequence (<xref ref-type="bibr" rid="bib79">Moeller et al., 2010</xref>) (<ext-link ext-link-type="uri" xlink:href="https://www.cmrr.umn.edu/multiband/">https://www.cmrr.umn.edu/multiband/</ext-link>, multi-band [MB] = 2, GRAPPA acceleration with [IPAT] = 2, partial Fourier [PF] = 7/8, matrix = 120×150, repetition time [TR] = 2 s, echo time [TE] = 22 ms, echo spacing [ES] = 0.71 ms, flip angle [FA] = 68°, bandwidth [BW] = 1588 Hz/px, phase-encode direction left &gt;&gt;right). Calibration preparation was done using Gradient Recalled Echo (GRE) data. Sixty oblique slices covering the occipital, parietal and partially the frontal cortex were obtained in ascending interleaved order. Before the experimental runs two single volumes were acquired with the parameters listed above but with opposite phase encode direction to be used for distortion correction in the later analysis (see Image Processing and Data Analysis). T1-weighted anatomical images were acquired at 0.8 mm isotropic resolution using an MP2RAGE sequence (GRAPPA acceleration with [IPAT] = 3, partial Fourier [PF] = 6/8, matrix = 281×300, repetition time [TR] = 6 s, echo time [TE] = 2.92 ms, time of inversion [TI] 1/2 = 800/2700 ms, flip angle [FA] 1/2 = 4°/5°, bandwidth [BW] = 240 Hz/px,). During scanning participants wore a radiofrequency absorbent jacket (Accusorb MRI, MWT Materials Inc, Passaic, NJ, USA) to minimize so-called ‘third-arm’ or ‘shoulder’ artifacts due to regions where the head gradient is unable to unambiguously spatially encode the image (<xref ref-type="bibr" rid="bib112">Wald et al., 2005</xref>). Head movement was minimized by padding and tape. Visual stimuli were back-projected onto a translucent screen at the end of the scanner bore and viewed through a mirror attached to the head coil. Participants held two response buttons in their left and right hands.</p></sec><sec id="s4-2"><title>Stimuli and procedure</title><p>During fMRI scanning participants were centrally presented with heterogeneous arrays of dots, half black, and half white, on a mid-gray background to ensure that total luminance was not a cue for number, a strategy used in many previous studies (<xref ref-type="bibr" rid="bib1">Anobile et al., 2012</xref>; <xref ref-type="bibr" rid="bib2">Anobile et al., 2014</xref>; <xref ref-type="bibr" rid="bib6">Anobile et al., 2016c</xref>; <xref ref-type="bibr" rid="bib4">Anobile et al., 2016a</xref>; <xref ref-type="bibr" rid="bib7">Anobile et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Cicchini et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Dakin et al., 2011</xref>; <xref ref-type="bibr" rid="bib42">Fornaciai et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Morgan et al., 2014</xref>; <xref ref-type="bibr" rid="bib98">Ross, 2010</xref>).</p><p>The generated sets of dots were orthogonally varied in number, average item size and total field area for a total of 18 conditions: six, ten or seventeen dots were presented with either small, medium or large average item area (0.04, 0.07, 0.12 visual squares degree) and designed to fall within a small or large total field area (defined by a virtual circle of either about 5 or 7.5 visual degree diameter). This implies that higher numbers were associated with higher total surface areas (total surface area for number six, ten and seventeen respectively corresponded to: 0.25, 0.42, 0.71 vd<sup>2</sup> for the smallest average item size, to 0.42, 0.71 and 1.19 vd<sup>2</sup> for the medium average item size and to 0.72, 1.19 and 2.03 vd2 for the largest average item size, correlation between numerosity and total surface area: rho = 0.68, p = 0.002, see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>) and higher density (density for numerosity six, ten and seventeen respectively corresponded to: 0.30, 0.50 and 0.85 dots/vd<sup>2</sup> for the small total field area and to: 0.14, 0.23, 0.39 dots/vd<sup>2</sup> for the large total field area, correlation between numerosity and density: rho = 0.71, p = 0.0008, see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). Despite the significant correlations between numerical and non-numerical dimensions, some pairs of stimuli had equal or similar values of total surface area and density across numerosities and sizes (for example the array of ten dots with the smallest average item size had total surface area equal to 0.42 vd<sup>2</sup> which corresponded to the total surface area of the array of six dots with medium average item size, see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for a more comprehensive visualization of the full stimuli set). Convex hull was not explicitly controlled and a-posteriori calculation showed that it was correlated with number (average convex hull for numerosity six, ten and seventeen respectively corresponded to: 9, 14 and 18 vd<sup>2</sup> for the small total field area and to: 20, 31, 41 vd<sup>2</sup> for the large total field area, correlation between numerosity and convex hull: rho = 0.57, p = 0.01) and total field area (correlation between total field area and convex hull: rho = 0.78, p = 0.0001). Numbers and average item sizes were chosen to be perceptually equally discriminable based on a previous behavioral study (<xref ref-type="bibr" rid="bib19">Castaldi et al., 2018</xref>). Total field areas were chosen so that arrays of dots could be sufficiently sparse (~1 dot/vd<sup>2</sup>) to target the ‘number regime’ (<xref ref-type="bibr" rid="bib2">Anobile et al., 2014</xref>; <xref ref-type="bibr" rid="bib3">Anobile et al., 2015</xref>).</p><p>Within each run participants performed two tasks in different blocks, as indicated by the written task instructions provided at the beginning of each block. Instructions were shown for 2 s and specified whether participants had to attend either to the number of dots (number task) or to the average item size of the dots (size task) in the array. Six seconds after the instruction a delayed comparison task started with brief presentation (500 ms) of a sample dot array stimulus. At each trial participants attended to the cued dimension of the sample stimulus and held this information in memory until the following trial was presented, knowing that a comparison response with the following trial may be required. After a variable ISI of 3.5–5.5 s, a second dot array was presented. If the color of the fixation point remained unchanged (green), no comparison was required and participants only had to update their memory with the new sample stimulus. If instead the fixation point changed color (turning to red 1 s before the stimulus presentation) participants had to compare the current stimulus (match stimulus) with the one held in memory and decide whether the current stimulus was larger or smaller (on the attended dimension) than the previous one. Response was provided by button press and after 5.5 s the next sample stimulus was presented and the whole procedure started again. Match stimuli were designed to be ~2 JNDs larger or smaller than the previously presented sample stimulus on the attended dimension, based on each participant’s Weber fraction as measured in a behavioral test prior to the fMRI scanning, while the unattended dimension was the same as the previous sample stimulus.</p><p>Twenty trials were presented in each block: one trial for each one of the 18 sample stimulus conditions (3 numerosity x 3 sizes x two total field areas) and two match trials. The hands assigned to either the ‘smaller’ or ‘larger’ response were inverted in the middle of the scanning session, that is after the third run, and counterbalanced across subjects. Within the scanning session participants performed six runs of ~7 min and 44 s. Each run included four blocks where the two tasks alternated. The type of task with which the run started was balanced across runs and participants.</p><p>To measure their numerical and average size acuity, participants performed a behavioral test prior to the fMRI scanning. In different sessions participants were shown two consecutive centrally presented arrays of dots and were required to perform a discrimination task on the attended dimension (either numerosity or average item size) by pressing the left or the right arrow (to choose the first or the second stimulus respectively). The set of stimuli used included arrays of 5,7,9,11,15 and 20 dots (ratios 0.5, 0.7, 0.9, 1.1, 1.5 and 2 with respect to the reference of 10 dots) that could be displayed with the average dot areas of 0.05, 0.06, 0.08, 0.11, 0.15 and 0.2 visual square degrees (ratios 0.5, 0.6, 0.8, 1.1, 1.5 and 2 with respect to the reference of 0.1 visual square degrees). Dots were randomly drawn within two possible virtual circles of ~5.8 and 7.6 visual degrees diameter. Reference and test stimuli could appear either as first or as second stimulus. After task instructions and twelve practice trials, participants performed three sessions of one task and three sessions of the other, with counterbalanced order across subjects. For each task participants performed a total of 432 comparisons (6 numerosities x six average item sizes x two total field areas x two presentation order x three sessions). To quantify participants’ precision in number and size judgments, we computed the JND for each task. The percentage of test trials with ‘greater than reference’ responses was plotted against the log-transformed difference between test and reference and fitted with a cumulative Gaussian function using Psignifit toolbox (<xref ref-type="bibr" rid="bib100">Schütt et al., 2016</xref>). The difference between the 50% and the 75% points yielded the JND.</p><p>Stimuli and paradigms were generated and presented under Matlab 9.0 using PsychToolbox routines (<xref ref-type="bibr" rid="bib10">Brainard, 1997</xref>).</p></sec><sec id="s4-3"><title>Image processing and data analysis</title><p>EPI images were motion-corrected and co-registered to the first single band reference image using statistical parametric mapping software (SPM12, <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>). The single-band reference images of the two initial volumes acquired with opposite phase encode directions served to estimate a set of field coefficients using topup in FSL (<ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL</ext-link>), which was subsequently used to apply distortion correction (apply_topup) to all EPI images. Cortical surface reconstruction and boundary based registration of single band reference images to each subject’s cortical surface, as well as a minimal amount of surface constrained smoothing (FWHM = 1.5 mm) for noise reduction were performed in Freesurfer (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>).</p><p>The preprocessed EPI images (in subjects’ native space) were entered into a general linear model separately modeling the effects of the 36 sample conditions (3 numerosities x three average item sizes x two total field areas x two tasks, within each run the two repetitions for each condition were pooled together), the match stimulus separately for left and right hand and the written instructions at the beginning of the block as stick functions (using the default of 0 duration for events) convolved with the standard hemodynamic response function. The six motion parameters were included in the GLM as covariate of no interest. An AR(1) model was used to account for serial auto-correlation and low-frequency signal drifts were removed by a high-pass filter with a cutoff of 192 s. In each subject we contrasted the activation elicited by: all the sample stimuli during the number tasks against the implicit baseline (contrast name: ‘Judge Number &gt; Baseline’); all the sample stimuli during the size tasks against the implicit baseline (contrast name: ‘Judge Size &gt;Baseline’); all the sample stimuli during the number tasks against all the sample stimuli during the size tasks (contrast name: ‘Judge Number &gt; Judge Size). After creating the contrasts in each single subject’s volume space, the contrast images were projected onto the surface with Freesurfer, aligned to fsaverage and smoothed with a 3 mm fwhm Gaussian kernel. The second-level group analysis was then performed in the surface space.</p><p>The beta estimates for the sample stimulus conditions from the first-level analysis (one beta estimate per run and condition) were entered into pattern recognition analysis. In each subject we defined anatomical regions of interest (ROIs) derived from a surface based probabilistic atlas (<xref ref-type="bibr" rid="bib113">Wang et al., 2015</xref>) where regions are defined based on retinotopy. ROIs for V1 to IPS5 were created on the Freesurfer surface and projected back into each subject’s volume space. For each ROI we merged the left and right hemisphere. ROIs were further merged into three large ROIs corresponding to early (V1 to V3), intermediate (V3A, V3B and V7, also known as IPS0) and higher-level (IPS one to IPS5) areas. In addition we focused the analysis on individual regions: V1, V2, V3, V3AB (merging V3A and V3B), V7, IPS12 (merging IPS 1 and 2), IPS345 (merging IPS 3, 4 and 5). Finally, for supplementary analyses, we defined a region along the intraparietal sulcus excluding the field map representation IPS 0–5. This region was defined by excluding V7 (also called IPS0) and IPS1-5 from the intraparietal and transverse parietal sulci ROI as defined by the <xref ref-type="bibr" rid="bib32">Destrieux et al. (2010)</xref>. Within each one of these bilateral regions we selected on a subject-by-subject basis an equal number of 800 voxels that responded most strongly to the orthogonal contrast ‘all sample stimuli &gt; baseline’ for pattern recognition analysis. To evaluate the degree of spatial consistency of the selected voxels across subjects we created an overlap map with Freesurfer (<xref ref-type="fig" rid="fig3">Figure 3B</xref>): single subjects’ ROIs were aligned to fsaverage and the number of subjects for which a given location was included in their specific ROI was represented by a heat map (with yellow color meaning that a given location was selected in all subjects).</p><p>Pattern classification analysis was performed in scikit-learn (<xref ref-type="bibr" rid="bib88">Pedregosa et al., 2011</xref>) using beta estimates after subtracting the voxel-wise mean across conditions by applying linear support vector machines (SVM) with regularization parameter C = 1. Classification analysis was performed leaving patterns of one run out at each loop of the 6-fold cross-validation cycle. This implies that classifiers were trained on five betas per condition and tested with the left-out beta images (one per condition). The classification accuracies obtained for each cycle were then averaged together. Pairwise classification was performed for all pairs of numerosities collapsing across the size and total field area dimensions, but keeping patterns separated by task. Classification accuracy was then averaged across all pairs of numerosities for each task. A one-sample t-test against the theoretical chance level of 50% was performed to evaluate significance of discrimination. Repeated measures ANOVAs where then performed on classification accuracies with ROI and task as factors. For the results described in the Supplementary Material, equivalent analyses were performed on the decoding accuracies when the classifier was trained and tested to discriminate between tasks.</p><p>For representational similarity analysis (<xref ref-type="bibr" rid="bib68">Kriegeskorte, 2008</xref>; <xref ref-type="bibr" rid="bib69">Kriegeskorte and Kievit, 2013</xref>) the GLM was performed concatenating the runs and obtaining one single beta per condition, task and subject. Comparable to the procedure of the pattern classification analysis, voxel-wise scaling was applied by subtracting the mean across conditions. Neural representational dissimilarity matrices (neural RDMs) for each task and ROI were created by computing the correlation distance (1 – the Pearson correlation across voxels) between activity patterns associated with all possible pairs of conditions using CoSMoMVPA Toolbox (<xref ref-type="bibr" rid="bib86">Oosterhof et al., 2016</xref>). The neural RDMs were then entered in a multiple regression with five predictors corresponding to matrices encoding the distance between all pairs of conditions on a logarithmic scale for the different quantitative dimensions defining the dot arrays: number, average item size, total field area, total surface area and density. To explore potential effects of correlations between predictors, equivalent supplementary analyses included only orthogonal dimensions (i.e. number, average item size and total field area), or all non-numerical dimensions except number (i.e. average item size, total field area, total surface area and density). In the multiple regression analysis all distance matrices were z-transformed before estimating the regression coefficients. The obtained beta weights for each dimension and ROI were tested with one-sample t-tests against zero across subjects. The effects of ROI, dimension and task were analyzed with repeated measures ANOVAs.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was funded by the French National Research Agency (grant No ANR-14-CE13- 0020–01 to E Eger). We thank F De Martino and V Kemper for advice on fMRI acquisition parameters and procedures.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Validation, Visualization, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Validation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Validation, Investigation, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by the regional ethics committee (CPP Ile de France VII, Hôpital de Bicêtre, No. 15-007) and all participants gave written informed consent.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.45160.013</object-id><label>Supplementary file 1.</label><caption><title>Statistical results for the performance of the classifiers trained to discriminate between different numerosities.</title><p>The table reports t-values, degrees of freedom (Dof), p-values and confidence intervals of the two-tailed t-tests against 0.5 (chance level) used to evaluate the accuracies of number classification for every ROI and task.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp1-v3.docx"/></supplementary-material><supplementary-material id="supp2"><object-id pub-id-type="doi">10.7554/eLife.45160.014</object-id><label>Supplementary file 2.</label><caption><title>Statistical results for beta weights obtained from the RSA multiple regression.</title><p>The table shows t-values, degrees of freedom (Dof), p-values and confidence intervals of two-tailed t-tests against zero across subjects for every ROI and dimension (N: number, S: average item size, TFA: total field area, TSA: total surface area, D: density) for the number (left table) and size (right table) tasks.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp2-v3.docx"/></supplementary-material><supplementary-material id="supp3"><object-id pub-id-type="doi">10.7554/eLife.45160.015</object-id><label>Supplementary file 3.</label><caption><title>Statistical results for the performance of the classifiers trained to discriminate between tasks.</title><p>The table reports t-values, degrees of freedom (Dof), p-values and confidence intervals of the two-tailed t-tests against 0.5 (chance level) used to evaluate the significance of task classification for every ROI.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp3-v3.docx"/></supplementary-material><supplementary-material id="supp4"><object-id pub-id-type="doi">10.7554/eLife.45160.016</object-id><label>Supplementary file 4.</label><caption><title>Statistical results for the ROI IPS excluding IPS 0–5.</title><p>(<bold>a</bold>) Statistical results for the performance of the classifiers trained to discriminate between numerosities during the number (left table) and size (right table) task for the ROI IPS excluding IPS 0–5. The table reports the statistical results of the two-tailed t-tests against 0.5 (chance level). (<bold>b</bold>). Statistical results for the performance of the classifiers trained to discriminate between tasks for the ROI IPS excluding IPS 0–5. The table reports the statistical results of the two-tailed t-tests against 0.5 (chance level). (<bold>c</bold>) Statistical results for beta weights obtained from the RSA multiple regression for the ROI IPS excluding IPS 0–5. The table shows t-values, degrees of freedom (Dof), p-values and confidence intervals of two-tailed t-tests against zero across subjects for every dimension (N: number, S: average item size, TFA: total field area, TSA: total surface area, D: density) for the number (left table) and size (right table) tasks.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp4-v3.docx"/></supplementary-material><supplementary-material id="supp5"><object-id pub-id-type="doi">10.7554/eLife.45160.017</object-id><label>Supplementary file 5.</label><caption><title>Statistical results for beta weights obtained from the RSA multiple regression when including only number, average item size and total field area as regressors.</title><p>The table shows t-values, degrees of freedom (Dof), p-values and confidence intervals of two-tailed t-tests against zero across subjects for every ROI and dimension (N: number, S: average item size, TFA: total field area) for the number (left table) and size (right table) tasks.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp5-v3.docx"/></supplementary-material><supplementary-material id="supp6"><object-id pub-id-type="doi">10.7554/eLife.45160.018</object-id><label>Supplementary file 6.</label><caption><title>Statistical results for beta weights obtained from the RSA multiple regression when including only non-numerical dimensions as regressors (i.e., average item size, total field area, total surface area and density).</title><p>The table shows t-values, degrees of freedom (Dof), p-values and confidence intervals of two-tailed t-tests against zero across subjects for every ROI and dimension (S: average item size, TFA: total field area, TSA: total surface area, D: density) for the number (left table) and size (right table) tasks.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-45160-supp6-v3.docx"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.45160.019</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-45160-transrepform-v3.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Individual subjects' data points for behavioural and fMRI results for all regions of interest, corresponding to Figures 2A, 3C, 5, Figure 3—figure supplements 1 and 2, and Figure 5—figure supplements 1 and 2 as. cvs files. The maps displayed in figure 2B-D and 3B are provided in a format readable with Freesurfer/Freeview, one of the most widely used free neuroimaging softwares. The functional imaging dataset is available via the Open Science Framework (osf.io/6zch2).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Castaldi</surname><given-names>E</given-names></name><name><surname>Eger</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Data from: Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="archive" xlink:href="https://osf.io/6zch2">6zch2</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Linear mapping of numbers onto space requires attention</article-title><source>Cognition</source><volume>122</volume><fpage>454</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2011.11.006</pub-id><pub-id pub-id-type="pmid">22154543</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Separate mechanisms for perception of numerosity and density</article-title><source>Psychological Science</source><volume>25</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1177/0956797613501520</pub-id><pub-id pub-id-type="pmid">24270462</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Turi</surname> <given-names>M</given-names></name><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mechanisms for perception of numerosity or texture-density are governed by crowding-like effects</article-title><source>Journal of Vision</source><volume>15</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/15.5.4</pub-id><pub-id pub-id-type="pmid">26067522</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Turi</surname> <given-names>M</given-names></name><name><surname>Tinelli</surname> <given-names>F</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Numerosity but not texture-density discrimination correlates with math ability in children</article-title><source>Developmental Psychology</source><volume>52</volume><fpage>1206</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1037/dev0000155</pub-id><pub-id pub-id-type="pmid">27455185</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Number as a primary perceptual attribute: a review</article-title><source>Perception</source><volume>45</volume><fpage>5</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1177/0301006615602599</pub-id><pub-id pub-id-type="pmid">26562858</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Arrighi</surname> <given-names>R</given-names></name><name><surname>Togoli</surname> <given-names>I</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016c</year><article-title>A shared numerical representation for action and perception</article-title><source>eLife</source><volume>5</volume><elocation-id>e16161</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16161</pub-id><pub-id pub-id-type="pmid">27504969</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Arrighi</surname> <given-names>R</given-names></name><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Grassi</surname> <given-names>E</given-names></name><name><surname>Pedonese</surname> <given-names>L</given-names></name><name><surname>Moscoso</surname> <given-names>PAM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatial but not temporal numerosity thresholds correlate with formal math skills in children</article-title><source>Developmental Psychology</source><volume>54</volume><fpage>458</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1037/dev0000448</pub-id><pub-id pub-id-type="pmid">29239633</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arsalidou</surname> <given-names>M</given-names></name><name><surname>Taylor</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Is 2+2=4? Meta-analyses of brain areas needed for numbers and calculations</article-title><source>NeuroImage</source><volume>54</volume><fpage>2382</fpage><lpage>2393</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.009</pub-id><pub-id pub-id-type="pmid">20946958</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borghesani</surname> <given-names>V</given-names></name><name><surname>de Hevia</surname> <given-names>MD</given-names></name><name><surname>Viarouge</surname> <given-names>A</given-names></name><name><surname>Pinheiro-Chagas</surname> <given-names>P</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name><name><surname>Piazza</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Processing number and length in the parietal cortex: sharing resources, not a common code</article-title><source>Cortex</source><volume>114</volume><fpage>17</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.07.017</pub-id><pub-id pub-id-type="pmid">30219571</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bugden</surname> <given-names>S</given-names></name><name><surname>Ansari</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Probing the nature of deficits in the 'Approximate Number System' in children with persistent Developmental Dyscalculia</article-title><source>Developmental Science</source><volume>19</volume><fpage>817</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1111/desc.12324</pub-id><pub-id pub-id-type="pmid">26227387</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulthé</surname> <given-names>J</given-names></name><name><surname>De Smedt</surname> <given-names>B</given-names></name><name><surname>Op de Beeck</surname> <given-names>HP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Format-dependent representations of symbolic and non-symbolic numbers in the human cortex as revealed by multi-voxel pattern analyses</article-title><source>NeuroImage</source><volume>87</volume><fpage>311</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.049</pub-id><pub-id pub-id-type="pmid">24201011</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulthé</surname> <given-names>J</given-names></name><name><surname>De Smedt</surname> <given-names>B</given-names></name><name><surname>Op de Beeck</surname> <given-names>HP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visual number beats abstract numerical magnitude: format-dependent representation of arabic digits and dot patterns in human parietal cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>1376</fpage><lpage>1387</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00787</pub-id><pub-id pub-id-type="pmid">25633646</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burr</surname> <given-names>D</given-names></name><name><surname>Ross</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A Visual Sense of Number</article-title><source>Current Biology</source><volume>18</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.02.052</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cant</surname> <given-names>JS</given-names></name><name><surname>Xu</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Object Ensemble Processing in Human Anterior-Medial Ventral Visual Cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>7685</fpage><lpage>7700</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3325-11.2012</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantlon</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Math, monkeys, and the developing brain</article-title><source>PNAS</source><volume>109</volume><fpage>10725</fpage><lpage>10732</lpage><pub-id pub-id-type="doi">10.1073/pnas.1201893109</pub-id><pub-id pub-id-type="pmid">22723349</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visual attention: The past 25 years</article-title><source>Vision Research</source><volume>51</volume><fpage>1484</fpage><lpage>1525</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.04.012</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Aagten-Murphy</surname> <given-names>D</given-names></name><name><surname>Tosetti</surname> <given-names>M</given-names></name><name><surname>Burr</surname> <given-names>D</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effects of adaptation on numerosity decoding in the human brain</article-title><source>NeuroImage</source><volume>143</volume><fpage>364</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.09.020</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Mirassou</surname> <given-names>A</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Asymmetrical interference between number and item size perception provides evidence for a domain specific impairment in dyscalculia</article-title><source>PLOS ONE</source><volume>13</volume><elocation-id>e0209256</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0209256</pub-id><pub-id pub-id-type="pmid">30550549</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Vignaud</surname> <given-names>A</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mapping numerical perception and operations in relationto functional and anatomical landmarks of humanparietal cortex </article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/602599</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavdaroglu</surname> <given-names>S</given-names></name><name><surname>Katz</surname> <given-names>C</given-names></name><name><surname>Knops</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dissociating estimation from comparison and response eliminates parietal involvement in sequential numerosity perception</article-title><source>NeuroImage</source><volume>116</volume><fpage>135</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.04.019</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavdaroglu</surname> <given-names>S</given-names></name><name><surname>Knops</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evidence for a posterior parietal cortex contribution to spatial but not temporal numerosity perception</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>2965</fpage><lpage>2977</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy163</pub-id><pub-id pub-id-type="pmid">30060143</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavina-Pratesi</surname> <given-names>C</given-names></name><name><surname>Kentridge</surname> <given-names>RW</given-names></name><name><surname>Heywood</surname> <given-names>CA</given-names></name><name><surname>Milner</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Separate channels for processing form, texture, and color: evidence from FMRI adaptation and visual object Agnosia</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>2319</fpage><lpage>2332</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp298</pub-id><pub-id pub-id-type="pmid">20100900</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Q</given-names></name><name><surname>Li</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Association between individual differences in non-symbolic number acuity and math performance: a meta-analysis</article-title><source>Acta Psychologica</source><volume>148</volume><fpage>163</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2014.01.016</pub-id><pub-id pub-id-type="pmid">24583622</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Anobile</surname> <given-names>G</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spontaneous perception of numerosity in humans</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12536</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12536</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dakin</surname> <given-names>SC</given-names></name><name><surname>Tibber</surname> <given-names>MS</given-names></name><name><surname>Greenwood</surname> <given-names>JA</given-names></name><name><surname>Kingdom</surname> <given-names>FAA</given-names></name><name><surname>Morgan</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common visual metric for approximate number and density</article-title><source>PNAS</source><volume>108</volume><fpage>19552</fpage><lpage>19557</lpage><pub-id pub-id-type="doi">10.1073/pnas.1113195108</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Hayden</surname> <given-names>BY</given-names></name><name><surname>Mazer</surname> <given-names>JA</given-names></name><name><surname>Gallant</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Attention to stimulus features shifts spectral tuning of V4 neurons during natural vision</article-title><source>Neuron</source><volume>59</volume><fpage>509</fpage><lpage>521</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.07.001</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Hevia</surname> <given-names>MD</given-names></name><name><surname>Castaldi</surname> <given-names>E</given-names></name><name><surname>Streri</surname> <given-names>A</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name><name><surname>Izard</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Perceiving numerosity from birth</article-title><source>Behavioral and Brain Sciences</source><volume>40</volume><fpage>21</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1017/S0140525X16002090</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Smedt</surname> <given-names>B</given-names></name><name><surname>Noël</surname> <given-names>M-P</given-names></name><name><surname>Gilmore</surname> <given-names>C</given-names></name><name><surname>Ansari</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How do symbolic and non-symbolic numerical magnitude processing skills relate to individual differences in children's mathematical skills? A review of evidence from brain and behavior</article-title><source>Trends in Neuroscience and Education</source><volume>2</volume><fpage>48</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.tine.2013.06.001</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>The Number Sense: How the Mind Creates Mathematics</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Changeux</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Development of elementary numerical abilities: a neuronal model</article-title><source>Journal of Cognitive Neuroscience</source><volume>5</volume><fpage>390</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1162/jocn.1993.5.4.390</pub-id><pub-id pub-id-type="pmid">23964915</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destrieux</surname> <given-names>C</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Dale</surname> <given-names>A</given-names></name><name><surname>Halgren</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature</article-title><source>NeuroImage</source><volume>53</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.010</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWind</surname> <given-names>NK</given-names></name><name><surname>Adams</surname> <given-names>GK</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Modeling the approximate number system to quantify the contribution of visual stimulus features</article-title><source>Cognition</source><volume>142</volume><fpage>247</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2015.05.016</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWind</surname> <given-names>NK</given-names></name><name><surname>Park</surname> <given-names>J</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Numerical encoding in early visual cortex</article-title><source>Cortex</source><volume>114</volume><fpage>76</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.03.027</pub-id><pub-id pub-id-type="pmid">29983159</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dormal</surname> <given-names>V</given-names></name><name><surname>Pesenti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Common and specific contributions of the intraparietal sulci to numerosity and length processing</article-title><source>Human Brain Mapping</source><volume>30</volume><fpage>2466</fpage><lpage>2476</lpage><pub-id pub-id-type="doi">10.1002/hbm.20677</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eger</surname> <given-names>E</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Amadon</surname> <given-names>A</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Deciphering cortical number coding from human brain activity patterns</article-title><source>Current Biology</source><volume>19</volume><fpage>1608</fpage><lpage>1615</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.08.047</pub-id><pub-id pub-id-type="pmid">19781939</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eger</surname> <given-names>E</given-names></name><name><surname>Pinel</surname> <given-names>P</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatially invariant coding of numerical information in functionally defined subregions of human parietal cortex</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>1319</fpage><lpage>1329</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht323</pub-id><pub-id pub-id-type="pmid">24293562</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Neuronal foundations of human numerical representations</chapter-title><source>Progress in Brain Research</source><publisher-name>Elsevier</publisher-name><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/bs.pbr.2016.04.015</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname> <given-names>EF</given-names></name><name><surname>Sutterer</surname> <given-names>DW</given-names></name><name><surname>Serences</surname> <given-names>JT</given-names></name><name><surname>Awh</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Feature-Selective Attentional Modulations in Human Frontoparietal Cortex</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>8188</fpage><lpage>8199</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3935-15.2016</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fias</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Neurocognitive Components of Mathematical Skills and Dyscalculia</chapter-title><source>Development of Mathematical Cognition</source><publisher-name>Elsevier</publisher-name><fpage>195</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-801871-2.00008-3</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Automatically Parcellating the Human Cerebral Cortex</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>11</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhg087</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname> <given-names>M</given-names></name><name><surname>Cicchini</surname> <given-names>GM</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptation to number operates on perceived rather than physical numerosity</article-title><source>Cognition</source><volume>151</volume><fpage>63</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.03.006</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname> <given-names>M</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name><name><surname>Park</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Numerosity processing in early visual cortex</article-title><source>NeuroImage</source><volume>157</volume><fpage>429</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.05.069</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname> <given-names>M</given-names></name><name><surname>Park</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct neural signatures for very small and very large numerosities</article-title><source>Frontiers in Human Neuroscience</source><volume>11</volume><pub-id pub-id-type="doi">10.3389/fnhum.2017.00021</pub-id><pub-id pub-id-type="pmid">28197086</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname> <given-names>M</given-names></name><name><surname>Park</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Early numerosity encoding in visual cortex is not sufficient for the representation of numerical magnitude</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>1788</fpage><lpage>1802</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01320</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Assad</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Distinct encoding of spatial and nonspatial visual information in parietal cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>5671</fpage><lpage>5680</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-08.2009</pub-id><pub-id pub-id-type="pmid">19403833</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gebuis</surname> <given-names>T</given-names></name><name><surname>Gevers</surname> <given-names>W</given-names></name><name><surname>Cohen Kadosh</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topographic representation of high-level cognition: numerosity or sensory processing?</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>1</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.10.002</pub-id><pub-id pub-id-type="pmid">24129333</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gebuis</surname> <given-names>T</given-names></name><name><surname>Reynvoet</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The interplay between nonsymbolic number and its continuous visual properties</article-title><source>Journal of Experimental Psychology: General</source><volume>141</volume><fpage>642</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1037/a0026218</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottlieb</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>From thought to action: the parietal cortex as a bridge between perception, action, and cognition</article-title><source>Neuron</source><volume>53</volume><fpage>9</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.12.009</pub-id><pub-id pub-id-type="pmid">17196526</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halberda</surname> <given-names>J</given-names></name><name><surname>Mazzocco</surname> <given-names>MM</given-names></name><name><surname>Feigenson</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Individual differences in non-verbal number acuity correlate with maths achievement</article-title><source>Nature</source><volume>455</volume><fpage>665</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1038/nature07246</pub-id><pub-id pub-id-type="pmid">18776888</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halberda</surname> <given-names>J</given-names></name><name><surname>Feigenson</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Developmental change in the acuity of the &quot;Number Sense&quot;: The Approximate Number System in 3-, 4-, 5-, and 6-year-olds and adults</article-title><source>Developmental Psychology</source><volume>44</volume><fpage>1457</fpage><lpage>1465</lpage><pub-id pub-id-type="doi">10.1037/a0012682</pub-id><pub-id pub-id-type="pmid">18793076</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>BM</given-names></name><name><surname>Klein</surname> <given-names>BP</given-names></name><name><surname>Petridou</surname> <given-names>N</given-names></name><name><surname>Dumoulin</surname> <given-names>SO</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Topographic representation of numerosity in the human parietal cortex</article-title><source>Science</source><volume>341</volume><fpage>1123</fpage><lpage>1126</lpage><pub-id pub-id-type="doi">10.1126/science.1239052</pub-id><pub-id pub-id-type="pmid">24009396</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>BM</given-names></name><name><surname>Fracasso</surname> <given-names>A</given-names></name><name><surname>Petridou</surname> <given-names>N</given-names></name><name><surname>Dumoulin</surname> <given-names>SO</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topographic representations of object size and relationships with numerosity reveal generalized quantity processing in human parietal cortex</article-title><source>PNAS</source><volume>112</volume><fpage>13525</fpage><lpage>13530</lpage><pub-id pub-id-type="doi">10.1073/pnas.1515414112</pub-id><pub-id pub-id-type="pmid">26483452</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>BM</given-names></name><name><surname>Ferri</surname> <given-names>S</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Comparing Parietal Quantity-Processing Mechanisms between Humans and Macaques</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>779</fpage><lpage>793</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.07.002</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>BM</given-names></name><name><surname>Dumoulin</surname> <given-names>SO</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>A network of topographic numerosity maps in human association cortex</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/s41562-016-0036</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>BM</given-names></name><name><surname>Dumoulin</surname> <given-names>SO</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Can responses to basic non-numerical visual features explain neural numerosity responses?</article-title><source>NeuroImage</source><volume>149</volume><fpage>200</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.012</pub-id><pub-id pub-id-type="pmid">28185950</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyde</surname> <given-names>DC</given-names></name><name><surname>Spelke</surname> <given-names>ES</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neural signatures of number processing in human infants: evidence for two core systems underlying numerical cognition</article-title><source>Developmental Science</source><volume>14</volume><fpage>360</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2010.00987.x</pub-id><pub-id pub-id-type="pmid">21399717</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ibos</surname> <given-names>G</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamic integration of task-relevant visual features in posterior parietal cortex</article-title><source>Neuron</source><volume>83</volume><fpage>1468</fpage><lpage>1480</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.020</pub-id><pub-id pub-id-type="pmid">25199703</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Im</surname> <given-names>HY</given-names></name><name><surname>Halberda</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The effects of sampling and internal noise on the representation of ensemble average size</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>75</volume><fpage>278</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.3758/s13414-012-0399-4</pub-id><pub-id pub-id-type="pmid">23188732</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname> <given-names>L</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Computational modelling of visual attention</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>194</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1038/35058500</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Iuculano</surname> <given-names>T</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>Development of Mathematical Reasoning</chapter-title><source>Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience</source><publisher-name>John Wiley &amp; Sons</publisher-name><fpage>183</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1002/9781119170174.epcn406</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izard</surname> <given-names>V</given-names></name><name><surname>Dehaene-Lambertz</surname> <given-names>G</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Distinct cerebral pathways for object identity and number in human infants</article-title><source>PLOS Biology</source><volume>6</volume><elocation-id>e11</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0060011</pub-id><pub-id pub-id-type="pmid">18254657</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jehee</surname> <given-names>JFM</given-names></name><name><surname>Brady</surname> <given-names>DK</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Attention Improves Encoding of Task-Relevant Features in the Human Visual Cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8210</fpage><lpage>8219</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6153-09.2011</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamitani</surname> <given-names>Y</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Decoding the visual and subjective contents of the human brain</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>679</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1038/nn1444</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamitani</surname> <given-names>Y</given-names></name><name><surname>Tong</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Decoding Seen and Attended Motion Directions from Activity in the Human Visual Cortex</article-title><source>Current Biology</source><volume>16</volume><fpage>1096</fpage><lpage>1102</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2006.04.003</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>Q</given-names></name><name><surname>Jeong</surname> <given-names>SK</given-names></name><name><surname>Mruczek</surname> <given-names>REB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A brief comparative review of primate posterior parietal cortex: a novel hypothesis on the human toolmaker</article-title><source>Neuropsychologia</source><volume>105</volume><fpage>123</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2017.01.034</pub-id><pub-id pub-id-type="pmid">28159617</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kourtzi</surname> <given-names>Z</given-names></name><name><surname>Grill-Spector</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>fMRI Adaptation: A Tool for Studying Visual Representations in the Primate Brain</chapter-title><person-group person-group-type="editor"><name><surname>Clifford Colin</surname> <given-names>W. G</given-names></name><name><surname>Gillian</surname> <given-names>R. hodes</given-names></name></person-group><source>Fitting the Mind to the WorldAdaptation and After-Effects in High-Level Vision</source><publisher-name>OUP Oxford Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780198529699.003.0007</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis – connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Kievit</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational geometry: integrating cognition, computation, and the brain</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id><pub-id pub-id-type="pmid">23876494</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lasne</surname> <given-names>G</given-names></name><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Discriminability of numerosity-evoked fMRI activity patterns in human intra-parietal cortex reflects behavioral numerical acuity</article-title><source>Cortex</source><volume>114</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.03.008</pub-id><pub-id pub-id-type="pmid">29655488</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leibovich</surname> <given-names>T</given-names></name><name><surname>Henik</surname> <given-names>A</given-names></name><name><surname>Salti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Numerosity processing is context driven even in the subitizing range: an fMRI study</article-title><source>Neuropsychologia</source><volume>77</volume><fpage>137</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.08.016</pub-id><pub-id pub-id-type="pmid">26297625</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leibovich</surname> <given-names>T</given-names></name><name><surname>Katzin</surname> <given-names>N</given-names></name><name><surname>Harel</surname> <given-names>M</given-names></name><name><surname>Henik</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>From &quot;sense of number&quot; to &quot;sense of magnitude&quot;: The role of continuous magnitudes in numerical cognition</article-title><source>Behavioral and Brain Sciences</source><volume>40</volume><elocation-id>e164</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X16000960</pub-id><pub-id pub-id-type="pmid">27530053</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leibovich</surname> <given-names>T</given-names></name><name><surname>Vogel</surname> <given-names>SE</given-names></name><name><surname>Henik</surname> <given-names>A</given-names></name><name><surname>Ansari</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Asymmetric processing of numerical and nonnumerical magnitudes in the brain: an fMRI study</article-title><source>Journal of Cognitive Neuroscience</source><volume>28</volume><fpage>166</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00887</pub-id><pub-id pub-id-type="pmid">26439268</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libertus</surname> <given-names>ME</given-names></name><name><surname>Feigenson</surname> <given-names>L</given-names></name><name><surname>Halberda</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Preschool acuity of the approximate number system correlates with school math ability: approximate number system and math abilities</article-title><source>Developmental Science</source><volume>14</volume><fpage>1292</fpage><lpage>1300</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2011.01080.x</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libertus</surname> <given-names>ME</given-names></name><name><surname>Feigenson</surname> <given-names>L</given-names></name><name><surname>Halberda</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Is approximate number precision a stable predictor of math ability?</article-title><source>Learning and Individual Differences</source><volume>25</volume><fpage>126</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.lindif.2013.02.001</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>T</given-names></name><name><surname>Hospadaruk</surname> <given-names>L</given-names></name><name><surname>Zhu</surname> <given-names>DC</given-names></name><name><surname>Gardner</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Feature-specific attentional priority signals in human cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>4484</fpage><lpage>4495</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5745-10.2011</pub-id><pub-id pub-id-type="pmid">21430149</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez-Trujillo</surname> <given-names>JC</given-names></name><name><surname>Treue</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Feature-based attention increases the selectivity of population responses in primate visual cortex</article-title><source>Current Biology</source><volume>14</volume><fpage>744</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2004.04.028</pub-id><pub-id pub-id-type="pmid">15120065</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAdams</surname> <given-names>CJ</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Attention to both space and feature modulates neuronal responses in macaque area V4</article-title><source>Journal of Neurophysiology</source><volume>83</volume><fpage>1751</fpage><lpage>1755</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.83.3.1751</pub-id><pub-id pub-id-type="pmid">10712494</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moeller</surname> <given-names>S</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Olman</surname> <given-names>CA</given-names></name><name><surname>Auerbach</surname> <given-names>E</given-names></name><name><surname>Strupp</surname> <given-names>J</given-names></name><name><surname>Harel</surname> <given-names>N</given-names></name><name><surname>Uğurbil</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multiband multislice GE-EPI at 7 tesla, with 16-fold acceleration using partial parallel imaging with application to high spatial and temporal whole-brain fMRI</article-title><source>Magnetic Resonance in Medicine</source><volume>63</volume><fpage>1144</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1002/mrm.22361</pub-id><pub-id pub-id-type="pmid">20432285</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname> <given-names>MJ</given-names></name><name><surname>Raphael</surname> <given-names>S</given-names></name><name><surname>Tibber</surname> <given-names>MS</given-names></name><name><surname>Dakin</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A texture-processing model of the ‘visual sense of number’</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>281</volume><elocation-id>20141137</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2014.1137</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname> <given-names>A</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Representation of the quantity of visual items in the primate prefrontal cortex</article-title><source>Science</source><volume>297</volume><fpage>1708</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1126/science.1072493</pub-id><pub-id pub-id-type="pmid">12215649</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The neuronal code for number</article-title><source>Nature Reviews Neuroscience</source><volume>17</volume><fpage>366</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.40</pub-id><pub-id pub-id-type="pmid">27150407</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname> <given-names>A</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A parieto-frontal network for visual numerical information in the monkey</article-title><source>PNAS</source><volume>101</volume><fpage>7457</fpage><lpage>7462</lpage><pub-id pub-id-type="doi">10.1073/pnas.0402239101</pub-id><pub-id pub-id-type="pmid">15123797</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>Polyn</surname> <given-names>SM</given-names></name><name><surname>Detre</surname> <given-names>GJ</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>424</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.07.005</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nys</surname> <given-names>J</given-names></name><name><surname>Ventura</surname> <given-names>P</given-names></name><name><surname>Fernandes</surname> <given-names>T</given-names></name><name><surname>Querido</surname> <given-names>L</given-names></name><name><surname>Leybaert</surname> <given-names>J</given-names></name><name><surname>Content</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Does math education modify the approximate number system? A comparison of schooled and unschooled adults</article-title><source>Trends in Neuroscience and Education</source><volume>2</volume><fpage>13</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.tine.2013.01.001</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oosterhof</surname> <given-names>NN</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>CoSMoMVPA: multi-modal multivariate pattern analysis of neuroimaging data in matlab/GNU octave</article-title><source>Frontiers in Neuroinformatics</source><volume>10</volume><pub-id pub-id-type="doi">10.3389/fninf.2016.00027</pub-id><pub-id pub-id-type="pmid">27499741</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname> <given-names>J</given-names></name><name><surname>DeWind</surname> <given-names>NK</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rapid and direct encoding of numerosity in the visual stream</article-title><source>Cerebral Cortex</source><volume>2</volume><elocation-id>bhv017</elocation-id><pub-id pub-id-type="doi">10.1093/cercor/bhv017</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Blondel</surname> <given-names>M</given-names></name><name><surname>Prettenhofer</surname> <given-names>P</given-names></name><name><surname>Weiss</surname> <given-names>R</given-names></name><name><surname>Dubourg</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2011">2011</year><data-title>Scikit-learn: Machine Learning in Python</data-title><version designator="7">7</version></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Izard</surname> <given-names>V</given-names></name><name><surname>Pinel</surname> <given-names>P</given-names></name><name><surname>Le Bihan</surname> <given-names>D</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Tuning curves for approximate numerosity in the human intraparietal sulcus</article-title><source>Neuron</source><volume>44</volume><fpage>547</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.10.014</pub-id><pub-id pub-id-type="pmid">15504333</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neurocognitive start-up tools for symbolic number representations</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>542</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.09.008</pub-id><pub-id pub-id-type="pmid">21055996</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Facoetti</surname> <given-names>A</given-names></name><name><surname>Trussardi</surname> <given-names>AN</given-names></name><name><surname>Berteletti</surname> <given-names>I</given-names></name><name><surname>Conte</surname> <given-names>S</given-names></name><name><surname>Lucangeli</surname> <given-names>D</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Zorzi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Developmental trajectory of number acuity reveals a severe impairment in developmental dyscalculia</article-title><source>Cognition</source><volume>116</volume><fpage>33</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2010.03.012</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Pica</surname> <given-names>P</given-names></name><name><surname>Izard</surname> <given-names>V</given-names></name><name><surname>Spelke</surname> <given-names>ES</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Education Enhances the Acuity of the Nonverbal Approximate Number System</article-title><source>Psychological Science</source><volume>24</volume><fpage>1037</fpage><lpage>1043</lpage><pub-id pub-id-type="doi">10.1177/0956797612464057</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>De Feo</surname> <given-names>V</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning to focus on number</article-title><source>Cognition</source><volume>181</volume><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2018.07.011</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Eger</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural foundations and functional specificity of number representations</article-title><source>Neuropsychologia</source><volume>83</volume><fpage>257</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.09.025</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinel</surname> <given-names>P</given-names></name><name><surname>Piazza</surname> <given-names>M</given-names></name><name><surname>Le Bihan</surname> <given-names>D</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Distributed and overlapping cerebral representations of number, size, and luminance during comparative judgments</article-title><source>Neuron</source><volume>41</volume><fpage>983</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(04)00107-2</pub-id><pub-id pub-id-type="pmid">15046729</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Pasternak</surname> <given-names>T</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Attention increases sensitivity of V4 neurons</article-title><source>Neuron</source><volume>26</volume><fpage>703</fpage><lpage>714</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)81206-4</pub-id><pub-id pub-id-type="pmid">10896165</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname> <given-names>JD</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Monotonic coding of numerosity in macaque lateral intraparietal area</article-title><source>PLOS Biology</source><volume>5</volume><fpage>1672</fpage><lpage>1682</lpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0050208</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Vision senses number directly</article-title><source>Journal of Vision</source><volume>10</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1167/10.2.10</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sapountzis</surname> <given-names>P</given-names></name><name><surname>Paneri</surname> <given-names>S</given-names></name><name><surname>Gregoriou</surname> <given-names>GG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distinct roles of prefrontal and parietal areas in the encoding of attentional priority</article-title><source>PNAS</source><volume>115</volume><fpage>E8755</fpage><lpage>E8764</lpage><pub-id pub-id-type="doi">10.1073/pnas.1804643115</pub-id><pub-id pub-id-type="pmid">30154164</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütt</surname> <given-names>HH</given-names></name><name><surname>Harmeling</surname> <given-names>S</given-names></name><name><surname>Macke</surname> <given-names>JH</given-names></name><name><surname>Wichmann</surname> <given-names>FA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Painfree and accurate bayesian estimation of psychometric functions for (potentially) overdispersed data</article-title><source>Vision Research</source><volume>122</volume><fpage>105</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2016.02.002</pub-id><pub-id pub-id-type="pmid">27013261</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serences</surname> <given-names>JT</given-names></name><name><surname>Boynton</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Feature-based attentional modulations in the absence of direct visual stimulation</article-title><source>Neuron</source><volume>55</volume><fpage>301</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.06.015</pub-id><pub-id pub-id-type="pmid">17640530</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokolowski</surname> <given-names>HM</given-names></name><name><surname>Fias</surname> <given-names>W</given-names></name><name><surname>Bosah Ononye</surname> <given-names>C</given-names></name><name><surname>Ansari</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Are numbers grounded in a general magnitude processing system? A functional neuroimaging meta-analysis</article-title><source>Neuropsychologia</source><volume>105</volume><fpage>50</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2017.01.019</pub-id><pub-id pub-id-type="pmid">28119003</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starr</surname> <given-names>A</given-names></name><name><surname>DeWind</surname> <given-names>NK</given-names></name><name><surname>Brannon</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The contributions of numerical acuity and non-numerical stimulus features to the development of the number sense and symbolic math achievement</article-title><source>Cognition</source><volume>168</volume><fpage>222</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2017.07.004</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoianov</surname> <given-names>I</given-names></name><name><surname>Zorzi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emergence of a 'visual number sense' in hierarchical generative models</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>194</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1038/nn.2996</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szucs</surname> <given-names>D</given-names></name><name><surname>Devine</surname> <given-names>A</given-names></name><name><surname>Soltesz</surname> <given-names>F</given-names></name><name><surname>Nobes</surname> <given-names>A</given-names></name><name><surname>Gabriel</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Developmental dyscalculia is related to visuo-spatial memory and inhibition impairment</article-title><source>Cortex</source><volume>49</volume><fpage>2674</fpage><lpage>2688</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2013.06.007</pub-id><pub-id pub-id-type="pmid">23890692</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname> <given-names>KG</given-names></name><name><surname>Bichot</surname> <given-names>NP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A visual salience map in the primate frontal eye field</article-title><source>Progress in Brain Research</source><volume>147</volume><fpage>251</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(04)47019-8</pub-id><pub-id pub-id-type="pmid">15581711</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname> <given-names>F</given-names></name><name><surname>Pratte</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decoding patterns of human brain activity</article-title><source>Annual Review of Psychology</source><volume>63</volume><fpage>483</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-120710-100412</pub-id><pub-id pub-id-type="pmid">21943172</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toth</surname> <given-names>LJ</given-names></name><name><surname>Assad</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dynamic coding of behaviourally relevant stimuli in parietal cortex</article-title><source>Nature</source><volume>415</volume><fpage>165</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1038/415165a</pub-id><pub-id pub-id-type="pmid">11805833</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treue</surname> <given-names>S</given-names></name><name><surname>Martínez Trujillo</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Feature-based attention influences motion processing gain in macaque visual cortex</article-title><source>Nature</source><volume>399</volume><fpage>575</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1038/21176</pub-id><pub-id pub-id-type="pmid">10376597</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verguts</surname> <given-names>T</given-names></name><name><surname>Fias</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Representation of number in animals and humans: a neural model</article-title><source>Journal of Cognitive Neuroscience</source><volume>16</volume><fpage>1493</fpage><lpage>1504</lpage><pub-id pub-id-type="doi">10.1162/0898929042568497</pub-id><pub-id pub-id-type="pmid">15601514</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname> <given-names>P</given-names></name><name><surname>Nieder</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Differential impact of behavioral relevance on quantity coding in primate frontal and parietal neurons</article-title><source>Current Biology</source><volume>25</volume><fpage>1259</fpage><lpage>1269</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.03.025</pub-id><pub-id pub-id-type="pmid">25913409</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wald</surname> <given-names>LL</given-names></name><name><surname>Wiggins</surname> <given-names>GC</given-names></name><name><surname>Potthast</surname> <given-names>A</given-names></name><name><surname>Wiggins</surname> <given-names>CJ</given-names></name><name><surname>Triantafyllou</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Design considerations and coil comparisons for 7 tesla brain imaging</article-title><source>Proc. Intl. Soc. Mag. Reson. Med</source><volume>13</volume><elocation-id>921</elocation-id><pub-id pub-id-type="doi">10.1007/BF03166954</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Mruczek</surname> <given-names>RE</given-names></name><name><surname>Arcaro</surname> <given-names>MJ</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Probabilistic maps of visual topography in human cortex</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3911</fpage><lpage>3931</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id><pub-id pub-id-type="pmid">25452571</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilkey</surname> <given-names>ED</given-names></name><name><surname>Pollack</surname> <given-names>C</given-names></name><name><surname>Price</surname> <given-names>GR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dyscalculia and typical math achievement are associated with individual differences in Number-Specific executive function</article-title><source>Child Development</source><pub-id pub-id-type="doi">10.1111/cdev.13194</pub-id><pub-id pub-id-type="pmid">30597527</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45160.023</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Ansari</surname><given-names>Daniel</given-names></name><role>Reviewing Editor</role><aff><institution>Western University</institution><country>Canada</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Ansari</surname><given-names>Daniel</given-names> </name><role>Reviewer</role><aff><institution>Western University</institution><country>Canada</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Harvey</surname><given-names>Ben</given-names> </name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Daniel Ansari as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Ben Harvey (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This manuscript reports the result of an experiment that addresses how numerosity is extracted in the brain and examines whether and at what level such numerosity extraction is independent of other visual variables that co-vary with numerosity (e.g. overall area). Participants' attention was either directed to the numerosity of a dot array or average item size. The results reveal that there is increasing sensitivity to numerosity the further away one moves from primary visual cortex and numerosity sensitivity is particularly strong in the IPS.</p><p>The reviewers all agreed that this is a well-written manuscript describing an elegantly designed experiment with sophisticated data acquisition and analysis methods.</p><p>Essential revisions:</p><p>1).Against the background of the data, is the conclusion that the findings &quot;reveal a dedicated extraction mechanism for numerosity that operates independently of other quantitative dimensions of the stimuli&quot; justified? The reviewers wondered whether such a strong statement is warranted against the background of the evidence presented. More specifically, just because numerosity can be decoded in higher-level regions when it is being attended to and explains unique variance this does not exclude the possibility that whatever representation is being activated there is the product of the integration of the non-numerical variables. It may just be a more abstract representation that emerged over the course of development or that such a representation is actively being constructed given the attentional focus and task demand. You need to explain in more detail how they can reject the alternative account and instead conclude that there is a 'dedicated' mechanism for numerosity processing. The fact that numerosity explains unique variance in the multiple regression analyses does not mean that it is not an emergent property?</p><p>2) Related point 1, you state that: &quot;The fact that such specifically numerical information is found from early stages of the cortical hierarchy on, and that attentional modulation does not affect associated non-numerical quantities makes it unlikely that numerical judgements would only be made indirectly on the basis of different non-numerical features. &quot; – yes it makes it unlikely but this explanation cannot be fully excluded on the basis of the data, especially because not all possible non-numerical dimensions that have been shown to influence numerosity processing were excluded and because the classification accuracies of numerosity were not high (and non-significant) in the early stages of the cortical hierarchy.</p><p>3) Other fMRI studies (at least two) have compared neural activation of non-symbolic dot stimuli with the instruction to either respond based on size or based on numerosity but are omitted from the background literature. How do you reconcile the current null results when contrasting activity related to the two tasks with previous results showing task-related differences?</p><p>Leibovich, Henik and Salti, 2015; Leibovich et al., 2016.</p><p>4) The stimuli description emphasizes the orthogonality of stimulus visual parameters and the &quot;partial decorrelation&quot; of numerosity and density. However, based on a rough calculation of stimulus characteristics from Figure 1A, total surface area and numerosity can be estimated to correlate at about r = 0.66, which can be considered a strong correlation. These numbers was calculated by multiplying the number of dots by the average item area and then computing a bivariate correlation between the list of stimulus numerosities and total surface areas.</p><p>The strength of this correlation is difficult to tell from the example RDM's presented in Figure 4, but remains quite strong. Rather than de-emphasize this potential confound as a &quot;partial decorrelation&quot; and a &quot;good dissociation&quot;, the authors should indicate that total surface area and numerosity remain highly correlated despite orthogonality along other stimulus parameters. This is a very serious caveat to all analyses and results in the current study and should be emphasized accordingly. The same may be true of density. Similar calculations should be run and included. Further, these correlations may be affecting the results of the multiple regression, as highly correlated predictors often do. It may be appropriate to calculate variance inflation factors if the correlations are high enough. Further, this issue of independent contributions to variance in the multiple regression model may be explored through removing and adding back in variables that may be correlated. For example, does total surface area or item size show a different pattern of results when number is removed from the model?</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Joshua Gold as the Senior Editor, a Reviewing Editor, and two reviewers.</p><p>As will see from their comments below, both reviewers feel that your manuscript has been substantially improved and feel that it is not ready to be accepted for publication. Before doing so, I would ask you to address the remaining comments by reviewer 3 (see below):</p><p><italic>Reviewer #2:</italic> </p><p>The authors have addressed all of my concerns.</p><p><italic>Reviewer #3:</italic> </p><p>The authors have addressed my concerns in their responses and additional analyses. I have two suggestions that do not need further review in order for the manuscript to be considered acceptable for publication.</p><p>First, it would be helpful if all supplementary files were converted to a standard, non-proprietary format. This is most important for beta-weight matrices or any files that a general reader may want to read. These could easily be saved as a.csv file. That said, it seems reasonable that stimulus design files or complex files like 3-dimensional matrices necessary for a replication could remain as. mat files.</p><p>Second, I find the schematic for the &quot;Neural RDM&quot; very helpful (the one with acronyms for each row and column). I would suggest adding it to the figure in the main paper along with a caption that denotes those abbreviations. It will clear up considerable confusion for the reader.</p><p>Overall, this is an excellent study. Well done.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.45160.024</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Against the background of the data, is the conclusion that the findings &quot;reveal a dedicated extraction mechanism for numerosity that operates independently of other quantitative dimensions of the stimuli&quot; justified? The reviewers wondered whether such a strong statement is warranted against the background of the evidence presented. More specifically, just because numerosity can be decoded in higher-level regions when it is being attended to and explains unique variance this does not exclude the possibility that whatever representation is being activated there is the product of the integration of the non-numerical variables. It may just be a more abstract representation that emerged over the course of development or that such a representation is actively being constructed given the attentional focus and task demand. You need to explain in more detail how they can reject the alternative account and instead conclude that there is a 'dedicated' mechanism for numerosity processing. The fact that numerosity explains unique variance in the multiple regression analyses does not mean that it is not an emergent property?</p></disp-quote><p>We have the impression that one important result of our study was not properly received, and we apologize if it was not clearly presented. We would like to stress the fact that the numerical information is present in our data already at early levels (as indicated by both the significant decoding accuracy and RSA beta values for number starting already from early visual cortex on, see Supplementary file 1 and 2 for significance values in individual areas), and this information remained significant also when attention was directed away from the numerical dimension. In other words, the numerical information is contained in the pattern of activity already in the early visual areas, and not only in higher level regions.</p><p>It is not entirely clear to us what the reviewers exactly refer to by a ‘product of integration’ and how and at what level in the brain this could be assumed to happen (e.g., at sensory extraction or decision stages). The fact that information related to number and the other properties becomes available in parallel at early levels seems to suggest to us that numerical information can be derived from very basic visual features during sensory processing, without the need to first construct explicit precepts of density and field area for example, based on which number would only be inferred indirectly.</p><p>We certainly agree with the reviewers that the capacity to selectively focus on the numerical information and to enhance it already at early levels as we show here, could be learned and/or may have emerged over development. We have now added a paragraph mentioning that the ability to focus on number may be learned/emerge over development in the Discussion (tenth paragraph). We now also avoid using the formulation ‘a dedicated extraction mechanism for numerosity’ throughout the manuscript, to not give the impression that we have evidence for an innate mechanism subserved by ‘dedicated’ neurons in the sense that they would be exclusively concerned with processing number and nothing else. Instead we replaced such formulation with’ a sensory extraction mechanism yielding information on numerosity separable from other dimensions’ or with similar expressions, such as ‘a neuronal mechanism directly sensitive to the numerosity of visual sets’ or ‘a sensory processing mechanism capable of disentangling signals related to visual numerosity from the ones related to associated non-numerical quantities’.</p><disp-quote content-type="editor-comment"><p>2) Related point 1, you state that: &quot;The fact that such specifically numerical information is found from early stages of the cortical hierarchy on, and that attentional modulation does not affect associated non-numerical quantities makes it unlikely that numerical judgements would only be made indirectly on the basis of different non-numerical features. &quot; – yes it makes it unlikely but this explanation cannot be fully excluded on the basis of the data, especially because not all possible non-numerical dimensions that have been shown to influence numerosity processing were excluded and because the classification accuracies of numerosity were not high (and non-significant) in the early stages of the cortical hierarchy.</p></disp-quote><p>As mentioned in point 1, we would like to point out that the classification accuracies (as well as results for number in the multiple regression RSA) were statistically significant already at the early stages of the cortical hierarchy, as detailed in the text and in Supplementary file 1.</p><p>In the revised version of the manuscript, we have replaced the formulation cited above by:</p><p>‘Given that numerical information becomes available in parallel with the other features and independently selectable by attention from early processing stages on, it appears that the human visual system has the capacity to detect signals related to numerosity and separate these from other quantitative dimensions, starting from very basic visual primitives. […] We acknowledge the fact that we cannot formally rule out that a feature of a different type than those considered by us may have contributed to the effects observed here, and our conclusions hold to the extent of the nonnumerical features tested.’</p><disp-quote content-type="editor-comment"><p>3) Other fMRI studies (at least two) have compared neural activation of non-symbolic dot stimuli with the instruction to either respond based on size or based on numerosity but are omitted from the background literature. How do you reconcile the current null results when contrasting activity related to the two tasks with previous results showing task-related differences?</p><p>Leibovich, Henik, and Salti, 2015; Leibovich et al., 2016.</p></disp-quote><p>We thank the reviewers for pointing out these two studies that are now mentioned in a dedicated paragraph in the Discussion (second and third paragraphs). We believe that these two studies differ in several methodological aspects which might have at least in part contributed to the different results obtained. First, differently from Leibovich et al., 2015, 2016b, we asked participants to compare the average item size, rather than the total surface area of the dot arrays. Moreover, we matched task difficulty for comparing item size with the one for comparing numerosity. We have noticed that task difficulty was not successfully matched in the Leibovich et al. studies, which reported differences in accuracy and reaction times across tasks. Differences in task difficulty might have led to unequal cognitive load which might have been detected by the univariate contrast between tasks. Finally, we noticed that Leibovich et al. required participants to perform an explicit comparison one very trial, therefore adding a decisional component to the brain response which is instead not present in our analyses (where the comparison was done only during the occasional match trials which were not included in the contrast reported).</p><disp-quote content-type="editor-comment"><p>4) The stimuli description emphasizes the orthogonality of stimulus visual parameters and the &quot;partial decorrelation&quot; of numerosity and density. However, based on a rough calculation of stimulus characteristics from Figure 1A, total surface area and numerosity can be estimated to correlate at about r = 0.66, which can be considered a strong correlation. These numbers was calculated by multiplying the number of dots by the average item area and then computing a bivariate correlation between the list of stimulus numerosities and total surface areas.</p><p>The strength of this correlation is difficult to tell from the example RDM's presented in Figure 4, but remains quite strong. Rather than de-emphasize this potential confound as a &quot;partial decorrelation&quot; and a &quot;good dissociation&quot;, the authors should indicate that total surface area and numerosity remain highly correlated despite orthogonality along other stimulus parameters. This is a very serious caveat to all analyses and results in the current study and should be emphasized accordingly. The same may be true of density. Similar calculations should be run and included. Further, these correlations may be affecting the results of the multiple regression, as highly correlated predictors often do. It may be appropriate to calculate variance inflation factors if the correlations are high enough. Further, this issue of independent contributions to variance in the multiple regression model may be explored through removing and adding back in variables that may be correlated. For example, does total surface area or item size show a different pattern of results when number is removed from the model?</p></disp-quote><p>We have now added a more detailed description of the stimuli characteristics in the Materials and methods section and in addition report the values of correlations between numerical and nonnumerical dimensions across the 18 conditions.</p><p>The aim of the current study was not to create a stimulus set which would control for all the nonnumerical features at the same time (or decorrelate number from all non-numerical dimensions), which is impossible to do. Rather, the approach used here was to include predictors for numerical and multiple non-numerical dimensions into a multiple regression model, thus estimating beta weights for every dimension which reflect the contribution of each given dimension above and beyond what all the other predictors can explain.</p><p>Generally, in the presence of correlations between predictors in a multiple regression, the amount of variance uniquely explained by each predictor is reduced, and betas have a tendency to be less reliably estimated (in the extreme case of complete collinearity they would be completely inestimable). Therefore, correlations between predictors increase the likelihood of non-significant results, since due to the smaller effect size and less reliable estimation, multiple independent replications of the same analysis (such as over subjects) are unlikely to yield a systematic effect. On the contrary, every significant effect of one predictor (as we observe here across subjects) obtained in spite of the correlations is valid and can be thought of as reflecting only the variance that is uniquely explained by that given predictor. For a discussion related to this point, see also for example: <underline>http://imaging.mrccbu.cam.ac.uk/imaging/DesignEfficiency#Correlation_between_regressors</underline>).</p><p>To get an impression of how much less reliably beta weights may have been estimated in our model due to the correlations between predictors, as suggested by the reviewers, we computed variance inflation factors for all predictors, and now report them also in the manuscript for information purposes. The resulting values were: 1.4874 for number, 1.1957 for average item size, 1.2048 for total field area, 1.3238 for total surface areas and 1.4591 for density. All of these point to an only moderately increased variance in the estimation, well below the threshold for what is typically considered excessive collinearity (10 or 5, according to different sources). This is likely the reason why we can still obtain the significant group results reported for the different predictors in our study.</p><p>As requested by the reviewers, we have also explored the effects of removing vs. including specific predictors in our model (Figure 5—figure supplement 1, Supplementary file 5; Figure 5—figure supplement 2, Supplementary file 6). In particular, in a first model we have carried out multiple regression analyses including only the predictors that orthogonally varied with number (i.e. average items size and total field area, see Figure 5—figure supplement 1, Supplementary file 5) and excluding the correlated ones (i.e. total surface area and density). Furthermore, in a second model we have computed the RSA multiple regression including only the non-numerical predictors (both those correlated with and those orthogonal to number, see Figure 5—figure supplement 2, Supplementary file 6).</p><p>We have added a paragraph in the Results section (subsection “Models with reduced number of predictors”) reporting the outcome of these analyses and figures and statistics are reported in the supplementary material (Figure 5—figure supplement 1, Supplementary file 5; Figure 5—figure supplement 2, Supplementary file 6).</p><p>We found that in the model including only the orthogonal dimensions (i.e. number, average item size and total field area), the triple interaction between ROI, task and dimension was significant both for the three large regions: F(2.86,54.43)=4.73, p=0.006 as well as for the individual regions: F(4.52,85.95)=3.34, p=0.01. Overall, early visual betas for number appeared somewhat enhanced in this case compared to the original model including all predictors. On the contrary, when excluding number from the model, but including all non-numerical dimensions (including those that in the full design are partially correlated with number), the triple interaction between ROI, task and dimension was significant neither for the three large regions: (F(4.12,78.24)=1.107, p=0.36) nor for the individual regions (F(5.66,107.50)=0.883, p=0.50). The interaction between task and dimension was significant both for the three large regions (F(3.12,40.42)=3.65, p=0.03) as well as for the individual regions (F(2.07,39.39)=3.32, p=0.04). In this case, the effect appeared to be mainly driven by total surface area and density yielding somewhat higher betas than in the original full model, most pronounced during the number task. The concern with both of these analyses is that it remains ambiguous whether the effects observed for one given predictor are truly driven by that predictor, or potentially attributable to the unmodeled contribution of another stimulus dimension (in the first case, the relatively enhanced effect of number in early visual regions might actually be due to density and TSA which are not included in the model, whereas in the second case, some effects attributed to density and TSA could actually be due to the unmodeled contribution of number.</p><p>Only our initial, most complete model reported in the manuscript is able to resolve this ambiguity, and we believe it is best suited to address our main question, which was to ask whether there is a unique contribution of numerosity to activation patterns above and beyond what can be explained by the ensemble of the non-numerical dimensions.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>As will see from their comments below, both reviewers feel that your manuscript has been substantially improved and feel that it is not ready to be accepted for publication. Before doing so, I would ask you to address the remaining comments by reviewer 3 (see below):</p><p>Reviewer #3:</p><p>The authors have addressed my concerns in their responses and additional analyses. I have two suggestions that do not need further review in order for the manuscript to be considered acceptable for publication.</p><p>First, it would be helpful if all supplementary files were converted to a standard, non-proprietary format. This is most important for beta-weight matrices or any files that a general reader may want to read. These could easily be saved as a.csv file. That said, it seems reasonable that stimulus design files or complex files like 3-dimensional matrices necessary for a replication could remain as. mat files.</p></disp-quote><p>All matrices containing the behavioral performance, decoding accuracies and betaweights, previously provided as. mat files, are now shared in. cvs format</p><disp-quote content-type="editor-comment"><p>Second, I find the schematic for the &quot;Neural RDM&quot; very helpful (the one with acronyms for each row and column). I would suggest adding it to the figure in the main paper along with a caption that denotes those abbreviations. It will clear up considerable confusion for the reader.</p></disp-quote><p>The schematic for the neural RDM with labels has been added to Figure 4 in the main text and the caption has been updated accordingly.</p></body></sub-article></article>