<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">39404</article-id><article-id pub-id-type="doi">10.7554/eLife.39404</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Control of entropy in neural models of environmental state</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-115576"><name><surname>Muller</surname><given-names>Timothy H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5817-4949</contrib-id><email>timothymuller127@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset1"/></contrib><contrib contrib-type="author" id="author-85824"><name><surname>Mars</surname><given-names>Rogier B</given-names></name><email>rogier.mars@ndcn.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-1044"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0048-1177</contrib-id><email>behrens@fmrib.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-103450"><name><surname>O'Reilly</surname><given-names>Jill X</given-names></name><email>jill.oreilly@psy.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/><xref ref-type="other" rid="dataset2"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Wellcome Centre for Integrative Neuroimaging, Centre for Functional Magnetic Resonance Imaging of the Brain</institution><institution>University of Oxford, John Radcliffe Hospital</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Donders Institute for Brain, Cognition and Behaviour</institution><institution>Radboud University</institution><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>The Netherlands</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Wellcome Centre for Human Neuroimaging, Institute of Neurology</institution><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Experimental Psychology</institution><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>28</day><month>02</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e39404</elocation-id><history><date date-type="received" iso-8601-date="2018-06-20"><day>20</day><month>06</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2019-02-06"><day>06</day><month>02</month><year>2019</year></date></history><permissions><copyright-statement>Â© 2019, Muller et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Muller et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-39404-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.39404.001</object-id><p>Humans and animals construct internal models of their environment in order to select appropriate courses of action. The representation of uncertainty about the current state of the environment is a key feature of these models that controls the rate of learning as well as directly affecting choice behaviour. To maintain flexibility, given that uncertainty naturally decreases over time, most theoretical inference models include a dedicated mechanism to drive up model uncertainty. Here we probe the long-standing hypothesis that noradrenaline is involved in determining the uncertainty, or entropy, and thus flexibility, of neural models. Pupil diameter, which indexes neuromodulatory state including noradrenaline release, predicted increases (but not decreases) in entropy in a neural state model encoded in human medial orbitofrontal cortex, as measured using multivariate functional MRI. Activity in anterior cingulate cortex predicted pupil diameter. These results provide evidence for top-down, neuromodulatory control of entropy in neural state models.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neuromodulators</kwd><kwd>neural models</kwd><kwd>flexibility</kwd><kwd>inference</kwd><kwd>learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MR/L019639/1</award-id><principal-award-recipient><name><surname>O'Reilly</surname><given-names>Jill</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>HMR00560.001</award-id><principal-award-recipient><name><surname>Behrens</surname><given-names>Timothy E</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>BRT00020</award-id><principal-award-recipient><name><surname>Muller</surname><given-names>Timothy H</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Evidence for neuromodulatory control of flexibility in human neural models.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Faced with a constant stream of complex sensory data, observers construct internal (mental) models of the underlying state of the world that generated that data. These models allow the observer to understand and make predictions about the environment. The current state of the environment can be thought of as a latent variable in such models, that is a variable that cannot be observed directly but must be inferred from sensory observations. For example a rat in a reversal learning task needs to know the underlying state of the world (which of two levers is more likely to deliver a food reward), but cannot observe the probabilities per se; instead the rat must infer the probabilities through repeated sampling of an observable variable (does the lever pay out on this trial or not?).</p><p>Theoretical accounts of inference (sometimes called learning, as in reinforcement learning) tend to include two distinct processes for updating beliefs over time. The first process is evidence-driven updating of beliefs â after each new piece of evidence (such as a reward) is observed, the model is updated to take into account the new observation. The second process is one that occurs <italic>between</italic> observations, as states of the world <italic>for which no evidence has necessarily been observed</italic> are up-weighted to account for the possibility that the environment <italic>could</italic> change before the next observation. Mathematically this second process is called the transition function as it determines the transition between posterior beliefs on trial t and prior beliefs on trial tÂ +Â 1.</p><p>These two updating processes differ somewhat, both conceptually and algorithmically.Â Conceptually, evidence-driven updating, as the name suggests, is driven by recently observed evidence and usually takes into account how that evidence differs from predictions under a prior belief (e.g., reward prediction error). In contrast, updating under the transition function is driven by higher order features of the environment such as the inferred level of environmental volatility and structural knowledge about which environmental states tend to follow each other (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib22">Meyniel and Dehaene, 2017</xref>).</p><p>Algorithmic examples of evidence-driven updatingÂ would be the value update equation of the Rescorla-Wagner model, or the application of Bayesâ theorem to combine a new observation with a prior belief. In contrast, a simple example of a transition function algorithm is a constant âleakâ that up-weights all possible future states of the environment equally, and down-weights beliefs based on past observations, such that the modelâs beliefs constantly decay towards a state of agnosticism (an example would be the leaky accumulator (<xref ref-type="bibr" rid="bib35">Usher and McClelland, 2001</xref>)). A more complex transition function could determine structured changes in the environment, for example by preferentially predicting that if the environment changes, it changes to a similar state (an example would be the Gaussian transition function on reward probability (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>)).</p><p>Put another way, the overall level and distribution of uncertainty in an internal model is controlled in part by the transition function. When the environment is believed to be changeable (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>), or to have recently changed (<xref ref-type="bibr" rid="bib38">Wilson et al., 2010</xref>), the transition function adjusts beliefs so that there is high uncertainty about the state of the world on trial tÂ +Â 1, even given what was known at trial t. The optimal level of uncertainty is determined by two opposing forces: if relatively little uncertainty is added at each transition the model can utilize a longer history of observations to infer the current state of the world; but if too little uncertainty is added, the model becomes inflexible.</p><p>Previous studies have addressed the question of how the optimal level of uncertainty, and hence the magnitude of the âleakâ or transition function, should be determined by inferring the higher order statistics of the environment such as its volatility or change-point probabilities.Â Furthermore, blood-oxygen-level dependent (BOLD) and pupillometric signals tracking such (optimal) uncertainty have been observedÂ (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib21">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Preuschoff et al., 2011</xref>). AÂ second, open question, however, is how the brain gets from calculating how flexible oneâs beliefs should be, to controlling flexibility and uncertainty within a model that represents the current state of the world.</p><p>In relation to the first question, how the optimal level of uncertainty is calculated, Behrens and colleagues (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>) argued that the learning rate (analogous to the magnitude of the leak) should optimally depend on environmental volatility, and observed that when volatility (hence learning rate) was high, anterior cingulate cortexÂ (ACC) was active. OâReilly and colleagues (<xref ref-type="bibr" rid="bib25">O'Reilly et al., 2013</xref>) showed activity in a similar region when participants were instructed that changes in the environment had occurred. McGuire and colleagues (<xref ref-type="bibr" rid="bib21">McGuire et al., 2014</xref>) found activity in ACC associated with belief uncertainty, another model-based measure that should determine the magnitude of the transition function (in their case, the probability that the model abandons its prior beliefs entirely in favour of a flat prior).</p><p>In relation to the second question, how uncertainty/flexibility is implemented within internal models, there is less evidence, one reason being that it is difficult to measure the uncertainty of an internal neural model directly. An intriguing possibility is that increases in neural model uncertainty are controlled via a neuromodulatory route. In particular noradrenaline has been proposed as a candidate mechanism by which the level of uncertainty in neural models of the world may be controlled (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib5">Bouret and Sara, 2005</xref>; <xref ref-type="bibr" rid="bib12">Iigaya, 2016</xref>; <xref ref-type="bibr" rid="bib20">Martins and Froemke, 2015</xref>; <xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Pulcu and Browning, 2017</xref>; <xref ref-type="bibr" rid="bib40">Yu and Dayan, 2005</xref>),Â andÂ experimental manipulations increasing noradrenaline levels in cortex tend to lead to increased randomness in behavior (<xref ref-type="bibr" rid="bib34">Tervo et al., 2014</xref>). One theoretical proposal, that noradrenaline performs a ânetwork resetâ (<xref ref-type="bibr" rid="bib5">Bouret and Sara, 2005</xref>), is particularly reminiscent of the second, transition-function updating process described above.</p><p>In the current experiment we focussed on the second question above. That is, we attempted to measure the level of uncertainty within a probabilistic world model, and determine signals that predicted changes in the level of this uncertainty. These are key components for any candidate mechanism for the implementation of a transition-function thatÂ increases uncertainty, such as a leak.</p><p>We first established that we could measure uncertainty in a neural representation of a simple task state space using functional MRI. Then we identified predictors of increases in belief uncertainty, in the absence of overt changes in behaviour. In a simple experimental environment (4-arm bandit task), human participants formed a probabilistic model of the state of the environment (which bandit has the high pay-out rate) that could be decoded from the medial orbitofrontal cortex (mOFC). This model represented participantsâ certainty about the state of the environment in that the strength of the representation of the currently selected option, relative to other options, depended on the strength of evidence experienced, as captured by an optimal observer model. As well as measuring a neural model with fMRI, we simultaneously measured pupil dilation â an index of neuromodulatory state, commonly used as a measure of noradrenaline release to cortex. We found changes in pupil dilation predicted changes in uncertainty in the mOFC state model, providing evidence that the mechanism for driving up entropy in cortical models of the environment could be neuromodulatory. In circumstances when model entropy should increase, such as after observations likely to indicate a change in environmental state, activity in the ACC was observed, which in turn explained the strength of the pupil dilation response, suggesting ACC may be involved in regulating these neuromodulatory processes.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To establish a task environment in which participants were constantly making inferences about the current state of the environment, we used a 4-arm bandit task (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>). At any given time, one of four response options had a high (70 or 90%) probability of delivering reward and the other three had a low (20%) probability. The high reward option switched after a variable number of trials (mean 20Â Â±Â SD 5). Participantsâ task was therefore to infer the current state of the environment, i.e. which option was the current high-reward option. Participants were explicitly instructed about the reward structure before beginning the task. Although there were only four options available for selection (denoted by a different colour), there were eight options on the screen at any given time (see MaterialsÂ andÂ methods for details and motivation). The individual trials in this task were presented in rapid succession to maximize design efficiency given that we were interested in a subset of trials.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.002</object-id><label>Figure 1.</label><caption><title>Task and behaviour.</title><p>(<bold>a</bold>) Participants chose freely between four available options on each trial.Â A total of 8 options were used in the experiment but only four were used in each run of the task (indicated by option colours: red circles above the fingers denote the available options, and the dark red circle denotes the selected option). (<bold>b</bold>) Schematic of a probabilistic model of the state of the environment â the weighting of each option represents its probability of being the high reward option. When entropy is low, i.e. participants are certain, the weighting of the selected option is higher than when entropy is high. (<bold>c</bold>) Example behaviour of a participant. Dot markers denote choices (location in y-dimension indicates which option was chosen) â grey circles are rewarded and red dots are unrewarded trials. The grey line indicates the true state of the world (high reward option), which the participant must infer. Note alternating phases of exploration and exploitation â the main analyses presented in the paper refer only to the exploitation phase in which there are no overt changes of action. (<bold>d</bold>) Model entropy for the same run as in (<bold>c</bold>). Note that model entropy is low during exploit periods but increases following a reward omission (red dots are trials with reward omission). Background shading indicates the pay-out rate of the high reward option:Â during low pay-out (70%) exploit periods, indicated in dark grey, entropy tends to remain higher; during high pay-out periods (light grey) entropy reaches a floor during exploitation. (<bold>e</bold>) State space of the model â four horizontal tracks represent the four possible states of the environment; shading indicates the posteriorÂ probability assigned to each state by the model (light colours indicate high probability).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.003</object-id><label>Figure 1âfigure supplement 1.</label><caption><title>Implementation of the task described in the Main Text and Methods.</title><p>Participants controlled a mouse seeking cheese or apples, counterbalanced across participants. Participants could select any of four available locations, denoted in this case by blue circles, again counterbalanced across participants. Please see the Main Text and Methods for details of the task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.004</object-id><label>Figure 1âfigure supplement 2.</label><caption><title>Exploitation and exploration engage different brain regions.</title><p>T-statistic map for the [1 -1] contrast in GLM1. Positive activation (hotter colours) denotes regions more active during exploitation than exploration, and vice versa for negative activation. Medial OFC and hippocampus were more active during exploitation, and a frontal-parietal action network was more active during exploration. Image thresholded at p&lt;0.001; corrected for multiple comparisons using cluster mass-based permutation testing: cluster forming threshold is voxelwise p&lt;0.001, cluster corrected threshold p&lt;0.05.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.005</object-id><label>Figure 1âfigure supplement 3.</label><caption><title>Activation related to task factors.</title><p>T-statistic maps for the entropy (<bold>a</bold>), whether changing response (<bold>b</bold>) and reward (<bold>c</bold>) regressors in GLM2. These variables explain variance in very similar brain regions to those in which variance is explained by differences between exploitation and exploration. Panels a and b images thresholded at p&lt;0.001 and corrected for multiple comparisons. Panel c image thresholded at p&lt;0.001, uncorrected.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.006</object-id><label>Figure 1âfigure supplement 4.</label><caption><title>A large amount of the difference between exploitation and exploration is captured by task factors.</title><p>T-statistic map for the [1 -1] contrast in GLM3, testing for differences between exploitation and exploration having regressed out effects of the task factors. (<bold>a</bold>) Image thresholded voxelwise at p&lt;0.001, the same threshold as in <xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref>, uncorrected. (<bold>b</bold>) Image thresholded voxelwise at a more liberal threshold of p&lt;0.01, uncorrected.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig1-figsupp4-v1.tif"/></fig></fig-group><p>Participantsâ behaviour alternated between exploitation and exploration as they formed and revised beliefs about the current state of the environment (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). 72% of trials on average were classified as exploit trials (SEM across participants 1.2%); the mean length for anÂ exploitationÂ 'block' was 13.7 trials (across participants) and the within-subject standard deviation of exploitationÂ block lengths was (mean across participants) 7.1 trials. In order to classify trials as either exploitative or exploratory, we used a simple heuristic. We defined the start of a period of exploitation as the first trial on which participants selected the true high reward probability option and received reward, and the end of the exploit period as the last trial before switching to a different option (thus within exploit periods, by definition, all choices were for the same option). The task therefore provided a clear behavioural marker of the onset of exploration, which was defined as the first trial on which participants switched away from making this selection. As an aside, in Appendix 1 we explore an alternative approach (<xref ref-type="bibr" rid="bib7">Ebitz et al., 2018</xref>) to defining explore and exploit phases using a hidden Markov model (HMM).Â ThisÂ approach yielded a very similar trial classification to the one we used. The relative merits of the two approaches are discussed in Appendix 1.</p><p>The possibility for voluntary exploration in the task created a constant pressure to evaluate whether the state of the environment had changed. Certainty about the state of the environment was modelled as the entropy across the state space in a Bayesian ideal observer model. The model, described in the Methods, had a space of possible states encompassing the possibility that each option was the current high reward option, and a range of possible pay-out rates; it also had a uniform leak.</p><p>We defined belief uncertainty as the entropy across the space of four possible states (namely, the four possible high-reward options, marginalizing over possible pay-out rates):<disp-formula id="equ1"><mml:math id="m1"><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo> <mml:mi/><mml:mrow><mml:msub><mml:mo>â</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>â</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>â¡</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the state that option <italic>i</italic> is the high reward option. For comparison we defined another measure of belief uncertainty, relative uncertainty (Wilson et al., 2010), which behaved similarly and was highly correlated with entropy (mean correlation across participants r=0.80). The relation between entropy and relative uncertainty is explored further in Appendix 1.</p><p>Model entropy was generally high in the exploit phases and low in the explore phases of the task (<xref ref-type="fig" rid="fig1">Figure 1d,e</xref>); it also tended to be higher when the pay-out rate of the high reward option was lower.Â Both high entropy, and high relative uncertainty, made it more likely that participants would switch from exploitation to exploration following a reward omission (two separate logistic regressions: entropy - t<sub>18</sub>Â =Â 7.60, p=2.57Ã10<sup>â7</sup>; relative uncertainty - t<sub>18</sub>Â =Â 13.50, p=3.7Ã10<sup>â11</sup>). Furthermore, using an action policy defined by fitting two multinomial softmax functions (one for explore trials, one for exploit) to the option probabilitiesÂ <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>, we found that the particpantsâ choices were correctly predicted on 95% of exploit trials and 51% of explore trials (chance would be 25%). The importance of using a model for the study was in fact to have a representation of participantsâ latent belief states during phases when their overt behaviour remained stable, rather than to predict overt changes of behaviour; however the fact that the model could predict behaviour relatively well across all phases of the task speaks to its validity.</p><p>The overall distribution of brain activity in explore and exploit phases of the task differed (GLM1, see <xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref>). The explore phase engaged a frontal-parietal action network and the dorsomedial prefrontal cortex (dorsal anterior cingulate dACC and adjacent preSMA). The exploit phase engaged medial orbitofrontal cortex (mOFC) and the hippocampus, two regions known to be engaged in model-based choice (<xref ref-type="bibr" rid="bib4">Boorman et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Jones et al., 2012</xref>; <xref ref-type="bibr" rid="bib24">Noonan et al., 2010</xref>; <xref ref-type="bibr" rid="bib37">Wikenheiser et al., 2017</xref>). In addition to state uncertainty (model entropy), several factors differed between explore and exploit phases, notably the frequency of response switching, and the frequency of reward omission. Further analysis (GLM2, <xref ref-type="fig" rid="fig1s3">Figure 1âfigure supplement 3</xref>) indicated that response switching and high model entropy (see below for details of model) predicted activity throughout the frontal parietal network and dorsomedial frontal cortex. Reward omission predicted activity in dorsomedial frontal cortex only, and reward activated ventral striatum. Low model entropy predicted activation of medial OFC and hippocampus (<xref ref-type="fig" rid="fig1s3">Figure 1âfigure supplement 3</xref>). Most of the differences in activity observed between exploitation and exploration were explained by these factors (GLM3; <xref ref-type="fig" rid="fig1s4">Figure 1âfigure supplement 4</xref>).</p><p>However, the main focus of our analysis was the variation in state uncertainty within the exploitation phase of the task, during which the chosen action was by definition constant, and how this uncertainty may be represented and modulated. By limiting our analysis to core exploitation trials (at least five trials, and therefore approximately twenty seconds, after the last action switch and at least five trials before the next action switch; such trials were 25% of all trials (mean across participantsÂ =Â 201/800 trials, SEMÂ =Â 7.0)), we were able to identify neural activity concerned with changes in participantsâ beliefs in the absence of changes in overt behaviour. This dissociated uncertainty about the state of the environment from variability of action. All analyses presented are limited to this subset of trials unless otherwise stated.</p><p>During each exploitation block, participantsâ certainty about the state of the environment varied due to probabilistic reward omission. To generate trial-by-trial estimates of the certainty of participantsâ beliefs to regress against neural responses, we constructed a normative Bayesian learning model (see Materials and methods). The model inferred the trial-wise probability that each of the four options was the high reward probability option, based on the data observed by each individual participant (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). For each trial, we calculated the entropy of the modelâs posterior probability distribution over options, based on evidence up to and including that trial (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). This was used as a proxy for the entropy in the participantsâ internal model, at the point of feedback on each trial. Entropy is low when the probability mass of the posterior is mostly over one option, i.e. participants are certain. Within exploitation phases, model entropy generally decreased over time as participants continued exploiting a single option, but increased following probabilistic omissions of reward, and accordingly depended on the payout rate of the high reward option (70% or 90% reward) (see <xref ref-type="fig" rid="fig1">Figure 1d,e</xref>).</p><p>Throughout the next sections of this paper, we discuss the relationship between model entropy (in our theoretical model) and the level of uncertainty in a neural model of the state of the world. However, it should be noted that in the current task, the possible states of the environment are simply the alternatives for which option is the high reward option, thatÂ isÂ {option A is high reward optionâ¦ option D is high reward option}. Thus, in the current task, state and option value are inherently interlinked. It is necessarily the case that high confidence in the currently chosen option (low entropy state) correlates with that option having a high expected value (mean correlation Â± s.e.m: -0.93 Â± 0.005). Thus it should be noted that throughout the subsequent analyses, a low entropy trial, defined by us as a trial on which one particular option is considered very likely to be the high reward option, could equivalently be described as a state in which one particular option (the selected one) has a high expected value and others have a low expected value. In behavioural control more generally, this association would hold for any world model for which the aim was to determine the expected value associated with different candidate actions.</p><sec id="s2-1"><title>Decoding a probabilistic representation of beliefs about the state of the environment</title><p>A probabilistic model of the current state of the world should comprise representations of candidate states, weighted by their probabilities. Recent studies have identified medial OFC as a likely site for such a probabilistic model in the context of model-based reinforcement learning (<xref ref-type="bibr" rid="bib6">Chan et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Schuck et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Wilson et al., 2014</xref>).</p><p>In the present task, such a probabilistic internal model could be thought of as a mixture model comprising representations of the possible options, wherein the strength of the representation of a given option on each trial is weighted by the belief that option is the high reward probability option (<xref ref-type="fig" rid="fig1">Figure 1b</xref>).</p><p>To identify regions that represented the task environment in this probabilistic manner, we used a multivariate searchlight approach over the whole brain as follows: at each searchlight, in one half of the data (training set) we identified activity patterns characteristic of trials on which each option was selected. In the other half of the data (test set) we calculated the trial-wise probability of classifying as each option (we then swapped training and test sets; see Materials and methods for details).</p><p>Simply searching for regions in which we could correctly classify the selected option, we were, as expected, able to decode at above-chance levels from a broad network of areas including motor and visual cortex (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). A plot of the probability of decoding each action from visual cortex (<xref ref-type="fig" rid="fig2">Figure 2c</xref>, top) and motor cortex (<xref ref-type="fig" rid="fig2">Figure 2c</xref>, middle) reveals a representational structure that is sensitive to spatial and motor factors; the most likely options to be decoded, other than the actually selected option, are those corresponding to the chosen hand (and equivalently, the chosen visual hemifield).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.007</object-id><label>Figure 2.</label><caption><title>Probabilistic beliefs represented in mOFC.</title><p>(<bold>a</bold>) The currently selected option can be decoded above chance, as expected, in motor and visual cortex (t score map for above chance decoding of the chosen option across subjects; thresholded at p&lt;0.001; corrected for multiple comparisons). (<bold>b</bold>) Medial OFC represents the current state of the task probabilistically. Highlighted voxels are the centers of searchlights in which the representation strength for the chosen option was higher when model entropy was low (i.e. when participants have high certainty about the state of the environment; t score map for the effect of model entropy on representation strength; thresholded at p&lt;0.001; corrected for multiple comparisons). (<bold>c</bold>) Region of interest analyses demonstrating multivariate decoding patterns. Left column: the multivariate classifier probability that each option was selected; on trials when model entropy was low (dark red) and high (light red). Right column: decoding accuracy (i.e. proportion of trials when the option with the highest probability of having been selected by the classifier was indeed the option selected by the participant) in low and high entropy trials. All error bars are SEM. Dashed lines denote chance. Top row and middle row: decoding in visual and motor cortices, respectively, is not sensitive to model entropy and errors in decoding tend to be to neighbouring options. Bottom row: decoding in mOFC is modulated by model entropy, such that decoding is higher when model entropy is low.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.008</object-id><label>Figure 2âfigure supplement 1.</label><caption><title>Representation strength in mOFC is explained by probability assigned to the currently selected option, as well as the difference between high and low reward exploit periods.</title><p>(<bold>a</bold>) T-statistic map showing model probability explains representation strength specifically in mOFC, as in GLM5. Image thresholded at p&lt;0.001; corrected for multiple comparisons. (<bold>b</bold>) T-statistic map showing regions where representation strength is higher in high (90%) vs. low (70%) reward exploit periods. Image thresholded voxelwise at p&lt;0.05, uncorrected.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.009</object-id><label>Figure 2âfigure supplement 2.</label><caption><title>Histogram of t scores for the effect of entropy on representation strength (GLM4) for null data produced by shuffling voxel identities prior to PCA.</title><p>This demonstrates that the dimensionality reduction does not introduce bias in to the result. The histogram is centred about 0 and the t score of our analysis (â6.8) is off the distribution.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig2-figsupp2-v1.tif"/></fig></fig-group><p>However, the defining feature of a probabilistic model is that the relative weighting of the chosen option should depend on certainty, as shown in schematic <xref ref-type="fig" rid="fig1">Figure 1b</xref>. To search for regions that had this property, we defined a trial-wise summary measure of representation strength as the ratio of the odds of classifying the trial as the chosen option, to the odds of classifying it as one of the unchosen options. This odds-ratio measure captured the extent to which the chosen option was represented more strongly than unchosen alternatives on each trial. Finally, we regressed trial-by-trial model entropy (as a proxy for the entropy of participantsâ beliefs) against representation strength (GLM4). This identified areas in which representation strength for the chosen option was higher when there was higher certainty that the chosen option was the high reward option.</p><p>Using this approach we identified a region in mOFC (peakÂ =Â 10,40,â22; <xref ref-type="fig" rid="fig2">Figure 2b</xref>) in which representation strength for the exploited option was higher when model entropy was lower (corrected for multiple comparisons using permutation testing; cluster mass p&lt;0.05 corrected with a cluster forming threshold of p=0.001). This was the only cluster to survive multiple comparisons correction. The same effect was also detectable in the hippocampus (t<sub>(18)</sub>=-2.11 p&lt;0.05 uncorrected at an ROI centered on the peak voxel 34, -14, -16 for the exploit vs. explore univariate contrast from GLM 1; <xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2</xref>). However the effect in hippocampus did not survive whole brain correction for multiple comparisons and should therefore be treated with caution.</p><p>The weighted representation of option preferences observed in mOFC is consistent with a probabilistic internal model of the environment, whereby the currently selected option has a higher decoding probability when model entropy is low (<xref ref-type="fig" rid="fig1">Figure 1b</xref> and <xref ref-type="fig" rid="fig2">Figure 2c</xref>, bottom). It is distinct from an action/policy representation, in which the representation of options is not modulated by entropy, as was observed in visual and motor areas (<xref ref-type="fig" rid="fig2">Figure 2c</xref>, top and middle).</p><p>To probe the robustness of the mOFC result, we repeated the analysis using two measures other than the model entropy regressor to predict representation strength. Entropy is a summary measure of the uncertainty across options; low entropy could arise from any of the four options being represented more strongly than the others. To check that the result was specific to the current state of the environment, we repeated the above analysis but instead of model entropy, used the probability (belief) assigned by the model that the currently exploited option is the high reward option as the predictor variable (GLM5). This also produced a specific effect in the medial OFC (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>). To confirm our result was not dependent on the particular learning model we used, we simply compared representation strength during exploit periods with high and low payout rates. When the pay-out rate of the exploited, high reward option was 90% vs. 70%, representation strength was higher in mOFC (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>).</p></sec><sec id="s2-2"><title>What is the nature of the representation in mOFC?</title><p>The multivariate whole brain analysis showed that the identity of the chosen option could be decoded with greater confidence (representation strength was higher) when model entropy was low. Whilst OFC has been proposed as the site of a representation of the current state of the world (<xref ref-type="bibr" rid="bib30">Schuck et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Wilson et al., 2014</xref>), it is also concerned with value representation. Trials with low model entropy in our task tended to be the same trials on which a high value option was chosen (an option which the participant believed had a high probability of leading to a reward), and trials on which recent reward history contained few reward omissions.</p><p>The reason we interpret the multivariate results as evidence for a probabilistic representation of the current state (which option is the current high reward option) is that our ability to decode the <italic>identity</italic> of the chosen option from mOFC (indexed as representation strength for the <italic>identity</italic> of that option) was higher when the participantâs uncertainty (model entropy) was lower. Therefore decoding is driven by the relative weightings of representations of specific options rather than decoding a general value representation. Indeed, the training and test sets used in the analysis both included cases where the option value was higher and lower, which was unknown to the classifier. We examined whether our effects still held after regressing out a univariate effect of option valueÂ by repeating the analysis after first regressing out the effect of value from univariateÂ activity in each voxel in the mOFC region of interest. The effect of model entropy on representation strength remained significant (t<sub>(18)</sub>=-7.62,p&lt;0.001). This was also true when regressing out recent reward history (whether the current and previous three trials were rewarded) in addition to value (t<sub>(18)</sub>=-7.26,p&lt;0.001) from voxelwise activityÂ before carrying out multivariate analysis. Since these analyses were performed on the residual voxelwise data after the effect of value (or reward history) on voxelwise activity was removed, univariate option value could not drive the classification.Â Regardless, given the decoding effects were on specific option <italic>identities</italic>, decoding a general value representation cannot explain our results. Rather the decoding must be driven by different relative weightings of specific option representations, consistent with a probabilistic state representation.</p><p>We should reiterate here thatÂ in the current task, state and option value are inherently interlinked because the possible states of the environment are simply the alternatives for which is the high reward option, i.e. {option A is high reward optionâ¦ option D is high reward option}. Whilst it is the representation strengthÂ of state <italic>identity</italic> that depends on uncertainty, the states themselves are defined in terms of option value. Therefore the present results in no way speak against the hypothesis that mOFC represents option values; in fact the opposite is true.</p></sec><sec id="s2-3"><title>A candidate neuromodulatoryÂ mechanism for increasing flexibility of belief representations</title><p>Having confirmed that a probabilistic model of the state of the world is represented in the brain, we went on to ask how entropy in that model might be controlled. An intriguing possibility is that increases in neural model uncertainty are controlled via a neuromodulatory route. The neuromodulatorÂ noradrenalineÂ has been proposed as a candidate mechanism by which the level of uncertainty in neural models of the world may be controlled (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib5">Bouret and Sara, 2005</xref>; <xref ref-type="bibr" rid="bib12">Iigaya, 2016</xref>; <xref ref-type="bibr" rid="bib20">Martins and Froemke, 2015</xref>; <xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Pulcu and Browning, 2017</xref>; <xref ref-type="bibr" rid="bib40">Yu and Dayan, 2005</xref>). Noradrenaline is produced in the locus coeruleus (LC), and is released very broadly in the cerebral cortex including the mOFC (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>).</p><p>We used baseline pupil size (mean pupil area in the 20 ms before outcome presentation, expressed as % signal change relative to the participantâs mean pupil area over the task run) to index neuromodulatory state. Pupil size has primarily been interpreted in the literature as indexing noradrenaline levels, although the muscles controlling pupil size are sensitive to both noradrenaline and acetylcholine. ChangesÂ inÂ pupil diameter have been linked to single-unit activity in the (noradrenergic) LC (<xref ref-type="bibr" rid="bib16">Joshi et al., 2016</xref>). Recent physiological work has demonstratedÂ thatÂ both noradrenaline and acetylcholine as measured in cortex, are associated with pupil size (<xref ref-type="bibr" rid="bib29">Reimer et al., 2016</xref>); levels of bothÂ noradrenaline andÂ acetylcholine were correlated with pupil dilation over a time course of up to a few seconds (a similar time course to the interval between trials in the current experiment). Therefore our pupillometry results cannot be interpreted as specific to noradrenaline but rather reflect a complex combination of neuromodulatory and other factors. However, <xref ref-type="bibr" rid="bib29">Reimer et al. (2016)</xref> also report that noradrenaline, but not acetylcholine, was correlated with changes in pupil dilation (the temporal derivative of pupil size) as well as pupil size itself, which favours a noradrenergic interpretation of our pupillometry results (most of the pupillometry results reported below concern changes in pupil size rather than pupil size per se). However, we must emphasise that pupillometry is a very indirect measure of neuromodulation andÂ although we mostly interpret our results in the context of noradrenaline due to the extensive literature on pupillometry and noradrenaline, as well as influential theories and experimental work linking noradrenaline to uncertainty, model updating and exploration, we note that our pupil size data cannot be specifically linked to noradrenaline over other pupil-linked arousal factors such as acetylcholine.</p><p>Baseline pupil size was larger in explore than exploit trials (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, left), and increased when transitioning into exploration <xref ref-type="fig" rid="fig3s1">(Figure 3âfigure supplement 1</xref>). On a trial-by-trial basis, reward omission produced a sustained increase in pupil size following feedback (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, right).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.010</object-id><label>Figure 3.</label><caption><title>Neuromodulatory systems as a candidate mechanism for increasing flexibility of belief representations.</title><p>(<bold>a</bold>) Pupil size mean timecourses throughout a trial. Left: mean timecourses shown for all trials as well as trials split according to whether they were explore or exploit trials, revealing a larger pupil size in exploration than exploitation. Right: splitting trials according to whether the trial was rewarded or not reveals a sustained increase in pupil size following omission of reward. Shaded regions denote SEM. (<bold>b</bold>) Change in pupil diameter predicts changes in representation strength in mOFC on exploit trials. Beta weights for the effect of change in pupil diameter on change in representation strength are significantly below zero. This is true only on trials when reward was omitted. Error bars are SEM. (<bold>c</bold>) Performing this analysis as a whole brain reveals, again, a relatively localized effect in mOFC (t score map shown, thresholded at p&lt;0.01, uncorrected; analysis performed on unrewarded exploit trials). (<bold>d</bold>) Median split on unrewarded exploit trials reveals that on trials when pupil change is high, change in representation strength is more negative than when pupil change is lower, in mOFC. Error bars are SEM. (<bold>e</bold>) Left: ACC region active when model entropy increased. Right: ACC region in which activity predicted changesÂ inÂ pupil dilation, over and above the effect of increase in model entropy and mean brain activity. Both thresholded at p&lt;0.001 and corrected for multiple comparisons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.012</object-id><label>Figure 3âfigure supplement 1.</label><caption><title>Task-related pupil size changes are not explained by outcome stimulus type.</title><p>We checked our results could not be explained by differences in luminosity between outcomes signalling reward vs. no reward. We counterbalanced the stimuli signalling rewarding vs. non-rewarding outcomes across participants: half the participants received a cheese stimulus as the rewarding outcome and apple stimulus as the unrewarding outcome, and the other half of participants received the converse. We analyse the pupil data from the behavioural session that each participant completed prior to the fMRI session, and split the participants according to the stimulus outcomes they received. We analyse the sixteen participants that entered pupil-brain analyses (ten received cheese as a reward, and six received apples as reward). We demonstrate that although noisier due to reduced power, pupil dilations to task factors are qualitatively the same when either the cheese or the apple was the rewarding outcome. We demonstrate this with two analyses. (<bold>a</bold>) First, by performing an analysis looking at the baseline pupil size on trials around transitions from exploitation to exploration. Mean baseline pupil size (again pupil size expressed as % of mean of that session) is presented as a function of trials around a transition from exploitation to exploration. A marked one trial increase in pupil size was observed as participants transitioned from exploitation to exploration (left panel), as has been previously observed (<xref ref-type="bibr" rid="bib13">Jepma and Nieuwenhuis, 2011</xref>). Although noisier due to reduced power, this result was true when data was split according to either outcome identity type (cheese or apples; middle and right panels, respectively). Error bars are SEM. (<bold>b</bold>) Second, by constructing a GLM with regressors: reward, changing response on the next trial, switching in to exploration, as well as a main effect regressor, and performing a timeseries analysis with this GLM on all data and on data split according to stimulus outcome identities. Mean beta weights for the effect of the regressors in the GLM on pupil size areÂ plotted as a function of time relative to outcome delivery. The data on each trial was normalised before performing the regression by demeaning the one second preceding outcome delivery. A constriction following reward delivery, a small dilation on trials on which participants changed their choice on the subsequent trial, and a large dilation when switching from exploitation in to exploration was observed. Again it can be observed that the results are qualitatively similar regardless of outcome identity type (middle and right panels). Shaded regions are SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.014</object-id><label>Figure 3âfigure supplement 2.</label><caption><title>The relationship between change in baseline pupil diameter and change in representation strength in mOFC replicates in explore trials.</title><p>The figure has the same notation as <xref ref-type="fig" rid="fig3">Figure 3b</xref> in the main text. When performing this regression (GLM6) on explore trials, whether participants changed their response on the subsequent trial was added as a coregressor.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.015</object-id><label>Figure 3âfigure supplement 3.</label><caption><title>ACC activity explains changes in baseline pupil size across all trials.</title><p>T-statistic map showing where univariate brain activity explains changes in baseline pupil size, as in GLM8. Analysis performed in a grey matter mask, hence the streak in the activation. Similar to <xref ref-type="fig" rid="fig3">Figure 3e</xref> in the main text except across all trials. Image thresholded at p&lt;0.001; corrected for multiple comparisons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp3-v1.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.016</object-id><label>Figure 3âfigure supplement 4.</label><caption><title>ACC is engaged when transitioning from exploitation to exploration.</title><p>(<bold>a</bold>) T-statistic maps for the regressor for switching from exploitation to exploration, as in GLM2 (note this is variance explained by the regressor over and above that explained by the other regressors in GLM2, such as changing response and reward). Image thresholding at p&lt;0.001; corrected for multiple comparisons. (<bold>b</bold>) T-statistic map at a more liberal threshold of p&lt;0.05, voxelwise and uncorrected, for the regressor for switching from exploration to exploitation, showing this transition does not engage ACC. Hence ACC transition-related activity appears to be specific for switching from exploitation to exploration and not vice versa.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp4-v1.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.011</object-id><label>Figure 3âfigure supplement 5.</label><caption><title>Individual pupil effects.</title><p>Here we show â as requested by a reviewer â individual pupil effects, since pupil effects are prone to strong individual differences. We present the mean timecourse for each participant for both of the two pupil effects presented in <xref ref-type="fig" rid="fig3">Figure 3a</xref>, namely splitting by exploit (red trace) and explore (blue trace) trials, and splitting by rewarded (red trace) and unrewarded (black trace) trials. Each panel denotes the effect for each of the 16 participants that entered the pupil analyses in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Notations are the same as in <xref ref-type="fig" rid="fig3">Figure 3a</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp5-v1.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.39404.013</object-id><label>Figure 3âfigure supplement 6.</label><caption><title>Breaking central fixation does not alter pupil effects.</title><p>Figure notation the same as that in <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>, and analyses presented are the same, but having removed trials on which central fixation was broken. We instructed participants to maintain central fixation throughout the task. For technical reasons, the quality of the gaze location data from the fMRI session was too poor to use, so we were unable to determine whether fixation was broken. However, we did have good quality gaze location data from the behavioural session. Repeating the analyses presented in <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref> having removed trials containing eye movements reveals the results are qualitatively the same and quantitatively very similar to those results when trials on which central fixation was broken are not removed (as in <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-fig3-figsupp6-v1.tif"/></fig></fig-group><p>We hypothesizedÂ thatÂ pupil dilation would predict changes in the level ofÂ uncertainty in the internal model. To test this hypothesis, we carried out a linear regression (GLM6) in which the change in baseline pupil size from one trial to the next was used to predict changes in representation strength in the mOFC from one trial to the next. In other words, we asked whether change in pupil size induced by observation of an outcome predicted decreases in representation strength between that trial and the next, providing evidence for changes in neuromodulatory state applying something analogous toÂ a leak to the posterior belief or partial network reset (<xref ref-type="bibr" rid="bib5">Bouret and Sara, 2005</xref>). The OFC representation strength was extracted from a region of interest (searchlight center) defined on the peak result shown in <xref ref-type="fig" rid="fig2">Figure 2b</xref> (change in model entropy was included as a co-regressor of no interest).</p><p>This analysis indicated that changes in baseline pupil size indeed explained changes in representation strength in mOFC; as expected, this relationship was negative, such that increases in pupil size predicted decreases in representation strength. Interestingly, this relationship was limited to unrewarded trials (t<sub>(15)</sub>=-2.94, p=0.01); within the subset of rewarded trials there was no relationship (t<sub>(15)</sub>=0.37, p=0.71; difference between rewarded and unrewarded: t<sub>(15)</sub>=2.82, p=0.01; <xref ref-type="fig" rid="fig3">Figure 3b</xref>). This is significant because (due to the 4-arm nature of the task and the fact that we included only exploitation trials in the analysis) increases in uncertainty occurred almost exclusively following reward omissions â on only 0.2% of core exploit trials (10/3833 trials over all participants) did uncertainty increase following a rewarded trial. Therefore the relationship between pupil dilation and change in representation strength seems to hold in cases where uncertainty is increasing, but not when it is decreasing. To test the temporal specificity of the result, we shifted the pupil and OFC signals relative to one another and recomputed the effect. We found that the result was no longer significant when shifting the signals in any direction (p&gt;0.1 for all analyses), suggesting the effect was temporally specific to change in pupil size predicting change in representation strength from the current trial to the next. This effect remained significant when regressing out value from the univariate signal before fitting the multivariate model, as discussed above (unrewarded: t<sub>(15)</sub>=-3.07, p&lt;0.01; rewarded: t<sub>(15)</sub>=0.56, p=0.58; difference: t<sub>(15)</sub>=2.95, p&lt;0.01).</p><p>Although we focus here on the exploitation phase, we found this result replicated in the mOFC ROI when including only explore trials in the analysis (<xref ref-type="fig" rid="fig3s2">Figure 3âfigure supplement 2</xref>; unrewarded: t<sub>(15)</sub>=-2.38, p=0.03; rewarded: t<sub>(15)</sub>=0.97, p=0.35; difference: t<sub>(15)</sub>=-2.23, p=0.04). Furthermore,Â performing the analysis on unrewarded exploit trials over the whole brain reveals a region relatively localized to mOFC (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). To illustrate this result further, we took the unrewarded exploit trials and looked at the change in representation strength in the mOFC ROI on trials separated according to a median split on change in pupil diameter. As expected, we found change in representation strength was more negative when change in pupil dilation was higher (<xref ref-type="fig" rid="fig3">Figure 3d</xref>; t<sub>(15)</sub> = 2.72, p=0.02).</p><p>These results demonstrate that on trials when evidence against the current belief is observed (unrewarded trials), the change in uncertainty in the neural model is predicted by changes in pupil diameter,Â suggesting a role for neuromodulation in control of uncertainty in neural models. The fact the relationshipÂ is specific to unrewarded trials suggests that the relationship between pupil dilation and representation strength in mOFC is directionally specific to the process of increasing, not decreasing, model entropy.</p></sec><sec id="s2-4"><title>Anterior cingulate cortex is activated when model entropy increases and predicts pupil change</title><p>Having provided evidence that neural model uncertainty may be increased via pupil-linkedÂ neuromodulatory mechanisms, we next asked which brain regions are engaged during increases in uncertainty and may regulate changes in neuromodulatory systems. We used a whole brain GLM analysis to identify regions that were sensitive to increases in model entropy, even in the absence of overt action switches (analysis again limited to exploit trials as defined above; GLM7). This analysis identified activity in the ACC and adjacent preSMA that was directionally sensitive to change in entropy (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, left). The greater the increase in entropy from the previous to current trial, the greater the activity in the ACC and surrounding regions of the dmPFC â that is, these regions were more active when entropy was increasing and less active when it was decreasing. These results are consistent with the observation ACC has been associated with the processing of feedback that should lead to changes of belief (<xref ref-type="bibr" rid="bib25">O'Reilly et al., 2013</xref>).</p><p>ACC is one of the few cortical regions reported to have an afferent influence on the noradrenergicÂ LC (<xref ref-type="bibr" rid="bib14">Jodo et al., 1998</xref>) . This provides at least one anatomical route by which, ifÂ ACCÂ is responsible for computing changes in beliefs, it may be able to broadcast increases in uncertainty to other brain regions via a neuromodulatory route. To probe the relationship between ACC and pupillometric effects,Â we asked where in the brain univariate activity predicts changes in baseline pupil size. We conducted a whole brain GLM analysis, again focused on the exploit period, in which univariate brain activity at each voxel was the predictor variable and changeÂ inÂ pupil size the dependent variable; change in model entropy was included as a co-regressor. Pupil dilation is globally correlated with neural gain (<xref ref-type="bibr" rid="bib9">Eldar et al., 2013</xref>), and we observed a strong correlation of pupil size with mean BOLD signal across the entire grey matter. When we controlled for this global effect by including mean activity across the grey matter as a co-regressor of no interest (GLM8), we observed a localized effect in ACC such that ACC activity on a given trial predicted the change in baseline pupil size from that trial to the next (<xref ref-type="fig" rid="fig3">Figure 3e</xref>, right; more activity in the brain associated with a greater increase in pupil dilation; corrected for multiple comparisons using permutation testing; p&lt;0.05 at cluster forming threshold of p=0.001). Although we focus on the exploit period, this result is also present when conducting the analysis across all trials (<xref ref-type="fig" rid="fig3s3">Figure 3âfigure supplement 3</xref>).</p><p>Given that ACC activity predicts pupil dilation and pupil dilation predicts changes in representation strength in mOFC, we tested whether there was a direct relationship between ACC activity and changes in representation strength in mOFC. However, there was no evidence for such a relationship (activity extracted from an ROI defined on peak of the ACC effect from either GLM7 or GLM8 did not have a significant relationship with change in representation strength in mOFC; p&gt;0.1 for all trial subsets tested). This may reflect the fact that both brain measures have relatively low SNR compared to the pupillometry data, to which both were significantly related.</p><p>Although we focus on the exploitation phase in which overt behavior was stable, it is worth noting that a very similar pattern of activity in medial prefrontal cortex was present when participants switched from exploitation to exploration (GLM2, <xref ref-type="fig" rid="fig3s4">Figure 3âfigure supplement 4</xref>). The activity observed in ACC in this analysis is activity over and above that driven by changing response/option selection (GLM2), which (by definition) occurs on the last trial of exploitation. Note that this effect is specific to exploration initiation, and was not observed when switching strategy from exploitation to exploration (<xref ref-type="fig" rid="fig3s4">Figure 3âfigure supplement 4</xref>), suggesting a particular role in disengaging from the exploited strategy.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We set out to investigate the mechanisms by which entropy in neural models of the world may be controlled, particularly mechanisms by which entropy may be increased. We identified patterns of activity indicative of a probabilistic model of the environment in the medial OFC. The hallmark of this probabilistic model is that it has stronger representation strength for the currently selected option when model entropy is low. This is distinct from sensory and motoric representations in visual and motor cortex that are not sensitive to model entropy. Changes in representation strength in medial OFC, over and above those predicted by our task model, were explained by changeÂ inÂ pupil dilation, a proxy measure for neuromodulator activity. Pupil dilation was in turn predicted by activity in the ACC â a region also active when model entropy increased.</p><p>That an internal model of the task is represented in mOFC is consistent with the proposal that this region represents the current location in task state space (<xref ref-type="bibr" rid="bib39">Wilson et al., 2014</xref>), and in particular represents information that is hidden to participants but required to solve the task (<xref ref-type="bibr" rid="bib6">Chan et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Schuck et al., 2016</xref>). Our work extends this proposal to include the representation of the strength of dynamic beliefs in a probabilistic task in which participants infer the hidden option-reward contingencies that define their location in the task state space.</p><p>The fact that mOFC is the locus of the probabilistic model in the current task is probably due to the choice of task, as mOFC plays a key role in representing stimulus-action-outcome contingencies during model-based action (<xref ref-type="bibr" rid="bib15">Jones et al., 2012</xref>). Different stimulus or task domains could rely on probabilistic models represented in other, task relevant parts of cortex. Furthermore, the exact nature of the representation we are interrogating in mOFC is an interesting avenue for future research. For example, it is possible the representation we observe here reflects the online representation of option-reward contingencies required to guide choice â for example, for online comparison â and is not where the option-reward contingencies are stored offline, which may be in another region such as hippocampus (<xref ref-type="bibr" rid="bib4">Boorman et al., 2016</xref>) or striatum (<xref ref-type="bibr" rid="bib26">Packard and Knowlton, 2002</xref>). The hippocampus showed some limited evidence of probabilistic option representations in the current study. The striatum also plays a key role in representing action-outcome associations, and indeed mechanisms for maintaining flexibility within these representations have been proposed (<xref ref-type="bibr" rid="bib10">Franklin and Frank, 2015</xref>). In the current study we were unable to detect evidence of a probabilistic model in the striatum. This could be because our multivariate analysis relied upon patterns across many voxels and was therefore relatively less sensitive to effects in small structures. Regardless of its exact nature, we are able to use the probabilistic model of the task space detected in mOFC as an index of the neural representation of participantsâ beliefs; thatÂ is, a neuralÂ measure of an internal model.</p><p>We next sought evidence for a role of neuromodulatory systems in increasing uncertainty in such an internal model. Although most theoretical work in this field has focussed on noradrenaline, it should be noted that our results concern pupil dilation, not noradrenaline per se. Pupil dilation depends on at least two neuromodulators (noradrenaline and acetylcholine)Â (<xref ref-type="bibr" rid="bib16">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Reimer et al., 2016</xref>), as well as other arousal-related factors, so our results cannot be linked directly to noradrenaline.</p><p>A large body of theoretical work has ascribed noradrenalineÂ various functions relating to the modification of internal models (changing gain (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>), network resets (<xref ref-type="bibr" rid="bib5">Bouret and Sara, 2005</xref>), and signalling unexpected uncertainty (<xref ref-type="bibr" rid="bib27">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib40">Yu and Dayan, 2005</xref>)). However, evidence for the impact of noradrenalineÂ on internal models has been relatively sparse, partly due to the requirement of measuring the internal model. In one significant rodent study, increasing noradrenaline results in broader â less selective â tuning curves of auditory neurons (akin to a network reset) (<xref ref-type="bibr" rid="bib20">Martins and Froemke, 2015</xref>). Such an impact on representations is what is required for noradrenaline to implement its proposed role in belief updating (<xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>) and increased weighting of current evidence versus prior belief on choice (<xref ref-type="bibr" rid="bib18">Krishnamurthy et al., 2017</xref>). By simultaneously measuring pupil size and an internal model in mOFC, we observed changes in pupil diameter predict increases in uncertainty in an internal model, demonstrating a potential analog of this rodent work in humans performing complex decision-making tasks, and suggesting a broad role of pupil-linked neuromodulation in reducing selectivity of cortical representations.</p><p>We then asked which brain regions contain signals associated with changes in the certainty of beliefs and may be involved in regulating the pupil-linked neuromodulatory system. We found ACC tracked changes in the certainty of beliefs, consistent with observations that it monitors the outcomes of oneâs actions (<xref ref-type="bibr" rid="bib36">Walton et al., 2004</xref>), predicts the updating of beliefs (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>), and is specifically engaged when internal models need to be updated (<xref ref-type="bibr" rid="bib25">O'Reilly et al., 2013</xref>). ACC was particularly involved when uncertainty should increase, consistent with its role in exploratory behavior (<xref ref-type="bibr" rid="bib11">Hayden et al., 2011</xref>) and information seeking (<xref ref-type="bibr" rid="bib33">Stoll et al., 2016</xref>). While the present study provides evidence for this role of ACC, it was not designed to dissociate it from other roles ascribed to ACC, such as cognitive control (<xref ref-type="bibr" rid="bib31">Shenhav et al., 2013</xref>) and choice difficulty (<xref ref-type="bibr" rid="bib32">Shenhav et al., 2014</xref>). Rather, we double dissociate ACC from other regions representing an internal model (mOFC), and provide evidence ACC may broadcast information to such regions via neuromodulatory systems.</p><p>Anatomical work suggests ACC is one of the few cortical regions with descending control on noradrenaline release (<xref ref-type="bibr" rid="bib14">Jodo et al., 1998</xref>). Further, recent studies have shown that activity of ACC neurons predicts pupil dilation and may temporally lead pupil-predicting LC activity (<xref ref-type="bibr" rid="bib8">Ebitz and Platt, 2015</xref>; <xref ref-type="bibr" rid="bib16">Joshi et al., 2016</xref>). Therefore it is anatomically plausible that ACC could influence belief uncertainty via the noradrenaline system, possibly amongst other routes.Â However, whilst both ACC and noradrenaline have been implicated in belief updating (<xref ref-type="bibr" rid="bib17">Karlsson et al., 2012</xref>; <xref ref-type="bibr" rid="bib25">O'Reilly et al., 2013</xref>) and setting the learning rate (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>), evidence for their suspected (<xref ref-type="bibr" rid="bib1">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib17">Karlsson et al., 2012</xref>; <xref ref-type="bibr" rid="bib23">Nassar et al., 2012</xref>) coordination during tasks requiring belief updating has been lacking. Here we found ACC activity explained changes in baseline pupil dilation, over and above the effect of changes in uncertainty and mean brain activity. Whilst our pupil results cannot be linked directly to noradrenaline, they are compatible with the hypothesis that theÂ noradrenaline system could offer a mechanism via which the computation of uncertainty of beliefs in ACC may be broadcast to internal models.</p><p>An alternative explanation for the relationship between ACC and pupil dilation is that they are associated, not with a change in beliefs, but with a change in the drive to produce exploratory behavioural output.Â The circumstances in which model entropy should increase are the same circumstances that should drive participants towards exploratory (random) behavior. Indeed, increasing noradrenaline release to the ACC has been associated with the output of stochastic behavior (<xref ref-type="bibr" rid="bib34">Tervo et al., 2014</xref>). However, an account in which ACC activity and noradrenaline release only track a drive to produce stochastic behavioural output, or to explore, cannot account for the association between pupil dilation and the increase in model uncertainty recorded in mOFC, in the absence of any behavioural change. Further, the animal work described above (<xref ref-type="bibr" rid="bib20">Martins and Froemke, 2015</xref>) provides causal evidence that noradrenaline reduces selectivity of cortical representations, supporting the proposed role for noradrenaline in reducing the strength of beliefs, in addition to its role of increasing stochastic behaviour (<xref ref-type="bibr" rid="bib34">Tervo et al., 2014</xref>). This hypothesis can be summarized in terms of economic models of choice as arguing that noradrenaline input to ACC alters the temperature parameter of a softmax choice model whereas noradrenaline input to internal models (mOFC) alters the option values, resulting in behavioural stochasticity (<xref ref-type="bibr" rid="bib34">Tervo et al., 2014</xref>) and entropic beliefs (present results), respectively.</p><p>We started by asking whether there was a mechanism for increasing uncertainty in neural models. The results presented, in which increases in belief uncertainty engage ACC, which explains changes in pupil size, that in turn explain changes to the selectivity of internal models following evidence the underlying state of the world has changed (reward omission), provide a candidate mechanism. These results suggest different neural mechanisms may be engaged when forming as compared to revising beliefs, and that neuromodulatoryÂ systems may play a crucial role in implementing flexibility of internal representations during decision-making in humans.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Twenty-two healthy human volunteers participated in the experiment. Participant identities were anonymized for analyses. All participants were right-handed, aged between 20 and 31 (mean age: 26), and eight were female. All participants had normal or corrected to normal (with contact lenses) vision. Three participants had to be excluded because of technical difficulties with fMRI, and three had to be excluded from pupil analyses because of technical difficulties with eyetracking in the fMRI scanner. Power analyses are as follows. For univariate effects of model updating: Based on a previously published result demonstrating an effect of model updating in the ACC (<xref ref-type="bibr" rid="bib25">O'Reilly et al., 2013</xref>), we performed a simple a-priori power calculation. This effect from <xref ref-type="bibr" rid="bib25">O'Reilly et al. (2013)</xref> had a Cohenâs d of 0.89; for this effect size, 80% power and an alpha level of 0.05 (one tailed) the minimum sample size was calculated as 17 subjects. For multivariate effects, no a priori power calculations were performed as effect sizes for multivariate analysis are notoriously hard to estimate in advance, depend on the type of information to be decoded and vary across cortical regions â given that we used a whole brain searchlight approach this would make it very difficult to pre-specify an effect size (<xref ref-type="bibr" rid="bib3">Bhandari et al., 2018</xref>). We present a posteriori power calculations because of a reviewer request. The effect size (Cohenâs d) for the key result that representation strength is predicted by model entropy was dÂ =Â 1.58. For a power of 80% and alphaÂ =Â 0.05 one tailed, the minimum sample size was calculated at six individuals. Whilst we would not be confident in a result based on such a small sample, we note that the regression analysis did give a negative regression coefficient (high entropy predicts low representation strength) in 18/19 individuals in our group. For comparison, Schuck et al (<xref ref-type="bibr" rid="bib30">Schuck et al., 2016</xref>) decoded task states from a similar medial OFC region to that found in the present study, in an a priori ROI. Their effect size (accuracy of decoding task state vs. chance) was dÂ =Â 1.77, which would suggest a minimum sample size of 5. For pupillometry effects, the most relevant study in the literature is <xref ref-type="bibr" rid="bib23">Nassar et al. (2012)</xref>. In this study the effect size for a regression of pupil average (similar to our baseline pupil measure) on relative uncertainty yielded an effect size of dÂ =Â 0.94, which would suggest a minimum sample size of 16 for this analysis. We collected data from a number of participants satisfying the estimated size effects, and in line with other papers in the field. The study was approved by a local University of Oxford ethics committee (ref: MSD-IDREC-C1-2013-171), and all participants gave written informed consent.</p></sec><sec id="s4-2"><title>Task</title><p>Participants were presented with eight options (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>), four of which were available for selection in each run of the task (participants completed four runs of the task â see below). The four available options were distinguished from unavailable options by their colour (blue or red, counterbalanced across participants). They were instructed that of the four available options, one had a high and the remainders a low probability of giving rise to reward, if selected. Participants selected, on each trial, any and only one of the four available options by pressing its corresponding button. Following this selection, reward was delivered probabilistically according to whether the option selected was the high probability (70 or 90% probability of reward) or one of the low probability (20%) options, and was displayed on the screen at the time of outcome.</p><p>The participantsâ objective was to accumulate as much reward as possible. Hence, the optimal strategy was to always select the high reward-probability option. This high reward option moved randomly to one of the three other options after a variable number of trials (mean 20 trials, SD 5) and independently of the participantsâ behaviour â adding to the unpredictability (due to the variable length of the exploratory period). When the high reward option moved, it was randomly selected with equal probability to have a 70 or 90% chance of reward delivery. The task was embedded in a game in which participants controlled a mouse seeking cheese (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>). Following selection of an option, the mouse moved to the option and the outcome (reward or no reward; cheese or apple, counterbalanced across participants) was revealed and remained on the screen for 200 ms. The next trial began soon after (jittered with a uniform distribution between 0 and 4 s; mean ITI of 3.44 s). The short spacing between trials was necessary, as we required large numbers of trials to drive participants between many periods of exploitation and exploration and because we focused our analysis on a subset of trials. The close trial spacing was also designed to encourage a sense of consistent engagement with a particular strategy within exploit blocks.</p><p>Participants completed two sessions â one behavioural and pupillometry only, and one additionally with fMRI â each containing four runs of 200 trials (1600 trials total per participant). The available (blue/red) stimuli switched across runs (see below). Before the first session, participants were given detailed instructions of the task. These included underlying statistics: they were explicitly told the probabilities of reward, although not the true underlying frequency at which the high reward probability jumped. Participants were told the probabilities so they would have comparable understanding of the task when doing the fMRI session. Selecting each of the eight options corresponds to a button press for each of the eight fingers. Before starting the first session, participants were trained on the mappings between the response buttons and the options by doing 300 trials of a training task, whereby one option would be highlighted and they would be required to press the corresponding response button. After this, they performed the four runs of the task in the behavioural session. The following day, participants completed the fMRI session, which similarly required participants to complete four runs of the task. The task and all instructions were the same across the two sessions. Participants were additionally instructed to centrally fixate the fixation cross throughout the whole experiment in both the behavioural and fMRI session.</p><p>The motive for having eight options but only four of which were available for selection was to test whether there was any difference between options available for selection but not selected and those not available for selection. The configuration of available options differed across the runs such that all options were available in two of the runs (to allow for training and testing sets of the multivariate model). Therefore the unavailable options were intended to act as a baseline. Analyses testing for differences between available but not selected and unavailable options did not yield significant results (data not shown).</p></sec><sec id="s4-3"><title>Modelling of behaviour</title><p>In order to generate regressors to analyse neural data, we constructed a normative Bayesian learning model that reflected information communicated to participants â specifically, that one option had a high probability of reward and the remainders a low probability of reward.</p><p>We implemented a normative Bayesian learning model to simulate how belief uncertainty should change depending on trial history. The model had information that reflected that which was communicated to participants. We informed participants that there was always and only one location with an either 70 or 90% probability of receiving reward and the remainders only 20%. The model estimated the probability that each of four hypotheses <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo> <mml:mi mathvariant="normal"/><mml:mo>{</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3,4</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula> is correct â one hypothesis for each of the four locations that could be chosen on any given trial <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â</mml:mo> <mml:mi mathvariant="normal"/><mml:mo>{</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3,4</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula> being the high reward-probability location. In each of these hypotheses, the three low probability locations were assigned p(reward)= 0.2, which was fixed. The other, high reward-probability location was assigned probability P, where P could take any value in the range 0.3 to 1. We allowed P to be more flexible to allow for possible differences in participantsâ estimates of probabilities, but constrained it to be greater than the default payoff of 0.2 by imposing a lower bound of p=0.3.</p><p>This information can be thought of as represented in a payout matrix â a matrix whose elements correspond to a probability of reward being delivered. The payout, or outcome, on trial t, <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, was determined by a binomial distribution parameterised by q:<disp-formula id="equ2"><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>B</mml:mi><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula>where q was obtained from the payout matrix M. M depends on which location is the true high reward-probability location H, what the payout probability P at the high reward-probability location is, and which location L was selected on that trial.</p><p>The posterior probability that each location was the correct one, H, and the payout probability P takes some value p, was found by considering the payout probability q associated with the cell (<inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>)Â in the payout matrix:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>â©</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The posterior probability over q, <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>Â was given using Bayesâ rule:<disp-formula id="equ4"><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The likelihood <inline-formula><mml:math id="inf8"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>Â was simply:<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>meaning that the likelihood distribution was a 2D matrix over<disp-formula id="equ6"><mml:math id="m6"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3,4</mml:mn></mml:mrow></mml:mfenced> <mml:mi mathvariant="normal"/><mml:mo>Ã</mml:mo> <mml:mi mathvariant="normal"/><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>0.3</mml:mn><mml:mo>:</mml:mo><mml:mn>0.01</mml:mn><mml:mo>:</mml:mo><mml:mn>1.0</mml:mn><mml:mo>}</mml:mo></mml:math></disp-formula></p><p>The prior <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>Â was none other than the probability of the values H=h and P=p, given all previous observations and the switch probability s:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>â©</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>This was obtained from the previous trialâs posterior after accounting for the possibility of a switch in H with a leak. The probability of a switch s was fixed and modelled as 1/20. This reflects the true underlying mean frequency of a switch, but was unknown to participants (we could model this flexibly â however, once in the fMRI session, participants likely have a rough gauge of how frequently there is a switch due to having already completed 800 trials of the task in the behavioural session). The prior was therefore given by:<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>â©</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext>Â </mml:mtext></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>â©</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>â</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>â©</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf10"><mml:mi>U</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">M</mml:mi><mml:mo>)</mml:mo><mml:mo>â</mml:mo><mml:mi>s</mml:mi></mml:math></inline-formula>Â is a uniform leak over the parameter space, weighted by s, allowing the model to âforgetâ past outcomes (otherwise the estimates in the posterior will just converge to the mean of all estimates).</p><p>To obtain the model entropy over Hypotheses (i.e. the spread of belief over which of the four possible locations was the high reward location), we marginalized over p:<disp-formula id="equ9"><mml:math id="m9"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:mrow><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo> <mml:mi mathvariant="normal"/><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This gave the marginalised posterior shown in <xref ref-type="fig" rid="fig1">Figure 1e</xref>. We then applied the formula for Entropy:<disp-formula id="equ10"><mml:math id="m10"><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mo>=</mml:mo> <mml:mi mathvariant="normal"/><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">â</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>â¡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This was the equation that gave the entropy regressor used in analyses and shown in <xref ref-type="fig" rid="fig1">Figure 1d</xref>.</p></sec><sec id="s4-4"><title>fMRI acquisition and preprocessing</title><p>In the fMRI session, four blocks, or runs, of functional data were acquired, with meanÂ ~12 min each. Data were acquired on a 3T Siemens TIM Prisma, using a 64-channel head and neck coil. Functional scans were collected using a gradient echo-planar imaging (EPI) sequence, Multi-band 4, with TRÂ =Â 1.35 s, TEÂ =Â 32 ms, flip angleÂ =Â 74 degrees, and voxel resolution of 2Ã2Ã2 mm. Structural scans were acquired using a T1-weighted MP-RAGE sequence, 1Ã1Ã1 mm voxels. All scans were of axial orientation angled to ACPC, covering the whole brain.</p><p>Preprocessing and univariate analysis of fMRI data was performed using tools from fMRI Expert Analysis Tool (FEAT), part of FMRIBâs Software Library (FSL). Data were preprocessed using the FEAT default options. Registration of EPI images to high-resolution structural images and to standard (MNI) space was performed using FMRIBâs Linear and Non-Linear Registration Tool, respectively (FLIRT and FNIRT). For GLMs run using FEAT, the four runs of the task for each participant were pooled using fixed effects, and then high-level analyses across participants were performed using mixed effects analyses. For the multivariate and pupil-brain analyses, data was concatenated across runs for each participant and then the GLM was run. These GLMs contained a bias term for each run separately to remove any differences across runs (i.e. the GLM had four bias/main effect regressors, each with ones for one of the runs and zeros for the other three).</p></sec><sec id="s4-5"><title>fMRI analyses</title><p>For univariate brain GLMs, we locked each trial event to the time of outcome presentation and convolved the BOLD signal with the canonical HRF. The same was performed for generating whole-brain beta maps for the multivariate analyses, which were then used to calculate representation strength (see fMRI multivariate measure of representation strength). We then ran the following GLMs that are presented in the main paper, where the dependent variable was either univariate brain activity, multivariate representation strength, or change in baseline pupil diameter. Analyses were carried out either on all trials or only included trials in the exploit period that were at least five trials from the adjacent explore periods so that any variation is not due to changes in action. These GLMs are specified below:</p><p>GLM1 included the following regressors: Exploit, explore. Dependent variable: Univariate brain activity. A [1 -1] contrast tested for differences between exploitation and exploration, with positive activation indicating regions more active in exploitation than exploration, and vice versa for negative activations. All trials included in the analysis. The goal of this analysis was to identify regions that were differentially active in exploitation and exploration phases of the task.</p><p>GLM2 included the following regressors: Main effect (bias; column of ones), entropy, whether reward was delivered at outcome, whether participants changed their choice on the subsequent trial, whether participants transitioned from exploitation to exploration on the subsequent trial (last exploit trial), whether participants transitioned from exploration to exploitation on the subsequent trial (first exploit trial). Dependent variable: univariate brain activity. All trials included in the analysis. The goal of this analysis was to identify regions sensitive to certain task factors, as well as to test for regions with activity at the transitions between exploitation and exploration (over and above that explained by the other task regressors, such as switching options).</p><p>GLM3 included the following regressors: Exploit, explore, and all the regressors from GLM2 except the main effect regressor. Dependent variable: Univariate brain activity. A [1 -1] contrast tested for differences between exploitation and exploration. All trials included in the analysis. The goal of this analysis was to investigate whether much of the difference between exploitation and exploration was explained by the task factors in GLM2.</p><p>GLM4 included the following regressors: Main effect (bias; column of ones), model entropy. Dependent variable: multivariate representation strength. Analysis carried out as a multivariate searchlight analysis. Only exploit trials (&gt;5 trials from adjacent explore phase) included in the analysis. The goal of this analysis was to identify regions in which the representation strength varied with model entropy.</p><p>GLM5 was the same as GLM4 except instead of the entropy regressor used the probability (belief) assigned by the model that the currently exploited option is the high reward option. The goal of this analysis was to show representation strength in the region identified in GLM4 varied with the belief over the currently selected option (not just entropy, which captures the certainty of the belief).</p><p>GLM6 included the following regressors: Main effect, change in baseline pupil diameter between the current trial and the next, change in entropy. Dependent variable: change in multivariate representation strength in mOFC (also performed as a whole brain searchlight analysis, as in <xref ref-type="fig" rid="fig3">Figure 3c</xref>). Analysis performed separately on only exploit trials (&gt;5 from adjacent explore phase), and only explore trials. When this analysis was performed on explore trials, whether participants changed their choice was added as a regressor to the GLM. These analyses were performed separately on trials on which reward was delivered and omitted. The goal of this analysis was to test whether changes in pupil diameter explained changes in representation strength.</p><p>GLM7 included the following regressors: Main effect, change in entropy. Dependent variable: Univariate brain activity. Only exploit trials (&gt;5 from adjacent explore phase) included in the analysis. The goal of this analysis was to identify regions in which activity reflected changes in the model entropy, and to test whether they were dissociated from those in which representation strength varied with model entropy (as in GLM4).</p><p>GLM8 included the following regressors: Main effect, brain univariate activity, difference in entropy following outcome between current trial and the previous, and whole-brain mean univariate activity. Dependent variable: change in baseline pupil diameter between the current trial and the next. Only exploit trials (&gt;5 from adjacent explore phase) included in the analysis. (When this analysis was performed on all trials, <xref ref-type="fig" rid="fig3s3">Figure 3âfigure supplement 3</xref>, whether participants changed their choice on the subsequent trial and whether the current trial was the last trial of exploitation were added as regressors to the GLM.) The goal of this analysis was to identify brain regions in which univariate activity explained changes in baseline pupil diameter.</p><p>Multiple comparisons correction was performed with cluster mass-based permutation testing with the FSL function randomise. The clusters were thresholded voxelwise at p=0.001 and cluster masses surviving correction at p&lt;0.05 are presented.</p></sec><sec id="s4-6"><title>fMRI multivariate measure of representation strength</title><p>To obtain a measure of representation strength at each grey matter voxel, we ran a multivariate searchlight analysis over the whole-brain grey matter. We trained and tested the model on different runs of the task. The configuration of available options differed across the runs, such that each option appeared in two different runs. We therefore split the runs in to two pairs â each pair containing all eight options. We train the model on one pair and test on the other, and then repeat, training and testing on the converse pairs.</p><p>The data used as input to the multivariate analyses are whole-brain, standard space beta maps for each trial. We then focus our analyses on the cortex using a grey matter mask. At each grey matter voxel, a set of voxels for that searchlight centre is defined by including all voxels within a radius of seven voxels from the searchlight centre and that lie within the grey matter mask. After performing dimensionality reduction on the voxels and ensuring a balanced training set (see following paragraphs), we train a multinomial logistic regression model using the training set and then use this model to obtain probabilities each of the eight locations was selected on each trial of the test set (see below). This is then repeated switching the training and test sets. The result of this analysis is a probability each of the eight options was selected on each trial of the task at each grey matter voxel.</p><p>At each searchlight of the multivariate analysis, we performed dimensionality reduction and ensured the number of exemplars of each option in the training set was balanced. We performed dimensionality reduction to denoise the data (<xref ref-type="bibr" rid="bib19">Mante et al., 2013</xref>) and to facilitate training the multivariate model (so that we didnât have many more dimensions [voxels] than exemplars [trials]). We concatenated the data across runs, and then at each searchlight centre extracted an nVoxels x nTrials matrix. To perform the dimensionality reduction, we carried out principle components analysis on the voxels-voxels covariance matrix. This resulted in nVoxels principle components (PCs) â each a vector of length nVoxels. We then kept only the top twenty PCs, which captured the 20 strongest spatial modes of variation (shared variance across voxels). The eigenvalues associated with the remainder of the PCs were all near 0, suggesting that the 20 PCs we retained captured most of the spatial variance of activity. Having conducted the PCA, we obtained the contributions of each PC on each trial by linear regression of the voxelwise patterns of activity on each trial against the PC vectors. This resulted in a set of 20 PC contributions (the beta weights from the regression) for each trial â a reduced-dimensionality (20 dimensions) representation of the activity on a given trial. These were taken as the dimensions to be used as predictors in fitting the model. The 20 PC weights on each trial were entered as predictor variables in to a multinomial logistic regression with the selected option as the predicted variable to train the model.</p><p>We performed dimensionality reduction on the entire dataset (800 trials). Because this data set included both training and test set, a reviewer raised the possibility that the procedure could introduce bias into the pattern classification. Since the PCA is agnostic to trial labels it is not clear how such bias could arise, but to check that the data reduction step did not give rise to spurious results we conducted a permutation analysis in which 1000 sets of null data (obtained by shuffling voxel identities within each trial) were passed through the entire analysis pipeline in the ROI defined on the peak of the OFC effect. The resulting t scores for the regression of representation strength on model entropy (the key result from this analysis) were symmetrically distributed about zero (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>). The maximum value of t for these 1000 iterations was 3.09, compared to the peak t-score of 6.8 obtained in mOFC. This suggests that our result is not due to bias introduced by the data reduction procedure.</p><p>Because subjects had a free choice as to which option they selected, we had variable numbers of trials on which a given participant selected each option (i.e. an imbalanced training set). To avoid introducing bias in to the model to predict stimuli selected more often, we oversampled the training set such that there were equal numbers of trials of each stimulus type used to train the model. We did this by repeating the trials in the training set for each option until all classes had the same number of trials as the most selected option.</p><p>After training the model, we used it to provide probabilities of each option being selected on each trial in the remaining data. For each trial in the test data, we used the PC beta weights on that trial as input to the model to obtain the estimated probability that each option was the selected option. This gave a probability on each trial for each of the eight options. To obtain a summary measure, we computed the ratio of the odds of classifying the trial as the chosen option, to the odds of classifying it as one of the offered but unchosen options (i.e. those options that were available for that run of the task but not selected on that trial). We took the logarithm of this ratio, providing us with a measure of the selectivity to the selected action of each searchlight on each trial, namely the log odds ratio, that is in theory normally distributed, although we used non-parametric statistics (permutation testing) to assess the significance of results at the whole brain level. This trial-by-trial scalar measure was then used in subsequent regression analyses to identify regions in which it is explained by participantsâ belief entropy or baseline pupil diameter.</p></sec><sec id="s4-7"><title>Region of interest definitions</title><p>The ACC ROIs for the analyses to test whether ACC activity explained changes in representation strength in mOFC were defined by thesholding the activation maps for both GLM7 and GLM8 at p=0.001 and p=0.01 separately. Hence we tried the analysis with four different ROIs separately. For ROIs we extracted the timecourses by applying the inverse of each participantâs registration to the mask to project the mask from standard space in to subject space and extracted the mean time series within this region of interest.</p></sec><sec id="s4-8"><title>Pupil acquisition and analysis</title><p>We simultaneously measured pupil size while participants performed the task, in both the behavioural session and the fMRI session. We used an EyeLink eyetracker, SR Research to acquire pupil size data, sampled at 1000 Hz.</p><p>We preprocessed the pupil size data using standard methods. We identified trials on which subjects blinked and removed the blinks by interpolation of values measured just before and just after the identified blinks. Trials on which the pupil measurement was lost were removed from the analyses. Finally, we removed the first 25 trials of each run of the task from analyses to avoid any luminance changes that may be caused by starting a new run of the task. After removal of these different trials, the number of core exploitation trials went from 201Â Â±Â 7.6 to 162Â Â±Â 9.4 (meanÂ Â±Â SEM).</p><p>Pupil size in all analyses is normalised for each run by expressing it in terms of percentage difference from the overall mean pupil size on that run. Baseline pupil size is defined as mean (normalised) pupil size in the 20 ms window preceding feedback.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We gratefully acknowledge the Medical Research Council (Career Development Award to JXOâR grant MR/L019639/1, and a grant to THM BRT00020) for funding.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Senior editor at eLife</p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Methodology, Writingâoriginal draft, Writingâreview and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Software, Investigation, Methodology, Writingâreview and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Methodology, Project administration, Writingâreview and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writingâoriginal draft, Project administration, Writingâreview and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by a local University of Oxford ethics committee (ref: MSD-IDREC-C1-2013-171), and all participants gave written informed consent.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.39404.017</object-id><label>Source code 1.</label><caption><title>MATLAB code for the Bayesian model in <xref ref-type="fig" rid="fig1">Figure 1</xref>, and the behavioural datasets to which the model was fit.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-39404-code1-v1.zip"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.39404.018</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-39404-transrepform-v1.docx"/></supplementary-material></sec><sec id="s8" sec-type="data-availability"><title>Data availability</title><p>1. We have uploaded the brain maps to NeuroVault (URL: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/4872/">https://neurovault.org/collections/4872/</ext-link>). 2. We have uploaded the MATLAB code for the Bayesian model in Figure 1, and the behavioural datasets to which the model was fit. No additional parameters are needed to run this model, all non-free parameters are hard coded and also described in the Supplementary section &quot;Bayesian learning model&quot;. The code and data have been uploaded as a source file (Source code 1). 3. We have uploaded the epoched pupil data to Dryad (<ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.5061/dryad.jk17vk0">https://dx.doi.org/10.5061/dryad.jk17vk0</ext-link>), which together with the behavioural data (point 2 above) can be used to replicate pupil analyses. 4. Individual participant data cannot be publicly shared as the ethical approval for our study does not permit this. Due to their large size (&gt;18GB), it's not practical to upload the multivariate fMRI analyses, but these are available on request from the corresponding author. 6. However, for the multivariate analyses, we are able to, and have, uploaded the medial OFC ROI data as a source data file (Figure 2-source data 1). This can be used to replicate the key multivariate results.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Timothy</surname><given-names>H Muller</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Brain maps from: Control of entropy in neural models of environmental state</data-title><source>NeuroVault</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://neurovault.org/collections/4872/">4872</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>T</given-names></name><name><surname>Mars</surname><given-names>R</given-names></name><name><surname>Behrens</surname><given-names>T</given-names></name><name><surname>Jill</surname><given-names>X O'Reilly</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Data from: Control of entropy in neural models of environmental state</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.jk17vk0</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname> <given-names>G</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhandari</surname> <given-names>A</given-names></name><name><surname>Gagne</surname> <given-names>C</given-names></name><name><surname>Badre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Just above chance: is it harder to decode information from prefrontal cortex hemodynamic activity patterns?</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>1473</fpage><lpage>1498</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01291</pub-id><pub-id pub-id-type="pmid">29877764</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname> <given-names>ED</given-names></name><name><surname>Rajendran</surname> <given-names>VG</given-names></name><name><surname>O'Reilly</surname> <given-names>JX</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Two anatomically and computationally distinct learning signals predict changes to Stimulus-Outcome associations in hippocampus</article-title><source>Neuron</source><volume>89</volume><fpage>1343</fpage><lpage>1354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.014</pub-id><pub-id pub-id-type="pmid">26948895</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname> <given-names>S</given-names></name><name><surname>Sara</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Network reset: a simplified overarching theory of locus coeruleus noradrenaline function</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>574</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2005.09.002</pub-id><pub-id pub-id-type="pmid">16165227</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname> <given-names>SC</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A probability distribution over latent causes, in the orbitofrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>7817</fpage><lpage>7828</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0659-16.2016</pub-id><pub-id pub-id-type="pmid">27466328</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebitz</surname> <given-names>RB</given-names></name><name><surname>Albarran</surname> <given-names>E</given-names></name><name><surname>Moore</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Exploration disrupts Choice-Predictive signals and alters dynamics in prefrontal cortex</article-title><source>Neuron</source><volume>97</volume><fpage>475</fpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.011</pub-id><pub-id pub-id-type="pmid">29290550</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebitz</surname> <given-names>RB</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal activity in primate dorsal anterior cingulate cortex signals task conflict and predicts adjustments in pupil-linked arousal</article-title><source>Neuron</source><volume>85</volume><fpage>628</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.053</pub-id><pub-id pub-id-type="pmid">25654259</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname> <given-names>E</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The effects of neural gain on attention and learning</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1146</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1038/nn.3428</pub-id><pub-id pub-id-type="pmid">23770566</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franklin</surname> <given-names>NT</given-names></name><name><surname>Frank</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A cholinergic feedback circuit to regulate striatal population uncertainty and optimize reinforcement learning</article-title><source>eLife</source><volume>4</volume><elocation-id>12029</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12029</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname> <given-names>BY</given-names></name><name><surname>Pearson</surname> <given-names>JM</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuronal basis of sequential foraging decisions in a patchy environment</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>933</fpage><lpage>939</lpage><pub-id pub-id-type="doi">10.1038/nn.2856</pub-id><pub-id pub-id-type="pmid">21642973</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iigaya</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptive learning and decision-making under uncertainty by metaplastic synapses guided by a surprise detection system</article-title><source>eLife</source><volume>5</volume><elocation-id>e12029</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18073</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname> <given-names>M</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21548</pub-id><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jodo</surname> <given-names>E</given-names></name><name><surname>Chiang</surname> <given-names>C</given-names></name><name><surname>Aston-Jones</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Potent excitatory influence of prefrontal cortex activity on noradrenergic locus coeruleus neurons</article-title><source>Neuroscience</source><volume>83</volume><fpage>63</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/S0306-4522(97)00372-2</pub-id><pub-id pub-id-type="pmid">9466399</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>JL</given-names></name><name><surname>Esber</surname> <given-names>GR</given-names></name><name><surname>McDannald</surname> <given-names>MA</given-names></name><name><surname>Gruber</surname> <given-names>AJ</given-names></name><name><surname>Hernandez</surname> <given-names>A</given-names></name><name><surname>Mirenzi</surname> <given-names>A</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Orbitofrontal cortex supports behavior and learning using inferred but not cached values</article-title><source>Science</source><volume>338</volume><fpage>953</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1126/science.1227489</pub-id><pub-id pub-id-type="pmid">23162000</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname> <given-names>S</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Kalwani</surname> <given-names>RM</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, Colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Tervo</surname> <given-names>DG</given-names></name><name><surname>Karpova</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Network resets in medial prefrontal cortex mark the onset of behavioral uncertainty</article-title><source>Science</source><volume>338</volume><fpage>135</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1126/science.1226518</pub-id><pub-id pub-id-type="pmid">23042898</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnamurthy</surname> <given-names>K</given-names></name><name><surname>Nassar</surname> <given-names>MR</given-names></name><name><surname>Sarode</surname> <given-names>S</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0107</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id><pub-id pub-id-type="pmid">29034334</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname> <given-names>V</given-names></name><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martins</surname> <given-names>AR</given-names></name><name><surname>Froemke</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coordinated forms of noradrenergic plasticity in the locus coeruleus and primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1483</fpage><lpage>1492</lpage><pub-id pub-id-type="doi">10.1038/nn.4090</pub-id><pub-id pub-id-type="pmid">26301326</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname> <given-names>JT</given-names></name><name><surname>Nassar</surname> <given-names>MR</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Kable</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><volume>84</volume><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id><pub-id pub-id-type="pmid">25459409</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname> <given-names>F</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Brain networks for confidence weighting and hierarchical inference during probabilistic learning</article-title><source>PNAS</source><volume>114</volume><fpage>E3859</fpage><lpage>E3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.1615773114</pub-id><pub-id pub-id-type="pmid">28439014</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname> <given-names>MR</given-names></name><name><surname>Rumsey</surname> <given-names>KM</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Parikh</surname> <given-names>K</given-names></name><name><surname>Heasly</surname> <given-names>B</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noonan</surname> <given-names>MP</given-names></name><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Sallet</surname> <given-names>J</given-names></name><name><surname>Buckley</surname> <given-names>MJ</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Separate value comparison and learning mechanisms in macaque medial and lateral orbitofrontal cortex</article-title><source>PNAS</source><volume>107</volume><fpage>20547</fpage><lpage>20552</lpage><pub-id pub-id-type="doi">10.1073/pnas.1012246107</pub-id><pub-id pub-id-type="pmid">21059901</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Reilly</surname> <given-names>JX</given-names></name><name><surname>SchÃ¼ffelgen</surname> <given-names>U</given-names></name><name><surname>Cuell</surname> <given-names>SF</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Mars</surname> <given-names>RB</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title><source>PNAS</source><volume>110</volume><fpage>E3660</fpage><lpage>E3669</lpage><pub-id pub-id-type="doi">10.1073/pnas.1305373110</pub-id><pub-id pub-id-type="pmid">23986499</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Packard</surname> <given-names>MG</given-names></name><name><surname>Knowlton</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Learning and memory functions of the Basal Ganglia</article-title><source>Annual Review of Neuroscience</source><volume>25</volume><fpage>563</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.25.112701.142937</pub-id><pub-id pub-id-type="pmid">12052921</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname> <given-names>K</given-names></name><name><surname>'t Hart</surname> <given-names>BM</given-names></name><name><surname>EinhÃ¤user</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil dilation signals surprise: evidence for noradrenaline's role in decision making</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id><pub-id pub-id-type="pmid">21994487</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulcu</surname> <given-names>E</given-names></name><name><surname>Browning</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Affective bias as a rational response to the statistics of rewards and punishments</article-title><source>eLife</source><volume>6</volume><elocation-id>e27879</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27879</pub-id><pub-id pub-id-type="pmid">28976304</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname> <given-names>J</given-names></name><name><surname>McGinley</surname> <given-names>MJ</given-names></name><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Rodenkirch</surname> <given-names>C</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>McCormick</surname> <given-names>DA</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuck</surname> <given-names>NW</given-names></name><name><surname>Cai</surname> <given-names>MB</given-names></name><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human orbitofrontal cortex represents a cognitive map of state space</article-title><source>Neuron</source><volume>91</volume><fpage>1402</fpage><lpage>1412</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.019</pub-id><pub-id pub-id-type="pmid">27657452</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title><source>Neuron</source><volume>79</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.007</pub-id><pub-id pub-id-type="pmid">23889930</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Straccia</surname> <given-names>MA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anterior cingulate engagement in a foraging context reflects choice difficulty, not foraging value</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1249</fpage><lpage>1254</lpage><pub-id pub-id-type="doi">10.1038/nn.3771</pub-id><pub-id pub-id-type="pmid">25064851</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoll</surname> <given-names>FM</given-names></name><name><surname>Fontanier</surname> <given-names>V</given-names></name><name><surname>Procyk</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Specific frontal neural dynamics contribute to decisions to check</article-title><source>Nature Communications</source><volume>7</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/ncomms11990</pub-id><pub-id pub-id-type="pmid">27319361</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tervo</surname> <given-names>DGR</given-names></name><name><surname>Proskurin</surname> <given-names>M</given-names></name><name><surname>Manakov</surname> <given-names>M</given-names></name><name><surname>Kabra</surname> <given-names>M</given-names></name><name><surname>Vollmer</surname> <given-names>A</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Karpova</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Behavioral variability through stochastic choice and its gating by anterior cingulate cortex</article-title><source>Cell</source><volume>159</volume><fpage>21</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.08.037</pub-id><pub-id pub-id-type="pmid">25259917</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname> <given-names>M</given-names></name><name><surname>McClelland</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.108.3.550</pub-id><pub-id pub-id-type="pmid">11488378</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walton</surname> <given-names>ME</given-names></name><name><surname>Devlin</surname> <given-names>JT</given-names></name><name><surname>Rushworth</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Interactions between decision making and performance monitoring within prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1259</fpage><lpage>1265</lpage><pub-id pub-id-type="doi">10.1038/nn1339</pub-id><pub-id pub-id-type="pmid">15494729</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikenheiser</surname> <given-names>AM</given-names></name><name><surname>Marrero-Garcia</surname> <given-names>Y</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Suppression of Ventral Hippocampal Output Impairs Integrated Orbitofrontal Encoding of Task Structure</article-title><source>Neuron</source><volume>95</volume><fpage>1197</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.003</pub-id><pub-id pub-id-type="pmid">28823726</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Nassar</surname> <given-names>MR</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Bayesian online learning of the hazard rate in change-point problems</article-title><source>Neural Computation</source><volume>22</volume><fpage>2452</fpage><lpage>2476</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00007</pub-id><pub-id pub-id-type="pmid">20569174</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Takahashi</surname> <given-names>YK</given-names></name><name><surname>Schoenbaum</surname> <given-names>G</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orbitofrontal cortex as a cognitive map of task space</article-title><source>Neuron</source><volume>81</volume><fpage>267</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.005</pub-id><pub-id pub-id-type="pmid">24462094</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s7" sec-type="appendix"><title>Modelling of beliefs and behaviour</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.39404.019</object-id><p>This appendix follows directly from the Modelling of behaviour section in the Methods. It includes additional modelling of participantsâ behaviour using alternative models.</p><sec id="s7-1"><title>Relative Uncertainty</title><p>As an alternative measure of belief uncertainty, we calculated relative uncertainty (Nassar et al., 2012). Relative uncertainty is defined as the uncertainty about (variance of) the outcome given the most likely state of the world (defined as joint maximum likelihood estimate of <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> divided by uncertainty about the outcome given the full posterior over <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>Over all participants and runs, Relative Uncertainty and Entropy were highly correlated (mean value of Pearsonâs r over all participantsÂ =Â 0.80, SEMÂ =Â 0.0056). This reflects the fact that both measures attempt to quantify the same construct (belief uncertainty). The evolution of entropy, relative uncertainty and change point probability (see below) over a representative run is shown in <xref ref-type="fig" rid="app1fig1">Appendix 1âfigure 1</xref> to give the reader a sense of the similarity between these measures.</p><fig id="app1fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.020</object-id><label>Appendix 1âfigure 1.</label><caption><title>Following the same layout as <xref ref-type="fig" rid="fig1">Figure 1</xref> in the main text.</title><p>Top panel â an example schedule for one participant/run.Â Y axis values 1â4 are the possible high reward locations, x axis values are trials. The dashed line shows the ground truth high reward location over time. Open black circles are participantsâ choices; red dots are reward omissions. Middle panel - Entropy, relative uncertainty and change point probability measures, normalized for comparison. Note that CPP peaks rapidly after reward omission but also falls off rapidly, whilst entropy and relative uncertainty integrate multiple feedback events. Bottom panel â the probability distribution across candidate high reward locations (bright colors are higher probabilities).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-app1-fig1-v1.tif"/></fig></sec><sec id="s7-2"><title>Change Point Probability</title><p>Change point probability on trial t (CPP<sub>t</sub>) is defined as the posterior probability that a change occurred between trial t-1 and trial t, after observing data point x<sub>t</sub>. From Bayesâ theorem, this is the probability of observation x<sub>t</sub> given that a change point has occurred, multiplied by the prior change point probability (i.e. inverse change point frequency), divided by the probability of observation x<sub>t</sub> regardless of whether a change point has occurred.<disp-formula id="equ11"><mml:math id="m11"><mml:msub><mml:mrow><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo> <mml:mi mathvariant="normal"/><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>In our model this translates as<disp-formula id="equ12"><mml:math id="m12"><mml:msub><mml:mrow><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo> <mml:mi mathvariant="normal"/><mml:mfrac bevelled="true"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>â</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo> <mml:mi mathvariant="normal"/><mml:mfrac bevelled="true"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>â</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>â</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>As per our Bayesian model, <inline-formula><mml:math id="inf13"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>â </mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, the probability of the outcome given that there has been a change point and the observer has chosen a low reward location, is given by a binomial with a constant payout parameter (0.2). The probability of the outcome given that there has been a change point and the observer has chosen the high reward location is given by a binomial with the mean payout rate for high reward locations (0.8).</p><p>As per Nassar et al (Nassar et al., 2012), for the purposes of calculating CPP we define the probability of the outcome given no change point, <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>,Â as the probability of the outcome <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> given that the true state of the world was the joint maximum likelihood values of H and q on trial t-1, i.e. the most likely combination of the identity and payout rate of the high reward option.</p><p>Over all participants and all runs, CPP moderately correlated with entropy (mean Pearsonâs r over all participants 0.37, SEM 0.0055) and weakly correlated with relative uncertainty (mean Pearsonâs r 0.20, SEM 0.0053). Conceptually, CPP differs from both entropy and relative uncertainty in that CPP measures only the probability of a change point given the current observation, whilst entropy and relative uncertainty integrate information across multiple trials. This can be seen in the example plot of entropy, relative uncertainty and CPP, in which CPP rises and falls on a single trial basis whilst entropy and relative uncertainty vary more smoothly over trials (<xref ref-type="fig" rid="app1fig1">Appendix 1âfigure 1</xref>).</p></sec><sec id="s7-3"><title>Predicting participantsâ choices</title><p>Although the purpose of our modelling was to provide trial-by-trial regressors to relate to neural responses, rather than to optimally capture behaviour, we checked our model was a reasonable fit to behaviour. To determine whether our model was a reasonable fit to the behaviour of our participants, we defined an action policy by fitting a softmax function for each participant and run, in which the model probabilities assigned to each option (of being the high reward option) were used to predict option choice, with softmax temperature as a free parameter. The modelâs predicted choice (defined as the option with the highest probability under the softmax) matched the participantsâ actual choices on 94.2% of exploit trials (averaged over all participants; SEM 0.70% across participants) and 31.5% (SEM 1.3%) of explore trials.</p><p>Arguably it is more appropriate to fit two separate softmax functions with independent temperature parametersÂ for explore and exploit phases of the task, since behaviour may be qualitatively different in the two cases (for example, behaviour could be more random in the explore phase, which would be reflected in a higher softmax temperature). When we fit softmax functions separately to explore and exploit trials, with temperature as an independent free parameter for each trial category, 96.0% of exploit trials (SEM 0.57%) and 50.9% of explore trials (SEM 1.8%) were predicted correctly. Notably the proportion of explore trials predicted correctly exceeded the expected proportion if people chose at random during explore phases, which would be 25% (one sample t-test comparing the proportion correctly classified to 25% across participants: t<sub>18</sub>Â =Â 13.2, p=5.2Ã10<sup>â11</sup>).</p><p>We compared the overall model log likelihood for the Bayesian model with a single softmax policy, and two softmax policies (fitted separately to explore and exploit periods) to two further models, which should represent a ceiling in terms of how well the model matches the actual data, in that they are fit to participantsâ responses rather than to latent variables reflecting participantsâ modelled beliefs. The first comparison model was a model in which the probability of choosing the selected option was always one during exploit periods and always 0.25 during explore periods. We call this the âall or noneâ model because its behaviour is totally deterministic during exploit periods and totally random during explore periods. The second comparison model was a Hidden Markov Model (HMM) described below in which behaviour was classified as âexploreâ or âexploitâ based on block length, and then the probability of choosing the selected option was always one during exploit periods and always 0.25 during explore periods as for the all-or-none model. In each case the model log likelihood was defined as the log likelihood of the model making the same choice as the human observer, summed over all trials.</p><p>Over all participants, the HMM had the best model log likelihood (mean over all participants = â165), closely followed by the Bayesian model with two separate softmax policies (â179). Both models did much better than the all-or-none model (â308) and the Bayesian model with a single softmax policy (â473). Model log likelihoods for all models are shown in <xref ref-type="fig" rid="app1fig2">Appendix 1âfigure 2</xref>.</p><fig id="app1fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.021</object-id><label>Appendix 1âfigure 2.</label><caption><title>Model log likelihoods for each participant and each model, based on predicting participantsâ choices across all trials.</title><p>Taken together, the model comparison suggests that the Bayesian model, when allowed to adopt different softmax policies in explore and exploit phases, performs very comparably to a model fitted directly to participantsâ behaviour (the HMM). Importantly, because the Bayesian model simulates latent states of belief uncertainty (model entropy, relative uncertainty) even when behaviour is held constant during exploitation periods, it provides useful information over and above that given by the HMM (which does not model belief uncertainty at all). A second notable point is that the Bayesian model (with double softmax policy) does predict participantsâ behaviour during explore periods. In contrast, the all-or-none model (which performed much worse than the Bayesian model with double softmax policy) sets an upper bound on the model log likelihood that could be achieved if behaviour in the explore period was random (as the probability of the chosen option during exploit periods is one and therefore model log likelihood is maximized in these periods).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-app1-fig2-v1.tif"/></fig></sec><sec id="s7-4"><title>Does belief uncertainty predict Explore-Exploit transitions?</title><p>An important feature of our model based approach was that we were able to model belief uncertainty as entropy or relative uncertainty in the modelâs hypothesis space. To confirm the validity of this approach, we asked whether high entropy, relative uncertainty or change point probability made participants more likely to transition from exploiting an option to exploration.</p><p>Limiting our analysis to trials classified as âexploitâ, we used logistic regression to ask whether the probability of switching option on trial tÂ +Â 1, given that a trial t was unrewarded, depended on the relative uncertainty, entropy or change point probability on trial t (three separate regression analyses). We limited the analysis to cases where trial t was unrewarded, because participants switched chosen option only following unrewarded trials (mean proportion of switch trial following an unrewarded trialÂ =Â 97.4% across all participants and runs). 21% of all trials over all participants were both classified as exploit and unrewarded and hence used in this analysis.</p><p>Both higher entropy and higher relative uncertainty predicted a higher probability of switching (entropy - t<sub>18</sub>Â =Â 7.60, p=2.57Ã10<sup>â7</sup>; relative uncertainty - t<sub>18</sub>Â =Â 13.50, p=3.7Ã10<sup>â11</sup>).</p><p>Interestingly, high change point probability on a given trial t predicted a lower probability of switching (change point probability - t<sub>18</sub>Â =Â 6.45, p=2.28Ã10<sup>â6</sup>). The reason for this can be seen in <xref ref-type="fig" rid="app1fig3">Appendix 1-figure 3</xref> in which change point probability for the trials in the run up to an exploit-explore transition is plotted. It is evident that CPP actually peaks 2â3 trials before the transition (<xref ref-type="fig" rid="app1fig3">Appendix 1-figure 3</xref>). This lag is reflective of the fact that CPP is driven primarily by reward omission on the current trial t, whilst participantsâ behaviour is guided by integrating outcomes over multiple trials, and thus participants were unlikely to switch on an unrewarded trial, unless other recent trials were also unrewarded. The proportion of exploit-explore transitions for which trial t-1, t-2 and t-3 were unrewarded was (meanÂ Â±SEM across participants): 13.1% (Â±2.36%), 57.5% (Â±6.4%) and 73.9% (Â±2,6%) respectively.</p><fig id="app1fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.022</object-id><label>Appendix 1âfigure 3.</label><caption><title>Change point probability in the trials leading up to, and following, the transition from exploit- to explore phase.</title><p>The last exploit trial is coded as â1, the first explore trial asÂ +1 (there is no trial zero in this plot). CPP peaks on the penultimate trial of the exploit block, or the trial before that.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-app1-fig3-v1.tif"/></fig><p>Both entropy and relative uncertainty are measures of the belief uncertainty that arises from reward omission integrated over multiple trials. To obtain a model-agnostic view of factors predicting exploit-explore transitions, we performed a logistic regression (limited to unrewarded trials in exploit periods) using reward omission on the previous four trials (t-1 to t-4) as explanatory variables. Reward omission on trials t-1 and t-2 significantly predicted option switching (i.e. exploit-explore transitions); on trial t-3 the effect was just n.s. and on trial t-4 the effect was clearly n.s. (p values for trials t-1 to t-4 respectively: 3.81 Ã 10<sup>â6</sup>, 7.63 Ã 10<sup>â5</sup>, 0.064, 0.65 â non-parametric sign test used as the regression coefficients were grossly non-normal across the group). These results further confirm that participants integrated reward omission over 3â4 trials (including the final exploit trial, t) to drive exploit-explore transitions.</p></sec><sec id="s7-5"><title>Classification of behaviour into Explore and Exploit phases</title><p>Throughout the main manuscript we used a heuristic method to define exploitation periods. We defined the start of a period of exploitation as the first trial on which participants selected the true high reward probability option and received reward, and the end of the exploit period as the last trial before switching to a different option (thus within exploit periods, by definition, all choices were for the same option). We furthermore defined âcore exploitâ trials as trials within an exploit block, more than five trials from the preceding and following changes of action. The primary aim of this heuristic was to identify, in a conservative way, trials that we could be confident represented stable exploitation behaviour. This was important because we wanted to carry out a number of analyses only on âcore exploitâ trials â trials where overt behaviour was stable but belief certainty varied.</p><p>It is possible to take a more principled, model-based approach to the definition of explore and exploit phases of the task and we present such an analysis here to justify the use of our heuristic.</p><p>Ebitz and colleagues (<xref ref-type="bibr" rid="bib7">Ebitz et al., 2018</xref>) gave careful consideration to how trials may be classified as explore or exploit in a task similar but not identical to the present task (three arm bandit with independently drifting bandit values; the present task is a four arm bandit but the bandit values are tied to each other). They concluded that a Hidden Markov Model (HMM) may be used to classify trials into explore- and exploit- states, based on block length. They fitted a double exponential distribution to block lengths, with the logic that block lengths are shorter in explore periods and longer in exploit periods. They then fitted a hidden Markov model to participantsâ choices, in which the hidden states were exploit (one state per option) or explore.</p><p>We used the same approach to classify trials as explore or exploit in the present task. The hidden states were {exploit option 1, exploit option 2, exploit option 3, exploit option 4, explore}. In each exploit state the only possible observation was the selection of the exploited option. In the explore state all options were equally likely to be selected. Transitions were possible (end equally likely) from the explore state to any exploit state. Transitions were also possible from each exploit state to the explore state, but not directly to another exploit state. The probabilities of transitioning between states were determined by the fitted time constants of the block length distributions for explore- and exploit- states; where <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was the time-constant of the fitted exponential distribution of block lengths in the explore condition, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>Î²</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>Â was the probability of transitioning from exploration to an (any) explore state; as all exploit states were equally likely, the probability of transition to any given exploit state wasÂ <inline-formula><mml:math id="inf18"><mml:mfrac bevelled="true"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula>. Similarly where <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was the time-constant of the fitted exponential distribution of block lengths in the exploit condition, <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula>Â was the probability of transitioning from an exploitation state to the explore state. Transitions directly between exploit states had probability zero.</p><p>The classification of trials as âexploitâ and âcore exploitâ by our heuristic and the Ebitz approach can be compared in <xref ref-type="fig" rid="app1fig4">Appendix 1âfigure 4</xref>. The critical trial group used for the analysis of stable exploit periods, called âcore exploitâ, wasÂ defined as exploit trials more than five trials from the nearest explore trial. In this trial group the two models were concordant in that almost all trials classified as âcore exploitâ by our heuristic were also classified as âcore exploitâ by the HMM approach (meanÂ Â±SEM across participants: 97.3%Â Â±Â 0.37%).</p><fig id="app1fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.39404.023</object-id><label>Appendix 1âfigure 4.</label><caption><title>Explore and Exploit phases extracted by the Ebitz model.</title><p>Trials classified as âexploitâ (light grey) and âcore exploitâ (dark grey) using our heuristic method (top) and the HMM method (bottom) for each of the 19 participants included in the main analysis. The HMM method tends to classify more trials as âexploitâ but because these are often short blocks, the trials classified as âcore exploitâ, used in all the multivariate analyses in the paper, are very similar for both classification methods.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-39404-app1-fig4-v1.tif"/></fig><p>Conversely, the HMM approach classified some additional trials as core exploit, which were not so-classified by our heuristic (meanÂ Â±SEM across participants: 7.8%Â Â±Â 1.3%). By definition, these excess exploit trials arise when participants erroneously select a low reward option for a long period of time, even though it had never (within that exploit phase) been the high reward option. For this reason, these additional exploit trials could be interpreted as periods of off-task behaviour. During the additional exploit trials, model entropy is likely high (as by definition participants are selecting a low-reward option and thus experiencing many reward omissions), but representational strength in any internal model would likely be low (due to disengagement from the task). We thus felt that the inclusion of these additional trials could artificially inflate the relation between model entropy and representation strength and chose to use our more conservative although heuristic approach throughout.</p></sec></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39404.029</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Gershman</surname><given-names>Samuel J</given-names></name><role>Reviewer</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Meyniel</surname><given-names>Florent</given-names> </name><role>Reviewer</role><aff><institution>CEA</institution><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>[Editorsâ note: the authors were asked to provide a plan for revisions before the editors issued a final decision. What follows is the editorsâ letter requesting such plan.]</p><p>Thank you for sending your article entitled &quot;Control of entropy in neural models of environmental state&quot; for peer review at <italic>eLife</italic>. Your article is being evaluated by Michael Frank as the Senior Editor, Tobias Donner as the Reviewing Editor and three reviewers. The following individuals involved in review of your submission have agreed to reveal their identity: Samuel J Gershman (Reviewer #2).</p><p>Given the list of essential revisions, including new experiments, the editors and reviewers invite you to respond within the next two weeks with an action plan and timetable for the completion of the additional work. We plan to share your responses with the reviewers and then issue a binding recommendation.</p><p>Summary:</p><p>The authors investigate how learners maintain flexibility, a necessary feature of learning in dynamic environments. They propose that noradrenaline increases posterior uncertainty in the currently held representation, thereby maintaining flexibility and counteracting the decrease in uncertainty that is entailed by accumulating more observations. They provide evidence in favor of this hypothesis by means of pupillometry and fMRI. They further propose that the current representation, whose uncertainty is increased by noradrenaline, is encoded in the medial orbitofrontal cortex and that the anterior cingulate cortex detects when the current model is no longer valid and signals it to the locus-coeruleus â noradrenaline system.</p><p>Overall, the reviewers found this work interesting. The reported results provide a potentially exciting link between two rapidly evolving domains in computational and cognitive neuroscience. The authors employ some clever analyses; the dissociation between state uncertainty and action variability, in particular, is a nice feature of the analysis.</p><p>But all reviewers also raised substantial concerns, of either conceptual or technical nature, which would need to be addressed before this paper can be reconsidered for publication at <italic>eLife</italic>. The conceptual concerns hover around the mechanistic interpretation of the results: reviewers did not feel like the modeling, and the link between model and physiology, were as clear as they could have been.</p><p>We realize that addressing all the essential points below might be challenging within the relatively short period of time intended for the revision process at <italic>eLife</italic>, and hence we would like you to prepare a response and action plan.</p><p>Essential revisions:</p><p>1) Please provide a detailed model-based analysis of participants' behavior, ideally comparing the current model to other plausible ones.</p><p>Currently, none of your analyses shows how well the model accounts for participants' behavior. The model doesn't even define a policy, so it doesn't address the explore-exploit trade-off directly. Modeling behavior is important both in order to state clearly a mechanistic hypothesis about choice behavior, and to show empirically that such a model is supported by the data.</p><p>Modeling behavior would be critical, for example, to determine whether the representational change in OFC reflects some multi-faceted entropy measure as might be predicted by a &quot;state&quot; account of OFC representation, or over-representation of an error signal during periods of high arousal, which would also be consistent with ideas about value signals in OFC.</p><p>By the same token, your primary behavioral figure shows that participants switched more under conditions of high entropy, but this is quite highly correlated with the actual trial outcome. Does the model-based entropy measure affect participant behavior beyond simple win-stay lose-shift or reinforcement learning effects? If so, what are the additional aspects of task environment (e.g. feedback validity, prior feedback history) that jointly affect entropy measures and switching behavior?</p><p>2) Please unpack your mechanistic reasoning with regards to entropy. You put forward the idea (i) that posterior uncertainty always decreases with more observations, and therefore (ii) that some specific mechanism must &quot;drive up entropy&quot; in dynamic environments, and they look for such a mechanism in this paper. The reviewers understand this can be an interpretation of a leaky accumulation process, in which the leak &quot;drives up entropy&quot; (ii) and the accumulation &quot;decreases posterior uncertainty&quot; (i). But it is not entirely clear from the perspective of Bayesian inference. Specifically, reviewers raised two issues in this context.</p><p>2a) It is not generally true that posterior entropy decreases with more observations.</p><p>You state (Introduction): &quot;if beliefs about the environment are expressed as a posterior distribution over possible states, the entropy, or uncertainty, of this posterior decreases as the number of concordant data points increases.&quot; Whether or not this is a mathematically correct statement depends on what is meant by &quot;concordant&quot; (which does not seem to be a technical concept). There are plenty of cases where posterior entropy will increase as more data arrive. For example, if you initially strongly believe that a coin is biased to produce heads and then you observe tails, then your posterior will be higher entropy than your prior. (This also comes up later on the same page: &quot;If the 'leak' were removed, the model entropy would still decrease with each new observation, as this is a natural consequence of gaining information&quot;).</p><p>2b) It is not clear why a dedicated mechanism would be required to &quot;drive up&quot; or &quot;inject&quot; entropy.</p><p>Reviewers do not understand why a Bayesian model of inference must &quot;counter&quot; inflexibility by &quot;injecting&quot; entropy. There is nothing, mathematically speaking, that requires a model of (presumably human) inference to inject entropy. Also, talking about mechanisms like &quot;leak&quot; seem to be confusing algorithmic/implementational level concerns with the computational-level analysis of the internal probabilistic model (see point 3a below). The &quot;leak&quot; in the Behrens et al. (2007) model, for example, comes directly from assumptions about volatility; it's not a mechanism that is &quot;injected&quot; into the model to increase entropy. The two computations called (i) and (ii) above are a direct consequence of probability calculus (subsection âBayesian learning modelâ). Equation 6 in subsection âBayesian learning modelâ shows that the assumption of non-stationarity (s &gt; 0) counterbalances, and may even override, the decrease in posterior uncertainty by constantly injecting a uniform prior in the inference. There is no need to further &quot;drive up entropy&quot;. Thus, reviewers feel that the statement in the Introduction: &quot;â¦ injecting uncertainty back into the model's state estimate to make rapid changes of belief possible&quot; needs to be qualified or dropped.</p><p>3) There are other mechanistic concepts and related terminology, which should be clarified.</p><p>3a) In general, the Introduction tends to conflate the computational level of analysis with the level of the biological mechanisms. Reviewers feel it would help to more carefully separate those two.</p><p>3b) In choosing your definition of exploitation, you try to rely on &quot;as few assumptions or arbitrary cut-offs as possible&quot; (Results section). Reviewers don't think that's possible. The definition of exploitation you adopted (the first trial on which participants selected the true high reward probability option and received reward) is arguably just as arbitrary as other sensible definitions. An agent in an exploratory mode will place some probability on this option, and hence its selection does not reliably indicate exploitation. Assumptions are inescapable, and it's better to adopt a model-based definition. But until the policy is defined explicitly, this is not possible.</p><p>3c) Reviewers do not understand the statement that uncertainty increases on unrewarded trials (subsection âNoradrenaline as a candidate mechanism for increasing flexibility of belief representationsâ). It's mathematically possible (though relatively unlikely) that uncertainty will increase on unrewarded trials, if subjects have low confidence during an exploitation phase.</p><p>3d) The following statement (Introduction) may be incorrect depending on how one interprets the terminology: &quot;the better established one's model of the environment, the less flexible one's beliefs are.&quot; This depends on what &quot;flexible&quot; and &quot;established&quot; mean. If flexibility means something like the degree to which the posterior can deviate from the prior when new data arrive (e.g., expected KL-divergence), and if &quot;established&quot; means lower prior entropy, then one can conceive situations where the claim is incorrect.</p><p>4) Please elaborate on the decoding analysis.</p><p>4a) You look for a region that shows &quot;stronger [decoded] representation strength for the currently selected option when model entropy is low&quot;, which should be a hallmark of a probabilistic model. It would be more natural to look for the posterior distribution of option values, rather than a representation of the selection option. It actually looks like it is the representation decoded in mOFC here. Indeed, if the representation decoded is that of the selected option, then it does not really make sense that the classifier's probability is actually lowest for the current option (compared to other options) in the high entropy condition (Figure 2C). By contrast, this result is expected for the option value. As seen on Figure 1C, when posterior entropy is highest in exploitation periods (the ones analyzed here), the value of the currently selected option tends to be the lowest.</p><p>4b) From the same basic perspective, the representational analyses could better clarify the source of the effects, rather than lumping everything into entropy. A difference in decoding reliability driven by differences in error versus correct trials is a rather different effect than one that emerges across feedback-validity conditions when accounting statistically for feedback history. The error versus correct distinction is one where the difference in frequency of these two conditions might lead to artificially low estimates of decoding reliability in error trials, which, given larger pupil responses on error trials, could make interpretation of the OFC pupil results fairly tricky. By this token, one could argue that a number of the findings reported in OFC [general uncertainty, choice-specific belief, and 70% vs 90% in the same regions (subsection âMedial OFC represents probabilistic beliefs about the state of the environmentâ and Figure 2âsupplement 1)] could all be driven by a conjunctive code over feedback and option value, rather than by the tracking of reliability weighted state representations.</p><p>5) Please substantiate claims about temporal precedence.</p><p>The results are interpreted in terms of temporal precedence with the implicit assumption being that pupil diameter prior to outcome presentation relates to subsequent reliability of OFC representations. However, since pupil diameter, BOLD responses, and entropy all likely contain fairly strong autocorrelations, it would be useful if you could better test this assumption by determining whether the relationships hold even after shifting the pupil and OFC signals in time relative to one another (e.g. does OFC representation reliability predict pupil diameter on subsequent trial?).</p><p>6) Please provide a more comprehensive characterization of LC responses, and the methods used to detect them.</p><p>You should show the actual response time courses, rather than only statistical maps. You should also show the correlation between the LC and pupil responses. There is a dispute in the literature about the feasibility of LC imaging and the pitfalls and physiological artefacts (e.g. Astafiev, 2010; de Gee et al., 2017). Please also provide more information in Materials and methods section â did you correct for physiological noise (using RETROICOR or related approaches)? If not, it might be better to take the LC findings out altogether and focus on the pupil. Finally, some of your claims seem to require that the effects should specific to the LC-NA system. Substantiating this claim would require contrasting LC responses to responses of other brainstem regions.</p><p>7) Please elaborate on the representation of the relevant prior literature.</p><p>There is a whole literature on this topic, which is only scarcely referred to. The following references (potentially more) should be included:</p><p>â Iigaya, 2016 presents a mechanistic view for driving up entropy with noradrenaline, with the idea that a surprise detection module is used to reset (by means of noradrenaline) the representation currently hold and stored in synapses.</p><p>â Meyniel and Dehaene, 2017 for waning and waxing of posterior uncertainty and its neural (fMRI) representation</p><p>â Pulcu and Browning, 2017 on pupil size variations with volatility</p><p>â Krishnamurthy, Nassar and Gold, 2017 on a link between pupil size and the balance between prior and current evidence in uncertain environments</p><p>â de Gee et al., 2017 for showing that fMRI responses in the human LC, but also other neuromodulatory brainstem nuclei, correlate with pupil dilation. In that regard, please tone down the statement that pupil dilation is a specific marker of LC activity (how specific this link is, has rarely been tested directly and the few studies that did, in humans, monkey, and rodents, founds links to several brainstem systems).</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your article &quot;Control of entropy in neural models of environmental state&quot; for further consideration by <italic>eLife</italic>. Your revised article has been favorably evaluated by a Reviewing Editor, a Senior Editor and three peer reviewers.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below.</p><p>Summary:</p><p>All three reviewers and the Reviewing Editor were overall happy with the revisions and think that the paper has become much clearer. All remain convinced that the paper addresses an important and interesting topic. One reviewer still voiced three major concerns and suggested ways of addressing them through textual revisions, plus one possible additional analysis. We feel that addressing these points through textual revisions, and toning down certain parts of the conclusions, would be essential for publication. We leave it to the authors to decide whether or not perform the additional analysis suggested.</p><p>Essential revisions:</p><p>1) Mathematical constructs that motivate the study and analysis.</p><p>The authors now clearly decompose the inference into (1) computing a posterior distribution and (2) turning this posterior distribution into a predictive distribution by applying a transition-function which, if volatility is assumed, blunts the posterior. Using this (clear) terminology, they then say, &quot;we investigate the hypothesis that the brain has a mechanism for increasing entropy in internal models that is analogous to the transition-function update described above&quot;. It seems that their analysis cannot be in line with this, since in their experiment, volatility (the rate of change) is constant, therefore the transition-function is constant, and it is impossible to correlate a brain/pupil signal with it or claim that a brain mechanism has been found for it. We suggest further editing the Introduction clarify this aspect.</p><p>2) Effect of entropy on representation strength.</p><p>It remains that the decoding results are not fully in line with the cartoon illustration in Figure 1B, in particular, that decoding is not significant in the high entropy condition. Instead, it looks like an effect of value, and indeed the effect is significant in GLM 4 testing reward probability.</p><p>We are concerned that the control (point 4, second part, in the response letter) for the contribution of value may not have been adequate. They regressed out, voxel-wise, the linear effect of value. The analysis in the (univariate) residuals does not preclude that there remains multivariate activity related to value, which, if correlated with entropy, will boost the effect of entropy. The conserve approach may be more appropriate: value should be regressed out from entropy, then if the correlation between representation strength (derived from the decoder) and residual entropy remains significant and negative, it will be convincing that the effect is not confounded by value.</p><p>We realize that this control analysis may not be possible with the current design (strong negative correlation between value and entropy) â if that is the case, then the claim about a specific involvement of entropy should be toned down.</p><p>3) Effect of noradrenaline.</p><p>The authors opted for removing the LC-fMRI results about which we had technical concerns. So, their claim about noradrenaline now relies entirely on the pupil data, but this overly specific conclusion is not supported by the available data. Specifically, the authors quote Joshi et al., 2016 to relate baseline pupil size (which is central in their analysis) to noradrenaline levels, but the quoted paper in fact shows that LC activity is specifically related to <italic>changes</italic> in pupil size. Reimer et al., 2016 go further in showing that pupil dynamics is correlated to both, noradrenaline <italic>and</italic> acetylcholine-release, and the former is more strongly related to the fast dilations of the pupil whereas the latter is more strongly related to slow variations in pupil size, which would correspond to fluctuations in baseline pupil size in the current paper. The authors should refrain from linking their results specifically to the LC-NA system; they should link their results to &quot;pupil-linked arousal&quot;. They can go on to speculate that the LC-NA system might play a key role in their findings, but then they would need to acknowledge that their slow baseline pupil size effects would be more in line with a cholinergic effect. It does not seem to match well with the influential accounts in this field, but we need to take this recent evidence from careful experiments into neuromodulatory correlates of pupil dynamics seriously.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.39404.030</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors' note: the authorsâ plan for revisions was approved and the authors made a formal revised submission.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Please provide a detailed model-based analysis of participants' behavior, ideally comparing the current model to other plausible ones.</p><p>Currently, none of your analyses shows how well the model accounts for participants' behavior. The model doesn't even define a policy, so it doesn't address the explore-exploit trade-off directly. Modeling behavior is important both in order to state clearly a mechanistic hypothesis about choice behavior, and to show empirically that such a model is supported by the data.</p><p>Modeling behavior would be critical, for example, to determine whether the representational change in OFC reflects some multi-faceted entropy measure as might be predicted by a &quot;state&quot; account of OFC representation, or over-representation of an error signal during periods of high arousal, which would also be consistent with ideas about value signals in OFC.</p><p>By the same token, your primary behavioral figure shows that participants switched more under conditions of high entropy, but this is quite highly correlated with the actual trial outcome. Does the model-based entropy measure affect participant behavior beyond simple win-stay lose-shift or reinforcement learning effects? If so, what are the additional aspects of task environment (eg. feedback validity, prior feedback history) that jointly affect entropy measures and switching behavior?</p></disp-quote><p>We carried out the following further behavioural analysis:</p><p>a) We added a soft max policy to our model to predict trialwise choice and calculate model log likelihood. This is reported in Appendix 1 subsection âPredicting participantsâ choicesâ, and Appendix 1âfigure 2.</p><p>b) We implemented the change point model of Wilson and colleagues (requires adapting from the original continuous hypothesis space to the discrete hypothesis space of the current experimental paradigm) to obtain alternative measures of uncertainty (Relative Uncertainty and Change Point probability). Nassar et al., 2012. This is reported in Appendix 1, subsections âRelative uncertaintyâ and âChange point probabilityâ, and Appendix 1âfigures 1, 2, and 3.</p><p>c) We implemented the Hidden Markov Model of Ebitz et al. 2018 to obtain an alternative definition of explore/exploit trials and an alternative prediction of trialwise choice. This is reported in Appendix 1 subsection âClassification of behaviour into Explore and Exploit phasesâ and Appendix 1âfigure 4.</p><p>d) We did a non model-based (GLM) analysis to determine how well patch leaving (exploit-explore switch) is predicted by recent feedback history (reward omission on trials t-1, t-2 etc) and compared to how well patch-leaving is predicted by entropy. This is reported in Appendix 1 subsection âDoes belief uncertainty predict Explore-Exploit transitions?â.</p><disp-quote content-type="editor-comment"><p>2) Please unpack your mechanistic reasoning with regards to entropy. You put forward the idea (i) that posterior uncertainty always decreases with more observations, and therefore (ii) that some specific mechanism must &quot;drive up entropy&quot; in dynamic environments, and they look for such a mechanism in this paper. The reviewers understand this can be an interpretation of a leaky accumulation process, in which the leak &quot;drives up entropy&quot; (ii) and the accumulation &quot;decreases posterior uncertainty&quot; (i). But it is not entirely clear from the perspective of Bayesian inference. Specifically, reviewers raised two issues in this context.</p><p>2a) It is not generally true that posterior entropy decreases with more observations.</p><p>You state (Introduction): &quot;if beliefs about the environment are expressed as a posterior distribution over possible states, the entropy, or uncertainty, of this posterior decreases as the number of concordant data points increases.&quot; Whether or not this is a mathematically correct statement depends on what is meant by &quot;concordant&quot; (which does not seem to be a technical concept). There are plenty of cases where posterior entropy will increase as more data arrive. For example, if you initially strongly believe that a coin is biased to produce heads and then you observe tails, then your posterior will be higher entropy than your prior. (This also comes up later on the same page: &quot;If the 'leak' were removed, the model entropy would still decrease with each new observation, as this is a natural consequence of gaining information&quot;).</p><p>2b) It is not clear why a dedicated mechanism would be required to &quot;drive up&quot; or &quot;inject&quot; entropy.</p><p>Reviewers do not understand why a Bayesian model of inference must &quot;counter&quot; inflexibility by &quot;injecting&quot; entropy. There is nothing, mathematically speaking, that requires a model of (presumably human) inference to inject entropy. Also, talking about mechanisms like &quot;leak&quot; seem to be confusing algorithmic/implementational level concerns with the computational-level analysis of the internal probabilistic model (see point 3a below). The &quot;leak&quot; in the Behrens et al. (2007) model, for example, comes directly from assumptions about volatility; it's not a mechanism that is &quot;injected&quot; into the model to increase entropy. The two computations called (i) and (ii) above are a direct consequence of probability calculus (subsection âBayesian learning modelâ). Equation 6 in subsection âBayesian learning modelâ shows that the assumption of non-stationarity (s &gt; 0) counterbalances, and may even override, the decrease in posterior uncertainty by constantly injecting a uniform prior in the inference. There is no need to further &quot;drive up entropy&quot;. Thus, reviewers feel that the statement in the Introduction: &quot;â¦ injecting uncertainty back into the model's state estimate to make rapid changes of belief possible&quot; needs to be qualified or dropped.</p></disp-quote><p>We accept the reviewersâ points and have redrafted the Introduction accordingly. We are not quoting all individual changes here since we did a complete redraft of the Introduction.</p><disp-quote content-type="editor-comment"><p>3) There are other mechanistic concepts and related terminology, which should be clarified.</p><p>3a) In general, the Introduction tends to conflate the computational level of analysis with the level of the biological mechanisms. Reviewers feel it would help to more carefully separate those two.</p></disp-quote><p>We accept the reviewersâ points and have redrafted the Introduction accordingly. We are not quoting all individual changes here since we did a complete redraft of the Introduction.</p><disp-quote content-type="editor-comment"><p>3b) In choosing your definition of exploitation, you try to rely on &quot;as few assumptions or arbitrary cut-offs as possible&quot; (Results section). Reviewers don't think that's possible. The definition of exploitation you adopted (the first trial on which participants selected the true high reward probability option and received reward) is arguably just as arbitrary as other sensible definitions. An agent in an exploratory mode will place some probability on this option, and hence its selection does not reliably indicate exploitation. Assumptions are inescapable, and it's better to adopt a model-based definition. But until the policy is defined explicitly, this is not possible.</p></disp-quote><p>The Ebitz paper cited above gives careful consideration to how trials may be classified as explore or exploit. In the paper we now present results of defining explore/exploit periods using this HMM approach but decided to keep our heuristic approach for the main analyses as it is actually more conservative.</p><p>This is reported in Appendix 1 subsection âClassification of behaviour into Explore and Exploit phasesâ and Appendix 1âfigure 4.</p><disp-quote content-type="editor-comment"><p>3c) Reviewers do not understand the statement that uncertainty increases on unrewarded trials (subsection âNoradrenaline as a candidate mechanism for increasing flexibility of belief representationsâ). It's mathematically possible (though relatively unlikely) that uncertainty will increase on unrewarded trials, if subjects have low confidence during an exploitation phase.</p></disp-quote><p>We have edited this sentence to make clear that it is possible, but unlikely, that uncertainty would increase on rewarded trials.</p><disp-quote content-type="editor-comment"><p>3d) The following statement (Introduction) may be incorrect depending on how one interprets the terminology: &quot;the better established one's model of the environment, the less flexible one's beliefs are.&quot; This depends on what &quot;flexible&quot; and &quot;established&quot; mean. If flexibility means something like the degree to which the posterior can deviate from the prior when new data arrive (e.g., expected KL-divergence), and if &quot;established&quot; means lower prior entropy, then one can conceive situations where the claim is incorrect.</p></disp-quote><p>We accept the reviewersâ points and have redrafted the Introduction accordingly. We are not quoting all individual changes here since we did a complete redraft of the Introduction.</p><disp-quote content-type="editor-comment"><p>4) Please elaborate on the decoding analysis.</p><p>4a) You look for a region that shows &quot;stronger [decoded] representation strength for the currently selected option when model entropy is low&quot;, which should be a hallmark of a probabilistic model. It would be more natural to look for the posterior distribution of option values, rather than a representation of the selection option.</p></disp-quote><p>We said in our response plan that we would attempt to decode the full posterior from mOFC.</p><p>However, when we came to do this analysis, we found that within core exploit trials (the trials that went into the fMRI analysis) it was not possible to dissociate the model probability associated with the three unchosen options from each other or from the probability associated with the chosen option. This is because on core exploit trials, by definition none of the unchosen options have been sampled for at least 5 trials. Therefore, most of the evidence informing the probabilities assigned to these options is in fact based on the sampling of the chosen option (i.e., if the chosen option is less likely to be correct based on recent feedback, all other options are upweighted equally). The average correlation matrix between the model probabilities for chosen option and the three other options (ordered from most to least probable under the model) is given in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>. As can be seen from this matrix, decoding the probability that the chosen option is correct is virtually equivalent, under the model, to decoding the full posterior over all 4 options. This is an inescapable feature of the design of our task.</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-39404-resp-fig1-v1"/></fig><p>The correlation matrix shows that the probability assigned to the exploited option is anticorrelated with that assigned to each of the other three, which themselves are all highly correlated.</p><disp-quote content-type="editor-comment"><p>It actually looks like it is the representation decoded in mOFC here. Indeed, if the representation decoded is that of the selected option, then it does not really make sense that the classifier's probability is actually lowest for the current option (compared to other options) in the high entropy condition (Figure 2C). By contrast, this result is expected for the option value.</p></disp-quote><p>To address the question, we repeated the decoding analysis (of option value) after having regressed out the effect of value, and the effect of recent feedback (reward omission on the current trial and previous 4 trials) from the signal at each voxel in the mOFC ROI. We were still able to decode chosen option identity from mOFC and the representation strength was proportional to model entropy.</p><p>We would like to point out, and have clarified in the manuscript, that we are not claiming that value/ feedback are not represented in mOFC. Indeed, model entropy is closely related to both option value and feedback history. The point is that we attempted to decode the <italic>identity</italic> of the chosen option (and hence, the current state of the environment) from mOFC, and found that entropy/value/feedback history modulated the strength with which one state representation dominated the activity pattern. Thus, the pattern of activity in mOFC represents a conjunctive code of state and confidence in that state, or state and value of that state, which are closely correlated in the current paradigm (as they would be in most RL paradigms).</p><p>Representation strength in mOFC was better predicted by model entropy than by the value of the chosen option; however, these two measures were rather closely correlated and were both related to recent feedback history. Because model entropy and option value both depended, within our learning model, on feedback history, this is to be expected; we cannot distinguish between these conceptually and statistically related constructs.</p><disp-quote content-type="editor-comment"><p>As seen on Figure 1C, when posterior entropy is highest in exploitation periods (the ones analyzed here), the value of the currently selected option tends to be the lowest.</p></disp-quote><p>Note that in Figure 2C, the probability of decoding the current option is not actually significantly below chance, we think it is around chance and appears below chance due to noise.</p><disp-quote content-type="editor-comment"><p>4b) From the same basic perspective, the representational analyses could better clarify the source of the effects, rather than lumping everything into entropy. A difference in decoding reliability driven by differences in error versus correct trials is a rather different effect than one that emerges across feedback-validity conditions when accounting statistically for feedback history. The error versus correct distinction is one where the difference in frequency of these two conditions might lead to artificially low estimates of decoding reliability in error trials, which, given larger pupil responses on error trials, could make interpretation of the OFC pupil results fairly tricky. By this token, one could argue that a number of the findings reported in OFC [general uncertainty, choice-specific belief, and 70% vs 90% in the same regions (subsection âMedial OFC represents probabilistic beliefs about the state of the environmentâ and Figure 2âsupplement 1)] could all be driven by a conjunctive code over feedback and option value, rather than by the tracking of reliability weighted state representations.</p></disp-quote><p>We asked for clarification on this point and it was agreed that the analyses described in response to the previous point should address this point also.</p><disp-quote content-type="editor-comment"><p>5) Please substantiate claims about temporal precedence.</p><p>The results are interpreted in terms of temporal precedence with the implicit assumption being that pupil diameter prior to outcome presentation relates to subsequent reliability of OFC representations. However, since pupil diameter, BOLD responses, and entropy all likely contain fairly strong autocorrelations, it would be useful if you could better test this assumption by determining whether the relationships hold even after shifting the pupil and OFC signals in time relative to one another (eg. does OFC representation reliability predict pupil diameter on subsequent trial?).</p></disp-quote><p>We have repeated the pupil-representation strength analysis shifting the trials used in the analysis by one trial either way (so pupil on trial t is paired with representation strength on trial t+1 or t-1). The analysis does not yield significant results if we make these shifts, suggesting the association is relatively specific to each trial.</p><p>This is reported in Results section of the manuscript, statement beginning âTo test the temporal specificity of the resultâ¦â</p><p>We should point out that we are not trying to make a strong claim about temporal precedence. We are simply saying that pupil dilation changes and representation strength changes tend to co-occur on the same trial as each other, as would be expected if internal models are updated on a trial-by-trial basis.</p><disp-quote content-type="editor-comment"><p>6) Please provide a more comprehensive characterization of LC responses, and the methods used to detect them.</p><p>You should show the actual response time courses, rather than only statistical maps. You should also show the correlation between the LC and pupil responses. There is a dispute in the literature about the feasibility of LC imaging and the pitfalls and physiological artefacts (e.g. Astafiev, 2010; de Gee et al., 2017). Please also provide more information in Materials and methods section â did you correct for physiological noise (using RETROICOR or related approaches)? If not, it might be better to take the LC findings out altogether, and focus on the pupil. Finally, some of your claims seem to require that the effects should specific to the LC-NA system. Substantiating this claim would require contrasting LC responses to responses of other brainstem regions.</p></disp-quote><p>We have removed this analysis entirely on the reviewerâs recommendation.</p><disp-quote content-type="editor-comment"><p>7) Please elaborate on the representation of the relevant prior literature.</p><p>There is a whole literature on this topic, which is only scarcely referred to. The following references (potentially more) should be included:</p><p>â Iigaya, 2016 presents a mechanistic view for driving up entropy with noradrenaline, with the idea that a surprise detection module is used to reset (by means of noradrenaline) the representation currently hold and stored in synapses.</p><p>â Meyniel and Dehaene, 2017 for waning and waxing of posterior uncertainty and its neural (fMRI) representation</p><p>â Pulcu and Browning, 2017 on pupil size variations with volatility</p><p>â Krishnamurthy, Nassar and Gold, 2017 on a link between pupil size and the balance between prior and current evidence in uncertain environments</p><p>â de Gee et al., 2017 for showing that fMRI responses in the human LC, but also other neuromodulatory brainstem nuclei, correlate with pupil dilation. In that regard, please tone down the statement that pupil dilation is a specific marker of LC activity (how specific this link is has rarely been tested directly and the few studies that did, in humans, monkey, and rodents, founds links to several brainstem systems).</p></disp-quote><p>Thanks for pointing these references out, we have now included discussion of these in the manuscript.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Mathematical constructs that motivate the study and analysis.</p><p>The authors now clearly decompose the inference into (1) computing a posterior distribution and (2) turning this posterior distribution into a predictive distribution by applying a transition-function which, if volatility is assumed, blunts the posterior. Using this (clear) terminology, they then say, &quot;we investigate the hypothesis that the brain has a mechanism for increasing entropy in internal models that is analogous to the transition-function update described above&quot;. It seems that their analysis cannot be in line with this, since in their experiment, volatility (the rate of change) is constant, therefore the transition-function is constant and it is impossible to correlate a brain/pupil signal with it or claim that a brain mechanism has been found for it. We suggest further editing the Introduction clarify this aspect.</p></disp-quote><p>We agree with the reviewerâs point here: indeed, we have not manipulated the magnitude of the transition function. This is in contrast to many previous papers investigating uncertainty, which have effectively searched for neural correlates of a control process (that determines the level of uncertainty) (discussed in the Introduction, fifth paragraph). The approach used by these previous papers is to manipulate the environment so that the optimal level of uncertainty in the transition function varies over time. To introduce this idea, we need to explain the concept of the transition function.</p><p>However, in the current study our aim was not to manipulate the optimal level of uncertainty in a model and identify brain regions tracking this, but to measure uncertainty as an intrinsic property of a model of the environment (discussed in the Introduction).</p><p>We tried to make the distinction between these concepts clear in the part of the Introduction referring to â2 questionsâ (fifth to final paragraph). However, we agree that the text suggested we had actually manipulated the transition function, rather than studied how uncertainty within a probabilistic world model is controlled â which amongst other things provides a mechanism by which a transition function could be implemented.</p><p>To try to clarify this point we have added a paragraph as follows</p><p>âIn the current experiment we focused on the second question above [i.e. not the strength of the leak but its consequences as manifest in the internal model itself]. [â¦] These are key components for any candidate mechanism for the implementation of a transition-function that increases uncertainty, such as a leak.â</p><disp-quote content-type="editor-comment"><p>2) Effect of entropy on representation strength.</p><p>It remains that the decoding results are not fully in line with the cartoon illustration in Figure 1B, in particular, that decoding is not significant in the high entropy condition.</p></disp-quote><p>We think the reviewer is referring to the mOFC results in Figure 2C here. This figure illustrates the effect of entropy on decoding accuracy and decoded option probabilities using a median split of trials into high and low entropy. It is true that the figure suggests that decoding would not be significant in this subset of trials. This simply reflects the key result that decoding was (parametrically) more accurate when entropy was lower. This graded effect is the effect we have tested statistically (analysis described in subsection âDecoding a probabilistic representation of beliefs about the state of the environmentâ).</p><p>The cartoon in Figure 1B is just an illustrative cartoon, which is supposed to show that the effect of entropy on representation strength is graded (i.e. we would expect the high reward option to be represented more strongly than other options in general, but that this pattern would be weaker in high entropy conditions). This is compatible with the linear regression showing a relationship between entropy and representation strength (analysis described in subsection âDecoding a probabilistic representation of beliefs about the state of the environmentâ). We donât think it would make the cartoon more informative to change it to look like the median split results when in fact the effect of entropy on representation strength is graded.</p><disp-quote content-type="editor-comment"><p>Instead, it looks like an effect of value, and indeed the effect is significant in GLM 4 testing reward probability. We are concerned that the control (point 4, second part, in the response letter) for the contribution of value may not have been adequate. They regressed out, voxel-wise, the linear effect of value. The analysis in the (univariate) residuals does not preclude that there remains multivariate activity related to value, which, if correlated with entropy, will boost the effect of entropy. The conserve approach may be more appropriate: value should be regressed out from entropy, then if the correlation between representation strength (derived from the decoder) and residual entropy remains significant and negative, it will be convincing that the effect is not confounded by value.</p><p>We realize that this control analysis may not be possible with the current design (strong negative correlation between value and entropy) -- if that is the case, then the claim about a specific involvement of entropy should be toned down.</p></disp-quote><p>The reviewer is correct that there is a strong relationship between the expected value of choosing the currently selected option, and the ideal observerâs confidence that this is the correct option. Therefore, it doesnât make sense to regress out option value from entropy â even if there was a residual relationship between entropy and representation strength, it is not clear what the residual of entropy, after value is regressed out, reflects conceptually in this context. In our opinion this is not so much a bug as a feature â because a relationship between actionâs expected value, and the agentâs certainty that is the correct action to take, would be a property of many naturalistic models of value based action. However, we agree that this should be spelled out clearly and have added a paragraph to do so, at an early point in the paper (directly after we introduce the idea of model entropy itself).</p><p>This is the text we added (subsection âWhat is the nature of the representation in mOFC?â):</p><p>âThroughout the next sections of this paper, we discuss the relationship between model entropy (in our theoretical model) and the level of uncertainty in a neural model of the state of the world. [â¦] In behavioural control more generally, this association would hold for any world model for which the aim was to determine the expected value associated with different candidate actions.â</p><p>We have retained the text about the control analysis (in which we regress out the univariate effect of value) because we think it may be of interest to readers in addition to the text above, and made the rest of the paragraph clearer:</p><p>âThe reason we interpret the multivariate results as evidence for a probabilistic representation of the current state (which option is the current high reward option) is that our ability to decode the identity of the chosen option from mOFC (indexed as representation strength for the identity of that option) was higher when the participantâs uncertainty (model entropy) was lower. [â¦] Rather the decoding must be driven by different relative weightings of specific option representations, consistent with a probabilistic state representation.â</p><disp-quote content-type="editor-comment"><p>3) Effect of noradrenaline.</p></disp-quote><p> <italic>The authors opted for removing the LC-fMRI results about which we had technical concerns. So, their claim about noradrenaline now relies entirely on the pupil data, but this overly specific conclusion is not supported by the available data. Specifically, the authors quote Joshi et al., 2016 to relate baseline pupil size (which is central in their analysis) to noradrenaline levels, but the quoted paper in fact shows that LC activity is specifically related to</italic> changes <italic>in pupil size. Reimer et al., 2016 go further in showing that pupil dynamics is correlated to both, noradrenaline</italic> and <italic>acetylcholine-release, and the former is more strongly related to the fast dilations of the pupil whereas the latter is more strongly related to slow variations in pupil size, which would correspond to fluctuations in baseline pupil size in the current paper. The authors should refrain from linking their results specifically to the LC-NA system; they should link their results to &quot;pupil-linked arousal&quot;. They can go on to speculate that the LC-NA system might play a key role in their findings, but then they would need to acknowledge that their slow baseline pupil size effects would be more in line with a cholinergic effect. It does not seem to match well with the influential accounts in this field, but we need to take this recent evidence from careful experiments into neuromodulatory correlates of pupil dynamics seriously.</italic></p><p>We agree that the pupillometry effects alone canât be linked directly to noradrenaline as opposed to Ach, for example. We have edited the language throughout to be careful about whether we are reporting (a) our results which speak only to pupil-related arousal per se, (b) other groupsâ results, some of which are in fact specific to noradrenaline (animal studies, anatomical studies, etc) or (c) other researchersâ theories, which are specifically theories about noradrenaline, even if experimental evidence for a specific role of noradrenaline as described in said theories is still lacking. In other words, we have removed any claim that our results specifically index noradrenaline, but we have not in general removed specific references to noradrenaline where discussing the work of others.</p><p>We have also added some text to make clear the current state of the literature, as we understand it, about how (non)specifically pupil data can be linked to noradrenaline:</p><p>âWe used baseline pupil size (mean pupil area in the 20ms before outcome presentation, expressed as% signal change relative to the participantâs mean pupil area over the task run) to index neuromodulatory state. [â¦] However, we must emphasise that pupillometry is a very indirect measure of neuromodulation and although we mostly interpret our results in the context of noradrenaline due to the extensive literature on pupillometry and noradrenaline, as well as influential theories and experimental work linking noradrenaline to uncertainty, model updating and exploration, we note that our pupil size data cannot be specifically linked to noradrenaline over other pupil-linked arousal factors such as acetylcholine.â</p></body></sub-article></article>