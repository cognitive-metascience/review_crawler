<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">21451</article-id><article-id pub-id-type="doi">10.7554/eLife.21451</article-id><article-categories><subj-group subj-group-type="sub-display-channel"><subject>Research</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Feature article</subject></subj-group></article-categories><title-group><article-title>Publication bias and the canonization of false facts</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-74615"><name><surname>Nissen</surname><given-names>Silas Boye</given-names></name><x>is in the</x><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-74616"><name><surname>Magidson</surname><given-names>Tali</given-names></name><x>is in the</x><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-74617"><name><surname>Gross</surname><given-names>Kevin</given-names></name><x>is in the</x><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-1046"><name><surname>Bergstrom</surname><given-names>Carl T</given-names></name><x>is in the</x><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2070-385X</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="fn" rid="equal-contrib">†</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Niels Bohr Institute</institution>, <institution>University of Copenhagen</institution>, <addr-line><named-content content-type="city">Copenhagen</named-content></addr-line>, <country>Denmark</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Computer Science</institution>, <institution>University of Washington</institution>, <addr-line><named-content content-type="city">Seattle</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Statistics</institution>, <institution>North Carolina State University</institution>, <addr-line><named-content content-type="city">Raleigh</named-content></addr-line>, <country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Department of Biology</institution>, <institution>University of Washington</institution>, <addr-line><named-content content-type="city">Seattle</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Rodgers</surname><given-names>Peter</given-names></name><role>Reviewing editor</role><aff id="aff5"><institution>eLife</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>krgross@ncsu.edu</email> (KG);</corresp><corresp id="cor2"><email>cbergst@u.washington.edu</email> (CTB)</corresp><fn fn-type="con" id="equal-contrib"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="pub" publication-format="electronic"><day>20</day><month>12</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e21451</elocation-id><history><date date-type="received"><day>12</day><month>09</month><year>2016</year></date><date date-type="accepted"><day>28</day><month>11</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Nissen et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Nissen et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-21451-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.21451.001</object-id><p>Science is facing a “replication crisis” in which many experimental findings cannot be replicated and are likely to be false. Does this imply that many scientific facts are false as well? To find out, we explore the process by which a claim becomes fact. We model the community’s confidence in a claim as a Markov process with successive published results shifting the degree of belief. Publication bias in favor of positive findings influences the distribution of published results. We find that unless a sufficient fraction of negative results are published, false claims frequently can become canonized as fact. Data-dredging, p-hacking, and similar behaviors exacerbate the problem. Should negative results become easier to publish as a claim approaches acceptance as a fact, however, true and false claims would be more readily distinguished. To the degree that the model reflects the real world, there may be serious concerns about the validity of purported facts in some disciplines.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.001">http://dx.doi.org/10.7554/eLife.21451.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>publication bias</kwd><kwd>false positive</kwd><kwd>hypothesis testing</kwd><kwd>replication crisis</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000925</institution-id><institution>John Templeton Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bergstrom</surname><given-names>Carl T</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Danish National Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Nissen</surname><given-names>Silas Boye</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Publication bias, in which positive results are preferentially reported by authors and published by journals, can restrict the visibility of evidence against false claims and allow such claims to be canonized inappropriately as facts.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Science is a process of collective knowledge creation in which researchers use experimental, theoretical and observational approaches to develop a naturalistic understanding of the world. In the development of a scientific field, certain claims stand out as both significant and stable in the face of further experimentation (<xref ref-type="bibr" rid="bib44">Ravetz, 1971</xref>). Once a claim reaches this stage of widespread acceptance as true, it has transitioned from claim to <italic>fact</italic>. This transition, which we call <italic>canonization</italic>, is often indicated by some or all of the following: a canonized fact can be taken for granted rather than treated as an open hypothesis in the subsequent primary literature; tests that do no more than to confirm previously canonized facts are seldom considered publication-worthy; and canonized facts begin to appear in review papers and textbooks without the company of alternative hypotheses. Of course the veracity of so-called facts may be called back into question (<xref ref-type="bibr" rid="bib1">Arbesman, 2012</xref>; <xref ref-type="bibr" rid="bib30">Latour, 1987</xref>), but for time being the issue is considered to be settled. Note that we consider facts to be epistemological rather than ontological: a claim is a fact because it is accepted by the relevant community, not because it accurately reflects or represents underlying physical reality (<xref ref-type="bibr" rid="bib44">Ravetz, 1971</xref>; <xref ref-type="bibr" rid="bib30">Latour, 1987</xref>).</p><p>But what is the status of these facts in light of the widely reported replication crisis in science? Large scale analyses have revealed that many published papers in fields ranging from cancer biology to psychology to economics cannot be replicated in subsequent experiments (<xref ref-type="bibr" rid="bib4">Begley and Ellis, 2012</xref>; <xref ref-type="bibr" rid="bib39">Open Science Collaboration, 2015</xref>; <xref ref-type="bibr" rid="bib17">Errington et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Ebrahim et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Chang and Li, 2015</xref>; <xref ref-type="bibr" rid="bib6">Camerer et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Baker, 2016</xref>). One possible explanation is that many published experiments are not replicable because many of their conclusions are ontologically false (<xref ref-type="bibr" rid="bib23">Ioannidis, 2005</xref>; <xref ref-type="bibr" rid="bib22">Higginson and Munafò, 2016</xref>).</p><p>If many experimental findings are ontologically false, does it follow that many scientific facts are ontologically untrue? Not necessarily. Claims of the sort that become facts are rarely if ever tested directly in their entirety. Instead, such claims typically comprise multiple subsidiary hypotheses which must be individually verified. Thus multiple experiments are usually required to establish a claim. Some of these may include direct replications, but more typically an ensemble of distinct experiments will produce multiple lines of evidence before a claim is accepted by the community.</p><p>For example, as molecular biologists worked to unravel the details of the eukaryotic RNA interference (RNAi) pathway in the early 2000s, they wanted to understand how the RNAi pathway was initiated. Based on work with <italic>Drosophila</italic> cell lines and embryo extracts, one group of researchers made the claim that the RNAi pathway is initiated by the Dicer enzyme which slices double-stranded RNA into short fragments of 20–22 amino acids in length (<xref ref-type="bibr" rid="bib5">Bernstein et al., 2001</xref>). Like many scientific facts, this claim was too broad to be validated directly in a single experiment. Rather, it comprised a number of subsidiary assertions: an enzyme called Dicer exists in eukaryotic cells; it is essential to initiate the RNAi pathway; it binds dsRNA and slices it into pieces; it is distinct from the enzyme or enzyme complex that destroys targeted messenger RNA; it is ubiquitous across eukaryotes that exhibit RNAi pathway. Researchers from numerous labs tested these subsidiary hypotheses or aspects thereof to derive numerous lines of convergent evidence in support of the original claim. While the initial breakthrough came from work in <italic>Drosophila melanogaster</italic> cell lines ((<xref ref-type="bibr" rid="bib5">Bernstein et al., (2001</xref>), subsequent research involved in establishing this fact drew upon in vitro and in vivo studies, genomic analyses, and even mathematical modeling efforts, and spanned species including the fission yeast <italic>Schizosaccharomyces pombe</italic>, the protozoan <italic>Giardia intestinalis</italic>, the nemotode <italic>Caenorhabditis elegans</italic>, the flowering plant <italic>Arabidopsis thaliana</italic>, mice, and humans (<xref ref-type="bibr" rid="bib25">Jaskiewicz and Filipowicz, 2008</xref>). Ultimately, sufficient supporting evidence accumulated to establish as fact the original claim about Dicer’s function.</p><p>Requiring multiple studies to establish a fact is no panacea, however. The same processes that allow publication of a single incorrect result can also lead to the accumulation of sufficiently many incorrect findings to establish a false claim as fact (<xref ref-type="bibr" rid="bib32">McElreath and Smaldino, 2015</xref>).</p><p>This risk is exacerbated by <italic>publication bias</italic> (<xref ref-type="bibr" rid="bib52">Sterling, 1959</xref>; <xref ref-type="bibr" rid="bib45">Rosenthal, 1979</xref>; <xref ref-type="bibr" rid="bib35">Newcombe, 1987</xref>; <xref ref-type="bibr" rid="bib3">Begg and Berlin, 1988</xref>; <xref ref-type="bibr" rid="bib12">Dickersin, 1990</xref>; <xref ref-type="bibr" rid="bib13">Easterbrook et al., 1991</xref>; <xref ref-type="bibr" rid="bib51">Song et al., 2000</xref>; <xref ref-type="bibr" rid="bib38">Olson et al., 2002</xref>; <xref ref-type="bibr" rid="bib7">Chan and Altman, 2005</xref>; <xref ref-type="bibr" rid="bib19">Franco et al., 2014</xref>). Publication bias arises when the probability that a scientific study is published is not independent of its results (<xref ref-type="bibr" rid="bib52">Sterling, 1959</xref>). As a consequence, the findings from published tests of a claim will differ in a systematic way from the findings of all tests of the same claim (<xref ref-type="bibr" rid="bib51">Song et al., 2000</xref>; <xref ref-type="bibr" rid="bib54">Turner et al., 2008</xref>).</p><p>Publication bias is pervasive. Authors have systematic biases regarding which results they consider worth writing up; this is known as the “file drawer problem” or “outcome reporting bias” (<xref ref-type="bibr" rid="bib45">Rosenthal, 1979</xref>; <xref ref-type="bibr" rid="bib7">Chan and Altman, 2005</xref>). Journals similarly have biases about which results are worth publishing. These two sources of publication bias act equivalently in the model developed here, and thus we will not attempt to separate them. Nor would separating them be simple; even if authors’ behavior is the larger contributor to publication bias (<xref ref-type="bibr" rid="bib38">Olson et al., 2002</xref>; <xref ref-type="bibr" rid="bib19">Franco et al., 2014</xref>), they may simply be responding appropriately to incentives imposed by editorial preferences for positive results.</p><p>What kinds of results are most valued? Findings of statistically significant differences between groups or treatments tend to be viewed as more worthy of submission and publication than those of non-significant differences. Correlations between variables are often considered more interesting than the absence of correlations. Tests that reject null hypotheses are commonly seen as more noteworthy than tests that fail to do so. Results that are interesting in any of these ways can be described as “positive”.</p><p>A substantial majority of the scientific results published appear to be positive ones (<xref ref-type="bibr" rid="bib9">Csada et al., 1996</xref>). It is relatively straightforward to measure the fraction of published results that are negative. One extensive study found that in 2007, more than 80% of papers reported positive findings, and this number exceeded 90% in disciplines such as psychology and ecology (<xref ref-type="bibr" rid="bib18">Fanelli, 2012</xref>). Moreover, the fraction of publications reporting positive results has increased over the past few decades. While this high prevalence of positive results could in principle result in part from experimental designs with increasing statistical power and a growing preference for testing claims that are believed likely to be true, publication bias doubtless contributes as well (<xref ref-type="bibr" rid="bib18">Fanelli, 2012</xref>).</p><p>How sizable is this publication bias? To answer that, we need to estimate the fraction of negative results that are published, and doing so can be difficult because we rarely have access to the set of findings that go unpublished. The best available evidence of this sort comes from registered clinical trials. For example, a 2008 meta-analysis examined 74 FDA-registered studies of antidepressants (<xref ref-type="bibr" rid="bib54">Turner et al., 2008</xref>). In that analysis, 37 of 38 positive studies were published as positive results, but only 3 of 24 negative studies were published as negative results. An additional 5 negative studies were re-framed as positive for the purposes of publication. Thus, negative studies were published at scarcely more than 10% the rate of positive studies.</p><p>We would like to understand how the possibility of misleading experimental results and the prevalence of publication bias shape the creation of scientific facts. Mathematical models of the scientific process can help us understand the dynamics by which scientific knowledge is produced and, consequently, the likelihood that elements of this knowledge are actually correct. In this paper, we look at the way in which repeated efforts to test a scientific claim establish this claim as fact or cause it to be rejected as false.</p><p>We develop a mathematical model in which successive publications influence the community’s perceptions around the likelihood of a given scientific claim. Positive results impel the claim toward fact, whereas negative results lead in the opposite direction. Describing this process, <xref ref-type="bibr" rid="bib30">Latour, (1987)</xref> compared the fate of a scientific claim to that of a rugby ball, pushed alternatively toward fact or falsehood by the efforts of competing teams, its fate determined by the balance of their collective actions. Put in these terms, our aim in the present paper is to develop a formal model of how the ball is driven up and down the epistemological pitch until one of the goal lines is reached. In the subsequent sections, we outline the model, explain how it can be analyzed, present the results that we obtain, and consider its implications for the functioning of scientific activity.</p></sec><sec id="s2"><title>Model</title><p>In this section, we will develop a simplified model of scientific activity, designed to capture the important qualitative features of fact-creation as a dynamic process.</p><sec id="s2-1"><title>Model description</title><p>We explore a simple model in which researchers sequentially test a single claim until the scientific community becomes sufficiently certain of its truth or falsehood that no further experimentation is needed. Our model is conceptually related to those developed in refs. (<xref ref-type="bibr" rid="bib46">Rzhetsky et al., 2006</xref>; <xref ref-type="bibr" rid="bib32">McElreath and Smaldino, 2015</xref>), though it is considerably simpler than either since we only consider a single claim at a time.</p><p><xref ref-type="fig" rid="fig1">Figure 1</xref> provides a schematic illustration of the experimentation and publication process. We begin with a claim which is ontologically either true or false. Researchers sequentially conduct experiments to test the claim; these experiments are typically not direct replications of one another, but rather distinct approaches that lend broader support to the claim. Each experiment returns either a positive outcome supporting the claim, or a negative outcome contravening it. For mathematical simplicity, we assume all tests to have the same error rates, in the sense that if the claim under scrutiny is false, then investigators obtain false positives with probability <inline-formula><mml:math id="inf1"><mml:mi>α</mml:mi></mml:math></inline-formula>. Conversely, when the claim is true, investigators obtain false negatives with probability <inline-formula><mml:math id="inf2"><mml:mi>β</mml:mi></mml:math></inline-formula>. We take these error rates to be the ones that are conventionally associated with statistical hypothesis testing, so that <inline-formula><mml:math id="inf3"><mml:mi>α</mml:mi></mml:math></inline-formula> is equivalent to the significance level (technically, the <italic>size</italic>) of a statistical test and <inline-formula><mml:math id="inf4"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> is the test’s power. We assume that, as in any reasonable test, a true claim is more likely to generate a positive result than a negative one: <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>. A broader interpretation of <inline-formula><mml:math id="inf6"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mi>β</mml:mi></mml:math></inline-formula> beyond statistical error does not change the interpretation of our results.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.002</object-id><label>Figure 1.</label><caption><title>Conducting and reporting the test of a claim.</title><p>In our model, a scientific claim is either true or false. Researchers conduct an experiment which either supports or fails to the support the claim. True claims are correctly supported with probability <inline-formula><mml:math id="inf8"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> while false claims are incorrectly supported with probability <inline-formula><mml:math id="inf9"><mml:mi>α</mml:mi></mml:math></inline-formula>. Next, the researchers may attempt to publish their results. Positive results that support the claim are published with probability <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> whereas negative results that fail to support the claim are published with probability <inline-formula><mml:math id="inf11"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. This process then repeats, with additional experiments conducted until the claim is canonized as fact or rejected as false.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.002">http://dx.doi.org/10.7554/eLife.21451.002</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig1-v1"/></fig></p><p>After completing a study, the investigators may attempt to publish their experimental results. However, publication bias occurs in that the result of the experiment influences the chance that a study is written up as a paper and accepted for publication. Positive results are eventually published somewhere with probability <inline-formula><mml:math id="inf12"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> whereas negative results are eventually published somewhere with probability <inline-formula><mml:math id="inf13"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. Given the reluctance of authors to submit negative results and of journals to publish them, we expect that in general <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>Finally, readers attempt to judge whether a claim is true by consulting the published literature only. For modeling purposes, we will consider a best-case scenario, in which the false positive and false negative rates <inline-formula><mml:math id="inf15"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf16"><mml:mi>β</mml:mi></mml:math></inline-formula> are established by disciplinary custom or accepted benchmarks, and readers perform Bayesian updating of their beliefs based upon these known values. In practice, these values may not be as well standardized or widely reported as would be desirable. Moreover, readers are unlikely to be this sophisticated in drawing their inferences. Instead readers are likely to form subjective beliefs in an informal fashion based on a general assessment of the accumulated positive and negative results and the strength of each. But the Bayesian updating case provides a well-defined model under which to explore the distortion of belief by publication bias.</p><p>The problem is that the results described in the published literature are now biased by the selection of which articles are drafted and accepted for publication. We assume that readers are unaware of the degree of this bias, and that they fail to correct for publication bias in drawing inferences from the published data. It may seem pessimistic that researchers would fail to make this correction, but much of the current concern over the replication crisis in science is predicated on exactly this. Moreover, it is usually impossible for a researcher to accurately estimate the degree of publication bias in a given domain.</p></sec><sec id="s2-2"><title>Model dynamics</title><p>Consider a claim that the community initially considers to have probability <inline-formula><mml:math id="inf17"><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> of being true. Researchers iteratively test hypotheses that bear upon the claim until it accumulates either sufficient support to be canonized as fact, or sufficient counter-evidence to be discarded as false. If the claim is true, the probability that a single test leads to a positive publication is <inline-formula><mml:math id="inf18"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM1"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and the corresponding probability of a negative publication is <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The remaining probability corresponds to results of the test not being published. If the claim is false, these probabilities are <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM2"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> for positive and negative published outcomes, respectively. Given that a claim is true, the probability that a published test of that claim reports a positive outcome is therefore<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM3"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM4"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For a false claim, the probability that a published test is positive is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM5"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Because only the ratio of <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> matters for the purposes of our model, we set <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> to 1 for the remainder of the paper. We initially assume that <inline-formula><mml:math id="inf25"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is constant, but will relax this assumption later.</p><p>To formalize ideas, consider a sequence of published outcomes <inline-formula><mml:math id="inf26"><mml:mi>X</mml:mi></mml:math></inline-formula>, and let <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> be the number of positive published outcomes in the first <inline-formula><mml:math id="inf28"><mml:mi>k</mml:mi></mml:math></inline-formula> terms of <inline-formula><mml:math id="inf29"><mml:mi>X</mml:mi></mml:math></inline-formula>. When the probability of publishing a negative result <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is constant, the outcomes of published experiments are exchangeable random variables. Thus after <inline-formula><mml:math id="inf31"><mml:mi>k</mml:mi></mml:math></inline-formula> published tests, the distribution of <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> for a true claim is the binomial distribution <inline-formula><mml:math id="inf33"><mml:mrow><mml:mtext>Bin</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM6">k</mml:mi><mml:mo>,</mml:mo><mml:msub id="XM7"><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and for a false claim is <inline-formula><mml:math id="inf34"><mml:mrow><mml:mtext>Bin</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM8">k</mml:mi><mml:mo>,</mml:mo><mml:msub id="XM9"><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Moreover, the sequence <inline-formula><mml:math id="inf35"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub id="XM10"><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup></mml:math></inline-formula> is a Markov chain. When the extent of publication bias is known, we can compute the conditional probability that a claim is true, given <inline-formula><mml:math id="inf36"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>, as<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We now consider the consequences of drawing inferences based on the published data alone, without correcting for publication bias. For model readers who do not condition on publication bias, let <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM15">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be the perceived, conditional probability that a claim is true given <inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>. We say “perceived” because these readers use Bayes’ Law to update <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, but do so under the incorrect assumption that there is no publication bias, i.e., that <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. To ease the narrative, we refer to the perceived conditional probability that a claim is true as the “belief” that the claim is true. Expressing this formally,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that without publication bias, we have <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM21"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>, and thus <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> coincides with <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>.</p><p>From the perspective of an observer who is unaware of any publication bias, the pair <inline-formula><mml:math id="inf43"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub id="XM22"><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi id="XM23">k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a sufficient statistic for the random variable <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>A</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mtext id="XM24">True</mml:mtext><mml:mo>,</mml:mo><mml:mtext id="XM25">False</mml:mtext><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> representing the truth value of the claim in question. This follows from the definition of statistical sufficiency and the fact that<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>True</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>prob</mml:mtext></mml:mstyle><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>True</mml:mtext></mml:mstyle><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>By analogous logic, the pair <inline-formula><mml:math id="inf45"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub id="XM30"><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi id="XM31">k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is also a sufficient statistic for an observer aware of the degree of publication bias provided that the publication probabilities <inline-formula><mml:math id="inf46"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf47"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> are constant.</p><p>We envision science as proceeding iteratively until the belief that a claim is true is sufficiently close to 1 that the claim is canonized as fact, or until belief is sufficiently close to 0 that the claim is discarded as false. We let <inline-formula><mml:math id="inf48"><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf49"><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> be the belief thresholds at which a claim is rejected or canonized as fact, respectively (<inline-formula><mml:math id="inf50"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), and refer to these as evidentiary standards. In our analysis, we make the simplifying assumption that the evidentiary standards are symmetric, i.e., <inline-formula><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. We describe the consequences of relaxing this assumption in the Discussion.</p><p>Thus, mathematically, we model belief in the truth of a claim as a discrete-time Markov chain <inline-formula><mml:math id="inf52"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub id="XM32"><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup></mml:math></inline-formula> with absorbing boundaries at the evidentiary standards for canonization or rejection (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). When the Markov chain represents belief, its possible values lie in the interval from 0 to 1. For mathematical convenience, however, it is often helpful to convert belief to the log odds scale, that is, <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi id="XM34">ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM35"><mml:msub><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM33"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Some algebra shows that the log odds of belief <inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM36">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be written as<disp-formula id="equ6"><label>(5)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"/></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.003</object-id><label>Figure 2.</label><caption><title>A time-directed graph represents the evolution of belief over time.</title><p>In panel <bold>A</bold>, the horizontal axis indicates the number of experiments published and the vertical axis reflects the observer’s belief, quantified as the probability that the claim is true. The process begins at the single point at far left with an initial belief <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. Each subsequent experiment either supports the claim, moving to the next node up and right, or contradicts the claim, moving to the next node down and right. At yellow nodes, the status of the claim is as yet undecided. At green nodes, it is canonized as fact, and at blue nodes, it is rejected as false. The black horizontal lines show the evidentiary standards (<inline-formula><mml:math id="inf56"><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf57"><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>). The red path shows one possible trajectory, in which a positive experiment is followed by a negative, then two positives, then a negative, etc., ultimately becoming canonized as fact when it reaches the upper boundary. Panel <bold>B</bold> shows the same network, but with the vertical axis representing log odds and using color to indicate the probability that the process visits each node. In log-odds space, each published positive result shifts belief by the constant distance <inline-formula><mml:math id="inf58"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and each negative result by a different distance <inline-formula><mml:math id="inf59"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Shown here (in both panel <bold>A</bold> and <bold>B</bold>) is a false claim with false positive rate <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, false negative rate <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, publication probabilities <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, and initial belief <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>. In this case, the claim is likely to be canonized as fact, despite being false.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.003">http://dx.doi.org/10.7554/eLife.21451.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig2-v1"/></fig></p><p>The log odds scale is convenient because, as <xref ref-type="disp-formula" rid="equ6">Equation. 5</xref> shows, each published positive outcome increases the log odds of belief by a constant increment<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>(<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Each published negative outcome decreases the log odds of belief by<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Below, we will see that much of the behavior of our model can be understood in terms of the expected change in the log odds of belief for each published outcome. For a true claim, the expected change in the log odds of belief is<disp-formula id="equ9"><label>(6)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>whereas for a false claim, the expected change in the log odds of belief is<disp-formula id="equ10"><label>(7)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM64"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s2-3"><title>Computing canonization and rejection probabilities</title><p>In general, we cannot obtain a closed-form expression for the probability that a claim is canonized as fact or for the probability that it is rejected as false. We can, however, derive recursive expressions for the probabilities that after <inline-formula><mml:math id="inf65"><mml:mi>k</mml:mi></mml:math></inline-formula> published experiments a claim has been canonized as fact, has been discarded as false, or remains undecided. From these, it is straightforward to compute the canonization and rejection probabilities numerically to any desired level of precision.</p><p>For each number of published experiments <inline-formula><mml:math id="inf66"><mml:mi>k</mml:mi></mml:math></inline-formula>, the state space for <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> is simply <inline-formula><mml:math id="inf68"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn id="XM65">0</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM66">1</mml:mn><mml:mo>,</mml:mo><mml:mi id="XM67" mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi id="XM68">k</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Partition this state space as follows:<disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="script">𝒞</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℐ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="script">ℛ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>That is, <inline-formula><mml:math id="inf69"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒞</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> is the set of outcomes corresponding to a belief greater than the evidentiary standard for canonization, <inline-formula><mml:math id="inf70"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℛ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> is the set of outcomes corresponding to a belief less than the evidentiary standard for rejection, and <inline-formula><mml:math id="inf71"><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> is the set of outcomes corresponding to belief in between these two standards (the “interior”). Let <inline-formula><mml:math id="inf72"><mml:mi>T</mml:mi></mml:math></inline-formula> be the number of publications until a claim is either canonized or rejected. Formally,<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For a true claim, we calculate the probability of canonization as follows. (A parallel set of equations gives the probability of canonization for a false claim.) For each <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, define <inline-formula><mml:math id="inf74"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM93">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>Prob</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>k</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. That is, <inline-formula><mml:math id="inf75"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM96">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the probability that there are exactly <inline-formula><mml:math id="inf76"><mml:mi>y</mml:mi></mml:math></inline-formula> positive outcomes in the first <inline-formula><mml:math id="inf77"><mml:mi>k</mml:mi></mml:math></inline-formula> publications, and the claim has yet to be canonized or rejected by publication <inline-formula><mml:math id="inf78"><mml:mi>k</mml:mi></mml:math></inline-formula>. Suppose these probabilities are known for each <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Then for each <inline-formula><mml:math id="inf80"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, these probabilities can be found recursively by<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM97">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM98"><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM99"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM100">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For computational purposes, in the recursion above we define <inline-formula><mml:math id="inf81"><mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM101">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> whenever <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∉</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The probability that the claim has yet to be canonized or rejected by publication <inline-formula><mml:math id="inf83"><mml:mi>k</mml:mi></mml:math></inline-formula> is simply<disp-formula id="equ14"><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">ℐ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Let <inline-formula><mml:math id="inf84"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> be the probability that a claim is first canonized at publication <inline-formula><mml:math id="inf85"><mml:mi>k</mml:mi></mml:math></inline-formula>. Formally,<disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℐ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo> <mml:mtext>and </mml:mtext><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">𝒞</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM102"><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Let <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="2"><mml:mo>⋆</mml:mo></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> be the smallest value of <inline-formula><mml:math id="inf87"><mml:mi>k</mml:mi></mml:math></inline-formula> for which <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi>Prob</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>k</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:math></inline-formula>. To calculate the probability of canonization, we calculate <inline-formula><mml:math id="inf89"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi id="XM103">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="2"><mml:mo>⋆</mml:mo></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The probability of canonization is then <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mo>⋆</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msubsup><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. For the analyses in this paper, we have set <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p></sec></sec><sec id="s3" sec-type="results"><title>Results</title><p>We focus throughout the paper on the dynamic processes by which false claims are canonized as facts, and explore how the probability of this happening depends on properties of the system such as the publication rate of negative results, the initial beliefs of researchers, the rates of experimental error, and the degree of evidence required to canonize a claim. In principle, the converse could be a problem as well: true claims could be discarded as false. However, this is rare in our model. Publication bias favors the publication of positive results and therefore will not tend to cause true claims to be discarded as false, irrespective of other parameters. We first establish this, and then proceed to a detailed examination of how scientific experimentation and publication influences the rate at which false claims are canonized as fact.</p><sec id="s3-1"><title>True claims tend to be canonized as facts</title><p>In our model, true claims are almost always canonized as facts. <xref ref-type="fig" rid="fig3">Figure</xref> <xref ref-type="fig" rid="fig3">3</xref> illustrates this result in the form of a receiver operating characteristic (ROC) curve. Holding the other parameters constant, the curve varies the negative publication rate <inline-formula><mml:math id="inf93"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, and uses the vertical and horizontal axes to indicate the probabilities that true and false claims respectively are canonized as fact.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.004</object-id><label>Figure 3.</label><caption><title>ROC curves reveal that true claims are almost always canonized as fact.</title><p>In the receiver operating characteristic (ROC) curves shown here, the vertical axis represents the probability that a true claim is correctly canonized as fact, and the horizontal axis represents the probability that a false one is incorrectly canonized as fact. Panel <bold>A</bold>: lax evidentiary standards <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Panel <bold>B</bold>: strict evidentiary standards <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf97"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math></inline-formula>. Error rates and initial belief are <inline-formula><mml:math id="inf98"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf100"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. Each point along the ROC curve corresponds to a different value of the negative publication rate, <inline-formula><mml:math id="inf101"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, as indicated by color. Grey regions of the curve correspond to the unlikely situations in which <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, i.e., negative results are more likely to be published than positive ones. The figures reveal two important points. First, when negative results are published at any rate <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the vast majority of true claims are canonized as fact. Second, when negative results are published at a low rate (<inline-formula><mml:math id="inf104"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> less than 0.3 or 0.2 depending on evidentiary standards), many false claims will also be canonized as true.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.004">http://dx.doi.org/10.7554/eLife.21451.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig3-v1"/></fig></p><p>One might fear that as the probability <inline-formula><mml:math id="inf105"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> of publishing negative results climbs toward unity, the risk of rejecting a true claim would increase dramatically as well. This is not the case. Even as the probability of publishing negative results approaches 1, the risk of rejecting a true claim is low when evidentiary standards are lax (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), and negligible when evidentiary standards are strict (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>This result turns out to be general across a broad range of parameters. Assuming the mild requirements that (i) tests of a true claim are more likely to result in positive publications than negative publications (i.e., <inline-formula><mml:math id="inf106"><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, or equivalently <inline-formula><mml:math id="inf107"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM107"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), and (ii) positive published outcomes increase belief that the claim is true (<inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, or equivalently <inline-formula><mml:math id="inf109"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM108"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>), true claims are highly likely to be canonized as facts. The exceptions occur only when minimal evidence is needed to discard a claim, i.e., when initial belief is small (<inline-formula><mml:math id="inf110"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>). In such cases a bit of bad luck—the first one or two published experiments report false negatives, for example—can cause a true claim to be rejected. But otherwise, truth is sufficient for canonization.</p><p>Unfortunately, truth is not required for canonization. The risk of canonizing a false claim—shown on the horizontal axis in <xref ref-type="fig" rid="fig3">Figure 3</xref>—is highly sensitive to the rate at which negative results are published. When negative results are published with high probability, false claims are seldom canonized. But when negative results are published with lower probability, many false claims are canonized.</p><p>Thus we see that the predominant risk associated with publication bias is the canonization of false claims. In the remainder of this analysis, we focus on this risk of incorrectly establishing a false claim as a fact.</p></sec><sec id="s3-2"><title>Publication of negative results is essential</title><p>As we discussed in the introduction, authors and journals alike tend to be reluctant to publish negative results, and as we found in the previous subsection, when most negative results go unpublished, science performs poorly. Here, we explore this relationship in further detail.</p><p><xref ref-type="fig" rid="fig4">Figure 4</xref> shows how the probability of erroneously canonizing a false claim as fact depends on the probability <inline-formula><mml:math id="inf111"><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> that a negative result is published. False claims are likely to be canonized below a threshold rate of negative publication, and unlikely to be canonized above this threshold. For example, when the false positive rate <inline-formula><mml:math id="inf112"><mml:mi>α</mml:mi></mml:math></inline-formula> is 0.05, the false negative rate <inline-formula><mml:math id="inf113"><mml:mi>β</mml:mi></mml:math></inline-formula> is 0.4, and the evidentiary requirements are strong (yellow points in Panel 4D), a false claim is likely to be canonized as fact unless negative results are at least 20% as likely as positive results to be published.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.005</object-id><label>Figure 4.</label><caption><title>Publishing negative outcomes is essential for rejecting false claims.</title><p>Probability that a false claim is incorrectly canonized, as a function of the negative publication rate. Throughout, initial belief is <inline-formula><mml:math id="inf114"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, and individual data series show false positive rates <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> (yellow), <inline-formula><mml:math id="inf116"><mml:mrow><mml:mn id="XM112">0.10</mml:mn><mml:mo>,</mml:mo><mml:mi id="XM113" mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mn id="XM114">0.25</mml:mn></mml:mrow></mml:math></inline-formula> (red). Top row: weak evidentiary standards <inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf118"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>. Panel <bold>A</bold>: false negative rate <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>. Panel <bold>B</bold>: <inline-formula><mml:math id="inf120"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. Panels <bold>C</bold>–<bold>D</bold>: similar to panels <bold>A</bold>–<bold>B</bold>, with more demanding evidentiary standards <inline-formula><mml:math id="inf121"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf122"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.005">http://dx.doi.org/10.7554/eLife.21451.005</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig4-v1"/></fig></p><p><xref ref-type="fig" rid="fig4">Figure 4</xref> also reveals that the probability of canonizing false claims as facts depends strongly on both the false positive rate and the false negative rate of the experimental tests. As these error rates increase, an increasingly large fraction of negative results must be published to preserve the ability to discriminate between true and false claims.</p></sec><sec id="s3-3"><title>Initial beliefs usually do not matter much</title><p>If the scientific process is working properly, it should not automatically confirm what we already believe, but rather it should lead us to change our beliefs based on evidence. Our model indicates that in general, this is the case.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref> shows how the probability that a false claim is canonized as true depends on the initial belief <inline-formula><mml:math id="inf123"><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> that the claim is true. Under most circumstances, the probability of canonization is relatively insensitive to initial belief. False canonization rates depend strongly on initial belief only when evidentiary standards are weak and experiments are highly prone to error (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In this case, belief is a random walk without a systematic tendency to increase or decrease with each published outcome, and thus the odds of canonization or rejection depend most strongly on the initial belief.<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.006</object-id><label>Figure 5.</label><caption><title>False canonization rates are relatively insensitive to initial belief, unless experimental tests are inaccurate and evidentiary standards are weak.</title><p>Probability that a false claim is mistakenly canonized as a true fact vs. prior belief for various negative publication rates. Top row: weak evidentiary standards <inline-formula><mml:math id="inf124"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf125"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>. Panel <bold>A</bold>: false positive rate <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, false negative rate <inline-formula><mml:math id="inf127"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, and publication rate of negative results <inline-formula><mml:math id="inf128"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.025</mml:mn></mml:mrow></mml:math></inline-formula> (light green), <inline-formula><mml:math id="inf129"><mml:mrow><mml:mn id="XM123">0.05</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM124">0.1</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM125">0.2</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM126">0.4</mml:mn></mml:mrow></mml:math></inline-formula> (dark green). Panel <bold>B</bold>: <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> (light green), <inline-formula><mml:math id="inf133"><mml:mrow><mml:mn id="XM127">0.3</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM128">0.4</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM129">0.5</mml:mn><mml:mo>,</mml:mo><mml:mn id="XM130">1</mml:mn></mml:mrow></mml:math></inline-formula> (dark green). Panels <bold>C</bold>–<bold>D</bold>: similar to panels <bold>A</bold>–<bold>B</bold>, with more demanding evidentiary standards <inline-formula><mml:math id="inf134"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.006">http://dx.doi.org/10.7554/eLife.21451.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig5-v1"/></fig></p><p>The step-function-like appearance of some of the results in <xref ref-type="fig" rid="fig5">Figure 5</xref>, particularly <xref ref-type="fig" rid="fig5">Figure 5A</xref>, is a real property of the curves in question and not a numerical artifact. The “steps” arise because, when evidentiary standards are weak, canonization or rejection often happens after a small number of experiments. Because the number of experiments must be integral, probabilities of false canonization can change abruptly when a small change in initial belief increases or decreases the number of experiments in the most likely path to canonization or rejection.</p></sec><sec id="s3-4"><title>Stronger evidentiary standards do not reduce the need to publish negative outcomes</title><p>We have seen in the previous sections that the scientific process struggles to distinguish true from false claims when the rate of publishing negative results is low. We might hope that we could remedy this problem simply by demanding more evidence before accepting a claim as fact. Unfortunately, this is not only expensive in terms of time and effort—sometimes it will not even help.</p><p><xref ref-type="fig" rid="fig6">Figure 6</xref> illustrates the problem. In this figure, we see the probability of canonizing a false claim as a function of negative publication rate for three different evidentiary standards: <inline-formula><mml:math id="inf136"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf137"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf138"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>. When the false positive rate <inline-formula><mml:math id="inf139"><mml:mi>α</mml:mi></mml:math></inline-formula> is relatively low (<xref ref-type="fig" rid="fig6">Figure 6A</xref>), increasing the evidentiary requirements reduces the chance of canonizing a false claim for negative publication rates above 0.1 or so, but below this threshold there is no advantage to requiring stronger evidence. When the false positive rate is higher (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), the situation is even worse: for negative publication rates below 0.3 or so, increasing evidentiary requirements actually increases the chance of canonizing a false fact.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.007</object-id><label>Figure 6.</label><caption><title>Strengthening evidentiary requirements does not necessarily decrease canonization of false facts.</title><p>In panel <bold>A</bold>, the false positive rate is <inline-formula><mml:math id="inf140"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, the false negative rate is <inline-formula><mml:math id="inf141"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, the original belief in the claim is <inline-formula><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, and the evidentiary standards are symmetric <inline-formula><mml:math id="inf143"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. In panel <bold>B</bold>, the false positive rate is increased to <inline-formula><mml:math id="inf144"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> while the other parameters remain unchanged. Particularly in this latter case, increasing evidentiary standards does not necessarily decrease the rate at which false claims are canonized as facts.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.007">http://dx.doi.org/10.7554/eLife.21451.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig6-v1"/></fig></p><p>The limited benefits of strengthening evidentiary standards can be understood through the mathematical theory of random walks (<xref ref-type="bibr" rid="bib36">Norris, 1998</xref>). In short, the thresholds of belief for canonizing or rejecting a claim are <italic>absorbing boundaries</italic> such that once belief attains either boundary, the walk terminates and beliefs will not change further. Increasing the evidentiary standards for canonization or rejection is tantamount to increasing the distance between these boundaries and the initial belief state. Basic results from the theory of random walks suggest that, as the distance between the initial state and the boundaries increases, the probability of encountering one boundary before the other depends increasingly strongly on the average change in the log odds of belief at each step (experiment), and less on the random fluctuations in belief that arise from the stochasticity of the walk. Thus, for exacting evidentiary standards, the probability of eventual canonization or rejection depends critically on the average change in the log odds of belief for each experiment. These are given by <xref ref-type="disp-formula" rid="equ9">Equation 6</xref> for a true claim and <xref ref-type="disp-formula" rid="equ10">Equation 7</xref> for a false one.</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows how the expected change in log odds of belief varies in response to changes in the publication rate of negative outcomes, for both false and true claims. Critically, for false claims, if too few negative outcomes are published, then on average each new publication will <italic>increase</italic> the belief that the claim is true, because there is a high probability this publication will report a positive result. Thus, paradoxically, scientific activity does not help sort true claims from false ones in this case, but instead promotes the erroneous canonization of false claims. The only remedy for this state of affairs is to publish enough negative outcomes that, on average, each published result moves belief in the “correct” direction, that is, towards canonization of true claims (a positive average change per experiment in log odds of belief) and rejection of false ones (a negative average change per experiment in log odds of belief).<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.008</object-id><label>Figure 7.</label><caption><title>Scientific activity will tend to increase belief in false claims if too few negative outcomes are published.</title><p>Expected change in log odds of belief vs. negative publication rate for (<bold>A</bold>) false and (<bold>B</bold>) true claims. Lines show false positive rates <inline-formula><mml:math id="inf145"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> (yellow), <inline-formula><mml:math id="inf146"><mml:mrow><mml:mn id="XM134">0.10</mml:mn><mml:mo>,</mml:mo><mml:mi id="XM135" mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mn id="XM136">0.25</mml:mn></mml:mrow></mml:math></inline-formula> (red). Other parameter values are false negative rate <inline-formula><mml:math id="inf147"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> and positive publication rate <inline-formula><mml:math id="inf148"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.008">http://dx.doi.org/10.7554/eLife.21451.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig7-v1"/></fig></p><p>Two additional points are in order here. First, for true claims, under most circumstances the expected change in the log odds of belief is positive (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). That is, on average, scientific activity properly increases belief in true claims, and thus the risk of incorrectly rejecting a true claim is small (under reasonable evidentiary standards). Second, the observation that more exacting evidentiary standards can occasionally increase the chance of incorrectly canonizing a false claim is not much of an argument in favor of weaker evidentiary standards. In short, weaker standards cause canonization or rejection to depend more strongly on the happenstance of the first several published experiments. When scientific activity tends to increase belief in a false claim, weaker evidentiary standards appear beneficial because they increase the chance that a few initial published negatives will lead to rejection and bring a halt to further investigation. While this is a logical result of the model, it is somewhat tantamount to stating that, if scientific activity tends to increase belief in false claims, then the best option is to weaken the dependence on scientific evidence. More robust practices for rejecting false claims seem desirable.</p></sec><sec id="s3-5"><title><inline-formula><mml:math id="inf149"><mml:mi>P</mml:mi></mml:math></inline-formula>-hacking dramatically increases the probability of canonizing false claims</title><p>Our model has been based on the optimistic premise that the significance levels reported in each study accurately reflect the actual false positive rates. This means that there is only a 5% chance that a false claim will yield a positive result at the <inline-formula><mml:math id="inf150"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> level.</p><p>In practice, reported significance levels can be misleading. Questionable research practices of all sorts can result in higher-than-reported false positive rates; these include p-hacking (<xref ref-type="bibr" rid="bib33">Head et al., 2015</xref>), outcome switching (<xref ref-type="bibr" rid="bib37">Le Noury et al., 2015</xref>), unreported multiple comparisons (<xref ref-type="bibr" rid="bib53">Tannock, 1996</xref>), data dredging (<xref ref-type="bibr" rid="bib50">Smith and Ebrahim, 2002</xref>), HARKing—hypothesizing after the results are known (<xref ref-type="bibr" rid="bib28">Kerr, 1998</xref>), data-dependent analysis (<xref ref-type="bibr" rid="bib20">Gelman and Loken, 2014</xref>), and opportunistic stopping or continuation (<xref ref-type="bibr" rid="bib41">Pocock, 1987</xref>). Insufficient validation of new technologies, or even software problems can also drive realized error rates far above what is expected given stated levels of statistical confidence (see e.g. ref. <xref ref-type="bibr" rid="bib16">Eklund et al., 2016</xref>). Research groups may be positively disposed toward their prior hypotheses or reluctant to contradict the work of closely allied labs. Finally, industry-sponsored clinical trials often allow the sponsors some degree of control over whether results are published (<xref ref-type="bibr" rid="bib27">Kasenda et al., 2016</xref>), resulting in an additional source of publication bias separate from the journal acceptance process.</p><p>To understand the consequences of these problems and practices, we can extend our model to distinguish the actual false positive rate <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub></mml:math></inline-formula> from the nominal false positive rate <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>α</mml:mi><mml:mtext>nom</mml:mtext></mml:msub></mml:math></inline-formula> which is reported in the paper and used by readers to draw their inferences. We assume the actual false positive rate is always at least as large as the nominal rate, that is, <inline-formula><mml:math id="inf153"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>nom</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>. In this scenario, the probability that a false claim leads to a positive published outcome depends on the actual false positive rate, i.e.,<disp-formula id="equ16"><mml:math id="m16"><mml:mrow><mml:mrow><mml:msub><mml:mi>ω</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM143"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>However, the change in belief following a positive or negative published outcome respectively depends on the nominal false positive rate:<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mtext>nom</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mtext>nom</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>An inflated false positive rate makes it much more likely that false claims will be canonized as true facts (<xref ref-type="fig" rid="fig8">Figure 8</xref>). For example, suppose the false negative rate is <inline-formula><mml:math id="inf154"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula> and the nominal false positive rate is <inline-formula><mml:math id="inf155"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>nom</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, but the actual false positive rate is <inline-formula><mml:math id="inf156"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula>. Even eliminating publication bias against negative outcomes (i.e., <inline-formula><mml:math id="inf157"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) and using strong evidentiary standards does not eliminate the possibility that false claims will be canonized as facts under these circumstances (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Less dramatic inflation of the false positive rate leaves open the possibility that true vs. false claims can be distinguished, but only if a higher percentage of negative outcomes is published.<fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.009</object-id><label>Figure 8.</label><caption><title><inline-formula><mml:math id="inf158"><mml:mi>p</mml:mi></mml:math></inline-formula>-hacking dramatically increases the chances of canonizing false claims.</title><p>Probability that a false claim is canonized as fact vs. fraction of negative outcomes. Throughout, all positive outcomes are published (<inline-formula><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), and the nominal false positive rate is <inline-formula><mml:math id="inf160"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>nom</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, the false negative rate is <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, and evidentiary standards are strong (<inline-formula><mml:math id="inf162"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math></inline-formula>). Curves show actual false positive rates <inline-formula><mml:math id="inf164"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mtext>act</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> (yellow), <inline-formula><mml:math id="inf165"><mml:mrow><mml:mn id="XM140">0.10</mml:mn><mml:mo>,</mml:mo><mml:mi id="XM141" mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mn id="XM142">0.25</mml:mn></mml:mrow></mml:math></inline-formula> (red). Compared with <xref ref-type="fig" rid="fig4">Figure 4C</xref>, in which the nominal rates are equal to the actual rates, the probability of canonizing a false claim as fact is substantially higher.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.009">http://dx.doi.org/10.7554/eLife.21451.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig8-v1"/></fig></p></sec><sec id="s3-6"><title>Increasing negative publication rates as a claim approaches canonization greatly increases accuracy</title><p>Thus far we have told a troubling story. Without high probabilities of publication for negative results, the scientific process may perform poorly at distinguishing true claims from false ones. And there are plenty of reasons to suspect that negative results are not always be likely to be published.</p><p>However, authors, reviewers, and editors are all drawn to unexpected results that challenge or modify prevalent views—and for a claim widely believed to be true, a negative result from a well-designed study is surprising. As a consequence, the probability of publishing a negative result may be higher for claims that are already considered likely to be true (<xref ref-type="bibr" rid="bib48">Silvertown and McConway, 1997</xref>; <xref ref-type="bibr" rid="bib23">Ioannidis, 2005</xref>)</p><p>In a simulation of point estimation by successive experimentation, de Winter and Happee considered an even more extreme situation in which it is only possible to publish results that contradict the prevailing wisdom (<xref ref-type="bibr" rid="bib10">de Winter and Happee, 2013</xref>). They argue that this has efficiency benefits, but their results have been challenged persuasively by van Assen and colleagues (<xref ref-type="bibr" rid="bib55">van Assen et al., 2014</xref>). In any event, such a publication strategy would not work in the framework we consider here, because a claim could neither be canonized nor rejected if each new published result were required to contradict the current beliefs of the community.</p><p>Some meta-analyses have revealed patterns consistent with this model (<xref ref-type="bibr" rid="bib42">Poulin, 2000</xref>). For example, when the fluctuating asymmetry hypothesis was proposed in evolutionary ecology, the initial publications exclusively reported strong associations between symmetry and attractiveness or mating success. As time passed, however, an increasing fraction of the papers on this hypothesis reported negative findings with no association between these variables (<xref ref-type="bibr" rid="bib49">Simmons et al., 1999</xref>). A likely interpretation is that initially journals were reluctant to publish results inconsistent with the hypothesis, but as it became better established, negative results came to be viewed as interesting and worthy of publication (<xref ref-type="bibr" rid="bib49">Simmons et al., 1999</xref>; <xref ref-type="bibr" rid="bib40">Palmer, 2000</xref>; <xref ref-type="bibr" rid="bib26">Jennions and Møller, 2002</xref>).</p><p>To explore the consequences of this effect, we consider a model in which the probability of publishing a negative outcome increases linearly from a baseline value <inline-formula><mml:math id="inf166"><mml:msub><mml:mi>ρ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula> when belief in the claim is weak, to a maximum value of <inline-formula><mml:math id="inf167"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> when belief in the claim is strong. We assume that the probability of publishing a negative outcome is <inline-formula><mml:math id="inf168"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow id="XM152"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf169"><mml:msub><mml:mi>ρ</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math></inline-formula> is the baseline probability for publishing negative outcomes, and <inline-formula><mml:math id="inf170"><mml:mi>q</mml:mi></mml:math></inline-formula> is the current belief. As before, our agents are unaware of any publication bias in updating their own beliefs.</p><p><xref ref-type="fig" rid="fig9">Figure 9</xref> indicates that dynamic publication rates can markedly reduce (though not eliminate) the false canonization rate under many scenarios. In particular, <xref ref-type="fig" rid="fig9">Figure 9</xref> suggests that even if it is difficult to publish negative outcomes for claims already suspected to be false, we can still accurately sort true claims from false ones provided that negative outcomes are more readily published for claims nearing canonization. In practice, this mechanism may play an important role in preventing false results from becoming canonized more frequently.<fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.21451.010</object-id><label>Figure 9.</label><caption><title>Publishing a larger fraction of negative outcomes as belief increases lessens the chances of canonizing false claims.</title><p>Probability that a false claim is mistakenly canonized as a true fact vs. baseline probability of publishing a negative outcome. The baseline probability of publishing a negative outcome is the probability that prevails when belief in the claim is weak. The actual probability of publishing a negative outcome increases linearly from the baseline rate when belief is 0 to a value of 1 when belief is 1. All other parameters are the same as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.21451.010">http://dx.doi.org/10.7554/eLife.21451.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-21451-fig9-v1"/></fig></p></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>In the model of scientific inquiry that we have developed here, publication bias creates serious problems. While true claims will seldom be rejected, publication bias has the potential to cause many false claims to be mistakenly canonized as facts. This can be avoided only if a substantial fraction of negative results are published. But at present, publication bias appears to be strong, given that only a small fraction of the published scientific literature presents negative results. Presumably many negative results are going unreported. While this problem has been noted before (<xref ref-type="bibr" rid="bib29">Knight, 2003</xref>), we do not know of any previous formal analysis of its consequences regarding the establishment of scientific facts.</p><sec id="s4-1"><title>Should scientists publish all of their results?</title><p>There is an active debate over whether science functions most effectively when researchers publish all of their results, or when they publish only a select subset of their findings <xref ref-type="bibr" rid="bib34">Nelson et al,, 2012</xref>; <xref ref-type="bibr" rid="bib10">de Winter and Happee, 2013</xref>; <xref ref-type="bibr" rid="bib55"> van Assen et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">McElreath and Smaldino, 2015</xref>). In our model, we observe no advantage to selective publication; in all cases treated we find that false canonization decreases monotonically with increasing publication of negative results. This seems logical enough. Decision theory affirms that in the absence of information costs, withholding information cannot on average improve performance in a decision problem such as the classification task we treat here (<xref ref-type="bibr" rid="bib47">Savage, 1954</xref>; <xref ref-type="bibr" rid="bib21">Good, 1967</xref>; <xref ref-type="bibr" rid="bib43">Ramsey, 1990</xref>). As <xref ref-type="bibr" rid="bib21">Good (1967)</xref> notes, a decision-maker “should use all the evidence <italic>already</italic> available, provided that the cost of doing so is negligible.”</p><p>Nonetheless, several research groups have argued that selective publishing can be more efficient than publishing the results of all studies. Clearly they must be implicitly or explicitly imposing costs of some sort on the acts of publishing papers or reading them, and it can be instructive to see where these costs lie. One source of such costs comes simply from the increased volume of scientific literature that ensues when all results are published; this is sometimes known as the “cluttered office” effect (<xref ref-type="bibr" rid="bib34">Nelson et al., 2012</xref>). If we envision that search costs increase with the volume of literature, for example, it may be beneficial not to publish everything.</p><p>Another possible cost is that of actually writing a paper and going through the publication process. If preparing a paper for publication is costly relative to doing the experiments which would be reported, it may be advantageous to publish only a subset of all experimental results. This is the argument that de Winter and Happee make when, in a mathematical model of point estimation, they find that selective publication minimizes the variance <italic>given the number of publications</italic> (as opposed to the number of experiments conducted). Note, however, that they assume a model of science in which experiments are only published when they contradict the prevailing wisdom—and that their results have been roundly challenged in a followup analysis (<xref ref-type="bibr" rid="bib55"> van Assen et al., 2014</xref>).</p><p><xref ref-type="bibr" rid="bib32">McElreath and Smaldino (2015)</xref> analyzed a model that is more similar to ours in structure. As we do, they consider repeated tests of binary-valued hypotheses. But rather than focusing on a single claim at a time, they model the progress of a group of scientists testing a suite of hypotheses. Based on this model, McElreath and Smaldino conclude that there can be advantages to selective publication under certain conditions.</p><p>While selective publication certainly can ameliorate the cluttered office problem—observed in their model as the flocking of researchers to questions already shown likely to be false—we are skeptical about the other advantages to selective publication. McElreath and Smaldino’s model and results appear to rely in part on their assumption that “the only information relevant for judging the truth of a hypothesis is its <italic>tally</italic>, the difference between the number of published positive and the number of published negative findings” (p. 3).</p><p>As a mathematical claim, this is incorrect. Presumably the claim is instead intended to be a tactical assumption that serves to simplify the analysis. But this assumption is severely limiting. The tally is often an inadequate summary of the evidence in favor of a hypothesis. One can see the problem with looking only at the tally by considering a simple example in which false positive rates are very low, false negative rates are high, and all studies are published. There is mild evidence that a hypothesis is false if no positive studies and one negative study have been published, but there is strong evidence that the hypothesis is true if three positive and four negative studies have been published. Yet both situations share the same tally: <inline-formula><mml:math id="inf171"><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The same problem arises when publication bias causes positive and negative findings to be published at different rates.</p><p>If one is forced to use only the tally to make decisions, an agent can sometimes make better inferences by throwing away some of the data (i.e., under selective publication). For example, when false negatives are common it may be beneficial to suppress some fraction of the negative results lest they swamp any signal from true positive findings. This is not the case when the agent has access to complete information about the number of positive and the number of negative results published. As a result, it is unclear whether most of McElreath and Smaldino’s arguments in favor of selective publication are relevant to optimal scientific inference, or whether they are consequences of the assumption that agents draw their inferences based on the tally alone.</p></sec><sec id="s4-2"><title>What do we do about the problem of publication bias?</title><p>Several studies have indicated that much of the publication bias observed in science can be attributed to authors not writing up null results, rather than journals rejecting null results (<xref ref-type="bibr" rid="bib11">Dickersin et al., 1992</xref>; <xref ref-type="bibr" rid="bib38">Olson et al., 2002</xref>; <xref ref-type="bibr" rid="bib19">Franco et al., 2014</xref>). This does not necessarily exonerate the journals; authors may be responding to incentives that the journals have put in place (<xref ref-type="bibr" rid="bib51">Song et al., 2000</xref>). Authors may be motivated by other reputational factors as well. It would be a very unusual job talk, promotion seminar, or grant application that was based primarily upon negative findings.</p><p>So what can we as a scientific community do? How can we avoid canonizing too many false claims, so that we can be confident in the veracity of most scientific facts? In this paper, we have shown that strengthening evidentiary standards does not necessarily help. In the presence of strong publication bias, false claims become canonized as fact not so much because of a few misleading chance results, but rather because on average, misleading results are more likely to be published than correct ones.</p><p>Fortunately, this problem may be ameliorated by several current aspects of the publication process. In this paper, we have modeled claims that have only one way of generating “positive” results. For many scientific claims, e.g. those like our Dicer example that propose particular mechanisms, this may be appropriate. In other cases, however, results may be continuous: not only do we care whether variables <inline-formula><mml:math id="inf172"><mml:mi>X</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf173"><mml:mi>Y</mml:mi></mml:math></inline-formula> are correlated, but also we want to know about the strength of the correlation, for example. This does not make the problem go away, if stronger or highly significant correlations are seen as more worthy of publication than weaker or non-significant correlations. However, one advantage of framing experimental results as continuous-valued instead of binary is that there may be multiple opposing directions in which a result could be considered positive. For example, the expression of two genes could be correlated, uncorrelated, or anticorrelated. Both correlation and anticorrelation might be seen as positive results, whereas the null result of no correlation could be subject to publication bias. But suppose there is truly no effect: what does publication bias do in this case? We would expect to see false positives in both directions. Meta-analysis would readily pick up the lack of a consistent direction of the effect, and (if the authors avoid mistakenly inferring population heterogeneity) it is unlikely that correlations in either direction would be falsely canonized as fact.</p><p>Our model assumes that research continues until each claim is either rejected or canonized as fact. In practice, researchers can and do lose interest in certain claims. False claims might generate more conflicting results, or take longer to reach one of the evidentiary thresholds; either mechanism could lead researchers to move on to other problems and leave the claim as unresolved. If this is the case, we might expect that instead of being rejected or canonized as fact, many false claims might simply be abandoned.</p><p>Another possible difference between the model and the real world is that we model the evidentiary standards as symmetric, but in practice it may require less certainty to discard a claim as false than it requires to accept the same claim as fact. In this case, the probability of rejecting false claims would be higher than predicted in our model—possibly with only a very small increase in the probability of rejecting true claims.</p><p>The scientific community could also actively respond to the problem of canonizing false claims. One of the most direct ways would be to invest more heavily in the publication of negative results. A number of new journals or collections within journals have been established to specialize in publishing negative results. These include Elsevier’s <italic>New Negatives in Plant Science</italic>, <italic>PLOS One’s</italic> Positively Negative collection, Biomed Central’s <italic>Journal of Negative Results in Biomedicine</italic>, and many others (<xref ref-type="bibr" rid="bib15">Editors, 2016</xref>). Alternatively, peer reviewed publication may be unnecessary; simply publishing negative results on preprint archives such as the arXiv, bioRxiv, and SocArXiv may make these results sufficiently visible. In either case, we face an incentive problem: if researchers accrue scant credit or reward for their negative findings, there is little reason for them to invest the substantial time needed in taking a negative result from a bench-top disappointment to a formal publication.</p><p>Another possibility—which may already be in play—involves shifting probabilities of publishing negative results. We have shown that if negative results become easier to publish as a claim becomes better established, this can greatly reduce the probability of canonizing false claims. One possibility is that negative results may become easier to publish as they become more surprising to the community, i.e., as researchers become increasingly convinced that a claim is true. Referees and journal editors could make an active effort to value papers of this sort. At present, however, our experience suggests that negative results or even corrections of blatant errors in previous publications rarely land in journals of equal prestige to those that published the original positive studies (<xref ref-type="bibr" rid="bib31">Matosin et al., 2014</xref>).</p><p>A final saving grace is that even after false claims are established as facts, science can still self-correct. In this paper, we have assumed for simplicity that claims are independent propositions, but in practice claims are entangled in a web of logical interrelations. When a false claim is canonized as fact, inconsistencies between it and other facts soon begin to accumulate until the field is forced to reevaluate the conflicting facts. Results that resolve these conflicts by disproving accepted facts then take on a special significance and suffer little of the stigma placed upon negative results. Until the scientific community finds more ways to deal with publication bias, this may be an essential corrective to a process that sometimes loses its way.</p><p>We conclude with a note on what this work tells us about the value of science as a means of comprehending the natural world. Science denialists on both ends of the ideological spectrum might be tempted to invoke our findings as justification for their world-views. This would be a mistake. The facts that science denialists target are almost always very different from the types of facts we are modeling. We are modeling small-scale facts of modest import, the kind that would be established based on one or two dozen studies and then considered settled. The reality of anthropogenic climate change, the lack of connection between vaccination and autism, or the causative role of smoking in cancer are very different. Facts of this sort have enormous practical importance; they are supported by massive volumes of research; and they have been established despite well-funded groups with powerful incentives to expose any evidence that might give cause for skepticism. The process by which false claims can become canonized as fact in our model simply would not operate under these circumstances.</p><p>Of all the institutions and methods that humankind have developed to make sense of our universe, science has proven unparalleled in its power to generate useful models of physical phenomena. Nothing that we have written here changes this. The point of asking questions such as those in the present paper is not to de-legitimize science, but rather to improve the accuracy and efficiency of scientific inquiry.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank Jacob G Foster, Frazer Meacham and Kevin Zollman for helpful comments and suggestions on the manuscript. This work was supported by the Danish National Research Foundation and by a generous grant to the Metaknowledge Network from the John Templeton Foundation. KG thanks the University of Washington Department of Biology for sabbatical support.</p></ack><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf2"><p>CTB: Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>SBN, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>TM, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con3"><p>KG, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con4"><p>CTB, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Arbesman</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>The Half-Life of Facts: Why Everything We Know Has an Expiration Date</source><publisher-name>Penguin</publisher-name></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>1,500 scientists lift the lid on reproducibility</article-title><source>Nature</source><volume>533</volume><fpage>452</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1038/533452a</pub-id><pub-id pub-id-type="pmid">27225100</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begg</surname><given-names>CB</given-names></name><name><surname>Berlin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Publication bias: a problem in interpreting medical data</article-title><source>Journal of the Royal Statistical Society. Series A</source><volume>151</volume><fpage>419</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.2307/2982993</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begley</surname><given-names>CG</given-names></name><name><surname>Ellis</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Drug development: Raise standards for preclinical cancer research</article-title><source>Nature</source><volume>483</volume><fpage>531</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/483531a</pub-id><pub-id pub-id-type="pmid">22460880</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernstein</surname><given-names>E</given-names></name><name><surname>Caudy</surname><given-names>AA</given-names></name><name><surname>Hammond</surname><given-names>SM</given-names></name><name><surname>Hannon</surname><given-names>GJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Role for a bidentate ribonuclease in the initiation step of RNA interference</article-title><source>Nature</source><volume>409</volume><fpage>363</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/35053110</pub-id><pub-id pub-id-type="pmid">11201747</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Camerer</surname><given-names>CF</given-names></name><name><surname>Dreber</surname><given-names>A</given-names></name><name><surname>Forsell</surname><given-names>E</given-names></name><name><surname>Ho</surname><given-names>TH</given-names></name><name><surname>Huber</surname><given-names>J</given-names></name><name><surname>Johannesson</surname><given-names>M</given-names></name><name><surname>Kirchler</surname><given-names>M</given-names></name><name><surname>Almenberg</surname><given-names>J</given-names></name><name><surname>Altmejd</surname><given-names>A</given-names></name><name><surname>Chan</surname><given-names>T</given-names></name><name><surname>Heikensten</surname><given-names>E</given-names></name><name><surname>Holzmeister</surname><given-names>F</given-names></name><name><surname>Imai</surname><given-names>T</given-names></name><name><surname>Isaksson</surname><given-names>S</given-names></name><name><surname>Nave</surname><given-names>G</given-names></name><name><surname>Pfeiffer</surname><given-names>T</given-names></name><name><surname>Razen</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Evaluating replicability of laboratory experiments in economics</article-title><source>Science</source><volume>351</volume><fpage>1433</fpage><lpage>1436</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0918</pub-id><pub-id pub-id-type="pmid">26940865</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>AW</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Identifying outcome reporting bias in randomised trials on PubMed: review of publications and survey of authors</article-title><source>BMJ</source><volume>330</volume><elocation-id>753</elocation-id><pub-id pub-id-type="doi">10.1136/bmj.38356.424606.8F</pub-id><pub-id pub-id-type="pmid">15681569</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>AC</given-names></name><name><surname>Li</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Is economics research replicable? sixty published papers from thirteen journals say “usually Not</article-title><source>Finance and Economics Discussion Series</source><volume>083</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.17016/feds.2015.083</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csada</surname><given-names>RD</given-names></name><name><surname>James</surname><given-names>PC</given-names></name><name><surname>Espie</surname><given-names>RHM</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The &quot;file drawer problem&quot; of non-significant results: does it apply to biological research?</article-title><source>Oikos</source><volume>76</volume><fpage>591</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.2307/3546355</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Winter</surname><given-names>J</given-names></name><name><surname>Happee</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Why selective publication of statistically significant results can be effective</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e66463</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0066463</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dickersin</surname><given-names>K</given-names></name><name><surname>Min</surname><given-names>YI</given-names></name><name><surname>Meinert</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Factors influencing publication of research results. follow-up of applications submitted to two institutional review boards</article-title><source>JAMA</source><volume>267</volume><fpage>374</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1001/jama.267.3.374</pub-id><pub-id pub-id-type="pmid">1727960</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dickersin</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The existence of publication bias and risk factors for its occurrence</article-title><source>JAMA</source><volume>263</volume><fpage>1385</fpage><pub-id pub-id-type="doi">10.1001/jama.1990.03440100097014</pub-id><pub-id pub-id-type="pmid">2406472</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Easterbrook</surname><given-names>PJ</given-names></name><name><surname>Gopalan</surname><given-names>R</given-names></name><name><surname>Berlin</surname><given-names>JA</given-names></name><name><surname>Matthews</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Publication bias in clinical research</article-title><source>The Lancet</source><volume>337</volume><fpage>867</fpage><lpage>872</lpage><pub-id pub-id-type="doi">10.1016/0140-6736(91)90201-Y</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebrahim</surname><given-names>S</given-names></name><name><surname>Sohani</surname><given-names>ZN</given-names></name><name><surname>Montoya</surname><given-names>L</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name><name><surname>Thorlund</surname><given-names>K</given-names></name><name><surname>Mills</surname><given-names>EJ</given-names></name><name><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reanalyses of randomized clinical trial data</article-title><source>JAMA</source><volume>312</volume><fpage>1024</fpage><lpage>1032</lpage><pub-id pub-id-type="doi">10.1001/jama.2014.9646</pub-id><pub-id pub-id-type="pmid">25203082</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>Editors</collab></person-group><year iso-8601-date="2016">2016</year><article-title>Go forth and replicate!</article-title><source>Nature</source><volume>536</volume><elocation-id>373</elocation-id><pub-id pub-id-type="doi">10.1038/536373a</pub-id><pub-id pub-id-type="pmid">27558028</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eklund</surname><given-names>A</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Knutsson</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates</article-title><source>PNAS</source><volume>113</volume><fpage>7900</fpage><lpage>7905</lpage><pub-id pub-id-type="doi">10.1073/pnas.1602413113</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Errington</surname><given-names>TM</given-names></name><name><surname>Iorns</surname><given-names>E</given-names></name><name><surname>Gunn</surname><given-names>W</given-names></name><name><surname>Tan</surname><given-names>FE</given-names></name><name><surname>Lomax</surname><given-names>J</given-names></name><name><surname>Nosek</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An open investigation of the reproducibility of cancer biology research</article-title><source>eLife</source><volume>3</volume><elocation-id>e04333</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04333</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fanelli</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Negative results are disappearing from most disciplines and countries</article-title><source>Scientometrics</source><volume>90</volume><fpage>891</fpage><lpage>904</lpage><pub-id pub-id-type="doi">10.1007/s11192-011-0494-7</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franco</surname><given-names>A</given-names></name><name><surname>Malhotra</surname><given-names>N</given-names></name><name><surname>Simonovits</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Social science. publication bias in the social sciences: unlocking the file drawer</article-title><source>Science</source><volume>345</volume><fpage>1502</fpage><lpage>1505</lpage><pub-id pub-id-type="doi">10.1126/science.1255484</pub-id><pub-id pub-id-type="pmid">25170047</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Loken</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The statistical crisis in science</article-title><source>American Scientist</source><volume>102</volume><fpage>460</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1511/2014.111.460</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Good</surname><given-names>IJ</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>On the principle of total evidence</article-title><source>The British Journal for the Philosophy of Science</source><volume>17</volume><fpage>319</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1093/bjps/17.4.319</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Higginson</surname><given-names>AD</given-names></name><name><surname>Munafò</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Current incentives for scientists lead to underpowered studies with erroneous conclusions</article-title><source>PLoS Biology</source><volume>14</volume><elocation-id>e2000995</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2000995</pub-id><pub-id pub-id-type="pmid">27832072</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Why most published research findings are false</article-title><source>PLoS Medicine</source><volume>2</volume><elocation-id>e124</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pmed.0020124</pub-id><pub-id pub-id-type="pmid">16060722</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioannidis</surname><given-names>JP</given-names></name><name><surname>Trikalinos</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Early extreme contradictory estimates may appear in published research: the Proteus phenomenon in molecular genetics research and randomized trials</article-title><source>Journal of Clinical Epidemiology</source><volume>58</volume><fpage>543</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2004.10.019</pub-id><pub-id pub-id-type="pmid">15878467</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaskiewicz</surname><given-names>L</given-names></name><name><surname>Filipowicz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Role of dicer in posttranscriptional RNA silencing</article-title><source>Current Topics in Microbiology and Immunology</source><volume>320</volume><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1007/978-3-540-75157-1_4</pub-id><pub-id pub-id-type="pmid">18268840</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jennions</surname><given-names>MD</given-names></name><name><surname>Moller</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Relationships fade with time: a meta-analysis of temporal trends in publication in ecology and evolution</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>269</volume><fpage>43</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1098/rspb.2001.1832</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasenda</surname><given-names>B</given-names></name><name><surname>von Elm</surname><given-names>E</given-names></name><name><surname>You</surname><given-names>JJ</given-names></name><name><surname>Blümle</surname><given-names>A</given-names></name><name><surname>Tomonaga</surname><given-names>Y</given-names></name><name><surname>Saccilotto</surname><given-names>R</given-names></name><name><surname>Amstutz</surname><given-names>A</given-names></name><name><surname>Bengough</surname><given-names>T</given-names></name><name><surname>Meerpohl</surname><given-names>JJ</given-names></name><name><surname>Stegert</surname><given-names>M</given-names></name><name><surname>Olu</surname><given-names>KK</given-names></name><name><surname>Tikkinen</surname><given-names>KA</given-names></name><name><surname>Neumann</surname><given-names>I</given-names></name><name><surname>Carrasco-Labra</surname><given-names>A</given-names></name><name><surname>Faulhaber</surname><given-names>M</given-names></name><name><surname>Mulla</surname><given-names>SM</given-names></name><name><surname>Mertz</surname><given-names>D</given-names></name><name><surname>Akl</surname><given-names>EA</given-names></name><name><surname>Bassler</surname><given-names>D</given-names></name><name><surname>Busse</surname><given-names>JW</given-names></name><name><surname>Ferreira-González</surname><given-names>I</given-names></name><name><surname>Lamontagne</surname><given-names>F</given-names></name><name><surname>Nordmann</surname><given-names>A</given-names></name><name><surname>Gloy</surname><given-names>V</given-names></name><name><surname>Raatz</surname><given-names>H</given-names></name><name><surname>Moja</surname><given-names>L</given-names></name><name><surname>Ebrahim</surname><given-names>S</given-names></name><name><surname>Schandelmaier</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Vandvik</surname><given-names>PO</given-names></name><name><surname>Johnston</surname><given-names>BC</given-names></name><name><surname>Walter</surname><given-names>MA</given-names></name><name><surname>Burnand</surname><given-names>B</given-names></name><name><surname>Schwenkglenks</surname><given-names>M</given-names></name><name><surname>Hemkens</surname><given-names>LG</given-names></name><name><surname>Bucher</surname><given-names>HC</given-names></name><name><surname>Guyatt</surname><given-names>GH</given-names></name><name><surname>Briel</surname><given-names>M</given-names></name><name><surname>Blümle</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Agreements between industry and academia on publication rights: A retrospective study of protocols and publications of randomized clinical trials</article-title><source>PLoS Medicine</source><volume>13</volume><elocation-id>e1002046</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pmed.1002046</pub-id><pub-id pub-id-type="pmid">27352244</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerr</surname><given-names>NL</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>HARKing: hypothesizing after the results are known</article-title><source>Personality and Social Psychology Review</source><volume>2</volume><fpage>196</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1207/s15327957pspr0203_4</pub-id><pub-id pub-id-type="pmid">15647155</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knight</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Negative results: Null and void</article-title><source>Nature</source><volume>422</volume><fpage>554</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1038/422554a</pub-id><pub-id pub-id-type="pmid">12686968</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Latour</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1987">1987</year><source>Science in Action: How to Follow Scientists and Engineers Through Society</source><publisher-name>Harvard University Press</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matosin</surname><given-names>N</given-names></name><name><surname>Frank</surname><given-names>E</given-names></name><name><surname>Engel</surname><given-names>M</given-names></name><name><surname>Lum</surname><given-names>JS</given-names></name><name><surname>Newell</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Negativity towards negative results: a discussion of the disconnect between scientific worth and scientific culture</article-title><source>Disease Models &amp; Mechanisms</source><volume>7</volume><fpage>171</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1242/dmm.015123</pub-id><pub-id pub-id-type="pmid">24713271</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McElreath</surname><given-names>R</given-names></name><name><surname>Smaldino</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Replication, communication, and the population dynamics of scientific discovery</article-title><source>PLoS One</source><volume>10</volume><elocation-id>e0136088</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0136088</pub-id><pub-id pub-id-type="pmid">26308448</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Head</surname><given-names>ML</given-names></name><name><surname>Holman</surname><given-names>L</given-names></name><name><surname>Lanfear</surname><given-names>R</given-names></name><name><surname>Kahn</surname><given-names>AT</given-names></name><name><surname>Jennions</surname><given-names>MD</given-names></name><name><surname>Megan</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The extent and consequences of p-hacking in science</article-title><source>PLoS Biology</source><volume>13</volume><elocation-id>e1002106</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002106</pub-id><pub-id pub-id-type="pmid">25768323</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>LD</given-names></name><name><surname>simmons</surname><given-names>JP</given-names></name><name><surname>simonsohn</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>let’s publish fewer papers</article-title><source>Psychological Inquiry</source><volume>233</volume><fpage>291</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1080/1047840x.2012.705245</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newcombe</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Towards a reduction in publication bias</article-title><source>BMJ</source><volume>295</volume><fpage>656</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1136/bmj.295.6599.656</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Norris</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Markov Chains</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Noury</surname><given-names>J</given-names></name><name><surname>Nardo</surname><given-names>JM</given-names></name><name><surname>Healy</surname><given-names>D</given-names></name><name><surname>Jureidini</surname><given-names>J</given-names></name><name><surname>Raven</surname><given-names>M</given-names></name><name><surname>Tufanaru</surname><given-names>C</given-names></name><name><surname>Abi-Jaoude</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Restoring study 329: efficacy and harms of paroxetine and imipramine in treatment of major depression in adolescence</article-title><source>BMJ</source><volume>351</volume><elocation-id>h4320</elocation-id><pub-id pub-id-type="doi">10.1136/bmj.h4320</pub-id><pub-id pub-id-type="pmid">26376805</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olson</surname><given-names>CM</given-names></name><name><surname>Rennie</surname><given-names>D</given-names></name><name><surname>Cook</surname><given-names>D</given-names></name><name><surname>Dickersin</surname><given-names>K</given-names></name><name><surname>Flanagin</surname><given-names>A</given-names></name><name><surname>Hogan</surname><given-names>JW</given-names></name><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Reiling</surname><given-names>J</given-names></name><name><surname>Pace</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Publication bias in editorial decision making</article-title><source>JAMA</source><volume>287</volume><fpage>2825</fpage><lpage>2828</lpage><pub-id pub-id-type="doi">10.1001/jama.287.21.2825</pub-id><pub-id pub-id-type="pmid">12038924</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>Open Science Collaboration</collab></person-group><year iso-8601-date="2015">2015</year><article-title>PSYCHOLOGY. Estimating the reproducibility of psychological science</article-title><source>Science</source><volume>349</volume><elocation-id>aac4716</elocation-id><pub-id pub-id-type="doi">10.1126/science.aac4716</pub-id><pub-id pub-id-type="pmid">26315443</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Quasi-replication and the contract of error: lessons from sex ratios, heritabilities and fluctuating asymmetry</article-title><source>Annual Review of Ecology and Systematics</source><volume>31</volume><fpage>441</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1146/annurev.ecolsys.31.1.441</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pocock</surname><given-names>SJ</given-names></name><name><surname>Hughes</surname><given-names>MD</given-names></name><name><surname>Lee</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Statistical problems in the reporting of clinical trials</article-title><source>New England Journal of Medicine</source><volume>317</volume><fpage>426</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1056/NEJM198708133170706</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Manipulation of host behaviour by parasites: a weakening paradigm?</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>267</volume><fpage>787</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1098/rspb.2000.1072</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramsey</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Weight or the value of knowledge</article-title><source>The British Journal for the Philosophy of Science</source><volume>41</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1093/bjps/41.1.1</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravetz</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Scientific knowledge and its social problems</article-title><source>British Society for the Philosophy of Science</source><volume>7</volume><elocation-id>72</elocation-id><pub-id pub-id-type="doi">10.1017/s0007087400012875</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>The file drawer problem and tolerance for null results</article-title><source>Psychological Bulletin</source><volume>86</volume><fpage>638</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.86.3.638</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rzhetsky</surname><given-names>A</given-names></name><name><surname>Iossifov</surname><given-names>I</given-names></name><name><surname>Loh</surname><given-names>JM</given-names></name><name><surname>White</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Microparadigms: Chains of collective reasoning in publications about molecular interactions</article-title><source>PNAS</source><volume>103</volume><fpage>4940</fpage><lpage>4945</lpage><pub-id pub-id-type="doi">10.1073/pnas.0600591103</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Savage</surname><given-names>LJ</given-names></name></person-group><year iso-8601-date="1954">1954</year><source>The Foundations of Statistics</source><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvertown</surname><given-names>J</given-names></name><name><surname>McConway</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Does &quot;publication bias&quot; lead to biased science?</article-title><source>Oikos</source><volume>79</volume><fpage>167</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.2307/3546101</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simmons</surname><given-names>LW</given-names></name><name><surname>Tomkins</surname><given-names>JL</given-names></name><name><surname>Kotiaho</surname><given-names>JS</given-names></name><name><surname>Hunt</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Fluctuating paradigm</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>266</volume><fpage>593</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1098/rspb.1999.0677</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>GD</given-names></name><name><surname>Ebrahim</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Data dredging, bias, or confounding</article-title><source>BMJ</source><volume>325</volume><fpage>1437</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1136/bmj.325.7378.1437</pub-id><pub-id pub-id-type="pmid">12493654</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>F</given-names></name><name><surname>Eastwood</surname><given-names>AJ</given-names></name><name><surname>Gilbody</surname><given-names>S</given-names></name><name><surname>Duley</surname><given-names>L</given-names></name><name><surname>Sutton</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Publication and related biases</article-title><source>Health Technology Assessment</source><volume>4</volume><fpage>1</fpage><lpage>115</lpage><pub-id pub-id-type="pmid">10932019</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterling</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Publication decisions and their possible effects on inferences drawn from tests of significance –Or vice versa</article-title><source>Journal of the American Statistical Association</source><volume>54</volume><fpage>30</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1080/01621459.1959.10501497</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tannock</surname><given-names>IF</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>False-positive results in clinical trials: Multiple significance tests and the problem of unreported comparisons</article-title><source>Journal of the National Cancer Institute</source><volume>88</volume><fpage>206</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1093/jnci/88.3-4.206</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>EH</given-names></name><name><surname>Matthews</surname><given-names>AM</given-names></name><name><surname>Linardatos</surname><given-names>E</given-names></name><name><surname>Tell</surname><given-names>RA</given-names></name><name><surname>Rosenthal</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Selective publication of antidepressant trials and its influence on apparent efficacy</article-title><source>New England Journal of Medicine</source><volume>358</volume><fpage>252</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1056/NEJMsa065779</pub-id><pub-id pub-id-type="pmid">18199864</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Assen</surname><given-names>MA</given-names></name><name><surname>van Aert</surname><given-names>RC</given-names></name><name><surname>Nuijten</surname><given-names>MB</given-names></name><name><surname>Wicherts</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Why publishing everything is more effective than selective publishing of statistically significant results</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e84896</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0084896</pub-id><pub-id pub-id-type="pmid">24465448</pub-id></element-citation></ref></ref-list></back></article>