<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research-article">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-01532</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004082</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>On the Number of Neurons and Time Scale of Integration Underlying the Formation of Percepts in the Brain</article-title>
<alt-title alt-title-type="running-head">The Scales of Perceptual Integration in the Brain</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Wohrer</surname> <given-names>Adrien</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Machens</surname> <given-names>Christian K.</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Group for Neural Theory, Laboratoire de Neurosciences Cognitives, INSERM U960, École Normale Supérieure, Paris, France</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Champalimaud Neuroscience Programme, Champalimaud Centre for the Unknown, Lisbon, Portugal</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Pillow</surname> <given-names>Jonathan W.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>The University of Texas at Austin, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: AW CM. Performed the experiments: AW. Analyzed the data: AW. Wrote the paper: AW CM.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label>
<p>Current address: Image-Guided Clinical Neurosciences and Connectomics, EA 7282, Université d’Auvergne, Clermont-Ferrand, France</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">adrien.wohrer@udamail.fr</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>3</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>20</day>
<month>3</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>3</issue>
<elocation-id>e1004082</elocation-id>
<history>
<date date-type="received">
<day>27</day>
<month>8</month>
<year>2013</year>
</date>
<date date-type="accepted">
<day>10</day>
<month>12</month>
<year>2014</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Wohrer, Machens</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004082" xlink:type="simple"/>
<abstract>
<p>All of our perceptual experiences arise from the activity of neural populations. Here we study the formation of such percepts under the assumption that they emerge from a linear readout, i.e., a weighted sum of the neurons’ firing rates. We show that this assumption constrains the trial-to-trial covariance structure of neural activities and animal behavior. The predicted covariance structure depends on the readout parameters, and in particular on the temporal integration window <italic>w</italic> and typical number of neurons <italic>K</italic> used in the formation of the percept. Using these predictions, we show how to infer the readout parameters from joint measurements of a subject’s behavior and neural activities. We consider three such scenarios: (1) recordings from the complete neural population, (2) recordings of neuronal sub-ensembles whose size exceeds <italic>K</italic>, and (3) recordings of neuronal sub-ensembles that are smaller than <italic>K</italic>. Using theoretical arguments and artificially generated data, we show that the first two scenarios allow us to recover the typical spatial and temporal scales of the readout. In the third scenario, we show that the readout parameters can only be recovered by making additional assumptions about the structure of the full population activity. Our work provides the first thorough interpretation of (feed-forward) percept formation from a population of sensory neurons. We discuss applications to experimental recordings in classic sensory decision-making tasks, which will hopefully provide new insights into the nature of perceptual integration.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>This article deals with the interpretation of neural activities during perceptual decision-making tasks, where animals must assess the value of a sensory stimulus and take a decision on the basis of their percept. A “standard model” for these tasks has progressively emerged, whence the animal’s percept and subsequent choice on each trial are obtained from a linear integration of the activity of sensory neurons. However, up to date, there has been no principled method to estimate the parameters of this model: mainly, the typical number of neurons <italic>K</italic> from the population involved in conveying the percept, and the typical time scale <italic>w</italic> during which these neurons’ activities are integrated. In this article, we propose a novel method to estimate these quantities from experimental data, and thus assess the validity of the standard model of percept formation. In the process, we clarify the predictions of the standard model regarding two classic experimental measures in these tasks: <italic>sensitivity</italic>, which is the animal’s ability to distinguish nearby stimulus values, and <italic>choice signals</italic>, which assess the amount of correlation between the activity of single neurons and the animal’s ultimate choice on each trial.</p>
</abstract>
<funding-group>
<funding-statement>The authors acknowledge support from an “Emmy-Noether Grant” of the Deutsche Forschungsgemeinschaft (Germany) and a “Chaire d’excellence” of the Agence Nationale de la Recherche (France). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="3"/>
<page-count count="38"/>
</counts>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Most cortical neurons are noisy, or at least appear so in experiments. When we record the responses of sensory neurons to well-controlled stimuli, their spike patterns vary from trial to trial. Does this variability reflect the uncertainties of the measurement process, or does it have a direct impact on behavior? These questions are central to our understanding of percept formation and decision-making in the brain and have been the focus of much previous work [<xref ref-type="bibr" rid="pcbi.1004082.ref001">1</xref>]. Many studies have sought to address these problems by studying animals that perform simple, perceptual decision-making tasks [<xref ref-type="bibr" rid="pcbi.1004082.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>]. In such tasks, an animal is typically presented with different stimuli <italic>s</italic> and trained to categorize them through a simple behavioral report. When this perceptual report is monitored simultaneously with the animal’s neural activity, one can try to find a causal link between the two.</p>
<p>One particular hypothesis about this link—which we refer to as the “sensory noise” hypothesis—postulates that the accuracy of the animal’s perceptual judgments is primarily limited by noise at the level of sensory neurons [<xref ref-type="bibr" rid="pcbi.1004082.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref005">5</xref>]. In terms of signal detection theory, the hypothesis predicts a quantitative match between (1) the animal’s ability to discriminate nearby stimulus values—known as <italic>psychometric</italic> sensitivity, and (2) an ideal observer’s ability to discriminate nearby stimulus values based on the activities of the underlying neural population—known as <italic>neurometric</italic> sensitivity. Both types of sensitivities can be quantified as signal-to-noise ratios (SNR). With this idea in mind, several studies have compared the neurometric and psychometric sensitivities in various sensory systems and behavioral tasks (see [<xref ref-type="bibr" rid="pcbi.1004082.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref007">7</xref>] for reference).</p>
<p>However, as was soon realized, any extrapolation from a few recorded cells to the entire population is fraught with implicit assumptions. For example, if neurons in a population behave independently one from another, then the SNR of the population is simply the sum of the individual SNRs. Consequently, any estimate of neurometric sensitivity will grow linearly with the number of recorded neurons <italic>K</italic>. However, if neurons in a population do not behave independently, the precise growth of neural sensitivity with <italic>K</italic> is determined by the correlation structure of noise in the population [<xref ref-type="bibr" rid="pcbi.1004082.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004082.ref010">10</xref>]. In addition, the neurometric sensitivities also depend on the time scale <italic>w</italic> that is used to integrate each neuron’s spike train in a given trial [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1004082.ref013">13</xref>]. Indeed, the more spikes are incorporated in the readout, the more accurate that readout will be. Adding extra neurons by increasing <italic>K</italic>, or adding extra spikes by increasing <italic>w</italic>, are two dual ways of increasing the readout’s overall SNR.</p>
<p>As there is no unique way of reading out information from a population of sensory neurons, the sensory noise hypothesis can only be tested if we understand how the organism itself “reads out” the relevant information. In other words, how many sensory neurons <italic>K</italic>, and what integration time scale <italic>w</italic>, provide a relevant description of the animal’s percept formation? Given the “<italic>K</italic>-<italic>w</italic>” duality mentioned above, we cannot answer that question based solely on sensitivity (SNR). Another experimental measure should also be included in the analysis.</p>
<p>A good candidate for such a measure are <italic>choice signals</italic>, i.e., measures of the trial-to-trial correlation between the activity of each recorded neuron and the animal’s ultimate choice on each trial. These signals, weak but often significant, arise from the unknown process by which each neuron’s activity influences—or is influenced by—the animal’s perceptual decision. In two-alternative forced choice (2AFC) discrimination tasks, they have generally been computed in the form of <italic>choice probabilities</italic> (CP) [<xref ref-type="bibr" rid="pcbi.1004082.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref015">15</xref>]. The temporal evolution of CPs has been used to find the instants in time when a given population covaries with the animal’s percept [<xref ref-type="bibr" rid="pcbi.1004082.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref016">16</xref>]. In a seminal study, Shadlen et al. (1996) proposed to jointly use sensitivity and choice signals, as two independent constraints characterizing the underlying neural code [<xref ref-type="bibr" rid="pcbi.1004082.ref017">17</xref>]. They derived a feed-forward model of perceptual integration in visual area MT, and studied numerically how the population’s sensitivity and CPs vary as a function of various model parameters. They acknowledged the existence of a link between CPs and pairwise noise correlations—both measures being (partial) reflections of how information is embedded in the neural population as a whole (see also [<xref ref-type="bibr" rid="pcbi.1004082.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref018">18</xref>]). However, the quantitative nature of this link was only revealed recently, when Haefner et al. (2013) derived the analytical expression of CPs in the standard model of perceptual integration [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>] (see <xref ref-type="sec" rid="sec024">Methods</xref>).</p>
<p>In this article, we show that the standard feed-forward model of percept formation gives rise to three <italic>characteristic equations</italic> that describe analytically the trial-to-trial covariance between neural activities and animal percept. These equations depend on the brain’s readout policy across neurons and time, and hold for any noise correlation structure in the neural population. In accordance with the intuition of Shadlen et al. (1996), we show that sensitivity and choice signals correspond to two distinct, characteristic properties of the readout. The equation describing choice signals is equivalent to the one derived by Haefner et al. (2013), but stripped from the non-linear complications inherent to the CP formulation. We use a linear formulation instead, which gives us a particularly simple prediction of choice signals at every instant in time.</p>
<p>We then show how these equations can be used in order to recover the time window and the number of neurons used in the formation of a percept. A quantitative analysis of choice signals allows us to overcome the “<italic>K</italic>–<italic>w</italic> trade-off” inherent to neurometric sensitivity. We specifically focus on situations in which only a finite sample of neurons has been measured from a large, unknown population. We show how to recover the typical number of neurons <italic>K</italic>, provided that the experimenter could record at least <italic>K</italic> neurons simultaneously. Finally, we discuss the scope and the limitations of our method, and how it can be applied to real experimental data.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Experimental measures of behavior and neural activities</title>
<p>We will study the formation of percepts in the context of perceptual decision-making experiments (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1</xref>, see <xref ref-type="sec" rid="sec024">Methods</xref> or Tables <xref ref-type="table" rid="pcbi.1004082.t001">1</xref>–<xref ref-type="table" rid="pcbi.1004082.t003">3</xref> for the corresponding formulas). In these experiments, an animal is typically confronted with a stimulus, <italic>s</italic>, and must then make a behavioral choice, <italic>c</italic>, according to the rules of the task. A specific example is the classic <italic>discrimination task</italic> in which the animal’s choice <italic>c</italic> is binary, and the animal must report whether it perceived <italic>s</italic> to be higher (<italic>c</italic> = 1) or lower (<italic>c</italic> = 0) than a fixed reference <italic>s</italic><sub>0</sub> (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1A</xref>, top and middle panels). While the animal is performing the task, the neural activity in a given brain area can be monitored (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1A</xref>, bottom panel). Typical examples from the literature include area MT in the context of a motion discrimination task [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>], area MT or V2 in the context of a depth discrimination task [<xref ref-type="bibr" rid="pcbi.1004082.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref020">20</xref>], or area S1 in the context of a tactile discrimination task [<xref ref-type="bibr" rid="pcbi.1004082.ref021">21</xref>]. For concreteness, we will mostly focus on these discrimination tasks, although the general framework can be applied to arbitrary perceptual decision-making tasks.</p>
<fig id="pcbi.1004082.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Framework and main experimental measures.</title>
<p>(A) Experimental setup. Top: A set of stimulus values <italic>s</italic> (color-coded as blue, yellow, red) are repeatedly presented to an animal. Middle: The animal’s choice <italic>c</italic> on each trial (green) indicates whether the animal judged <italic>s</italic> to be larger or smaller than the fixed central value, <italic>s</italic><sub>0</sub>. Bottom: In each session, several task-relevant sensory neurons are recorded simultaneously with the behavior. (B) The psychometric curve <italic>ψ</italic>(<italic>s</italic>) quantifies the animal’s sensory accuracy. Its inverse slope in <italic>s</italic><sub>0</sub> provides the just-noticeable-difference (JND), <italic>Z</italic>. (C) The noise covariance structure can be assessed in each pair of simultaneously recorded neurons, as their joint peri-stimulus histogram (JPSTH) <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>). (D) Responses of a particular neuron. Each thin line is the schematic (smoothed) representation of the spike train on one trial. Segregating trials according to stimulus (top), we access the neuron’s peri-stimulus histogram (PSTH, thick lines) and its tuning signal <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>)—shown in panel (E). Fixing a stimulus value and segregating trials according to the animal’s choice <italic>c</italic> (bottom), we access the neuron’s choice covariance (CC) curve <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>)—shown in panel (F).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g001"/>
</fig>
<table-wrap id="pcbi.1004082.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.t001</object-id>
<label>Table 1</label>
<caption>
<title>Variables and notations: typography.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004082.t001g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.t001"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1"><bold>Notation</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Description</bold></th>
<th align="left" rowspan="1" colspan="1"><bold>Examples</bold></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Bold</td>
<td align="left" rowspan="1" colspan="1">Lower case: vector notation, across neurons<break/>Upper case: matrix notation, across neurons</td>
<td align="left" rowspan="1" colspan="1"><bold>r</bold>(<italic>t</italic>), <bold>b</bold>(<italic>t</italic>)<break/><bold>C</bold>(<italic>t</italic>, <italic>u</italic>), <inline-formula id="pcbi.1004082.e001"><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Overline</td>
<td align="left" rowspan="1" colspan="1">Temporal integration, using readout parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e002">
<mml:math id="M2" display="inline" overflow="scroll">
<mml:mrow>
<mml:msub>
<mml:mover>
<mml:mi>r</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula>, <inline-formula id="pcbi.1004082.e003"><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>C</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="pcbi.1004082.e004"><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Starred</td>
<td align="left" rowspan="1" colspan="1">Pertaining to the animal’s true behavior<break/>(as opposed to model-based predictions)</td>
<td align="left" rowspan="1" colspan="1"><italic>Z</italic><sup>⋆</sup>, <inline-formula id="pcbi.1004082.e005"><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="pcbi.1004082.e006"><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">E[⋅]</td>
<td align="left" rowspan="1" colspan="1">Expectation across trials (can also be conditional)</td>
<td align="left" rowspan="1" colspan="1">E[<italic>s</italic>], E[<italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)∣<italic>s</italic>], E[<italic>sr</italic><sub><italic>i</italic></sub>(<italic>t</italic>)]</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Cov[⋅]</td>
<td align="left" rowspan="1" colspan="1">Covariance across trials (can also be conditional)</td>
<td align="left" rowspan="1" colspan="1">Cov[<italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>), <italic>c</italic><sup>⋆</sup>∣<italic>s</italic>]</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>x</bold><sub><italic>r</italic></sub></td>
<td align="left" rowspan="1" colspan="1">Vector (or matrix) <bold>x</bold> restricted to neurons in readout ensemble 𝓔</td>
<td align="left" rowspan="1" colspan="1"><bold>a</bold><sub><italic>r</italic></sub>, <inline-formula id="pcbi.1004082.e007"><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="pcbi.1004082.e008"><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="pcbi.1004082.e009"><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1004082.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.t002</object-id>
<label>Table 2</label>
<caption>
<title>Variables and notations: experimental data.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004082.t002g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.t002"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<tbody>
<tr>
<td align="left" colspan="3" rowspan="1"><bold>Raw experimental data</bold></td>
<td align="left" rowspan="1" colspan="1"><bold>Ref in text</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>s</italic></td>
<td align="left" rowspan="1" colspan="1">Stimulus—a varying scalar value on each trial</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>s</italic><sub>0</sub></td>
<td align="left" rowspan="1" colspan="1">Threshold stimulus value in the 2AFC task</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>c</italic><sup>⋆</sup></td>
<td align="left" rowspan="1" colspan="1">Animal choice—binary report on each trial</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)</td>
<td align="left" rowspan="1" colspan="1">Spike train from neuron <italic>i</italic> in a given trial</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e010">
<mml:math id="M10" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">Stimulus variance across trials</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e011">
<mml:math id="M11" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>≔</mml:mo>
<mml:mtext mathvariant="normal">Var</mml:mtext>
<mml:mo stretchy="false">[</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">after <xref ref-type="disp-formula" rid="pcbi.1004082.e108">eq. 18</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Animal psychometry</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>ψ</italic><sup>⋆</sup>(<italic>s</italic>)</td>
<td align="left" rowspan="1" colspan="1">Psychometric curve</td>
<td align="left" rowspan="1" colspan="1"><italic>ψ</italic><sup>⋆</sup>(<italic>s</italic>)≔E[<italic>c</italic><sup>⋆</sup>∣<italic>s</italic>]</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e133">eq. 23</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>Z</italic><sup>⋆</sup><break/><inline-formula id="pcbi.1004082.e013">
<mml:math id="M13" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mi>μ</mml:mi>
<mml:mi>d</mml:mi>
<mml:mo>⋆</mml:mo>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">Just-noticeable difference<break/>Decision bias</td>
<td align="left" rowspan="1" colspan="1">Best fit to <inline-formula id="pcbi.1004082.e012"><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>ψ</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo minsize="1.6" maxsize="1.6" stretchy="true">(</mml:mo> <mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>−</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:msup><mml:mi>Z</mml:mi> <mml:mo>⋆</mml:mo></mml:msup></mml:mfrac> <mml:mo minsize="1.6" maxsize="1.6" stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e137">eq. 27</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Individual statistics for the neurons</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>m</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>)</td>
<td align="left" rowspan="1" colspan="1">PSTH for neuron <italic>i</italic> with stimulus <italic>s</italic></td>
<td align="left" rowspan="1" colspan="1"><italic>m</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>)≔E[<italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)∣<italic>s</italic>]</td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e134">eq. 24</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>)</td>
<td align="left" rowspan="1" colspan="1">Tuning signal for neuron <italic>i</italic><break/>(variation of the PSTH wrt. stimulus)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e014">
<mml:math id="M14" display="inline" overflow="scroll">
<mml:mrow>
<mml:msub>
<mml:mi>b</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≔</mml:mo>
<mml:msubsup>
<mml:mo>∂</mml:mo>
<mml:mi>s</mml:mi>
<mml:mrow/>
</mml:msubsup>
<mml:mspace width="0.167em"/>
<mml:msub>
<mml:mi>m</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>;</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e142">eq. 30</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e143">31</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>)</td>
<td align="left" rowspan="1" colspan="1">JPSTH for neurons <italic>i</italic> and <italic>j</italic><break/>(pairwise noise correlations)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e015">
<mml:math id="M15" display="inline" overflow="scroll">
<mml:mrow>
<mml:msub>
<mml:mi>C</mml:mi>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo>,</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≔</mml:mo>
<mml:mtext mathvariant="normal">E</mml:mtext>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo>
<mml:mtext mathvariant="normal">Cov</mml:mtext>
<mml:mo stretchy="false">[</mml:mo>
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>u</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo stretchy="false">∣</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e135">eq. 25</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e144">32</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e016">
<mml:math id="M16" display="inline" overflow="scroll">
<mml:mrow>
<mml:mover>
<mml:mover>
<mml:mtext mathvariant="bold">C</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">Noise covariance matrix<break/>(time average of <italic>C</italic>, with parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>))</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e017">
<mml:math id="M17" display="inline" overflow="scroll">
<mml:mrow>
<mml:msub>
<mml:mover>
<mml:mover>
<mml:mi>C</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mi>j</mml:mi>
</mml:mrow>
</mml:msub>
<mml:mo>≔</mml:mo>
<mml:mtext mathvariant="normal">E</mml:mtext>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo>
<mml:mtext mathvariant="normal">Cov</mml:mtext>
<mml:mo stretchy="false">[</mml:mo>
<mml:msub>
<mml:mover>
<mml:mi>r</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo>,</mml:mo>
<mml:msub>
<mml:mover>
<mml:mi>r</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>j</mml:mi>
</mml:msub>
<mml:mo stretchy="false">∣</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e159">eq. 40</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e018">
<mml:math id="M18" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
<mml:mo>⋆</mml:mo>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">Choice Covariance for neuron <italic>i</italic><break/>(linear equivalent of choice probabilities)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e019">
<mml:math id="M19" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mi>d</mml:mi>
<mml:mi>i</mml:mi>
<mml:mo>⋆</mml:mo>
</mml:msubsup>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>≔</mml:mo>
<mml:mtext mathvariant="normal">E</mml:mtext>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo>
<mml:mtext mathvariant="normal">Cov</mml:mtext>
<mml:mo stretchy="false">[</mml:mo>
<mml:msub>
<mml:mi>r</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>,</mml:mo>
<mml:msup>
<mml:mi>c</mml:mi>
<mml:mo>⋆</mml:mo>
</mml:msup>
<mml:mo stretchy="false">∣</mml:mo>
<mml:mi>s</mml:mi>
<mml:mo stretchy="false">]</mml:mo>
<mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e136">eq. 26</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e146">33</xref></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1004082.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.t003</object-id>
<label>Table 3</label>
<caption>
<title>Variables and notations: model and methods.</title>
</caption>
<alternatives>
<graphic id="pcbi.1004082.t003g" mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.t003"/>
<table frame="box" rules="all" border="0">
<colgroup span="1">
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
<col align="left" valign="top" span="1"/>
</colgroup>
<tbody>
<tr>
<td align="left" colspan="3" rowspan="1"><bold>Linear readout and decision model</bold></td>
<td align="left" rowspan="1" colspan="1"><bold>Ref in text</bold></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>w</italic></td>
<td align="left" rowspan="1" colspan="1">Readout window—duration of the temporal integration</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>t</italic><sub><italic>R</italic></sub></td>
<td align="left" rowspan="1" colspan="1">extraction time—time at which the percept is formed</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>a</italic><sub><italic>i</italic></sub></td>
<td align="left" rowspan="1" colspan="1">Readout weight—contribution of neuron <italic>i</italic> to the percept</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>σ</italic><sub><italic>d</italic></sub></td>
<td align="left" rowspan="1" colspan="1">Decision noise—added to the percept at decision time</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e020">
<mml:math id="M20" display="inline" overflow="scroll">
<mml:mrow>
<mml:mover>
<mml:mi>s</mml:mi>
<mml:mo accent="true">̂</mml:mo>
</mml:mover>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1">Readout—computed on every trial</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e021">
<mml:math id="M21" display="inline" overflow="scroll">
<mml:mrow>
<mml:mover>
<mml:mi>s</mml:mi>
<mml:mo accent="true">̂</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mo>∑</mml:mo>
<mml:mrow>
<mml:mi>i</mml:mi>
<mml:mo>=</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
<mml:msub>
<mml:mi>N</mml:mi>
<mml:mtext mathvariant="normal">tot</mml:mtext>
</mml:msub>
</mml:msubsup>
<mml:msub>
<mml:mi>a</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mover>
<mml:mi>r</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e035">eq. 2</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>c</italic></td>
<td align="left" rowspan="1" colspan="1">Choice—computed on every trial</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e022">
<mml:math id="M22" display="inline" overflow="scroll">
<mml:mrow>
<mml:mi>c</mml:mi>
<mml:mo>=</mml:mo>
<mml:mi>H</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mover>
<mml:mi>s</mml:mi>
<mml:mo accent="true">̂</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:msub>
<mml:mi>ξ</mml:mi>
<mml:mi>d</mml:mi>
</mml:msub>
<mml:mo>−</mml:mo>
<mml:msub>
<mml:mi>s</mml:mi>
<mml:mn>0</mml:mn>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e047">eq. 3</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Model predictions</bold> (characteristic equations)</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>Z</italic></td>
<td align="left" rowspan="1" colspan="1">Just-noticeable difference</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e023">
<mml:math id="M23" display="inline" overflow="scroll">
<mml:mrow>
<mml:msup>
<mml:mi>Z</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo>=</mml:mo>
<mml:msup>
<mml:mtext mathvariant="bold">a</mml:mtext>
<mml:mo>⊤</mml:mo>
</mml:msup>
<mml:mover>
<mml:mover>
<mml:mtext mathvariant="bold">C</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mtext mathvariant="bold">a</mml:mtext>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>d</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e066">eq. 8</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>d</bold>(<italic>t</italic>)</td>
<td align="left" rowspan="1" colspan="1">Choice covariance for every neuron</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e024">
<mml:math id="M24" display="inline" overflow="scroll">
<mml:mrow>
<mml:mtext mathvariant="bold">d</mml:mtext>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mo>=</mml:mo>
<mml:mi>κ</mml:mi>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>Z</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mspace width="0.278em"/>
<mml:mover>
<mml:mtext mathvariant="bold">C</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo stretchy="false">(</mml:mo>
<mml:mi>t</mml:mi>
<mml:mo stretchy="false">)</mml:mo>
<mml:mtext mathvariant="bold">a</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>κ</italic>(<italic>Z</italic>)</td>
<td align="left" colspan="2" rowspan="1">Conversion factor from <italic>Percept Covariance</italic> to <italic>Choice Covariance</italic></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e179">eq. 46</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Restricted optimality</bold> hypothesis</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">𝓔</td>
<td align="left" rowspan="1" colspan="1">Readout ensemble—neurons used for the readout</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>K</italic></td>
<td align="left" rowspan="1" colspan="1">Readout size—number of neurons in 𝓔</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>H</bold></td>
<td align="left" rowspan="1" colspan="1">Restriction matrix on 𝓔 (of size <italic>K</italic> × <italic>N</italic><sub>tot</sub>)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e025">
<mml:math id="M25" display="inline" overflow="scroll">
<mml:mrow>
<mml:msubsup>
<mml:mtext mathvariant="bold">x</mml:mtext>
<mml:mi>r</mml:mi>
<mml:mspace width="0.333em"/>
</mml:msubsup>
<mml:mo>=</mml:mo>
<mml:mtext mathvariant="bold">Hx</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e195">eq. 54</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>a</bold><sub><italic>r</italic></sub></td>
<td align="left" rowspan="1" colspan="1">Optimal readout vector (over 𝓔)</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e026">
<mml:math id="M26" display="inline" overflow="scroll">
<mml:mrow>
<mml:msub>
<mml:mtext mathvariant="bold">a</mml:mtext>
<mml:mi>r</mml:mi>
</mml:msub>
<mml:mo>~</mml:mo>
<mml:msup>
<mml:mrow>
<mml:mo stretchy="false">(</mml:mo>
<mml:msub>
<mml:mover>
<mml:mover>
<mml:mtext mathvariant="bold">C</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>r</mml:mi>
</mml:msub>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
<mml:mrow>
<mml:mo>−</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
<mml:msub>
<mml:mover>
<mml:mtext mathvariant="bold">b</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mi>r</mml:mi>
</mml:msub>
<mml:mspace width="0.333em"/>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e077">eq. 12</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Population-wide indicators for choice signals</bold></td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>q</italic>(<italic>u</italic>, <italic>t</italic>)</td>
<td align="left" rowspan="1" colspan="1">Population-wide link between tuning and CC</td>
<td align="left" rowspan="1" colspan="1"><italic>q</italic>(<italic>u</italic>, <italic>t</italic>)≔⟨<italic>b</italic><sub><italic>i</italic></sub>(<italic>u</italic>)<italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>)⟩<sub><italic>i</italic></sub></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e079">eq. 14</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>V</italic></td>
<td align="left" rowspan="1" colspan="1">Deviation from linearity between tuning and CC</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e027">
<mml:math id="M27" display="inline" overflow="scroll">
<mml:mrow>
<mml:mi>V</mml:mi><mml:mspace width="1pt"/><mml:mo>≔</mml:mo><mml:msubsup>
<mml:mrow>
<mml:mo>〈</mml:mo><mml:msubsup>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>b</mml:mi>
<mml:mo stretchy="true">¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>〉</mml:mo></mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow/>
</mml:msubsup>
<mml:msubsup>
<mml:mrow>
<mml:mo>〈</mml:mo><mml:msubsup>
<mml:mrow>
<mml:mover accent="true">
<mml:mi>d</mml:mi>
<mml:mo stretchy="true">¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mi>i</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>〉</mml:mo></mml:mrow>
<mml:mi>i</mml:mi>
<mml:mrow/>
</mml:msubsup>
<mml:mo>−</mml:mo><mml:mspace width="1pt"/><mml:msup>
<mml:mrow>
<mml:mover accent="true">
<mml:mover accent="true">
<mml:mi>q</mml:mi>
<mml:mo stretchy="true">¯</mml:mo>
</mml:mover>
<mml:mo stretchy="true">¯</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mn>2</mml:mn>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e080">eq. 15</xref></td>
</tr>
<tr>
<td align="left" colspan="2" rowspan="1"><bold>Rescaled indicators</bold> (used in the SVD analysis)</td>
<td align="left" rowspan="1" colspan="1"/>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>A</bold></td>
<td align="left" rowspan="1" colspan="1">Total covariance matrix</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e028">
<mml:math id="M28" display="inline" overflow="scroll">
<mml:mrow>
<mml:mtext mathvariant="bold">A</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mover>
<mml:mover>
<mml:mtext mathvariant="bold">C</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo>+</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mover>
<mml:mtext mathvariant="bold">b</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:msup>
<mml:mover>
<mml:mtext mathvariant="bold">b</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo>⊤</mml:mo>
</mml:msup>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e188">eq. 50</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>Y</italic></td>
<td align="left" rowspan="1" colspan="1">Sensitivity to stimulus</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e029">
<mml:math id="M29" display="inline" overflow="scroll">
<mml:mrow>
<mml:mi>Y</mml:mi>
<mml:mo>≔</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mspace width="0.167em"/>
<mml:mo>/</mml:mo>
<mml:mspace width="0.167em"/>
<mml:mo stretchy="false">(</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi>s</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>+</mml:mo>
<mml:msup>
<mml:mi>Z</mml:mi>
<mml:mn>2</mml:mn>
</mml:msup>
<mml:mo stretchy="false">)</mml:mo>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e183">eq. 47</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold>e</bold></td>
<td align="left" rowspan="1" colspan="1">Total percept covariance</td>
<td align="left" rowspan="1" colspan="1"><bold>e</bold> ≔ <bold>A</bold> <bold>a</bold></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e249">eq. 76</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><italic>Q</italic></td>
<td align="left" rowspan="1" colspan="1">Rescaled version of <inline-formula id="pcbi.1004082.e030"><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e031">
<mml:math id="M31" display="inline" overflow="scroll">
<mml:mrow>
<mml:mi>Q</mml:mi>
<mml:mspace width="1pt"/>
<mml:mo>≔</mml:mo>
<mml:mspace width="1pt"/>
<mml:msub>
<mml:mrow>
<mml:mo stretchy="false">⟨</mml:mo>
<mml:msub>
<mml:mi>e</mml:mi>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:msub>
<mml:mrow>
<mml:mover>
<mml:mi>b</mml:mi>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
<mml:mo stretchy="false">⟩</mml:mo>
</mml:mrow>
<mml:mi>i</mml:mi>
</mml:msub>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e108">eq. 18</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e257">79</xref></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><bold><italic>η</italic></bold></td>
<td align="left" rowspan="1" colspan="1">Tuning vector in the space of modes</td>
<td align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1004082.e032">
<mml:math id="M32" display="inline" overflow="scroll">
<mml:mrow>
<mml:mover>
<mml:mtext mathvariant="bold">b</mml:mtext>
<mml:mo accent="true">‾</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mtext mathvariant="bold">U</mml:mtext>
<mml:mrow>
<mml:mtext mathvariant="bold">Λ</mml:mtext>
</mml:mrow>
<mml:mtext mathvariant="bold-italic">η</mml:mtext>
</mml:mrow>
</mml:math>
</inline-formula></td>
<td align="left" rowspan="1" colspan="1"><xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The animal’s behavior in a discrimination task can be quantified through the <italic>psychometric curve</italic> <italic>ψ</italic>(<italic>s</italic>). This curve measures the animal’s repartition of responses at each stimulus value <italic>s</italic> (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1B</xref>). If the animal is unbiased, it will choose randomly whenever the stimulus <italic>s</italic> is equal to the threshold value <italic>s</italic><sub>0</sub>, so that <italic>ψ</italic>(<italic>s</italic><sub>0</sub>) = 1/2. The slope of the psychometric curve at <italic>s</italic> = <italic>s</italic><sub>0</sub> determines the animal’s ability to distinguish near-threshold values of the stimulus, i.e., its psychometric sensitivity. We assess this sensitivity through the <italic>just noticeable difference</italic> (JND) or <italic>difference limen</italic>, noted <italic>Z</italic>. The more sensitive the animal, the smaller <italic>Z</italic>, and the steeper its psychometric curve.</p>
<p>We assume that the neural activity within the recorded brain area conveys the stimulus information that the animal uses to make its choice (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1A</xref>, bottom). We describe the activity of this neural population on every trial as a multivariate point process <bold>r</bold>(<italic>t</italic>) = {<italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)}<sub><italic>i</italic> = 1…<italic>N</italic><sub>tot</sub></sub>, where each <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the spike train for neuron <italic>i</italic>, and <italic>N</italic><sub>tot</sub> denotes the full population size, a very large and unknown number. (The number of neurons actually recorded is generally much smaller.) As is common in electrophysiological recordings, we will quantify the raw spike trains by their first and second order statistics. First, neuron <italic>i</italic>’s trial-averaged activity in response to each tested stimulus <italic>s</italic> is given by the peri-stimulus time histogram (PSTH) or time-varying firing rate, <italic>m</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>) (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1D</xref>). In so-called “fine” discrimination tasks, the stimuli <italic>s</italic> display only moderate variations around the central value <italic>s</italic><sub>0</sub>, so that the PSTH at each instant in time can often be approximated by a linear function of <italic>s</italic>: <inline-formula id="pcbi.1004082.e033"><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.167em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>≃</mml:mo> <mml:msubsup><mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>. The slope <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>), defined at every instant in time, summarizes neuron <italic>i</italic>’s tuning properties (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1E</xref>). Second, we assume that several neurons can be recorded simultaneously, so that we can access samples from the trial-to-trial covariance structure of the population activity (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1C</xref>). For every pair of neurons (<italic>i</italic>, <italic>j</italic>) and instants in time (<italic>t</italic>, <italic>u</italic>), the joint peri-stimulus time histogram (JPSTH, [<xref ref-type="bibr" rid="pcbi.1004082.ref022">22</xref>]) <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>) summarizes the pairwise noise correlations between the two neurons (<xref ref-type="disp-formula" rid="pcbi.1004082.e135">eq. 25</xref>). For simplicity, we furthermore assume that the JPSTHs do not depend on the exact stimulus value <italic>s</italic>.</p>
<p>Finally, we can measure a choice signal for each neuron, which captures the trial-to-trial covariation of neuron activity <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) with the animal’s choice (<xref ref-type="fig" rid="pcbi.1004082.g001">Fig. 1F</xref>). Traditionally, this signal is measured in the form of choice probability (CP) curves. We consider here a simpler linear equivalent, that we term <italic>choice covariance</italic> (CC) curves [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>]. The CC curve for neuron <italic>i</italic>, denoted by <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>), measures the difference in firing rate (at each instant in time) between trials where the animal chose <italic>c</italic> = 1 and trials where it chose <italic>c</italic> = 0—all experimental features (including stimulus value) being fixed.</p>
<p>Unlike many characterizations of neural activity that rely only on spike counts, our framework requires an explicit temporal description of neural activity through PSTHs, JPSTHs, and CC curves. Exact formulas for these statistical measures are provided in the Methods. By keeping track of time, we will be able to predict <italic>when</italic>, and <italic>how long</italic>, perceptual integration takes place in an organism.</p>
</sec>
<sec id="sec004">
<title>From the neural activities to the animal’s choice</title>
<sec id="sec005">
<title>Linear readout model</title>
<p>Our goal is to quantify the mapping from the neural activities, <bold>r</bold>(<italic>t</italic>), to the animal’s choice, <italic>c</italic>. This can be done if we assume (1) how the stimulus information is extracted from the neural activities and (2) how the animal’s decision is formed. For (1) we assume the common linear readout model (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2A</xref>). Here, each neuron’s spike train <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is first integrated into a single number describing the neuron’s activity over the trial. We write,
<disp-formula id="pcbi.1004082.e034"><alternatives><graphic id="pcbi.1004082.e034g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e034"/><mml:math id="M34" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>w</mml:mi></mml:mfrac> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>h</mml:mi> <mml:mfenced open="(" close=")"><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>w</mml:mi></mml:mfrac></mml:mfenced> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where the kernel <italic>h</italic>(⋅) defines the shape of the integration window (e.g., square window, decreasing exponential, etc.), the parameter <italic>w</italic> controls the length of temporal integration, and the parameter <italic>t</italic><sub><italic>R</italic></sub> specifies the time at which the percept is built or read out. Second, the actual percept is given by a weighted sum over the neurons’ activities,
<disp-formula id="pcbi.1004082.e035"><alternatives><graphic id="pcbi.1004082.e035g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e035"/><mml:math id="M35" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mi>tot</mml:mi></mml:msub></mml:munderover> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
where <bold>a</bold> = (<italic>a</italic><sub>1</sub>, …, <italic>a</italic><sub><italic>N</italic><sub>tot</sub></sub>) is a specific readout vector, or “perceptual policy”. This classic linear readout has sometimes been referred to as the “standard” model of perceptual integration [<xref ref-type="bibr" rid="pcbi.1004082.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>].</p>
<fig id="pcbi.1004082.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Linear readout and its interpretation.</title>
<p>(A) We study a “standard” model of percept formation, with two parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub> defining integration in time, and a readout vector <bold>a</bold> defining integration across neurons. (B) Geometric interpretation of the model. The temporal parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub> define the tuning vector <inline-formula id="pcbi.1004082.e036"><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and noise covariance matrix <inline-formula id="pcbi.1004082.e037"><mml:math id="M37" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> in the population. Colored ellipses represent the distribution of neural activities from trial to trial, for the three possible stimulus values. The readout <inline-formula id="pcbi.1004082.e038"><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be viewed as an orthogonal projection of neural activities in the direction given by <bold>a</bold>. (C) Behavioral part of the model. The percept <inline-formula id="pcbi.1004082.e039"><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be corrupted by decision noise <italic>ξ</italic><sub><italic>d</italic></sub>. Then it is thresholded to produce a binary choice <italic>c</italic>.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g002"/>
</fig>
<p>Previous studies have generally made ad hoc choices for the various constituents of this model. Most often, <inline-formula id="pcbi.1004082.e040"><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is taken to be the total spike count for neuron <italic>i</italic>, in which case <italic>t</italic><sub><italic>R</italic></sub> = <italic>w</italic> coincides with the end of the stimulation period, and <italic>h</italic>(⋅) in <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref> is a square kernel. However, this readout is likely incorrect: the length of the integration window <italic>w</italic> influences the neurometric sensitivity, and experiments suggest that animals do not always use the full stimulation period to build their judgment [<xref ref-type="bibr" rid="pcbi.1004082.ref023">23</xref>]. Similarly, vector <bold>a</bold> is often defined over an arbitrary set of neurons, typically those recorded by the experimenter. Again, this choice is arbitrary, and it has a direct influence on the predicted sensitivities.</p>
<p>Instead, we view the readout window <italic>w</italic> and extraction time <italic>t</italic><sub><italic>R</italic></sub> as free parameters, and we generically define <bold>a</bold> over the full, unknown population of neurons. If a neuron does not contribute to the percept, it simply corresponds to a zero entry in <bold>a</bold>. For conceptual and implementation simplicity, we take <italic>h</italic>(⋅) to be a simple square window (see <xref ref-type="sec" rid="sec019">Discussion</xref> for a generalization). Our goal is now to understand whether the readout <inline-formula id="pcbi.1004082.e041"><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be a good model for the animal’s true percept formation and if yes, for what set of parameters.</p>
</sec>
<sec id="sec006">
<title>Decision policy</title>
<p>The linear model builds a continuous-valued, internal percept <inline-formula id="pcbi.1004082.e042"><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> of stimulus value by the animal on each trial. To emulate the discrimination tasks, we also need to model the animal’s decision policy, which converts the continuous percept <inline-formula id="pcbi.1004082.e043"><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> into a binary choice <italic>c</italic>. While the linear model is rather universal, the decision model will depend on the specifics of each experimental task. To ground our argumentation, we model here the required decision in a classic random dot motion discrimination task [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>]. However, the ideas herein could also be transposed to other types of behavioral tasks (see <xref ref-type="sec" rid="sec019">Discussion</xref>).</p>
<p>On each trial, we assume that an extraneous source of noise <italic>ξ</italic><sub><italic>d</italic></sub> is added to the animal’s percept <inline-formula id="pcbi.1004082.e044"><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2C</xref>). Known in the literature as ‘decision noise’ or ‘pooling noise’, <italic>ξ</italic><sub><italic>d</italic></sub> encompasses all extra-sensory sources of variation which may influence the animal’s decision. We assume that <italic>ξ</italic><sub><italic>d</italic></sub> is a Gaussian variable with variance <inline-formula id="pcbi.1004082.e045"><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, which we take as an additional model parameter. Then, the animal’s choice on each trial is built deterministically, by comparing <inline-formula id="pcbi.1004082.e046"><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to the threshold value <italic>s</italic><sub>0</sub> (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2C</xref>), so that
<disp-formula id="pcbi.1004082.e047"><alternatives><graphic id="pcbi.1004082.e047g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e047"/><mml:math id="M47" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mi>H</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>H</italic>(⋅) is the Heaviside function. We note that the decision noise is negligible in the classic “sensory noise hypothesis”, in which case <italic>σ</italic><sub><italic>d</italic></sub> → 0.</p>
</sec>
</sec>
<sec id="sec007">
<title>The characteristic equations of the standard model</title>
<p>The linear readout model and the animal’s decision policy specify both how the animal’s percepts are formed from its neural activities and how its choices are generated from these percepts. If we had recorded the activities of the entire neural population together with the animal’s behavior, then the parameters of this model could be estimated from the data using any standard regression method. However, this is generally not a realistic experimental situation. Instead, we take here a statistical approach to the problem, which (1) allows us to deal with incomplete recordings and (2) relates the estimation problem to the standard experimental measures described above.</p>
<sec id="sec008">
<title>Characteristic equations of the linear readout</title>
<p>Thanks to its linear structure, the readout defined in <xref ref-type="disp-formula" rid="pcbi.1004082.e035">eq. 2</xref> induces a simple covariance between the neural activities, <bold>r</bold>(<italic>t</italic>), and the resulting percept, <inline-formula id="pcbi.1004082.e048"><mml:math id="M48" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2B</xref>). Since the linear readout relies on the integrated spike trains, <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref>, we need similarly integrated versions of the neural tuning and noise covariances in order to express the respective covariance relations. In general, we will denote these time-integrated quantities by an overhead bar, and alert the reader that the respective quantities depend implicitly on the readout window <italic>w</italic> and the extraction time <italic>t</italic><sub><italic>R</italic></sub>. We will write <inline-formula id="pcbi.1004082.e049"><mml:math id="M49" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for the integrated version of the neural tuning, <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>), we will write <inline-formula id="pcbi.1004082.e050"><mml:math id="M50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>C</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for the once integrated noise covariances, and <inline-formula id="pcbi.1004082.e051"><mml:math id="M51" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>C</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for the doubly integrated noise covariance. This latter quantity, known in the literature as the ‘noise covariance matrix’, measures how the spike counts of two neurons, <inline-formula id="pcbi.1004082.e052"><mml:math id="M52" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e053"><mml:math id="M53" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, covary due to shared random fluctuations across trials (stimulus <italic>s</italic> being held fixed). We can then summarize the covariances between neural activities and the resulting percepts by three characteristic equations (see <xref ref-type="sec" rid="sec024">Methods</xref>):
<disp-formula id="pcbi.1004082.e054"><alternatives><graphic id="pcbi.1004082.e054g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e054"/><mml:math id="M54" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>∂</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">a</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
<disp-formula id="pcbi.1004082.e055"><alternatives><graphic id="pcbi.1004082.e055g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e055"/><mml:math id="M55" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Var</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
<disp-formula id="pcbi.1004082.e056"><alternatives><graphic id="pcbi.1004082.e056g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e056"/><mml:math id="M56" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
On the left-hand sides of <xref ref-type="disp-formula" rid="pcbi.1004082.e054">eq. 4</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e056">6</xref>, we find statistical quantities related to the percept <inline-formula id="pcbi.1004082.e057"><mml:math id="M57" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. On the right-hand sides of these equations, we find the model’s predictions, which are based on the neurons’ (measurable) response statistics, <italic>b</italic> and <italic>C</italic>. More specifically, the first line describes the average dependency of <inline-formula id="pcbi.1004082.e058"><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> on stimulus <italic>s</italic>, the second line expresses the resulting variance for the percept, and the third line expresses the linear covariance between each neuron’s spike train, and the animal’s percept <inline-formula id="pcbi.1004082.e059"><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> on the trial.</p>
</sec>
<sec id="sec009">
<title>Characteristic equations of the decision policy</title>
<p>To produce a binary choice, the continuous percept <inline-formula id="pcbi.1004082.e060"><mml:math id="M60" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is fed into the decision model (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2C</xref>). From the output of this decision model, we obtain a second set of characteristic equations (see <xref ref-type="sec" rid="sec024">Methods</xref>),
<disp-formula id="pcbi.1004082.e061"><alternatives><graphic id="pcbi.1004082.e061g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e061"/><mml:math id="M61" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mn>1</mml:mn> <mml:mo>=</mml:mo> <mml:msub><mml:mi>∂</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1004082.e062"><alternatives><graphic id="pcbi.1004082.e062g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e062"/><mml:math id="M62" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mi>Var</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1004082.e063"><alternatives><graphic id="pcbi.1004082.e063g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e063"/><mml:math id="M63" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Here the first equation simply expresses that both percept and decision are assumed to be unbiased. The second equation relates the JND, <italic>Z</italic>, extracted from the psychometric curve, to the variance in the percept, <inline-formula id="pcbi.1004082.e064"><mml:math id="M64" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. The third equation restates the definition of choice covariance, except for the scaling factor, <italic>κ</italic>(<italic>Z</italic>), which will be constant for most practical purposes, and is described in detail in the Methods (<xref ref-type="disp-formula" rid="pcbi.1004082.e179">eq. 46</xref>). Hence, in our full model of the task, we are able to predict both the psychometric sensitivity and the individual neurons’ choice signals from the first and second-order statistics of the neural responses. Specifically, by combining the characteristic equations for the linear readout and the decision policy, we obtain
<disp-formula id="pcbi.1004082.e065"><alternatives><graphic id="pcbi.1004082.e065g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e065"/><mml:math id="M65" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mn>1</mml:mn> <mml:mo>=</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">a</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
<disp-formula id="pcbi.1004082.e066"><alternatives><graphic id="pcbi.1004082.e066g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e066"/><mml:math id="M66" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
<disp-formula id="pcbi.1004082.e067"><alternatives><graphic id="pcbi.1004082.e067g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e067"/><mml:math id="M67" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.277778em"/><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
Importantly, since these equations deal with integrated versions of the raw neural signals, they depend on both the readout time window, <italic>w</italic>, and the extraction time, <italic>t</italic><sub><italic>R</italic></sub>.</p>
<p>We note that the choice covariance equation (<xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref>) can also be derived in a simpler, time-averaged form. Let <inline-formula id="pcbi.1004082.e068"><mml:math id="M68" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> be the time-integrated version of <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>), using the readout’s temporal parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>). Then, <xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref> becomes
<disp-formula id="pcbi.1004082.e069"><alternatives><graphic id="pcbi.1004082.e069g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e069"/><mml:math id="M69" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.277778em"/><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
which provides the linear covariance between each neuron’s spike count <inline-formula id="pcbi.1004082.e070"><mml:math id="M70" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the trial, and the animal’s choice. This is essentially the relationship already revealed by Haefner et al. (2013) [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>], that choice probabilities are related to readout weights through the noise covariance matrix. The simpler linear measure of choice covariance, used in this article, allows us (1) to get rid of some non-linearities inherent to the choice probability formulation, and (2) to easily extend the interpretation of choice signals in the time domain, with <xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref>.</p>
</sec>
</sec>
<sec id="sec010">
<title>Estimating the parameters of sensory integration</title>
<p>Equations <xref ref-type="disp-formula" rid="pcbi.1004082.e065">7</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e067">9</xref> describe the analytical link between measures of neural response to the stimulus (<italic>b</italic><sub><italic>i</italic></sub> and <italic>C</italic><sub><italic>ij</italic></sub>) and measures related to the animal’s percept (<italic>Z</italic> and <italic>d</italic><sub><italic>i</italic></sub>), based on the model’s readout parameters (<bold>a</bold>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, and <italic>σ</italic><sub><italic>d</italic></sub>). This naturally raises the reverse question: can we estimate the parameters of the standard model (<bold>a</bold>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, and <italic>σ</italic><sub><italic>d</italic></sub>) from actual measurements? From here on, we will denote the <italic>true</italic> (and unknown) values of these parameters, i.e., the values used in the animal’s actual percept formation, with a star (<bold>a</bold><sup>⋆</sup>, <italic>w</italic><sup>⋆</sup>, <inline-formula id="pcbi.1004082.e071"><mml:math id="M71" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula id="pcbi.1004082.e072"><mml:math id="M72" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>).</p>
<p>As mentioned in the introduction, our primary interest concerns the trade-off between the time scale <italic>w</italic><sup>⋆</sup> of integration, and the size <italic>K</italic><sup>⋆</sup> of the functional population which conveys the animal’s percept to downstream areas. Thus, we assume that the animal’s percept is constructed from a specific sub-ensemble 𝓔<sup>⋆</sup> of neurons, of size <italic>K</italic><sup>⋆</sup> (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3A</xref>). Neurons inside 𝓔<sup>⋆</sup> correspond to nonzero entries in the readout vector <bold>a</bold><sup>⋆</sup>, while neurons outside 𝓔<sup>⋆</sup> have zero entries. Since only a subset of neurons within a cortical area will project to a downstream area, we can generally assume that <italic>K</italic><sup>⋆</sup> &lt; <italic>N</italic><sub>tot</sub>.</p>
<fig id="pcbi.1004082.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Statistical recovery of readout parameters: method.</title>
<p>(A) The full population (of size <italic>N</italic><sub>tot</sub>) and the true readout ensemble <inline-formula id="pcbi.1004082.e292"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e292" xlink:type="simple"/></inline-formula><sup>⋆</sup> (of size <italic>K</italic><sup>⋆</sup>), are not fully measured. Only subsets of <italic>N</italic> neurons are recorded simultaneously from the population. (B) True measures for the three statistical indicators: the animal’s psychometric JND <italic>Z</italic><sup>⋆</sup>, plus indicators <italic>q</italic><sup>⋆</sup>(<italic>u</italic>, <italic>t</italic>) and <italic>V</italic><sup>⋆</sup> that summarize the distribution of the recorded neurons’ CC curves <inline-formula id="pcbi.1004082.e073"><mml:math id="M73" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. (C) A large number of neural ensembles <inline-formula id="pcbi.1004082.e293"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e293" xlink:type="simple"/></inline-formula> of size <italic>K</italic> are randomly selected from the experimental pool and proposed as the candidate readout ensemble. This yields model-based predictions for the indicators as a function of the proposed readout parameters (<italic>K</italic>, <italic>σ</italic><sub><italic>d</italic></sub>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>). (D-F) The three statistical indicators considered (see text for details).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g003"/>
</fig>
<p>Naturally, all those parameters are not measurable experimentally. For any candidate set of parameters, <bold>a</bold>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, and <italic>σ</italic><sub><italic>d</italic></sub>, the characteristic equations <xref ref-type="disp-formula" rid="pcbi.1004082.e065">7</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e067">9</xref> lead to <italic>predictions</italic> for <italic>Z</italic> and <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>) (note the absence of star when referring to predictions). In turn, the experimenter <italic>can</italic> measure the animal’s actual choice <italic>c</italic><sup>⋆</sup> on each trial, from which they can estimate the JND <italic>Z</italic><sup>⋆</sup>, and the CC curves <inline-formula id="pcbi.1004082.e074"><mml:math id="M74" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for all recorded neurons. In the next three sections, we study whether this information is sufficient to retrieve the true readout parameters, depending on the amount of data available.</p>
<p>In the ideal scenario where all neurons in the population are recorded simultaneously, <italic>N</italic> = <italic>N</italic><sub>tot</sub>, all parameters can be retrieved exactly (Case 1). In most experimental recordings, however, we only measure the activities of a small subset of that population (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3A</xref>). If this subset is representative of the full population, we may want to retrieve the readout parameters through extrapolation. Unfortunately, any such extrapolation is fraught with additional assumptions—whether implicit or explicit—as it requires to replace the missing data with some form of (generative) model. In Case 2, we impose a generative model for the readout vector <bold>a</bold>. Coupled with a statistical principle, it allows us to estimate the true size <italic>K</italic><sup>⋆</sup> of the readout ensemble, provided that the number of neurons recorded simultaneously, <italic>N</italic>, is larger: <italic>N</italic> &gt; <italic>K</italic><sup>⋆</sup>. In Case 3, we study the scenario in which <italic>N</italic> ≤ <italic>K</italic><sup>⋆</sup>. Here, we need to assume a generative model for the neural activities themselves. Since the noise covariance structure assumed by that model exerts a strong influence on the predicted JND and CC curves, a direct inference of the readout scales becomes impossible.</p>
</sec>
<sec id="sec011">
<title>Case 1: all cells recorded</title>
<p>If all neurons in the population have been recorded, with a sufficient amount of trials to estimate the complete covariance structure of the population, then the only unknown quantities in <xref ref-type="disp-formula" rid="pcbi.1004082.e065">eq. 7</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e067">9</xref> are the readout parameters <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub> and <bold>a</bold>, and the decision noise <italic>σ</italic><sub><italic>d</italic></sub>. For fixed parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>, <xref ref-type="disp-formula" rid="pcbi.1004082.e065">eq. 7</xref> and <xref ref-type="disp-formula" rid="pcbi.1004082.e067">9</xref> impose linear constraints on vector <bold>a</bold>. These constraints are generally over-complete, since <bold>a</bold> is <italic>N</italic><sub>tot</sub>-dimensional, while each time <italic>t</italic> in <xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref> provides <italic>N</italic><sub>tot</sub> additional linear constraints. Thus, in general, a solution <bold>a</bold> will only exist if one has targeted the true parameters <italic>w</italic><sup>⋆</sup> and <inline-formula id="pcbi.1004082.e075"><mml:math id="M75" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>, and it will then be unique. (If no choice of the readout parameters approximately fulfills the characteristic equations, we would have to conclude that the linear readout model is fundamentally wrong.) In practice, we can find the best solution to the characteristic equations by simply combining them and then minimizing the following mean-square error:
<disp-formula id="pcbi.1004082.e076"><alternatives><graphic id="pcbi.1004082.e076g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e076"/><mml:math id="M76" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">a</mml:mi></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mi>λ</mml:mi> <mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>−</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>∫</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:msup><mml:mfenced separators="" open="∥" close="∥"><mml:msup><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>Z</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where the parameters <italic>λ</italic> and <italic>μ</italic> trade off the importance of the errors in the different characteristic equations. Note that the loss function <italic>L</italic> depends not only on the readout weights <bold>a</bold> and the decision noise <italic>σ</italic><sub><italic>d</italic></sub>, but also on the parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>, both of which enter all the time integrations that are denoted by an overhead bar. Once vector <bold>a</bold><sup>⋆</sup> is estimated, the readout ensemble 𝓔<sup>⋆</sup> will correspond to the set of neurons with nonzero readout weights.</p>
</sec>
<sec id="sec012">
<title>Case 2: more than <italic>K</italic><sup>⋆</sup> cells recorded</title>
<p>Unfortunately, measuring the neural activity of a full population is essentially impossible, although optogenetic techniques are coming ever closer to this goal [<xref ref-type="bibr" rid="pcbi.1004082.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1004082.ref026">26</xref>]. Nevertheless, if the activity patterns of the recorded cells are statistically similar to those of the readout ensemble, and if the number of simultaneously recorded cells exceeds the number of cells in the readout ensemble, we can still retrieve the readout parameters by making specific assumptions about the true readout vector <bold>a</bold><sup>⋆</sup>.</p>
<sec id="sec013">
<title>A statistical approach</title>
<p>Our central assumption will be that the system uses the principle of <italic>restricted optimality</italic>: we assume that the readout vector <bold>a</bold><sup>⋆</sup> extracts as much information as possible from the neurons within the readout ensemble, 𝓔<sup>⋆</sup>, and no information from all other neurons. Since most of the neurons contributing to the readout were probably not recorded, we cannot directly estimate the true readout vector, <bold>a</bold><sup>⋆</sup>. However, we can form candidate ensembles from the recorded pool of neurons, 𝓔, compute their optimal readout vector, <bold>a</bold><sub><italic>r</italic></sub>(𝓔), and then test to what extent these candidate ensembles can predict the JND or the CC curves (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3C</xref>). By changing the size of the candidate ensembles, <italic>K</italic>, we can in turn infer the number of neurons involved in the readout.</p>
<p>For an arbitrary candidate ensemble 𝓔, we can express its optimal readout vector, <bold>a</bold><sub><italic>r</italic></sub>(𝓔) ≔ {<italic>a</italic><sub><italic>i</italic></sub>}<sub><italic>i</italic> ∈ 𝓔</sub>, on the basis of the neurons’ tuning and noise covariance, through a formula known as Fisher’s linear discriminant [<xref ref-type="bibr" rid="pcbi.1004082.ref027">27</xref>]:
<disp-formula id="pcbi.1004082.e077"><alternatives><graphic id="pcbi.1004082.e077g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e077"/><mml:math id="M77" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mspace width="0.277778em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
Here, the subscript <italic>r</italic> indicates that all quantities are only evaluated for the neurons within the ensemble 𝓔. The remaining neurons in the population do not participate in the readout. The resulting readout vector verifies <xref ref-type="disp-formula" rid="pcbi.1004082.e065">eq. 7</xref>, and minimizes the just noticeable difference <italic>Z</italic> under the given constraints. Specifically, by entering the optimal readout into <xref ref-type="disp-formula" rid="pcbi.1004082.e066">eq. 8</xref>, we obtain a prediction for the JND (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3D</xref>),
<disp-formula id="pcbi.1004082.e078"><alternatives><graphic id="pcbi.1004082.e078g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e078"/><mml:math id="M78" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula></p>
<p>As for CC signals, the statistical description eliminates any reference to neuron identities, so we can no longer work directly with <xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref>. Instead, we re-express this equation in terms of two population-wide indicators, that summarize the CC signals of the individual neurons. The first indicator assesses the population-wide link between a neuron’s tuning at each time <italic>u</italic>, and its choice covariance at each time <italic>t</italic>. The second indicator measures the average deviation from this link (see also <xref ref-type="sec" rid="sec024">Methods</xref>):
<disp-formula id="pcbi.1004082.e079"><alternatives><graphic id="pcbi.1004082.e079g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e079"/><mml:math id="M79" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≔</mml:mo> <mml:msub><mml:mfenced separators="" open="⟨" close="⟩"><mml:mspace width="0.166667em"/><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/></mml:mfenced> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
<disp-formula id="pcbi.1004082.e080"><alternatives><graphic id="pcbi.1004082.e080g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e080"/><mml:math id="M80" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>V</mml:mi> <mml:mo>≔</mml:mo> <mml:msub><mml:mfenced open="⟨" close="⟩"><mml:msubsup><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mfenced open="⟨" close="⟩"><mml:msubsup><mml:mover accent="true"><mml:mi>d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mi>i</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mi>q</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
Here, the angular brackets ⟨⋅⟩<sub><italic>i</italic></sub> denote averaging over the full neural population—or, in practice, over a representative ensemble of neurons (see <xref ref-type="sec" rid="sec024">Methods</xref> on how to construct this from actual data).</p>
<p>Experimentally, <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) is expected to be globally positive, because the tuning of a neuron is often found to be somewhat correlated with its choice signal [<xref ref-type="bibr" rid="pcbi.1004082.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref015">15</xref>] (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3E</xref>)—likely due to the fact that positively-tuned neurons contribute positively to stimulus estimation, and negatively-tuned neurons negatively. This correlation can be quantified under the assumption of restricted optimality (see <xref ref-type="sec" rid="sec024">Methods</xref>). The indicator <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) has a simple interpretation which we will illustrate by focusing on its doubly time-integrated version, <inline-formula id="pcbi.1004082.e081"><mml:math id="M81" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mspace width="0.167em"/><mml:msub><mml:mrow><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:mspace width="0.167em"/><mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. When we seek to predict a neuron’s choice covariance <inline-formula id="pcbi.1004082.e082"><mml:math id="M82" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from its tuning <inline-formula id="pcbi.1004082.e083"><mml:math id="M83" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, then <inline-formula id="pcbi.1004082.e084"><mml:math id="M84" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the best regression coefficient (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3F</xref>), so that
<disp-formula id="pcbi.1004082.e085"><alternatives><graphic id="pcbi.1004082.e085g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e085"/><mml:math id="M85" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mover accent="true"><mml:mover accent="true"><mml:mi>q</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>j</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>j</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mfrac> <mml:mspace width="0.166667em"/><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
The deviations from this prediction are indicated by <italic>ξ</italic><sub><italic>i</italic></sub>, whose variance in turn is measured by the indicator <italic>V</italic> (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3F</xref>). A similar relation holds for the time-dependent indicator <italic>q</italic>(<italic>u</italic>, <italic>t</italic>).</p>
<p>We now seek readout parameters which provide the best fit to the indicators introduced above. We set a number of potential values for parameters <italic>K</italic>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, <italic>σ</italic><sub><italic>d</italic></sub>, and we explore routinely all their possible combinations. For each tested value of the readout ensemble size, <italic>K</italic>, we repeatedly pick a random neural ensemble 𝓔 of size <italic>K</italic> from the pool of neurons recorded by the experimenter, and propose it as the source of the animal’s percept (<xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3C</xref>). Then, we compute the average indicators across ensembles of similar size (see <xref ref-type="sec" rid="sec024">Methods</xref>), which we will denote by <inline-formula id="pcbi.1004082.e086"><mml:math id="M86" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="pcbi.1004082.e087"><mml:math id="M87" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula id="pcbi.1004082.e088"><mml:math id="M88" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mi>V</mml:mi> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Note that all of these indicators depend on the parameters <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, <italic>K</italic>, and <italic>σ</italic><sub><italic>d</italic></sub>. Finally, we replace the loss function of Case 1 (<xref ref-type="disp-formula" rid="pcbi.1004082.e076">eq. 11</xref>) by the following “statistical” loss function:
<disp-formula id="pcbi.1004082.e089"><alternatives><graphic id="pcbi.1004082.e089g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e089"/><mml:math id="M89" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>K</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mrow><mml:mo>⋆</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mi>λ</mml:mi> <mml:mrow><mml:mspace width="0.277778em"/><mml:mpadded width="-3pt"><mml:mo>∫</mml:mo></mml:mpadded> <mml:mpadded width="-3pt"><mml:mo>∫</mml:mo></mml:mpadded> <mml:mspace width="0.277778em"/></mml:mrow> <mml:mspace width="-0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mspace width="0.166667em"/><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>q</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi></mml:msub></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mi>μ</mml:mi> <mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>V</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>V</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
The minimum of the loss function then indicates what values of the readout parameters agree best with the recorded data.</p>
</sec>
<sec id="sec014">
<title>Network simulations and retrieval of readout parameters</title>
<p>To validate these claims, we have tested our method on synthetic data—which are the only way to control the true parameters of integration, and thus to test our predictions. We implemented a recurrent neural network with <italic>N</italic> = 5000 integrate-and-fire neurons that encodes some input stimulus <italic>s</italic> in the spiking activity of its neurons, and we built a perceptual readout from that network according to our model, with parameters <italic>K</italic><sup>⋆</sup> = 80 neurons, <italic>w</italic><sup>⋆</sup> = 50 ms, <inline-formula id="pcbi.1004082.e090"><mml:math id="M90" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> ms, and <inline-formula id="pcbi.1004082.e091"><mml:math id="M91" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> stimulus units (see <xref ref-type="sec" rid="sec024">Methods</xref> for a description of the network, and supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>).</p>
<p>Then, as experimenters, we observed on every trial the perceptual report <italic>c</italic><sup>⋆</sup> and samples of network activity, from which we computed neural response statistics <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>) and <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>), the psychometric curve <italic>ψ</italic><sup>⋆</sup>(<italic>s</italic>), and the neuron CC curves <inline-formula id="pcbi.1004082.e092"><mml:math id="M92" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="pcbi.1004082.g004">Fig. 4</xref>). From these (partial) measures, we extracted the three population-wide indicators <italic>Z</italic><sup>⋆</sup>, <italic>q</italic><sup>⋆</sup>(<italic>u</italic>, <italic>t</italic>) and <italic>V</italic><sup>⋆</sup>, and investigated whether the loss function from <xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref> allows us to recover the system’s true scales of perceptual integration <inline-formula id="pcbi.1004082.e093"><mml:math id="M93" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>K</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
<fig id="pcbi.1004082.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Simulated neural network used for testing the method.</title>
<p>(A) Spike count statistics amongst the population of 5000 neurons (spike counts over 400 msec, on 3 × 180 stimulus repetitions). Note the weak, but significant, correlation between tuning (<italic>b</italic><sub><italic>i</italic></sub>) and choice covariance (<italic>d</italic><sub><italic>i</italic></sub>). (B) Sample PSTHs: the model neurons display varied firing rates, and tunings of different polarities. (C) Sample choice covariance curves for the same neurons as panel B (thin lines: bootstrap-based error bars). (D) Sample JPSTHs (noise correlations) for pairs of model neurons. Inset: corresponding cross-correlograms, obtained by projection along the diagonal. For better visibility, the curves in panels B-D were computed from a larger number of trials (3 × 3000) than used for the study itself (3 × 180), and time-averaged with a 10 msec Gaussian kernel.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g004"/>
</fig>
<p>The results, summarized in <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5</xref>, show that the recovery is indeed possible. Each indicator plays a specific role in recovering some of the parameters. First, indicator <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) allows us to recover the temporal parameters of integration (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>). Indeed, it characterizes the time interval during which the population—as a whole—shows the strongest choice covariance (<xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5A</xref>), and the bounds of this interval are essentially governed by parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>) (<xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5B</xref>). As a result, the match between true measure and prediction—second term in <xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>—shows a clear optimum near the true values <inline-formula id="pcbi.1004082.e094"><mml:math id="M94" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5C</xref>). The bi-temporal structure of <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) in <xref ref-type="disp-formula" rid="pcbi.1004082.e079">eq. 14</xref>, with time index <italic>u</italic> corresponding to the neurons’ tuning <italic>b</italic><sub><italic>i</italic></sub>(<italic>u</italic>), stabilizes the results by insuring that <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) is globally positive.</p>
<fig id="pcbi.1004082.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Statistical recovery of readout parameters: structure of the results.</title>
<p>(A) Experimental indicator <italic>q</italic><sup>⋆</sup>(<italic>u</italic>, <italic>t</italic>). Note the noisiness due to limited amounts of data. (B) Prediction <inline-formula id="pcbi.1004082.e294"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e294" xlink:type="simple"/></inline-formula> for a given set of readout parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, <italic>K</italic>, <italic>σ</italic><sub><italic>d</italic></sub>). The temporal location of the CC signal is mostly governed by parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>. (C) (Normalized) mean square error between measured and predicted <italic>q</italic>(<italic>u</italic>, <italic>t</italic>), as a function of readout parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>). The true values <inline-formula id="pcbi.1004082.e095"><mml:math id="M95" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are indicated by a white square. (D) Predicted JND <inline-formula id="pcbi.1004082.e295"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e295" xlink:type="simple"/></inline-formula> as a function of <italic>K</italic> and <italic>w</italic>. (E) Predicted JND <inline-formula id="pcbi.1004082.e296"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e296" xlink:type="simple"/></inline-formula> as a function of <italic>K</italic> and <italic>σ</italic><sub><italic>d</italic></sub>. (F) Predicted deviation <inline-formula id="pcbi.1004082.e297"><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1004082.e297" xlink:type="simple"/></inline-formula> as a function of <italic>K</italic> and <italic>σ</italic><sub><italic>d</italic></sub>. In panels C-F, the white square indicates the true (starred) value for the parameters being represented. The parameters not represented are always fixed at their true (starred) value. In panels D-F, the red curve marks the intersection of the predicted indicator with its measured value. All indicators have units derived from Hz, owing to stimulus <italic>s</italic> being itself a frequency (see <xref ref-type="sec" rid="sec024">Methods</xref>).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g005"/>
</fig>
<p>Second, indicator <italic>Z</italic> allows us to target readouts with the correct ‘overall amount’ of integration, resulting in a JND compatible with the data. <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5D</xref> depicts the predicted value for <italic>Z</italic> as a function of <italic>w</italic> and <italic>K</italic>. The mark of the ‘<italic>K</italic>-<italic>w</italic> trade-off’ is visible: higher sensitivity to stimulus can be achieved either through longer temporal integration (<italic>w</italic>), or through larger readout ensembles (<italic>K</italic>). Analytically, the JND <italic>Z</italic> depends on <italic>w</italic> because the covariance matrix <inline-formula id="pcbi.1004082.e096"><mml:math id="M96" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> will generally scale with <italic>w</italic><sup>−1</sup> (under mild assumptions, supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>). The red curve marks the pairs (<italic>K</italic>, <italic>w</italic>) for which the prediction matches the measured JND <italic>Z</italic><sup>⋆</sup>—thereby minimizing the first loss term in <xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>. The true parameters (<italic>K</italic><sup>⋆</sup>, <italic>w</italic><sup>⋆</sup>) lie along that curve (white square in <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5D</xref>). Since <italic>w</italic><sup>⋆</sup> is recovered independently thanks to indicator <italic>q</italic>(<italic>u</italic>, <italic>t</italic>), this in turn allows us to recover parameter <italic>K</italic><sup>⋆</sup>.</p>
<p>If sensory noise is the main source of error in the animal’s judgments (meaning <italic>σ</italic><sub><italic>d</italic></sub> ≃ 0 in the model), the two indicators <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) and <italic>Z</italic> suffice to characterize the readout parameters. But in the general case, the observed JND <italic>Z</italic><sup>⋆</sup> can also be influenced by extraneous sources of noise in the animal’s decision, and bias the comparison between <italic>Z</italic><sup>⋆</sup> and its prediction. To account for this potential effect, our model includes the decision-noise term <italic>σ</italic><sub><italic>d</italic></sub>. For a fixed value of <italic>w</italic>, the JND <italic>Z</italic> is influenced both by parameters <italic>K</italic> and <italic>σ</italic><sub><italic>d</italic></sub> (<xref ref-type="disp-formula" rid="pcbi.1004082.e078">eq. 13</xref>, <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5E</xref>). However, both parameters can be disentangled thanks to the third indicator <italic>V</italic>, which depends mostly on <italic>K</italic> (<xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5F</xref>).</p>
<p>The signification of <italic>V</italic> hinges on the following result, that was first shown in [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>]: when the readout is <italic>truly</italic> optimal over the full population (<italic>K</italic> = <italic>N</italic><sub>tot</sub>), then each neuron’s choice covariance <inline-formula id="pcbi.1004082.e097"><mml:math id="M97" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is simply proportional to its tuning <inline-formula id="pcbi.1004082.e098"><mml:math id="M98" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (see <xref ref-type="sec" rid="sec024">Methods</xref>). Since the indicator <italic>V</italic> quantifies the deviations from perfect proportionality between <inline-formula id="pcbi.1004082.e099"><mml:math id="M99" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e100"><mml:math id="M100" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e080">eq. 15</xref>, <xref ref-type="fig" rid="pcbi.1004082.g003">Fig. 3F</xref>), it becomes a marker of the readout’s <italic>global</italic> optimality, and decreases to zero as <italic>K</italic> grows to large populations. At the same time, the dependency of <italic>V</italic> on parameter <italic>σ</italic><sub><italic>d</italic></sub> is minimal, and limited to the influence of the scaling factor <italic>κ</italic>(<italic>Z</italic>) in <xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref> (see <xref ref-type="sec" rid="sec024">Methods</xref>).</p>
<p>When minimizing the loss function in <xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>, we impose the joint fit of the three indicators <italic>Z</italic>, <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) and <italic>V</italic>. Following the explanations above, this will be obtained for parameters close to the true values <inline-formula id="pcbi.1004082.e101"><mml:math id="M101" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>K</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. In our simulation, the minimum was achieved for the following values: <italic>w</italic> = 50 msec, <italic>t</italic><sub><italic>R</italic></sub> = 100 msec, <italic>K</italic> = 60 neurons, <italic>σ</italic><sub><italic>d</italic></sub> = 0.25 stimulus units (with the following levels of discretization: 10 neurons for <italic>K</italic>, 0.25 stimulus units for <italic>σ</italic><sub><italic>d</italic></sub>, 10 msec for <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>).</p>
<p>The best fit parameters are represented in <xref ref-type="fig" rid="pcbi.1004082.g006">Fig. 6</xref>, along with bootstrap confidence intervals derived from 14 resamplings of our original data. The temporal parameters (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>) are recovered with good precision (panel A). Conversely, parameters <italic>K</italic> and <italic>σ</italic><sub><italic>d</italic></sub> are somewhat underestimated (panels B and C) compared to their true values (black square). Indeed, the values of <italic>K</italic> and <italic>σ</italic><sub><italic>d</italic></sub> are disentangled thanks to indicator <italic>V</italic> which, of the three indicators introduced, is the most subject to measurement noise. As a result, the match between <italic>V</italic><sup>⋆</sup> and its prediction <italic>V</italic> is not as precise as the other two: see <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5F</xref>. Nevertheless, the true values are rather close to the final estimates, lying within the 1-standard deviation confidence region (<xref ref-type="fig" rid="pcbi.1004082.g006">Fig. 6C</xref>).</p>
<fig id="pcbi.1004082.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Statistical recovery of readout parameters: best fit parameters.</title>
<p>Efficiency of the inference method, applied to our simulated LIF network. The three panels show different 2d projections of the underlying 4d parameter space: (<italic>t</italic><sub><italic>R</italic></sub>, <italic>w</italic>) plane (A), (<italic>K</italic>, <italic>w</italic>) plane (B), (<italic>K</italic>, <italic>σ</italic><sub><italic>d</italic></sub>) plane (C). Black square: true parameters <inline-formula id="pcbi.1004082.e102"><mml:math id="M102" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msup><mml:mi>K</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msup><mml:mi>w</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> used to produce the data. Red square: best fit parameters (<italic>K</italic>, <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>, <italic>σ</italic><sub><italic>d</italic></sub>), achieving the minimum of the loss function in <xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>. Gray points: best fit parameters for 14 (bootstrap) resamplings of the original trials (some points are superimposed, due to the finite grid of tested parameters). Red ellipses: corresponding confidence intervals, as the 1- and 2- standard deviation of the bootstrap resamplings.</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g006"/>
</fig>
<p>Importantly, only a reasonable amount of data is required to produce these estimates. Network activity was monitored on 15 independent runs, each run consisting of 180 repetitions for each of the 3 stimuli. On each run, a different set of <italic>N</italic> = 170 random neurons were simultaneously recorded—out of a total population of <italic>N</italic><sub>tot</sub> = 5000. As a result, (i) individual neuron statistics such as <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>) or <inline-formula id="pcbi.1004082.e103"><mml:math id="M103" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> display an important amount of measurement noise, (ii) population statistics such as indicator <italic>V</italic> are computed from relatively few neurons <italic>i</italic>. Numerically, this noisiness introduces a number of biases in the above indicators, such as overfitting, which require counteracting with specific corrections (see <xref ref-type="sec" rid="sec024">Methods</xref> and supplementary material for details). Naturally, the width of the confidence intervals in <xref ref-type="fig" rid="pcbi.1004082.g006">Fig. 6</xref> is directly related to the amount of data available.</p>
<p>In conclusion, if the data conform to a number of hypotheses (optimal linear readout from a neural ensemble typical of the full population, and smaller than the recording pool size), then it is possible to estimate the underlying readout’s parameters, from a plausible amount of experimental samples.</p>
</sec>
</sec>
<sec id="sec015">
<title>Case 3: less than <italic>K</italic><sup>⋆</sup> cells recorded</title>
<p>By construction, the method presented in Case 2 can only test ensemble sizes <italic>K</italic> smaller than <italic>N</italic>, the number of neurons recorded simultaneously by the experimenter. If <italic>N</italic> is smaller than the true size <italic>K</italic><sup>⋆</sup>, the method will provide biased estimates. In current-day experiments, <italic>N</italic> can range from a few tens to a few hundred neurons. While it is not excluded that typical readout sizes <italic>K</italic><sup>⋆</sup> be of that magnitude in real neural populations (as suggested, e.g., by [<xref ref-type="bibr" rid="pcbi.1004082.ref008">8</xref>]), it is also possible that they are larger. In this case, the only way to estimate the readout parameters is to make specific assumptions about the nature of the full population activity. In turn, the extrapolated results will depend on these assumptions.</p>
<sec id="sec016">
<title>Singular value analysis of the linear readout</title>
<p>To investigate the underlying issues, and to explain why there is no “natural” extrapolation, we will study how the indicators <italic>Z</italic>, <inline-formula id="pcbi.1004082.e104"><mml:math id="M104" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, and <italic>V</italic> defined above evolve as a function of the number of neurons <italic>K</italic> used for the readout. For simplicity, we assume a fixed choice of (<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>) and focus on the time-integrated neural activities <inline-formula id="pcbi.1004082.e105"><mml:math id="M105" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref>). We also suppose that the decision noise <italic>σ</italic><sub><italic>d</italic></sub> ≃ 0 is negligible. Finally, we consider alternative definitions for the indicators <italic>Z</italic> and <inline-formula id="pcbi.1004082.e106"><mml:math id="M106" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> that simplify the following analysis. We define
<disp-formula id="pcbi.1004082.e107"><alternatives><graphic id="pcbi.1004082.e107g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e107"/><mml:math id="M107" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>Y</mml:mi> <mml:mo>≔</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
<disp-formula id="pcbi.1004082.e108"><alternatives><graphic id="pcbi.1004082.e108g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e108"/><mml:math id="M108" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>Q</mml:mi> <mml:mo>≔</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>κ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mover accent="true"><mml:mi>q</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>i</mml:mi> <mml:mrow/></mml:msubsup> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
where <inline-formula id="pcbi.1004082.e109"><mml:math id="M109" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the variance of the tested stimuli, i.e., <inline-formula id="pcbi.1004082.e110"><mml:math id="M110" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>≔</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:msup><mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo stretchy="false">]</mml:mo> <mml:mo>−</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. The <italic>sensitivity</italic> <italic>Y</italic> is simply an inverse reparametrization of the JND, <italic>Z</italic>. More specifically, <italic>Y</italic> is the ratio between the signal-related variance and the total variance (see <xref ref-type="sec" rid="sec024">Methods</xref>), which grows from zero (if <italic>Z</italic> = ∞) to one (if <italic>Z</italic> = 0) as the readout’s sensitivity to the stimulus increases. As for <italic>Q</italic>, it is simply a convenient linear rescaling of <inline-formula id="pcbi.1004082.e111"><mml:math id="M111" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>.</p>
<p>Then, we re-express the population activity through a singular value decomposition (SVD) (see <xref ref-type="sec" rid="sec024">Methods</xref> for details). Specifically, we write the time-averaged activity of neuron <italic>i</italic> for the <italic>q</italic>-th presentation of stimulus <italic>s</italic> as
<disp-formula id="pcbi.1004082.e112"><alternatives><graphic id="pcbi.1004082.e112g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e112"/><mml:math id="M112" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
where <inline-formula id="pcbi.1004082.e113"><mml:math id="M113" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the trial-averaged activity of each neuron. This decomposition is best interpreted as a change of variables, which re-expresses the neural activities <inline-formula id="pcbi.1004082.e114"><mml:math id="M114" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo> <mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">}</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi><mml:mspace width="1pt"/><mml:mo>=</mml:mo><mml:mspace width="1pt"/><mml:mn>1</mml:mn> <mml:mo>…</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext mathvariant="normal">tot</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in terms of a new set of variables, {<italic>v</italic><sub><italic>m</italic></sub>}<sub><italic>m</italic> = 1…<italic>M</italic></sub>, which we will call the activations of the population’s <italic>modes</italic>. These modes can be viewed as the underlying “patterns of activity” that shape the population on each trial. Each mode <italic>m</italic> has a strength <italic>λ</italic><sub><italic>m</italic></sub> &gt; 0 which describes the mode’s overall impact on population activity. We assume <italic>λ</italic><sub>1</sub> ≥ … ≥ <italic>λ</italic><sub><italic>M</italic></sub>, so we progressively include modes with lower strengths (<xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7A</xref>). The vector <bold>u</bold><sup><italic>m</italic></sup> is the “shape” of mode <italic>m</italic> and describes how the mode affects the individual neurons. Finally, <inline-formula id="pcbi.1004082.e115"><mml:math id="M115" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the mode’s activation variable, which takes a different (random) value on every trial <italic>q</italic> for a given stimulus <italic>s</italic>. The number of modes <italic>M</italic> is the intrinsic dimensionality of the neural population’s activity. In real populations we may expect <italic>M</italic> &lt; <italic>N</italic><sub>tot</sub>, because neural activities are largely correlated.</p>
<fig id="pcbi.1004082.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Readout properties as a function of ensemble size <italic>K</italic>.</title>
<p>(A) The SVD decomposes population activity into a number of modes <italic>m</italic> with decreasing powers <inline-formula id="pcbi.1004082.e116"><mml:math id="M116" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. (B) Each mode <italic>m</italic> has a sensitivity to stimulus, <italic>y</italic><sub><italic>m</italic></sub>. Red bars: individual sensitivities, black dots: cumulative distribution. (C) The fractions <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) describe the “proportion” of each mode which can be observed, on average, in random neural ensembles of size <italic>K</italic>. They are a function of the SVD decomposition, but bear no analytical expression in general. (D) Mean sensitivity from neural ensembles of size <italic>K</italic>, empirically measured (blue) and predicted with <xref ref-type="disp-formula" rid="pcbi.1004082.e120">eq. 21</xref> (green). The dashed black line indicates the optimal sensitivity, for a readout from the full population. (E) Same for the CC indicator <italic>Q</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e121">eq. 22</xref>). All panels computed from the spike counts <inline-formula id="pcbi.1004082.e117"><mml:math id="M117" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">r</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> of the 5000 simulated neurons, over the first 10 msec after stimulus presentation, on 3 × 3000 recording trials (without correcting for measurement errors owing to the large dimensionality and limited number of trials).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g007"/>
</fig>
<p>Since the singular value decomposition is simply a linear coordinate transform, we can redefine all quantities with respect to the activity modes. Of particular interest is the <italic>sensitivity</italic> of each mode, which is the square of its respective tuning parameter, or (see <xref ref-type="sec" rid="sec024">Methods</xref>)
<disp-formula id="pcbi.1004082.e118"><alternatives><graphic id="pcbi.1004082.e118g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e118"/><mml:math id="M118" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced separators="" open="[" close="]"><mml:msub><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mi>tot</mml:mi></mml:msub></mml:munderover> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msubsup><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow/></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
If the readout vector <bold>a</bold> is chosen optimally over the full population, the resulting percept’s sensitivity will be a simple sum over the modes: <italic>Y</italic><sup>tot</sup> = ∑<sub><italic>m</italic></sub> <italic>y</italic><sub><italic>m</italic></sub>.</p>
<p>The mode sensitivities and their cumulative sum for the simulated network above are shown in <xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7B</xref>. Note the presence of a “dominant” mode for the sensitivity. This seems to be a rather systematic effect, which arises because the definition of total covariance (<xref ref-type="sec" rid="sec024">Methods</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e188">eq. 50</xref>) favors the appearance of a mode almost collinear with <inline-formula id="pcbi.1004082.e119"><mml:math id="M119" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Even so, this dominant mode accounted only for 71% of the population’s total sensitivity, so the residual sensitivity in the other modes is generally not negligible.</p>
</sec>
<sec id="sec017">
<title>Sensitivity and choice covariance as a function of the size <italic>K</italic> of the readout ensemble</title>
<p>However, we wish to study the more general case where the readout is built from sub-ensembles of size <italic>K</italic>. In such a case, not all modes are equally observable, and we rather need to introduce a set of fractions, {<italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>)}<sub><italic>m</italic> = 1…<italic>M</italic></sub>, that express to what extent each mode <italic>m</italic> is “observed”, on average, in sub-ensembles 𝓔 of size <italic>K</italic> (see <xref ref-type="sec" rid="sec024">Methods</xref> for a precise definition). Modes with larger power <italic>λ</italic><sub><italic>m</italic></sub> tend to be observed more, so <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) globally decreases with <italic>m</italic>. Conversely, <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) naturally increases with <italic>K</italic>. For the full population, <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>N</italic><sub>tot</sub>) = 1 for all modes <italic>m</italic>, meaning that all modes are fully observed (see <xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7C</xref>; here, the mode observation fractions were empirically computed by averaging over random neural sub-ensembles). Using these fractions, we can analytically approximate the values of <italic>Y</italic> and <italic>Q</italic> which are expected, on average, if the readout is based on ensembles of size <italic>K</italic>:
<disp-formula id="pcbi.1004082.e120"><alternatives><graphic id="pcbi.1004082.e120g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e120"/><mml:math id="M120" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mfenced open="⟨" close="⟩"><mml:mi>Y</mml:mi></mml:mfenced> <mml:mi>𝓔</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≃</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>y</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
<disp-formula id="pcbi.1004082.e121"><alternatives><graphic id="pcbi.1004082.e121g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e121"/><mml:math id="M121" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mfenced open="⟨" close="⟩"><mml:mi>Q</mml:mi></mml:mfenced> <mml:mi>𝓔</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≃</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mfenced open="⟨" close="⟩"><mml:mi>Y</mml:mi></mml:mfenced> <mml:mi>𝓔</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>y</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(22)</label></disp-formula></p>
<p>Thus, the sensitivity ⟨<italic>Y</italic>⟩<sub>𝓔</sub> grows with <italic>K</italic> as mode sensitivities <italic>y</italic><sub><italic>m</italic></sub> are progressively revealed by the fractions <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>). The sensitivity reaches its maximum value, <italic>Y</italic>(<italic>N</italic><sub>tot</sub>) = <italic>Y</italic><sup>tot</sup>, when <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) = 1 for all modes <italic>m</italic> with a nonzero <italic>y</italic><sub><italic>m</italic></sub> (<xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7D</xref>). Conversely, ⟨<italic>Q</italic>⟩<sub>𝓔</sub> decreases with <italic>K</italic>. Indeed, it can be viewed as an average of the squared powers <inline-formula id="pcbi.1004082.e122"><mml:math id="M122" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">{</mml:mo> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>, each mode <italic>m</italic> contributing with a weight <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>)<italic>y</italic><sub><italic>m</italic></sub>. As <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) progressively reveals modes with lower power <italic>λ</italic><sub><italic>m</italic></sub>, this average power is expected to decrease with <italic>K</italic>. Again, the minimum value is reached when all nonzero <italic>y</italic><sub><italic>m</italic></sub> are revealed (<xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7E</xref>).</p>
<p>The results for the simulated network in <xref ref-type="fig" rid="pcbi.1004082.g007">Fig. 7D-E</xref> illustrate that the approximations leading to <xref ref-type="disp-formula" rid="pcbi.1004082.e120">eq. 21</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e121">22</xref> are well justified in practice. As for the third indicator used in Case 2, <italic>V</italic>, it can also be expressed in the SVD basis (see <xref ref-type="sec" rid="sec024">Methods</xref>). However, being a second-order variance term, its approximation based solely on the average fractions {<italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>)}, as in <xref ref-type="disp-formula" rid="pcbi.1004082.e120">eq. 21</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e121">22</xref>, is generally poor.</p>
</sec>
<sec id="sec018">
<title>The extrapolation problem revisited</title>
<p>What do these results imply in terms of extrapolation to larger neural ensembles than those recorded by the experimenter? Arguably, <xref ref-type="disp-formula" rid="pcbi.1004082.e120">eq. 21</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e121">22</xref> constitute an interesting basis for principled extrapolations to larger sizes <italic>K</italic>. These equations show that the evolution of <italic>Y</italic> and <italic>Q</italic> in growing ensembles of size <italic>K</italic> is mostly related to the interplay between the modes’ sensitivity spectrum {<italic>y</italic><sub><italic>m</italic></sub>} and their power spectrum {<italic>λ</italic><sub><italic>m</italic></sub>}. (Empirically, the observation fractions {<italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>)} seem primarily governed by the decay rate of {<italic>λ</italic><sub><italic>m</italic></sub>}, although the analytical link between the two remains elusive.) However, note that the spectra {<italic>y</italic><sub><italic>m</italic></sub>}, {<italic>λ</italic><sub><italic>m</italic></sub>} and {<italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>)} are generally not accessible to the experimenter—this would precisely require to have recorded at least <italic>N</italic> &gt; <italic>M</italic> neurons, and potentially the whole neural population if <italic>M</italic> = <italic>N</italic><sub>tot</sub>.</p>
<p>To extrapolate sensitivity ⟨<italic>Y</italic>⟩<sub>𝓔</sub>(<italic>K</italic>) in ensembles of size <italic>K</italic> larger than those monitored, one must (implicitly or explicitly) assume a model for {<italic>λ</italic><sub><italic>m</italic></sub>} and {<italic>y</italic><sub><italic>m</italic></sub>}—which amounts to characterizing the relative embedding of signal and noise in the full population [<xref ref-type="bibr" rid="pcbi.1004082.ref028">28</xref>]. A number of reasonable heuristics could be used to produce such a model. For example, one may assume a simple distribution for {<italic>λ</italic><sub><italic>m</italic></sub>}, such as a power law, and estimate its parameters from recorded data. Alternatively, it is often assumed that the noise covariance matrix is “smooth” with respect to the signal covariance matrix, so that the former can be predicted on the basis of the latter [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref029">29</xref>]. Finally, the extrapolation could rely on more specific assumptions about how neural activities evolve, e.g., through linear dynamics with additive noise [<xref ref-type="bibr" rid="pcbi.1004082.ref030">30</xref>]. In all cases, the additional assumptions impose (implicit) constraints on the structure of the spectra {<italic>λ</italic><sub><italic>m</italic></sub>} and {<italic>y</italic><sub><italic>m</italic></sub>}.</p>
<p>However, most likely, any chosen model will be (1) difficult to fit rigorously on the basis of experimental data, (2) subject to pathological situations when extrapolations fail to produce the correct predictions. For example, one can imagine scenarios in which the most sensitive modes (those with highest <italic>y</italic><sub><italic>m</italic></sub>) correspond to very local circuits of neurons, independent from the rest of the population, and thus invisible to the experimenter (see also [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>]). Another pathological situation could be a neural network specifically designed to dispatch information non-redundantly across the full population [<xref ref-type="bibr" rid="pcbi.1004082.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref032">32</xref>], resulting in a few ‘global’ modes of activity with very large SNR—meaning high <italic>y</italic><sub><italic>m</italic></sub> and low <italic>λ</italic><sub><italic>m</italic></sub>. As a result, extrapolation to neural populations larger than those recorded is never trivial, and always subject to some <italic>a priori</italic> assumptions. The most judicious assumptions, and the extent to which they are justified, will depend on each specific context.</p>
</sec>
</sec>
</sec>
<sec id="sec019" sec-type="conclusions">
<title>Discussion</title>
<p>We have proposed a framework to interpret sensitivity and choice signals in a standard model of perceptual decision-making. Our study describes percept formation within a full sensory population, and proposes novel methods to estimate its characteristic readout scales on the basis of realistic samples of experimental data. Here, we briefly discuss the underlying assumptions and their restrictions, the possibility of further extensions, and the applicability to real data.</p>
<sec id="sec020">
<title>The linear readout assumption</title>
<p>The readout model (<xref ref-type="disp-formula" rid="pcbi.1004082.e035">eq. 2</xref>) used to analyze sensitivity and choice signals is an installment of the “standard”, feed-forward model of percept formation [<xref ref-type="bibr" rid="pcbi.1004082.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>]. As such it makes a number of hypotheses which should be understood when applying our methods to real experimental data. First, it assumes that the percept <inline-formula id="pcbi.1004082.e123"><mml:math id="M123" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is built linearly from the activities of the neurons—a common assumption which greatly simplifies the overall formalism (but see, e.g., [<xref ref-type="bibr" rid="pcbi.1004082.ref033">33</xref>] for a recent example of nonlinear decoding). Even if the real percept formation departs from linearity, fitting a linear model will most likely retain meaningful estimates for the coarse information (temporal scales, number of neurons involved) that we seek to estimate in our work.</p>
<p>More precisely, the model in <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e035">2</xref> assumes that spikes are integrated using a kernel that is separable across neurons and time, that is <italic>A</italic><sub><italic>i</italic></sub>(<italic>t</italic>) = <italic>a</italic><sub><italic>i</italic></sub> <italic>h</italic>(<italic>t</italic>/<italic>w</italic>)/<italic>w</italic>. Theory does not prevent us from studying a more general integration, where each neuron <italic>i</italic> contributes with a different time course <italic>A</italic><sub><italic>i</italic></sub>(<italic>t</italic>). The readout’s characteristic equations are derived equally well in that case. Rather, assuming a separable form reflects our intuition that the time scale of integration is somewhat uniform across the population. This time scale, <italic>w</italic>, is then the one crucial parameter of the integration kernel. Although the shape <italic>h</italic>(<italic>t</italic>) of the kernel could also be fit from data in theory, it seems more fruitful to assume a simple shape from the start. We assumed a classic square kernel in our applications. Other shapes may be more plausible biologically, such as a decreasing exponential mimicking synaptic integration by downstream neurons. However, given that our goal is to estimate the (coarse) time scale of percept formation, our method will likely be robust to various simple choices for <italic>h</italic>. As a simple example, we tested our method, assuming a square kernel, on data produced by an exponential readout kernel, and still recovered the correct parameters <italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub> and <italic>K</italic> (data not shown).</p>
<p>Through the process of integration across time and neurons, each instant in time could be associated to an “ongoing percept”, i.e., the animal’s estimate of stimulus value at current time. In our model, the animal’s estimate at time <italic>t</italic><sub><italic>R</italic></sub> serves as the basis for its behavioral report (<xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2A</xref>), and we designate this single number <inline-formula id="pcbi.1004082.e124"><mml:math id="M124" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> as the “percept”. A second strong assumption of our model is that this perceptual readout occurs at the same time <italic>t</italic><sub><italic>R</italic></sub> on every stimulus presentation. In reality, there is indirect evidence that <italic>t</italic><sub><italic>R</italic></sub> could vary from trial to trial, as suggested by the subjects’ varying reaction times (RT) when they are allowed to react freely [<xref ref-type="bibr" rid="pcbi.1004082.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref035">35</xref>]. In such tasks, we expect the variations in <italic>t</italic><sub><italic>R</italic></sub> to be moderate—because subjects generally react as fast as they can—and we may even try to correct for fluctuations across trials by measuring RTs. On the other hand, when subjects are forced to wait for a long period of time before responding, there is room for ample variations in <italic>t</italic><sub><italic>R</italic></sub> from trial to trial, and the model presented above may become insufficient.</p>
<p>As a first step towards addressing this question, we derived a more general version of the characteristic equations <xref ref-type="disp-formula" rid="pcbi.1004082.e054">4</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e056">6</xref> assuming that <italic>t</italic><sub><italic>R</italic></sub> in <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref> is itself a random variable, drawn on each trial following some probability distribution <italic>g</italic>(<italic>t</italic>) (supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>). The main impact of this modification is on CC curves, which become broader and flatter; essentially, the resulting curve resembles a convolution of the deterministic CC curve by <italic>g</italic>(<italic>t</italic>) (<xref ref-type="fig" rid="pcbi.1004082.g008">Fig. 8A</xref>). This means that if a behavioral task is built such that <italic>t</italic><sub><italic>R</italic></sub> can display strong variations from trial to trial, the methods introduced above will produce biased estimates. In theory, this issue could be resolved by adding an additional parameter in the analysis, to describe <italic>g</italic>(<italic>t</italic>) (see supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>).</p>
<fig id="pcbi.1004082.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004082.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Discussion.</title>
<p>(A) If the extraction time <italic>t</italic><sub><italic>R</italic></sub> varies strongly from trial to trial (with density <italic>g</italic>(<italic>t</italic>)), it leads to a flattening of CC signals (thick green curve) compared to the case with deterministic <italic>t</italic><sub><italic>R</italic></sub> (dashed green curve). (B) If a choice-related signal feedbacks into sensory areas, it leads to an increase of CC signals (thick green curve) after the extraction time <italic>t</italic><sub><italic>R</italic></sub>, compared to the case without feedback (dashed green curve).</p>
</caption>
<graphic mimetype="image" xlink:type="simple" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.g008"/>
</fig>
</sec>
<sec id="sec021">
<title>The decision model</title>
<p>The linear readout provides a percept <inline-formula id="pcbi.1004082.e125"><mml:math id="M125" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> on every trial. In principle, behavioral experiments could be set up such that the subject directly reports this percept, so that <inline-formula id="pcbi.1004082.e126"><mml:math id="M126" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Such experiments could be treated completely without a decision model. However, almost all experiments that have been studied in the past involve a more indirect report of the animal’s percept. In these cases, some assumptions about how the percept is transformed into the behavioral report <italic>c</italic> need to be made.</p>
<p>In the choice of a decision model, we have followed the logic of the classic random dot motion discrimination task [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>], in which a monkey observes a set of randomly moving dots whose overall motion is slightly biased towards the left (<italic>s</italic> &lt; 0 in our notations) or towards the right (<italic>s</italic> &gt; 0). The monkey must then press either of two buttons depending on its judgment of the overall movement direction. The simplest decision model assumes a fixed integration time window, additive noise on the percept, <inline-formula id="pcbi.1004082.e127"><mml:math id="M127" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, and an optimal binary decision. A slightly more sophisticated model, the “integration-to-bound” model, assumes that the integration time is not fixed, but rather limited by a desired behavioral accuracy. This model requires variable readout windows, rather than the fixed readout window assumed here, and will require further investigation in the future.</p>
<p>In another classic task [<xref ref-type="bibr" rid="pcbi.1004082.ref002">2</xref>], the monkey must discriminate the frequencies <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> of two successive vibrating stimuli on their fingertip. They must press either of two buttons depending on whether they consider that <italic>s</italic><sub>1</sub> &gt; <italic>s</italic><sub>2</sub> or not. In this task, the optimal behavioral model would be <inline-formula id="pcbi.1004082.e128"><mml:math id="M128" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mi>H</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. In reality, however, the monkey needs to memorize <italic>s</italic><sub>1</sub> for a few seconds before <italic>s</italic><sub>2</sub> is presented, so potential effects of memory loss may also come into play (see e.g. [<xref ref-type="bibr" rid="pcbi.1004082.ref036">36</xref>] for a study of these problems).</p>
<p>More generally, behaving animals can display biases, lapses of attention, various exploratory and reward-maximization policies that lead to deviations from the optimal behavioral model. Choosing a relevant behavioral model is a connected problem that cannot be addressed here, and that will vary depending on the task and individual considered. For most tractable behavioral models, the predicted sensitivities and choice signals will ultimately rely on the quantities introduced in this article.</p>
</sec>
<sec id="sec022">
<title>The feedforward assumption</title>
<p>Finally, the standard model assumes that percept formation is exclusively feed-forward. The activities <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) of the sensory neurons are integrated to give rise to the percept <inline-formula id="pcbi.1004082.e129"><mml:math id="M129" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and the animal’s choice <italic>c</italic>, yet the formation of this decision does not affect sensory neurons in return. Recent evidence suggests that reality is more complex. By looking at the temporal evolution of CP signals in V2 neurons during a depth discrimination task, Nienborg and Cumming (2009) evidenced dynamics which are best explained by a top-down signal, biasing the activity of the neurons on each trial after the choice is formed [<xref ref-type="bibr" rid="pcbi.1004082.ref020">20</xref>]. In our notations, the population spikes <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) would thus display a choice-dependent signal which kicks in on every trial after time <italic>t</italic><sub><italic>R</italic></sub>, resulting in CC signals that deviate from their prediction in the absence of feedback (<xref ref-type="fig" rid="pcbi.1004082.g008">Fig. 8B</xref>).</p>
<p>What descriptive power does our model retain, if such top-down effects are strong? The answer depends on the nature of the putative feedback. If the feedback depends linearly on percept <inline-formula id="pcbi.1004082.e130"><mml:math id="M130" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (and thus, on the spike trains), its effects are fully encompassed in our model. Indeed, this feedback signal will then be totally captured by the neurons’ linear covariance structure <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>), so that our predictions will naturally take it into account. On the other hand, if the feedback depends directly on the choice <italic>c</italic>—which displays a nonlinear, “all-or-none” dependency on <inline-formula id="pcbi.1004082.e131"><mml:math id="M131" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>—then it will not be captured by our model, and lead to possible biases. Even so, our model would still apply if percept and decision were essentially uncoupled before the putative extraction time <italic>t</italic><sub><italic>R</italic></sub>, in which case one could simply compare true and predicted CC signals up to (candidate) time <italic>t</italic><sub><italic>R</italic></sub> (see <xref ref-type="fig" rid="pcbi.1004082.g008">Fig. 8B</xref>).</p>
</sec>
<sec id="sec023">
<title>Undersampled neural populations</title>
<p>In most real-life situations, experimenters only have access to samples from a large, unknown population, so they must resort to a statistical description of readout vector <bold>a</bold>. Our solution relies on an assumption of restricted optimality, based on Fisher’s linear discriminant formula (<xref ref-type="disp-formula" rid="pcbi.1004082.e077">eq. 12</xref>). By assuming that readout is made optimally from some unknown neural ensemble 𝓔, we reformulated the problem of characterizing <bold>a</bold> in that of characterizing 𝓔, and could in turn exploit the characteristic equations <xref ref-type="disp-formula" rid="pcbi.1004082.e054">4</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e056">6</xref> statistically.</p>
<p>In real experiments, the true readout profile <bold>a</bold> may not match this description: most vectors <bold>a</bold> do not implement optimal readout from a sub-ensemble. This potential discrepancy from the true readout is inescapable, once we start representing <bold>a</bold> through a statistical model. However, note that our model uses <italic>two</italic> distinct sources of non-optimality: (1) the size <italic>K</italic> of the readout ensemble, which can be much smaller than the full population, and (2) the decision noise <italic>σ</italic><sub><italic>d</italic></sub>, which adds a ‘global’ non-optimality to the readout. Arguably, by combining both factors, our chosen model for <bold>a</bold> will be flexible enough to provide meaningful estimates when fit to real data.</p>
<p>At present, the main limitation is likely to be the size of ensembles of neurons that have been recorded simultaneously. Past work has often shown that small ensembles of neurons are completely sufficient to account for an animal’s behavior [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref037">37</xref>]. However, there is an inherent trade-off between the number of neurons and the time scale of integration. One simple explanation for the small sizes of previous readout ensembles is that the true readout time scales used by subjects are much shorter. Unfortunately, as detailed above (Case 3), extrapolations from a finite-size recording onto the whole population always come at the price of strong additional assumptions.</p>
<p>However, as experimental techniques advance, and as the number of simultaneously recorded neurons reaches the number of neurons implied in the readout, we will eventually be able to directly infer the readout parameters from the data. In this case, our method can readily be tested on real data, and hopefully provide new insights into the nature of percept formation from populations of sensory neurons.</p>
</sec>
</sec>
<sec id="sec024" sec-type="materials|methods">
<title>Methods</title>
<p>The methods are organized as follows. First, we set our basic notations and definitions. Second, we derive the characteristic equations of the model, both for the linear part and decision part. Third, we detail the predictions in case of an optimal readout from some neural sub-ensemble 𝓔. Fourth, we re-express these predictions in the basis of the population’s SVD modes. Finally, we detail our methodology to empirically estimate the quantities used in this article, from limited amounts of experimental data. Tables <xref ref-type="table" rid="pcbi.1004082.t001">1</xref>–<xref ref-type="table" rid="pcbi.1004082.t003">3</xref> summarize the main variables and notations used in the article.</p>
<sec id="sec025">
<title>Statistical notation</title>
<p>In the following, we generally deal with variables <italic>x</italic> that assume different values on different trials. An example is the spike count of a single neuron. Trials in turn can be grouped by stimulus <italic>s</italic> or choice <italic>c</italic>. We can make this explicit by writing <italic>x</italic><sup><italic>scq</italic></sup> to denote the <italic>q</italic>-th trial in which the stimulus was <italic>s</italic> and the subject’s choice was <italic>c</italic>. Given such a variable, we will write E[<italic>x</italic>] for its expectation value, i.e., for the hypothetical value this quantity would take if it could be averaged over infinitely many trials. We will write E[<italic>x</italic>∣<italic>s</italic>] for the expectation value conditioned on stimulus <italic>s</italic>, i.e., for the expectation value computed over all trials in which the stimulus was <italic>s</italic>. A similar notation holds when conditioning on choices <italic>c</italic>. We note that for quantities that are already conditional expectations, for instance, <italic>y</italic>(<italic>s</italic>) = E[<italic>x</italic>∣<italic>s</italic>], their expectation value E[<italic>y</italic>(<italic>s</italic>)] will average out the stimuli according to their relative probabilities, i.e., E[<italic>y</italic>(<italic>s</italic>)] = ∑<sub><italic>s</italic></sub> <italic>p</italic>(<italic>s</italic>)<italic>y</italic>(<italic>s</italic>). Thereby, each stimulus <italic>s</italic> contributes to the expectation in proportion to the number of trials associated to it. Then the notations are coherent, since we have <inline-formula id="pcbi.1004082.e132"><mml:math id="M132" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Covariances are generically defined as Cov[<italic>x</italic>, <italic>y</italic>] = E[<italic>xy</italic>] − E[<italic>x</italic>]E[<italic>y</italic>], and variances as Var[<italic>x</italic>] = Cov[<italic>x</italic>, <italic>x</italic>]. For vectorial quantities, we assume Cov[<bold>x</bold>, <bold>y</bold>] = E[<bold>x</bold> <bold>y</bold><sup>⊤</sup>] − E[<bold>x</bold>]E[<bold>y</bold><sup>⊤</sup>], and introduce the shorthand Cov[<bold>x</bold>] ≔ Cov[<bold>x</bold>, <bold>x</bold>].</p>
</sec>
<sec id="sec026">
<title>Experimental statistics of neural activity and choice</title>
<p>Classic measures in decision-making experiments can be interpreted as estimates of the first- and second-order statistics of choice <italic>c</italic> and recorded spike trains <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>), across all trials with a fixed stimulus value <italic>s</italic>:
<disp-formula id="pcbi.1004082.e133"><alternatives><graphic id="pcbi.1004082.e133g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e133"/><mml:math id="M133" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ψ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≔</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi>c</mml:mi> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(23)</label></disp-formula>
<disp-formula id="pcbi.1004082.e134"><alternatives><graphic id="pcbi.1004082.e134g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e134"/><mml:math id="M134" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(24)</label></disp-formula>
<disp-formula id="pcbi.1004082.e135"><alternatives><graphic id="pcbi.1004082.e135g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e135"/><mml:math id="M135" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula>
<disp-formula id="pcbi.1004082.e136"><alternatives><graphic id="pcbi.1004082.e136g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e136"/><mml:math id="M136" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>c</mml:mi> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(26)</label></disp-formula>
Here, <italic>ψ</italic>(<italic>s</italic>) is the psychometric curve, <italic>m</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>) is known as the PSTH, and <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>; <italic>s</italic>) as the JPSTH. The choice covariance (CC) curve <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>) is our proposal for measuring each neuron’s “choice signal”. Theoretically, the temporal signals in <xref ref-type="disp-formula" rid="pcbi.1004082.e134">eq. 24</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e136">26</xref> are well-defined quantities in the framework of continuous-time point processes [<xref ref-type="bibr" rid="pcbi.1004082.ref038">38</xref>]. In practice, they are estimated by binning spike trains <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>) with a finite temporal precision, depending on the amount of data available.</p>
<p>From the psychometric curve, we also derive two simpler quantities: the animal’s <italic>just-noticeable difference</italic> (JND), <italic>Z</italic>, and <italic>decision bias</italic> <italic>μ</italic><sub><italic>d</italic></sub>. We obtain them as the best (MSE) fit to the following formula:
<disp-formula id="pcbi.1004082.e137"><alternatives><graphic id="pcbi.1004082.e137g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e137"/><mml:math id="M137" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ψ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mtext>Φ</mml:mtext> <mml:mfenced open="(" close=")"><mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(27)</label></disp-formula>
where Φ is the standard cumulative normal distribution. <italic>Z</italic> measures the inverse slope of the psychometric curve (up to a scaling factor <inline-formula id="pcbi.1004082.e138"><mml:math id="M138" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>). The decision bias <italic>μ</italic><sub><italic>d</italic></sub>, when non-zero, represents a bias towards one button when <italic>s</italic> = <italic>s</italic><sub>0</sub>. This formula for the psychometric curve arises naturally when we model the decision task (see below).</p>
</sec>
<sec id="sec027">
<title>Choice covariance and choice probability</title>
<p>Throughout the article, we consider the special case of a binary choice <italic>c</italic> = {0, 1}. In this case, the variance of the choice conditioned on <italic>s</italic> is given by
<disp-formula id="pcbi.1004082.e139"><alternatives><graphic id="pcbi.1004082.e139g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e139"/><mml:math id="M139" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mi>Var</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>c</mml:mi> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula>
and a straightforward computation shows that
<disp-formula id="pcbi.1004082.e140"><alternatives><graphic id="pcbi.1004082.e140g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e140"/><mml:math id="M140" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mfenced separators="" open="(" close=")"><mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>]</mml:mo></mml:mrow></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(29)</label></disp-formula>
(These formulas, and all those below, assume that the choice takes values 0 and 1. Any other binary parametrization should first be reparametrized to {0, 1}.)</p>
<p>The term in brackets is the difference between the two conditional PSTHs, computed only from trials where the animal took one decision vs. the other (stimulus <italic>s</italic> keeping a fixed value). This measure is sometimes used as a simpler alternative to choice probabilities [<xref ref-type="bibr" rid="pcbi.1004082.ref003">3</xref>]. In fact, CC curves and CP curves can be analytically related if one assumes Gaussian statistics: see [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>] or supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>.</p>
</sec>
<sec id="sec028">
<title>Simplified dependencies on the stimulus</title>
<p>The neural statistics in <xref ref-type="disp-formula" rid="pcbi.1004082.e134">eq. 24</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e136">26</xref> are defined conditionally for each stimulus <italic>s</italic> used in the task. To ease the subsequent analysis, we assume that the activity of each neuron is well approximated by a time-varying, linear dependency on the stimulus <italic>s</italic>, and that <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>; <italic>s</italic>) is independent of <italic>s</italic>. Consequently,
<disp-formula id="pcbi.1004082.e141"><alternatives><graphic id="pcbi.1004082.e141g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e141"/><mml:math id="M141" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>m</mml:mi> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Since we are modeling a discrimination task, in which stimuli <italic>s</italic> display only small variations around the central value <italic>s</italic><sub>0</sub>, the linearity assumption seems reasonable. In turn, we can write
<disp-formula id="pcbi.1004082.e142"><alternatives><graphic id="pcbi.1004082.e142g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e142"/><mml:math id="M142" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mi>∂</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(30)</label></disp-formula>
We will refer to <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>) as the neural tuning. More precisely, it is the slope of the neuron’s tuning curve at each time point.</p>
<p>Naturally, actual data (even from a synthetic simulation) always somewhat deviate from this idealized situation. In practice, we obtain the best fits for <italic>b</italic><sub><italic>i</italic></sub>(<italic>t</italic>) and <italic>C</italic><sub><italic>ij</italic></sub>(<italic>t</italic>, <italic>u</italic>) using linear regression, so that
<disp-formula id="pcbi.1004082.e143"><alternatives><graphic id="pcbi.1004082.e143g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e143"/><mml:math id="M143" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>s</mml:mi> <mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>m</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msup><mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>−</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(31)</label></disp-formula>
<disp-formula id="pcbi.1004082.e144"><alternatives><graphic id="pcbi.1004082.e144g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e144"/><mml:math id="M144" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(32)</label></disp-formula></p>
<p>Similarly, it is convenient to integrate the various CC curves <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>) (<xref ref-type="disp-formula" rid="pcbi.1004082.e136">eq. 26</xref>) into a single CC curve for each neuron, say <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>). There is no obvious choice for this simplification, because <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic>) has to change with <italic>s</italic>. For example, the CC signal is non-zero only if stimulus <italic>s</italic> and threshold <italic>s</italic><sub>0</sub> are close enough for the animal to make occasional mistakes (this is reflected in <xref ref-type="disp-formula" rid="pcbi.1004082.e140">eq. 29</xref>, since <inline-formula id="pcbi.1004082.e145"><mml:math id="M145" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>c</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> tends to zero when the animal makes no mistakes). In the experimental literature, a common choice is to focus only on the CC curve at threshold, that is <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>) = <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>; <italic>s</italic><sub>0</sub>). In experiments with a limited number of trials, this has the inconvenience of losing the statistical power from nearby stimulus values <italic>s</italic> that were also tested. We thus propose an alternative definition:
<disp-formula id="pcbi.1004082.e146"><alternatives><graphic id="pcbi.1004082.e146g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e146"/><mml:math id="M146" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(33)</label></disp-formula>
which exploits each stimulus <italic>s</italic> in proportion to the number of associated trials. In our model, this averaging also limits the influence of the JND <italic>Z</italic> on the magnitude of CC signals: see <xref ref-type="disp-formula" rid="pcbi.1004082.e178">eq. 45</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e179">46</xref>.</p>
</sec>
<sec id="sec029">
<title>Derivation of the linear characteristic equations</title>
<p>The readout defined in <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e035">2</xref> is linear with respect to the underlying spike trains {<italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>)}. To clarify the equations, let us introduce the temporal averaging kernel
<disp-formula id="pcbi.1004082.e147"><alternatives><graphic id="pcbi.1004082.e147g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e147"/><mml:math id="M147" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>w</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>w</mml:mi></mml:mfrac> <mml:mi>h</mml:mi> <mml:mfenced open="(" close=")"><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi> <mml:mi>R</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>w</mml:mi></mml:mfrac></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(34)</label></disp-formula>
where parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub> are generally implicit. Then, the integrated spike counts from <xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref> are simply <inline-formula id="pcbi.1004082.e148"><mml:math id="M148" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>k</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
<p>Using this notation, <xref ref-type="disp-formula" rid="pcbi.1004082.e035">eq. 2</xref> becomes <inline-formula id="pcbi.1004082.e149"><mml:math id="M149" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mi>k</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. Thanks to the linear structure, the two first moments of <inline-formula id="pcbi.1004082.e150"><mml:math id="M150" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can easily be developed:
<disp-formula id="pcbi.1004082.e151"><alternatives><graphic id="pcbi.1004082.e151g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e151"/><mml:math id="M151" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1004082.e152"><alternatives><graphic id="pcbi.1004082.e152g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e152"/><mml:math id="M152" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Var</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>u</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>t</mml:mi></mml:msub></mml:mrow> <mml:mspace width="0.277778em"/> </mml:mrow> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1004082.e153"><alternatives><graphic id="pcbi.1004082.e153g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e153"/><mml:math id="M153" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>u</mml:mi></mml:msub> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Given our various definitions (<xref ref-type="disp-formula" rid="pcbi.1004082.e134">eq. 24</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e135">25</xref>), and after differentiating the first line with respect to <italic>s</italic>, see <xref ref-type="disp-formula" rid="pcbi.1004082.e142">eq. 30</xref>, we obtain:
<disp-formula id="pcbi.1004082.e154"><alternatives><graphic id="pcbi.1004082.e154g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e154"/><mml:math id="M154" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>∂</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:mtd> <mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(35)</label></disp-formula>
<disp-formula id="pcbi.1004082.e155"><alternatives><graphic id="pcbi.1004082.e155g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e155"/><mml:math id="M155" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Var</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>u</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mi>t</mml:mi></mml:msub></mml:mrow> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>u</mml:mi></mml:mrow></mml:mtd> <mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(36)</label></disp-formula>
<disp-formula id="pcbi.1004082.e156"><alternatives><graphic id="pcbi.1004082.e156g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e156"/><mml:math id="M156" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>j</mml:mi></mml:munder> <mml:msub><mml:mi>a</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>u</mml:mi></mml:msub> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi></mml:mrow></mml:mtd> <mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(37)</label></disp-formula>
These are exactly the characteristic equations <xref ref-type="disp-formula" rid="pcbi.1004082.e054">4</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e056">6</xref> from the main text, after introducing the following vectors and matrices:
<disp-formula id="pcbi.1004082.e157"><alternatives><graphic id="pcbi.1004082.e157g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e157"/><mml:math id="M157" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(38)</label></disp-formula>
<disp-formula id="pcbi.1004082.e158"><alternatives><graphic id="pcbi.1004082.e158g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e158"/><mml:math id="M158" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>u</mml:mi></mml:msub> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(39)</label></disp-formula>
<disp-formula id="pcbi.1004082.e159"><alternatives><graphic id="pcbi.1004082.e159g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e159"/><mml:math id="M159" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>≔</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(40)</label></disp-formula>
<disp-formula id="pcbi.1004082.e160"><alternatives><graphic id="pcbi.1004082.e160g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e160"/><mml:math id="M160" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>k</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(41)</label></disp-formula>
which simply correspond to the statistics of activity for the integrated spike counts <inline-formula id="pcbi.1004082.e161"><mml:math id="M161" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e034">eq. 1</xref>). Indeed, <inline-formula id="pcbi.1004082.e162"><mml:math id="M162" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∂</mml:mo> <mml:mi>s</mml:mi></mml:msub> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (tuning vector), <inline-formula id="pcbi.1004082.e163"><mml:math id="M163" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>C</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">Cov</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>j</mml:mi></mml:msub> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (noise covariance matrix), and <inline-formula id="pcbi.1004082.e164"><mml:math id="M164" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mtext mathvariant="normal">Cov</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>c</mml:mi> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (choice covariance vector). Given our assumptions above, the resulting quantities are all independent of the stimulus <italic>s</italic>. Note though, that all quantities depend on the readout parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>. Importantly, one can show that the noise covariance matrix <inline-formula id="pcbi.1004082.e165"><mml:math id="M165" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> scales as <italic>w</italic><sup>−1</sup>, under mild assumptions (supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>, section 2).</p>
</sec>
<sec id="sec030">
<title>The decision model of a fine-discrimination task</title>
<p>To produce a binary choice, the (continuous) percept <inline-formula id="pcbi.1004082.e166"><mml:math id="M166" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is fed into the decision model <inline-formula id="pcbi.1004082.e167"><mml:math id="M167" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi> <mml:mo>=</mml:mo> <mml:mi>H</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo>−</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>H</italic> is the Heaviside function, <italic>s</italic><sub>0</sub> is the (task-imposed) decision threshold, and <italic>ξ</italic><sub><italic>d</italic></sub> ∼ 𝒩(<italic>μ</italic><sub><italic>d</italic></sub>, <italic>σ</italic><sub><italic>d</italic></sub>) is a Gaussian variable representing additional noise and biases. The mean <italic>μ</italic><sub><italic>d</italic></sub> implements a possible bias towards one button when <italic>s</italic> = <italic>s</italic><sub>0</sub>. The standard deviation <italic>σ</italic><sub><italic>d</italic></sub> implements additional sources of noise in the animal’s decision process.</p>
<p>Using this decision model, and mild additional assumptions, we can relate the left-hand sides of <xref ref-type="disp-formula" rid="pcbi.1004082.e154">eq. 35</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e156">37</xref> to experimental data. First, we assume that <inline-formula id="pcbi.1004082.e168"><mml:math id="M168" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, meaning that <inline-formula id="pcbi.1004082.e169"><mml:math id="M169" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> follows <italic>s</italic> on average. (In statistical terminology, <inline-formula id="pcbi.1004082.e170"><mml:math id="M170" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is an <italic>unbiased estimator</italic> of <italic>s</italic>.) Then, the left-hand side of <xref ref-type="disp-formula" rid="pcbi.1004082.e154">eq. 35</xref> is simply equal to
<disp-formula id="pcbi.1004082.e171"><alternatives><graphic id="pcbi.1004082.e171g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e171"/><mml:math id="M171" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>∂</mml:mi> <mml:mi>s</mml:mi></mml:msub> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(42)</label></disp-formula></p>
<p>Second, we assume that the distribution of <bold>r</bold>(<italic>t</italic>) (given <italic>s</italic>) is Gaussian. (In theory, this assumption is violated at small time scales due to the binary nature of <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>). But in practice this is not an issue, as the spike trains always undergo some form of temporal integration afterwards.) Then, <inline-formula id="pcbi.1004082.e172"><mml:math id="M172" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (given <italic>s</italic>) is normally distributed, and <xref ref-type="disp-formula" rid="pcbi.1004082.e155">eq. 36</xref> ensures that its variance <inline-formula id="pcbi.1004082.e173"><mml:math id="M173" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">Var</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is independent of <italic>s</italic> (see <xref ref-type="fig" rid="pcbi.1004082.g002">Fig. 2B</xref>). In these conditions, the predicted formula for the psychometric curve is exactly that of <xref ref-type="disp-formula" rid="pcbi.1004082.e137">eq. 27</xref>, namely,
<disp-formula id="pcbi.1004082.e174"><alternatives><graphic id="pcbi.1004082.e174g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e174"/><mml:math id="M174" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mtext>Φ</mml:mtext> <mml:mfenced open="(" close=")"><mml:mfrac><mml:mrow><mml:mi>s</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub></mml:mrow> <mml:mi>Z</mml:mi></mml:mfrac></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and the JND, <italic>Z</italic>, is given by the following expression:
<disp-formula id="pcbi.1004082.e175"><alternatives><graphic id="pcbi.1004082.e175g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e175"/><mml:math id="M175" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:mi>Var</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(43)</label></disp-formula>
Furthermore, under the same assumptions, we can predict the CC curve for each neuron. We use the following general result: for any bivariate normal variables (<italic>X</italic>, <italic>Y</italic>) and threshold <italic>t</italic>, Cov[<italic>X</italic>, <italic>H</italic>(<italic>Y</italic> − <italic>t</italic>)] = Cov[<italic>X</italic>, <italic>Y</italic>]𝒢(<italic>t</italic>; <italic>μ</italic><sub><italic>Y</italic></sub>, <italic>σ</italic><sub><italic>Y</italic></sub>), where 𝒢(⋅; <italic>μ</italic>, <italic>σ</italic>) is the normal density function. Here, we take <italic>X</italic> = <italic>r</italic><sub><italic>i</italic></sub>(<italic>t</italic>), <inline-formula id="pcbi.1004082.e176"><mml:math id="M176" display="inline" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi> <mml:mo>=</mml:mo> <mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic>t</italic> = <italic>s</italic><sub>0</sub>, to obtain:
<disp-formula id="pcbi.1004082.e177"><alternatives><graphic id="pcbi.1004082.e177g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e177"/><mml:math id="M177" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>;</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>𝓖</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>;</mml:mo> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(44)</label></disp-formula>
With <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>) defined as an average CC curve over tested stimuli (<xref ref-type="disp-formula" rid="pcbi.1004082.e146">eq. 33</xref>), we finally obtain
<disp-formula id="pcbi.1004082.e178"><alternatives><graphic id="pcbi.1004082.e178g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e178"/><mml:math id="M178" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(45)</label></disp-formula>
<disp-formula id="pcbi.1004082.e179"><alternatives><graphic id="pcbi.1004082.e179g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e179"/><mml:math id="M179" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>with</mml:mi> <mml:mspace width="11.38109pt"/><mml:mi>κ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mfenced separators="" open="[" close="]"><mml:mo>𝓖</mml:mo> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mspace width="0.166667em"/><mml:mo>;</mml:mo> <mml:mspace width="0.166667em"/><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="0.166667em"/><mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(46)</label></disp-formula>
The final equation for CC signals (<xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref>) is obtained by combining <xref ref-type="disp-formula" rid="pcbi.1004082.e156">eq. 37</xref> and <xref ref-type="disp-formula" rid="pcbi.1004082.e178">45</xref>.</p>
<p>In many experimental setups, the averaging over stimuli <italic>s</italic> will ensure that <italic>κ</italic>(<italic>Z</italic>) has only a mild dependency on its argument <italic>Z</italic>. Indeed, note the rough approximation <italic>κ</italic>(<italic>Z</italic>) ∝ ∫<sub><italic>s</italic></sub>d<italic>s</italic>𝒢(<italic>s</italic>; <italic>s</italic><sub>0</sub>−<italic>μ</italic><sub><italic>d</italic></sub>, <italic>Z</italic>) = 1, valid whenever the tested stimuli <italic>s</italic> are uniformly distributed over a range of values comparable to <italic>Z</italic>. This is another practical argument for considering the stimulus-averaged CC signal <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>), from <xref ref-type="disp-formula" rid="pcbi.1004082.e146">eq. 33</xref>.</p>
</sec>
<sec id="sec031">
<title>Signal, noise, and sensitivity</title>
<p>The just-noticeable difference (JND) and the sensitivity can be related to the variances of signal and noise in the population. Here, we briefly review these relations. The variance of any scalar variable <italic>x</italic> that changes from trial to trial can be decomposed in a signal term <inline-formula id="pcbi.1004082.e180"><mml:math id="M180" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi><mml:mn>2</mml:mn> </mml:msubsup> <mml:mo>≔</mml:mo> <mml:mtext mathvariant="normal">Var</mml:mtext> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo></mml:mrow></mml:math></inline-formula> and a noise term <inline-formula id="pcbi.1004082.e181"><mml:math id="M181" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>Z</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>≔</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">[</mml:mo> <mml:mtext mathvariant="normal">Var</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>s</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">]</mml:mo></mml:mrow></mml:math></inline-formula>. Then, note that <inline-formula id="pcbi.1004082.e182"><mml:math id="M182" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">Var</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>x</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn> </mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>Z</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
<p>The noise term <italic>Z</italic><sub><italic>x</italic></sub> defines the minimal level past which fluctuations in <italic>x</italic> can be attributed to <italic>s</italic> rather than intrinsic noise—hence the term JND. When a decision is taken on the basis of variable <italic>x</italic>, the JND governs the inverse slope of the corresponding psychometric curve (see <xref ref-type="disp-formula" rid="pcbi.1004082.e137">eq. 27</xref>). We also define the <italic>sensitivity</italic> of variable <italic>x</italic> as
<disp-formula id="pcbi.1004082.e183"><alternatives><graphic id="pcbi.1004082.e183g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e183"/><mml:math id="M183" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>Y</mml:mi> <mml:mi>x</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>Z</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(47)</label></disp-formula>
which is simply the ratio of the signal to the total variance. The sensitivity <italic>Y</italic><sub><italic>x</italic></sub> takes values between 0 and 1. It thus avoids singularities which may occur when <italic>Z</italic><sub><italic>x</italic></sub> tends to 0 or +∞.</p>
<p>We can also distinguish between signal-related and noise-related variance for the (time-averaged) neural activities <inline-formula id="pcbi.1004082.e184"><mml:math id="M184" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">r</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. The signal covariance matrix, <bold>Σ</bold>, noise covariance matrix, <inline-formula id="pcbi.1004082.e185"><mml:math id="M185" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, and total covariance matrix, <bold>A</bold>, are given by the following relations:
<disp-formula id="pcbi.1004082.e186"><alternatives><graphic id="pcbi.1004082.e186g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e186"/><mml:math id="M186" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtext mathvariant="bold">Σ</mml:mtext> <mml:mo>≔</mml:mo> <mml:mi>Cov</mml:mi> <mml:mfenced separators="" open="[" close="]"><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">m</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(48)</label></disp-formula>
<disp-formula id="pcbi.1004082.e187"><alternatives><graphic id="pcbi.1004082.e187g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e187"/><mml:math id="M187" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>≔</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mfenced separators="" open="[" close="]"><mml:mi>Cov</mml:mi> <mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(49)</label></disp-formula>
<disp-formula id="pcbi.1004082.e188"><alternatives><graphic id="pcbi.1004082.e188g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e188"/><mml:math id="M188" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold">A</mml:mi> <mml:mo>≔</mml:mo> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(50)</label></disp-formula>
The last equality is the classic decomposition of total covariance into noise and signal terms. Note that <bold>Σ</bold> is a rank-1 matrix, owing to the system’s assumed linearity wrt. stimulus <italic>s</italic>.</p>
<p>In turn, these matrices allow to compute the signal- and noise- variances for any weighted sum of the neural activities. For our linear readout (with added decision noise <italic>ξ</italic><sub><italic>d</italic></sub>), we have <inline-formula id="pcbi.1004082.e189"><mml:math id="M189" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi> <mml:mo>=</mml:mo> <mml:msup><mml:mtext mathvariant="bold">a</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:mover><mml:mtext mathvariant="bold">r</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ξ</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and thus:
<disp-formula id="pcbi.1004082.e190"><alternatives><graphic id="pcbi.1004082.e190g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e190"/><mml:math id="M190" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mtext mathvariant="bold">Σ</mml:mtext> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(51)</label></disp-formula>
<disp-formula id="pcbi.1004082.e191"><alternatives><graphic id="pcbi.1004082.e191g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e191"/><mml:math id="M191" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>Z</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(52)</label></disp-formula>
<disp-formula id="pcbi.1004082.e192"><alternatives><graphic id="pcbi.1004082.e192g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e192"/><mml:math id="M192" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>Z</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(53)</label></disp-formula></p>
</sec>
<sec id="sec032">
<title>Optimal readout from a neural ensemble 𝓔</title>
<p>We now assume that the readout vector <bold>a</bold> has support only on some neural ensemble 𝓔. Formally, we introduce the <italic>K</italic> × <italic>N</italic><sub>tot</sub> projection matrix <bold>H</bold>(𝓔), such that for <italic>i</italic> ∈ 𝓔 and every neuron <italic>j</italic>, <italic>H</italic><sub><italic>ij</italic></sub>(𝓔) = <italic>δ</italic><sub><italic>ij</italic></sub>. Then, the restrictions of vectors and matrices in neuron space, such as <inline-formula id="pcbi.1004082.e193"><mml:math id="M193" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e194"><mml:math id="M194" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, to ensemble 𝓔 will be denoted by a subscript <italic>r</italic> (for restriction), so that
<disp-formula id="pcbi.1004082.e195"><alternatives><graphic id="pcbi.1004082.e195g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e195"/><mml:math id="M195" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:mi mathvariant="bold">H</mml:mi> <mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(54)</label></disp-formula>
<disp-formula id="pcbi.1004082.e196"><alternatives><graphic id="pcbi.1004082.e196g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e196"/><mml:math id="M196" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:mi mathvariant="bold">H</mml:mi> <mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(55)</label></disp-formula></p>
<p>Our principle of (restricted) optimality selects the readout vector <bold>a</bold> which maximizes the signal-to-noise ratio of the resulting percept <inline-formula id="pcbi.1004082.e197"><mml:math id="M197" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mi>s</mml:mi> <mml:mo accent="true">̂</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Since <inline-formula id="pcbi.1004082.e198"><mml:math id="M198" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">a</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (unbiased percept, <xref ref-type="disp-formula" rid="pcbi.1004082.e154">eq. 35</xref> and <xref ref-type="disp-formula" rid="pcbi.1004082.e171">42</xref>), the signal variance is imposed to be <inline-formula id="pcbi.1004082.e199"><mml:math id="M199" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e190">eq. 51</xref>). Under this constraint, optimality is achieved by minimizing the noise variance <inline-formula id="pcbi.1004082.e200"><mml:math id="M200" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">a</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mtext mathvariant="bold">a</mml:mtext></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e191">eq. 52</xref>)—or equivalently, the total variance <bold>a</bold><sup>⊤</sup> <bold>A</bold> <bold>a</bold> (<xref ref-type="disp-formula" rid="pcbi.1004082.e192">eq. 53</xref>). The solution, known as Fisher’s Linear Discriminant, is easily found with Lagrange multipliers (either based on <inline-formula id="pcbi.1004082.e201"><mml:math id="M201" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> or <bold>A</bold>):
<disp-formula id="pcbi.1004082.e202"><alternatives><graphic id="pcbi.1004082.e202g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e202"/><mml:math id="M202" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mspace width="0.277778em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mspace width="0.277778em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(56)</label></disp-formula>
The second formulation of <bold>a</bold><sub><italic>r</italic></sub>, based on the total covariance matrix <bold>A</bold><sub><italic>r</italic></sub>, will prove more useful when we turn to the SVD analysis. It also has the advantage of avoiding the singularity which may occur when vector <inline-formula id="pcbi.1004082.e203"><mml:math id="M203" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> lies outside the span of matrix <inline-formula id="pcbi.1004082.e204"><mml:math id="M204" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. In that case one simply replaces (<bold>A</bold><sub><italic>r</italic></sub>)<sup>−1</sup> by the (Moore-Penrose) pseudoinverse (<bold>A</bold><sub><italic>r</italic></sub>)<sup>+</sup>.</p>
<p>When combining the optimal readout in <xref ref-type="disp-formula" rid="pcbi.1004082.e202">eq. 56</xref> with the equation for the JND (<xref ref-type="disp-formula" rid="pcbi.1004082.e191">eq. 52</xref>), we obtain the JND predicted by the model:
<disp-formula id="pcbi.1004082.e205"><alternatives><graphic id="pcbi.1004082.e205g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e205"/><mml:math id="M205" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mfenced> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(57)</label></disp-formula>
Equivalently, using the formulations based on total variance (<xref ref-type="disp-formula" rid="pcbi.1004082.e183">eq. 47</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e192">53</xref>, <xref ref-type="disp-formula" rid="pcbi.1004082.e202">56</xref>) we obtain the model’s prediction for sensitivity:
<disp-formula id="pcbi.1004082.e206"><alternatives><graphic id="pcbi.1004082.e206g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e206"/><mml:math id="M206" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Y</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mrow><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mfenced> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(58)</label></disp-formula></p>
</sec>
<sec id="sec033">
<title>CC signals for the optimal readout</title>
<p>When combining the optimal readout in <xref ref-type="disp-formula" rid="pcbi.1004082.e202">eq. 56</xref> with the characteristic equation for the CC curves (<xref ref-type="disp-formula" rid="pcbi.1004082.e067">eq. 9</xref>), we obtain the CC curves predicted by the model,
<disp-formula id="pcbi.1004082.e207"><alternatives><graphic id="pcbi.1004082.e207g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e207"/><mml:math id="M207" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mspace width="0.277778em"/><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(59)</label></disp-formula>
Here, <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is the resulting, predicted CC curve for every neuron <italic>i</italic> in the population (not only in ensemble 𝓔). Note that <inline-formula id="pcbi.1004082.e208"><mml:math id="M208" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the restriction of vector <inline-formula id="pcbi.1004082.e209"><mml:math id="M209" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e158">eq. 39</xref>) to neurons <italic>j</italic> ∈ 𝓔, but that <italic>i</italic> = 1…<italic>N</italic><sub>tot</sub> still runs over all neurons. <xref ref-type="disp-formula" rid="pcbi.1004082.e207">Equation 59</xref> can also be expressed in its temporally-integrated form, using the definition <inline-formula id="pcbi.1004082.e210"><mml:math id="M210" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mo>∫</mml:mo> <mml:mi>t</mml:mi></mml:msub> <mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>k</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>:
<disp-formula id="pcbi.1004082.e211"><alternatives><graphic id="pcbi.1004082.e211g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e211"/><mml:math id="M211" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mspace width="0.277778em"/><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(60)</label></disp-formula>
If neuron <italic>i</italic> belongs to the readout ensemble 𝓔, matrix <inline-formula id="pcbi.1004082.e212"><mml:math id="M212" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> simplifies away from <xref ref-type="disp-formula" rid="pcbi.1004082.e211">eq. 60</xref>, yielding:
<disp-formula id="pcbi.1004082.e213"><alternatives><graphic id="pcbi.1004082.e213g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e213"/><mml:math id="M213" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mspace width="0.277778em"/><mml:msubsup><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(61)</label></disp-formula>
This equation, first shown in [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>], means that choice signals within the readout ensemble are simply proportional to tuning. This is not true, however, for neurons outside the readout ensemble.</p>
<p>This has two important implications. First, it proves that choice signals are markedly different for neurons inside or outside the readout ensemble (an observation made empirically by [<xref ref-type="bibr" rid="pcbi.1004082.ref012">12</xref>]). Second, as we consider readout ensembles 𝓔 larger and larger, <xref ref-type="disp-formula" rid="pcbi.1004082.e213">eq. 61</xref> will become true for more and more neurons. As a result the statistical indicator <italic>V</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e080">eq. 15</xref>), which measures the population-wide deviation from linearity between <inline-formula id="pcbi.1004082.e214"><mml:math id="M214" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e215"><mml:math id="M215" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, is expected to decrease with the readout ensemble’s size <italic>K</italic>.</p>
<p>Finally, under the assumption of (restricted) optimality, the time-averaged statistical indicator <inline-formula id="pcbi.1004082.e216"><mml:math id="M216" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is always positive. Indeed, averaging over all neurons <italic>i</italic> in the population is akin to a scalar product: <inline-formula id="pcbi.1004082.e217"><mml:math id="M217" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mspace width="1pt"/> <mml:msub><mml:mrow><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mtext mathvariant="normal">tot</mml:mtext></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="0.167em"/><mml:msup><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mo>⊤</mml:mo></mml:msup> <mml:mover><mml:mtext mathvariant="bold">d</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Using this relation and <xref ref-type="disp-formula" rid="pcbi.1004082.e211">eq. 60</xref>, we get
<disp-formula id="pcbi.1004082.e218"><alternatives><graphic id="pcbi.1004082.e218g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e218"/><mml:math id="M218" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>q</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced> <mml:mspace width="0.277778em"/><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mfenced separators="" open="(" close=")"><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">H</mml:mi></mml:mfenced> <mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(62)</label></disp-formula>
which is always positive because both matrices <inline-formula id="pcbi.1004082.e219"><mml:math id="M219" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e220"><mml:math id="M220" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">H</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:msub><mml:mrow><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>r</mml:mi></mml:msub> <mml:mo stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mtext mathvariant="bold">H</mml:mtext></mml:mrow></mml:math></inline-formula> are symmetric semi-definite positive.</p>
</sec>
<sec id="sec034">
<title>Singular value decomposition</title>
<p>We denote the time-averaged activities of neuron <italic>i</italic> in the <italic>q</italic>-th presentation of stimulus <italic>s</italic> as <inline-formula id="pcbi.1004082.e221"><mml:math id="M221" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. We interpret these activities as a very large <italic>N</italic><sub>tot</sub> × Ω matrix, where <italic>N</italic><sub>tot</sub> refers to the number of neurons and Ω to an idealized, and essentially infinitely large number of trials.</p>
<p>Next, we consider the singular value decomposition (SVD) of the neural activities. The (compact) SVD is a standard decomposition which can be applied to any rectangular matrix <bold>R</bold>. It is given by <bold>R</bold> = <bold>U</bold> <bold>Λ</bold> <bold>V</bold><sup>⊤</sup>, where <bold>Λ</bold> is an <italic>M</italic> × <italic>M</italic> diagonal matrix with strictly positive entries <italic>λ</italic><sub><italic>m</italic></sub> (the singular values), <bold>U</bold> is an <italic>N</italic><sub>tot</sub> × <italic>M</italic> matrix of orthogonal columns (meaning <bold>U</bold><sup>⊤</sup> <bold>U</bold> = <bold>Id</bold><sub><italic>M</italic></sub>), and <bold>V</bold> is an Ω × <italic>M</italic> matrix of orthogonal columns (meaning <bold>V</bold><sup>⊤</sup> <bold>V</bold> = <bold>Id</bold><sub><italic>M</italic></sub>).</p>
<p>Using the indices defined above, the SVD decomposition for the neural activities becomes
<disp-formula id="pcbi.1004082.e222"><alternatives><graphic id="pcbi.1004082.e222g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e222"/><mml:math id="M222" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>r</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(63)</label></disp-formula>
where <inline-formula id="pcbi.1004082.e223"><mml:math id="M223" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the average activity of each cell over all trials and stimuli. The orthogonality of <bold>U</bold> implies that for all indices <italic>m</italic> and <italic>n</italic>, we have <inline-formula id="pcbi.1004082.e224"><mml:math id="M224" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, while the orthogonality of <bold>V</bold> similarly implies <inline-formula id="pcbi.1004082.e225"><mml:math id="M225" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
</sec>
<sec id="sec035">
<title>Statistics of activity, in the space of modes</title>
<p>The SVD decomposition (<xref ref-type="disp-formula" rid="pcbi.1004082.e222">eq. 63</xref>) is best interpreted as a change of variables re-expressing neural activities <inline-formula id="pcbi.1004082.e226"><mml:math id="M226" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo> <mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo stretchy="false">}</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>…</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mrow><mml:mtext mathvariant="normal">tot</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in terms of mode appearance variables <inline-formula id="pcbi.1004082.e227"><mml:math id="M227" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo stretchy="false">}</mml:mo></mml:mrow> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>…</mml:mo> <mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. As a result, we can define the respective equivalents of all statistical quantities in the space of activity modes. Specifically, we can reinterpret sums over trials in the SVD as expectations, thus emphasizing the statistical interpretation of the SVD. First we note that <inline-formula id="pcbi.1004082.e228"><mml:math id="M228" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>0</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:msubsup><mml:mover><mml:mi>r</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> for all neurons <italic>i</italic>, so that the data for the actual SVD has been “centered”. This centering implies for all modes <italic>m</italic> that
<disp-formula id="pcbi.1004082.e229"><alternatives><graphic id="pcbi.1004082.e229g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e229"/><mml:math id="M229" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(64)</label></disp-formula>
<disp-formula id="pcbi.1004082.e230"><alternatives><graphic id="pcbi.1004082.e230g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e230"/><mml:math id="M230" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:msubsup><mml:mi>v</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>q</mml:mi></mml:mrow></mml:msubsup> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>η</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mfenced separators="" open="(" close=")"><mml:mi>s</mml:mi> <mml:mo>−</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(65)</label></disp-formula>
where <italic>η</italic><sub><italic>m</italic></sub> is the tuning parameter of the <italic>m</italic>-th mode, just as <inline-formula id="pcbi.1004082.e231"><mml:math id="M231" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> was the tuning parameter for the <italic>i</italic>-th neuron. Grouping all mode appearance variables in a vector <bold>v</bold>, we obtain the signal covariance and total covariance matrices in mode space as
<disp-formula id="pcbi.1004082.e232"><alternatives><graphic id="pcbi.1004082.e232g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e232"/><mml:math id="M232" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mtext mathvariant="bold">Σ</mml:mtext> <mml:mi>v</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:mi>Cov</mml:mi> <mml:mfenced separators="" open="[" close="]"><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(66)</label></disp-formula>
<disp-formula id="pcbi.1004082.e233"><alternatives><graphic id="pcbi.1004082.e233g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e233"/><mml:math id="M233" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>v</mml:mi></mml:msub> <mml:mo>:</mml:mo> <mml:mo>=</mml:mo> <mml:mi>Cov</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:msup><mml:mi mathvariant="bold">v</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">Id</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(67)</label></disp-formula>
where the last relation follows from the orthogonality of <bold>V</bold> explained in the previous section. The singular values <italic>λ</italic><sub><italic>m</italic></sub> and distribution vectors <bold>u</bold><sup><italic>m</italic></sup> then allow us to relate the statistics at the levels of neurons and modes. Using the SVD formula (<xref ref-type="disp-formula" rid="pcbi.1004082.e222">eq. 63</xref>) yields (in matrix form):
<disp-formula id="pcbi.1004082.e234"><alternatives><graphic id="pcbi.1004082.e234g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e234"/><mml:math id="M234" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">U</mml:mi> <mml:mi mathvariant="bold">Λ</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(68)</label></disp-formula>
<disp-formula id="pcbi.1004082.e235"><alternatives><graphic id="pcbi.1004082.e235g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e235"/><mml:math id="M235" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold">A</mml:mi> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">U</mml:mi> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi mathvariant="bold">U</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(69)</label></disp-formula></p>
</sec>
<sec id="sec036">
<title>Sensitivity of sub-ensembles, in the space of modes</title>
<p>We now wish to understand which factors govern the sensitivity embedded in a neural sub-ensemble 𝓔 of cardinality <italic>K</italic>. For simplicity, we will consider the case for which the decision noise is negligible, i.e., <italic>σ</italic><sub><italic>d</italic></sub> → 0. Then, from <xref ref-type="disp-formula" rid="pcbi.1004082.e206">eq. 58</xref>, we have
<disp-formula id="pcbi.1004082.e236"><alternatives><graphic id="pcbi.1004082.e236g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e236"/><mml:math id="M236" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Y</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.277778em"/><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(70)</label></disp-formula>
Here we use explicitly the most general formula, based on the pseudo-inverse of matrix <bold>A</bold><sub><italic>r</italic></sub>. To re-express this sensitivity of finite sub-ensembles 𝓔 into mode space, we need to find the equivalent, restricted expressions of <xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e235">69</xref>. For that purpose, we introduce the <italic>design matrix</italic> associated to ensemble 𝓔 in mode space:
<disp-formula id="pcbi.1004082.e237"><alternatives><graphic id="pcbi.1004082.e237g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e237"/><mml:math id="M237" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi> <mml:mo>≔</mml:mo> <mml:mtext mathvariant="bold">Λ</mml:mtext> <mml:msup><mml:mi mathvariant="bold">U</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(71)</label></disp-formula>
where <bold>H</bold> is the restriction operator from <xref ref-type="disp-formula" rid="pcbi.1004082.e195">eq. 54</xref>. <bold>X</bold> is an <italic>M</italic> × <italic>K</italic> matrix with elements <inline-formula id="pcbi.1004082.e238"><mml:math id="M238" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:mo>≔</mml:mo> <mml:msub><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. Using this matrix, we obtain from <xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e235">69</xref> that <inline-formula id="pcbi.1004082.e239"><mml:math id="M239" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mtext mathvariant="bold">X</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:mtext mathvariant="bold">Ζ</mml:mtext></mml:mrow></mml:math></inline-formula> and <bold>A</bold><sub><italic>r</italic></sub> = <bold>X</bold><sup>⊤</sup> <bold>X</bold>, so that <xref ref-type="disp-formula" rid="pcbi.1004082.e236">eq. 70</xref> becomes
<disp-formula id="pcbi.1004082.e240"><alternatives><graphic id="pcbi.1004082.e240g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e240"/><mml:math id="M240" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>Y</mml:mi></mml:mtd> <mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.277778em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:msup> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold-italic">η</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.277778em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(72)</label></disp-formula>
where we have defined the <italic>M</italic> × <italic>M</italic> matrix
<disp-formula id="pcbi.1004082.e241"><alternatives><graphic id="pcbi.1004082.e241g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e241"/><mml:math id="M241" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">P</mml:mi> <mml:mo>≔</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:msup> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(73)</label></disp-formula>
Note that <bold>P</bold> is simply the orthogonal projector on <inline-formula id="pcbi.1004082.e242"><mml:math id="M242" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">Im</mml:mtext> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">(</mml:mo> <mml:mtext mathvariant="bold">X</mml:mtext> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, since <bold>P</bold> = <bold>P</bold><sup>2</sup> = <bold>P</bold><sup>⊤</sup>, and Im(<bold>P</bold>) = Im(<bold>X</bold>).</p>
<p>The projector <bold>P</bold> = <bold>P</bold>(𝓔) spans more and more space as the size <italic>K</italic> of ensemble 𝓔 increases. In the limiting case, when <italic>K</italic> is larger than the number of modes <italic>M</italic>, then necessarily <bold>P</bold> = <bold>Id</bold><sub><italic>M</italic></sub>, and we obtain
<disp-formula id="pcbi.1004082.e243"><alternatives><graphic id="pcbi.1004082.e243g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e243"/><mml:math id="M243" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>Y</mml:mi> <mml:mi>tot</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(74)</label></disp-formula>
In other words, all modes are available experimentally, and sensitivity estimates saturate to their maximum value, independently of ensemble 𝓔. We can explicitly denote the sensitivity of each mode’s activation variable <italic>v</italic><sub><italic>m</italic></sub> by defining
<disp-formula id="pcbi.1004082.e244"><alternatives><graphic id="pcbi.1004082.e244g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e244"/><mml:math id="M244" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>≔</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(75)</label></disp-formula>
By solving <xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref> for <bold><italic>η</italic></bold>, we obtain <inline-formula id="pcbi.1004082.e245"><mml:math id="M245" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>η</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>u</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msub><mml:mover><mml:mi>b</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, which in turn yields <xref ref-type="disp-formula" rid="pcbi.1004082.e118">eq. 20</xref> from the main text.</p>
</sec>
<sec id="sec037">
<title>CC signals, in the space of modes</title>
<p>Similarly, we can express CC signals in mode space. First, we re-express the CC equation (<xref ref-type="disp-formula" rid="pcbi.1004082.e069">eq. 10</xref>) as a function of the total covariance <bold>A</bold> (<xref ref-type="disp-formula" rid="pcbi.1004082.e188">eq. 50</xref>) to obtain
<disp-formula id="pcbi.1004082.e246"><alternatives><graphic id="pcbi.1004082.e246g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e246"/><mml:math id="M246" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.277778em"/><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi mathvariant="bold">a</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.277778em"/><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">A</mml:mi> <mml:mo>−</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
We further recall that <inline-formula id="pcbi.1004082.e247"><mml:math id="M247" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mtext mathvariant="bold">a</mml:mtext> <mml:mo>⊤</mml:mo></mml:msup> <mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (unbiased percept, see <xref ref-type="disp-formula" rid="pcbi.1004082.e154">eq. 35</xref> and <xref ref-type="disp-formula" rid="pcbi.1004082.e171">42</xref>). Hence, up to a scaling and shift, the CC vector <inline-formula id="pcbi.1004082.e248"><mml:math id="M248" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">d</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be replaced by the <italic>total percept covariance</italic> vector
<disp-formula id="pcbi.1004082.e249"><alternatives><graphic id="pcbi.1004082.e249g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e249"/><mml:math id="M249" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>≔</mml:mo> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">a</mml:mi> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi mathvariant="bold">d</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(76)</label></disp-formula>
In the case of an optimal readout, vector <bold>a</bold> is given by <xref ref-type="disp-formula" rid="pcbi.1004082.e202">eq. 56</xref>, so that we obtain
<disp-formula id="pcbi.1004082.e250"><alternatives><graphic id="pcbi.1004082.e250g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e250"/><mml:math id="M250" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">e</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msubsup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo></mml:msubsup> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:msup> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(77)</label></disp-formula>
Second, using the corresponding sensitivity <italic>Y</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e236">eq. 70</xref>), and the SVD expressions for <bold>A</bold> and <inline-formula id="pcbi.1004082.e251"><mml:math id="M251" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e235">69</xref>), and for <bold>A</bold><sub><italic>r</italic></sub> and <inline-formula id="pcbi.1004082.e252"><mml:math id="M252" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as a function of matrix <bold>X</bold> (<xref ref-type="disp-formula" rid="pcbi.1004082.e237">eq. 71</xref>), we write:
<disp-formula id="pcbi.1004082.e253"><alternatives><graphic id="pcbi.1004082.e253g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e253"/><mml:math id="M253" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold">e</mml:mi></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:msup><mml:mi mathvariant="bold">H</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msubsup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>r</mml:mi> <mml:mo>+</mml:mo></mml:msubsup> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.277778em"/><mml:mi mathvariant="bold">U</mml:mi> <mml:mi mathvariant="bold">Λ</mml:mi> <mml:mi mathvariant="bold">X</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">X</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:msup> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold-italic">η</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.277778em"/><mml:mi mathvariant="bold">U</mml:mi> <mml:mi mathvariant="bold">Λ</mml:mi> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(78)</label></disp-formula>
Here also, the final result can be expressed as a function of <bold>P</bold>, the projection matrix associated to ensemble 𝓔 in the space of modes (<xref ref-type="disp-formula" rid="pcbi.1004082.e241">eq. 73</xref>). Note again that <bold>e</bold> provides the CC signal for every neuron <italic>i</italic> in the population (not only in ensemble 𝓔). As 𝓔 tends to the full population, <bold>P</bold> = <bold>P</bold>(𝓔) tends to <bold>Id</bold><sub><italic>M</italic></sub> and we recover <inline-formula id="pcbi.1004082.e254"><mml:math id="M254" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold">e</mml:mtext> <mml:mo stretchy="false">(</mml:mo> <mml:mo>∞</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>Y</mml:mi> <mml:mtext mathvariant="normal">tot</mml:mtext> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="0.167em"/><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, the prediction for choice signals in the case of a (globally) optimal readout [<xref ref-type="bibr" rid="pcbi.1004082.ref019">19</xref>].</p>
<p>Using <xref ref-type="disp-formula" rid="pcbi.1004082.e253">eq. 78</xref>, we can finally compute the analytical predictions for the two CC statistical indicators, <inline-formula id="pcbi.1004082.e255"><mml:math id="M255" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <italic>V</italic>. Precisely, we compute the following population-wide regression coefficient between <bold>e</bold> and <inline-formula id="pcbi.1004082.e256"><mml:math id="M256" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>:
<disp-formula id="pcbi.1004082.e257"><alternatives><graphic id="pcbi.1004082.e257g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e257"/><mml:math id="M257" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Q</mml:mi> <mml:mo>≔</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>e</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>i</mml:mi></mml:msub></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">e</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">Λ</mml:mi> <mml:msup><mml:mi mathvariant="bold">U</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">U</mml:mi> <mml:mi mathvariant="bold">Λ</mml:mi> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(79)</label></disp-formula>
Again, we made use of the SVD expressions for <inline-formula id="pcbi.1004082.e258"><mml:math id="M258" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">b</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1004082.e234">eq. 68</xref>) and <bold>e</bold> (<xref ref-type="disp-formula" rid="pcbi.1004082.e253">eq. 78</xref>). Note that, since <bold>e</bold> is a linear rescaling of <inline-formula id="pcbi.1004082.e259"><mml:math id="M259" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mtext mathvariant="bold">d</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <italic>Q</italic> is a similar rescaling of indicator <inline-formula id="pcbi.1004082.e260"><mml:math id="M260" display="inline" overflow="scroll"><mml:mrow><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, as pointed in the main text (<xref ref-type="disp-formula" rid="pcbi.1004082.e108">eq. 18</xref>). Finally, a very similar computation leads to the expression of indicator <italic>V</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e080">eq. 15</xref>) in the space of modes:
<disp-formula id="pcbi.1004082.e261"><alternatives><graphic id="pcbi.1004082.e261g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e261"/><mml:math id="M261" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>V</mml:mi> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>Z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mspace width="0.277778em"/><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>4</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:msup><mml:mi>Y</mml:mi> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msup> <mml:mspace width="0.277778em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mfenced separators="" open="(" close=")"><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mi mathvariant="bold">P</mml:mi> <mml:mo>−</mml:mo> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>⊤</mml:mi></mml:msup></mml:mfenced> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(80)</label></disp-formula></p>
</sec>
<sec id="sec038">
<title>Sensitivity and CC signals as a function of <italic>K</italic></title>
<p>We are now better armed to understand how sensitivity and CC indicators vary as a function of the readout ensemble 𝓔. We are mostly interested in averages of these quantities over very large numbers of randomly chosen ensembles 𝓔 of size <italic>K</italic>; we thus use the generic notation E[<italic>x</italic>∣<italic>K</italic>]≔E[<italic>x</italic>(𝓔)∣Card(𝓔) = <italic>K</italic>] to denote the expected value of a variable <italic>x</italic> when averaging over ensembles of size <italic>K</italic>. Note that this notation is equivalent to the more explicit notation used in the main text, so that E[<italic>x</italic>∣<italic>K</italic>] = ⟨<italic>x</italic>⟩<sub>𝓔</sub>(<italic>K</italic>). From <xref ref-type="disp-formula" rid="pcbi.1004082.e240">eq. 72</xref> we find: <inline-formula id="pcbi.1004082.e262"><mml:math id="M262" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mi>Y</mml:mi> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>K</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.278em"/><mml:msup><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mo>⊤</mml:mo></mml:msup> <mml:mspace width="0.167em"/><mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>K</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="0.167em"/><mml:mi mathvariant="bold-italic">η</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
<p>To understand the properties of the (<italic>M</italic> × <italic>M</italic>) matrix E[<bold>P</bold>∣<italic>K</italic>], we view the (<italic>M</italic> × <italic>K</italic>) design matrix <bold>X</bold>(𝓔) (<xref ref-type="disp-formula" rid="pcbi.1004082.e237">eq. 71</xref>) as a collection of <italic>K</italic> random vectors <bold>x</bold><sub><italic>i</italic></sub> in mode space, viewing neuron identities <italic>i</italic> as the random variable. Thus, <bold>P</bold>(𝓔) is the orthogonal projector on the linear span of the <italic>K</italic> sample vectors {<bold>x</bold><sub><italic>i</italic></sub>}<sub><italic>i</italic> ∈ 𝓔</sub>. As a projector, its trace is equal to its rank, so we have <inline-formula id="pcbi.1004082.e263"><mml:math id="M263" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="normal">Tr</mml:mtext> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">(</mml:mo> <mml:mtext mathvariant="normal">E</mml:mtext> <mml:mo stretchy="false">[</mml:mo> <mml:mtext mathvariant="bold">P</mml:mtext> <mml:mo stretchy="false">∣</mml:mo> <mml:mi>K</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mo minsize="1.2" maxsize="1.2" stretchy="true">)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>. Furthermore, since <italic>K</italic>+1 samples span on average more space than <italic>K</italic> samples, we are ensured that E[<bold>P</bold>∣<italic>K</italic>+1] ≽ E[<bold>P</bold>∣<italic>K</italic>], in the sense of positive semidefinite matrices.</p>
<p>Finally, intuition and numerical simulations suggest that E[<bold>P</bold>∣<italic>K</italic>] is almost diagonal. Indeed, as the various modes are linearly independent, there is no linear interplay between the different dimensions of <bold>x</bold><sub><italic>i</italic></sub> across samples <italic>i</italic>. More precisely, the expectation value over neurons is <inline-formula id="pcbi.1004082.e264"><mml:math id="M264" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>i</mml:mi> <mml:mspace width="0.333em"/></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mtext mathvariant="normal">tot</mml:mtext></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>m</mml:mi> <mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. This leads to the matrix expression:
<disp-formula id="pcbi.1004082.e265"><alternatives><graphic id="pcbi.1004082.e265g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e265"/><mml:math id="M265" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi mathvariant="bold">X</mml:mi> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:mi>K</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi> <mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Let us consider the (compact) SVD decomposition <bold>X</bold> <bold>X</bold><sup>⊤</sup>≔ <bold>W</bold> <bold>D</bold> <bold>W</bold><sup>⊤</sup>, with <bold>W</bold><sup>⊤</sup> <bold>W</bold> = <bold>Id</bold>, and <bold>D</bold> an invertible diagonal matrix. Then, the projection matrix <bold>P</bold> is simply equal to <bold>W</bold> <bold>W</bold><sup>⊤</sup>. As for the previous equation, it rewrites
<disp-formula id="pcbi.1004082.e266"><alternatives><graphic id="pcbi.1004082.e266g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e266"/><mml:math id="M266" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mrow><mml:mo>[</mml:mo> <mml:mi mathvariant="bold">W</mml:mi> <mml:mi mathvariant="bold">D</mml:mi> <mml:msup><mml:mi mathvariant="bold">W</mml:mi> <mml:mi>⊤</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:mi>K</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi> <mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi mathvariant="bold">Λ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Here, both matrices <bold>D</bold> and <bold>Λ</bold> are diagonal. So, if we assume a form of independence between <bold>W</bold> and <bold>D</bold>, it is reasonable to suppose that E[<bold>W</bold> <bold>W</bold><sup>⊤</sup>∣<italic>K</italic>] = E[<bold>P</bold>∣<italic>K</italic>] is close to diagonal as well. (Actually, we postulate that E[<bold>P</bold>∣<italic>K</italic>] is exactly diagonal when the random vectors <bold>x</bold><sub><italic>i</italic></sub> follow a normal distribution. In the general case, small or moderate deviations from diagonality can be observed.) We denote these diagonal terms as
<disp-formula id="pcbi.1004082.e267"><alternatives><graphic id="pcbi.1004082.e267g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e267"/><mml:math id="M267" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>ϵ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≔</mml:mo> <mml:mtext>diag</mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">P</mml:mi> <mml:mo>|</mml:mo> <mml:mi>K</mml:mi> <mml:mo>]</mml:mo> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(81)</label></disp-formula>
The properties of E[<bold>P</bold>∣<italic>K</italic>] stated above imply that ∑<sub><italic>m</italic></sub> <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) = <italic>K</italic> (trace property), and <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>+1) ≥ <italic>ϵ</italic><sub><italic>m</italic></sub>(<italic>K</italic>) (growth property). Finally, we can consider the resulting approximations of sensitivity (<xref ref-type="disp-formula" rid="pcbi.1004082.e240">eq. 72</xref>) and CC indicator (<xref ref-type="disp-formula" rid="pcbi.1004082.e257">eq. 79</xref>):
<disp-formula id="pcbi.1004082.e268"><alternatives><graphic id="pcbi.1004082.e268g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e268"/><mml:math id="M268" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi>Y</mml:mi> <mml:mo>|</mml:mo> <mml:mi>K</mml:mi> <mml:mo>]</mml:mo> <mml:mo>≃</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(82)</label></disp-formula>
<disp-formula id="pcbi.1004082.e269"><alternatives><graphic id="pcbi.1004082.e269g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e269"/><mml:math id="M269" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>[</mml:mo> <mml:mi>Y</mml:mi> <mml:mi>Q</mml:mi> <mml:mo>|</mml:mo> <mml:mi>K</mml:mi> <mml:mo>]</mml:mo> <mml:mo>≃</mml:mo> <mml:msubsup><mml:mi>N</mml:mi> <mml:mrow><mml:mi>tot</mml:mi></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mspace width="0.166667em"/><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:msub><mml:mi>ϵ</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>λ</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(83)</label></disp-formula>
In this expression, we recognize the individual mode sensitivities <inline-formula id="pcbi.1004082.e270"><mml:math id="M270" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>s</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>m</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. For CC signals, we also make the approximation E[<italic>YQ</italic>∣<italic>K</italic>] ≃ E[<italic>Y</italic>∣<italic>K</italic>]E[<italic>Q</italic>∣<italic>K</italic>], and recover <xref ref-type="disp-formula" rid="pcbi.1004082.e120">eq. 21</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e121">22</xref> from the main text. Unfortunately, there is no such simple approximation for indicator <italic>V</italic>, that would lead from <xref ref-type="disp-formula" rid="pcbi.1004082.e261">eq. 80</xref> to E[<italic>V</italic>∣<italic>K</italic>].</p>
</sec>
<sec id="sec039">
<title>Validation on a simulated neural network</title>
<p>In this final part of the Methods, we provide additional information for applying our inference method (Case 2) to experimental data. The neural network used to test our methods is described in detail in supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref> (section 3). Briefly, on each trial, 2000 input Poisson neurons fire with rate <italic>s</italic>, taking one of three possible values 25, 30 and 35 Hz (so in our simulation, stimulus units are Hz). The encoding population <italic>per se</italic> consists of 5000 leaky integrate-and-fire (LIF) neurons. 1000 of these neurons receive sparse excitatory projections from the input Poisson neurons, which naturally endows them with a positive tuning to stimulus <italic>s</italic>. Another 1000 neurons receive sparse inhibitory projections from the Poisson neurons, which naturally endows them with negative tuning. The remaining 3000 neurons receive no direct projections from the input. Instead, all neurons in the encoding population are coupled through a sparse connectivity with random delays up to 5 msec. Synaptic weights are random and balanced, leading to a mean firing rate of 21.8 Hz in the population. We implemented and simulated the network using Brian, a spiking neural network simulator in Python [<xref ref-type="bibr" rid="pcbi.1004082.ref039">39</xref>].</p>
<p>The “true” perceptual readout from this network was built from a fixed random set of <italic>K</italic><sup>⋆</sup> = 80 neurons, with temporal parameters <italic>w</italic><sup>⋆</sup> = 50 msec and <inline-formula id="pcbi.1004082.e271"><mml:math id="M271" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi> <mml:mi>R</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> msec, and decision noise <inline-formula id="pcbi.1004082.e272"><mml:math id="M272" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> stimulus units (Hz). The readout vector <bold>a</bold><sup>⋆</sup> was built optimally given these constraints (<xref ref-type="disp-formula" rid="pcbi.1004082.e077">eq. 12</xref>). The trials used to learn <bold>a</bold><sup>⋆</sup> were not used in the subsequent analysis. The resulting JND for the “animal” was <italic>Z</italic><sup>⋆</sup> ≈ 3 stimulus units (Hz).</p>
<p>Then, “experimentally”, neural activity was observed through 15 pools of 170 simultaneously recorded neurons, each pool being recorded on 3 × 180 trials. For the statistical inference method, we assumed a square integration kernel <italic>h</italic>. We tested all combinations of the following readout parameters (in matrix notation): <italic>K</italic> = 10:10:150 neurons, <italic>w</italic> = 10:10:100 msec, <italic>t</italic><sub><italic>R</italic></sub> = 10:10:200 msec, <italic>σ</italic><sub><italic>d</italic></sub> = 0:0.25:3 stimulus units (Hz). For each tested size <italic>K</italic>, we picked 2000 random candidate ensembles 𝓔 (always within one of the 15 simultaneous pools) to build the predictions. For each ensemble 𝓔, another ensemble ℐ of 20 neurons, segregated from 𝓔, were used to predict CC signals outside the readout ensemble (this was always possible since recording pools had size 170, and <italic>K</italic> ≤ 150). The details of these predictions are explained in the following paragraph. Finally, the three terms in the “statistical” loss function (<xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>) were weighted according to the power of the respective, true measures. That is:
<disp-formula id="pcbi.1004082.e273"><alternatives><graphic id="pcbi.1004082.e273g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e273"/><mml:math id="M273" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>λ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mfenced open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mo>⋆</mml:mo></mml:msup></mml:mfenced> <mml:mn>4</mml:mn></mml:msup> <mml:mrow><mml:mrow><mml:mspace width="0.277778em"/><mml:mpadded width="-3pt"><mml:mo>∫</mml:mo></mml:mpadded> <mml:mpadded width="-3pt"><mml:mo>∫</mml:mo></mml:mpadded> <mml:mspace width="0.277778em"/></mml:mrow> <mml:mspace width="-0.166667em"/><mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>d</mml:mi> <mml:mi>u</mml:mi> <mml:mspace width="0.166667em"/><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>q</mml:mi> <mml:mo>⋆</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mspace width="14.22636pt"/><mml:mi>and</mml:mi> <mml:mspace width="14.22636pt"/><mml:mi>μ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:msup><mml:mfenced open="(" close=")"><mml:msup><mml:mi>Z</mml:mi> <mml:mo>⋆</mml:mo></mml:msup></mml:mfenced> <mml:mn>4</mml:mn></mml:msup> <mml:msup><mml:mfenced open="(" close=")"><mml:msup><mml:mi>V</mml:mi> <mml:mo>⋆</mml:mo></mml:msup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
</sec>
<sec id="sec040">
<title>Experimental predictions for CC indicators</title>
<p>Here, we detail how to compute the CC indicators <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) and <italic>V</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e079">eq. 14</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e080">15</xref>) from actual data. For the <italic>measured</italic> versions <italic>q</italic><sup>⋆</sup>(<italic>u</italic>, <italic>t</italic>) and <italic>V</italic><sup>⋆</sup>(<italic>w</italic>, <italic>t</italic><sub><italic>R</italic></sub>), this is straightforward. One considers the true, <italic>measured</italic> CC signals <inline-formula id="pcbi.1004082.e274"><mml:math id="M274" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, and computes the population averages in <xref ref-type="disp-formula" rid="pcbi.1004082.e079">eq. 14</xref>–<xref ref-type="disp-formula" rid="pcbi.1004082.e080">15</xref> over as many neurons <italic>i</italic> as were recorded. Note however that the final indicators can be corrupted by noise, whenever each measure <inline-formula id="pcbi.1004082.e275"><mml:math id="M275" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi> <mml:mi>i</mml:mi> <mml:mo>⋆</mml:mo></mml:msubsup> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> comes from too few recording trials (this problem is addressed in the next section). Also note that, since the definition of <italic>V</italic> requires a temporal integration, we actually have to produce a different “true” <italic>V</italic><sup>⋆</sup> for each tested set of temporal parameters <italic>w</italic> and <italic>t</italic><sub><italic>R</italic></sub>.</p>
<p>Conversely, special care must be taken when it comes to <italic>predicted</italic> CC indicators. Whenever a candidate ensemble 𝓔 is proposed as the source of the readout, <xref ref-type="disp-formula" rid="pcbi.1004082.e207">eq. 59</xref> predicts the resulting CC signal <italic>d</italic><sub><italic>i</italic></sub>(<italic>t</italic>∣𝓔) for every neuron <italic>i</italic> in the population. However, in practice, the noise covariance term <inline-formula id="pcbi.1004082.e276"><mml:math id="M276" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>r</mml:mi></mml:mrow></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>t</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is required in the computation, so neuron <italic>i</italic> and ensemble 𝓔 must have been recorded simultaneously during the same run. This limits the number of neurons <italic>i</italic> which can participate in the population averages.</p>
<p>Furthermore, choice covariances will generally differ between neurons that are part of the readout ensemble and neurons that are not (see <xref ref-type="disp-formula" rid="pcbi.1004082.e213">eq. 61</xref> and the associated discussion). As a result, the two following averages must be predicted separately:
<disp-formula id="pcbi.1004082.e277"><alternatives><graphic id="pcbi.1004082.e277g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e277"/><mml:math id="M277" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mi>𝓔</mml:mi> <mml:mrow/></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mi>𝓔</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(84)</label></disp-formula>
<disp-formula id="pcbi.1004082.e278"><alternatives><graphic id="pcbi.1004082.e278g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e278"/><mml:math id="M278" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mi>out</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>∉</mml:mo> <mml:mi>𝓔</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(85)</label></disp-formula>
before one can recombine them in the correct proportions:
<disp-formula id="pcbi.1004082.e279"><alternatives><graphic id="pcbi.1004082.e279g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e279"/><mml:math id="M279" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≔</mml:mo> <mml:mfrac><mml:mi>K</mml:mi> <mml:msub><mml:mi>N</mml:mi> <mml:mi>tot</mml:mi></mml:msub></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(86)</label></disp-formula>
<disp-formula id="pcbi.1004082.e280"><alternatives><graphic id="pcbi.1004082.e280g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e280"/><mml:math id="M280" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>q</mml:mi> <mml:mi>𝓔</mml:mi> <mml:mrow/></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mfenced> <mml:msub><mml:mi>q</mml:mi> <mml:mi>out</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(87)</label></disp-formula>
and similarly for <italic>V</italic>(𝓔). To compute <inline-formula id="pcbi.1004082.e281"><mml:math id="M281" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mtext mathvariant="normal">out</mml:mtext> <mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> experimentally, each tested candidate ensemble 𝓔 (of size <italic>K</italic>) is associated to a complimentary set of neurons ℐ (of size <italic>I</italic>), which we use to approximate the average in <xref ref-type="disp-formula" rid="pcbi.1004082.e278">eq. 85</xref>:
<disp-formula id="pcbi.1004082.e282"><alternatives><graphic id="pcbi.1004082.e282g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e282"/><mml:math id="M282" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>q</mml:mi> <mml:mo>𝓘</mml:mo> <mml:mrow/></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mspace width="0.277778em"/><mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>d</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mo>𝓘</mml:mo></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(88)</label></disp-formula>
All neurons in ensembles 𝓔 and ℐ must have been recorded during the same run, which imposes that <italic>I</italic>+<italic>K</italic> ≤ <italic>N</italic>. Hence in our simulations, we chose a size <italic>I</italic> = 170−150 = 20 neurons.</p>
<p>Clearly, 20 neurons is not sufficient for <italic>q</italic><sub>ℐ</sub> to be a reliable population average. So in practice, we cannot estimate reliably each prediction <italic>q</italic>(<italic>u</italic>, <italic>t</italic> ∣𝓔) from <xref ref-type="disp-formula" rid="pcbi.1004082.e280">eq. 87</xref>. Luckily, we are not interested in their value for each individual readout ensemble 𝓔. We simply need to estimate their means across all tested ensembles 𝓔 of similar size:
<disp-formula id="pcbi.1004082.e283"><alternatives><graphic id="pcbi.1004082.e283g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e283"/><mml:math id="M283" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow> <mml:mo>≔</mml:mo> <mml:msub><mml:mfenced separators="" open="⟨" close="⟩"><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mfenced> <mml:mrow><mml:mi>𝓔</mml:mi> <mml:mspace width="1pt"/> <mml:mi>with</mml:mi> <mml:mspace width="1pt"/> <mml:mi>Card</mml:mi> <mml:mspace width="1pt"/> <mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(89)</label></disp-formula>
<disp-formula id="pcbi.1004082.e284"><alternatives><graphic id="pcbi.1004082.e284g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e284"/><mml:math id="M284" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>V</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup> <mml:mo>≔</mml:mo> <mml:msub><mml:mfenced separators="" open="⟨" close="⟩"><mml:mi>V</mml:mi> <mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo></mml:mfenced> <mml:mrow><mml:mi>𝓔</mml:mi> <mml:mspace width="1pt"/> <mml:mi>with</mml:mi> <mml:mspace width="1pt"/> <mml:mi>Card</mml:mi> <mml:mspace width="1pt"/> <mml:mo>(</mml:mo> <mml:mi>𝓔</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(90)</label></disp-formula>
which will be reliable as soon as we test a sufficient amount of candidate ensembles 𝓔.</p>
<p>Note that in the final inference (<xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>), a match is sought between the true indicators <italic>q</italic><sup>⋆</sup> and <italic>V</italic><sup>⋆</sup>—which arise from a single readout ensemble 𝓔<sup>⋆</sup>, and the predictions <inline-formula id="pcbi.1004082.e285"><mml:math id="M285" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mi>q</mml:mi> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="0.333em"/></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="pcbi.1004082.e286"><mml:math id="M286" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo stretchy="false">⟨</mml:mo> <mml:mi>V</mml:mi> <mml:mo stretchy="false">⟩</mml:mo></mml:mrow> <mml:mi>𝓔</mml:mi> <mml:mspace width="0.333em"/></mml:msubsup></mml:mrow></mml:math></inline-formula>—which are average values across all readout ensembles 𝓔 of size <italic>K</italic>. Thus, a prediction error can occur whenever the true readout ensemble 𝓔<sup>⋆</sup> is not a “typical” representative of its size <italic>K</italic><sup>⋆</sup>. To quantify these potential errors, one should also estimate the indicators’ <italic>variance</italic> across ensembles 𝓔 of same size.</p>
</sec>
<sec id="sec041">
<title>Correcting for the finite amounts of data</title>
<p>The computations of <italic>Z</italic>, <italic>q</italic> and <italic>V</italic>, as described above, can produce imprecise results when the data are overly limited. Generically, for any quantity <italic>X</italic> estimated from the data, we can write
<disp-formula id="pcbi.1004082.e287"><alternatives><graphic id="pcbi.1004082.e287g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e287"/><mml:math id="M287" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>X</mml:mi> <mml:mi>noisy</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>X</mml:mi> <mml:mi>ideal</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>ξ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>ξ</italic> represents the measurement error on <italic>X</italic> due to the finite amounts of data. If we could recompute <italic>X</italic> from a different set of neurons and/or a different set of trials, variable <italic>ξ</italic> would take a different value—meaning that Var(<italic>ξ</italic>) &gt; 0. This is an inescapable phenomenon for experimental measures.</p>
<p>More problematically, variable <italic>ξ</italic> can display a systematic <italic>bias</italic>, meaning that E(<italic>ξ</italic>) ≠ 0. Since the bias is generally different for the ‘true’ and ‘predicted’ versions, the comparison between the two (<xref ref-type="disp-formula" rid="pcbi.1004082.e089">eq. 16</xref>) will be systematically flawed. To counteract this effect, we applied a number of correction procedures when computing indicators <italic>Z</italic>, <italic>q</italic> and <italic>V</italic>, to ensure that they are globally unbiased. We only provide an overview here, and refer to supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref> for a detailed description.</p>
<p>First, when the optimal vector <bold>a</bold> is computed with Fisher’s linear discriminant, it systematically underestimates the JND <italic>Z</italic> (overestimates the sensitivity <italic>Y</italic>). Essentially, vector <bold>a</bold><sub><italic>r</italic></sub> computed through <xref ref-type="disp-formula" rid="pcbi.1004082.e077">eq. 12</xref> finds artificial “holes” in matrix <inline-formula id="pcbi.1004082.e288"><mml:math id="M288" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mtext mathvariant="bold">C</mml:mtext> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> which are only due to its imprecise measurement—a phenomenon known as statistical <italic>overfitting</italic>. The less recording trials, the more overfitting there will be [<xref ref-type="bibr" rid="pcbi.1004082.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1004082.ref041">41</xref>]. We addressed this problem with a regularization technique, inspired by Bayesian linear regression [<xref ref-type="bibr" rid="pcbi.1004082.ref042">42</xref>]. We replaced <xref ref-type="disp-formula" rid="pcbi.1004082.e077">eq. 12</xref> by the following:
<disp-formula id="pcbi.1004082.e289"><alternatives><graphic id="pcbi.1004082.e289g" mimetype="image" xlink:type="simple" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004082.e289"/><mml:math id="M289" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">a</mml:mi> <mml:mi>r</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mspace width="0.277778em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>λ</mml:mi> <mml:mi mathvariant="bold">Id</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow> <mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mi>⊤</mml:mi></mml:msubsup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>λ</mml:mi> <mml:mi mathvariant="bold">Id</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold">b</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>r</mml:mi> <mml:mspace width="3.33333pt"/></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where the strength of parameter <italic>λ</italic> imposes the degree of regularization. We chose <italic>λ</italic> according to an ‘empirical Bayes’ principle, to maximize the likelihood of the data under a given statistical model (supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>, section 4). It largely mitigated the effects of overfitting, without totally suppressing them—as can be seen in <xref ref-type="fig" rid="pcbi.1004082.g005">Fig. 5D-E</xref>.</p>
<p>Second, indicator <italic>V</italic> (<xref ref-type="disp-formula" rid="pcbi.1004082.e080">eq. 15</xref>) can also display substantial biases (E(<italic>ξ</italic>) ≠ 0 in the above discussion). Indeed, its computation relies on squared quantities—such as <inline-formula id="pcbi.1004082.e290"><mml:math id="M290" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover><mml:mi>d</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> or <inline-formula id="pcbi.1004082.e291"><mml:math id="M291" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mover><mml:mover><mml:mi>q</mml:mi> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mo accent="true">‾</mml:mo></mml:mover> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>—that systematically transform measurement errors into positive biases. The required corrections are very similar to the classic “<italic>N</italic>/(<italic>N</italic>−1)” correction for the naive variance estimator, with the additional difficulty that <italic>V</italic> is affected by <italic>two</italic> sources of noise: the finite number of recording trials, and the finite number of recorded neurons. The exact corrections to ensure an unbiased estimation of <italic>V</italic> are detailed in supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>, section 5.</p>
<p>Third, indicator <italic>q</italic>(<italic>u</italic>, <italic>t</italic>) displays little or no measurement bias—because its computation is essentially linear. Yet, it can display an important level of measurement noise (Var(<italic>ξ</italic>) ≫ 0 in the above discussion) that may deteriorate the subsequent inference procedure. We mitigated this measurement noise by applying a bi-temporal Gaussian smoothing to <italic>q</italic><sup>⋆</sup>(<italic>u</italic>, <italic>t</italic>) and predictions <italic>q</italic>(<italic>u</italic>, <italic>t</italic>), with time constant 10 msec.</p>
<p>To estimate the measurement errors due to the finite number of trials, we produced 14 sets of surrogate data by sampling our original trials with replacement (bootstrap procedure). These resamplings were used to derive some of the correction terms for <italic>V</italic>, and <italic>also</italic> to derive confidence intervals on our final estimators, as shown in <xref ref-type="fig" rid="pcbi.1004082.g006">Fig. 6</xref>. This departure from the statistical canon was imposed by the length of the whole inference procedure (see supporting <xref ref-type="supplementary-material" rid="pcbi.1004082.s001">S1 Text</xref>, section 5, for details).</p>
</sec>
<sec id="sec042">
<title>Reproduction of our results and implementation</title>
<p>In the Supporting Information, we provide a generic implementation of the inference method (“Case 2” above) in MATLAB, which can be applied to any data from a 2AFC discrimination task. We also provide the Python code for the network simulation, and MATLAB scripts for the reproduction of the experimental Figures in this article (<xref ref-type="fig" rid="pcbi.1004082.g004">Fig. 4</xref>–<xref ref-type="fig" rid="pcbi.1004082.g007">7</xref>).</p>
</sec>
</sec>
<sec id="sec043">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004082.s001" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.s001" mimetype="application/pdf" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supporting text.</title>
<p>Contains additional information about Choice Probabilities (section <bold>1</bold>), the influence of parameter <italic>w</italic> on stimulus sensitivity (section <bold>2</bold>), the encoding neural network used for testing the method (section <bold>3</bold>), the Bayesian regularization procedure on Fisher’s linear discriminant (section <bold>4</bold>), unbiased computation of CC indicators in the presence of measurement noise (section <bold>5</bold>), and an extended readout model with variable extraction time <italic>t</italic><sub><italic>R</italic></sub> (section <bold>6</bold>).</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004082.s002" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004082.s002" mimetype="application/x-compressed" xlink:type="simple">
<label>S1 Compressed file archive</label>
<caption>
<title>Supporting code for the article.</title>
<p>(GZ)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1004082.ref001">
<label>1</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Renart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name> (<year>2014</year>) <article-title>Variability in neural activity and behavior</article-title>. <source>Current Opinion in Neurobiology</source> <volume>25</volume>: <fpage>211</fpage>–<lpage>220</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2014.02.013" xlink:type="simple">10.1016/j.conb.2014.02.013</ext-link></comment> <object-id pub-id-type="pmid">24632334</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref002">
<label>2</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Mountcastle</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Steinmetz</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name> (<year>1990</year>) <article-title>Frequency discrimination in the sense of flutter: psychophysical measurements correlated with postcentral events in behaving monkeys</article-title>. <source>Journal of Neuroscience</source> <volume>10</volume>: <fpage>3032</fpage>–<lpage>3044</lpage>. <object-id pub-id-type="pmid">2118947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref003">
<label>3</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Britten</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name> (<year>1992</year>) <article-title>The analysis of visual motion: a comparison of neuronal and psychophysical performance</article-title>. <source>Journal of Neuroscience</source> <volume>12</volume>: <fpage>4745</fpage>–<lpage>4765</lpage>. <object-id pub-id-type="pmid">1464765</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref004">
<label>4</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Werner</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Mountcastle</surname> <given-names>V</given-names></name> (<year>1965</year>) <article-title>Neural activity in mechanoreceptive cutaneous afferents: Stimulus-response relations, weber functions, and information transmission</article-title>. <source>Journal of Neurophysiology</source> <volume>28</volume>. <object-id pub-id-type="pmid">14283062</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref005">
<label>5</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Talbot</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Darian-Smith</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Kornhuber</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Mountcastle</surname> <given-names>V</given-names></name> (<year>1968</year>) <article-title>The sense of flutter-vibration: comparison of the human capacity with response patterns of mechanoreceptive afferents from the monkey hand</article-title>. <source>Journal of Neurophysiology</source> <volume>31</volume>. <object-id pub-id-type="pmid">4972033</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref006">
<label>6</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Salinas</surname> <given-names>E</given-names></name> (<year>2003</year>) <article-title>Flutter discrimination: neural codes, perception, memory and decision making</article-title>. <source>Nature Reviews Neuroscience</source> <volume>4</volume>: <fpage>203</fpage>–<lpage>18</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1058" xlink:type="simple">10.1038/nrn1058</ext-link></comment> <object-id pub-id-type="pmid">12612633</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref007">
<label>7</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name> (<year>2007</year>) <article-title>The neural basis of decision making</article-title>. <source>Annual Review of Neuroscience</source> <volume>30</volume>: <fpage>535</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.29.051605.113038" xlink:type="simple">10.1146/annurev.neuro.29.051605.113038</ext-link></comment> <object-id pub-id-type="pmid">17600525</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref008">
<label>8</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name> (<year>1998</year>) <article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title>. <source>Journal of Neuroscience</source> <volume>18</volume>: <fpage>3870</fpage>–<lpage>3896</lpage>. <object-id pub-id-type="pmid">9570816</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref009">
<label>9</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name> (<year>1999</year>) <article-title>The effect of correlated variability on the accuracy of a population code</article-title>. <source>Neural computation</source> <volume>11</volume>: <fpage>91</fpage>–<lpage>101</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976699300016827" xlink:type="simple">10.1162/089976699300016827</ext-link></comment> <object-id pub-id-type="pmid">9950724</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref010">
<label>10</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Averbeck</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name> (<year>2006</year>) <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature Reviews Neuroscience</source> <volume>7</volume>: <fpage>358</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1888" xlink:type="simple">10.1038/nrn1888</ext-link></comment> <object-id pub-id-type="pmid">16760916</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref011">
<label>11</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Uka</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name> (<year>2003</year>) <article-title>Contribution of middle temporal area to coarse depth discrimination: comparison of neuronal and psychophysical sensitivity</article-title>. <source>Journal of Neuroscience</source> <volume>23</volume>: <fpage>3515</fpage>–<lpage>30</lpage>. <object-id pub-id-type="pmid">12716961</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref012">
<label>12</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cohen</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name> (<year>2009</year>) <article-title>Estimates of the contribution of single neurons to perception depend on timescale and noise correlation</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>6635</fpage>–<lpage>48</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5179-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5179-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19458234</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref013">
<label>13</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Price</surname> <given-names>NSC</given-names></name>, <name name-style="western"><surname>Born</surname> <given-names>RT</given-names></name> (<year>2010</year>) <article-title>Timescales of sensory- and decision-related activity in the middle temporal and medial superior temporal areas</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>: <fpage>14036</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2336-10.2010" xlink:type="simple">10.1523/JNEUROSCI.2336-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20962225</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref014">
<label>14</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Green</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Swets</surname> <given-names>J</given-names></name> (<year>1966</year>) <source>Signal detection theory and psychophysics</source>, <volume>volume 1974</volume>. <publisher-name>Wiley</publisher-name>, <publisher-loc>New York, USA</publisher-loc>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref015">
<label>15</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Britten</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Celebrini</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>AJ</given-names></name> (<year>1996</year>) <article-title>A relationship between behavioral choice and the visual response of neurons in macaque MT</article-title>. <source>Visual Neuroscience</source> <volume>13</volume>: <fpage>87</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S095252380000715X" xlink:type="simple">10.1017/S095252380000715X</ext-link></comment> <object-id pub-id-type="pmid">8730992</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref016">
<label>16</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>de Lafuente</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name> (<year>2006</year>) <article-title>Neural correlate of subjective sensory experience gradually builds up across cortical areas</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>103</volume>: <fpage>14266</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0605826103" xlink:type="simple">10.1073/pnas.0605826103</ext-link></comment> <object-id pub-id-type="pmid">16924098</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref017">
<label>17</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Britten</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>AJ</given-names></name> (<year>1996</year>) <article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title>. <source>Journal of Neuroscience</source> <volume>76</volume>: <fpage>1486</fpage>–<lpage>1510</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref018">
<label>18</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nienborg</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Cumming</surname> <given-names>BG</given-names></name> (<year>2010</year>) <article-title>Correlations between the activity of sensory neurons and behavior: how much do they tell us about a neuron’s causality?</article-title> <source>Current opinion in neurobiology</source> <volume>20</volume>: <fpage>376</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2010.05.002" xlink:type="simple">10.1016/j.conb.2010.05.002</ext-link></comment> <object-id pub-id-type="pmid">20545019</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref019">
<label>19</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Haefner</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Gerwinn</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name> (<year>2013</year>) <article-title>Inferring decoding strategies from choice probabilities in the presence of correlated variability</article-title>. <source>Nature Neuroscience</source> <volume>16</volume>: <fpage>235</fpage>–<lpage>242</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3309" xlink:type="simple">10.1038/nn.3309</ext-link></comment> <object-id pub-id-type="pmid">23313912</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref020">
<label>20</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Nienborg</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Cumming</surname> <given-names>BG</given-names></name> (<year>2009</year>) <article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source>Nature</source> <volume>459</volume>: <fpage>89</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07821" xlink:type="simple">10.1038/nature07821</ext-link></comment> <object-id pub-id-type="pmid">19270683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref021">
<label>21</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hernández</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zainos</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name> (<year>2000</year>) <article-title>Neuronal correlates of sensory discrimination in the somatosensory cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>97</volume>: <fpage>6191</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.120018597" xlink:type="simple">10.1073/pnas.120018597</ext-link></comment> <object-id pub-id-type="pmid">10811922</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref022">
<label>22</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Aertsen</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Gerstein</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Habib</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Palm</surname> <given-names>G</given-names></name> (<year>1989</year>) <article-title>Dynamics of neuronal firing correlation: modulation of “effective connectivity”</article-title>. <source>Journal of neurophysiology</source> <volume>61</volume>: <fpage>900</fpage>–<lpage>17</lpage>. <object-id pub-id-type="pmid">2723733</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref023">
<label>23</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Luna</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hernández</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Brody</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name> (<year>2005</year>) <article-title>Neural codes for perceptual discrimination in primary somatosensory cortex</article-title>. <source>Nature Neuroscience</source> <volume>8</volume>: <fpage>1210</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1513" xlink:type="simple">10.1038/nn1513</ext-link></comment> <object-id pub-id-type="pmid">16056223</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref024">
<label>24</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ahrens</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Orger</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Robson</surname> <given-names>DN</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Keller</surname> <given-names>PJ</given-names></name> (<year>2013</year>) <article-title>Whole-brain functional imaging at cellular resolution using light-sheet microscopy</article-title>. <source>Nature methods</source> <volume>10</volume>: <fpage>413</fpage>–<lpage>420</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nmeth.2434" xlink:type="simple">10.1038/nmeth.2434</ext-link></comment> <object-id pub-id-type="pmid">23524393</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref025">
<label>25</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Panier</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Romano</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Olive</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pietri</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sumbre</surname> <given-names>G</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Fast functional imaging of multiple brain regions in intact zebrafish larvae using selective plane illumination microscopy</article-title>. <source>Frontiers in neural circuits</source> <volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncir.2013.00065" xlink:type="simple">10.3389/fncir.2013.00065</ext-link></comment> <object-id pub-id-type="pmid">23576959</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref026">
<label>26</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Portugues</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Feierstein</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Engert</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Orger</surname> <given-names>MB</given-names></name> (<year>2014</year>) <article-title>Whole-brain activity maps reveal stereotyped, distributed networks for visuomotor behavior</article-title>. <source>Neuron</source> <volume>81</volume>: <fpage>1328</fpage>–<lpage>1343</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.01.019" xlink:type="simple">10.1016/j.neuron.2014.01.019</ext-link></comment> <object-id pub-id-type="pmid">24656252</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref027">
<label>27</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name> (<year>2009</year>) <source>The elements of statistical learning</source>. <publisher-name>Springer Verlag</publisher-name>, <publisher-loc>New York, USA</publisher-loc>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref028">
<label>28</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wohrer</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Humphries</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name> (<year>2013</year>) <article-title>Population-wide distributions of neural activity during perceptual decision-making</article-title>. <source>Progress in Neurobiology</source> <volume>103</volume>: <fpage>156</fpage>–<lpage>193</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.pneurobio.2012.09.004" xlink:type="simple">10.1016/j.pneurobio.2012.09.004</ext-link></comment> <object-id pub-id-type="pmid">23123501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref029">
<label>29</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Wohrer</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name> (<year>2010</year>) <article-title>Linear readout from a neural population with partial correlation data</article-title>. In: <source>Advances in Neural Information Processing</source>. volume <volume>23</volume>, pp. <fpage>2469</fpage>–<lpage>2477</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref030">
<label>30</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Turaga</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Packer</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Dalgleish</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Pettit</surname> <given-names>N</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Inferring neural population dynamics from multiple partial recordings of the same neural circuit</article-title>. In: <source>Advances in Neural Information Processing Systems</source>. pp. <fpage>539</fpage>–<lpage>547</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref031">
<label>31</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boerlin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Denève</surname> <given-names>S</given-names></name> (<year>2013</year>) <article-title>Predictive coding of dynamical variables in balanced spiking networks</article-title>. <source>PLoS computational biology</source> <volume>9</volume>: <fpage>e1003258</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003258" xlink:type="simple">10.1371/journal.pcbi.1003258</ext-link></comment> <object-id pub-id-type="pmid">24244113</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref032">
<label>32</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Boerlin</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Denève</surname> <given-names>S</given-names></name> (<year>2011</year>) <article-title>Spike-based population coding and working memory</article-title>. <source>PLoS computational biology</source> <volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001080" xlink:type="simple">10.1371/journal.pcbi.1001080</ext-link></comment> <object-id pub-id-type="pmid">21379319</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref033">
<label>33</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Schaub</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>S</given-names></name> (<year>2012</year>) <article-title>The ising decoder: reading out the activity of large neural ensembles</article-title>. <source>Journal of Computational Neuroscience</source> <volume>32</volume>: <fpage>101</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-011-0342-z" xlink:type="simple">10.1007/s10827-011-0342-z</ext-link></comment> <object-id pub-id-type="pmid">21667155</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref034">
<label>34</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Cook</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JHR</given-names></name> (<year>2002</year>) <article-title>Dynamics of neuronal responses in macaque mt and vip during motion detection</article-title>. <source>Nature neuroscience</source> <volume>5</volume>: <fpage>985</fpage>–<lpage>994</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn924" xlink:type="simple">10.1038/nn924</ext-link></comment> <object-id pub-id-type="pmid">12244324</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref035">
<label>35</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Stanford</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Shankar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Massoglia</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Costello</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Salinas</surname> <given-names>E</given-names></name> (<year>2010</year>) <article-title>Perceptual decision making in less than 30 milliseconds</article-title>. <source>Nature Neuroscience</source> <volume>13</volume>: <fpage>379</fpage>–<lpage>385</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2485" xlink:type="simple">10.1038/nn.2485</ext-link></comment> <object-id pub-id-type="pmid">20098418</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref036">
<label>36</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Ashourian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>Y</given-names></name> (<year>2011</year>) <article-title>Bayesian inference underlies the contraction bias in delayed comparison tasks</article-title>. <source>PloS one</source> <volume>6</volume>: <fpage>e19551</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0019551" xlink:type="simple">10.1371/journal.pone.0019551</ext-link></comment> <object-id pub-id-type="pmid">21589867</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref037">
<label>37</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Miura</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name> (<year>2012</year>) <article-title>Odor representations in olfactory cortex: distributed rate coding and decorrelated population activity</article-title>. <source>Neuron</source> <volume>74</volume>: <fpage>1087</fpage>–<lpage>1098</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.04.021" xlink:type="simple">10.1016/j.neuron.2012.04.021</ext-link></comment> <object-id pub-id-type="pmid">22726838</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref038">
<label>38</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Daley</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Vere-Jones</surname> <given-names>D</given-names></name> (<year>2007</year>) <source>An introduction to the theory of point processes</source>, <volume>volume 1</volume>. <publisher-name>Springer Verlag</publisher-name>, <publisher-loc>New York, USA</publisher-loc>.</mixed-citation>
</ref>
<ref id="pcbi.1004082.ref039">
<label>39</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Goodman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Brette</surname> <given-names>R</given-names></name> (<year>2008</year>) <article-title>Brian: a simulator for spiking neural networks in python</article-title>. <source>Frontiers in neuroinformatics</source> <volume>2</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.11.005.2008" xlink:type="simple">10.3389/neuro.11.005.2008</ext-link></comment> <object-id pub-id-type="pmid">19115011</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref040">
<label>40</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Raudys</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Duin</surname> <given-names>R</given-names></name> (<year>1998</year>) <article-title>Expected classification error of the fisher linear classifier with pseudoinverse covariance matrix</article-title>. <source>Pattern Recognition Letters</source> <volume>19</volume>: <fpage>385</fpage>–<lpage>392</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-8655(98)00016-6" xlink:type="simple">10.1016/S0167-8655(98)00016-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref041">
<label>41</label>
<mixed-citation xlink:type="simple" publication-type="journal">
<name name-style="western"><surname>Hoyle</surname> <given-names>DC</given-names></name> (<year>2011</year>) <article-title>Accuracy of pseudo-inverse covariance learning–a random matrix theory analysis</article-title>. <source>Pattern Analysis and Machine Intelligence, IEEE Transactions on</source> <volume>33</volume>: <fpage>1470</fpage>–<lpage>1481</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TPAMI.2010.186" xlink:type="simple">10.1109/TPAMI.2010.186</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004082.ref042">
<label>42</label>
<mixed-citation xlink:type="simple" publication-type="book">
<name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name> (<year>2006</year>) <source>Pattern recognition and machine learning</source>. <publisher-name>Springer Verlag</publisher-name>, <publisher-loc>New York, USA</publisher-loc>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>