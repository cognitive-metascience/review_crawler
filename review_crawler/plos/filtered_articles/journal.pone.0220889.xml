<article xmlns:ns0="http://www.w3.org/1999/xlink" xmlns:ns1="http://www.w3.org/1998/Math/MathML" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PONE-D-19-14718</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0220889</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Entropy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Replication studies</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Research errors</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Statistical distributions</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject><subj-group><subject>Skewness</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Regression analysis</subject><subj-group><subject>Linear regression analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Regression analysis</subject><subj-group><subject>Linear regression analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Robustness of statistical methods when measure is affected by ceiling and/or floor effect</article-title>
<alt-title alt-title-type="running-head">Robustness of statistical methods when measure is affected by ceiling and/or floor effect</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" ns0:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0358-8607</contrib-id>
<name name-style="western">
<surname>&#352;imkovic</surname> <given-names>Mat&#250;&#353;</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; original draft</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; review &amp; editing</role>
<xref ref-type="aff" rid="aff001" />
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" ns0:type="simple">
<name name-style="western">
<surname>Tr&#228;uble</surname> <given-names>Birgit</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; original draft</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; review &amp; editing</role>
<xref ref-type="aff" rid="aff001" />
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Universit&#228;t zu K&#246;ln, Cologne, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" ns0:type="simple">
<name name-style="western">
<surname>Hutson</surname> <given-names>Alan D</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1" />
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Roswell Park Cancer Institute, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email ns0:type="simple">matus.simkovic@uni-koeln.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>19</day>
<month>8</month>
<year>2019</year>
</pub-date>
<volume>14</volume>
<issue>8</issue>
<elocation-id>e0220889</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>5</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>7</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>&#352;imkovic, Tr&#228;uble</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" ns0:href="info:doi/10.1371/journal.pone.0220889" />
<abstract>
<sec id="sec001">
<title>Goals and methods</title>
<p>A simulation study investigated how ceiling and floor effect (CFE) affect the performance of Welch&#8217;s <italic>t</italic>-test, <italic>F</italic>-test, Mann-Whitney test, Kruskal-Wallis test, Scheirer-Ray-Hare-test, trimmed <italic>t</italic>-test, Bayesian <italic>t</italic>-test, and the &#8220;two one-sided tests&#8221; equivalence testing procedure. The effect of CFE on the estimate of group difference and on its confidence interval, and on Cohen&#8217;s <italic>d</italic> and on its confidence interval was also evaluated. In addition, the parametric methods were applied to data transformed with log or logit function and the performance was evaluated. The notion of essential maximum from abstract measurement theory is used to formally define CFE and the principle of maximum entropy was used to derive probability distributions with essential maximum/minimum. These distributions allow the manipulation of the magnitude of CFE through a parameter. Beta, Gamma, Beta prime and Beta-binomial distributions were obtained in this way with the CFE parameter corresponding to the logarithm of the geometric mean. Wald distribution and ordered logistic regression were also included in the study due to their measure-theoretic connection to CFE, even though these models lack essential minimum/maximum. Performance in two-group, three-group and 2 &#215; 2 factor design scenarios was investigated by fixing the group differences in terms of CFE parameter and by adjusting the base level of CFE.</p>
</sec>
<sec id="sec002">
<title>Results and conclusions</title>
<p>In general, bias and uncertainty increased with CFE. Most problematic were occasional instances of biased inference which became more certain and more biased as the magnitude of CFE increased. The bias affected the estimate of group difference, the estimate of Cohen&#8217;s <italic>d</italic> and the decisions of the equivalence testing methods. Statistical methods worked best with transformed data, albeit this depended on the match between the choice of transformation and the type of CFE. Log transform worked well with Gamma and Beta prime distribution while logit transform worked well with Beta distribution. Rank-based tests showed best performance with discrete data, but it was demonstrated that even there a model derived with measurement-theoretic principles may show superior performance. Trimmed <italic>t</italic>-test showed poor performance. In the factor design, CFE prevented the detection of main effects as well as the detection of interaction. Irrespective of CFE, <italic>F</italic>-test misidentified main effects and interactions on multiple occasions. Five different constellations of main effect and interactions were investigated for each probability distribution, and weaknesses of each statistical method were identified and reported. As part of the discussion, the use of generalized linear models based on abstract measurement theory is recommended to counter CFE. Furthermore, the necessity of measure validation/calibration studies to obtain the necessary knowledge of CFE to design and select an appropriate statistical tool, is stressed.</p>
</sec>
</abstract>
<funding-group>
<funding-statement>The authors received no specific funding for this work.</funding-statement>
</funding-group>
<counts>
<fig-count count="11" />
<table-count count="2" />
<page-count count="47" />
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the manuscript and its Supporting Information files. The code used to run the simulations and to generate the figures is available from <ext-link ext-link-type="uri" ns0:href="https://github.com/simkovic/CFE" ns0:type="simple">https://github.com/simkovic/CFE</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec003" sec-type="intro">
<title>1 Introduction</title>
<p>In 2008, Schnall investigated how participants rate moral dilemmas after they have been presented with words related to the topic of cleanliness, as opposed to neutral words [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>]. The study reported that participants who were primed with the concept of cleanliness, found moral transgressions less bad than participants who weren&#8217;t primed. [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>] conducted a replication study using the same methods and materials. In contrast to [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>], [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>] found that the mean ratings of the two groups in their study did not differ. [<xref ref-type="bibr" rid="pone.0220889.ref003">3</xref>] pointed out that in [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>] participants provided overall higher ratings than in the original study. [<xref ref-type="bibr" rid="pone.0220889.ref003">3</xref>] argued that the failure of the replication study to establish a difference between the two groups was due to a <italic>ceiling effect</italic>. Since substantial proportions of both groups provided maximum ratings, it was not possible to determine a difference in rating between these two groups. [<xref ref-type="bibr" rid="pone.0220889.ref004">4</xref>] provided their own analyses of ceiling effects in both, the original and the replication study and concluded that the ceiling effect can&#8217;t account for the failure to replicate the original finding. Other researchers shared their analyses of the ceiling effects in these two studies on their websites and on social media. Here is a quick overview of the variety of the suggested analyses: [<xref ref-type="bibr" rid="pone.0220889.ref003">3</xref>] showed that the mean ratings in the replication study were significantly higher than those in the original study. Furthermore, she showed that the proportion of the most extreme ratings on the 10 point scale was significantly higher in the replication study than in the original study. [<xref ref-type="bibr" rid="pone.0220889.ref004">4</xref>] argued that rank-based Mann-Whitney test provides results that are identical to an analysis with Analysis of Variance (ANOVA). Furthermore, analyses without extreme values failed to reach significance as well. [<xref ref-type="bibr" rid="pone.0220889.ref005">5</xref>] did not find the above-mentioned analyses satisfactory and suggested an analysis with Tobit model, which showed a non-significant effect. [<xref ref-type="bibr" rid="pone.0220889.ref006">6</xref>] argued that Schnall&#8217;s analyses do not support her conclusions. [<xref ref-type="bibr" rid="pone.0220889.ref007">7</xref>] investigated how ceiling effects would affect the power of a t-test. He used a graded response model to simulate data that were affected by ceiling, similar to those obtained in the replication study. The effect size was set to a value obtained in the original study. He found that, depending on the model parametrization, the power of a t-test in the simulated replication study ranges from 70 to 84% which should be sufficient to detect the effect. [<xref ref-type="bibr" rid="pone.0220889.ref008">8</xref>] performed Bayes Factor analysis and compared the quantiles. Both analyses suggested an absence of an effect in the replication study.</p>
<p>In our opinion, this discussion about the presence and impact of ceilings effects illustrates how relevant, yet elusive, the concept of ceiling effect is. Apparently, the only point regarding ceiling effects, on which all parties agreed, is that the application of parametric analyses such as ANOVA or t-test is problematic in the presence of a ceiling effect. Yet the authors disagreed on how to demonstrate and measure the impact of ceiling effect, which makes the default application of ANOVA problematic per se. Motivated by these concerns, the current work presents a computer simulation study that investigates how various methods of statistical inference perform when the measurements are affected by ceiling and/or floor effect (CFE). The main focus is on the performance of the textbook methods: Welch&#8217;s version of t-test, ANOVA and rank-based tests. In addition, the performance of potential candidate methods, some of which were already encountered in the discussion of the study by [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>], is investigated. The hallmark of the current work is the theoretical elaboration of the concept of CFE with the help of formal measurement theory [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>]. This theoretical embedding provides a backbone for the simulations, and, as we further point out, the lack of such theoretical embedding may be one of the reasons why the number and scope of simulation studies of CFE up until now is limited.</p>
<p>Measurement-theoretic definitions of CFE are discussed in section 1.1. Section 1.2 reviews the literature on the robustness of the textbook methods. Only few robustness studies do explicitly consider the CFE. However, numerous studies investigate other factors, which may combine to create CFE. These studies, in particular, are considered in section 1.2. Taking stock of the material presented in the preceding sections, sections 1.3.1 and 1.3.2 justify the choice of statistical methods and the choice of the data-generating mechanism utilized by the simulations. While section 2 provides additional details on the methods and procedures, the description provided in sections 1.3.1 and 1.3.2 should be sufficient to follow the results presentation and a reader interested in the results may directly skip to section 3 and 4.</p>
<sec id="sec004">
<title>1.1 Formal definition of CFE</title>
<p>Consider first some informal notions of CFE. The dictionary of statistical terms by [<xref ref-type="bibr" rid="pone.0220889.ref010">10</xref>] provides the following entry on CFE. &#8220;Ceiling effect: occurs when scores on a variable are approaching the maximum they can be. Thus, there may be bunching of values close to the upper point. The introduction of a new variable cannot do a great deal to elevate the scores any further since they are virtually as high as they can go.&#8221; The dictionary entry in [<xref ref-type="bibr" rid="pone.0220889.ref011">11</xref>] (see also [<xref ref-type="bibr" rid="pone.0220889.ref012">12</xref>]) says: &#8220;Ceiling effect: A term used to describe what happens when many subjects in a study have scores on a variable that are at or near the possible upper limit (&#8216;ceiling&#8217;). Such an effect may cause problems for some types of analysis because it reduces the possible amount of variation in the variable.&#8221;</p>
<p>We identify two crucial aspects of CFE in these quotes. First, CFE causes a &#8220;bunching&#8221; of measured variables, such that the measure becomes insensitive to changes in the latent variable that it is supposed to measure. Second, CFE does not only affect the expected change in the measured variable but its other distributional properties as well which may in turn affect the performance of some statistical methods. [<xref ref-type="bibr" rid="pone.0220889.ref011">11</xref>] mentions the variability, which one may interpret as the variance of the measured variable. [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] hypothesized that skew is the crucial property that characterizes CFE. Importantly, the informal descriptions lack precise rationale and risk excluding less obvious and intuitive phenomena from the definition of CFE. In section 1.1.1 we show that formal measurement theory allows us to make these (and many others) informal notions precise. Historically, the research in measurement theory has been concerned with deterministic variables and despite multiple attempts a principled extension to random variables was not achieved. In section 1.1.3 we review the derivation of maximum entropy distributions, which provides an extension of measurement theory to random variables and in particular allow us to derive distributions, that can be used to simulate CFE and to manipulate its magnitude.</p>
<sec id="sec005">
<title>1.1.1 Measurement theory</title>
<p>A function, say <italic>&#981;</italic> from <italic>A</italic> to a subset of <inline-formula id="pone.0220889.e001"><alternatives><graphic id="pone.0220889.e001g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e001" ns0:type="simple" /><ns1:math display="inline" id="M1"><ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:math></alternatives></inline-formula>, describes the assignment of numbers to empirical objects or events. <italic>&#981;</italic> is, in the context of measurement theory, referred to as <italic>scale</italic>. It is crucial that <italic>&#981;</italic> is chosen such that the numerical values retain the relations and properties of the empirical objects in <italic>A</italic> (i.e. <italic>&#981;</italic> is a homomorphism, see section 1.2.2 in [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>]). For instance, if the empirical objects are ordered, such that <italic>a</italic> &#10927; <italic>b</italic> for some <italic>a</italic>, <italic>b</italic> &#8712; <italic>A</italic>, then it is desirable that <italic>&#981;</italic> satisfies <italic>a</italic> &#10927; <italic>b</italic> if and only if (iff) <italic>&#981;</italic>(<italic>a</italic>) &#8804; <italic>&#981;</italic>(<italic>b</italic>). Measurement theory describes various scale types and the properties of the empirical events necessary and sufficient to construct the respective scale type. In addition, given a set of properties of empirical objects, multiple choices of <italic>&#981;</italic> may be possible and measurement theory delineates the set of such permissible functions. A scale that preserves the order, i.e. <italic>a</italic> &#10927; <italic>b</italic> iff <italic>&#981;</italic>(<italic>a</italic>)&#8804;<italic>&#981;</italic>(<italic>b</italic>) is referred to as <italic>ordinal</italic> scale. Given that <italic>&#981;</italic> is an ordinal scale, then <italic>&#981;</italic>&#8242;(<italic>a</italic>) = <italic>f</italic>(<italic>&#981;</italic>(<italic>a</italic>)) is also an ordinal scale for all <italic>a</italic> &#8712; <italic>A</italic> and for a strictly increasing <italic>f</italic> (ibid. p.15). Note that the set of possible scales is described as a set of possible transformations <italic>f</italic> of some valid scale <italic>&#981;</italic>. Other notable instances are <italic>ratio</italic> scale and <italic>interval</italic> scale. In addition to order, a ratio scale preserves a concatenation operation &#8728; such that <italic>&#981;</italic>(<italic>a</italic> &#8728; <italic>b</italic>) = <italic>&#981;</italic>(<italic>a</italic>) + <italic>&#981;</italic>(<italic>b</italic>). A ratio scale is specified up to a choice of unit i.e. <italic>&#981;</italic>&#8242;(<italic>a</italic>) = <italic>&#945;&#981;</italic>(<italic>a</italic>), with <italic>&#945;</italic> &gt; 0. The required structure of empirical events is called <italic>extensive structure</italic> (ibid. chapter 3). In some situations it is not possible to take direct measurements of the empirical objects of interest, however one may measure pairwise differences or intervals between the empirical objects, say <italic>a</italic> &#8854; <italic>b</italic> or <italic>c</italic> &#8854; <italic>d</italic>. Then, one may construct an interval scale given that <italic>a</italic> &#8854; <italic>b</italic> &#10927; <italic>c</italic> &#8854; <italic>d</italic> if <italic>&#981;</italic>(<italic>a</italic> &#8854; <italic>b</italic>) &#8804; <italic>&#981;</italic>(<italic>c</italic> &#8854; <italic>d</italic>) and <italic>&#981;</italic>(<italic>a</italic> &#8854; <italic>c</italic>) = <italic>&#981;</italic>(<italic>a</italic> &#8854; <italic>b</italic>) + <italic>&#981;</italic>(<italic>b</italic> &#8854; <italic>c</italic>) for all <italic>a</italic>, <italic>b</italic>, <italic>c</italic>, <italic>d</italic> &#8712; <italic>A</italic> (ibid, p. 147). The set of permissible transformations is given by <italic>&#981;</italic>&#8242;(<italic>a</italic>) = <italic>&#945;&#981;</italic>(<italic>a</italic>) + <italic>&#946;</italic> with <inline-formula id="pone.0220889.e002"><alternatives><graphic id="pone.0220889.e002g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e002" ns0:type="simple" /><ns1:math display="inline" id="M2"><ns1:mrow><ns1:mi>&#946;</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> and <italic>&#945;</italic> &gt; 0. The corresponding structure is labelled <italic>difference structure</italic> (ibid. chapter 4).</p>
<p>Consider concatenation again. The concatenation operation in length measurement can be performed by placing two rods sequentially. In weight measurement the concatenation may be performed by placing two objects on the pan of a balance scale. As [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] (chap. 3.14) point out, finding and justifying a concatenation operation in social sciences often poses difficulties. Furthermore, it is not necessary to map concatenation to addition. For instance, taking <italic>&#968;</italic> = exp(<italic>&#981;</italic>), with interval scale <italic>&#981;</italic>, will translate addition on <inline-formula id="pone.0220889.e003"><alternatives><graphic id="pone.0220889.e003g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e003" ns0:type="simple" /><ns1:math display="inline" id="M3"><ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:math></alternatives></inline-formula> to multiplication on <inline-formula id="pone.0220889.e004"><alternatives><graphic id="pone.0220889.e004g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e004" ns0:type="simple" /><ns1:math display="inline" id="M4"><ns1:msup><ns1:mi mathvariant="double-struck">R</ns1:mi> <ns1:mo>+</ns1:mo></ns1:msup></ns1:math></alternatives></inline-formula>. More generally, any strictly monotonous function <italic>f</italic> may be used to obtain a valid numerical representation <italic>&#968;</italic>(<italic>a</italic>) = <italic>f</italic><sup>&#8722;1</sup>(<italic>&#981;</italic>(<italic>a</italic>)) with a (possibly non-additive) concatenation formula <italic>&#968;</italic>(<italic>a</italic> &#8728; <italic>b</italic>) = <italic>f</italic><sup>&#8722;1</sup>(<italic>f</italic>(<italic>&#968;</italic>(<italic>a</italic>)) + <italic>f</italic>(<italic>&#968;</italic>(<italic>b</italic>))). [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] (chap. 3.7.1) make use of this fact when considering measurement of relativistic velocity (also referred to as rapidity). Relativistic velocity is of interest in the present work because it is bounded&#8212;it can&#8217;t exceed the velocity of light. The upper bound poses difficulties for the additive numerical representation since an extensive structure assumes positivity of addition, i.e. <italic>a</italic> &#8826; <italic>a</italic> &#8728; <italic>b</italic> for all <italic>a</italic>, <italic>b</italic> &#8712; <italic>A</italic> (axiom 5 in definition 1 on p.73 ibid.). However, if <italic>z</italic> is the velocity of light, we have <italic>z</italic> &#8764; <italic>z</italic> &#8728; <italic>a</italic>, which violates positivity. [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] resolve this issue by mapping velocity from a bounded range to an unbounded range, performing addition there and mapping the result back to the bounded range. Formally, concatenation is given by ([<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] chapter 3, theorem 6)
<disp-formula id="pone.0220889.e005"><alternatives><graphic id="pone.0220889.e005g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e005" ns0:type="simple" /><ns1:math display="block" id="M5"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>&#8728;</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>z</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>z</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>z</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(1)</label></disp-formula>
where <italic>f</italic><sub><italic>u</italic></sub> is a strictly increasing function from [0, 1] to <inline-formula id="pone.0220889.e006"><alternatives><graphic id="pone.0220889.e006g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e006" ns0:type="simple" /><ns1:math display="inline" id="M6"><ns1:msup><ns1:mi mathvariant="double-struck">R</ns1:mi> <ns1:mo>+</ns1:mo></ns1:msup></ns1:math></alternatives></inline-formula> that is unique up to a positive multiplicative constant. As [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] point out, taking transformation <italic>f</italic><sub><italic>u</italic></sub> = tanh<sup>&#8722;1</sup> results in the velocity-addition formula of the relativistic physics. However, this choice is arbitrary and <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> provides us with the general result, which we will use in the current work. [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] call an element which satisfies <italic>z</italic><sub><italic>u</italic></sub> &#8764; <italic>z</italic><sub><italic>u</italic></sub> &#8728; <italic>a</italic> (for all <italic>a</italic> &#8712; <italic>A</italic>) an <italic>essential maximum</italic>. [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] further show that given an extensive structure with an essential maximum, there always exists a strictly increasing function <italic>f</italic><sub><italic>u</italic></sub> such that <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> is satisfied.</p>
<p>Next, we consider several straightforward extensions of the result by [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>]. First, we wish to introduce extensive structures with an essential minimum <italic>z</italic><sub><italic>l</italic></sub>. Note that even though velocity has a lower bound at zero, this lower bound is not an essential minimum, because the concatenation is positive and a repeated concatenation results in increasing numerical values. As a consequence, essential maximum or essential minimum is a property related to a concatenation operation rather than a property of the numerical range of a scale. If we distinguish between <italic>z</italic><sub><italic>u</italic></sub> and <italic>z</italic><sub><italic>l</italic></sub> we need to distinguish between &#8728;<sub><italic>u</italic></sub> and &#8728;<sub><italic>l</italic></sub> and in turn between <italic>f</italic><sub><italic>u</italic></sub> and <italic>f</italic><sub><italic>l</italic></sub>. Of course, this does not preclude the possibility that in some particular application it may be true that <italic>f</italic><sub><italic>u</italic></sub> = <italic>f</italic><sub><italic>l</italic></sub>.</p>
<p>Consider a modification of <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> to describe an essential minimum. Qualitatively, an essential minimum manifests, similar to an essential maximum, the property <italic>z</italic> &#8764; <italic>z</italic> &#8728;<sub><italic>l</italic></sub> <italic>a</italic>. In this case however &#8728;<sub><italic>l</italic></sub> is a negative operation in the sense that <italic>a</italic> &#8827; <italic>a</italic> &#8728;<sub><italic>l</italic></sub> <italic>b</italic> for all <italic>a</italic>, <italic>b</italic> &#8712; <italic>A</italic>. The results then are analogous to those of the velocity derivation. The main difference is that the scale <italic>&#981;</italic><sub><italic>l</italic></sub> maps to [<italic>&#981;</italic><sub><italic>l</italic></sub>(<italic>z</italic><sub><italic>l</italic></sub>), 0] rather than to [0, <italic>&#981;</italic><sub><italic>u</italic></sub>(<italic>z</italic><sub><italic>u</italic></sub>)]. However, both expressions <italic>&#981;</italic><sub><italic>l</italic></sub>(<italic>a</italic>)/<italic>&#981;</italic><sub><italic>l</italic></sub>(<italic>z</italic><sub><italic>l</italic></sub>) and <italic>&#981;</italic><sub><italic>u</italic></sub>(<italic>a</italic>)/<italic>&#981;</italic><sub><italic>u</italic></sub>(<italic>z</italic><sub><italic>u</italic></sub>) translate into the range [0, 1] and hence, the only modification of <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> is to add subscripts:
<disp-formula id="pone.0220889.e007"><alternatives><graphic id="pone.0220889.e007g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e007" ns0:type="simple" /><ns1:math display="block" id="M7"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>l</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>.</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(2)</label></disp-formula>
Thus, if a structure has an essential minimum, then a strictly increasing function <italic>f</italic><sub><italic>l</italic></sub> exists such that <xref ref-type="disp-formula" rid="pone.0220889.e007">Eq 2</xref> is satisfied.</p>
<p>Second, we wish to extend <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> to situations in which the minimal element <italic>z</italic><sub><italic>l</italic></sub> (irrespective of whether it is essential minimum or not) is non-zero. We do so by first translating the measured values from range [<italic>&#981;</italic>(<italic>z</italic><sub><italic>l</italic></sub>), <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>)] to [0, <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>) &#8722; <italic>&#981;</italic>(<italic>z</italic><sub><italic>l</italic></sub>)] and then to the domain of <italic>f</italic><sub><italic>u</italic></sub> i.e. [0, 1]:
<disp-formula id="pone.0220889.e008"><alternatives><graphic id="pone.0220889.e008g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e008" ns0:type="simple" /><ns1:math display="block" id="M8"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>u</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>.</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(3)</label></disp-formula>
Third, similar to step two, we modify <xref ref-type="disp-formula" rid="pone.0220889.e007">Eq 2</xref> to apply in situations with a non-zero maximal element <italic>z</italic><sub><italic>u</italic></sub> <disp-formula id="pone.0220889.e009"><alternatives><graphic id="pone.0220889.e009g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e009" ns0:type="simple" /><ns1:math display="block" id="M9"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>l</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>.</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(4)</label></disp-formula>
Above, we distinguished between a scale with an essential minimum <italic>&#981;</italic><sub><italic>l</italic></sub> and a scale with an essential maximum <italic>&#981;</italic>, which was in <xref ref-type="disp-formula" rid="pone.0220889.e008">Eq 3</xref> labelled more accurately as <italic>&#981;</italic><sub><italic>u</italic></sub>. This distinction was necessary, because the two scales in Eqs <xref ref-type="disp-formula" rid="pone.0220889.e008">3</xref> and <xref ref-type="disp-formula" rid="pone.0220889.e009">4</xref> map to different number ranges. However, and this is the fourth extension, we need to consider a single scale which has both, an essential minimum and an essential maximum. To do so, consider a scale <italic>&#981;</italic> with range [<italic>&#981;</italic>(<italic>z</italic><sub><italic>l</italic></sub>), <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>)]. Then both Eqs <xref ref-type="disp-formula" rid="pone.0220889.e008">3</xref> and <xref ref-type="disp-formula" rid="pone.0220889.e009">4</xref> apply. We just change the labels: <italic>&#981;</italic><sub><italic>l</italic></sub> = <italic>&#981;</italic><sub><italic>u</italic></sub> = <italic>&#981;</italic>.</p>
<p>Fifth, a further simplification can be achieved by assuming that essential minima and essential maxima affect concatenation in an identical manner i.e. <italic>f</italic> = <italic>&#945;</italic><sub><italic>u</italic></sub> <italic>f</italic><sub><italic>u</italic></sub> = <italic>&#945;</italic><sub><italic>l</italic></sub> <italic>f</italic><sub><italic>l</italic></sub> = <italic>f</italic> for some positive constants <italic>&#945;</italic><sub><italic>l</italic></sub> and <italic>&#945;</italic><sub><italic>u</italic></sub>. Eqs <xref ref-type="disp-formula" rid="pone.0220889.e008">3</xref> and <xref ref-type="disp-formula" rid="pone.0220889.e009">4</xref> simplify respectively to:
<disp-formula id="pone.0220889.e010"><alternatives><graphic id="pone.0220889.e010g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e010" ns0:type="simple" /><ns1:math display="block" id="M10"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>u</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo> <ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>+</ns1:mo> <ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(5)</label></disp-formula> <disp-formula id="pone.0220889.e011"><alternatives><graphic id="pone.0220889.e011g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e011" ns0:type="simple" /><ns1:math display="block" id="M11"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>-</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>l</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo> <ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>-</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>+</ns1:mo> <ns1:mi>f</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>-</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(6)</label></disp-formula>
for all <italic>a</italic>, <italic>b</italic> &#8712; <italic>A</italic>. To simplify the notation, we introduced the function <inline-formula id="pone.0220889.e012"><alternatives><graphic id="pone.0220889.e012g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e012" ns0:type="simple" /><ns1:math display="inline" id="M12"><ns1:mrow><ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>x</ns1:mi> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:mi>x</ns1:mi> <ns1:mo>-</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac></ns1:mrow></ns1:math></alternatives></inline-formula>. This notation highlights that in terms of measurement <italic>&#981;</italic>, the operations &#8728;<sub><italic>l</italic></sub> and &#8728;<sub><italic>u</italic></sub> are symmetric around the line <italic>g</italic>[<italic>x</italic>] = 0.5. To illustrate this with an example, consider the popular choice <italic>f</italic><sub><italic>l</italic></sub>(<italic>x</italic>) = <italic>f</italic><sub><italic>u</italic></sub>(<italic>x</italic>) = <italic>f</italic>(<italic>x</italic>) = &#8722;log(1 &#8722; <italic>x</italic>) with <italic>x</italic> restricted to [0, 1]. This is a strictly increasing function to <inline-formula id="pone.0220889.e013"><alternatives><graphic id="pone.0220889.e013g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e013" ns0:type="simple" /><ns1:math display="inline" id="M13"><ns1:msup><ns1:mi mathvariant="double-struck">R</ns1:mi> <ns1:mo>+</ns1:mo></ns1:msup></ns1:math></alternatives></inline-formula> and hence provides a valid choice. The left panel in <xref ref-type="fig" rid="pone.0220889.g001">Fig 1</xref> shows <italic>f</italic>(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) = &#8722;log(<italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) and <italic>f</italic>(<italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) = &#8722;log(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) as a function of <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)] &#8712; [0, 1]. As noted, the two curves manifest symmetry around <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)] = 0.5</p>
<fig id="pone.0220889.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Examples of <italic>f</italic><sub><italic>u</italic></sub> and <italic>f</italic><sub><italic>l</italic></sub>.</title>
<p>The panels show functions <italic>f</italic><sub><italic>l</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>]) and <italic>f</italic><sub><italic>u</italic></sub>(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>]). In the left panel <italic>f</italic><sub><italic>l</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>]) = <italic>f</italic><sub><italic>u</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>]) = log <italic>g</italic>[<italic>&#981;</italic>] while in the right panel <italic>f</italic><sub><italic>l</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>]) = <italic>f</italic><sub><italic>u</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>]) = log(<italic>g</italic>[<italic>&#981;</italic>]/(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>])).</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g001" ns0:type="simple" />
</fig>
<p>Above, we assumed that <italic>&#981;</italic> is a ratio scale. As a final modification we consider the case when <italic>&#981;</italic> is an interval scale. The result for an interval scale and the corresponding difference structure is provided in chapter 4.4.2 in [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>]. The result is identical to <xref ref-type="disp-formula" rid="pone.0220889.e005">Eq 1</xref> except that <italic>f</italic> is a function to <inline-formula id="pone.0220889.e014"><alternatives><graphic id="pone.0220889.e014g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e014" ns0:type="simple" /><ns1:math display="inline" id="M14"><ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:math></alternatives></inline-formula> rather than to <inline-formula id="pone.0220889.e015"><alternatives><graphic id="pone.0220889.e015g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e015" ns0:type="simple" /><ns1:math display="inline" id="M15"><ns1:msup><ns1:mi mathvariant="double-struck">R</ns1:mi> <ns1:mo>+</ns1:mo></ns1:msup></ns1:math></alternatives></inline-formula> and that <italic>f</italic> is unique up to a linear transformation. Hence, if <italic>&#981;</italic> is an interval scale and &#8728;<sub><italic>l</italic></sub> = &#8728;<sub><italic>u</italic></sub> then <italic>f</italic> = <italic>&#945;</italic><sub><italic>u</italic></sub> <italic>f</italic><sub><italic>u</italic></sub> + <italic>&#946;</italic><sub><italic>u</italic></sub> = <italic>&#945;</italic><sub><italic>l</italic></sub> <italic>f</italic><sub><italic>l</italic></sub> + <italic>&#946;</italic><sub><italic>l</italic></sub> (<italic>&#945;</italic> &gt; 0 and <inline-formula id="pone.0220889.e016"><alternatives><graphic id="pone.0220889.e016g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e016" ns0:type="simple" /><ns1:math display="inline" id="M16"><ns1:mrow><ns1:mi>&#946;</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula>). Again, to provide an example of an interval scale with an essential maximum and an essential minimum, consider a case with logit function <italic>f</italic><sub><italic>l</italic></sub>(<italic>x</italic>) = <italic>f</italic><sub><italic>u</italic></sub>(<italic>x</italic>) = <italic>f</italic>(<italic>x</italic>) = log(<italic>x</italic>/(1 &#8722; <italic>x</italic>)). The right panel in figure shows <italic>f</italic>(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) and <italic>f</italic>(<italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)]) as a function of <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)] &#8712; [0, 1]. A logit function is a strictly increasing function from [0, 1] to <inline-formula id="pone.0220889.e017"><alternatives><graphic id="pone.0220889.e017g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e017" ns0:type="simple" /><ns1:math display="inline" id="M17"><ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:math></alternatives></inline-formula> and is hence valid model for difference structure with essential maximum and with essential minimum. The set of permissible transformations of <italic>f</italic> is given by <italic>f</italic>(<italic>x</italic>) = <italic>&#945;</italic> log(<italic>x</italic>/(1 &#8722; <italic>x</italic>)) + <italic>&#946;</italic>.</p>
</sec>
<sec id="sec006">
<title>1.1.2 Structure with Tobit maximum</title>
<p>The measurement structures discussed so far have the notable property that it&#8217;s not possible to obtain the maximal element by concatenation of two non-maximal elements. [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] note that &#8220;we do not know of any empirical structure in which the concatenation of two such elements is an essential maximum&#8221;. [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] (theorem 7 on p. 95-96) nevertheless provide the results for such a case, which we refer to as extensive structure with <italic>Tobit maximum</italic>. This measurement structure is implicit in the popular Tobit model which is sometimes discussed in connection with CFE and hence, we briefly present it. The scale <italic>&#981;</italic> must satisfy order monotonicity and monotonicity of concatenation when the concatenation result is not equal to the Tobit maximum. In the remaining case, i.e. when <italic>z</italic><sub><italic>u</italic></sub> &#8764; <italic>a</italic> &#8728; <italic>b</italic>, the concatenation is represented numerically as <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>) = inf(<italic>&#981;</italic>(<italic>a</italic>) + <italic>&#981;</italic>(<italic>b</italic>)) where inf is the infimum over all <italic>a</italic>, <italic>b</italic> &#8712; <italic>A</italic> which satisfy <italic>z</italic><sub><italic>u</italic></sub> &#8764; <italic>a</italic> &#8728; <italic>b</italic>. The scale <italic>&#981;</italic> is unique up to a multiplication by a positive constant. Extensions to extensive structures with Tobit minimum and to difference structures with Tobit maximum and/or minimum are straightforward and follow the rationale presented in the previous section.</p>
</sec>
<sec id="sec007">
<title>1.1.3 Random variables with CFE</title>
<p>The extensive and difference structures with essential minimum/maximum introduce a crucial aspect of CFE that was exemplified by the dictionary entry on the ceiling effect by [<xref ref-type="bibr" rid="pone.0220889.ref010">10</xref>]. Formally, we may interpret the &#8220;introduction of a new variable&#8221; that elevates the previous level of the variable as a concatenation with some other element. Then we may look at the difference between the new level <italic>f</italic><sup>&#8722;1</sup>(<italic>f</italic>(<italic>x</italic>) + <italic>f</italic>(<italic>h</italic>)) and the old level <italic>x</italic>. Notably, we get lim<sub><italic>x</italic>&#8594;1</sub>|<italic>f</italic><sup>&#8722;1</sup>(<italic>f</italic>(<italic>x</italic>) + <italic>f</italic>(<italic>h</italic>)) &#8722; <italic>x</italic>| = 0 (for <italic>h</italic> &#8800; 0), which may be seen as a formal notion of &#8220;bunching&#8221;. Crucially, measurement theory suggests that the concept of a boundary effect implicitly assumes the existence of a concatenation operation which has a non-additive numerical representation.</p>
<p>The measurement-theoretic account fits well with the description of CFE by [<xref ref-type="bibr" rid="pone.0220889.ref010">10</xref>]. It misses however the other highlighted aspects of CFE: the distributional properties of the measured variable such as the variance reduction or the increased skew. To formally approach the concept of reduced variation and the influence of CFE on the distribution of the measured values more generally, we need to introduce the concept of random variables (RVs). Recall, that scale <italic>&#981;</italic> maps from the set of empirical events to some interval. Instead, we consider <italic>&#981;</italic> to map from empirical events to a set of RVs over the same interval. We are not aware of work that explores such a probabilistic formulation of measurement theory. Nor do we wish to explore such an approach in detail in the current work. Our plan is to point out that the above-listed results from measurement theory along with few straight-forward assumptions about the probabilistic representation, allow us to derive most widely used probability distributions. Crucially, the derivation determines which parameters and under what transformation, represent the concatenation operation. This in turn allows us to specify and justify the choice of data generators used in the simulations and the choice of the metrics used to evaluate the performance on the simulated data.</p>
<p>When the scale maps to a set of RVs, constraints, such us <italic>&#981;</italic>(<italic>a</italic> &#8728; <italic>b</italic>) = <italic>&#981;</italic>(<italic>a</italic>) + <italic>&#981;</italic>(<italic>b</italic>), or <italic>a</italic> &#10927; <italic>b</italic> iff <italic>&#981;</italic>(<italic>a</italic>) &#8804; <italic>&#981;</italic>(<italic>b</italic>), are in general not sufficient to determine the distribution of <italic>&#981;</italic>. The first step is to formulate the constraints in terms of summaries of RVs. We choose the expected value E[<italic>X</italic>] as data summary. The expected value is linear in the sense that E[<italic>aX</italic> + <italic>b</italic>] = <italic>a</italic>E[<italic>X</italic>] + <italic>b</italic> and also E[<italic>X</italic>] + E[<italic>Y</italic>] = E[<italic>X</italic> + <italic>Y</italic>] (where <italic>X</italic>,<italic>Y</italic> are independent RVs and <italic>a</italic>, <italic>b</italic> are constants). Due to the linearity property, we view expected value as a data summary that is applicable to scales, which represent concatenation by addition. See chapter 2 in [<xref ref-type="bibr" rid="pone.0220889.ref014">14</xref>] and chapter 22 in [<xref ref-type="bibr" rid="pone.0220889.ref015">15</xref>] for similar views on the role of expectation in additive numerical representations.</p>
<p>As a consequence, we modify the constraint <italic>a</italic> &#10927; <italic>b</italic> iff <italic>&#981;</italic>(<italic>a</italic>) &#8804; <italic>&#981;</italic>(<italic>b</italic>) to <italic>a</italic> &#10927; <italic>b</italic> iff <italic>E</italic>[<italic>&#981;</italic>(<italic>a</italic>)] &#8804; <italic>E</italic>[<italic>&#981;</italic>(<italic>b</italic>)]. We modify the constraint <italic>&#981;</italic>(<italic>a</italic> &#8728; <italic>b</italic>) = <italic>&#981;</italic>(<italic>a</italic>) + <italic>&#981;</italic>(<italic>b</italic>) to <italic>E</italic>[<italic>&#981;</italic>(<italic>a</italic> &#8728; <italic>b</italic>)] = <italic>E</italic>[<italic>&#981;</italic>(<italic>a</italic>)] + <italic>E</italic>[<italic>&#981;</italic>(<italic>b</italic>)]. Effectively, the above constraints state that <italic>&#981;</italic> is a parametric distribution with a parameter equal to E[<italic>&#981;</italic>(<italic>a</italic>)] for each <italic>a</italic> &#8712; <italic>A</italic> and in which the parameter satisfies monotonicity, additivity, or some additional property required by the structure.</p>
<p>Above, we saw that in the presence of CFE, concatenation can&#8217;t be represented by addition. Instead, we apply the expectation to the values transformed with <italic>f</italic> which supports addition. For instance <xref ref-type="disp-formula" rid="pone.0220889.e008">Eq 3</xref> translates into
<disp-formula id="pone.0220889.e018"><alternatives><graphic id="pone.0220889.e018g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e018" ns0:type="simple" /><ns1:math display="block" id="M18"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mtext>E</ns1:mtext> <ns1:mo>[</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi><ns1:mspace width="4pt" /><ns1:msub><ns1:mo>&#8728;</ns1:mo> <ns1:mi>u</ns1:mi></ns1:msub><ns1:mspace width="4pt" /><ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>]</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:mtext>E</ns1:mtext> <ns1:mo>[</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr> <ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mo>+</ns1:mo> <ns1:mtext>E</ns1:mtext> <ns1:mo>[</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>(</ns1:mo> <ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>&#981;</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo> <ns1:mo>]</ns1:mo> <ns1:mo>.</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives> <label>(7)</label></disp-formula>
Thus, we require that the distribution is parametrized by <italic>c</italic><sub><italic>u</italic></sub> = E[(<italic>f</italic><sub><italic>u</italic></sub>(<italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)])] and/or <italic>c</italic><sub><italic>l</italic></sub> = E[(<italic>f</italic><sub><italic>l</italic></sub>(1 &#8722; <italic>g</italic>[<italic>&#981;</italic>(<italic>a</italic>)])] depending on whether the structure has an essential maximum, an essential minimum or both.</p>
<p>Consider again the dictionary descriptions of CFE. One may interpret these in terms of random variables as follows. With the repeated concatenation, the expected value of the measured values approaches the boundary. Furthermore, as it approaches the boundary, a concatenation of the equivalent object/event results in an increasingly smaller adjustment to the expected value. Finally, [<xref ref-type="bibr" rid="pone.0220889.ref011">11</xref>] stated that the variability decreases as the values approach boundary, which one may interpret as that the variance of the random variable approaches zero upon repeated concatenation.</p>
<p>Consider a random variable <italic>Y</italic>(<italic>c</italic><sub><italic>u</italic></sub>) &#8712; [<italic>y</italic><sub><italic>l</italic></sub>, <italic>y</italic><sub><italic>u</italic></sub>] with a ceiling effect at <italic>y</italic><sub><italic>u</italic></sub> and parameter <inline-formula id="pone.0220889.e019"><alternatives><graphic id="pone.0220889.e019g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e019" ns0:type="simple" /><ns1:math display="inline" id="M19"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mo>[</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>f</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="script">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula>. We may investigate whether the stated requirements are satisfied by checking whether the following formal conditions of a ceiling effect are true:</p>
<list list-type="order">
<list-item>
<p>
<inline-formula id="pone.0220889.e020">
<alternatives>
<graphic id="pone.0220889.e020g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e020" ns0:type="simple" />
<ns1:math display="inline" id="M20">
<ns1:mrow>
<ns1:msub>
<ns1:mrow>
<ns1:mtext>lim</ns1:mtext>
</ns1:mrow>
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>&#8594;</ns1:mo>
<ns1:mi>&#8734;</ns1:mi>
</ns1:mrow>
</ns1:msub>
<ns1:mtext>E</ns1:mtext>
<ns1:mo stretchy="false">[</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo stretchy="false">(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo stretchy="false">)</ns1:mo>
<ns1:mo stretchy="false">]</ns1:mo>
<ns1:mo>=</ns1:mo>
<ns1:msub>
<ns1:mi>y</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</p>
</list-item>
<list-item>
<p>
<inline-formula id="pone.0220889.e021">
<alternatives>
<graphic id="pone.0220889.e021g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e021" ns0:type="simple" />
<ns1:math display="inline" id="M21">
<ns1:mrow>
<ns1:msub>
<ns1:mrow>
<ns1:mtext>lim</ns1:mtext>
</ns1:mrow>
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>&#8594;</ns1:mo>
<ns1:mi>&#8734;</ns1:mi>
</ns1:mrow>
</ns1:msub>
<ns1:mtext>E</ns1:mtext>
<ns1:mo stretchy="false">[</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo stretchy="false">(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>+</ns1:mo>
<ns1:mi>x</ns1:mi>
<ns1:mo stretchy="false">)</ns1:mo>
<ns1:mo stretchy="false">]</ns1:mo>
<ns1:mo>&#8722;</ns1:mo>
<ns1:mtext>E</ns1:mtext>
<ns1:mo stretchy="false">[</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo stretchy="false">(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo stretchy="false">)</ns1:mo>
<ns1:mo stretchy="false">]</ns1:mo>
<ns1:mo>=</ns1:mo>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula> for every <italic>x</italic> &gt; 0</p>
</list-item>
<list-item>
<p>
<inline-formula id="pone.0220889.e022">
<alternatives>
<graphic id="pone.0220889.e022g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e022" ns0:type="simple" />
<ns1:math display="inline" id="M22">
<ns1:mrow>
<ns1:msub>
<ns1:mrow>
<ns1:mtext>lim</ns1:mtext>
</ns1:mrow>
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>&#8594;</ns1:mo>
<ns1:mi>&#8734;</ns1:mi>
</ns1:mrow>
</ns1:msub>
<ns1:mtext>Var</ns1:mtext>
<ns1:mo stretchy="false">[</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo stretchy="false">(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo stretchy="false">)</ns1:mo>
<ns1:mo stretchy="false">]</ns1:mo>
<ns1:mo>=</ns1:mo>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</p>
</list-item>
<list-item>
<p>
<inline-formula id="pone.0220889.e023">
<alternatives>
<graphic id="pone.0220889.e023g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e023" ns0:type="simple" />
<ns1:math display="inline" id="M23">
<ns1:mrow>
<ns1:msub>
<ns1:mrow>
<ns1:mtext>lim</ns1:mtext>
</ns1:mrow>
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>&#8594;</ns1:mo>
<ns1:mi>&#8734;</ns1:mi>
</ns1:mrow>
</ns1:msub>
<ns1:mtext>Skew</ns1:mtext>
<ns1:mo stretchy="false">[</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo stretchy="false">(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo stretchy="false">)</ns1:mo>
<ns1:mo stretchy="false">]</ns1:mo>
<ns1:mo>=</ns1:mo>
<ns1:mi>&#8734;</ns1:mi>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>.</p>
</list-item>
</list>
<p specific-use="continuation">Instead of condition 3 and 4, one may alternatively consider whether Var[<italic>Y</italic>(<italic>c</italic><sub><italic>u</italic></sub>)] and Skew[<italic>Y</italic>(<italic>c</italic><sub><italic>u</italic></sub>)] are respectively increasing and decreasing functions of <italic>c</italic><sub><italic>u</italic></sub>. <xref ref-type="disp-formula" rid="pone.0220889.e018">Eq 7</xref> implies the existence of series of random variables <italic>Y</italic>(<italic>c</italic><sub><italic>u</italic></sub>) that converge to <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>) as <italic>c</italic><sub><italic>u</italic></sub> &#8594; &#8734;. By dominated convergence theorem (chapter 9.2 in [<xref ref-type="bibr" rid="pone.0220889.ref016">16</xref>]) then the second condition holds but instead of the first condition we obtain <inline-formula id="pone.0220889.e024"><alternatives><graphic id="pone.0220889.e024g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e024" ns0:type="simple" /><ns1:math display="inline" id="M24"><ns1:mrow><ns1:msub><ns1:mrow><ns1:mtext>lim</ns1:mtext></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>&#8594;</ns1:mo> <ns1:mo>&#8722;</ns1:mo> <ns1:mi>&#8734;</ns1:mi></ns1:mrow></ns1:msub> <ns1:mtext>E</ns1:mtext> <ns1:mo stretchy="false">[</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo stretchy="false">(</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo stretchy="false">)</ns1:mo> <ns1:mo stretchy="false">]</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:mtext>E</ns1:mtext> <ns1:mo stretchy="false">[</ns1:mo> <ns1:mi>&#981;</ns1:mi> <ns1:mo stretchy="false">(</ns1:mo> <ns1:msub><ns1:mi>z</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo stretchy="false">)</ns1:mo> <ns1:mo stretchy="false">]</ns1:mo></ns1:mrow></ns1:math></alternatives></inline-formula>. By assuming E[<italic>&#981;</italic>(<italic>z</italic><sub><italic>l</italic></sub>)] = <italic>y</italic><sub><italic>l</italic></sub> one additionally obtains both, the first and the third condition. Indeed, the third condition is a direct consequence of the first condition. Analogous results follow for a variable with a floor effect at <italic>y</italic><sub><italic>l</italic></sub> with the limiting process <italic>c</italic><sub><italic>u</italic></sub> &#8594; &#8722;&#8734;. To conclude, the second condition follows immediately from the measurement-theoretic considerations, however to determine the remaining conditions one has to consider specific distributions of <italic>Y</italic> which we do next.</p>
</sec>
<sec id="sec008">
<title>1.1.4 Maximum entropy distributions with CFE</title>
<p>In this section we present an approach that allows us to derive probability distribution <italic>Y</italic>(<italic>c</italic><sub><italic>l</italic></sub>, <italic>c</italic><sub><italic>u</italic></sub>) given functions <italic>f</italic><sub><italic>l</italic></sub> and <italic>f</italic><sub><italic>u</italic></sub>. We adapt the principle of maximum entropy (POME, [<xref ref-type="bibr" rid="pone.0220889.ref017">17</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref019">19</xref>]) to obtain the probability distributions with the desired parametrization. According to POME, if nothing else is known about the distribution of <italic>Y</italic> except a set of <italic>N</italic> constraints of the form <italic>c</italic><sub><italic>i</italic></sub> = E[<italic>g</italic><sub><italic>i</italic></sub>(<italic>Y</italic>)] and that the domain of <italic>Y</italic> is [<italic>y</italic><sub><italic>l</italic></sub>, <italic>y</italic><sub><italic>u</italic></sub>] (and that it is a probability distribution, i.e. <inline-formula id="pone.0220889.e025"><alternatives><graphic id="pone.0220889.e025g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e025" ns0:type="simple" /><ns1:math display="inline" id="M25"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mo>&#8747;</ns1:mo> <ns1:mrow><ns1:msub><ns1:mi>y</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub></ns1:mrow> <ns1:msub><ns1:mi>y</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msubsup> <ns1:mi>p</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mi>y</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mtext>d</ns1:mtext> <ns1:mi>y</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mn>1</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>), then one should select a distribution that maximizes the entropy of the distribution subject to the stated constraints. Mathematically, this is achieved with the help of the calculus of variations ([<xref ref-type="bibr" rid="pone.0220889.ref020">20</xref>] chapter 12). The POME derivation results in a distribution with <italic>N</italic> parameters and the derivation fails if the constraints are inconsistent. The procedure is similar, but somewhat more general compared to the alternative method of deriving a parametric distribution that is member of the exponential family with the help of constraints ([for applications of this method see for instance [<xref ref-type="bibr" rid="pone.0220889.ref021">21</xref>]). POME allows to derive distributions that are not part of the exponential family. To mention some general examples, the uniform distribution is the maximum entropy distribution of RV on closed interval without any additional constraints. Normal distribution is the maximum entropy distribution of RV <italic>Y</italic> on real line with constraints <italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>] and <italic>c</italic><sub><italic>v</italic></sub> = E[(<italic>Y</italic> &#8722; <italic>c</italic><sub>1</sub>)<sup>2</sup>] ([<xref ref-type="bibr" rid="pone.0220889.ref019">19</xref>] section 3.1.1).</p>
<p><xref ref-type="table" rid="pone.0220889.t001">Table 1</xref> provides an overview of maximum entropy distributions found in the POME literature that are derived from constraints posed by structures with essential minimum and/or essential maximum and thus relevant in the current context. For more details on the derivation of the listed maximum entropy distributions see [<xref ref-type="bibr" rid="pone.0220889.ref019">19</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref022">22</xref>]. We make the following observations. First, the popular choice <italic>f</italic><sub><italic>u</italic></sub> = <italic>f</italic><sub><italic>l</italic></sub> = &#8722;log(1 &#8722; <italic>Y</italic>) translates into constraints <italic>c</italic><sub><italic>u</italic></sub> = E[log(1 &#8722; <italic>Y</italic>)] and <italic>c</italic><sub><italic>l</italic></sub> = E[log<italic>Y</italic>], which correspond to the logarithm of geometric mean of <italic>Y</italic> and of 1 &#8722; <italic>Y</italic> respectively. The sole exception in the table is the Logit-normal distribution which uses <italic>f</italic><sub><italic>u</italic></sub> = <italic>f</italic><sub><italic>l</italic></sub> = log(<italic>Y</italic>/(1 &#8722; <italic>Y</italic>)) to model CFE.</p>
<table-wrap id="pone.0220889.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.t001</object-id>
<label>Table 1</label>
<caption>
<title>Maximum entropy distributions derived from constraints posed by structures with essential minimum and/or essential maximum.</title>
</caption>
<alternatives>
<graphic id="pone.0220889.t001g" mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.t001" ns0:type="simple" />
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">distribution</th>
<th align="left" style="border-bottom:thick">range</th>
<th align="left" style="border-bottom:thick">constraint on <italic>c</italic><sub><italic>u</italic></sub> and <italic>c</italic><sub><italic>l</italic></sub></th>
<th align="left" style="border-bottom:thick">additional constraint</th>
<th align="left" style="border-bottom:thick"><italic>p</italic>(<italic>Y</italic> = <italic>y</italic>)</th>
<th align="left" style="border-bottom:thick">parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Beta</td>
<td align="left"><italic>Y</italic> &#8712; [0, 1]</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = E[log(1 &#8722; <italic>Y</italic>)]</td>
<td align="left" />
<td align="left"><italic>B</italic>(<italic>a</italic>, <italic>b</italic>)<sup>&#8722;1</sup> <italic>y</italic><sup><italic>a</italic></sup>(1 &#8722; <italic>y</italic>)<sup><italic>b</italic></sup></td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = <italic>&#968;</italic>(<italic>a</italic>) &#8722; <italic>&#968;</italic>(<italic>a</italic> + <italic>b</italic>)</td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left" />
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = <italic>&#968;</italic>(<italic>b</italic>) &#8722; <italic>&#968;</italic>(<italic>a</italic> + <italic>b</italic>)</td>
</tr>
<tr>
<td align="left">Logit-normal</td>
<td align="left"><italic>Y</italic> &#8712; [0, 1]</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = E[log(<italic>Y</italic>/(1 &#8722; <italic>Y</italic>))]</td>
<td align="left"><italic>c</italic><sub><italic>v</italic></sub> = Var[log(<italic>Y</italic>/(1 &#8722; <italic>Y</italic>))]</td>
<td align="left">
<inline-formula id="pone.0220889.e026">
<alternatives>
<graphic id="pone.0220889.e026g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e026" ns0:type="simple" />
<ns1:math display="inline" id="M26">
<ns1:mrow>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>v</ns1:mi>
</ns1:msub>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>-</ns1:mo>
<ns1:msup>
<ns1:mi>y</ns1:mi>
<ns1:mn>2</ns1:mn>
</ns1:msup>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:msqrt>
<ns1:mrow>
<ns1:mn>2</ns1:mn>
<ns1:mi>&#960;</ns1:mi>
</ns1:mrow>
</ns1:msqrt>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mrow>
<ns1:mo>-</ns1:mo>
<ns1:mn>1</ns1:mn>
</ns1:mrow>
</ns1:msup>
<ns1:mo>&#215;</ns1:mo>
</ns1:mrow>
<ns1:mrow>
<ns1:mspace width="2pt" />
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mo>(</ns1:mo>
<ns1:mo>-</ns1:mo>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mtext>log</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mrow>
<ns1:mo>[</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>/</ns1:mo>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mn>1</ns1:mn>
<ns1:mo>-</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mo>]</ns1:mo>
</ns1:mrow>
<ns1:mo>-</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mn>2</ns1:mn>
</ns1:msup>
<ns1:mo>/</ns1:mo>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:msqrt>
<ns1:mn>2</ns1:mn>
</ns1:msqrt>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>v</ns1:mi>
</ns1:msub>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mrow>
<ns1:mo>-</ns1:mo>
<ns1:mn>2</ns1:mn>
</ns1:mrow>
</ns1:msup>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = <italic>c</italic><sub><italic>l</italic></sub></td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>/(1 &#8722; <italic>Y</italic>))]</td>
<td align="left" />
<td align="left" />
<td align="left" />
</tr>
<tr>
<td align="left">Truncated Gamma</td>
<td align="left"><italic>Y</italic> &#8712; [0, 1]</td>
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left"><italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>]</td>
<td align="left">
<inline-formula id="pone.0220889.e027">
<alternatives>
<graphic id="pone.0220889.e027g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e027" ns0:type="simple" />
<ns1:math display="inline" id="M27">
<ns1:mrow>
<ns1:mfrac>
<ns1:mn>1</ns1:mn>
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:mfrac>
<ns1:mspace width="2pt" />
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mo>-</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:msup>
<ns1:mi>y</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:msup>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left">
<inline-formula id="pone.0220889.e029">
<alternatives>
<graphic id="pone.0220889.e029g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e029" ns0:type="simple" />
<ns1:math display="inline" id="M29">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>m</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:msubsup>
<ns1:mo>&#8747;</ns1:mo>
<ns1:mrow>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
<ns1:mn>1</ns1:mn>
</ns1:msubsup>
<ns1:mi>y</ns1:mi>
<ns1:mi>p</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo>=</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mi>d</ns1:mi>
<ns1:mi>y</ns1:mi>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick" />
<td align="left" style="border-bottom:thick" />
<td align="left" style="border-bottom:thick" />
<td align="left" style="border-bottom:thick" />
<td align="left" style="border-bottom:thick">
<inline-formula id="pone.0220889.e031">
<alternatives>
<graphic id="pone.0220889.e031g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e031" ns0:type="simple" />
<ns1:math display="inline" id="M31">
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mo>=</ns1:mo>
<ns1:msubsup>
<ns1:mo>&#8747;</ns1:mo>
<ns1:mrow>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
<ns1:mn>1</ns1:mn>
</ns1:msubsup>
<ns1:mspace width="2pt" />
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mo>-</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:msup>
<ns1:mi>y</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:msup>
<ns1:mi>d</ns1:mi>
<ns1:mi>y</ns1:mi>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left" style="border-bottom:thick">
<inline-formula id="pone.0220889.e032">
<alternatives>
<graphic id="pone.0220889.e032g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e032" ns0:type="simple" />
<ns1:math display="inline" id="M32">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:msubsup>
<ns1:mo>&#8747;</ns1:mo>
<ns1:mrow>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
<ns1:mn>1</ns1:mn>
</ns1:msubsup>
<ns1:mspace width="2pt" />
<ns1:mtext>log</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mi>y</ns1:mi>
<ns1:mi>p</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>Y</ns1:mi>
<ns1:mo>=</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mi>d</ns1:mi>
<ns1:mi>y</ns1:mi>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left">Generalized Gamma</td>
<td align="left"><italic>Y</italic> &#8712; [0, &#8734;]</td>
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left">
<inline-formula id="pone.0220889.e033">
<alternatives>
<graphic id="pone.0220889.e033g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e033" ns0:type="simple" />
<ns1:math display="inline" id="M33">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>m</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:mi mathvariant="normal">E</ns1:mi>
<ns1:mrow>
<ns1:mo>[</ns1:mo>
<ns1:msup>
<ns1:mi>Y</ns1:mi>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
</ns1:msup>
<ns1:mo>]</ns1:mo>
</ns1:mrow>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula> <italic>c</italic><sub><italic>n</italic></sub> &gt; 0</td>
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = log <italic>b</italic> + <italic>&#968;</italic>(<italic>a</italic>)/<italic>c</italic><sub><italic>n</italic></sub></td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left">
<inline-formula id="pone.0220889.e034">
<alternatives>
<graphic id="pone.0220889.e034g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e034" ns0:type="simple" />
<ns1:math display="inline" id="M34">
<ns1:mrow>
<ns1:mfrac>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
<ns1:mrow>
<ns1:mi>y</ns1:mi>
<ns1:mo>&#915;</ns1:mo>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:mfrac>
<ns1:mo>(</ns1:mo>
<ns1:mfrac>
<ns1:mi>y</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:mfrac>
<ns1:msup>
<ns1:mo>)</ns1:mo>
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
<ns1:mi>a</ns1:mi>
</ns1:mrow>
</ns1:msup>
<ns1:mspace width="2pt" />
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mo>(</ns1:mo>
<ns1:mo>-</ns1:mo>
<ns1:mo>(</ns1:mo>
<ns1:mfrac>
<ns1:mi>y</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:mfrac>
<ns1:msup>
<ns1:mo>)</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
</ns1:msup>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left">
<inline-formula id="pone.0220889.e035">
<alternatives>
<graphic id="pone.0220889.e035g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e035" ns0:type="simple" />
<ns1:math display="inline" id="M35">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>m</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:msup>
<ns1:mi>b</ns1:mi>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
</ns1:msup>
<ns1:mi>a</ns1:mi>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left">Beta Prime</td>
<td align="left"><italic>Y</italic> &#8712; [0, &#8734;]</td>
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left"><italic>c</italic><sub><italic>n</italic></sub> = E[log(1 + <italic>Y</italic>)]</td>
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = <italic>&#968;</italic>(<italic>a</italic>) &#8722; <italic>&#968;</italic>(<italic>b</italic>)</td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left"><italic>B</italic>(<italic>a</italic>, <italic>b</italic>)<sup>&#8722;1</sup> <italic>y</italic><sup><italic>a</italic>&#8722;1</sup>(1 + <italic>y</italic>)<sup>&#8722;<italic>a</italic>&#8722;<italic>b</italic></sup></td>
<td align="left"><italic>c</italic><sub><italic>n</italic></sub> = <italic>&#968;</italic>(<italic>a</italic> + <italic>b</italic>) &#8722; <italic>&#968;</italic>(<italic>b</italic>)</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick">Log-normal</td>
<td align="left" style="border-bottom:thick"><italic>Y</italic> &#8712; [0, &#8734;]</td>
<td align="left" style="border-bottom:thick"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left" style="border-bottom:thick"><italic>c</italic><sub><italic>v</italic></sub> = Var[log(<italic>Y</italic>)]</td>
<td align="left" style="border-bottom:thick">
<inline-formula id="pone.0220889.e036">
<alternatives>
<graphic id="pone.0220889.e036g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e036" ns0:type="simple" />
<ns1:math display="inline" id="M36">
<ns1:mrow>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>v</ns1:mi>
</ns1:msub>
<ns1:mi>y</ns1:mi>
<ns1:msqrt>
<ns1:mrow>
<ns1:mn>2</ns1:mn>
<ns1:mi>&#960;</ns1:mi>
</ns1:mrow>
</ns1:msqrt>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mrow>
<ns1:mo>-</ns1:mo>
<ns1:mn>1</ns1:mn>
</ns1:mrow>
</ns1:msup>
<ns1:mo>&#183;</ns1:mo>
<ns1:mspace width="2pt" />
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mo>(</ns1:mo>
<ns1:mo>-</ns1:mo>
<ns1:mfrac>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mtext>log</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mi>y</ns1:mi>
<ns1:mo>-</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
</ns1:msub>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mn>2</ns1:mn>
</ns1:msup>
<ns1:mrow>
<ns1:mn>2</ns1:mn>
<ns1:msubsup>
<ns1:mi>c</ns1:mi>
<ns1:mi>v</ns1:mi>
<ns1:mn>2</ns1:mn>
</ns1:msubsup>
</ns1:mrow>
</ns1:mfrac>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left" style="border-bottom:thick" />
</tr>
<tr>
<td align="left">Generalized Geometric</td>
<td align="left"><italic>Y</italic> &#8712; {0, 1, &#8230;, &#8734;}</td>
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left"><italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>]</td>
<td align="left"><italic>D</italic>(<italic>a</italic>, <italic>b</italic>)<sup>&#8722;1</sup><italic>a</italic><sup><italic>y</italic></sup> <italic>y</italic><sup><italic>b</italic></sup></td>
<td align="left">
<inline-formula id="pone.0220889.e037">
<alternatives>
<graphic id="pone.0220889.e037g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e037" ns0:type="simple" />
<ns1:math display="inline" id="M37">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mfrac>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>D</ns1:mi>
</ns1:mrow>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:mrow>
</ns1:mfrac>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left" />
<td align="left">
<inline-formula id="pone.0220889.e038">
<alternatives>
<graphic id="pone.0220889.e038g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e038" ns0:type="simple" />
<ns1:math display="inline" id="M38">
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mo>=</ns1:mo>
<ns1:msubsup>
<ns1:mo>&#8721;</ns1:mo>
<ns1:mrow>
<ns1:mi>y</ns1:mi>
<ns1:mo>=</ns1:mo>
<ns1:mn>0</ns1:mn>
</ns1:mrow>
<ns1:mi>&#8734;</ns1:mi>
</ns1:msubsup>
<ns1:msup>
<ns1:mi>a</ns1:mi>
<ns1:mi>y</ns1:mi>
</ns1:msup>
<ns1:msup>
<ns1:mi>y</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:msup>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left">
<inline-formula id="pone.0220889.e039">
<alternatives>
<graphic id="pone.0220889.e039g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e039" ns0:type="simple" />
<ns1:math display="inline" id="M39">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>m</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:mfrac>
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>+</ns1:mo>
<ns1:mn>1</ns1:mn>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:mfrac>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left">Discrete Beta</td>
<td align="left"><italic>Y</italic> &#8712; {0, 1, &#8230;, <italic>c</italic><sub><italic>n</italic></sub>}</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = E[log(1 &#8722; <italic>Y</italic>)]</td>
<td align="left" />
<td align="left"><italic>D</italic>(<italic>a</italic>, <italic>b</italic>)<sup>&#8722;1</sup><italic>y</italic><sup><italic>a</italic></sup>(1 &#8722; <italic>y</italic>)<sup><italic>b</italic></sup></td>
<td align="left">
<inline-formula id="pone.0220889.e040">
<alternatives>
<graphic id="pone.0220889.e040g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e040" ns0:type="simple" />
<ns1:math display="inline" id="M40">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>u</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mfrac>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>D</ns1:mi>
</ns1:mrow>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>a</ns1:mi>
</ns1:mrow>
</ns1:mfrac>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]</td>
<td align="left" />
<td align="left">
<inline-formula id="pone.0220889.e041">
<alternatives>
<graphic id="pone.0220889.e041g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e041" ns0:type="simple" />
<ns1:math display="inline" id="M41">
<ns1:mrow>
<ns1:mi>D</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mo>=</ns1:mo>
<ns1:msubsup>
<ns1:mo>&#8721;</ns1:mo>
<ns1:mrow>
<ns1:mi>y</ns1:mi>
<ns1:mo>=</ns1:mo>
<ns1:mn>1</ns1:mn>
</ns1:mrow>
<ns1:mi>&#8734;</ns1:mi>
</ns1:msubsup>
<ns1:msup>
<ns1:mi>y</ns1:mi>
<ns1:mi>a</ns1:mi>
</ns1:msup>
<ns1:msup>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mn>1</ns1:mn>
<ns1:mo>-</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mi>b</ns1:mi>
</ns1:msup>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left">
<inline-formula id="pone.0220889.e042">
<alternatives>
<graphic id="pone.0220889.e042g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e042" ns0:type="simple" />
<ns1:math display="inline" id="M42">
<ns1:mrow>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
</ns1:msub>
<ns1:mo>=</ns1:mo>
<ns1:mtext>exp</ns1:mtext>
<ns1:mspace width="2pt" />
<ns1:mfrac>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>D</ns1:mi>
</ns1:mrow>
<ns1:mrow>
<ns1:mi>&#8706;</ns1:mi>
<ns1:mi>b</ns1:mi>
</ns1:mrow>
</ns1:mfrac>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left">Beta-binomial</td>
<td align="left"><italic>Y</italic> &#8712; {0, 1, &#8230;, <italic>c</italic><sub><italic>n</italic></sub>}</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = E[log(1 &#8722; <italic>Q</italic>)]</td>
<td align="left">E[<italic>Y</italic>] = <italic>q</italic></td>
<td align="left">
<inline-formula id="pone.0220889.e043">
<alternatives>
<graphic id="pone.0220889.e043g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e043" ns0:type="simple" />
<ns1:math display="inline" id="M43">
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mfrac linethickness="0pt">
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
<ns1:mi>y</ns1:mi>
</ns1:mfrac>
<ns1:mo>)</ns1:mo>
<ns1:mi>B</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>+</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:msub>
<ns1:mi>c</ns1:mi>
<ns1:mi>n</ns1:mi>
</ns1:msub>
<ns1:mo>-</ns1:mo>
<ns1:mi>y</ns1:mi>
<ns1:mo>+</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
<ns1:mo>/</ns1:mo>
<ns1:mi>B</ns1:mi>
<ns1:mrow>
<ns1:mo>(</ns1:mo>
<ns1:mi>a</ns1:mi>
<ns1:mo>,</ns1:mo>
<ns1:mi>b</ns1:mi>
<ns1:mo>)</ns1:mo>
</ns1:mrow>
</ns1:mrow>
</ns1:math>
</alternatives>
</inline-formula>
</td>
<td align="left"><italic>c</italic><sub><italic>u</italic></sub> = <italic>&#968;</italic>(<italic>a</italic>) &#8722; <italic>&#968;</italic>(<italic>a</italic> + <italic>b</italic>)</td>
</tr>
<tr>
<td align="left" />
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Q</italic>)]</td>
<td align="left"><italic>q</italic> &#8764; Beta(<italic>a</italic>, <italic>b</italic>)</td>
<td align="left" />
<td align="left"><italic>c</italic><sub><italic>l</italic></sub> = <italic>&#968;</italic>(<italic>b</italic>) &#8722; <italic>&#968;</italic>(<italic>a</italic> + <italic>b</italic>)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001">
<p>PDF&#8212;probability density function. <italic>B</italic> is beta function. <italic>&#968;</italic> is Digamma function.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Second, the maximum entropy distributions include large portion of the most popular distributions on [0, 1] and [0, &#8734;]. Exponential, Weibull, Gamma, F, Log-logistic or Power function distribution are included by Generalized Gamma family, by Beta Prime distribution or both [<xref ref-type="bibr" rid="pone.0220889.ref023">23</xref>]. A generalized version of the Beta prime distribution can be obtained with a constraint <inline-formula id="pone.0220889.e044"><alternatives><graphic id="pone.0220889.e044g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e044" ns0:type="simple" /><ns1:math display="inline" id="M44"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>m</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>+</ns1:mo> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula>. [<xref ref-type="bibr" rid="pone.0220889.ref022">22</xref>] went further and showed that a maximum entropy distribution with constraints <italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)] and <inline-formula id="pone.0220889.e045"><alternatives><graphic id="pone.0220889.e045g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e045" ns0:type="simple" /><ns1:math display="inline" id="M45"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>m</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>p</ns1:mi></ns1:msub> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>/</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>p</ns1:mi></ns1:msub> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> includes the Generalized Gamma family (for <italic>c</italic><sub><italic>p</italic></sub> &#8594; 0) and the generalized Beta Prime family (<italic>c</italic><sub><italic>p</italic></sub> = 1). While [<xref ref-type="bibr" rid="pone.0220889.ref022">22</xref>] don&#8217;t consider the case <italic>c</italic><sub><italic>p</italic></sub> = &#8722;1, it is straightforward to see that assuming <inline-formula id="pone.0220889.e046"><alternatives><graphic id="pone.0220889.e046g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e046" ns0:type="simple" /><ns1:math display="inline" id="M46"><ns1:mrow><ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>&#8712;</ns1:mo> <ns1:mo>[</ns1:mo> <ns1:mn>0</ns1:mn> <ns1:mo>,</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:math></alternatives></inline-formula> results in a generalized form of Beta distribution. The resulting distributions and the relations between them are discussed in more detail by [<xref ref-type="bibr" rid="pone.0220889.ref023">23</xref>].</p>
<p>Third, the parameters <italic>c</italic><sub><italic>v</italic></sub> may be interpreted as variance parameters, or more generally as constraints that introduce a distance metric. Notably, the variance is formulated over <italic>f</italic>(<italic>Y</italic>). Thus while <italic>c</italic><sub><italic>l</italic></sub> can be respectively interpreted as expected log-odds or logarithm of geometric mean, <italic>c</italic><sub><italic>v</italic></sub> can be interpreted as log-odds variance or geometric variance. Introduction of these parameters is consistent with the measurement theoretic framework, except that the constraints are expressed in terms of variance <italic>c</italic><sub><italic>v</italic></sub> = Var[<italic>f</italic>(<italic>Y</italic>)] rather than in terms of expectation <italic>c</italic><sub><italic>l</italic></sub> = E[<italic>f</italic>(<italic>Y</italic>)].</p>
<p>Fourth, the interpretation of the <italic>c</italic><sub><italic>m</italic></sub> parameters is interesting as well. One possibility is to view <italic>c</italic><sub><italic>m</italic></sub> as an additional constraint unrelated to CFE. As [<xref ref-type="bibr" rid="pone.0220889.ref024">24</xref>] discuss in the case of gamma distribution, the parameter <italic>c</italic><sub><italic>l</italic></sub> controls the generation of small values while <italic>c</italic><sub><italic>m</italic></sub> controls the generation of large values. This interpretation is similar to the interpretation of <italic>c</italic><sub><italic>l</italic></sub> and <italic>c</italic><sub><italic>u</italic></sub> of beta distribution even though there is no essential maximum in the former case as opposed to the latter case.</p>
<p>Fifth, one may illustrate the similarity between <italic>c</italic><sub><italic>u</italic></sub> of Beta and <italic>c</italic><sub><italic>m</italic></sub> of Gamma distribution in one additional way. Consider a generalization of Beta distribution with a scaling parameter <italic>b</italic> = <italic>&#981;</italic>(<italic>z</italic><sub><italic>u</italic></sub>) such that <italic>Y</italic> &#8712; [0, <italic>b</italic>]. As detailed in [<xref ref-type="bibr" rid="pone.0220889.ref023">23</xref>] Gamma and some other distributions can be obtained from a generalized Beta by constructing the limit <italic>b</italic> &#8594; &#8734;. The parameter <italic>c</italic><sub><italic>u</italic></sub> of Beta translates into <italic>c</italic><sub><italic>m</italic></sub> of Gamma.</p>
<p>Sixth, it&#8217;s possible for two notationally distinct constraints to result in the same probability distribution, albeit with different parametrization. For instance, constraints <inline-formula id="pone.0220889.e047"><alternatives><graphic id="pone.0220889.e047g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e047" ns0:type="simple" /><ns1:math display="inline" id="M47"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msubsup><ns1:mi>Y</ns1:mi> <ns1:mi>n</ns1:mi> <ns1:mi>c</ns1:mi></ns1:msubsup> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> and <inline-formula id="pone.0220889.e048"><alternatives><graphic id="pone.0220889.e048g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e048" ns0:type="simple" /><ns1:math display="inline" id="M48"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>m</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> imply a Generalized Gamma distribution with a somewhat different parametrization than that of the Generalized Gamma distribution listed in the table: <italic>c</italic><sub><italic>l</italic></sub> = <italic>c</italic><sub><italic>n</italic></sub> log <italic>b</italic> + <italic>&#968;</italic>(<italic>a</italic>).</p>
<p>Seventh, recall that <italic>f</italic><sub><italic>l</italic></sub> and <italic>f</italic><sub><italic>u</italic></sub> are defined up to a scaling constant (extensive structure) or up to linear transformation (difference structure). As a consequence <italic>c</italic><sub><italic>l</italic></sub> and <italic>c</italic><sub><italic>u</italic></sub> are known up to a scale or up to a linear transformation, i.e. <italic>c</italic><sub><italic>l</italic></sub> = <italic>&#946;</italic><sub><italic>l</italic></sub> + <italic>&#945;</italic><sub><italic>l</italic></sub>E[<italic>f</italic><sub><italic>l</italic></sub>(<italic>Y</italic>)]. In similar manner, one may modify the constraints <italic>c</italic><sub><italic>u</italic></sub> or even <italic>c</italic><sub><italic>m</italic></sub> so that the set of permissible transformations of <italic>f</italic> is explicit. <italic>&#945;</italic> and <italic>&#946;</italic> are not identifiable in addition to <italic>c</italic><sub><italic>l</italic></sub> and their introduction does not affect the derivation of maximum entropy distribution. Nevertheless, it may be possible to parametrize the distribution with <italic>&#945;</italic> and/or <italic>&#946;</italic> instead of some nuisance parameter. Consider the Generalized Gamma distribution with constraints <inline-formula id="pone.0220889.e049"><alternatives><graphic id="pone.0220889.e049g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e049" ns0:type="simple" /><ns1:math display="inline" id="M49"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> and <inline-formula id="pone.0220889.e050"><alternatives><graphic id="pone.0220889.e050g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e050" ns0:type="simple" /><ns1:math display="inline" id="M50"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>m</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mi mathvariant="normal">E</ns1:mi> <ns1:mrow><ns1:mo>[</ns1:mo> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula>. Note that we may introduce transform <italic>c</italic><sub><italic>l</italic></sub> = <italic>c</italic><sub><italic>n</italic></sub>E[log(<italic>Y</italic>)] so that <italic>c</italic><sub><italic>n</italic></sub> can be interpreted as the scale/unit of <italic>c</italic><sub><italic>l</italic></sub>. Finally, one may sacrifice parameter <italic>c</italic><sub><italic>m</italic></sub> and introduce shift parameter, say <italic>c</italic><sub><italic>&#946;</italic></sub> such that <italic>c</italic><sub><italic>l</italic></sub> = <italic>c</italic><sub><italic>&#946;</italic></sub> + <italic>c</italic><sub><italic>n</italic></sub>E[log(<italic>Y</italic>)]. From the formula for <italic>c</italic><sub><italic>l</italic></sub> from <xref ref-type="table" rid="pone.0220889.t001">Table 1</xref> it follows that <italic>c</italic><sub><italic>&#946;</italic></sub> = <italic>c</italic><sub><italic>n</italic></sub> log <italic>b</italic> = log <italic>c</italic><sub><italic>m</italic></sub> &#8722; log <italic>a</italic>.</p>
<p>Eighth, as illustrated with the case of truncated gamma distribution, it is straightforward to introduce a maximum of the distribution while maintaining the floor effect. Note though that the maximum thus introduced is not an essential maximum and the process of truncation can&#8217;t be used to introduce CFE. This can be perhaps best seen on the case of truncated normal distribution with range [0, &#8734;] which does not satisfy the CFE conditions listed in the previous section.</p>
<p>Finally, it is straightforward to apply the above ideas to discrete measurement. While the values of <italic>Y</italic> are discrete, the values E[<italic>f</italic>(<italic>Y</italic>)], that are part of the constraints, are continuous. Maximum entropy derivation provides analogous results to continuous distributions. Constraints <italic>c</italic><sub><italic>l</italic></sub> = E[log<italic>Y</italic>] and <italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>] with <italic>Y</italic> &#8712; {0, 1, &#8230;} lead to generalized geometric distribution ([<xref ref-type="bibr" rid="pone.0220889.ref019">19</xref>] section 2.1d). Constraints <italic>c</italic><sub><italic>l</italic></sub> = E[log <italic>Y</italic>] and <italic>c</italic><sub><italic>m</italic></sub> = E[log(1 &#8722; <italic>Y</italic>)] result in a discrete version of Beta distribution with <italic>Y</italic> &#8712; {0, 1/<italic>n</italic>, 2/<italic>n</italic>, &#8230;, (<italic>n</italic> &#8722; 1)/<italic>n</italic>, 1} and <inline-formula id="pone.0220889.e051"><alternatives><graphic id="pone.0220889.e051g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e051" ns0:type="simple" /><ns1:math display="inline" id="M51"><ns1:mrow><ns1:mi>n</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">N</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula>. Discrete Beta distribution is seldom used in applied work, perhaps due to the fact that <italic>p</italic>(<italic>Y</italic> = 0) = <italic>p</italic>(<italic>Y</italic> = 1) = 0. As a more popular and more plausible alternative we included the Beta-binomial distribution, which can be obtained by sampling <italic>q</italic> from Beta distribution parametrized by <italic>c</italic><sub><italic>l</italic></sub> and <italic>c</italic><sub><italic>u</italic></sub> and <italic>y</italic> &#8712; 0, 1, &#8230;, <italic>n</italic> is then sampled from Binomial distribution with proportion parameter <italic>q</italic> and <inline-formula id="pone.0220889.e052"><alternatives><graphic id="pone.0220889.e052g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e052" ns0:type="simple" /><ns1:math display="inline" id="M52"><ns1:mrow><ns1:mi>n</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">N</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula>. As described in [<xref ref-type="bibr" rid="pone.0220889.ref025">25</xref>], binomial distribution can be seen as a maximum entropy distribution with E[<italic>Y</italic>] = <italic>q</italic> and with additional assumptions about the discretization process.</p>
<p>Having presented the maximum entropy distributions, we now consider to what extent these satisfy the informal CFE conditions. As already mentioned, the second CFE condition is incorporated as an assumption in the derivation of the maximum entropy distributions, but the remaining three conditions must be checked separately. In principle, such task is in exercise of looking up the formula for expectation, variance or skew and then computing the limit. Unfortunately, the analytic formulas for these quantities are either not known or do not exist (Generalized Gamma, Log-logistic) or the available formulas do not use the current parametrization (Beta, Beta prime, Beta-binomial, Generalized geometric). As a consequence only few results are readily available and are discussed next. The remaining results are obtained through simulation and presented in section 3.9.</p>
<p>In the case of Log-normal distribution, the first and the third condition are satisfied while the skew is independent of <italic>c</italic><sub><italic>l</italic></sub>. In the case of Beta distribution we set <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8734; while <italic>c</italic><sub><italic>u</italic></sub> is held constant (and vice versa). As a consequence <italic>c</italic><sub><italic>l</italic></sub> &#8722; <italic>c</italic><sub><italic>u</italic></sub> = <italic>&#968;</italic>(<italic>a</italic>) &#8722; <italic>&#968;</italic>((1/E[<italic>Y</italic>] &#8722; 1)<italic>a</italic>) &#8594; &#8734;. Since <italic>&#968;</italic> is increasing and convex, <italic>c</italic><sub><italic>l</italic></sub> &#8722; <italic>c</italic><sub><italic>u</italic></sub> &#8594; &#8734; when E[<italic>Y</italic>] &#8594; 0 or both <italic>a</italic> &#8594; 0 and <italic>b</italic> &#8594; 0. In the latter case, however <italic>c</italic><sub><italic>u</italic></sub> &#8594; &#8734; which is in contradiction with our assumptions and hence only the former case is valid. Thus, the first condition is satisfied by Beta distribution.</p>
<p>Regarding Generalized Gamma distribution, note that the result depends on the choice of nuisance parameters. Trivially, if we hold <italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>] constant, then <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8722;&#8734; will not affect the expected value. Instead, we propose to hold <italic>c</italic><sub><italic>n</italic></sub> and <italic>c</italic><sub><italic>n</italic></sub> log <italic>b</italic> constant, where the latter term may be conceived as the offset of <italic>c</italic><sub><italic>l</italic></sub>. Then <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8722;&#8734; implies, <italic>&#968;</italic>(<italic>a</italic>) &#8594; &#8722;&#8734;, hence <italic>a</italic> &#8594; 0 and as a consequence E[<italic>Y</italic>] = exp(<italic>c</italic><sub><italic>n</italic></sub> log <italic>b</italic>)<italic>a</italic> &#8594; 0. The first condition is satisfied by Generalized Gamma distribution distribution.</p>
</sec>
<sec id="sec009">
<title>1.1.5 Additional distributions with CFE</title>
<p>We discuss two additional distributions that are popular in the literature, that mostly satisfy the CFE conditions and that offer a plausible connection to measurement theory, yet their maximum entropy derivation is not available in the literature.</p>
<p>Boundary hitting times of Brownian motion and its extensions are popular models of response times and response choice in psychology [<xref ref-type="bibr" rid="pone.0220889.ref026">26</xref>]. Wald distribution describes the first boundary hitting time of a one dimensional Wiener Process with one boundary located at distance <italic>a</italic> &gt; 0 from the starting position of the particle, which moves with a drift <italic>b</italic> &gt; 0 and a diffusion rate <italic>s</italic> &gt; 0. The probability density function of the hitting time is
<disp-formula id="pone.0220889.e053"><alternatives><graphic id="pone.0220889.e053g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e053" ns0:type="simple" /><ns1:math display="block" id="M53"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mi>p</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mi>y</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo> <ns1:mfrac><ns1:mi>a</ns1:mi> <ns1:mrow><ns1:mi>s</ns1:mi> <ns1:msqrt><ns1:mrow><ns1:mn>2</ns1:mn> <ns1:mi>&#960;</ns1:mi> <ns1:msup><ns1:mi>y</ns1:mi> <ns1:mn>3</ns1:mn></ns1:msup></ns1:mrow></ns1:msqrt></ns1:mrow></ns1:mfrac><ns1:mspace width="2pt" /><ns1:mtext>exp</ns1:mtext><ns1:mspace width="2pt" /><ns1:mo>(</ns1:mo> <ns1:mo>-</ns1:mo> <ns1:mfrac><ns1:msup><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>b</ns1:mi> <ns1:mi>y</ns1:mi> <ns1:mo>-</ns1:mo> <ns1:mi>a</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mn>2</ns1:mn></ns1:msup> <ns1:mrow><ns1:mn>2</ns1:mn> <ns1:msup><ns1:mi>s</ns1:mi> <ns1:mn>2</ns1:mn></ns1:msup> <ns1:mi>y</ns1:mi></ns1:mrow></ns1:mfrac> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives></disp-formula>
All three parameters are not identifiable. The common choice in the psychological literature is to fix <italic>s</italic> = 1 [<xref ref-type="bibr" rid="pone.0220889.ref026">26</xref>], although we prefer <italic>a</italic> = 1 because <italic>s</italic> and <italic>b</italic> are independent while <italic>a</italic> on <italic>b</italic> are not. The concatenation can be numerically represented by addition of positive quantities to <italic>b</italic> while holding <italic>s</italic> constant. The increments to <italic>b</italic> increase the speed of the particle and result in a faster response.</p>
<p>A more recent approach by [<xref ref-type="bibr" rid="pone.0220889.ref027">27</xref>] at conceptualization of maximum velocity, considers the conjoint structure of velocity, duration and distance. Such conjoint structure is inherent in the process definition of Wald distribution, which suggests a possible measure-theoretic derivation of the Wald distribution. We are not aware of such derivation in the literature and we limit this section to checking whether Wald distribution satisfies the CFE conditions. The expected value, variance and skewness of Wald distribution are 1/<italic>b</italic>, <italic>s</italic><sup>2</sup>/<italic>b</italic><sup>3</sup> and <inline-formula id="pone.0220889.e054"><alternatives><graphic id="pone.0220889.e054g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e054" ns0:type="simple" /><ns1:math display="inline" id="M54"><ns1:mrow><ns1:mn>3</ns1:mn> <ns1:mi>s</ns1:mi> <ns1:mo>/</ns1:mo> <ns1:msqrt><ns1:mi>b</ns1:mi></ns1:msqrt></ns1:mrow></ns1:math></alternatives></inline-formula>. All three quantities converge to zero for <italic>b</italic> &#8594; &#8734; and thus Wald distribution satisfies all four CFE conditions.</p>
<p>Two additional popular models for <italic>Y</italic> &#8712; {0, 1, &#8230;, <italic>N</italic>} are the Polytomous Rasch model and Ordered logistic regression. Polytomous Rasch model is defined by
<disp-formula id="pone.0220889.e055"><alternatives><graphic id="pone.0220889.e055g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e055" ns0:type="simple" /><ns1:math display="block" id="M55"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mi>p</ns1:mi> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mi>y</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mo>=</ns1:mo><ns1:mspace width="2pt" /><ns1:mfrac><ns1:mrow><ns1:mtext>exp</ns1:mtext><ns1:mspace width="2pt" /><ns1:msubsup><ns1:mo>&#8721;</ns1:mo> <ns1:mrow><ns1:mi>k</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mn>1</ns1:mn></ns1:mrow> <ns1:mi>y</ns1:mi></ns1:msubsup> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:msubsup><ns1:mo>&#8721;</ns1:mo> <ns1:mrow><ns1:mi>j</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mn>0</ns1:mn></ns1:mrow> <ns1:mi>N</ns1:mi></ns1:msubsup><ns1:mspace width="2pt" /><ns1:mtext>exp</ns1:mtext><ns1:mspace width="2pt" /><ns1:msubsup><ns1:mo>&#8721;</ns1:mo> <ns1:mrow><ns1:mi>k</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mn>1</ns1:mn></ns1:mrow> <ns1:mi>j</ns1:mi></ns1:msubsup> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives></disp-formula>
where <italic>c</italic><sub><italic>u</italic></sub> = &#8722;<italic>c</italic><sub><italic>l</italic></sub> represents concatenation and <inline-formula id="pone.0220889.e056"><alternatives><graphic id="pone.0220889.e056g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e056" ns0:type="simple" /><ns1:math display="inline" id="M56"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> are threshold weights. [<xref ref-type="bibr" rid="pone.0220889.ref028">28</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref029">29</xref>] show that Polytomous Rasch model presents an extension of Boltzmann distribution and they use Boltzmann&#8217;s method of maximum probability distribution in their derivation. [<xref ref-type="bibr" rid="pone.0220889.ref019">19</xref>] (chapter 9) shows that this method provides identical results as POME. [<xref ref-type="bibr" rid="pone.0220889.ref018">18</xref>] (see section 10.5) provides POME derivation of the case <italic>N</italic> = 3. All these derivations utilize the constraint <italic>c</italic><sub><italic>m</italic></sub> = E[<italic>Y</italic>], even though a parametrization in terms of <italic>c</italic><sub><italic>m</italic></sub> is rarely used in the applied research. In any case, with <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8722;&#8734; and <italic>c</italic><sub><italic>k</italic></sub> constant, <italic>p</italic>(<italic>Y</italic> = 0) &#8594; 1 and hence E[<italic>Y</italic>] = <italic>c</italic><sub><italic>m</italic></sub> &#8594; 0 and Var[<italic>Y</italic>] &#8594; 0. The Rasch model thus satisfies the first three CFE conditions.</p>
<p>Another, different parametrization of Rasch model is available in the literature under the label <italic>ordered logistic regression</italic> and can be formulated as a latent variable model ([<xref ref-type="bibr" rid="pone.0220889.ref030">30</xref>], p. 120):
<disp-formula id="pone.0220889.e057"><alternatives><graphic id="pone.0220889.e057g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e057" ns0:type="simple" /><ns1:math display="block" id="M57"><ns1:mtable displaystyle="true"><ns1:mtr><ns1:mtd columnalign="right"><ns1:mrow><ns1:mi>y</ns1:mi> <ns1:mo>=</ns1:mo> <ns1:mi>n</ns1:mi><ns1:mspace width="2pt" /><ns1:mtext>iff</ns1:mtext><ns1:mspace width="2pt" /><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mrow><ns1:mi>n</ns1:mi> <ns1:mo>-</ns1:mo> <ns1:mn>1</ns1:mn></ns1:mrow></ns1:msub> <ns1:mo>&gt;</ns1:mo> <ns1:mi>z</ns1:mi> <ns1:mo>&gt;</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:math></alternatives></disp-formula>
with latent variable <inline-formula id="pone.0220889.e058"><alternatives><graphic id="pone.0220889.e058g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e058" ns0:type="simple" /><ns1:math display="inline" id="M58"><ns1:mrow><ns1:mi>z</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> generated from the logistic distribution <italic>z</italic> &#8764; Logistic(<italic>c</italic><sub><italic>u</italic></sub>, <italic>c</italic><sub><italic>v</italic></sub>) and thresholds <inline-formula id="pone.0220889.e059"><alternatives><graphic id="pone.0220889.e059g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e059" ns0:type="simple" /><ns1:math display="inline" id="M59"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> for <italic>k</italic> &#8712; {0, 1, &#8230;, <italic>N</italic>}. The parameters <italic>c</italic><sub><italic>u</italic></sub> = &#8722;<italic>c</italic><sub><italic>l</italic></sub> provide an opportunity to manipulate the CFE. In particular <inline-formula id="pone.0220889.e060"><alternatives><graphic id="pone.0220889.e060g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e060" ns0:type="simple" /><ns1:math display="inline" id="M60"><ns1:mrow><ns1:msub><ns1:mrow><ns1:mtext>lim</ns1:mtext></ns1:mrow> <ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>&#8594;</ns1:mo> <ns1:mi>&#8734;</ns1:mi></ns1:mrow></ns1:msub> <ns1:mtext>E</ns1:mtext> <ns1:mo stretchy="false">[</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo stretchy="false">]</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:mn>0</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula> and <inline-formula id="pone.0220889.e061"><alternatives><graphic id="pone.0220889.e061g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e061" ns0:type="simple" /><ns1:math display="inline" id="M61"><ns1:msub><ns1:mtext>lim</ns1:mtext> <ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>&#8594;</ns1:mo> <ns1:mo>&#8722;</ns1:mo> <ns1:mi>&#8734;</ns1:mi></ns1:mrow></ns1:msub> <ns1:mtext>Var</ns1:mtext> <ns1:mo stretchy="false">[</ns1:mo> <ns1:mi>Y</ns1:mi> <ns1:mo stretchy="false">]</ns1:mo> <ns1:mo>=</ns1:mo> <ns1:mn>0</ns1:mn></ns1:math></alternatives></inline-formula>. Thus Ordered logistic regression satisfies the first three CFE conditions.</p>
<p>The current section showed how measurement theory along with POME allows us to derive the most popular distributions with bounded or semi-bounded range. Crucially, these derivations suggest the appropriate parametrization and tell us which parameters must be manipulated to create CFE. Informal CFE conditions were considered and two additional distributions were suggested based on these conditions. This review of probability distributions will facilitate the review of robustness literature in the subsequent section and the choice and justification of the data-generating process used in the simulations as described in section 1.3.2.</p>
</sec>
</sec>
<sec id="sec010">
<title>1.2 Robustness of <italic>t</italic>-test and <italic>F</italic>-test</title>
<p>The previous section suggested that CFE affects mean, variance and other distributional properties of the measured quantity. These in turn, may lead to violations of assumption of normal error distribution and assumption of variance homogeneity which underlie the derivation of <italic>t</italic>-test and <italic>F</italic>-test. To what extent does violation of these assumptions affect the conclusions obtained with <italic>t</italic>-test and ANOVA? The early analytic derivations and initial computer simulations came to the prevailing conclusion that <italic>t</italic>-test and <italic>F</italic>-test are surprisingly robust to violations&#8212;perhaps with the exception of homogeneity violations in unbalanced designs (see [<xref ref-type="bibr" rid="pone.0220889.ref031">31</xref>] or a review of this early work). More recent literature however suggests that the early studies underestimated the magnitude of normality and variance homogeneity violations in data [<xref ref-type="bibr" rid="pone.0220889.ref032">32</xref>]. In addition, the question of robustness depends on the choice of performance measure. The decision depends on the costs and benefits of alternative methods. Early literature stressed the advantage in terms of power and computational simplicity of parametric relative to non-parametric methods. However more recent research suggests that power loss of non-parametric methods is often negligible and the advent of computer technology made use of non-parametric methods readily available.</p>
<p>Apart from the parametric/non-parametric distinction, large chunk of robustness studies, especially those utilizing discrete RVs, have been concerned with the danger of applying parametric methods to data with ordinal scale. As highlighted by [<xref ref-type="bibr" rid="pone.0220889.ref033">33</xref>], for various reasons formal measurement theory did not become popular and is rarely used in applied research. Instead a limited version of measurement theory, to which we refer as Stevens&#8217; scale types [<xref ref-type="bibr" rid="pone.0220889.ref034">34</xref>, <xref ref-type="bibr" rid="pone.0220889.ref035">35</xref>], has become prominent. The tools of formal measurement theory provide the flexibility to design infinite variety of structures, that capture the apparently infinite variety of data generating processes encountered by the researcher. [<xref ref-type="bibr" rid="pone.0220889.ref034">34</xref>] proposed to reduce this complexity to four structures (and the corresponding scales), which he considered essential. <italic>Interval</italic> scale preserves intervals and allows researcher to make statements about the differences between the empirical objects. <italic>Ordinal</italic> scale preserves ranks and allows researcher to make statements about the order of empirical objects. With ordinal scale any transformation that preserves order is permitted and does not alter the conclusions obtained from the data. However, with interval scale only linear transformations are permitted. Since <italic>t</italic>-test or <italic>F</italic>-test compute means and variances which in turn imply additive representation a controversy arose as to whether the application of parametric methods to data with ordinal scale is meaningful. Some of the related simulation studies will be described below, for a review of the issue and the arguments see [<xref ref-type="bibr" rid="pone.0220889.ref036">36</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref040">40</xref>]. A more recent and more specialized branch of this controversy was concerned with the application of parametric methods to data obtained with Likert scales [<xref ref-type="bibr" rid="pone.0220889.ref041">41</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref044">44</xref>].</p>
<p>Below we review the robustness studies relevant to the present topic with data generated from continuous distributions. Discrete distributions are covered in the subsequent section which is followed by our discussion of this literature.</p>
<sec id="sec011">
<title>1.2.1 Continuous distributions</title>
<p>The robustness studies of <italic>t</italic>-test [<xref ref-type="bibr" rid="pone.0220889.ref045">45</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref051">51</xref>] show a type I error change of up to 3 percentage points and a power loss of up to 20 percentage points. Most studies used the <italic>t</italic>-test for groups with equal variance instead of Welch&#8217;s <italic>t</italic>-test [<xref ref-type="bibr" rid="pone.0220889.ref052">52</xref>] for unequal variances, which appears to be unequivocally recommended in its favour and is more robust [<xref ref-type="bibr" rid="pone.0220889.ref053">53</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref057">57</xref>]. For instance, [<xref ref-type="bibr" rid="pone.0220889.ref058">58</xref>] compared type I error rate of <italic>t</italic>-test, Welch test and Wilcoxon test on variates with Exponential, Log-normal, Chi squared, Gumbel and Power function distribution. Welch test showed best performance with error rate ranging to 0.083 for two Log-normal distributions with unequal variance. In this case, Wilcoxon test showed error rate of 0.491, even though it performed on par with Welch test when the variances were equal. In their meta-analytic review of the literature, though, [<xref ref-type="bibr" rid="pone.0220889.ref059">59</xref>] noted &#8220;the apparent sensitivity of the Welch test to distinctly non-normal score distributions&#8221; (p.334). Most simulation studies on performance of <italic>F</italic>-test were either performed with normal variates (see table 2 in [<xref ref-type="bibr" rid="pone.0220889.ref059">59</xref>] or with discrete variates (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref060">60</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>]). The few available studies with non-normal continuous distributions used exponential, Log-normal or double exponential distribution. In their meta-analysis [<xref ref-type="bibr" rid="pone.0220889.ref059">59</xref>] conclude that &#8220;the Type I error rate of the <italic>F</italic>-test was relatively insensitive to the effects of the explanatory variables SKEW and KURT&#8221; which corresponded to the skew and kurtosis of the distribution from which the data were generated in the respective studies. [<xref ref-type="bibr" rid="pone.0220889.ref056">56</xref>] reported similar results, but provided a results for particular distribution types (table 12 in their work). The average type I error rate across studies ranged from.048 of Log-normal to.059 of exponential distribution. At the same time KW test performance was.035 with Log-normal and 0.055 with exponential distribution. Regarding the power of <italic>F</italic>-test [<xref ref-type="bibr" rid="pone.0220889.ref056">56</xref>] did not provide an analysis as they concluded that the number of studies was not sufficient and they pointed to additional conceptual difficulties of power estimation. In particular, with non-normal distribution it&#8217;s not straightforward to compute power [<xref ref-type="bibr" rid="pone.0220889.ref055">55</xref>]. While [<xref ref-type="bibr" rid="pone.0220889.ref059">59</xref>] provided an analysis of power, their analysis was inconclusive.</p>
<p>The studies discussed so far suggest that skew, kurtosis and choice of distribution do not notably affect the performance of <italic>t</italic>-test, <italic>F</italic>-test and KW test and other factors such as group size homogeneity and variance homogeneity of the groups are more important. These studies and reviews are not very informative in the present context as they mostly manipulate variance (type I error), or mean and variance (power) and only in few cases skew and kurtosis are manipulated. As such it is difficult make conclusions regarding the robustness with respect to CFE. Some researchers claim that the simulations are not representative with respect to the data that actually occur in research. [<xref ref-type="bibr" rid="pone.0220889.ref032">32</xref>] presented a survey of 440 large-sample achievement and psychometric measures. He reported that &#8220;no distributions among those investigated passed all tests of normality, and very few seem to be even reasonably close approximations to the Gaussian.&#8221; and he pointed out that &#8220;The implications of this for many commonly applied statistics are unclear because few robustness studies, either empirical or theoretical, have dealt with lumpiness or multimodality.&#8221; (p. 160) [<xref ref-type="bibr" rid="pone.0220889.ref064">64</xref>] investigated the performance of <italic>t</italic>-test on data sampled from distributions that resembled those reported by [<xref ref-type="bibr" rid="pone.0220889.ref032">32</xref>] and concluded that <italic>t</italic>-test is robust in particular the &#8220;multi-modality and lumpiness and digit preference, appeared to have little impact&#8221;. They further concluded that &#8220;a dominant factor bringing about nonrobustness to Type I error was extreme skew&#8221; (p.359). [<xref ref-type="bibr" rid="pone.0220889.ref064">64</xref>] discuss the practice of manipulating group variance and group means in isolation as part of the simulation studies intended to test type I and type II errors. They state that &#8220;we have spent many years examining large data sets but have never encountered a treatment or other naturally occurring condition that produces heterogeneous variances while leaving population means exactly equal. While the impact of some treatments may be seen primarily in measures of scale, they always (in our experience) impact location as well.&#8221; We suggest that CFE is one possible mechanism that explains the dependence between mean and variance.</p>
</sec>
<sec id="sec012">
<title>1.2.2 Discrete distributions</title>
<p>Numerous studies investigated type I error rate of <italic>t</italic>-test and <italic>F</italic>-test when data were generated from discrete distribution [<xref ref-type="bibr" rid="pone.0220889.ref060">60</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>, <xref ref-type="bibr" rid="pone.0220889.ref065">65</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref067">67</xref>]. The error rate ranged from 0.02 to 0.055 (<italic>&#945;</italic> = 0.05) depending on the choice of data generating mechanism. These studies lack the measurement-theoretic embedding. As a consequence multiple factors such as discretness, nonlinearity, skewness or variance heterogeneity were confounded. However, some insight can be obtained from graphical and numerical summaries of the data generating process.</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref060">60</xref>] first generated a latent discrete variable in range [1, 30] with approximately normal, uniform or exponential distribution. This was then transformed using a set of 35 nonlinear monotonic transformations. Notably, one set of transformations qualitatively resembled a floor effect (see Figure 3 in [<xref ref-type="bibr" rid="pone.0220889.ref060">60</xref>]) and, compared other three sets of transformations, this set manifested the worst performance, both in terms of <italic>t</italic>-test&#8217;s type I error rate (2.8 to 5.1% with <italic>&#945;</italic> = 0.05) and in terms of the correlation between <italic>t</italic> values of transformed and raw latent values (see Table 4 in [<xref ref-type="bibr" rid="pone.0220889.ref060">60</xref>]).</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>] generated values from uniform, normal and normal mixture distributions which were then transformed to integers from 1 to 5 with help of predetermined sets of thresholds. [<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>] focused mainly on the type I error rate of Wilcoxon test and CI procedure based on <italic>t</italic>-test. For the present purpose of most interest is the test of difference between one group with symmetric normal distribution and another group with shifted and skewed normal distribution. <italic>t</italic>-test showed higher power than Wilcoxon test for small sample size. For large sample sizes both methods performed at 100% power. Again, it&#8217;s not possible to judge the magnitude of power reduction due to the change of distribution properties such as skewness since a comparable control condition with shifted but not skewed condition is missing.</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref067">67</xref>] investigated type I error rate of <italic>t</italic>-test with group values randomly sampled from over 140 thousand scores obtained from trauma patients with Glasgow Coma scale. The scores were integers and ranged from 3 to 15 points and their distribution manifests strong ceiling and floor effect with two modes at 3 and 15. The error rate was 0.018 for a two-tailed test with group size 10, but the error was negligible for the next larger group with 30 samples.</p>
<p>In addition to [<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>], only a couple of studies investigated the power of statistical methods with discrete distributions. We think that the reasons are conceptual. Such study requires a formulation with help of measure-theoretic concepts. As a consequence the few available studies are the ones that are conceptually most similar to the present study, even though these are not explicitly concerned with CFE. Hence these studies are reviewed in some detail.</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref068">68</xref>] explicitly discussed formal measurement theory in relation to the controversy of application of parametric methods to ordinal scales. [<xref ref-type="bibr" rid="pone.0220889.ref068">68</xref>] (p. 392) argued that the question of invariance of results under a permissible scale transformation was crucial: &#8220;A test of this question would seem to require a comparison of the statistical decision made on the underlying structure with that of the statistical decision made on the observed numerical representational structure. [&#8230;] If the statistical decision based on the underlying structure is not consistent with the decision made on the representational structure then level of measurement is important when applying statistical tests. Since statistical statements are probabilistic, consistency of the statistical decision is reflected by the power functions for the given test.&#8221; The authors generated normal RV which was then transformed to ranks, pseudo-ranks and ranks with added continuous normal error. The authors compared the power of <italic>t</italic>-test between the transformed and untransformed variables. The power loss due to the transformation was rather negligible with up to two percentage points for ranks and pseudo-ranks. Power loss for ranks with noise was up to ten percentage points.</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref069">69</xref>] generated data from uniform, normal, exponential or triangular distribution, and then squashed the values with thresholds to obtain a discrete RV with 2 to 10 levels. The authors compared the power of linear and probit regression and concluded that linear regression (OLSLR) performed well. Exponential distribution which had most resemblance to ceiling effect got a special mention (p. 383): &#8220;As an exception, we note OLSLR-based power was decreased relative to that of probit models for specific scenarios in which violation of OLSLR assumptions was most noticeable; namely, when the OCR had 7 or more levels and a frequency distribution of exponential shape.&#8221;</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>] generated two group samples from ordered probit regression model and showed that a normal model may lead to incorrect inferences compared to ordered probit model fitted to these data. The ordered probit model is similar to the ordered logistic regression model described in section 1.1.5 except that <inline-formula id="pone.0220889.e062"><alternatives><graphic id="pone.0220889.e062g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e062" ns0:type="simple" /><ns1:math display="inline" id="M62"><ns1:mrow><ns1:mi>z</ns1:mi> <ns1:mo>&#8764;</ns1:mo> <ns1:mi mathvariant="script">N</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>&#956;</ns1:mi> <ns1:mo>,</ns1:mo> <ns1:mi>&#963;</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:math></alternatives></inline-formula>. From all of the reviewed studies, the design of this study is the most similar to the current work. Note, that the authors compare the performance of parametric methods with a performance of a model which was used to generate the data. Trivially, in terms of likelihood, any model that was used to generate data will fit those data better than any other non-nested model. The current work will try to avoid such situation by using distinct and non-overlapping models for the purpose of method evaluation and for the purpose of data generation.</p>
</sec>
<sec id="sec013">
<title>1.2.3 Robustness research explicitly concerned with ceiling effect</title>
<p>The research on statistical ceiling effect is difficult to find due to the abundance of research on an equally named phenomenon in managerial science. Hence the review in this section, which is focused on the research that explicitly mentions CFE in statistical sense, is likely to be incomplete.</p>
<p>Majority of this literature considers the Tobit model and the relative performance of linear regression and Tobit regression. Tobit model assumes that a RV <italic>Y</italic> is generated as <italic>y</italic> = <italic>y</italic><sub><italic>u</italic></sub> if <italic>z</italic> &#8805; <italic>y</italic><sub><italic>u</italic></sub> and <italic>y</italic> = <italic>z</italic> if <italic>y</italic> &lt; <italic>y</italic><sub><italic>u</italic></sub>, where <inline-formula id="pone.0220889.e063"><alternatives><graphic id="pone.0220889.e063g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e063" ns0:type="simple" /><ns1:math display="inline" id="M63"><ns1:mrow><ns1:mi>z</ns1:mi> <ns1:mo>&#8764;</ns1:mo> <ns1:mi mathvariant="script">N</ns1:mi> <ns1:mo>(</ns1:mo> <ns1:mi>&#956;</ns1:mi> <ns1:mo>,</ns1:mo> <ns1:mi>&#963;</ns1:mi> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:math></alternatives></inline-formula>. <italic>y</italic><sub><italic>u</italic></sub> is fixed and finite, while <italic>&#956;</italic> and <italic>&#963;</italic> are model parameters. The procedure, used by Tobit, in which the value below some or above some fixed threshold is replaced with the threshold value is called <italic>censoring</italic>(e.g. see entry on censored observations in [<xref ref-type="bibr" rid="pone.0220889.ref010">10</xref>]). Censoring should be distinguished from truncation in which the values above some ceiling are discarded. The distinction between the observed <italic>Y</italic> and the latent <italic>Z</italic> is similar to the distinction between the empirical structure and the numerical representation, in which the concatenation is not represented by addition. In Tobit model <italic>Z</italic> is an additive numerical representation while <italic>Y</italic> is not. In particular, the Tobit model is an instance of a structure in which the maximal element can be obtained by concatenation and which was briefly mentioned in section 1.1.1. Contrary to the claim by [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>] that such structure is not relevant to research, a considerable literature on Tobit model and CFE emerged in recent two decades.</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref071">71</xref>] considered how ceiling effect affects the growth estimates of linear model applied to longitudinal data generated from multivariate normal model which were then subject to a threshold similar to how <italic>Z</italic> was treated in the Tobit model. Up to 42% of the data were subject to ceiling effect. The authors compared performance of Tobit model with that of a linear model. The linear model was applied to data subjected to omission or list-wise deletion of the data at ceiling, which was intended to improve its performance. However, linear model performed worse and it underestimated the growth magnitude. In particular, &#8220;the magnitude of the biases was positively related to the proportion of the ceiling data in the data set.&#8221; ([<xref ref-type="bibr" rid="pone.0220889.ref071">71</xref>] p. 491).</p>
<p>[<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] investigated how ceiling effect changes the value-added estimates of a linear method compared to a Tobit model. Similar to [<xref ref-type="bibr" rid="pone.0220889.ref071">71</xref>], this was an educational research scenario with longitudinal structure, but unlike the former study, [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] used test scores obtained with human participants which were then censored. The authors concluded that Tobit model considerably improved estimation, but also concluded that the linear method performed reasonably well up to a situation in which the ceiling affected more than the half of the values. See [<xref ref-type="bibr" rid="pone.0220889.ref072">72</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref075">75</xref>] for additional studies on the relative performance of Tobit and linear method with similar results.</p>
<p>The aforementioned studies rely on censoring to generate data. The sole exception is the study by [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] who distinguish between <italic>hard ceiling</italic> and <italic>soft ceiling</italic>. Hard ceiling was generated using the Tobit procedure and corresponds to the empirical structure in which the maximal element can be obtained through concatenation of two non-maximal elements. Soft ceiling corresponds to the structure with essential maximum, which we described in detail in section 1.1.1 and which is the focus of the current work. [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] considered skewness to constitute the crucial feature of a soft ceiling and used a spline to simulate RVs with skewed distribution. The choice of spline model is ad hoc and as [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] concede there are other valid choices. [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] found that the effects of soft ceiling were somewhat less severe.</p>
<p>The focus on data generated with censored normal or empirical distributions, limits the conclusions of the literature discussed so far in this section. Apart from the exclusion of soft ceiling, as mentioned by [<xref ref-type="bibr" rid="pone.0220889.ref071">71</xref>] (p.492), there are other potential choices to model the latent variable <italic>Z</italic>, such as Weibull or Log-normal distribution. Another class of excluded models with similar distributions are zero-inflated models, the most notable instance being the zero-inflated poisson model [<xref ref-type="bibr" rid="pone.0220889.ref076">76</xref>] used in survival analysis. Furthermore, censoring is readily recognizable&#8212;especially with continuous measurements. It manifests as a distinct mode at maximum/minimum. Thus, the Tobit model provides a very specific way to model CFE, which raises the concern about generality of the results obtained with this model.</p>
<p>A few additional studies on CFE compare the performance of linear regression model with a generalized linear model on discrete data. [<xref ref-type="bibr" rid="pone.0220889.ref077">77</xref>] used logistic model to study attrition in gerontological research and claimed that the choice of generalized linear model helped them avoid incorrect inferences caused by CFE. [<xref ref-type="bibr" rid="pone.0220889.ref078">78</xref>] compared the data fit of four statistical models. The simulated data modelled the distribution of four psychometric tests popular in epidemiological studies. The four tested models were: linear regression, linear regression applied to square root transformed data, linear regression applied to data transformed with CDF of Beta distribution, and a threshold model similar to ordered logistic regression reviewed in section 1.1.3. The last two models provided better fit than linear regression with no data transformation. [<xref ref-type="bibr" rid="pone.0220889.ref079">79</xref>] compared linear regression with generalized linear model based on binomial logit link function. They analysed a large data set obtained with Health of the Nation Outcome Scale for Children and Adolescent. The scale has integer outcome in range from 0 to 52. The linear method provided considerably larger effect size estimates (change between two time point of magnitude &#8722;2.75 vs. &#8722;0.49).</p>
<p>The three studies of CFE on discrete data demonstrated that generalized linear model and linear regression provide different effect size estimates. Strictly, this does not imply that the estimates from linear model are incorrect or biased. The authors made this conclusion, by assuming that the bounded values obtained with the test or the scale reflect an unbounded latent trait which seems plausible. The assumption of continuity of the latent trait and the discrepancy between the latent trait and the measured values highlights the conceptual link of these studies to the measure-theoretic framework. Unlike Tobit studies, these studies investigated the soft ceiling. All the studies reviewed in this section focused on effect size estimation of either regression coefficient or of differences (between groups or between repeated measurements) and how their estimation is affected by CFE. The effect of CFE on hypothesis testing, p values or confidence intervals was rarely discussed.</p>
</sec>
</sec>
<sec id="sec014">
<title>1.3 Goals and scope</title>
<sec id="sec015">
<title>1.3.1 Selection of statistical methods for investigation</title>
<p>The main goal driving the selection of statistical analyses is to complement the literature by providing additional results for previously untested modern methods. We focus on performance of <italic>t</italic>-test and ANOVA due to their popularity. As already mentioned in the previous section, estimation of regression coefficients in linear regression under CFE has been repeatedly investigated, hence we omit the regression setting and focus mainly on hypothesis testing. In particular, we investigate the performance of Welch test as it has been recommended in favor of the standard <italic>t</italic>-test without any additional drawbacks. We consider one-way ANOVA with three levels and a 2 &#215; 2 omnibus ANOVA, in which case we present results from two <italic>F</italic>-tests for the two respective main effects and the results from <italic>F</italic>-test for the interaction. The following alternatives to <italic>t</italic>-test and ANOVA are included.</p>
<p>First, while the robustness of non-parametric methods has been investigated extensively, the investigations did not manipulate or account for the magnitude of CFE. Instead the focus was set on the ordinality of measurement and on the distributional properties such as variance or skew. We look at the performance of Mann-Whitney (MW) Test, Kruskal-Wallis (KW) Test and Scheirer-Ray-Hare-Test (SRHT).</p>
<p>Second, [<xref ref-type="bibr" rid="pone.0220889.ref080">80</xref>, <xref ref-type="bibr" rid="pone.0220889.ref081">81</xref>] argued for a wider use of so-called robust statistical methods&#8212;methods that were designed to tolerate violation of normality and presence of outliers. [<xref ref-type="bibr" rid="pone.0220889.ref082">82</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref083">83</xref>] recommended the trimmed <italic>t</italic>-test by [<xref ref-type="bibr" rid="pone.0220889.ref084">84</xref>] in which a predefined proportion of the smallest and largest data values is discarded. Investigation of the performance of the trimmed <italic>t</italic>-test is included in the present study.</p>
<p>Third, Bayesian hypothesis testing has been recommended for diverse reasons [<xref ref-type="bibr" rid="pone.0220889.ref085">85</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref088">88</xref>]. Notably, it allows researchers to both confirm and reject hypotheses and the results are easier to interpret than p values since they describe the probability of hypotheses. One difficulty with Bayesian methods is that they require the specification of the data distribution under the alternative hypothesis. Another difficulty is computational: nuisance parameters are handled by integrating the data likelihood over their prior probability, which, depending on the choice of prior and the amount of data, can be computationally intensive. As a consequence various approaches to Bayesian hypothesis testing have been recommended [<xref ref-type="bibr" rid="pone.0220889.ref086">86</xref>, <xref ref-type="bibr" rid="pone.0220889.ref089">89</xref>, <xref ref-type="bibr" rid="pone.0220889.ref090">90</xref>]. The Bayesian <italic>t</italic>-test presented by [<xref ref-type="bibr" rid="pone.0220889.ref086">86</xref>] was selected in the current study, due to its computational simplicity as well as to its close relation to the frequentist <italic>t</italic>-test, which facilitates comparison. The Bayesian <italic>t</italic>-test provides the probability of the null hypothesis that the groups are equal relative to the alternative hypothesis that the groups differ.</p>
<p>Fourth, a frequentist alternative which offers the flexibility to confirm a hypothesis is equivalence testing. In particular, &#8220;two one-sided tests&#8221; (TOST) procedure by [<xref ref-type="bibr" rid="pone.0220889.ref091">91</xref>] has been advocated by [<xref ref-type="bibr" rid="pone.0220889.ref092">92</xref>]. The procedure asks the researcher to specify an equivalence interval around the effect size value suggested by the null hypothesis. Two <italic>t</italic>-tests are performed to determine whether the test statistic is respectively higher and lower than the lower and higher bound implied by the equivalence interval. Equivalence is assumed, if both hypotheses can be rejected. We are not aware of any robustness studies of the TOST procedure.</p>
<p>Fifth, a shift from null-hypothesis significance testing to reporting of (standardized) effect sizes along with confidence intervals was advocated by numerous authors (see e.g. [<xref ref-type="bibr" rid="pone.0220889.ref093">93</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref095">95</xref>]. Since any hypothesis testing procedure may be used to construct a confidence interval, the decisions based on confidence intervals fail under conditions similar to <italic>t</italic>-test. [<xref ref-type="bibr" rid="pone.0220889.ref096">96</xref>] showed with data generated from skewed distributions that the capture rate of the parametric CI does not correspond to the nominal CI. As an alternative, they recommended a CI of a bias-corrected effect size computed with bootstrap procedure. In the current work we present effect size estimates along with CI estimates in a research scenario with two groups. We present both the unstandardised effect size which corresponds to the mean difference in the observed value and its standardized version&#8212;Cohen&#8217;s <italic>d</italic>. The effect size estimates and CIs can be viewed as an inferential alternative to <italic>t</italic>-test, but in the present context they also highlight how CFE affects mean, variance and standard error, i.e. the elementary quantities utilized by the <italic>t</italic>-test computation.</p>
<p>Sixth, the literature review suggested that extreme skew and heterogeneous variances are (in addition to unequal group size) crucial factors leading to poor performance of <italic>t</italic>-test. The review of measurement theory as well as some publications [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] suggest that the two are related and we investigate the issue further by providing estimates of mean, variance and skew of the generated data. This further facilitates the discussion of the results as it helps us to relate these to those obtained by robustness studies with focus on skew manipulation.</p>
<p>Finally, our goal was to evaluate a statistical inferential method that would specifically target CFE and provide an alternative to the established methods. In selecting such method we had two concerns. First, the method should be reasonably easy to apply in terms of both computation and interpretation. Second, we wanted to avoid the obvious but not very helpful choice to use models identical to the data-generating process. This would mean for instance, that we compare the performance of generalized gamma model with say a <italic>t</italic>-test when the data are generated from generalized gamma distribution. Such setup has been used previously (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>]), and it may be useful for demonstrating drawbacks of the linear method, where by fitting a model identical with the data-generating mechanism one obtains an upper bound on the performance. However, as an alternative to established methods, it&#8217;s not helpful to recommend a model that precisely matches the data-generating distribution, as the main difficulty is that the data-generating mechanism is not known, or only very rough knowledge is available. Such rough knowledge may be a suspicion that CFE affects the measure. The candidate statistical methods can be justified by considering the measurement theory behind CFE that was discussed in section 1.1.1. There we considered the appropriate models of CFE and for each distribution we distinguished the nuisance parameters from parameters describing the magnitude of CFE. The latter correspond to <italic>c</italic><sub><italic>u</italic></sub> and <italic>c</italic><sub><italic>l</italic></sub> in <xref ref-type="table" rid="pone.0220889.t001">Table 1</xref>. We saw that in most cases CFE is described by a logarithmic function which is further modified by the nuisance parameters e.g. <inline-formula id="pone.0220889.e064"><alternatives><graphic id="pone.0220889.e064g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e064" ns0:type="simple" /><ns1:math display="inline" id="M64"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:mtext>log</ns1:mtext><ns1:mspace width="2pt" /><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msup><ns1:mi>Y</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>n</ns1:mi></ns1:msub></ns1:msup> <ns1:mo>/</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>m</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> in the case of Gamma distribution. Thus, one may assume that the logarithmic function provides accurate descriptions of CFE even though its precise shape determined by the nuisance parameters may not be known. We think that this situation, better describes the applied case, in which the researcher may suspect an influence of ceiling effect due to the bounded measurement range or due to the skew; but she may not have the exact knowledge of how CFE affects the measurement.</p>
<p>Given these consideration we decided to use Log-normal model and Logit-normal model in scenarios with one and two bounds respectively. In fact, since these models correspond to an application of normal linear model to data transformed by log or logit function, we make the comparison more direct by comparing t-test with t-test applied to log or logit transformed data. The data transformation is additionally used in the case of one-way ANOVA, two-way ANOVA, with CIs, Bayesian <italic>t</italic>-test and equivalence testing, thereby obtaining an additional version of each statistical method. In our opinion, such design helps us distinguish to what extent the performance of each statistical method depends on the assumption of normality.</p>
<p>To conclude, the selected statistical methods used in the current work are Welch&#8217;s <italic>t</italic>-test, one-way ANOVA, two-way ANOVA, Bayesian <italic>t</italic>-test and TOST. Each method is applied to log-transformed or logit-transformed data. In addition, <italic>t</italic>-test is compared with trimmed <italic>t</italic>-test and rank-based MW test, while one-way ANOVA is compared to KW test and two-way ANOVA is compared to SRHT.</p>
</sec>
<sec id="sec016">
<title>1.3.2 Selection of data-generating process and performance metric</title>
<p>The present work will utilize Beta distribution, Generalized Gamma distribution, Beta prime distribution, Wald distribution, Beta-Binomial distribution and Ordered Logit Regression model (OLRM). We excluded the Log-normal and Logit-normal distribution as these would coincide with the models which performance is being investigated. The discrete Beta distribution and generalized geometric distribution listed in <xref ref-type="table" rid="pone.0220889.t001">Table 1</xref> are excluded for lack of applied interest in these models. In addition, theoretical results needed for simulation of such random variables are not available in the statistical literature.</p>
<p>Even more important than the choice of distributions is the choice of their parametrization. All distributions are parametrized with <italic>c</italic><sub><italic>i</italic></sub> as described in section 1.1.3. Gamma distribution is the sole exception, for which we use parameter <italic>b</italic> instead of <italic>c</italic><sub><italic>m</italic></sub>. The latter choice would result in the expected value <italic>c</italic><sub><italic>m</italic></sub> being held constant, which in turn would result in a trivial failure of any statistical method which uses the difference between means for inference. We gave priority to OLRM over polytomous Rasch model as the former appears to be more popular being included in textbooks such as [<xref ref-type="bibr" rid="pone.0220889.ref030">30</xref>] and has generated some prior research interest relevant to the current topic [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>, <xref ref-type="bibr" rid="pone.0220889.ref078">78</xref>, <xref ref-type="bibr" rid="pone.0220889.ref079">79</xref>].</p>
<p>Since all three distributions which manifest both ceiling and floor effect use the same function for ceiling and floor effect (<italic>f</italic><sub><italic>u</italic></sub> = <italic>f</italic><sub><italic>l</italic></sub>), without a loss of generality, we restrict the investigation to a floor effect and the related parameter <italic>c</italic><sub><italic>l</italic></sub>. Then the goal is to investigate the ability of statistical methods to detect constant difference in <italic>c</italic><sub><italic>l</italic></sub> as the offset of <italic>c</italic><sub><italic>l</italic></sub> goes to &#8722;&#8734;. In particular, we investigate seven research scenarios. First, two groups (A and B) of 50 values each are generated from the respective distributions with <inline-formula id="pone.0220889.e065"><alternatives><graphic id="pone.0220889.e065g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e065" ns0:type="simple" /><ns1:math display="inline" id="M65"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mi>A</ns1:mi></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula> and <inline-formula id="pone.0220889.e066"><alternatives><graphic id="pone.0220889.e066g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e066" ns0:type="simple" /><ns1:math display="inline" id="M66"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mi>B</ns1:mi></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup> <ns1:mo>+</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula>. We manipulate the magnitude of CFE by varying <inline-formula id="pone.0220889.e067"><alternatives><graphic id="pone.0220889.e067g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e067" ns0:type="simple" /><ns1:math display="inline" id="M67"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup></ns1:math></alternatives></inline-formula>, while <inline-formula id="pone.0220889.e068"><alternatives><graphic id="pone.0220889.e068g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e068" ns0:type="simple" /><ns1:math display="inline" id="M68"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> (which may be interpreted as an effect size) and all remaining parameters are held constant. The two-group scenario is used to investigate the inference with Confidence intervals, with Cohen&#8217;s <italic>d</italic>, Welch&#8217;s <italic>t</italic>-test, Trimmed <italic>t</italic>-test, MW test, TOST, Bayesian <italic>t</italic>-test and Welch&#8217;s <italic>t</italic>-test on transformed data. In the second situation, we introduce a third group with <inline-formula id="pone.0220889.e069"><alternatives><graphic id="pone.0220889.e069g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e069" ns0:type="simple" /><ns1:math display="inline" id="M69"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mi>C</ns1:mi></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup> <ns1:mo>+</ns1:mo> <ns1:mn>2</ns1:mn> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula> and the performance of one-way ANOVA, KW test and one-way ANOVA on transformed data is investigated. The remaining five scenarios assume presence of two factors with two levels each and and the performance of 2 &#215; 2 ANOVA applied to raw and transformed data and the performance of the rank-based SRHT is investigated. <xref ref-type="fig" rid="pone.0220889.g002">Fig 2</xref> illustrates the five different types of interactions that are being investigated. The choice of the scenarios is motivated by the research on how CFE affects linear regression, which showed that the linear method has problems identifying interactions [<xref ref-type="bibr" rid="pone.0220889.ref078">78</xref>]. In the first two cases we are interested in whether the statistical methods are able to correctly distinguish between a main effect and an interaction. In the first case, one main effect occurs and there is no interaction. The second case describes a situation with interaction but without main effect. The last three cases include two main effects and an interaction on <italic>c</italic><sub><italic>l</italic></sub>, but differ in the order of the <italic>c</italic><sub><italic>l</italic></sub> mean values of the four groups. We label these uncrossed, crossed and double-crossed interaction. Assuming that CFE affects the performance, the double-crossed interaction should pose least problems for statistical methods, since CFE preserves order information and the inferential methods should be able to pick out this information. In contrast, the uncrossed interaction should pose most problems. As in previous scenarios, the group differences are held constant, while <inline-formula id="pone.0220889.e070"><alternatives><graphic id="pone.0220889.e070g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e070" ns0:type="simple" /><ns1:math display="inline" id="M70"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup> <ns1:mo>&#8594;</ns1:mo> <ns1:mo>-</ns1:mo> <ns1:mi>&#8734;</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula>. In each interaction case the group specific <italic>c</italic><sub><italic>l</italic></sub> is computed as <inline-formula id="pone.0220889.e071"><alternatives><graphic id="pone.0220889.e071g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e071" ns0:type="simple" /><ns1:math display="inline" id="M71"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mi>C</ns1:mi></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup> <ns1:mo>+</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mi>d</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> with <italic>d</italic> shown in <xref ref-type="fig" rid="pone.0220889.g002">Fig 2</xref>. The procedure is repeated for various combinations of nuisance parameters. Notably, for each distribution we look at how different values of <inline-formula id="pone.0220889.e072"><alternatives><graphic id="pone.0220889.e072g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e072" ns0:type="simple" /><ns1:math display="inline" id="M72"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> affect performance. One additional nuisance parameter is investigated for each distribution. The identity of these nuisance parameters as well as the ranges of all parameters are listed in <xref ref-type="table" rid="pone.0220889.t002">Table 2</xref>.</p>
<fig id="pone.0220889.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Types of interactions.</title>
<p>Each panel shows a qualitatively different outcome of a 2 &#215; 2 factorial design. The first panel (from left) shows two main effects without an interaction. The second panel shows an (additive) interaction but no main effect. The remaining three panels show different constellations of two main effects accompanied by an interaction. Crucially the relative order of the conditions differs across these three constellations. The five displayed outcomes are used in the simulations.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g002" ns0:type="simple" />
</fig>
<table-wrap id="pone.0220889.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.t002</object-id>
<label>Table 2</label>
<caption>
<title>Parameter values used in simulation.</title>
</caption>
<alternatives>
<graphic id="pone.0220889.t002g" mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.t002" ns0:type="simple" />
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
</colgroup>
<thead>
<tr>
<th align="left">Distribution</th>
<th align="center">Range <italic>c</italic><sub><italic>l</italic></sub></th>
<th align="center">
<inline-formula id="pone.0220889.e073">
<alternatives>
<graphic id="pone.0220889.e073g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e073" ns0:type="simple" />
<ns1:math display="inline" id="M73">
<ns1:msubsup>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
<ns1:mo>&#916;</ns1:mo>
</ns1:msubsup>
</ns1:math>
</alternatives>
</inline-formula> value</th>
<th align="center">
<inline-formula id="pone.0220889.e074">
<alternatives>
<graphic id="pone.0220889.e074g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e074" ns0:type="simple" />
<ns1:math display="inline" id="M74">
<ns1:msubsup>
<ns1:mi>c</ns1:mi>
<ns1:mi>l</ns1:mi>
<ns1:mo>&#916;</ns1:mo>
</ns1:msubsup>
</ns1:math>
</alternatives>
</inline-formula> range</th>
<th align="center">NP label</th>
<th align="center">NP value</th>
<th align="center">NP range</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Gen. Gamma</td>
<td align="center">[&#8722;4, 4]</td>
<td align="center">0.25</td>
<td align="center">[0, 1]</td>
<td align="center"><italic>c</italic><sub><italic>n</italic></sub></td>
<td align="center">1.0</td>
<td align="center">[0, 2]</td>
</tr>
<tr>
<td align="left">Wald</td>
<td align="center">[20, 0]</td>
<td align="center">1.0</td>
<td align="center">[0, 4]</td>
<td align="center"><italic>&#963;</italic></td>
<td align="center">1.0</td>
<td align="center">[0, 2]</td>
</tr>
<tr>
<td align="left">Beta Prime</td>
<td align="center">[&#8722;10, &#8722;2]</td>
<td align="center">2.0</td>
<td align="center">[0, 8]</td>
<td align="center"><italic>c</italic><sub><italic>m</italic></sub></td>
<td align="center">0.155</td>
<td align="center">[0, 0]</td>
</tr>
<tr>
<td align="left">Beta</td>
<td align="center">[&#8722;20, 0]</td>
<td align="center">3</td>
<td align="center">[1, 5]</td>
<td align="center"><italic>c</italic><sub><italic>u</italic></sub></td>
<td align="center">-0.2</td>
<td align="center">[0, 0]</td>
</tr>
<tr>
<td align="left">Beta-Binomial</td>
<td align="center">[&#8722;5, &#8722;1]</td>
<td align="center">4</td>
<td align="center">[1, 8]</td>
<td align="center"><italic>n</italic></td>
<td align="center">7</td>
<td align="center">[3, 15]</td>
</tr>
<tr>
<td align="left">OLRM</td>
<td align="center">[&#8722;5, 5]</td>
<td align="center">0.8</td>
<td align="center">[0, 1]</td>
<td align="center"><italic>n</italic></td>
<td align="center">7</td>
<td align="center">[3, 15]</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001">
<p>NP- nuisance parameter</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Regarding the robustness metric, we repeat each simulation 10000 times and present the proportion of cases in which a group difference was detected. Assuming a binomial model, the width of the 95% CI of the proportion metric is less than 0.02. As an exception, when reporting the performance of confidence intervals, Cohen&#8217;s d and Bayesian <italic>t</italic>-test, we report median values. With Bayesian <italic>t</italic>-test we report the median probability of hypothesis that the two groups differ as opposed to the hypothesis that the two groups are equal.</p>
</sec>
</sec>
</sec>
<sec id="sec017" sec-type="materials|methods">
<title>2 Materials and methods</title>
<sec id="sec018">
<title>2.1 Design</title>
<p>For each of the eight distributions and each of the seven scenarios, two, three or four groups of data were generated with 50, 33 or 25 samples per group respectively. The statistical methods were then applied and the inferential outcome was determined and recorded. This was repeated 10000 times and the performance metrics were computed over repetitions. Furthermore, the procedure was repeated for 25 combinations of five values of <inline-formula id="pone.0220889.e075"><alternatives><graphic id="pone.0220889.e075g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e075" ns0:type="simple" /><ns1:math display="inline" id="M75"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and five values of a distribution-specific nuisance parameter. The distribution-specific nuisance parameter is listed in <xref ref-type="table" rid="pone.0220889.t002">Table 2</xref> (column NP label). The five values of <inline-formula id="pone.0220889.e076"><alternatives><graphic id="pone.0220889.e076g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e076" ns0:type="simple" /><ns1:math display="inline" id="M76"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and of the nuisance parameter were selected from the ranges listed in <xref ref-type="table" rid="pone.0220889.t002">Table 2</xref> with equally spaced intervals.</p>
</sec>
<sec id="sec019">
<title>2.2 Software implementation</title>
<p>The implementation relied on the stats library from Python&#8217;s Scipy package (Python 3.7.3, Numpy 1.16.3, Scipy 1.2.1). A translation from the <italic>c</italic><sub><italic>l</italic></sub> and/or <italic>c</italic><sub><italic>u</italic></sub> to the more common parametrization of Gamma and Beta distribution (in terms of <italic>a</italic> and <italic>b</italic> in <xref ref-type="table" rid="pone.0220889.t001">Table 1</xref>) was obtained iteratively with Newton method. The formulas for compution of the gradient are provided in [<xref ref-type="bibr" rid="pone.0220889.ref097">97</xref>] (chapter 7.1) and [<xref ref-type="bibr" rid="pone.0220889.ref098">98</xref>] (chapter 25.4) respectively. To compute the initial guess we used the approximation <italic>&#968;</italic>(<italic>x</italic>) = log(<italic>x</italic> &#8722; 0.5).</p>
<p>The confidence intervals were computed with the normal-based procedure (theorem 6.16 in [<xref ref-type="bibr" rid="pone.0220889.ref099">99</xref>]). The standard error was that of the Welch test. To compute standard error of Cohen&#8217;s <italic>d</italic> we used the approximation in [<xref ref-type="bibr" rid="pone.0220889.ref100">100</xref>] (Eq 12.14): <inline-formula id="pone.0220889.e077"><alternatives><graphic id="pone.0220889.e077g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e077" ns0:type="simple" /><ns1:math display="inline" id="M77"><ns1:mrow><ns1:msub><ns1:mtext>SE</ns1:mtext> <ns1:mi>d</ns1:mi></ns1:msub> <ns1:mo>=</ns1:mo> <ns1:msqrt><ns1:mrow><ns1:mfrac><ns1:mn>2</ns1:mn> <ns1:mi>n</ns1:mi></ns1:mfrac> <ns1:mo>+</ns1:mo> <ns1:mfrac><ns1:msup><ns1:mi>d</ns1:mi> <ns1:mn>2</ns1:mn></ns1:msup> <ns1:mrow><ns1:mn>4</ns1:mn> <ns1:mi>n</ns1:mi></ns1:mrow></ns1:mfrac></ns1:mrow></ns1:msqrt></ns1:mrow></ns1:math></alternatives></inline-formula> where <italic>n</italic> is the sample size of each group. The denominator in computation of Cohen&#8217;s <italic>d</italic> was (Eq 12.12 [<xref ref-type="bibr" rid="pone.0220889.ref100">100</xref>]): <inline-formula id="pone.0220889.e078"><alternatives><graphic id="pone.0220889.e078g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e078" ns0:type="simple" /><ns1:math display="inline" id="M78"><ns1:mrow><ns1:msqrt><ns1:mfrac><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo> <ns1:mi>n</ns1:mi> <ns1:mo>-</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>)</ns1:mo></ns1:mrow> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>v</ns1:mi> <ns1:mn>1</ns1:mn></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>v</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow> <ns1:mrow><ns1:mn>2</ns1:mn> <ns1:mi>n</ns1:mi> <ns1:mo>-</ns1:mo> <ns1:mn>2</ns1:mn></ns1:mrow></ns1:mfrac></ns1:msqrt> <ns1:mo>=</ns1:mo> <ns1:msqrt><ns1:mfrac><ns1:mrow><ns1:msub><ns1:mi>v</ns1:mi> <ns1:mn>1</ns1:mn></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>v</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msub></ns1:mrow> <ns1:mn>2</ns1:mn></ns1:mfrac></ns1:msqrt></ns1:mrow></ns1:math></alternatives></inline-formula> where <italic>v</italic><sub><italic>i</italic></sub> is the group variance. The TOST thresholds were fixed across <italic>c</italic><sub><italic>l</italic></sub> to correspond to an median estimate of the group difference obtained with a <italic>c</italic><sub><italic>l</italic></sub> located 3/4 between the lower and upper bound of the <italic>c</italic><sub><italic>l</italic></sub> range. E.g. <italic>c</italic><sub><italic>l</italic></sub> used to obtain the threshold for gamma distribution was 4 &#8722; (&#8722;4) &#215; 0.75 &#8722; 4 = 2. Separate thresholds were obtained for transformed and raw data. The threshold estimates were obtained with Monte Carlo simulation with 5000 samples in each group. The code used to run the simulations and to generate the figures is available from <ext-link ext-link-type="uri" ns0:href="https://github.com/simkovic/CFE" ns0:type="simple">https://github.com/simkovic/CFE</ext-link>.</p>
</sec>
<sec id="sec020">
<title>2.3 Parameter recovery with ordered logistic regression and Beta-binomial distribution</title>
<p>This section describes the methods used in section 3.8. The motivation behind this supplementary investigation is described in section 3.8. In the first step OLRM was fitted to ratings of moral dilemmas reported in [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>]. The data are labelled <inline-formula id="pone.0220889.e079"><alternatives><graphic id="pone.0220889.e079g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e079" ns0:type="simple" /><ns1:math display="inline" id="M79"><ns1:msubsup><ns1:mi>y</ns1:mi> <ns1:mrow><ns1:msub><ns1:mi>n</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msub> <ns1:mi>i</ns1:mi></ns1:mrow> <ns1:mrow><ns1:mi>g</ns1:mi> <ns1:mi>s</ns1:mi></ns1:mrow></ns1:msubsup></ns1:math></alternatives></inline-formula>, where <italic>y</italic> &#8712; 0, 1, &#8230;, 9 is the rating, <italic>n</italic><sub><italic>s</italic></sub> indexes the participant, <italic>i</italic> &#8712; {1, &#8230;, 6} indexes the item, <italic>g</italic> &#8712; {0, 1} indicates whether the data come from the experiment group or from the control group, and <italic>s</italic> &#8712; {0, 1} indicates wheter the data come from the original or from the replication study. OLRM is then given by <inline-formula id="pone.0220889.e080"><alternatives><graphic id="pone.0220889.e080g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e080" ns0:type="simple" /><ns1:math display="inline" id="M80"><ns1:mrow><ns1:msubsup><ns1:mi>y</ns1:mi> <ns1:mrow><ns1:msub><ns1:mi>n</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msub> <ns1:mi>i</ns1:mi></ns1:mrow> <ns1:mrow><ns1:mn>0</ns1:mn> <ns1:mi>s</ns1:mi></ns1:mrow></ns1:msubsup> <ns1:mo>&#8764;</ns1:mo> <ns1:mtext>orlm</ns1:mtext> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msubsup><ns1:mi>b</ns1:mi> <ns1:mi>i</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msubsup> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> for control group and for experimental group it&#8217;s <inline-formula id="pone.0220889.e081"><alternatives><graphic id="pone.0220889.e081g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e081" ns0:type="simple" /><ns1:math display="inline" id="M81"><ns1:mrow><ns1:msubsup><ns1:mi>y</ns1:mi> <ns1:mrow><ns1:msub><ns1:mi>n</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msub> <ns1:mi>i</ns1:mi></ns1:mrow> <ns1:mrow><ns1:mn>1</ns1:mn> <ns1:mi>s</ns1:mi></ns1:mrow></ns1:msubsup> <ns1:mo>&#8764;</ns1:mo> <ns1:mtext>orlm</ns1:mtext> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msubsup><ns1:mi>b</ns1:mi> <ns1:mi>i</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msubsup> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:msub><ns1:mi>d</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> where <inline-formula id="pone.0220889.e082"><alternatives><graphic id="pone.0220889.e082g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e082" ns0:type="simple" /><ns1:math display="inline" id="M82"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="script">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> is the set of nine thresholds, <inline-formula id="pone.0220889.e083"><alternatives><graphic id="pone.0220889.e083g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e083" ns0:type="simple" /><ns1:math display="inline" id="M83"><ns1:mrow><ns1:mi>b</ns1:mi> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="script">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> is item difficulty and <italic>d</italic><sub><italic>s</italic></sub> is the group difference.</p>
<p>In the second step a set of data points <inline-formula id="pone.0220889.e084"><alternatives><graphic id="pone.0220889.e084g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e084" ns0:type="simple" /><ns1:math display="inline" id="M84"><ns1:msub><ns1:mi>z</ns1:mi> <ns1:mrow><ns1:mi>n</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub></ns1:math></alternatives></inline-formula> were generated with <inline-formula id="pone.0220889.e085"><alternatives><graphic id="pone.0220889.e085g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e085" ns0:type="simple" /><ns1:math display="inline" id="M85"><ns1:msub><ns1:mi>z</ns1:mi> <ns1:mrow><ns1:mi>n</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub> <ns1:mo>~</ns1:mo> <ns1:mtext>orlm</ns1:mtext> <ns1:mo stretchy="false">(</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:msub><ns1:mi>d</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msub> <ns1:mo>&#8722;</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo stretchy="false">)</ns1:mo></ns1:math></alternatives></inline-formula>, where <italic>d</italic><sub>0</sub> and <italic>c</italic><sub><italic>k</italic></sub> were fixed to median estimates of the corresponding parameters obtained in the previous step. <italic>c</italic><sub><italic>u</italic></sub> was fixed to one of 50 values in the range [&#8722;7.7, 4.8] with equally spaced intervals between the values. In the third step another OLRM was fitted <inline-formula id="pone.0220889.e086"><alternatives><graphic id="pone.0220889.e086g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e086" ns0:type="simple" /><ns1:math display="inline" id="M86"><ns1:mrow><ns1:msub><ns1:mi>z</ns1:mi> <ns1:mrow><ns1:mi>n</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub> <ns1:mo>&#8764;</ns1:mo> <ns1:mtext>orlm</ns1:mtext> <ns1:mrow><ns1:mo>(</ns1:mo> <ns1:msub><ns1:mi>b</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:mi>g</ns1:mi> <ns1:msub><ns1:mi>d</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msub> <ns1:mo>-</ns1:mo> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mrow><ns1:mi>k</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:mrow></ns1:msub> <ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:math></alternatives></inline-formula> with which estimates of <inline-formula id="pone.0220889.e087"><alternatives><graphic id="pone.0220889.e087g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e087" ns0:type="simple" /><ns1:math display="inline" id="M87"><ns1:msub><ns1:mi>b</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msub></ns1:math></alternatives></inline-formula>, <inline-formula id="pone.0220889.e088"><alternatives><graphic id="pone.0220889.e088g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e088" ns0:type="simple" /><ns1:math display="inline" id="M88"><ns1:msub><ns1:mi>d</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msub></ns1:math></alternatives></inline-formula> and <inline-formula id="pone.0220889.e089"><alternatives><graphic id="pone.0220889.e089g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e089" ns0:type="simple" /><ns1:math display="inline" id="M89"><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mrow><ns1:mi>k</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:mrow></ns1:msub></ns1:math></alternatives></inline-formula> were obtained.</p>
<p>The estimation was performed with PySTAN 2.19 [<xref ref-type="bibr" rid="pone.0220889.ref101">101</xref>] which is a software for statistical inference with MCMC sampling. In each analysis, six chains were sampled and a total of 2400 samples was obtained. The convergence was checked by estimating the potential scale reduction <inline-formula id="pone.0220889.e090"><alternatives><graphic id="pone.0220889.e090g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e090" ns0:type="simple" /><ns1:math display="inline" id="M90"><ns1:mover accent="true"><ns1:mi>R</ns1:mi> <ns1:mo>^</ns1:mo></ns1:mover></ns1:math></alternatives></inline-formula> ([<xref ref-type="bibr" rid="pone.0220889.ref102">102</xref>] p.297)in the parameters. In all analyses and for all parameters <inline-formula id="pone.0220889.e091"><alternatives><graphic id="pone.0220889.e091g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e091" ns0:type="simple" /><ns1:math display="inline" id="M91"><ns1:mrow><ns1:mover accent="true"><ns1:mi>R</ns1:mi> <ns1:mo>^</ns1:mo></ns1:mover> <ns1:mo>&lt;</ns1:mo> <ns1:mn>1</ns1:mn> <ns1:mo>.</ns1:mo> <ns1:mn>05</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula> where <inline-formula id="pone.0220889.e092"><alternatives><graphic id="pone.0220889.e092g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e092" ns0:type="simple" /><ns1:math display="inline" id="M92"><ns1:mrow><ns1:mover accent="true"><ns1:mi>R</ns1:mi> <ns1:mo>^</ns1:mo></ns1:mover> <ns1:mo>=</ns1:mo> <ns1:mn>1</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula> upon convergence.</p>
</sec>
</sec>
<sec id="sec021" sec-type="results">
<title>3 Results</title>
<p>The results are presented as graphs with <inline-formula id="pone.0220889.e093"><alternatives><graphic id="pone.0220889.e093g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e093" ns0:type="simple" /><ns1:math display="inline" id="M93"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup></ns1:math></alternatives></inline-formula> on the horizontal axis and performance metric on the vertical axis. To facilitate comparison, statistical methods which were applied to the same data, in the same scenario and with the same metric are presented together in the same graph. Excluding 2 &#215; 2 ANOVA, the result is a total of 1050 graphs, which we structure as 42 figures with 5 &#215; 5 panels. It is neither feasible nor instructive to present all figures in this report. The figures are included in <xref ref-type="supplementary-material" rid="pone.0220889.s001">S1 Appendix</xref>. Most of the graphs manifest qualitatively similar patterns and in the results section we present, what we deem to be a fair and representative selection. In particular we present for each distribution the results for a particular pair of values of <inline-formula id="pone.0220889.e094"><alternatives><graphic id="pone.0220889.e094g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e094" ns0:type="simple" /><ns1:math display="inline" id="M94"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and of the nuisance parameter. These values are listed in the third and the sixth column of <xref ref-type="table" rid="pone.0220889.t002">Table 2</xref>.</p>
<sec id="sec022">
<title>3.1 Generalized gamma distribution</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> displays the results for Gamma distribution with <italic>c</italic><sub><italic>n</italic></sub> = 1 and <inline-formula id="pone.0220889.e095"><alternatives><graphic id="pone.0220889.e095g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e095" ns0:type="simple" /><ns1:math display="inline" id="M95"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:mn>0</ns1:mn> <ns1:mo>.</ns1:mo> <ns1:mn>25</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>. In the first panel, the raw group difference converges to zero and the CI gets narrower as <italic>c</italic><sub><italic>l</italic></sub> decreases. Accordingly, as <italic>c</italic><sub><italic>l</italic></sub> decreases, Bayesian <italic>t</italic>-test and TOST switch to support the group equivalence. In contrast, the difference between log-transformed group data oscillates around the true value, with CI getting wider as <italic>c</italic><sub><italic>l</italic></sub> CL decreases. Accordingly, log-TOST does not suggest equivalence for low <italic>c</italic><sub><italic>l</italic></sub>, however the Bayesian log-<italic>t</italic>-test still switches to incorrect conclusion and shows only marginal improvement compared to Bayesian <italic>t</italic>-test on raw data. Cohen&#8217;s <italic>d</italic> goes towards zero with decreasing <italic>c</italic><sub><italic>l</italic></sub> for both raw and log data. Accordingly, <italic>t</italic>-test and log <italic>t</italic>-test both fail to detect a group difference for low <italic>c</italic><sub><italic>l</italic></sub>, with log-<italic>t</italic>-test showing better performance of up to 6.9 percentage points (pp) over raw <italic>t</italic>-test. The rank-based test manifests similar performance (up to 3.2 pp difference) as log-<italic>t</italic>-test, while trimmed <italic>t</italic>-test shows biggest gap to log-<italic>t</italic>-test with up to 20 pp. The test performance in the three group design provides similar results, with <italic>F</italic>-test trailing by up to 10.1 pp behind log-<italic>F</italic>-test and the rank-based test, while all three tests show a switch from group difference detection to no detection as the floor effect increases in magnitude.</p>
<fig id="pone.0220889.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Results obtained with Generalized Gamma distribution.</title>
<p>The panels are referred to in order from left to right, from top to bottom. Horizontal axis in each panel shows <italic>c</italic><sub><italic>l</italic></sub> (<inline-formula id="pone.0220889.e096"><alternatives><graphic id="pone.0220889.e096g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e096" ns0:type="simple" /><ns1:math display="inline" id="M96"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mi>A</ns1:mi></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mn>0</ns1:mn></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula> to be precise). The colored polygons in the first panel show the mean group difference (thick line) and its 95% CI (surface). The blue color shows results with log-transformed data while the red color shows results with raw data. The second panel shows Cohen&#8217;s <italic>d</italic> along with CIs. The layout is similar to the layout of the first panel. The third panel shows results of the TOST equivalence testing procedure. The vertical axis shows the proportion of cases which supported group equivalence. In the fourth panel, the vertical axis shows the probability of the hypothesis of group mean equivalence relative to the hypothesis of a group mean difference. The blue and the red color in the third and fourth panel designate whether the methods are applied to transformed or raw data. The vertical axis in the fifth and sixth panel shows the proportion of rejections of null hypothesis (group equivalence). Fifth panel shows results from <italic>t</italic>-test (red), log-<italic>t</italic>-test (blue), MW test (green) and trimmed <italic>t</italic>-test (yellow). The sixth panel show results from three-level-<italic>F</italic>-test with transformed data (blue) and raw data (red). The green line shows results of KW test. The values in panels one, two and four were obtained as median across replications.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g003" ns0:type="simple" />
</fig>
<p>Other choices of <inline-formula id="pone.0220889.e097"><alternatives><graphic id="pone.0220889.e097g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e097" ns0:type="simple" /><ns1:math display="inline" id="M97"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and <italic>c</italic><sub><italic>n</italic></sub> do not affect the qualitative nature of the results. Note that <italic>c</italic><sub><italic>n</italic></sub> and <inline-formula id="pone.0220889.e098"><alternatives><graphic id="pone.0220889.e098g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e098" ns0:type="simple" /><ns1:math display="inline" id="M98"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> function both as scale with respect to E[<italic>logX</italic>]. When statistical methods are applied to log-transformed data, then, a different choice of <inline-formula id="pone.0220889.e099"><alternatives><graphic id="pone.0220889.e099g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e099" ns0:type="simple" /><ns1:math display="inline" id="M99"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and <italic>c</italic><sub><italic>n</italic></sub> merely scales <italic>c</italic><sub><italic>l</italic></sub> and stretches or shrinks the horizontal axis in <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. With respect to E[<italic>X</italic>], higher values of <inline-formula id="pone.0220889.e100"><alternatives><graphic id="pone.0220889.e100g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e100" ns0:type="simple" /><ns1:math display="inline" id="M100"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and <italic>c</italic><sub><italic>n</italic></sub> make CI tighter, increase the mean group difference but also affect the shape of CI. The performance gaps between the tests increase as <inline-formula id="pone.0220889.e101"><alternatives><graphic id="pone.0220889.e101g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e101" ns0:type="simple" /><ns1:math display="inline" id="M101"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and <italic>c</italic><sub><italic>n</italic></sub> increase with the absolute test performance increasing as well.</p>
</sec>
<sec id="sec023">
<title>3.2 Wald distribution</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g004">Fig 4</xref> displays the results for Wald distribution with <italic>&#963;</italic> = 1 and <inline-formula id="pone.0220889.e102"><alternatives><graphic id="pone.0220889.e102g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e102" ns0:type="simple" /><ns1:math display="inline" id="M102"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:mn>0</ns1:mn> <ns1:mo>.</ns1:mo> <ns1:mn>25</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>. Note that the severity of floor effect increases as <italic>b</italic> increases. We inverted the horizontal axis in <xref ref-type="fig" rid="pone.0220889.g004">Fig 4</xref> to facilitate comparison between figures. CI of the group difference decreases towards zero with both raw data and with the log-transformed data. Both CIs become narrower as the magnitude of floor effect increases. The CIs of Cohen&#8217;s <italic>d</italic> are identical for both types of data, with Cohen&#8217;s <italic>d</italic> decreasing towards zero. As a consequence the <italic>t</italic>-test and log <italic>t</italic>-test (and MW test as well) show similar performance. Trimmed <italic>t</italic>-test performs worst with a gap of up to 20% to <italic>t</italic>-test. All two group and three group tests manifest a decrease in performance as the magnitude of the floor effect increases. As the floor effect becomes stronger, both TOST and Bayesian <italic>t</italic>-test switch to support group equivalence.</p>
<fig id="pone.0220889.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Results obtained with Wald distribution.</title>
<p>The figure layout follows the layout of <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. Refer to <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g004" ns0:type="simple" />
</fig>
<p>Adjustments to <italic>&#963;</italic> and <inline-formula id="pone.0220889.e103"><alternatives><graphic id="pone.0220889.e103g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e103" ns0:type="simple" /><ns1:math display="inline" id="M103"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> alter the scale and offset of <italic>b</italic> but otherwise do not change qualitative nature of the results. Higher values of <inline-formula id="pone.0220889.e104"><alternatives><graphic id="pone.0220889.e104g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e104" ns0:type="simple" /><ns1:math display="inline" id="M104"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and lower values of <italic>&#963;</italic> lead to better test performance and gaps between the tests are larger when both values are large. These adjustments also suggest the test performance does not converge to zero. The performance at the convergence point depends on <italic>&#963;</italic> and <inline-formula id="pone.0220889.e105"><alternatives><graphic id="pone.0220889.e105g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e105" ns0:type="simple" /><ns1:math display="inline" id="M105"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec024">
<title>3.3 Beta prime distribution</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g005">Fig 5</xref> shows the results for Beta Prime distribution with <italic>c</italic><sub><italic>n</italic></sub> = 0.15 and <inline-formula id="pone.0220889.e106"><alternatives><graphic id="pone.0220889.e106g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e106" ns0:type="simple" /><ns1:math display="inline" id="M106"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:mn>2</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>. The mean group difference is negative but close to zero, while the mean group difference of log-scaled data oscillates around the true value of <inline-formula id="pone.0220889.e107"><alternatives><graphic id="pone.0220889.e107g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e107" ns0:type="simple" /><ns1:math display="inline" id="M107"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>. In both cases the CI becomes wider as <italic>c</italic><sub><italic>l</italic></sub> decreases. The test performance in the two-group and in the three group scenario decreases with decreases in <italic>c</italic><sub><italic>l</italic></sub>. The performance of <italic>t</italic>-test and <italic>F</italic>-test with raw data is in the range [0, 0.1] irrespective of <italic>c</italic><sub><italic>l</italic></sub>. Similar, Bayesian <italic>t</italic>-test indicates support for no difference from zero with raw data irrespective of <italic>c</italic><sub><italic>l</italic></sub>, but with log-data Bayesian <italic>t</italic>-test switches from support of difference to support of no difference. Log-<italic>t</italic>-test and log-<italic>F</italic>-test show best performance, which is followed by rank-based tests (gap of up to 20.1 and 19.4 pp respectively) and by trimmed <italic>t</italic>-test (gap of up to 60.8 pp). TOST rarely detects equivalence because the TOST threshold is too conservative.</p>
<fig id="pone.0220889.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Results obtained with Beta Prime distribution.</title>
<p>The figure layout follows the layout of <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. Refer to <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g005" ns0:type="simple" />
</fig>
<p>Large values of <italic>c</italic><sub><italic>n</italic></sub> and <inline-formula id="pone.0220889.e108"><alternatives><graphic id="pone.0220889.e108g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e108" ns0:type="simple" /><ns1:math display="inline" id="M108"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> increase the (negative) mean difference and the width of the CI. The CI of the log-transformed data is unaffected. Finally, larger <inline-formula id="pone.0220889.e109"><alternatives><graphic id="pone.0220889.e109g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e109" ns0:type="simple" /><ns1:math display="inline" id="M109"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> result in better test performance, including the performance of Bayesian <italic>t</italic>-test on log-scaled data.</p>
</sec>
<sec id="sec025">
<title>3.4 Beta distribution</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g006">Fig 6</xref> shows the results for Beta distribution with <italic>c</italic><sub><italic>u</italic></sub> = &#8722;0.2 and <inline-formula id="pone.0220889.e110"><alternatives><graphic id="pone.0220889.e110g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e110" ns0:type="simple" /><ns1:math display="inline" id="M110"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:mn>3</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>. Recall, that in this case logit transform is used instead of log transform. The difference in mean of logit values oscillates around the true value while with raw data the difference decreases towards zero with decreasing <italic>c</italic><sub><italic>l</italic></sub>. In the former case the CI width increases as the magnitude of floor effect increases, while in the latter case it remains constant. Cohen&#8217;s <italic>d</italic> of both raw and logit data decreases with decreasing <italic>c</italic><sub><italic>l</italic></sub> while the corresponding CI remains constant. The logit <italic>t</italic>-test shows best test performance followed by rank based test with a gap of up to 19.1 pp and raw <italic>t</italic>-test and trimmed <italic>t</italic>-test with even larger gaps. In all four cases, a switch from high rejection rate to low rejection rate is observed as <italic>c</italic><sub><italic>l</italic></sub> decreases. The scenario with three groups shows similar results. Bayesian <italic>t</italic>-test switches to support equivalence rather than group difference as <italic>c</italic><sub><italic>l</italic></sub> decreases. As in previous section, the TOST thresholds are too conservative to detect equivalence. However a switch to support equivalence can be observed when TOST is applied to data generated with larger values of <inline-formula id="pone.0220889.e111"><alternatives><graphic id="pone.0220889.e111g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e111" ns0:type="simple" /><ns1:math display="inline" id="M111"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>.</p>
<fig id="pone.0220889.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Results obtained with Beta distribution.</title>
<p>The figure layout follows the layout of <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. Refer to <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g006" ns0:type="simple" />
</fig>
<p>Larger <inline-formula id="pone.0220889.e112"><alternatives><graphic id="pone.0220889.e112g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e112" ns0:type="simple" /><ns1:math display="inline" id="M112"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and smaller <italic>c</italic><sub><italic>u</italic></sub> improve the test performance. Smaller values of <italic>c</italic><sub><italic>u</italic></sub> make CIs narrower while <inline-formula id="pone.0220889.e113"><alternatives><graphic id="pone.0220889.e113g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e113" ns0:type="simple" /><ns1:math display="inline" id="M113"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> increases the mean difference. In all cases, the logit-based difference estimate matches the true group difference <inline-formula id="pone.0220889.e114"><alternatives><graphic id="pone.0220889.e114g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e114" ns0:type="simple" /><ns1:math display="inline" id="M114"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec026">
<title>3.5 Beta-binomial distribution</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g007">Fig 7</xref> shows the results for Beta distribution with <italic>c</italic><sub><italic>u</italic></sub> = &#8722;0.3, <italic>n</italic> = 7 and <inline-formula id="pone.0220889.e115"><alternatives><graphic id="pone.0220889.e115g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e115" ns0:type="simple" /><ns1:math display="inline" id="M115"><ns1:mrow><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup> <ns1:mo>=</ns1:mo> <ns1:mn>4</ns1:mn></ns1:mrow></ns1:math></alternatives></inline-formula>. In this case the blue color highlights a transformation with logit function. For both transformed and raw data, the CIs are similar: the mean decreases with decreasing <italic>c</italic><sub><italic>l</italic></sub> while the CI width remains constant. Similar pattern is observed with Cohen&#8217;s <italic>d</italic>. The rank-based test performs best with a gap of up to 25.3 pp to logit <italic>t</italic>-test. The logit <italic>t</italic>-test shows better performance than the raw <italic>t</italic>-test when the data are unaffected by floor effect. Trimmed <italic>t</italic>-test performs worst with a gap of up to 49.9 pp to rank-based test. Similar results are obtained in the three group scenario, with rank-based test showing the best performance. Larger <inline-formula id="pone.0220889.e116"><alternatives><graphic id="pone.0220889.e116g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e116" ns0:type="simple" /><ns1:math display="inline" id="M116"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and larger values of <italic>n</italic> improve the test performance. Both <italic>n</italic> and <inline-formula id="pone.0220889.e117"><alternatives><graphic id="pone.0220889.e117g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e117" ns0:type="simple" /><ns1:math display="inline" id="M117"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> increase the mean difference, while higher <italic>n</italic> results in wider CI.</p>
<fig id="pone.0220889.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Results obtained with Beta-binomial distribution.</title>
<p>The figure layout follows the layout of <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. Refer to <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g007" ns0:type="simple" />
</fig>
<p>With more severe floor effect, Bayesian <italic>t</italic>-test favours hypothesis of no group difference. TOST once again does not detect equivalence as the thresholds are too conservative.</p>
</sec>
<sec id="sec027">
<title>3.6 Ordinal logistic regression model</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g008">Fig 8</xref> shows the results for OLRM with <italic>&#963;</italic> = 0.8 and thresholds at &#8722;3, &#8722;1, 1, 3. Again, blue lines show results for data transformed with logit function. In this case <italic>c</italic><sub><italic>l</italic></sub> = &#8722;<italic>c</italic><sub><italic>u</italic></sub>. We used this fact to show both floor and ceiling effect in <xref ref-type="fig" rid="pone.0220889.g008">Fig 8</xref>. As <italic>c</italic><sub><italic>l</italic></sub> decreases, floor effect increases, while as <italic>c</italic><sub><italic>l</italic></sub> increases, the ceiling effect increases in magnitude. Note that one of the groups was further offset with respect to <italic>c</italic><sub><italic>l</italic></sub> on the horizontal axis, which explains why the graphs are not fully symmetric around <italic>c</italic><sub><italic>l</italic></sub> = 0. With ceiling and floor effect the positive mean difference goes to zero and the CI becomes narrower. This is true for both raw and transformed data as well as their Cohen&#8217;s <italic>d</italic>. The test performance decreases as the magnitude of ceiling and floor effect increases. Regarding test comparison, all tests with exception of trimmed <italic>t</italic>-test show comparable performance. TOST supports equivalence at floor and at ceiling. Similar, Bayesian <italic>t</italic>-test favours equivalence at ceiling and at floor. Note that in principle the simulation could be extended beyond <italic>c</italic><sub><italic>l</italic></sub> = &#8722;5 and <italic>c</italic><sub><italic>l</italic></sub> = 5, however at <italic>c</italic><sub><italic>l</italic></sub> = &#8722;5 already more than 90% of values are zero, and the presence of the floor effect should be apparent to an investigator.</p>
<fig id="pone.0220889.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Results obtained with OLRM.</title>
<p>The figure layout follows the layout of <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>. Refer to <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref> for details.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g008" ns0:type="simple" />
</fig>
</sec>
<sec id="sec028">
<title>3.7 Two-way factor design</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g009">Fig 9</xref> shows the comparison of detection rate of rank-based SRHT (green) with ANOVA (red) and with ANOVA on transformed data (blue). Log transform is used with positive outcomes in the first three columns. Logit transform is used with bounded outcome in fourth, fifth and sixth column. Dotted lines show the stronger main effect, dashed line shows the weaker main effect and full line shows the interaction. The vertical axis shows the proportion of rejections of hypothesis that there is no main effect/interaction. As in previous section, horizontal axis shows the values of parameters used to create floor effect. The floor effect increases in the negative (to the left) direction of the horizontal axis. This is true of Wald distribution as well, in which case we reversed the values of <italic>b</italic> such that higher values are located towards the left part of the axis. The panel columns show six different data generating processes, while the rows show five different main effect/interaction constellations. These constellations were described in <xref ref-type="fig" rid="pone.0220889.g002">Fig 2</xref>. Most importantly, recall that in the &#8220;no X&#8221; situation there were two main effects but no interaction, &#8220;no ME&#8221; labels situation with interaction but no main effects and in the remaining three situations both main effects and an interaction occurred.</p>
<fig id="pone.0220889.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Performance with 2 &#215; 2 factor design.</title>
<p>Figure shows the comparison of detection rate of rank-based SRHT (green) with ANOVA (red) and with ANOVA on transformed data (blue). Further details are provided in the text.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g009" ns0:type="simple" />
</fig>
<p>First, note that over all conditions the detection performance decreased as the magnitude of the floor effect increased. In the &#8220;no X&#8221; situation there were two main effects but no interaction. The tests mostly managed to detect the main effects when the floor effect was weak. The tests correctly avoided detection of interaction in most cases. As an exception, <italic>F</italic>-test (with raw data) detected interaction when the floor effect was weak while the data were generated from Gamma or Wald distribution. <italic>F</italic>-test furthermore failed to detect the stronger main effect with Beta prime and Beta distribution (columns 3 and 4), which was in contrast with the other two methods. SRHT outperformed the other two tests on Beta-binomial data, while with Beta prime and Beta distributed data the log <italic>F</italic>-test showed slight advantage over SRHT.</p>
<p>&#8220;no ME&#8221; labels the situation with an interaction but no main effects. All methods correctly avoided detecting main effects. Raw ANOVA encountered problems with detecting interaction when the data were generated from Beta and Beta prime distribution. In these cases the log <italic>F</italic>-test displayed a power advantage over SRHT. In contrast, SRHT was most successful at detecting interaction when data were generated from Beta-binomial distribution.</p>
<p>In the remaining three situations both main effects and an interaction occurred. Note that the three results in the last three rows are very similar, except they show different permutations between the two main effects and the interaction. Compare the third and fourth row: if one exchanges the dashed and the full lines, one obtains results that are very similar. Between the fourth and the fifth row, the dotted and full lines are swapped. This is perhaps not surprising as the three different interaction types were obtained by swapping the true mean values between factors.</p>
<p>All three statistical methods encountered problems detecting uncrossed interaction. The sole exception was log-ANOVA on Gamma distributed data when the floor effect was weak. Accordingly, all tests (again with exception of log-ANOVA on Gamma distributed data) encountered problems detecting the weaker main effect (dashed lines) in the presence of crossed and double-crossed interaction. Regarding main effects that accompanied the uncrossed interaction, ANOVA with transformed data showed best performance followed by rank-based test and ANOVA. Again, when the data are generated from Beta Prime and Beta distribution <italic>F</italic> test with transformed data showed advantage over SRHT, while SRHT benefited in the case of Beta-binomial distribution. In all these three cases the raw <italic>F</italic>-test showed poor performance at detecting the main effects. When data were generated from Ordered Logistic model, the three tests showed similar performance.</p>
<p>In the scenario with no interaction (&#8220;no X&#8221;) and with uncrossed interaction when the data were generated from Beta, Beta prime and Beta-binomial distribution, the reader may wonder what the interaction detection performance would look like, if one would select larger <italic>c</italic><sub><italic>l</italic></sub>. Due to the constraints of the beta function such choice is not possible, one may however increase the effect size i.e. scale the group differences to facilitate easier detection. The last figure in <xref ref-type="supplementary-material" rid="pone.0220889.s001">S1 Appendix</xref> shows the detection rate in the 2 &#215; 2 factor scenario with <inline-formula id="pone.0220889.e118"><alternatives><graphic id="pone.0220889.e118g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e118" ns0:type="simple" /><ns1:math display="inline" id="M118"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> set to the upper bound listed in the fourth column in <xref ref-type="table" rid="pone.0220889.t002">Table 2</xref>. The figure indicates that for large <italic>c</italic><sub><italic>l</italic></sub> in &#8220;no X&#8221; scenario SRHT provides at least some support for interaction with data from Beta, Beta prime and Beta-binomial distribution. The interaction detection performance of the other two methods remains unaffected. The larger <inline-formula id="pone.0220889.e119"><alternatives><graphic id="pone.0220889.e119g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e119" ns0:type="simple" /><ns1:math display="inline" id="M119"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> does not improve detection of uncrossed interaction for these three distributions. Interestingly, raw <italic>F</italic>-test outperforms log <italic>F</italic>-test when <inline-formula id="pone.0220889.e120"><alternatives><graphic id="pone.0220889.e120g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e120" ns0:type="simple" /><ns1:math display="inline" id="M120"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and <italic>c</italic><sub><italic>l</italic></sub> are large.</p>
</sec>
<sec id="sec029">
<title>3.8 Parameter recovery with Ordered logistic regression and Beta-binomial distribution</title>
<p>As shown in Sections 3.5 and 3.6, the application of logit transformation to discrete data did not provide a performance improvement relative to methods applied to untransformed data. Such result raises the question, whether this outcome describes an ineffectiveness of the selected transformation or whether the discrete data present a more general inferential challenge, that requires a rank-based solution. In this section we provide clarification by fitting OLRM and Beta-binomial distribution to data generated from OLRM. As already mentioned in the introduction, the difficulty with this procedure is computational one. The analytic results for parameter estimation with OLRM or Beta-binomial distribution under the parametrization used in the current work are not available in the literature. Approximate methods are available but computationally expensive. For these reasons, parameter recovery (i.e. the same model is used to generate and fit the data) was avoided in the previous sections even though it would provide interesting information about the best-case performance. For these reasons, the current section does not consider performance across 10000 repetitions and nor does it consider performance across a range of nuisance parameters. Only a single research scenario is considered. To make the choice of the scenario less arbitrary and less artificial, we adapt the research scenario discussed in the introduction. We ask how the magnitude of ceiling effect would affect the conclusions regarding the replication attempt by [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>]. In particular, we fitted OLRM to the data from [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>]. We estimated the difficulty separately for each of the six items in the original study and we estimated a separate set of parameters for the replication study. The item difficulty of the control group was <italic>c</italic><sub><italic>u</italic></sub> while the item difficulty of the experimental group was <inline-formula id="pone.0220889.e121"><alternatives><graphic id="pone.0220889.e121g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e121" ns0:type="simple" /><ns1:math display="inline" id="M121"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub> <ns1:mo>+</ns1:mo> <ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula> The thresholds <inline-formula id="pone.0220889.e122"><alternatives><graphic id="pone.0220889.e122g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e122" ns0:type="simple" /><ns1:math display="inline" id="M122"><ns1:mrow><ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>k</ns1:mi></ns1:msub> <ns1:mo>&#8712;</ns1:mo> <ns1:mi mathvariant="double-struck">R</ns1:mi></ns1:mrow></ns1:math></alternatives></inline-formula> were pooled across the items and across the datasets. The group difference <inline-formula id="pone.0220889.e123"><alternatives><graphic id="pone.0220889.e123g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e123" ns0:type="simple" /><ns1:math display="inline" id="M123"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> was identical across items but two separate parameters were used for original and replication sample. In the second step, multiple sets of fake data were generated from the OLRM with thresholds and with the group difference fixed to the median estimates obtained from the original study in the previous step. Similar to the procedure that was used to obtain the results in section 3.6, <italic>c</italic><sub><italic>u</italic></sub> was varied in order to adjust the magnitude of the ceiling effect. OLRM was fitted to each fake data set. Note that a separate <italic>c</italic><sub><italic>u</italic></sub>, <inline-formula id="pone.0220889.e124"><alternatives><graphic id="pone.0220889.e124g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e124" ns0:type="simple" /><ns1:math display="inline" id="M124"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> and a separate set of thresholds was estimated for each fake dataset. Since no repetitions were available, only the median estimate of the group difference <inline-formula id="pone.0220889.e125"><alternatives><graphic id="pone.0220889.e125g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e125" ns0:type="simple" /><ns1:math display="inline" id="M125"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> along with 95% percentage interval is shown. Markov chain Monte Carlo method was used to obtain the estimates. The technical details of this method are provided in section 2.3.</p>
<p>The left panel of <xref ref-type="fig" rid="pone.0220889.g010">Fig 10</xref> shows the estimate of the group difference (vertical axis) as a function of the ceiling effect which increases from left to right. The median estimate (black) matches the true group difference (blue). The width of 95% interval (gray surface) increases as the magnitude of the ceiling effect (and of the floor effect as well) increases.</p>
<fig id="pone.0220889.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Parameter recovery with Ordered logistic regression and Beta-binomial distribution.</title>
<p>Figure shows the estimate of group difference <inline-formula id="pone.0220889.e126"><alternatives><graphic id="pone.0220889.e126g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e126" ns0:type="simple" /><ns1:math display="inline" id="M126"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> on vertical axis that was obtained by fitting OLRM (left panel) and Beta-binomial distribution (right panel) to the data generated with OLRM by manipulating the magnitude of ceiling effect <italic>c</italic><sub><italic>u</italic></sub>. <italic>c</italic><sub><italic>u</italic></sub> is shown on the horizontal axis and the magnitude of the ceiling effect increases from left to right. In reference to the precise notation in section 2.3, the black line shows the median estimate of the group difference <inline-formula id="pone.0220889.e127"><alternatives><graphic id="pone.0220889.e127g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e127" ns0:type="simple" /><ns1:math display="inline" id="M127"><ns1:msub><ns1:mi>d</ns1:mi> <ns1:msub><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi></ns1:msub></ns1:msub></ns1:math></alternatives></inline-formula>, while the gray surface shows the estimate&#8217;s 95% interval. The blue line shows the true value used by OLRM that generated the data and the true value corresponds to an OLRM estimate of group difference in [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>] (i.e. median estimate of <italic>d</italic><sub>0</sub>). The crosses show the difficulty of the six items (i.e. <inline-formula id="pone.0220889.e128"><alternatives><graphic id="pone.0220889.e128g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e128" ns0:type="simple" /><ns1:math display="inline" id="M128"><ns1:msubsup><ns1:mi>b</ns1:mi> <ns1:mi>i</ns1:mi> <ns1:mi>s</ns1:mi></ns1:msubsup></ns1:math></alternatives></inline-formula>) in the original study (green [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>]) and in the replication study (red [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>]), while <italic>c</italic><sub><italic>i</italic></sub> and grid lines of the horizontal axis show the OLRM thresholds obtained by pooling the original and replication data.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g010" ns0:type="simple" />
</fig>
<p>As already argued in the introduction, parameter recovery can be useful for estimating the best-case performance, but we don&#8217;t think it demonstrates superiority of the fitting/generating model over some other statistical model fitted to the same data. Thus the results in the left panel of <xref ref-type="fig" rid="pone.0220889.g010">Fig 10</xref> can&#8217;t be used to argue for superiority of OLRM&#8217;s performance over the performance of, say, linear methods that were considered in section 3.6. Hence we added a final investigation in which the group difference was estimated with Beta-binomial model with parameters <italic>c</italic><sub><italic>l</italic></sub> and <italic>c</italic><sub><italic>u</italic></sub>. The results are shown in the right panel of <xref ref-type="fig" rid="pone.0220889.g010">Fig 10</xref>. The median group difference is not constant and does not match the true group difference of OLRM. However, similar to the OLRM estimate, the width of the percentage interval increases as the magnitude of the ceiling effect increases.</p>
<p>The crosses in <xref ref-type="fig" rid="pone.0220889.g010">Fig 10</xref> show the difficulty of the six items in the original study (green [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>]) and in the replication study (red [<xref ref-type="bibr" rid="pone.0220889.ref002">2</xref>]), while the ticks on the horizontal axis show the OLRM thresholds obtained by pooling the original and the replication data. Items were more difficult in the replication study than in the original study. To return to the question from the opening of the introduction: does the stronger ceiling effect in the replication study mask the significant group difference? If we consider the question whether the probability that the group difference <inline-formula id="pone.0220889.e129"><alternatives><graphic id="pone.0220889.e129g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e129" ns0:type="simple" /><ns1:math display="inline" id="M129"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> is smaller than zero, is smaller than 0.025, then the answer is no. Across all items the lower bound of the OLRM percentage interval does not cross zero for all levels of <italic>c</italic><sub><italic>l</italic></sub> that correspond to the item&#8217;s difficulty. This is true for <inline-formula id="pone.0220889.e130"><alternatives><graphic id="pone.0220889.e130g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e130" ns0:type="simple" /><ns1:math display="inline" id="M130"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>u</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> of Beta-binomial model, with the exception of the most difficult item. If the original and the replication study consisted of six items with difficulty of the sixth item, then the significant group difference would disappear in the replication study due to the ceiling effect. However, considering the actual difficulty of the items in the replication study, in the context of estimation with Beta-binomial distribution, such disappearance is highly unlikely.</p>
</sec>
<sec id="sec030">
<title>3.9 Mean, variance and skewness</title>
<p>
<xref ref-type="fig" rid="pone.0220889.g011">Fig 11</xref> shows how the magnitude of floor effect affects the expectation, variance and skewness of the distributions shown in columns. Note that OLRM manifests ceiling effect as well as floor effect, because <italic>c</italic><sub><italic>l</italic></sub> = &#8722;<italic>c</italic><sub><italic>u</italic></sub>. To facilitate the comparison, the values obtained with Beta distribution, Beta-binomial and OLRM were scaled to interval [0, 1]. With exception of Beta prime distribution the mean decreases as <italic>c</italic><sub><italic>l</italic></sub> decreases. The variance goes to zero for Gamma distribution and Wald distribution while in the case of Beta prime distribution the variance increases with decreasing <italic>c</italic><sub><italic>l</italic></sub>. To consider Beta and Beta-binomial distribution, as <italic>c</italic><sub><italic>l</italic></sub> decreases, the variance initially increases, reaches maximum at <italic>c</italic><sub><italic>l</italic></sub> = <italic>c</italic><sub><italic>u</italic></sub> (which corresponds to <italic>a</italic> = <italic>b</italic>) and then decreases as <italic>c</italic><sub><italic>l</italic></sub> &lt; <italic>c</italic><sub><italic>u</italic></sub>. The variance of OLRM shows maximum at <italic>c</italic><sub><italic>l</italic></sub> = 0 while the skew is zero at this point. As <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8722;&#8734; the variance goes to zero and the distribution manifests a positive skew. As <italic>c</italic><sub><italic>l</italic></sub> &#8594; &#8734;, the distribution shows a negative skew and its variance goes to zero. With the exception of OLRM, the skew is positive. For all distributions except the Wald distribution, the skew is increasing as <italic>c</italic><sub><italic>l</italic></sub> decreases.</p>
<fig id="pone.0220889.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0220889.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Effect of CFE on mean, variance and skewness.</title>
<p>Figure shows how the magnitude of floor effect affects the expectation, variance and skewness of the distributions shown in columns. In each panel, the magnitude of the floor effect increases from right to the left. Further details are provided in the text.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.g011" ns0:type="simple" />
</fig>
<p>The distributions mostly satisfy all CFE conditions. One exception is Wald distribution which manifests decreasing skew and thus fails the fourth condition. Beta Prime distribution provides the complementary case, it satisfies only the fourth condition and fails the remaining conditions. Note that the second condition can be checked by considering the mean difference shown in first panel of the preceding figures from results section. All mean differences, with exception of Beta Prime distribution, are decreasing with decreasing <italic>c</italic><sub><italic>l</italic></sub>.</p>
</sec>
</sec>
<sec id="sec031" sec-type="conclusions">
<title>4 Discussion</title>
<sec id="sec032">
<title>4.1 Bias and uncertainty due to CFE</title>
<p>We first organize and digest the presented findings. When considering the performance of inferential methods we find it advantageous to distinguish the categories of inferential outcomes listed below. These categories are not meant to be exhaustive or precise. The categories are intended to help us refer to certain phenomena and to facilitate the subsequent discussion.</p>
<sec id="sec033">
<title>Correct inference</title>
<p>One may imagine an ideal case in which there is no statistical bias (i.e. the magnitude of CFE does not alter the mean group difference) and no added uncertainty due to CFE (i.e. the magnitude of CFE does not affect the width of CI). Such scenario was not encountered in the current study.</p>
</sec>
<sec id="sec034">
<title>Noisy inference</title>
<p>In this scenario, CFE increases uncertainty but does not cause bias. Noisy inference is perhaps an intuitively acceptable outcome: if the measurement tool fails to provide accurate information, it is desirable to recognize the situation as such and to avoid over-confident inferences. All of the considered inferential methods do offer an inferential outcome option which implies a noisy inference scenario. Exceptions are <italic>t</italic>-test, <italic>F</italic>-test and rank-based tests, where a failure to reject null hypothesis, may signal both inferential uncertainty <italic>and</italic> a situation in which the null hypothesis is true. Noisy inference is apparent from confidence intervals that were obtained with log and logit transformed data from Gamma, Beta and Beta Prime distribution. Noisy inference was further found in the investigation of parameter recovery with OLRM which was reported in the left panel of <xref ref-type="fig" rid="pone.0220889.g010">Fig 10</xref>. This results also suggests that noisy inference is the best-case scenario, when the uncertainty about the functional formulation of the parametric model is removed.</p>
</sec>
<sec id="sec035">
<title>Biased noisy inference</title>
<p>In this scenario CFE creates both bias and increases uncertainty. In most cases CFE caused a bias of the mean difference towards zero. Biased noisy inference with bias towards zero was observed with untransformed data from Beta and Beta prime distribution. Furthermore, biased noisy inference with bias towards zero was observed with transformed data from Beta-binomial distribution. When fitting the Beta-binomial model to data from OLRM, CFE amplified the group difference.</p>
<p>Biased noisy inference may be considered as a fortunate outcome, since the increasing uncertainty prevents a biased conclusion. Similar fortunate outcome occurs in scenarios with bias and large but constant uncertainty and hence we include these in the category of biased noisy inference. Estimates of Cohen&#8217;s <italic>d</italic> and its CI and perhaps the mean difference estimates with raw data from Beta and Beta-binomial distribution manifest bias towards zero which is dominated by noise.</p>
</sec>
<sec id="sec036">
<title>Biased inference</title>
<p>Biased inference is the worst inferential outcome, in which the inferential method supports the incorrect conclusion and the inferential method becomes more certain about the incorrect conclusion as CFE increases. All biased confidence intervals that become narrower as magnitude of CFE increases fall into this category. Such is the case with raw CIs of Gamma distribution, Wald distribution and OLRM as well as with log CIs of Wald distribution and logit CIs of OLRM.</p>
</sec>
<sec id="sec037">
<title>Test performance gap</title>
<p>As already stated, the performance of <italic>F</italic>-test and <italic>t</italic>-test do not fit well in the above mentioned categories, because they do not permit a distinction between bias and uncertainty, since a failure to reject null hypothesis may be caused by each of these or their combination. Rather the outcomes differ in what we label as test performance gap. In most test cases the detection rate goes from one to zero as the CFE magnitude increases. The tests differ in terms of the onset of this degradation. As the performance starts to degrade, gaps between the tests open up. All test scenarios manifest such a gap perhaps with the exception of Wald distribution and OLRM, where the performance gaps are too small to consider them as reliable. In most cases when such power gap opens up the test with transformed data performs best, followed closely by rank-based test and followed by a wider margin by test on raw data and the trimmed <italic>t</italic>-test. A notable exception is the case of Beta-binomial distribution in which the rank-based test performs best followed by a transformation-based test. Note that this applies across all three research scenarios: two groups, three groups and 2 &#215; 2 factorial design.</p>
<p>It should be noted that similar power gaps were observed in power studies that investigate the robustness of parametric and non-parametric methods, see for instance figures in [<xref ref-type="bibr" rid="pone.0220889.ref046">46</xref>, <xref ref-type="bibr" rid="pone.0220889.ref058">58</xref>, <xref ref-type="bibr" rid="pone.0220889.ref103">103</xref>]. In these studies, the standardized effect size was drawn on the horizontal axis, which suggests that standardized effect size and the magnitude of CFE are related. The top-right panel in Figs <xref ref-type="fig" rid="pone.0220889.g003">3</xref>, <xref ref-type="fig" rid="pone.0220889.g004">4</xref>, <xref ref-type="fig" rid="pone.0220889.g005">5</xref>, <xref ref-type="fig" rid="pone.0220889.g006">6</xref>, <xref ref-type="fig" rid="pone.0220889.g007">7</xref> and <xref ref-type="fig" rid="pone.0220889.g008">8</xref> confirms that this is the case. In all cases where a power gap opens up, Cohen&#8217;s d monotonically increases with <italic>c</italic><sub><italic>l</italic></sub>.</p>
</sec>
<sec id="sec038">
<title>Poor test performance irrespective of CFE</title>
<p>In the case of Beta Prime distribution the mean is inverse proportional to <italic>c</italic><sub><italic>l</italic></sub> and hence the <italic>t</italic>-test and <italic>F</italic>-test (in both three group and four group situation) do not open up a gap but rather consistently fail to reject the null hypothesis irrespective of the magnitude of CFE.</p>
</sec>
</sec>
<sec id="sec039">
<title>4.2 Performance of statistical methods when affected by CFE</title>
<p>The transformation-based and measurement-theory-motivated methods outperformed other methods with data from Gamma, Beta and Beta prime distribution and matched the performance of other methods with data from OLRM and Wald distribution. This can be observed in terms of performance gap in the two-group, in the three-group scenario and in the 2 &#215; 2 factor design. It can be also observed in terms of bias and uncertainty pattern manifested by CIs. Relative to the raw data application, transformation-based methods showed more often the more benevolent biased and biased noisy inference rather than biased inference.</p>
<p>With data from Beta-binomial distribution, the rank-based tests showed best performance. It is worth noting that in the case of Gamma, Beta and Beta prime distribution the choice of transformation function was derived from measurement theory while the measurement-theoretic considerations of Wald distribution suggested that CFE does not follow a log function. The choice of logit transform on discrete data did not take into account the discreteness. We think this is the main reason why logit transform failed to replicate the success of log and logit transform when these were applied to continuous data. The results in section 3.8 suggest that it is possible to obtain noisy inference (OLRM) or biased noisy inference (Beta-binomial) on discrete data with with the help of a generalized linear models which implicitly assumes existence of a non-additive concatenation operation. Whether these models can match the rank-based tests in terms of test performance can&#8217;t be determined from the current data and requires further research.</p>
<p>One may as well ask whether the rank-based tests are able to match the performance of transform-based <italic>F</italic>-test when applied to continuous data. Is there an information loss associated with rank-transformation and CFE? The rank-based tests manifest test performance gap to the transformation-based tests on data from Beta and Beta Prime distribution which suggests that there is a loss of information and performance. A similar performance loss of rank-based tests was observed in comparisons with <italic>t</italic>-test when the data were generated from normal distribution [<xref ref-type="bibr" rid="pone.0220889.ref046">46</xref>, <xref ref-type="bibr" rid="pone.0220889.ref055">55</xref>].</p>
<p>Welch&#8217;s <italic>t</italic>-test with raw data showed mixed results. For OLMR and Wald distribution it matched the performance of other tests, while for Gamma distribution the performance gap to log <italic>t</italic>-test was small. For Beta-binomial and Beta distribution the gap was wider and for Beta Prime distribution Welch test failed to reject null hypothesis irrespective of CFE due to the mean inversion. Beta Prime distribution did only satisfy one of the four CFE conditions, so perhaps it may be discarded as an odd result. With raw data the <italic>F</italic>-test in three-group design and the <italic>F</italic>-tests in the two factor design show a performance similar to <italic>t</italic>-test.</p>
<p>One should note at this point that the relative and absolute detection performance of MW test and raw <italic>t</italic>-test are similar to the power estimates in previous robustness research [<xref ref-type="bibr" rid="pone.0220889.ref051">51</xref>, <xref ref-type="bibr" rid="pone.0220889.ref064">64</xref>, <xref ref-type="bibr" rid="pone.0220889.ref103">103</xref>]. As mentioned in the introduction, several robustness studies generate data with exponential distribution while the (standardized) group difference was varied. Recognizing that exponential distribution is a special case of generalized gamma distribution and that, in the current study, the effect size varied proportionally with the magnitude of CFE, it is valid to make a comparison. One still needs to take into account that most earlier robustness studies used <italic>t</italic>-test that assumed equal group variance, while the current study uses Welch&#8217;s <italic>t</italic>-test. We are not aware of comparable robustness studies that focus on Wald, Beta prime, Beta, Beta-binomial distribution or some special case of these. The few available studies with OLRM do investigate the performance of linear regression models rather than hypothesis testing performance.</p>
<p>On few occasions, poor test performance was encountered with large values of <italic>c</italic><sub><italic>l</italic></sub>. In &#8220;no X&#8221; scenario with Gamma distribution and large values of <italic>c</italic><sub><italic>l</italic></sub>, the raw <italic>F</italic>-test provided some support for interaction and this support was stronger with larger <inline-formula id="pone.0220889.e131"><alternatives><graphic id="pone.0220889.e131g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e131" ns0:type="simple" /><ns1:math display="inline" id="M131"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>. In &#8220;no X&#8221; scenario with Wald distribution and large values of <italic>c</italic><sub><italic>l</italic></sub> raw <italic>F</italic>-test and log <italic>F</italic>-test provided some support for interaction. SRHT failed to detect uncrossed interaction of Gamma and Wald distribution (and accordingly failed to detect the weaker main effect in the scenario with crossed and double-crossed interaction). Finally, raw <italic>F</italic>-test failed to detect an interaction with Beta prime distribution irrespective of the underlying interaction type and raw <italic>t</italic>-test failed to detect group difference in the two-group and three-group scenario. Since these problems affect large values of <italic>c</italic><sub><italic>l</italic></sub>, one needs to ask whether these problems are caused by CFE or by some other factor. Notably, one may argue that these failures are caused by the nonlinear numeric representation of concatenation. There certainly are nonlinearities that do not manifest as CFE and one would expect, that these nonlinearities affect the performance irrespective of the magnitude of CFE. However, if we accept the definition of CFE as essential maximum/minimum or if we use the formal CFE conditions as defining conditions, such definitions do <italic>not</italic> imply that the amount of nonlinearity should covary with the magnitude of the CFE or in fact that for large <italic>c</italic><sub><italic>l</italic></sub> the nonlinear behaviour should disappear. This is in contrast with the Tobit maximum/minimum definition of CFE, where concatenation translates into addition for values that are far away from the boundaries. Gamma distribution is a special case. We provided its derivation in terms of essential minimum, but, as argued by [<xref ref-type="bibr" rid="pone.0220889.ref024">24</xref>], Gamma distribution can be viewed as a distribution with two regimes where for small mean values it behaves like power-law distribution (which can be derived with the POME constraint <italic>c</italic><sub><italic>l</italic></sub> = E[log(<italic>Y</italic>)]) and for large mean values it behaves like normal distribution. In the latter case one would expect concatenation to map to addition while in the former case one would expect concatenation to map to multiplication. Since for fixed <italic>b</italic> the expected value of Gamma distribution covaries with <italic>c</italic><sub><italic>l</italic></sub> one would expect that the amount of nonlinearity increases with the magnitude of CFE. This may as well explain why raw <italic>F</italic>-test was more successful at detecting uncrossed interaction when <inline-formula id="pone.0220889.e132"><alternatives><graphic id="pone.0220889.e132g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e132" ns0:type="simple" /><ns1:math display="inline" id="M132"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> was large, while log <italic>F</italic>-test performed better when <inline-formula id="pone.0220889.e133"><alternatives><graphic id="pone.0220889.e133g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e133" ns0:type="simple" /><ns1:math display="inline" id="M133"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> was small. The log transformation functions well with power-law distribution, but with data from normal distribution one would prefer an analysis of untransformed data in order to detect an interaction. We return to the issue of relation between CFE and nonlinearity in the subsequent section. For the current purpose, we conclude that the relation is not simple one and that the occurrence of poor performance with large <italic>c</italic><sub><italic>l</italic></sub> depends on how well the measurement-theoretic assumptions behind the statistical method match the data generating mechanism.</p>
<p>Trimmed <italic>t</italic>-test showed consistently the worst performance of all four two-group tests. Trimmed <italic>t</italic>-test showed large performance gap to other tests and only occasionally outperformed <italic>t</italic>-test with untransformed data. Apparently, distribution tails include important information and discarding this information when the data are affected by CFE results in a poor performance.</p>
<p>Performance of TOST can be largely deduced from the CI pattern. A bias towards zero in the difference estimate is accompanied by TOST support for equivalence irrespective of whether it is a case of biased or a case of biased noisy inference. In contrast, with noisy inference, TOST does not support equivalence. For half of the distributions (Beta, Beta prime, Beta-binomial) the TOST threshold was apparently too large so that TOST did not support equivalence irrespective of CFE magnitude. As described in the methods section, the TOST thresholds were fixed to correspond to an median estimate of the group difference obtained with a <italic>c</italic><sub><italic>l</italic></sub> located 3/4 between the lower and the upper bound of the <italic>c</italic><sub><italic>l</italic></sub> range. Separate thresholds were obtained for transformed and raw data. Simple rules for obtaining thresholds are not available in the literature and we chose this threshold selection procedure to select thresholds that are plausible and so that we can compare the performance when TOST is applied to transformed data with when it is applied to untransformed data. Perhaps, it would be possible to make a more informative selection on a case-by-case basis. This would raise concerns about the plausibility of such choice and about the comparability of results. As such, a bigger investment into the derivation and the justification of such thresholds would be required. To maintain the focus we omitted a detailed investigation and leave it to future research.</p>
<p>As the magnitude of CFE increased, Bayesian <italic>t</italic>-test invariably favoured the equivalence, irrespective of the distribution and whether or not a data transformation was used. This was even the case when CIs showed noisy inference. In an ideal case, one would expect the probability of the Bayesian <italic>t</italic>-test to converge to 0.5 and thereby to recognize the uncertain situation as such. This did not occur. It&#8217;s worth noting that Bayesian <italic>t</italic>-test by [<xref ref-type="bibr" rid="pone.0220889.ref086">86</xref>] assumes equal group variance which explains its poor performance.</p>
<p>Across all conditions, Cohen&#8217;s <italic>d</italic> decreased as the floor effect increased. Such result is unproblematic, if it is understood that Cohen&#8217;s <italic>d</italic> depends, in addition to the theoretical construct which one intends to measure, on the adequacy of the measurement tool and possibly on the base level at which the difference is measured. Unfortunately, the recommendations regarding the use of effect size for meta-analysis and experiment planning (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref095">95</xref>]) take this rarely into account.</p>
</sec>
<sec id="sec040">
<title>4.3 Ordinality, discreteness, nonlinearity and skewness</title>
<p>As argued in the introduction, we consider CFE to be one of the crucial phenomena that account for the performance loss reported in the robustness literature. At the same time the discussion in the published work is focused on other factors such as ordinality, nonlinearity, discreteness or skewness The current results permit further consideration of the relative importance of the these factors.</p>
<p>The performance of logit transform on discrete data fell below that of log and logit transform with continuous data, both in terms of failing to achieve noisy performance and in terms of performance gap to rank-based tests. At the same time we demonstrated that noisy inference can be obtained with discrete data when OLRM was fitted to data from OLRM. Fitting Beta-binomial model to data from OLRM showed biased noisy performance, but the bias was to overestimate rather than to underestimate the group difference. If the research goal is to test whether the mean group outcomes are equal, then such bias is not problematic. Apart from pointing to the inadequacy of logit transform&#8217;s application to discrete data, these results suggest that when the measure offers an information from the non-additive representation of concatenation, then a statistical method designed to take into account this information, outperform the rank-based and linear methods (see [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>, <xref ref-type="bibr" rid="pone.0220889.ref078">78</xref>] or similar results). Whether such information is available from some particular measurement tool is an empirical questions that requires further investigation. While studies that compare the fit of linear and nonlinear models to data suspected of CFE exist (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref072">72</xref>, <xref ref-type="bibr" rid="pone.0220889.ref078">78</xref>]) and show the better fit of nonlinear methods, we are not aware of model fitting comparison between nonlinear and rank-based methods on data with CFE. In sum, these results suggest that discreteness is an important aspect of data, that should not be ignored when designing and selecting statistical tools with help of measurement theory. A recourse to rank-based methods may alleviate the problems due to discreteness, but will discount the information offered by concatenation operation. If such information is available in the measure, its omission can lead to lower power and to a confusion regarding the presence or absence of an interaction.</p>
<p>Another factor, that is often considered during comparisons of rank-based and linear methods as well as in studies with Tobit model, is the nonlinearity of the data-generating process, or to put it more precisely, the measure&#8217;s non-additive representation of concatenation. Due to the non-additive representation, <italic>F</italic>-test confused interactions and main effects in the four-group scenario and this was already discussed in the previous section. There we discussed the case of Gamma distribution which switches between linear and nonlinear regime. Thus, the view of nonlinearity as some fixed aspect of the data-generating process may be misleading. While there may be other causes of nonlinearity, based on the data surveys in [<xref ref-type="bibr" rid="pone.0220889.ref032">32</xref>] it appears that, when it comes to psychological data with bounded range, CFE is the prevalent cause of nonlinearity. [<xref ref-type="bibr" rid="pone.0220889.ref075">75</xref>] noted that linear regression underestimates the regression coefficients of interaction terms when tested on data from Tobit model. It should be noted that the nonlinear behaviour of Tobit model is slightly different. When the data are far away from Tobit threshold, the data show linear behaviour. As the data approach threshold, the nonlinearity manifests and causes a misdetection of main effects and interaction. Finally as CFE gets more severe, any effects become indiscernible. The CFE created by essential minimum/maximum does not manifest the last stage.</p>
<p>Finally, skewness has been discussed by [<xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] as the main aspect of CFE and multiple robustness studies focused on skewed data. The current work further showed that the selected distributions with CFE show association between floor effect and a positive skew. Wald distribution was an exception, in which the skew decreased with the increasing severity of the floor effect thereby suggesting that the relation between skewness and CFE is not as straightforward. Perhaps, a probabilistic formulation of a structure with essential minimum implies a positive relation between skewness and the magnitude of floor effect, while the velocity-based account behind Wald distribution implies a negative relation. Further research into the connection between these measure-theoretic structures and the associated probability distributions is required to answer this question. Apart from skew, the results suggested that variance decreases with CFE. Beta prime distribution proved to be an exception with increasing variance and the variance of Beta and Beta-binomial distribution decreased only slowly.</p>
<p>In sum, CFE describes a constellation of several phenomena, such as heterogeneous variance, strong skew or nonlinear relation between measurement and the latent trait. The measure discreteness may add to that. The overview of the robustness literature suggested that these factors are detrimental to the performance of popular inferential methods. The current study illustrated, that when these phenomena co-occur, the resulting performance loss is not just sum of its parts, but ranges from cases of biased noisy inference, in which the detrimental effects cancel out, to cases of biased inference in which the detrimental effects reinforce each other. Hence, these phenomena need to be considered in conjunction.</p>
<p>A constellation of phenomena, that commonly finds reference in the literature, is the concept of ordinal scale. The measure-theoretic motivation behind this concept has been surveyed in the introduction. Unfortunately, due to the popularity of Steven&#8217;s scale typology, ordinal scale is not used to refer to a measurement tool that exclusively utilize the order information. Rather all measures with an ordered value range, that do not fit into the category of nominal scale are lumped together as ordinal. We think this does not only pose a problem for theoretical discussions, but it actually affects the presentation and interpretation of simulation studies. For instance, the study by [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>] is a prima facie investigation of CFE with methods and results similar to the current study. The authors even highlight the cases where the popular statistical methods fail and these cases manifest the strongest CFE. However, the authors fail to notice this, they never refer to ceiling or floor effect in their publication, and rather frame their study as a robustness investigation with ordinal data.</p>
<p>To name other instances, [<xref ref-type="bibr" rid="pone.0220889.ref065">65</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref047">47</xref>] created ordinal data by manipulating variance, skew and kurtosis of a continuous variable, which was then transformed into a discrete variable with hundred levels. The discretization with so many levels had negligible effect on the test performance, and the values were mostly allocated in the middle of the scale. As such these studies investigate, under the label of ordinal data, the effect of variance, skew and kurtosis on the robustness. In contrast, [<xref ref-type="bibr" rid="pone.0220889.ref063">63</xref>] generated &#8220;ordinal data&#8221; with five discrete levels, and while skew and variance was manipulated, most probability mass was allocated to the inner three levels so that CFE was not a concern. Thus, this was a study that investigated discreteness under the label of ordinality. Finally, [<xref ref-type="bibr" rid="pone.0220889.ref068">68</xref>] compared test performance of methods applied to continuous data with performance of methods applied to ranks obtained from the continuous data. Thus, this study generates ordinal data in the measure-theoretic sense. As one may imagine, the conclusions of these studies diverge, which is perhaps the reason why the application of <italic>t</italic>-test and <italic>F</italic>-test to ordinal data remains a controversial topic [<xref ref-type="bibr" rid="pone.0220889.ref040">40</xref>&#8211;<xref ref-type="bibr" rid="pone.0220889.ref043">43</xref>, <xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>, <xref ref-type="bibr" rid="pone.0220889.ref104">104</xref>, <xref ref-type="bibr" rid="pone.0220889.ref105">105</xref>] even after decades of accumulated research. We believe that the robustness research would benefit from switching its focus from the blurry concept of ordinal scale, to other more specific concepts such as skewness, nonlinearity, discreteness, or as we already suggested, to focus on their co-occurrence as ceiling and floor effect.</p>
</sec>
<sec id="sec041">
<title>4.4 Limitations, scope and future research</title>
<sec id="sec042">
<title>Focus on qualitative results</title>
<p>In the results section, we did not dwell much on quantifying the results. We pointed the reader to figures and occasionally mentioned the maximum performance gap between a pair of statistical methods. Such qualitative approach is not uncommon to power studies (e.g. boneau62), although for instance [<xref ref-type="bibr" rid="pone.0220889.ref051">51</xref>] extensively report the maximum performance gaps in tables. The main purpose of the latter type of reporting is to compare conditions in terms of power advantage/loss or to design recommendations and guidelines such that the applied researcher may estimate the power loss based on simple statistical descriptors derived from the data set at hand. Clearly, the current study is not suited to provide such recommendations as that would require the knowledge of <italic>c</italic><sub><italic>l</italic></sub> and of values of other distribution parameters. For the same reason we find comparisons between conditions difficult. Can we, for instance, conclude that the performance loss of <italic>t</italic>-test relative to <italic>t</italic>-test with transformed values is more severe for Beta than for Gamma distribution, because the performance gap that occurred in <xref ref-type="fig" rid="pone.0220889.g006">Fig 6</xref> was larger than that in <xref ref-type="fig" rid="pone.0220889.g003">Fig 3</xref>? This depends on the choice of <inline-formula id="pone.0220889.e028"><alternatives><graphic id="pone.0220889.e028g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e028" ns0:type="simple" /><ns1:math display="inline" id="M28"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula> (for each Gamma and Beta distribution), <italic>c</italic><sub><italic>u</italic></sub> (Beta), <italic>c</italic><sub><italic>n</italic></sub> (Gamma) and possibly on the choice of additional parameters not considered in this work (such as <italic>b</italic> of Gamma). As we noted the values of these parameters affect the size of the performance gap and in principle could be used to find a scenario with gap of up to 100 pp. In contrast the qualitative patterns (such as biased, noisy and biased noisy inference; or misidentification of interaction) occurred irrespective of the choice of nuisance parameter and of <inline-formula id="pone.0220889.e030"><alternatives><graphic id="pone.0220889.e030g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0220889.e030" ns0:type="simple" /><ns1:math display="inline" id="M30"><ns1:msubsup><ns1:mi>c</ns1:mi> <ns1:mi>l</ns1:mi> <ns1:mo>&#916;</ns1:mo></ns1:msubsup></ns1:math></alternatives></inline-formula>. The few deviations that occurred were discussed in the results section.</p>
</sec>
<sec id="sec043">
<title>Type I error</title>
<p>We avoided to frame the current simulations in terms of Type I and Type II error and attempted to avoid the term statistical power. The current simulations did not systematically create situations in which the null or alternative hypothesis of some of the selected tests was true or false. Rather, the groups differed in terms of the latent trait <italic>c</italic><sub><italic>l</italic></sub>. The hypotheses of the utilized tests were a priori unrelated to <italic>c</italic><sub><italic>l</italic></sub>. One may nevertheless consider a &#8220;type I error&#8221; simulations as presented by [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>]. In these simulations, the groups are identical with respect to <italic>c</italic><sub><italic>l</italic></sub> or some other latent parameter representing the empirical event. Crucially, the groups differ in terms of some other latent parameter. The main challenge with simulations with such scenario, is the choice and justification of this auxiliary parameter. While <italic>c</italic><sub><italic>l</italic></sub> parameter was similar across wide range of distributions and a justification based on measurement theory was provided, the auxiliary parameters differed. [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>] selected the latent scale parameter of OLRM. While for some CFE distributions a similar latent scale parameter is available and commonly used (e.g. <italic>c</italic><sub><italic>v</italic></sub> of Log-normal and Logit-normal distribution), a theoretical work is required to derive such parametrization for other CFE distributions. Furthermore, researchers need to ask whether a case in which two groups differ in terms of latent scale but not in terms of latent mean represents a plausible empirical situation. As already mentioned, numerous robustness studies have been concerned with cases of equal means and heterogeneous group variances. [<xref ref-type="bibr" rid="pone.0220889.ref064">64</xref>] expressed the concern that such situation does not well represent the empirical reality. The current study further supports this view by suggesting that if the measure is affected by CFE, then a decrease in mean is associated with a decrease in variance through <italic>c</italic><sub><italic>l</italic></sub> (or <italic>c</italic><sub><italic>u</italic></sub>). With a heterogeneous latent scale, it is somewhat easier to conceive of a relevant research situation in which such &#8220;type I error&#8221; may occur. For instance, one may imagine that some cognitive measure is affected by both CFE and intelligence. Then if the groups are not balanced in terms of participant&#8217;s sex and assuming that intelligence of male population varies more than that of a female population (while the sexes do not differ in terms of mean intelligence), then the two groups will differ in terms of latent variance. Needless to say, this assumes that the latent parametrization accurately represents the empirical structure (in this case intelligence). Hence, the case of CFE-affected measure with groups equal in terms of <italic>c</italic><sub><italic>l</italic></sub> and <italic>c</italic><sub><italic>u</italic></sub>, but heterogeneous in terms of some other parameter, may be of some interest, but requires further theoretical work which would substantiate the choice of the auxiliary latent parameter.</p>
</sec>
<sec id="sec044">
<title>Hierarchical structures</title>
<p>In discussions of robustness of application of linear statistical methods to questionnaire data it is common to consider a situation with multiple items that measure the same latent trait. Then it is argued that averaging across items improves the robustness (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref043">43</xref>], see [<xref ref-type="bibr" rid="pone.0220889.ref070">70</xref>] for a different opinion). We didn&#8217;t consider hierarchical or other non-nested structures in the current work as we think that these introduce different type of difficulties that requires a separate investigation. To briefly sketch the difficulties, consider <italic>Y</italic><sub><italic>ij</italic></sub> to be the response of participant <italic>i</italic> on item <italic>j</italic> of a questionnaire. Then for equation mean<sub><italic>i</italic></sub>(mean<sub><italic>j</italic></sub>(<italic>Y</italic><sub><italic>ij</italic></sub>)) = mean<sub><italic>j</italic></sub>(mean<sub><italic>i</italic></sub>(<italic>Y</italic><sub><italic>ij</italic></sub>)) to hold, it is necessary for variance of <italic>Y</italic><sub><italic>ij</italic></sub> to be equal across <italic>i</italic> and <italic>j</italic>. If CFE affects <italic>Y</italic><sub><italic>ij</italic></sub> and its magnitude varies across items, then variance will vary across items and mean<sub><italic>j</italic></sub> will provide a biased estimate. A popular solution ([<xref ref-type="bibr" rid="pone.0220889.ref030">30</xref>] section 12.3) is to use weighted mean, where less noisy observations are given more weight, thereby increasing the overall accuracy of the estimator. If CFE results in a noisy inference, then such estimator will tend to ignore items with CFE. If however CFE results in biased noisy inference, then the weighting procedure will give more weight to items with CFE and will increase the overall influence of CFE on the mean. This example illustrates that CFE-affected measures applied in hierarchical and non-nested design require a separate investigation.</p>
</sec>
<sec id="sec045">
<title>Tobit minimum/maximum</title>
<p>The current work focused exclusively on CFE defined by essential maximum/minimum rather than CFE defined by Tobit maximum/minimum. The aim was to fill in the gap left by the existing research on CFE. It is difficult to compare the results between the essential maximum CFE and Tobit CFE, since the Tobit research is mostly focused on comparison of linear regression with Tobit regression on test scores of human subjects. The general finding that Tobit regression provides better fit to data and different estimates than the linear methods echoes current results. Furthermore, difficulty in dealing with interactions (e.g. inaccurate estimation of regression coefficients of interaction terms [<xref ref-type="bibr" rid="pone.0220889.ref075">75</xref>]) was observed in Tobit research as well as in the current work. To discuss the difference between the two types of CFE, recall that we observed in section 4.2 that the probability distributions with essential minimum showed nonlinearity with weak CFE, which is in contrast with Tobit model, which shows linear behaviour when CFE is weak. As noted, it is possible to obtain a shift between linear and nonlinear regime with Gamma distribution [<xref ref-type="bibr" rid="pone.0220889.ref024">24</xref>]. The question of a suitable parametrization of Gamma distribution to obtain regime-switching behaviour and how the resulting distribution compares to Tobit model require further investigation. However, the case of Gamma distribution suggests, that the distinction between Tobit minimum and essential minimum is less pointed than it is presented in the literature [<xref ref-type="bibr" rid="pone.0220889.ref009">9</xref>, <xref ref-type="bibr" rid="pone.0220889.ref013">13</xref>] and less sharp than it was presented in the literature overview of this report. We think, that it may be possible to formulate Tobit minimum as a limiting case of essential minimum. Then Tobit model may be obtained as a limiting case of some probability distribution with essential minimum/maximum.</p>
</sec>
<sec id="sec046">
<title>Choice of parametrization</title>
<p>We feel obliged to stress again, without having much to add, that the presented results crucially depend on the choice of parametrization. This includes the choice of nuisance parameters. Comparisons of current results with those from other studies need to take the discrepancy in parametrization into account. The results in <xref ref-type="fig" rid="pone.0220889.g011">Fig 11</xref> suggest that the parametrization was reasonable as in most cases the distributions satisfied the informal CFE conditions.</p>
</sec>
</sec>
<sec id="sec047">
<title>4.5 Recommendations</title>
<p>The performance comparison between statistical methods is perhaps of most importance to the applied researcher and we conclude the report on this topic. Use of data transformation has great potential with continuous measures, but requires a careful consideration of how CFE affects the measurement tool, otherwise it may be ineffective. With discrete data and with more complex study design, use of generalized linear models is appropriate. Again, the model assumptions must accurately match how CFE affects the measure. Rank-based tests performed fairly well when considered relative to other alternatives. The results however suggest that methods that utilize rank-transform perform similar to methods that utilize log or logit transform. As with other transforms, if the fit between the choice of rank-based transform and the data generating mechanism is poor, test performance degrades and main effects and interactions may not be correctly identified. The same applies to linear methods. However, across wide range of scenarios, <italic>t</italic>-test and <italic>F</italic>-test showed inferior performance and their use with data with CFE should be discouraged. Perhaps, application of Welch&#8217;s <italic>t</italic>-test may be defended on the grounds that, it &#8220;only&#8221; leads to a (possibly negligible) loss of power.</p>
<p>Thus, in order to make the proper choice, the researcher requires knowledge how the measurement tool numerically represents the concatenation operation and hence how CFE affects themeasurement. In an ideal case, this information was obtained by validation and calibration studies done by the author/manufacturer of the measurement tool and is provided in the manual. If this information is not available, as is often the case, the researcher has to perform such studies herself. Note that such validation/calibration procedure is advisable when handling any kind of nonlinearity not just CFE. At minimum, the researcher should establish the numerical range of the measurement tool in which linear behaviour can be assumed and then she should restrict the conclusions to the corresponding range of the latent trait. Researchers wishing for more general inferences may consider whether the bounds of the numerical range create a CFE with Tobit or with essential maximum/minimum. In an ideal case, the researcher would obtain a parametric functional specification of ceiling and floor effect. Our review of formal measurement theory and POME provided the language to formulate and express such specification. We encourage researchers to use this formalism.</p>
<p>The use of modern inferential methods, that were considered in the current work, can&#8217;t be recommended in their current form. The trimmed <italic>t</italic>-test showed worst performance of all tests and was ineffective at countering CFE. The equivalence testing methods, depended on the correct data transformation and otherwise produced false rejection of alternative hypothesis when the measure was affected by CFE. On occasion, confidence intervals manifested patterns of biased inference, where the estimate became more biased and more certain as the magnitude of CFE increased. Cohen&#8217;s <italic>d</italic> was biased by CFE as well and hence its use in meta-analysis or for research planning with measures affected by CFE is problematic. For research planning, we recommend the use of fake data simulation([<xref ref-type="bibr" rid="pone.0220889.ref030">30</xref>] chapter 8.1) which we illustrated with research scenario from [<xref ref-type="bibr" rid="pone.0220889.ref001">1</xref>].</p>
<p>Apart from robustness, computational costs and difficulty of interpretation may be considered as main hurdles to wider application of generalized linear models. With the recent advance of Monte Carlo methods, packages for fitting generalized linear models are readily available (e.g. [<xref ref-type="bibr" rid="pone.0220889.ref101">101</xref>]). Such software makes the fitting process fast and straightforward. If not already the case, computational cost of generalized linear models should cease to be a hurdle in the foreseeable future. Interpretation of GLMs is somewhat more involved, but for instance if CFE is modelled with the logarithm function, an additive change in the latent trait may be interpreted as a multiplicative change in the measured quantity, which can be expressed and interpreted as a percentage increase. Change in Logit function, may be interpreted as additive change (for values around 0.5) or as multiplicative change (for values near 0 and 1). [<xref ref-type="bibr" rid="pone.0220889.ref030">30</xref>] and other textbooks provide good guidance on the interpretation of estimates obtained with generalized linear models.</p>
<p>Finally, one may consider modification of the measurement tool itself with the goal of mitigating CFE. [<xref ref-type="bibr" rid="pone.0220889.ref106">106</xref>] and [<xref ref-type="bibr" rid="pone.0220889.ref107">107</xref>] discuss revision of questionnaire norms in the extremal regions which goes towards our appeal for further validation studies, rather than being a modification of a measurement tool itself. [<xref ref-type="bibr" rid="pone.0220889.ref071">71</xref>] proposed to omit the extremal data from analysis. Given the performance of trimmed <italic>t</italic>-test in the current work, we doubt that such omission can effectively counter CFE. [<xref ref-type="bibr" rid="pone.0220889.ref108">108</xref>] proposed to expand the options of a rating scale, which may perhaps mitigate, but will not remove CFE. If one considers that any data transformation or even model fitting procedure can be made evaluative part of the measurement tool then, what has been written about the utility of transformations and about the necessity of validation/calibration studies, applies to measure design as well. If the evaluative procedure of the measurement tool is designed poorly, this may lead to a loss of information (unless the researcher has an access to validation/calibration data). While successful data analysis may turn biased inference or biased noisy inference into noisy inference, correct inference can&#8217;t be obtained with data-analytic solution and a modification of measurement tool is the only option to avoid or at least mitigate noisy inference.</p>
<p>Irrespective of the recommendations, we hope, that the current work will alert researchers to the types of detrimental effects associated with CFE and that it will motivate the design of new effective statistical solutions and new measurement tools, that avoid the bias and noise created by CFE.</p>
</sec>
</sec>
<sec id="sec048">
<title>Supporting information</title>
<supplementary-material id="pone.0220889.s001" mimetype="application/pdf" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.s001" ns0:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Figures with results of supplementary analyses.</title>
<p>See the introductory paragraph of section 3 for details.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pone.0220889.ref001">
<label>1</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Schnall</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Benton</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Harvey</surname> <given-names>S</given-names></name>. <article-title>With a clean conscience: Cleanliness reduces the severity of moral judgments</article-title>. <source>Psychological science</source>. <year>2008</year>;<volume>19</volume>(<issue>12</issue>):<fpage>1219</fpage>&#8211;<lpage>1222</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1111/j.1467-9280.2008.02227.x" ns0:type="simple">10.1111/j.1467-9280.2008.02227.x</ext-link></comment> <object-id pub-id-type="pmid">19121126</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref002">
<label>2</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Johnson</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Cheung</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Donnellan</surname> <given-names>MB</given-names></name>. <article-title>Does Cleanliness Influence Moral Judgments?</article-title> <source>Social Psychology</source>. <year>2014</year>;<volume>45</volume>(<issue>3</issue>):<fpage>209</fpage>&#8211;<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1027/1864-9335/a000186" ns0:type="simple">10.1027/1864-9335/a000186</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref003">
<label>3</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Schnall</surname> <given-names>S</given-names></name>. <article-title>Clean Data: Statistical Artifacts Wash Out Replication Efforts</article-title>. <source>Social Psychology</source>. <year>2014</year>;<volume>45</volume>(<issue>4</issue>):<fpage>315</fpage>&#8211;<lpage>317</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1027/1864-9335/a000204" ns0:type="simple">10.1027/1864-9335/a000204</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref004">
<label>4</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Johnson</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Cheung</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Donnellan</surname> <given-names>MB</given-names></name>. <article-title>Hunting for Artifacts The Perils of Dismissing Inconsistent Replication Results</article-title>. <source>Social psychology</source>. <year>2014</year>;<volume>45</volume>(<issue>4</issue>):<fpage>318</fpage>&#8211;<lpage>320</lpage>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref005">
<label>5</label>
<mixed-citation publication-type="other" ns0:type="simple">Simonsohn U. type [; 2014] <ext-link ext-link-type="uri" ns0:href="http://datacolada.org/23" ns0:type="simple">http://datacolada.org/23</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref006">
<label>6</label>
<mixed-citation publication-type="other" ns0:type="simple">Yarkoni T. type [; 2014] <ext-link ext-link-type="uri" ns0:href="http://www.talyarkoni.org/blog/2014/06/01/there-is-no-ceiling-effect-in-johnson-cheung-donnellan-2014" ns0:type="simple">http://www.talyarkoni.org/blog/2014/06/01/there-is-no-ceiling-effect-in-johnson-cheung-donnellan-2014</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref007">
<label>7</label>
<mixed-citation publication-type="other" ns0:type="simple">Fraley CR. type [; 2014] <ext-link ext-link-type="uri" ns0:href="https://pigee.wordpress.com/2014/05/24/additional-reflections-on-ceiling-effects-in-recent-replication-research" ns0:type="simple">https://pigee.wordpress.com/2014/05/24/additional-reflections-on-ceiling-effects-in-recent-replication-research</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref008">
<label>8</label>
<mixed-citation publication-type="other" ns0:type="simple">Sch&#246;nbrodt F. type [; 2014] <ext-link ext-link-type="uri" ns0:href="https://www.nicebread.de/reanalyzing-the-schnalljohnson-cleanliness-data-sets-new-insight-from-bayesian-and-robust-approaches" ns0:type="simple">https://www.nicebread.de/reanalyzing-the-schnalljohnson-cleanliness-data-sets-new-insight-from-bayesian-and-robust-approaches</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref009">
<label>9</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Krantz</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Luce</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Suppes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <source>Foundations of measurement, Additive and polynomial representations</source>. <volume>vol. 1</volume>. <publisher-name>Academic Press</publisher-name>, <publisher-loc>New York</publisher-loc>; <year>1971</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref010">
<label>10</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Cramer</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Howitt</surname> <given-names>DL</given-names></name>. <source>The SAGE dictionary of statistics</source>. <publisher-name>SAGE</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref011">
<label>11</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Everitt</surname> <given-names>BS</given-names></name>. <source>The Cambridge Dictionary of Statistics</source>. <edition>2nd ed</edition>. <publisher-name>Cambridge University Press</publisher-name>; <year>2002</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref012">
<label>12</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Vogt</surname> <given-names>WP</given-names></name>. <source>The SAGE dictionary of statistics &amp; methodology</source>. <edition>3rd ed</edition>. <publisher-name>SAGE</publisher-name>; <year>2005</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref013">
<label>13</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Koedel</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Betts</surname> <given-names>J</given-names></name>. <article-title>Value added to what? How a ceiling in the testing instrument influences value-added estimation</article-title>. <source>Education Finance and Policy</source>. <year>2010</year>;<volume>5</volume>(<issue>1</issue>):<fpage>54</fpage>&#8211;<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1162/edfp.2009.5.1.5104" ns0:type="simple">10.1162/edfp.2009.5.1.5104</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref014">
<label>14</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Pfanzagl</surname> <given-names>J</given-names></name>. <source>Theory of measurement</source>. <publisher-name>Wiley</publisher-name>; <year>1968</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref015">
<label>15</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Luce</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Krantz</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Suppes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <source>Foundations of measurement, Additive and polynomial representations</source>. <volume>vol. 3</volume>. <publisher-name>Academic Press</publisher-name>, <publisher-loc>New York</publisher-loc>; <year>1990</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref016">
<label>16</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Van der Vaart</surname> <given-names>AW</given-names></name>. <source>Asymptotic statistics</source>. <volume>vol. 3</volume>. <publisher-name>Cambridge University Press</publisher-name>; <year>2000</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref017">
<label>17</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Jaynes</surname> <given-names>ET</given-names></name>. <article-title>Information theory and statistical mechanics</article-title>. <source>Physical review</source>. <year>1957</year>;<volume>106</volume>(<issue>4</issue>):<fpage>620</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1103/PhysRev.106.620" ns0:type="simple">10.1103/PhysRev.106.620</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref018">
<label>18</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Jaynes</surname> <given-names>ET</given-names></name>. <source>Probability theory: The logic of science</source>. <publisher-name>Cambridge university press</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref019">
<label>19</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Kapur</surname> <given-names>JN</given-names></name>. <source>Maximum-entropy models in science and engineering</source>. <edition>2nd ed</edition>. <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>1993</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref020">
<label>20</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Wright</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nocedal</surname> <given-names>J</given-names></name>. <source>Numerical optimization</source>. <volume>vol. 35</volume>. <publisher-name>Springer</publisher-name>; <year>1999</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref021">
<label>21</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Rasch</surname> <given-names>G</given-names></name>. <source>Probabilistic models for some intelligence and attainment tests</source>. <publisher-name>The University of Chicago Press</publisher-name>. <year>1980</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref022">
<label>22</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Papalexiou</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Koutsoyiannis</surname> <given-names>D</given-names></name>. <article-title>Entropy based derivation of probability distributions: A case study to daily rainfall</article-title>. <source>Advances in Water Resources</source>. <year>2012</year>;<volume>45</volume>:<fpage>51</fpage>&#8211;<lpage>57</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.advwatres.2011.11.007" ns0:type="simple">10.1016/j.advwatres.2011.11.007</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref023">
<label>23</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>McDonald</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>YJ</given-names></name>. <article-title>A generalization of the beta distribution with applications</article-title>. <source>Journal of Econometrics</source>. <year>1995</year>;<volume>66</volume>(<issue>1-2</issue>):<fpage>133</fpage>&#8211;<lpage>152</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/0304-4076(94)01612-4" ns0:type="simple">10.1016/0304-4076(94)01612-4</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref024">
<label>24</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Frank</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>DE</given-names></name>. <article-title>Measurement invariance, entropy, and probability</article-title>. <source>Entropy</source>. <year>2010</year>;<volume>12</volume>(<issue>3</issue>):<fpage>289</fpage>&#8211;<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3390/e12030289" ns0:type="simple">10.3390/e12030289</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref025">
<label>25</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Harremo&#235;s</surname> <given-names>P</given-names></name>. <article-title>Binomial and Poisson distributions as maximum entropy distributions</article-title>. <source>IEEE Transactions on Information Theory</source>. <year>2001</year>;<volume>47</volume>(<issue>5</issue>):<fpage>2039</fpage>&#8211;<lpage>2041</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/18.930936" ns0:type="simple">10.1109/18.930936</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref026">
<label>26</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>McKoon</surname> <given-names>G</given-names></name>. <article-title>Diffusion decision model: Current issues and history</article-title>. <source>Trends in cognitive sciences</source>. <year>2016</year>;<volume>20</volume>(<issue>4</issue>):<fpage>260</fpage>&#8211;<lpage>281</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.tics.2016.01.007" ns0:type="simple">10.1016/j.tics.2016.01.007</ext-link></comment> <object-id pub-id-type="pmid">26952739</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref027">
<label>27</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Luce</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Narens</surname> <given-names>L</given-names></name>. <article-title>A qualitative equivalent to the relativistic addition law for velocities</article-title>. <source>Synthese</source>. <year>1976</year>;<volume>33</volume>(<issue>1</issue>):<fpage>483</fpage>&#8211;<lpage>487</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/BF00485457" ns0:type="simple">10.1007/BF00485457</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref028">
<label>28</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Noventa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stefanutti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vidotto</surname> <given-names>G</given-names></name>. <article-title>An analysis of item response theory and Rasch models based on the most probable distribution method</article-title>. <source>Psychometrika</source>. <year>2014</year>;<volume>79</volume>(<issue>3</issue>):<fpage>377</fpage>&#8211;<lpage>402</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s11336-013-9348-y" ns0:type="simple">10.1007/s11336-013-9348-y</ext-link></comment> <object-id pub-id-type="pmid">25205004</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref029">
<label>29</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Noventa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stefanutti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vidotto</surname> <given-names>G</given-names></name>. <article-title>A derivation of the polytomous Rasch model based on the most probable distribution method</article-title>. <source>The Spanish journal of psychology</source>. <year>2014</year>;<volume>17</volume>(<issue>e84</issue>):<fpage>1</fpage>&#8211;<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref030">
<label>30</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hill</surname> <given-names>J</given-names></name>. <source>Data analysis using regression and multilevel/hierarchical models</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref031">
<label>31</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Glass</surname> <given-names>GV</given-names></name>, <name name-style="western"><surname>Peckham</surname> <given-names>PD</given-names></name>, <name name-style="western"><surname>Sanders</surname> <given-names>JR</given-names></name>. <article-title>Consequences of failure to meet assumptions underlying the fixed effects analyses of variance and covariance</article-title>. <source>Review of educational research</source>. <year>1972</year>;<volume>42</volume>(<issue>3</issue>):<fpage>237</fpage>&#8211;<lpage>288</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3102/00346543042003237" ns0:type="simple">10.3102/00346543042003237</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref032">
<label>32</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Micceri</surname> <given-names>T</given-names></name>. <article-title>The unicorn, the normal curve, and other improbable creatures</article-title>. <source>Psychological bulletin</source>. <year>1989</year>;<volume>105</volume>(<issue>1</issue>):<fpage>156</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.105.1.156" ns0:type="simple">10.1037/0033-2909.105.1.156</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref033">
<label>33</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Cliff</surname> <given-names>N</given-names></name>. <article-title>Article Commentary: Abstract Measurement Theory and the Revolution that Never Happened</article-title>. <source>Psychological Science</source>. <year>1992</year>;<volume>3</volume>(<issue>3</issue>):<fpage>186</fpage>&#8211;<lpage>190</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1111/j.1467-9280.1992.tb00024.x" ns0:type="simple">10.1111/j.1467-9280.1992.tb00024.x</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref034">
<label>34</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Stevens</surname> <given-names>S</given-names></name>. <article-title>On the Theory of Scales of Measurement</article-title>. <source>Science</source>. <year>1946</year>;<volume>103</volume>:<fpage>677</fpage>&#8211;<lpage>680</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1126/science.103.2684.677" ns0:type="simple">10.1126/science.103.2684.677</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref035">
<label>35</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Stevens</surname> <given-names>SS</given-names></name>. <chapter-title>Mathematics, measurement, and psychophysics</chapter-title>. In: <name name-style="western"><surname>Stevens</surname> <given-names>SS</given-names></name>, editor. <source>Handbook of Experimental Psychology</source>. <publisher-name>Wiley</publisher-name>; <year>1951</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref036">
<label>36</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Anderson</surname> <given-names>NH</given-names></name>. <article-title>Scales and statistics: Parametric and nonparametric</article-title>. <source>Psychological bulletin</source>. <year>1961</year>;<volume>58</volume>(<issue>4</issue>):<fpage>305</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/h0042576" ns0:type="simple">10.1037/h0042576</ext-link></comment> <object-id pub-id-type="pmid">13683251</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref037">
<label>37</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Gaito</surname> <given-names>J</given-names></name>. <article-title>Measurement scales and statistics: Resurgence of an old misconception</article-title>. <source>Psychological Bulletin</source>. <year>1980</year>;<volume>87</volume>(<issue>3</issue>):<fpage>564</fpage>&#8211;<lpage>567</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.87.3.564" ns0:type="simple">10.1037/0033-2909.87.3.564</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref038">
<label>38</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Michell</surname> <given-names>J</given-names></name>. <article-title>Measurement scales and statistics: A clash of paradigms</article-title>. <source>Psychological bulletin</source>. <year>1986</year>;<volume>100</volume>(<issue>3</issue>):<fpage>398</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.100.3.398" ns0:type="simple">10.1037/0033-2909.100.3.398</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref039">
<label>39</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Stine</surname> <given-names>WW</given-names></name>. <article-title>Meaningful inference: The role of measurement in statistics</article-title>. <source>Psychological Bulletin</source>. <year>1989</year>;<volume>105</volume>(<issue>1</issue>):<fpage>147</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.105.1.147" ns0:type="simple">10.1037/0033-2909.105.1.147</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref040">
<label>40</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Velleman</surname> <given-names>PF</given-names></name>, <name name-style="western"><surname>Wilkinson</surname> <given-names>L</given-names></name>. <article-title>Nominal, ordinal, interval, and ratio typologies are misleading</article-title>. <source>The American Statistician</source>. <year>1993</year>;<volume>47</volume>(<issue>1</issue>):<fpage>65</fpage>&#8211;<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/2684788" ns0:type="simple">10.2307/2684788</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref041">
<label>41</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Jamieson</surname> <given-names>S</given-names></name>. <article-title>Likert scales: how to (ab) use them</article-title>. <source>Medical education</source>. <year>2004</year>;<volume>38</volume>(<issue>12</issue>):<fpage>1217</fpage>&#8211;<lpage>1218</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1111/j.1365-2929.2004.02012.x" ns0:type="simple">10.1111/j.1365-2929.2004.02012.x</ext-link></comment> <object-id pub-id-type="pmid">15566531</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref042">
<label>42</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Carifio</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Perla</surname> <given-names>RJ</given-names></name>. <article-title>Ten common misunderstandings, misconceptions, persistent myths and urban legends about Likert scales and Likert response formats and their antidotes</article-title>. <source>Journal of Social Sciences</source>. <year>2007</year>;<volume>3</volume>(<issue>3</issue>):<fpage>106</fpage>&#8211;<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3844/jssp.2007.106.116" ns0:type="simple">10.3844/jssp.2007.106.116</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref043">
<label>43</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Norman</surname> <given-names>G</given-names></name>. <article-title>Likert scales, levels of measurement and the &#8220;laws&#8221; of statistics</article-title>. <source>Advances in health sciences education</source>. <year>2010</year>;<volume>15</volume>(<issue>5</issue>):<fpage>625</fpage>&#8211;<lpage>632</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s10459-010-9222-y" ns0:type="simple">10.1007/s10459-010-9222-y</ext-link></comment> <object-id pub-id-type="pmid">20146096</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref044">
<label>44</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Sullivan</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Artino</surname> <given-names>AR</given-names></name>. <article-title>Analyzing and interpreting data from Likert-type scales</article-title>. <source>Journal of graduate medical education</source>. <year>2013</year>;<volume>5</volume>(<issue>4</issue>):<fpage>541</fpage>&#8211;<lpage>542</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.4300/JGME-5-4-18" ns0:type="simple">10.4300/JGME-5-4-18</ext-link></comment> <object-id pub-id-type="pmid">24454995</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref045">
<label>45</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Boneau</surname> <given-names>CA</given-names></name>. <article-title>The effects of violations of assumptions underlying the t test</article-title>. <source>Psychological bulletin</source>. <year>1960</year>;<volume>57</volume>(<issue>1</issue>):<fpage>49</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/h0041412" ns0:type="simple">10.1037/h0041412</ext-link></comment> <object-id pub-id-type="pmid">13802482</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref046">
<label>46</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Boneau</surname> <given-names>CA</given-names></name>. <article-title>A comparison of the power of the U and t tests</article-title>. <source>Psychological Review</source>. <year>1962</year>;<volume>69</volume>(<issue>3</issue>):<fpage>246</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/h0047269" ns0:type="simple">10.1037/h0047269</ext-link></comment> <object-id pub-id-type="pmid">13870963</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref047">
<label>47</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Havlicek</surname> <given-names>LL</given-names></name>, <name name-style="western"><surname>Peterson</surname> <given-names>NL</given-names></name>. <article-title>Robustness of the t test: A guide for researchers on effect of violations of assumptions</article-title>. <source>Psychological Reports</source>. <year>1974</year>;<volume>34</volume>(<issue>3_suppl</issue>):<fpage>1095</fpage>&#8211;<lpage>1114</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2466/pr0.1974.34.3c.1095" ns0:type="simple">10.2466/pr0.1974.34.3c.1095</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref048">
<label>48</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Thompson</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Govindarajulu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Doksum</surname> <given-names>K</given-names></name>. <article-title>Distribution and power of the absolute normal scores test</article-title>. <source>Journal of the American Statistical Association</source>. <year>1967</year>;<volume>62</volume>(<issue>319</issue>):<fpage>966</fpage>&#8211;<lpage>975</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/01621459.1967.10500908" ns0:type="simple">10.1080/01621459.1967.10500908</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref049">
<label>49</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Bradley</surname> <given-names>JV</given-names></name>. <article-title>Nonrobustness in Z, t, and F tests at large sample sizes</article-title>. <source>Bulletin of the Psychonomic Society</source>. <year>1980</year>;<volume>16</volume>(<issue>5</issue>):<fpage>333</fpage>&#8211;<lpage>336</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3758/BF03329558" ns0:type="simple">10.3758/BF03329558</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref050">
<label>50</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Bradley</surname> <given-names>JV</given-names></name>. <article-title>The insidious L-shaped distribution</article-title>. <source>Bulletin of the Psychonomic Society</source>. <year>1982</year>;<volume>20</volume>(<issue>2</issue>):<fpage>85</fpage>&#8211;<lpage>88</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3758/BF03330089" ns0:type="simple">10.3758/BF03330089</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref051">
<label>51</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Blair</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JJ</given-names></name>. <article-title>Comparison of the power of the paired samples t test to that of Wilcoxon&#8217;s signed-ranks test under various population shapes</article-title>. <source>Psychological Bulletin</source>. <year>1985</year>;<volume>97</volume>(<issue>1</issue>):<fpage>119</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.97.1.119" ns0:type="simple">10.1037/0033-2909.97.1.119</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref052">
<label>52</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Welch</surname> <given-names>BL</given-names></name>. <article-title>The generalization of Student&#8217;s&#8217; problem when several different population variances are involved</article-title>. <source>Biometrika</source>. <year>1947</year>;<volume>34</volume>(<issue>1/2</issue>):<fpage>28</fpage>&#8211;<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1093/biomet/34.1-2.28" ns0:type="simple">10.1093/biomet/34.1-2.28</ext-link></comment> <object-id pub-id-type="pmid">20287819</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref053">
<label>53</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Kohr</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Games</surname> <given-names>PA</given-names></name>. <article-title>Robustness of the analysis of variance, the Welch procedure and a Box procedure to heterogeneous variances</article-title>. <source>The Journal of Experimental Education</source>. <year>1974</year>;<volume>43</volume>(<issue>1</issue>):<fpage>61</fpage>&#8211;<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/00220973.1974.10806305" ns0:type="simple">10.1080/00220973.1974.10806305</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref054">
<label>54</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Ramsey</surname> <given-names>PH</given-names></name>. <article-title>Exact type 1 error rates for robustness of student&#8217;s t test with unequal variances</article-title>. <source>Journal of Educational Statistics</source>. <year>1980</year>;<volume>5</volume>(<issue>4</issue>):<fpage>337</fpage>&#8211;<lpage>349</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3102/10769986005004337" ns0:type="simple">10.3102/10769986005004337</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref055">
<label>55</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Tomarken</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Serlin</surname> <given-names>RC</given-names></name>. <article-title>Comparison of ANOVA alternatives under variance heterogeneity and specific noncentrality structures</article-title>. <source>Psychological Bulletin</source>. <year>1986</year>;<volume>99</volume>(<issue>1</issue>):<fpage>90</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.99.1.90" ns0:type="simple">10.1037/0033-2909.99.1.90</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref056">
<label>56</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Lix</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Keselman</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Keselman</surname> <given-names>H</given-names></name>. <article-title>Consequences of assumption violations revisited: A quantitative review of alternatives to the one-way analysis of variance F test</article-title>. <source>Review of educational research</source>. <year>1996</year>;<volume>66</volume>(<issue>4</issue>):<fpage>579</fpage>&#8211;<lpage>619</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/1170654" ns0:type="simple">10.2307/1170654</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref057">
<label>57</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Delacre</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lakens</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Leys</surname> <given-names>C</given-names></name>. <article-title>Why psychologists should by default use Welch&#8217;s t-test instead of Student&#8217;s t-test</article-title>. <source>International Review of Social Psychology</source>. <year>2017</year>;<volume>30</volume>(<issue>1</issue>). <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.5334/irsp.82" ns0:type="simple">10.5334/irsp.82</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref058">
<label>58</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Zimmerman</surname> <given-names>DW</given-names></name>. <article-title>Two separate effects of variance heterogeneity on the validity and power of significance tests of location</article-title>. <source>Statistical Methodology</source>. <year>2006</year>;<volume>3</volume>(<issue>4</issue>):<fpage>351</fpage>&#8211;<lpage>374</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.stamet.2005.10.002" ns0:type="simple">10.1016/j.stamet.2005.10.002</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref059">
<label>59</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Harwell</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Rubinstein</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Hayes</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Olds</surname> <given-names>CC</given-names></name>. <article-title>Summarizing Monte Carlo results in methodological research: The one-and two-factor fixed effects ANOVA cases</article-title>. <source>Journal of educational statistics</source>. <year>1992</year>;<volume>17</volume>(<issue>4</issue>):<fpage>315</fpage>&#8211;<lpage>339</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/1165126" ns0:type="simple">10.2307/1165126</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref060">
<label>60</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Baker</surname> <given-names>BO</given-names></name>, <name name-style="western"><surname>Hardyck</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Petrinovich</surname> <given-names>LF</given-names></name>. <article-title>Weak Measurements vs. Strong Statistics: An Empirical Critique of SS Stevens&#8217; Proscriptions on Statistics</article-title>. <source>Educational and psychological measurement</source>. <year>1966</year>;<volume>26</volume>(<issue>2</issue>):<fpage>291</fpage>&#8211;<lpage>309</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/001316446602600204" ns0:type="simple">10.1177/001316446602600204</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref061">
<label>61</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Labovitz</surname> <given-names>S</given-names></name>. <article-title>Some observations on measurement and statistics</article-title>. <source>Social Forces</source>. <year>1967</year>;<volume>46</volume>(<issue>2</issue>):<fpage>151</fpage>&#8211;<lpage>160</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/2574595" ns0:type="simple">10.2307/2574595</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref062">
<label>62</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Hsu</surname> <given-names>TC</given-names></name>, <name name-style="western"><surname>Feldt</surname> <given-names>LS</given-names></name>. <article-title>The effect of limitations on the number of criterion score values on the significance level of the F-test</article-title>. <source>American Educational Research Journal</source>. <year>1969</year>;<volume>6</volume>(<issue>4</issue>):<fpage>515</fpage>&#8211;<lpage>527</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3102/00028312006004515" ns0:type="simple">10.3102/00028312006004515</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref063">
<label>63</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Gregoire</surname> <given-names>TG</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>B</given-names></name>. <article-title>Analysis of ordinal data to detect population differences</article-title>. <source>Psychological Bulletin</source>. <year>1987</year>;<volume>101</volume>(<issue>1</issue>):<fpage>159</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0033-2909.101.1.159" ns0:type="simple">10.1037/0033-2909.101.1.159</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref064">
<label>64</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Sawilowsky</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Hillman</surname> <given-names>SB</given-names></name>. <article-title>Power of the independent samples t test under a prevalent psychometric measure distribution</article-title>. <source>Journal of Consulting and Clinical Psychology</source>. <year>1992</year>;<volume>60</volume>(<issue>2</issue>):<fpage>240</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0022-006X.60.2.240" ns0:type="simple">10.1037/0022-006X.60.2.240</ext-link></comment> <object-id pub-id-type="pmid">1592953</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref065">
<label>65</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Labovitz</surname> <given-names>S</given-names></name>. <article-title>The assignment of numbers to rank order categories</article-title>. <source>American sociological review</source>. <year>1970</year>; p. <fpage>515</fpage>&#8211;<lpage>524</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/2092993" ns0:type="simple">10.2307/2092993</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref066">
<label>66</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Trachtman</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Giambalvo</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Dippner</surname> <given-names>RS</given-names></name>. <article-title>On the assumptions concerning the assumptions of at test</article-title>. <source>The Journal of General Psychology</source>. <year>1978</year>;<volume>99</volume>(<issue>1</issue>):<fpage>107</fpage>&#8211;<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/00221309.1978.9920901" ns0:type="simple">10.1080/00221309.1978.9920901</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref067">
<label>67</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Lucke</surname> <given-names>JF</given-names></name>. <article-title>Student&#8217;s t test and the Glasgow Coma Scale</article-title>. <source>Annals of emergency medicine</source>. <year>1996</year>;<volume>28</volume>(<issue>4</issue>):<fpage>408</fpage>&#8211;<lpage>413</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/s0196-0644(96)70006-9" ns0:type="simple">10.1016/s0196-0644(96)70006-9</ext-link></comment> <object-id pub-id-type="pmid">8839526</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref068">
<label>68</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Zumbo</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Zimmerman</surname> <given-names>DW</given-names></name>. <article-title>Is the selection of statistical methods governed by level of measurement?</article-title> <source>Canadian Psychology/Psychologie canadienne</source>. <year>1993</year>;<volume>34</volume>(<issue>4</issue>):<fpage>390</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/h0078865" ns0:type="simple">10.1037/h0078865</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref069">
<label>69</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Larrabee</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Scott</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Bello</surname> <given-names>NM</given-names></name>. <article-title>Ordinary least squares regression of ordered categorical data: Inferential implications for practice</article-title>. <source>Journal of agricultural, biological, and environmental statistics</source>. <year>2014</year>;<volume>19</volume>(<issue>3</issue>):<fpage>373</fpage>&#8211;<lpage>386</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s13253-014-0176-z" ns0:type="simple">10.1007/s13253-014-0176-z</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref070">
<label>70</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Liddell</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Kruschke</surname> <given-names>JK</given-names></name>. <article-title>Analyzing ordinal data with metric models: What could possibly go wrong?</article-title> <source>Journal of Experimental Social Psychology</source>. <year>2018</year>;<volume>79</volume>:<fpage>328</fpage>&#8211;<lpage>348</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.jesp.2018.08.009" ns0:type="simple">10.1016/j.jesp.2018.08.009</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref071">
<label>71</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>McArdle</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Salthouse</surname> <given-names>TA</given-names></name>. <article-title>Investigating ceiling effects in longitudinal data analysis</article-title>. <source>Multivariate behavioral research</source>. <year>2008</year>;<volume>43</volume>(<issue>3</issue>):<fpage>476</fpage>&#8211;<lpage>496</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/00273170802285941" ns0:type="simple">10.1080/00273170802285941</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref072">
<label>72</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Twisk</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rijmen</surname> <given-names>F</given-names></name>. <article-title>Longitudinal tobit regression: a new approach to analyze outcome variables with floor or ceiling effects</article-title>. <source>Journal of clinical epidemiology</source>. <year>2009</year>;<volume>62</volume>(<issue>9</issue>):<fpage>953</fpage>&#8211;<lpage>958</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.jclinepi.2008.10.003" ns0:type="simple">10.1016/j.jclinepi.2008.10.003</ext-link></comment> <object-id pub-id-type="pmid">19211221</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref073">
<label>73</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Zhu</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gonzalez</surname> <given-names>J</given-names></name>. <article-title>Modeling Floor Effects in Standardized Vocabulary Test Scores in a Sample of Low SES Hispanic Preschool Children under the Multilevel Structural Equation Modeling Framework</article-title>. <source>Frontiers in psychology</source>. <year>2017</year>;<volume>8</volume>:<fpage>2146</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3389/fpsyg.2017.02146" ns0:type="simple">10.3389/fpsyg.2017.02146</ext-link></comment> <object-id pub-id-type="pmid">29312033</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref074">
<label>74</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Resch</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Isenberg</surname> <given-names>E</given-names></name>. <article-title>How do test scores at the ceiling affect value-added estimates?</article-title> <source>Statistics and Public Policy</source>. <year>2018</year>;<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/2330443X.2018.1460226" ns0:type="simple">10.1080/2330443X.2018.1460226</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref075">
<label>75</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Twisk</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Spriensma</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Eekhout</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>de</surname> <given-names>Boer M</given-names></name>, <name name-style="western"><surname>Luime</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>de</surname> <given-names>Jong P</given-names></name>, <etal>et al</etal>. <article-title>Analysing outcome variables with floor effects due to censoring: a simulation study with longitudinal trial data</article-title>. <source>Epidemiology, Biostatistics and Public Health</source>. <year>2018</year>;<volume>15</volume>(<issue>2</issue>).</mixed-citation>
</ref>
<ref id="pone.0220889.ref076">
<label>76</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Cheung</surname> <given-names>YB</given-names></name>. <article-title>Zero-inflated models for regression analysis of count data: a study of growth and development</article-title>. <source>Statistics in medicine</source>. <year>2002</year>;<volume>21</volume>(<issue>10</issue>):<fpage>1461</fpage>&#8211;<lpage>1469</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1002/sim.1088" ns0:type="simple">10.1002/sim.1088</ext-link></comment> <object-id pub-id-type="pmid">12185896</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref077">
<label>77</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Holstein</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Avlund</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Due</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Martinussen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Keiding</surname> <given-names>N</given-names></name>. <article-title>The measurement of change in functional ability: dealing with attrition and the floor/ceiling effect</article-title>. <source>Archives of gerontology and geriatrics</source>. <year>2006</year>;<volume>43</volume>(<issue>3</issue>):<fpage>337</fpage>&#8211;<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.archger.2005.12.004" ns0:type="simple">10.1016/j.archger.2005.12.004</ext-link></comment> <object-id pub-id-type="pmid">16469399</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref078">
<label>78</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Proust-Lima</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dartigues</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Jacqmin-Gadda</surname> <given-names>H</given-names></name>. <article-title>Misuse of the linear mixed model when evaluating risk factors of cognitive decline</article-title>. <source>American journal of epidemiology</source>. <year>2011</year>;<volume>174</volume>(<issue>9</issue>):<fpage>1077</fpage>&#8211;<lpage>1088</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1093/aje/kwr243" ns0:type="simple">10.1093/aje/kwr243</ext-link></comment> <object-id pub-id-type="pmid">21965187</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref079">
<label>79</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Iachina</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bilenberg</surname> <given-names>N</given-names></name>. <article-title>Measuring reliable change of emotional and behavioural problems in children</article-title>. <source>Psychiatry research</source>. <year>2012</year>;<volume>200</volume>(<issue>2-3</issue>):<fpage>867</fpage>&#8211;<lpage>871</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.psychres.2012.06.023" ns0:type="simple">10.1016/j.psychres.2012.06.023</ext-link></comment> <object-id pub-id-type="pmid">22789839</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref080">
<label>80</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wilcox</surname> <given-names>RR</given-names></name>. <article-title>The goals and strategies of robust methods</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>. <year>1998</year>;<volume>51</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1111/j.2044-8317.1998.tb00659.x" ns0:type="simple">10.1111/j.2044-8317.1998.tb00659.x</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref081">
<label>81</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wilcox</surname> <given-names>RR</given-names></name>. <article-title>How many discoveries have been lost by ignoring modern statistical methods?</article-title> <source>American Psychologist</source>. <year>1998</year>;<volume>53</volume>(<issue>3</issue>):<fpage>300</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/0003-066X.53.3.300" ns0:type="simple">10.1037/0003-066X.53.3.300</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref082">
<label>82</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wilcox</surname> <given-names>RR</given-names></name>. <article-title>A note on testing hypotheses about trimmed means</article-title>. <source>Biometrical Journal</source>. <year>1996</year>;<volume>38</volume>(<issue>2</issue>):<fpage>173</fpage>&#8211;<lpage>180</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1002/bimj.4710380205" ns0:type="simple">10.1002/bimj.4710380205</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref083">
<label>83</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wilcox</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Keselman</surname> <given-names>H</given-names></name>. <article-title>Modern robust data analysis methods: measures of central tendency</article-title>. <source>Psychological methods</source>. <year>2003</year>;<volume>8</volume>(<issue>3</issue>):<fpage>254</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/1082-989X.8.3.254" ns0:type="simple">10.1037/1082-989X.8.3.254</ext-link></comment> <object-id pub-id-type="pmid">14596490</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref084">
<label>84</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Yuen</surname> <given-names>KK</given-names></name>. <article-title>The two-sample trimmed t for unequal population variances</article-title>. <source>Biometrika</source>. <year>1974</year>;<volume>61</volume>(<issue>1</issue>):<fpage>165</fpage>&#8211;<lpage>170</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2307/2334299" ns0:type="simple">10.2307/2334299</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref085">
<label>85</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wagenmakers</surname> <given-names>EJ</given-names></name>. <article-title>A practical solution to the pervasive problems of p values</article-title>. <source>Psychonomic bulletin &amp; review</source>. <year>2007</year>;<volume>14</volume>(<issue>5</issue>):<fpage>779</fpage>&#8211;<lpage>804</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3758/BF03194105" ns0:type="simple">10.3758/BF03194105</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref086">
<label>86</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Rouder</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Speckman</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Morey</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Iverson</surname> <given-names>G</given-names></name>. <article-title>Bayesian t tests for accepting and rejecting the null hypothesis</article-title>. <source>Psychonomic bulletin &amp; review</source>. <year>2009</year>;<volume>16</volume>(<issue>2</issue>):<fpage>225</fpage>&#8211;<lpage>237</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3758/PBR.16.2.225" ns0:type="simple">10.3758/PBR.16.2.225</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref087">
<label>87</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wetzels</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Grasman</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Wagenmakers</surname> <given-names>EJ</given-names></name>. <article-title>A default Bayesian hypothesis test for ANOVA designs</article-title>. <source>The American Statistician</source>. <year>2012</year>;<volume>66</volume>(<issue>2</issue>):<fpage>104</fpage>&#8211;<lpage>111</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1080/00031305.2012.695956" ns0:type="simple">10.1080/00031305.2012.695956</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref088">
<label>88</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Johnson</surname> <given-names>VE</given-names></name>. <article-title>Revised standards for statistical evidence</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>48</issue>):<fpage>19313</fpage>&#8211;<lpage>19317</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1073/pnas.1313476110" ns0:type="simple">10.1073/pnas.1313476110</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref089">
<label>89</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wetzels</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Raaijmakers</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Jakab</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Wagenmakers</surname> <given-names>EJ</given-names></name>. <article-title>How to quantify support for and against the null hypothesis: A flexible WinBUGS implementation of a default Bayesian t test</article-title>. <source>Psychonomic bulletin &amp; review</source>. <year>2009</year>;<volume>16</volume>(<issue>4</issue>):<fpage>752</fpage>&#8211;<lpage>760</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.3758/PBR.16.4.752" ns0:type="simple">10.3758/PBR.16.4.752</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref090">
<label>90</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Wagenmakers</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Lodewyckx</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kuriyal</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Grasman</surname> <given-names>R</given-names></name>. <article-title>Bayesian hypothesis testing for psychologists: A tutorial on the Savage&#8211;Dickey method</article-title>. <source>Cognitive psychology</source>. <year>2010</year>;<volume>60</volume>(<issue>3</issue>):<fpage>158</fpage>&#8211;<lpage>189</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.cogpsych.2009.12.001" ns0:type="simple">10.1016/j.cogpsych.2009.12.001</ext-link></comment> <object-id pub-id-type="pmid">20064637</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref091">
<label>91</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Schuirmann</surname> <given-names>DJ</given-names></name>. <article-title>A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability</article-title>. <source>Journal of pharmacokinetics and biopharmaceutics</source>. <year>1987</year>;<volume>15</volume>(<issue>6</issue>):<fpage>657</fpage>&#8211;<lpage>680</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/BF01068419" ns0:type="simple">10.1007/BF01068419</ext-link></comment> <object-id pub-id-type="pmid">3450848</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref092">
<label>92</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Lakens</surname> <given-names>D</given-names></name>. <article-title>Equivalence tests: a practical primer for t tests, correlations, and meta-analyses</article-title>. <source>Social Psychological and Personality Science</source>. <year>2017</year>;<volume>8</volume>(<issue>4</issue>):<fpage>355</fpage>&#8211;<lpage>362</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/1948550617697177" ns0:type="simple">10.1177/1948550617697177</ext-link></comment> <object-id pub-id-type="pmid">28736600</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref093">
<label>93</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Cohen</surname> <given-names>J</given-names></name>. <chapter-title>The earth is round (p&#161;. 05)</chapter-title>. In: <source>What if there were no significance tests?</source> <publisher-name>Routledge</publisher-name>; <year>2016</year>. p. <fpage>69</fpage>&#8211;<lpage>82</lpage>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref094">
<label>94</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Cumming</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Finch</surname> <given-names>S</given-names></name>. <article-title>A primer on the understanding, use, and calculation of confidence intervals that are based on central and noncentral distributions</article-title>. <source>Educational and Psychological Measurement</source>. <year>2001</year>;<volume>61</volume>(<issue>4</issue>):<fpage>532</fpage>&#8211;<lpage>574</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/0013164401614002" ns0:type="simple">10.1177/0013164401614002</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref095">
<label>95</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Cumming</surname> <given-names>G</given-names></name>. <article-title>The new statistics: Why and how</article-title>. <source>Psychological science</source>. <year>2014</year>;<volume>25</volume>(<issue>1</issue>):<fpage>7</fpage>&#8211;<lpage>29</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/0956797613504966" ns0:type="simple">10.1177/0956797613504966</ext-link></comment> <object-id pub-id-type="pmid">24220629</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref096">
<label>96</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Kelley</surname> <given-names>K</given-names></name>. <article-title>The effects of nonnormal distributions on confidence intervals around the standardized mean difference: Bootstrap and parametric confidence intervals</article-title>. <source>Educational and Psychological Measurement</source>. <year>2005</year>;<volume>65</volume>(<issue>1</issue>):<fpage>51</fpage>&#8211;<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/0013164404264850" ns0:type="simple">10.1177/0013164404264850</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref097">
<label>97</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Johnson</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kotz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Balakrishnan</surname> <given-names>N</given-names></name>. <source>Continuous Univariate Distributions</source>. <volume>vol. 1</volume>. <edition>2nd ed</edition>. <publisher-name>Wiley</publisher-name>: <publisher-loc>New York</publisher-loc>; <year>1994</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref098">
<label>98</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Johnson</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kotz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Balakrishnan</surname> <given-names>N</given-names></name>. <source>Continuous Univariate Distributions</source>. <volume>vol. 2</volume>. <edition>2nd ed</edition>. <publisher-name>Wiley</publisher-name>: <publisher-loc>New York</publisher-loc>; <year>1995</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref099">
<label>99</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Wasserman</surname> <given-names>L</given-names></name>. <source>All of statistics</source>. <publisher-name>Springer Science</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref100">
<label>100</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Cooper</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Hedges</surname> <given-names>LV</given-names></name>, <name name-style="western"><surname>Valentine</surname> <given-names>JC</given-names></name>. <source>The handbook of research synthesis and meta-analysis</source>. <publisher-name>Russell Sage Foundation</publisher-name>; <year>2009</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref101">
<label>101</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Carpenter</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hoffman</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Goodrich</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Betancourt</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Stan: A probabilistic programming language</article-title>. <source>Journal of statistical software</source>. <year>2017</year>;<volume>76</volume>(<issue>1</issue>). <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.18637/jss.v076.i01" ns0:type="simple">10.18637/jss.v076.i01</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref102">
<label>102</label>
<mixed-citation publication-type="book" ns0:type="simple">
<name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Stern</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Carlin</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <source>Bayesian data analysis</source>. <publisher-name>Chapman and Hall/CRC</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref103">
<label>103</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Blair</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Higgins</surname> <given-names>JJ</given-names></name>. <article-title>A comparison of the power of Wilcoxon&#8217;s rank-sum statistics to that of Student&#8217;s t statistic under various nonnormal distributions</article-title>. <source>Evaluation Review</source>. <year>1980</year>;<volume>4</volume>(<issue>5</issue>):<fpage>645</fpage>&#8211;<lpage>656</lpage>.</mixed-citation>
</ref>
<ref id="pone.0220889.ref104">
<label>104</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Knapp</surname> <given-names>TR</given-names></name>. <article-title>Treating ordinal scales as interval scales: an attempt to resolve the controversy</article-title>. <source>Nursing research</source>. <year>1990</year>;<volume>39</volume>(<issue>2</issue>):<fpage>121</fpage>&#8211;<lpage>123</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1097/00006199-199003000-00019" ns0:type="simple">10.1097/00006199-199003000-00019</ext-link></comment> <object-id pub-id-type="pmid">2315066</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref105">
<label>105</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Hunter</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>May</surname> <given-names>RB</given-names></name>. <article-title>Some myths concerning parametric and nonparametric tests</article-title>. <source>Canadian Psychology/Psychologie canadienne</source>. <year>1993</year>;<volume>34</volume>(<issue>4</issue>):<fpage>384</fpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1037/h0078860" ns0:type="simple">10.1037/h0078860</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref106">
<label>106</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Whitaker</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gordon</surname> <given-names>S</given-names></name>. <article-title>Floor effects on the WISC-IV</article-title>. <source>International Journal of Developmental Disabilities</source>. <year>2012</year>;<volume>58</volume>(<issue>2</issue>):<fpage>111</fpage>&#8211;<lpage>119</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1179/2047387711Y.0000000012" ns0:type="simple">10.1179/2047387711Y.0000000012</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0220889.ref107">
<label>107</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Pezzuti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Nacinovich</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Oggiano</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bomba</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ferri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>La Stella</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Beyond the floor effect on the WISC-IV in individuals with Down syndrome: are there cognitive strengths and weaknesses?</article-title> <source>Journal of Intellectual Disability Research</source>. <year>2018</year>;<volume>62</volume>(<issue>7</issue>):<fpage>593</fpage>&#8211;<lpage>603</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1111/jir.12499" ns0:type="simple">10.1111/jir.12499</ext-link></comment> <object-id pub-id-type="pmid">29682828</object-id></mixed-citation>
</ref>
<ref id="pone.0220889.ref108">
<label>108</label>
<mixed-citation publication-type="journal" ns0:type="simple">
<name name-style="western"><surname>Keeley</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>English</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Irons</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Henslee</surname> <given-names>AM</given-names></name>. <article-title>Investigating halo and ceiling effects in student evaluations of instruction</article-title>. <source>Educational and Psychological Measurement</source>. <year>2013</year>;<volume>73</volume>(<issue>3</issue>):<fpage>440</fpage>&#8211;<lpage>457</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/0013164412475300" ns0:type="simple">10.1177/0013164412475300</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0220889.r001" specific-use="decision-letter">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0220889.r001</article-id>
<title-group>
<article-title>Decision Letter 0</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name name-style="western">
<surname>Hutson</surname>
<given-names>Alan D</given-names>
</name>
<role>Academic Editor</role>
</contrib>
</contrib-group>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Alan D Hutson</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<related-object document-id="10.1371/journal.pone.0220889" document-id-type="doi" document-type="article" id="rel-obj001" link-type="peer-reviewed-article" />
<custom-meta-group>
<custom-meta>
<meta-name>Submission Version</meta-name>
<meta-value>0</meta-value>
</custom-meta>
</custom-meta-group>
</front-stub>
<body>
<p>
<named-content content-type="letter-date">26 Jul 2019</named-content>
</p>
<p>Robustness of statistical methods when measure is affected by ceiling and/or floor effect</p>
<p>PONE-D-19-14718</p>
<p>Dear Dr. Simkovic,</p>
<p>We are pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it complies with all outstanding technical requirements.</p>
<p>Within one week, you will receive an e-mail containing information on the amendments required prior to publication. When all required modifications have been addressed, you will receive a formal acceptance letter and your manuscript will proceed to our production department and be scheduled for publication.</p>
<p>Shortly after the formal acceptance letter is sent, an invoice for payment will follow. To ensure an efficient production and billing process, please log into Editorial Manager at <ext-link ext-link-type="uri" ns0:href="https://www.editorialmanager.com/pone/" ns0:type="simple">https://www.editorialmanager.com/pone/</ext-link>, click the "Update My Information" link at the top of the page, and update your user information. If you have any billing related questions, please contact our Author Billing department directly at <email ns0:type="simple">authorbilling@plos.org</email>.</p>
<p>If your institution or institutions have a press office, please notify them about your upcoming paper to enable them to help maximize its impact. If they will be preparing press materials for this manuscript, you must inform our press team as soon as possible and no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email ns0:type="simple">onepress@plos.org</email>.</p>
<p>With kind regards,</p>
<p>Alan D Hutson</p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
<p>Additional Editor Comments (optional):</p>
<p>Please attend to the typos noted by one reviewer.</p>
<p>Reviewers' comments:</p>
<p>Reviewer's Responses to Questions</p>
<p><bold>Comments to the Author</bold></p>
<p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
<p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>2. Has the statistical analysis been performed appropriately and rigorously? </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
<p>The <ext-link ext-link-type="uri" ns0:href="http://www.plosone.org/static/policies.action#sharing" ns0:type="simple">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
<p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>5. Review Comments to the Author</p>
<p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
<p>Reviewer #1: If possible, as written in the attached review report, application of proposed methods on real data sets may be shown.</p>
<p>Reviewer #2: 1. This study investigates the effects of ceiling and/or floor effects on hypothesis testing, such as t-test, F-test, in addition, on estimations of effect sizes and confidence interval, etc. The author presented explicit results and concluded that the presence of CFE results in bias, divergence in estimation and testing after comparing different statistical methods with different data distributions. The uniqueness in this study is the use of measurement theory in defining CFE and using this theory in data generation. This study contributes to the CFE research and is worthy of publication.</p>
<p>2. There are minor typos in the manuscript, please read throughly and correct them , e.g., Line 511, Line 958&#8230;</p>
<p>**********</p>
<p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" ns0:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ns0:type="simple">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
<p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p>
<p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" ns0:href="https://www.plos.org/privacy-policy" ns0:type="simple">Privacy Policy</ext-link>.</p>
<p>Reviewer #1: No</p>
<p>Reviewer #2: No</p>
<supplementary-material id="pone.0220889.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" ns0:href="info:doi/10.1371/journal.pone.0220889.s002" ns0:type="simple">
<label>Attachment</label>
<caption>
<p>Submitted filename: <named-content content-type="submitted-filename">SNDwivedi.Plos. One.doc</named-content></p>
</caption>
</supplementary-material>
</body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0220889.r002" specific-use="acceptance-letter">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0220889.r002</article-id>
<title-group>
<article-title>Acceptance letter</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name name-style="western">
<surname>Hutson</surname>
<given-names>Alan D</given-names>
</name>
<role>Academic Editor</role>
</contrib>
</contrib-group>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Alan D Hutson</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<related-object document-id="10.1371/journal.pone.0220889" document-id-type="doi" document-type="article" id="rel-obj002" link-type="peer-reviewed-article" />
</front-stub>
<body>
<p>
<named-content content-type="letter-date">2 Aug 2019</named-content>
</p>
<p>PONE-D-19-14718</p>
<p>Robustness of statistical methods when measure is affected by ceiling and/or floor effect </p>
<p>Dear Dr. &#352;imkovic:</p>
<p>I am pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
<p>If your institution or institutions have a press office, please notify them about your upcoming paper at this point, to enable them to help maximize its impact. If they will be preparing press materials for this manuscript, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email ns0:type="simple">onepress@plos.org</email>.</p>
<p>For any other questions or concerns, please email <email ns0:type="simple">plosone@plos.org</email>. </p>
<p>Thank you for submitting your work to PLOS ONE.</p>
<p>With kind regards,</p>
<p>PLOS ONE Editorial Office Staff</p>
<p>on behalf of</p>
<p>Dr. Alan D Hutson  </p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
</body>
</sub-article>
</article>