<article xmlns:ns0="http://www.w3.org/1999/xlink" xmlns:ns1="http://www.w3.org/1998/Math/MathML" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLOS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pone.0222406</article-id>
<article-id pub-id-type="publisher-id">PONE-D-19-15441</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Signal processing</subject><subj-group><subject>Image processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Bone imaging</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Bone imaging</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Bone imaging</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>X-ray radiography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Bioengineering</subject><subj-group><subject>Biotechnology</subject><subj-group><subject>Medical devices and equipment</subject><subj-group><subject>Assistive technologies</subject><subj-group><subject>Prosthetics</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Bioengineering</subject><subj-group><subject>Biotechnology</subject><subj-group><subject>Medical devices and equipment</subject><subj-group><subject>Assistive technologies</subject><subj-group><subject>Prosthetics</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Medical devices and equipment</subject><subj-group><subject>Assistive technologies</subject><subj-group><subject>Prosthetics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Mathematical functions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Surgical and invasive medical procedures</subject><subj-group><subject>Musculoskeletal system procedures</subject><subj-group><subject>Arthroplasty</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Development of a denoising convolutional neural network-based algorithm for metal artifact reduction in digital tomosynthesis for arthroplasty: A phantom study</article-title>
<alt-title alt-title-type="running-head">Metal artifact reduction applying denoising convolutional neural network</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" ns0:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2322-714X</contrib-id>
<name name-style="western">
<surname>Gomi</surname>
<given-names>Tsutomu</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; original draft</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001" />
</contrib>
<contrib contrib-type="author" ns0:type="simple">
<name name-style="western">
<surname>Sakai</surname>
<given-names>Rina</given-names>
</name>
<role content-type="http://credit.casrai.org/">Software</role>
<xref ref-type="aff" rid="aff001" />
</contrib>
<contrib contrib-type="author" ns0:type="simple">
<name name-style="western">
<surname>Hara</surname>
<given-names>Hidetake</given-names>
</name>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; review &amp; editing</role>
<xref ref-type="aff" rid="aff001" />
</contrib>
<contrib contrib-type="author" ns0:type="simple">
<name name-style="western">
<surname>Watanabe</surname>
<given-names>Yusuke</given-names>
</name>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing &#8211; review &amp; editing</role>
<xref ref-type="aff" rid="aff001" />
</contrib>
<contrib contrib-type="author" ns0:type="simple">
<name name-style="western">
<surname>Mizukami</surname>
<given-names>Shinya</given-names>
</name>
<role content-type="http://credit.casrai.org/">Visualization</role>
<xref ref-type="aff" rid="aff001" />
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>School of Allied Health Sciences, Kitasato University, Sagamihara, Kanagawa, Japan</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" ns0:type="simple">
<name name-style="western">
<surname>Zeng</surname>
<given-names>Li</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1" />
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Chongqing University, CHINA</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email ns0:type="simple">gomi@kitasato-u.ac.jp</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>13</day>
<month>9</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<year>2019</year>
</pub-date>
<volume>14</volume>
<issue>9</issue>
<elocation-id>e0222406</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>5</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>8</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Gomi et al</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" ns0:href="info:doi/10.1371/journal.pone.0222406" />
<abstract>
<p>The present study aimed to develop a denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm for decreasing metal objects in digital tomosynthesis (DT) for arthroplasty by using projection data. For metal artifact reduction (MAR), we implemented a DnCNN-MARHR algorithm based on a training network (mini-batch stochastic gradient descent algorithm with momentum) to estimate the residual reference (140 keV virtual monochromatic [VM]) and object (70 kV with metal artifacts) images. For this, we used projection data and subtracted the estimated residual images from the object images, involving hybrid and subjectively reconstructed image usage (back projection and maximum likelihood expectation maximization [MLEM]). The DnCNN-MARHR algorithm was compared with the dual-energy material decomposition reconstruction algorithm (DEMDRA), VM, MLEM, established and commonly used filtered back projection (FBP), and a simultaneous algebraic reconstruction technique-total variation (SART-TV) with MAR processing. MAR was compared using artifact index (AI) and texture analysis. Artifact spread functions (ASFs) for images that were out-of-plane and in-focus were evaluated using a prosthesis phantom. The overall performance of the DnCNN-MARHR algorithm was adequate with regard to the ASF, and the derived images showed better results, without being influenced by the metal type (AI was almost equal to the best value for the DEMDRA). In the ASF analysis, the DnCNN-MARHR algorithm generated better MAR compared with that obtained employing usual algorithms for reconstruction using MAR processing. In addition, comparison of the difference (mean square error) between DnCNN-MARHR and the conventional algorithm resulted in the smallest VM. The DnCNN-MARHR algorithm showed the best performance with regard to image homogeneity in the texture analysis. The proposed algorithm is particularly useful for reducing artifacts in the longitudinal direction, and it is not affected by tissue misclassification.</p>
</abstract>
<funding-group>
<funding-statement>The author(s) received no specific funding for this work.</funding-statement>
</funding-group>
<counts>
<fig-count count="11" />
<table-count count="2" />
<page-count count="22" />
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the manuscript.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Cementless hip arthroplasty has gained more popularity in clinic, recently. It is essential that biological fixation procedures employed are reliable for achieving success with this technique [<xref ref-type="bibr" rid="pone.0222406.ref001">1</xref>]. Medical imaging plays an important role for assessing the proper placement of the components of hip arthroplasty, postoperatively, and also to evaluate the potential complications in the long-term [<xref ref-type="bibr" rid="pone.0222406.ref002">2</xref>]. Digital tomosynthesis (DT), a recently developed technique, provides three-dimensional (3D) structural information to a limited extent, by combining computed tomography (CT) with the advantages of digital imaging [<xref ref-type="bibr" rid="pone.0222406.ref001">1</xref>&#8211;<xref ref-type="bibr" rid="pone.0222406.ref008">8</xref>], and another advantage of DT is that it can be employed easily with radiography, it can help reducing the radiation doses. However, the image rebuilding procedure using DT is unpredictable and is restricted by low ratios of signal-to-noise, related to the superposition of multiple low-exposure projection images.</p>
<p>Metal objects, that reduce the image quality by decreasing contrast and masking specific features, obstruct the observation of relevant organ parts leading to incorrect diagnosis. Before imaging, it is necessary to ascertain that there is no hematoma or inflammation in tissues surrounding target area and to evaluate any potential interaction of osteosynthetic materials, metallic joint prostheses or implants with nearby tissues and radiation.</p>
<p>Artifacts in DT imaging show along the sweep direction, as zones of much less signal, surrounding the edges of metal prostheses and osteosynthetic materials, which are highly attenuating. This is mostly due to discrepancies between the reality (i.e., wide spectral range) and the reconstruction algorithm assumptions (i.e., ideal monochromatic beam). A relatively minor contribution to these artifacts is also caused by limited sweep angle.</p>
<p>Efficiency of iterative reconstruction (IR) was investigated in earlier studies on DT for arthroplasty [<xref ref-type="bibr" rid="pone.0222406.ref001">1</xref>, <xref ref-type="bibr" rid="pone.0222406.ref006">6</xref>, <xref ref-type="bibr" rid="pone.0222406.ref007">7</xref>]. Indeed, the image quality was superior and the balance between low- and high-frequency features was better with IR, compared with the filtered back projection (FBP) [<xref ref-type="bibr" rid="pone.0222406.ref005">5</xref>] technique [<xref ref-type="bibr" rid="pone.0222406.ref001">1</xref>, <xref ref-type="bibr" rid="pone.0222406.ref007">7</xref>]. In fact, many of the earlier studies made a quantitative comparison of radiation doses generated by different prevailing DT algorithms for arthroplasty and the image qualities [<xref ref-type="bibr" rid="pone.0222406.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>] and have noticed that IR effectively lowers both radiation exposure and quantum noise. In the latest study [<xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>], it was found that among IR algorithms (including total variation [TV]-based compressive sensing [<xref ref-type="bibr" rid="pone.0222406.ref010">10</xref>&#8211;<xref ref-type="bibr" rid="pone.0222406.ref013">13</xref>]), the reconstruction algorithm with the best effect for reducing metal artifacts in DT imaging was maximum likelihood expectation maximization (MLEM) [<xref ref-type="bibr" rid="pone.0222406.ref014">14</xref>].</p>
<p>Previous reports have evaluated metal artifacts and have developed methods (adaptive filtering [combined IR and shift-and-add method] using polychromatic X-ray [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>] and combined material decomposition and adaptive filtering using dual-energy [DE] X-ray [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]) for metal artifact reduction (MAR) [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>&#8211;<xref ref-type="bibr" rid="pone.0222406.ref018">18</xref>]. Among these reported MAR methods, the most effective method for reducing metal artifacts at present is the DE material decomposition reconstruction algorithm (DEMDRA) [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. Although the DEMDRA is particularly excellent for reducing the high-frequency component in a metal artifact image, its drawback involves mechanical limitations (DE X-ray exposure) because it requires material decomposition processing using DE X-rays. Therefore, further studies are required to generalize the benefits of MAR.</p>
<p>Deep learning approaches have successfully been employed recently, in pattern recognition and image processing methods, including image denoising [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>], image super-resolution [<xref ref-type="bibr" rid="pone.0222406.ref020">20</xref>], and low-dose CT reconstruction [<xref ref-type="bibr" rid="pone.0222406.ref021">21</xref>, <xref ref-type="bibr" rid="pone.0222406.ref022">22</xref>]. For instance, a convolutional neural network (CNN) has been implemented for artifact reduction in medical imaging [<xref ref-type="bibr" rid="pone.0222406.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0222406.ref024">24</xref>], and the CNN has been employed to get rid-off the residual errors from MAR. Even though these previous studies showed that the CNN could enhance MAR effectively, no study has been conducted on MAR using DT. A CNN-based modification (denoising convolutional neural network [DnCNN]) was presented by Zhang et al. [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>]. The feature of this DnCNN is construction to include the progresses in learning algorithms, very deep architecture and methods of regularization for image denoising. The reference image used in the training workflow for the DnCNN is important for enhancing MAR. Different physical elements can generate metal artifacts, and these include beam hardening, photon starvation, and X-ray scattering. Beam hardening results when an X-ray beam consisting of polychromatic photons passes through a medium. It was suggested earlier that DE virtual monochromatic (VM) spectral imaging can potentially reduce beam hardening induced metal artifacts [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>, <xref ref-type="bibr" rid="pone.0222406.ref025">25</xref>&#8211;<xref ref-type="bibr" rid="pone.0222406.ref029">29</xref>]. We think that the application of the VM approach is useful for MAR, as the reference image is appropriate. By performing denoising at the projection data level using DnCNN processing, a reduction effect for metal artifacts after reconstruction can be expected. To support this basis, DnCNN is designed primarily to remove noise from the image. It comprises of a built-in deep feedforward CNN. However, as the DnCNN uses a residual learning method, it is also possible to train the DnCNN architecture to reduce artifacts. In the residual learning method, effects as the MAR method can be expected because the residual image is estimated by learning in the DnCNN network.</p>
<p>The DnCNN algorithm could possibly provide a superior solution to the intrinsic problems. In addition, a decrease in metal artifacts can be achieved by reconstruction employing denoised projection results from each material (e.g., titanium and bone) and adaptive filtering [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>]. The novelty of this study is to reduce metal artifacts by processing DnCNN in combination with adaptive filtering [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>] at the projection data level. In the present study, we developed a hybrid method of reconstruction that is based on projection space approach by combining the DnCNN and adaptive filtering [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>] with a focus on reducing metal artifacts (DnCNN MAR hybrid reconstruction [DnCNN-MARHR] algorithm) in DT. The developmental process of the method and its basic evaluation are presented in this study.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Phantom specifications</title>
<p>A prosthetic phantom consisting of an artificial bone and implant (<xref ref-type="table" rid="pone.0222406.t001">Table 1</xref>) was immersed in the center of a water-filled polymethyl methacrylate case (case dimensions, &#966; 200 &#215; 300 mm), for evaluating MAR. A simulated humeral proximal fracture (internal fracture fixation via retrograde intramedullary nail fixation) was present in the prosthetic phantom. In order for DE-DT acquisition, the phantom was positioned parallel to the detector plane (<xref ref-type="fig" rid="pone.0222406.g001">Fig 1</xref>).</p>
<fig id="pone.0222406.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The experimental geometric placement adopted to assess metal artifact reduction employing the new denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm and conventional algorithms.</title>
<p>A prosthetic phantom consisting of an artificial joint and implant positioned parallel to the detector plane was employed for the experiments.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g001" ns0:type="simple" />
</fig>
<table-wrap id="pone.0222406.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.t001</object-id>
<label>Table 1</label> <caption><title>Specifications of prosthetic phantom employed in this study.</title></caption>
<alternatives>
<graphic id="pone.0222406.t001g" mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.t001" ns0:type="simple" />
<table>
<colgroup>
<col align="left" valign="middle" />
<col align="left" valign="middle" />
<col align="left" valign="middle" />
</colgroup>
<thead>
<tr>
<th align="center" />
<th align="center">Element</th>
<th align="center">Ratio (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><bold>[Artificial bone</bold><xref ref-type="table-fn" rid="t001fn002"><sup><bold>a</bold></sup></xref> <bold>(Foam cortical shell) ]</bold></td>
<td align="center">Hydrogen (H)</td>
<td align="center">7.9192</td>
</tr>
<tr>
<td align="center"><bold>Local density (0.48 g/cm</bold><sup><bold>3</bold></sup><bold>)</bold></td>
<td align="center">Carbon (C)</td>
<td align="center">40.4437</td>
</tr>
<tr>
<td align="center" />
<td align="center">Nitrogen (N)</td>
<td align="center">15.7213</td>
</tr>
<tr>
<td align="center" />
<td align="center">Oxygen (O)</td>
<td align="center">35.9157</td>
</tr>
<tr>
<td align="center"><bold>[Implant</bold><xref ref-type="table-fn" rid="t001fn003"><sup><bold>b</bold></sup></xref> <bold>(Titanium alloy) ]</bold></td>
<td align="center">Titanium (Ti)</td>
<td align="center">90.255</td>
</tr>
<tr>
<td align="center"><bold>Local density (4.43 g/cm</bold><sup><bold>3</bold></sup><bold>)</bold></td>
<td align="center">Nitrogen (N)</td>
<td align="center">0.05</td>
</tr>
<tr>
<td align="center" />
<td align="center">Carbon (C)</td>
<td align="center">0.08</td>
</tr>
<tr>
<td align="center" />
<td align="center">Hydrogen (H)</td>
<td align="center">0.015</td>
</tr>
<tr>
<td align="center" />
<td align="center">Iron (Fe)</td>
<td align="center">0.40</td>
</tr>
<tr>
<td align="center" />
<td align="center">Oxygen (O)</td>
<td align="center">0.20</td>
</tr>
<tr>
<td align="center" />
<td align="center">Aluminum (Al)</td>
<td align="center">5.5</td>
</tr>
<tr>
<td align="center" />
<td align="center">Vanadium (V)</td>
<td align="center">3.5</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>Specifications and chemical composition of the prosthetic phantom employed in this study.</p></fn>
<fn id="t001fn002"><p><sup>a</sup>Orthopedic Humerus Normal Anatomy (Model 1013, Sawbones, Inc., WA, USA)</p></fn>
<fn id="t001fn003"><p><sup>b</sup>Proximal Retrograde Humeral Nail&#174; (PRHN, Mizuho Inc., Tokyo, Japan)</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec004">
<title>DE-DT system</title>
<p>The DE-DT system (SonialVision Safire II; Shimadzu Co., Kyoto, Japan) contained an X-ray tube (anode, made out of tungsten with rhenium and molybdenum; real filter: inherent; aluminum [1.1 mm], additional; aluminum [0.9 mm] and copper [0.1 mm]) with a 0.4-mm focal spot and an amorphous selenium (362.88 &#215; 362.88-mm) digital flat-panel detector (detector element, 0.15 &#215; 0.15-mm). The distances between source (focal point)-to-isocenter and source-to-detector were 924 and 1100 mm, respectively (anti-scatter grid, focused type; grid ratio, 12:1). We selected the kV values (low, 70 kV; high, 140 kV) because the focus of this study is MAR improvement [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>].</p>
<p>A 40&#176; swing angle and linear system movement were employed while conducting tomography, and 37 projection images (1024 &#215; 1024 matrix) at low- and high-voltage were obtained during a single tomographic pass. In DE-DT imaging, pulsed X-ray exposures were used with rapid switching between low and high energies. Even though, low voltage is generally used for clinical application (e.g., prosthesis assessment), all the projection images for low-voltage X-ray were acquired at 187 mA with a 22-ms exposure time and for high-voltage X-ray, at 260 mA with a 5-ms exposure time. To produce reconstructed tomograms of the required height, we employed a 1024 &#215; 1024 matrix with 32 bits (single-precision floating number) per image (pixel size, 0.279 mm/pixel; reconstruction interval, 1 mm; total slice number, 50; starting height of the reconstruction from the detector surface, 150mm). The plane locations were the in-focus plane and out-of-plane from the object location. The image reconstructed at the in-focus plane shows that the object is faithfully reconstructed on the focal plane (<xref ref-type="fig" rid="pone.0222406.g002">Fig 2</xref>).</p>
<fig id="pone.0222406.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g002</object-id>
<label>Fig 2</label>
<caption>
<title>The schematic diagram to illustrate the relationship of the in-focus plane and the out-of-plane in the Z-axis direction.</title>
<p>The in-focus plane is not affected by the blur, but the out-of-plane is contains blur.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g002" ns0:type="simple" />
</fig>
</sec>
<sec id="sec005">
<title>Generation of reference projection images</title>
<p>One of the approaches for MAR is the use of VM X-ray. A previous study on DT reported that a VM X-ray image is more useful for MAR when compared with a polychromatic X-ray image [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. Considering these results, we decided to use a VM X-ray image as a reference image for training workflow. The proposed algorithm was developed to realize the projection data level as well as the contents reported by Gomi et al. [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. In the MAR, it has been reported that DEMDRA applying material decomposition is the most effective for MAR [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. However, DEMDRA has to apply DnCNN to projection data separated into a plurality of material decompositions. Then, it may be difficult to maintain the residual accuracy with the polychromatic projection data to be compared. Conversely, VM X-ray imaging can learn residuals with high accuracy by using a single projection datum; thus an effective MAR can be expected. Therefore, the VM X-ray image was used as a reference image in this study. Thirty-seven reference images (VM X-ray projection image) corresponding to the corrected input image pairs were randomly selected as the training set from the original projection data set (total original projection data set: 74). In the present study, we made use of a simple projection space (pre-reconstruction) decomposition method to assess the material fractions (<italic>F</italic><sub><italic>n</italic></sub>) of the artificial bone (foam cortical shell, <italic>F</italic><sub><italic>f</italic></sub>), soft tissue (water, <italic>F</italic><sub><italic>w</italic></sub>), and implant (titanium alloy, <italic>F</italic><sub><italic>t</italic></sub>) in the phantom.</p>
<p>The three basis materials can also be denoted as a linear combination of their attenuation coefficients as follows:
<disp-formula id="pone.0222406.e001">
<alternatives>
<graphic id="pone.0222406.e001g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e001" ns0:type="simple" />
<ns1:math display="block" id="M1">
<ns1:mrow><ns1:mi>&#956;</ns1:mi><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>r</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>=</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>&#961;</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>r</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>+</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>&#961;</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>r</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>+</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>&#961;</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>r</ns1:mi><ns1:mo stretchy="false">)</ns1:mo></ns1:mrow>
</ns1:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where the basis materials exhibit different photoelectric and Compton characteristics; (<italic>&#956;</italic>/<italic>&#961;</italic>)<sub><italic>i</italic></sub>(<italic>E</italic>), <italic>i</italic> = <italic>t</italic> (titanium alloy), <italic>w</italic> (water), and <italic>f</italic> (foam cortical shell), is the mass attenuation coefficient of the three basis materials; and <italic>&#961;</italic><sub><italic>i</italic></sub>(<italic>r</italic>), <italic>i</italic> = <italic>t</italic> (titanium alloy), <italic>w</italic>(water), and <italic>f</italic>(foam cortical shell), is the local density (<italic>g</italic>/<italic>cm</italic><sup>3</sup>) of the three basis materials at location <italic>r</italic>.</p>
<p>In DE acquisition, the detected image intensity can be depicted as:
<disp-formula id="pone.0222406.e002">
<alternatives>
<graphic id="pone.0222406.e002g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e002" ns0:type="simple" />
<ns1:math display="block" id="M2">
<ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mi>L</ns1:mi></ns1:msub><ns1:mo>=</ns1:mo><ns1:mstyle displaystyle="false"><ns1:mrow><ns1:mo>&#8747;</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>I</ns1:mi><ns1:mi>L</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mi mathvariant="normal">exp</ns1:mi><ns1:mrow><ns1:mo>{</ns1:mo><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub></ns1:mrow><ns1:mo>}</ns1:mo></ns1:mrow><ns1:mi>d</ns1:mi><ns1:mi>E</ns1:mi></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow>
</ns1:math>
</alternatives>
<label>(2)</label>
</disp-formula>
<disp-formula id="pone.0222406.e003">
<alternatives>
<graphic id="pone.0222406.e003g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e003" ns0:type="simple" />
<ns1:math display="block" id="M3">
<ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mi>H</ns1:mi></ns1:msub><ns1:mo>=</ns1:mo><ns1:mstyle displaystyle="false"><ns1:mrow><ns1:mo>&#8747;</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>I</ns1:mi><ns1:mi>H</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mi mathvariant="normal">exp</ns1:mi><ns1:mrow><ns1:mo>{</ns1:mo><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8901;</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub></ns1:mrow><ns1:mo>}</ns1:mo></ns1:mrow><ns1:mi>d</ns1:mi><ns1:mi>E</ns1:mi></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow>
</ns1:math>
</alternatives>
<label>(3)</label>
</disp-formula>
<disp-formula id="pone.0222406.e004">
<alternatives>
<graphic id="pone.0222406.e004g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e004" ns0:type="simple" />
<ns1:math display="block" id="M4">
<ns1:mrow><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mi>K</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo>=</ns1:mo><ns1:mn>1.0</ns1:mn></ns1:mrow>
</ns1:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>I</italic><sub><italic>L</italic></sub>(<italic>E</italic>) and <italic>I</italic><sub><italic>H</italic></sub>(<italic>E</italic>) are the primary intensities at low- and high energy, respectively, whereas, <italic>P</italic><sub><italic>L</italic></sub> and <italic>P</italic><sub><italic>H</italic></sub> are the attenuated intensities at low- and high energy, respectively. Each X-ray spectrum is shown in <xref ref-type="fig" rid="pone.0222406.g003">Fig 3</xref>. (Measurement tool: RAMTEC413 Toyo Medic Co., Tokyo, Japan; Detector: CdTe; Channel: 1024 (0.2keV/channel); Measuring method: Compton-scattering measurement [<xref ref-type="bibr" rid="pone.0222406.ref030">30</xref>])</p>
<fig id="pone.0222406.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Spectra of the Sonial Vision Safire II tube at 70 and 140 kV potentials.</title>
<p>The peaks represent the characteristic lines of the tungsten with rhenium and molybdenum anode and the continuous spectrum is a result of Bremsstrahlung. The mean photon energies are 49 and 80 keV, respectively. (Real filter: inherent; aluminum [1.1 mm], additional; aluminum [0.9 mm] and copper [0.1 mm]).</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g003" ns0:type="simple" />
</fig>
<p>The equivalent densities (<italic>g</italic>/<italic>cm</italic><sup>3</sup>) <italic>K</italic><sub><italic>t</italic></sub>, <italic>K</italic><sub><italic>w</italic></sub>, and <italic>K</italic><sub><italic>f</italic></sub> of the three basis materials should be calculated for each ray path. Eqs (<xref ref-type="disp-formula" rid="pone.0222406.e002">2</xref>), (<xref ref-type="disp-formula" rid="pone.0222406.e003">3</xref>) and (<xref ref-type="disp-formula" rid="pone.0222406.e004">4</xref>) can be solved for the equivalent area densities, where <italic>K</italic><sub><italic>t</italic></sub>, <italic>K</italic><sub><italic>w</italic></sub>, and <italic>K</italic><sub><italic>f</italic></sub> represent the unknown materials. Basis material decomposition can thus be ascertained by solving simultaneous equations to determine the values of <italic>K</italic><sub><italic>t</italic></sub>, <italic>K</italic><sub><italic>w</italic></sub>, and <italic>K</italic><sub><italic>f</italic></sub> from the quantified projection pixel values [<xref ref-type="bibr" rid="pone.0222406.ref031">31</xref>]. By employing the density that corresponds to each of the areas with the 3 basis materials, the linear attenuation coefficient <italic>&#956;</italic>(<italic>r</italic>,<italic>E</italic>) can be determined for any photon. The theoretical mass attenuation coefficient and linear attenuation coefficient curve shown in <xref ref-type="fig" rid="pone.0222406.g004">Fig 4</xref> were calculated using the local density and area density of each material. These are generated by inputting the chemical compositions of the titanium alloy, foam cortical shell, and water shown in <xref ref-type="table" rid="pone.0222406.t001">Table 1</xref> into the XCOM program developed by Berger and Hubbell [<xref ref-type="bibr" rid="pone.0222406.ref032">32</xref>]. Finally, for the projection space decomposition approach, the following process was used to generate material decomposition images for titanium alloy, foam cortical shell, and water.</p>
<fig id="pone.0222406.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g004</object-id>
<label>Fig 4</label>
<caption>
<title>The linear attenuation and mass attenuation coefficients of a foam cortical shell, titanium alloy, and water with respect to the photons.</title>
<p>Based on the linear attenuation coefficient map, each energy image of virtual monochromatic X-ray processing was created.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g004" ns0:type="simple" />
</fig>
<p>Eqs (<xref ref-type="disp-formula" rid="pone.0222406.e002">2</xref>) and (<xref ref-type="disp-formula" rid="pone.0222406.e003">3</xref>) were used to calculate values for <italic>P</italic><sub><italic>L</italic>_<italic>t</italic></sub>, <italic>P</italic><sub><italic>L</italic>_<italic>w</italic></sub>, <italic>P</italic><sub><italic>L</italic>_<italic>f</italic></sub>, <italic>P</italic><sub><italic>H</italic>_<italic>t</italic></sub>, <italic>P</italic><sub><italic>H</italic>_<italic>w</italic></sub>, and <italic>P</italic><sub><italic>H</italic>_<italic>f</italic></sub> as simulated attenuation intensities of these materials at the two energy levels. These values were then used to construct a sensitivity matrix, and the material fractions (material decomposition images; <italic>F</italic><sub><italic>t</italic></sub>, <italic>F</italic><sub><italic>w</italic></sub>, <italic>F</italic><sub><italic>f</italic></sub>) were obtained from the inverse of this matrix, as shown in Eq (<xref ref-type="disp-formula" rid="pone.0222406.e005">5</xref>):
<disp-formula id="pone.0222406.e005">
<alternatives>
<graphic id="pone.0222406.e005g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e005" ns0:type="simple" />
<ns1:math display="block" id="M5">
<ns1:mrow><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:mtable><ns1:mtr><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow><ns1:mo>=</ns1:mo><ns1:msup><ns1:mrow><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:mtable><ns1:mtr><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>t</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>f</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>t</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>f</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:mn>1.0</ns1:mn></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:mn>1.0</ns1:mn></ns1:mrow></ns1:mtd><ns1:mtd><ns1:mrow><ns1:mn>1.0</ns1:mn></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow></ns1:msup><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:mtable><ns1:mtr><ns1:mtd><ns1:mrow><ns1:mi>X</ns1:mi><ns1:mi>D</ns1:mi><ns1:mi>T</ns1:mi><ns1:msub><ns1:mi>S</ns1:mi><ns1:mrow><ns1:mi>E</ns1:mi><ns1:mi>L</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:mi>X</ns1:mi><ns1:mi>D</ns1:mi><ns1:mi>T</ns1:mi><ns1:msub><ns1:mi>S</ns1:mi><ns1:mrow><ns1:mi>E</ns1:mi><ns1:mi>H</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow></ns1:mtd></ns1:mtr><ns1:mtr><ns1:mtd><ns1:mrow><ns1:mn>1.0</ns1:mn></ns1:mrow></ns1:mtd></ns1:mtr></ns1:mtable></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow>
</ns1:math>
</alternatives>
<label>(5)</label>
</disp-formula>
<disp-formula id="pone.0222406.e006">
<alternatives>
<graphic id="pone.0222406.e006g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e006" ns0:type="simple" />
<ns1:math display="block" id="M6">
<ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>t</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>L</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>f</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:mi>X</ns1:mi><ns1:mi>D</ns1:mi><ns1:mi>T</ns1:mi><ns1:msub><ns1:mi>S</ns1:mi><ns1:mrow><ns1:mi>E</ns1:mi><ns1:mi>L</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow>
</ns1:math>
</alternatives>
</disp-formula>
<disp-formula id="pone.0222406.e007">
<alternatives>
<graphic id="pone.0222406.e007g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e007" ns0:type="simple" />
<ns1:math display="block" id="M7">
<ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>t</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mi>H</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>f</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:mi>X</ns1:mi><ns1:mi>D</ns1:mi><ns1:mi>T</ns1:mi><ns1:msub><ns1:mi>S</ns1:mi><ns1:mrow><ns1:mi>E</ns1:mi><ns1:mi>H</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow>
</ns1:math>
</alternatives>
</disp-formula>
<disp-formula id="pone.0222406.e008">
<alternatives>
<graphic id="pone.0222406.e008g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e008" ns0:type="simple" />
<ns1:math display="block" id="M8">
<ns1:mrow><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo>=</ns1:mo><ns1:mn>1.0</ns1:mn></ns1:mrow>
</ns1:math>
</alternatives>
</disp-formula>
where, two DT projection image sets, each acquired with a different energy (<italic>XDTS</italic><sub><italic>EL</italic></sub> and <italic>XDTS</italic><sub><italic>EH</italic></sub> i.e., 70 and 140 kV).</p>
<p>Inverse of this matrix was used to obtain material fractions. Following decomposition by matrix inversion, the &#8220;<italic>inv</italic>&#8221; function available in MATLAB (Mathworks; Natick, MA, USA) was employed; this function limits the possible fraction to [0,1] while imposing a sum of 1. Thus, three material fractions arise from the processing pipeline, related to water, foam cortical shell and the titanium alloy [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. VM processing are obtained using the Eq (<xref ref-type="disp-formula" rid="pone.0222406.e004">4</xref>):
<disp-formula id="pone.0222406.e009">
<alternatives>
<graphic id="pone.0222406.e009g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e009" ns0:type="simple" />
<ns1:math display="block" id="M9">
<ns1:mrow><ns1:mi>V</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>p</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>t</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>w</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>+</ns1:mo><ns1:msub><ns1:mi>F</ns1:mi><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mfrac><ns1:mi>&#956;</ns1:mi><ns1:mi>&#961;</ns1:mi></ns1:mfrac></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mi>f</ns1:mi></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>E</ns1:mi><ns1:mo stretchy="false">)</ns1:mo></ns1:mrow>
</ns1:math>
</alternatives>
<label>(6)</label>
</disp-formula>
where <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub> is the VM projection image, and (<italic>&#956;</italic>/<italic>&#961;</italic>)<sub><italic>t</italic></sub>(<italic>E</italic>), (<italic>&#956;</italic>/<italic>&#961;</italic>)<sub><italic>w</italic></sub>(<italic>E</italic>), and (<italic>&#956;</italic>/<italic>&#961;</italic>)<sub><italic>f</italic></sub>(<italic>E</italic>) are each material&#8217;s corresponding mass attenuation coefficients. The energy of the VM X-ray was selected as 140 keV, which is effective for reducing metal artifacts [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>].</p>
</sec>
<sec id="sec006">
<title>DnCNN-MARHR</title>
<p>Zhang et al. further investigated the construction of a feed-forward DnCNN to include the progresses in learning algorithms, very deep architecture, and methods of regularization for image denoising [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>]. Particularly, residual learning and batch normalization were used to fasten the process of training and also to enhance the denoising performance [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>]. This network is primarily designed to remove noise from the image (residual learning method). However, it is possible to train the DnCNN architecture to remove artifacts and increase the image resolution. Therefore, by applying this algorithm as an image quality improvement method (for MAR), it is expected that MAR can be effectively achieved. The training workflow of the DnCNN can be realized by using the mini-batch stochastic gradient descent algorithm with momentum (SGDM) method [<xref ref-type="bibr" rid="pone.0222406.ref033">33</xref>]. The SGDM has extensively been employed for the training of CNN models. Even though, the mini-batch SGDM is simple and effective to use, its efficiency of training is mostly compromised by the shift of internal covariates, i.e., alterations in the distributions of internal non-linearity inputs while training [<xref ref-type="bibr" rid="pone.0222406.ref034">34</xref>]. The main algorithm we propose involves processing and correction at the projection data level using the DnCNN. The input image to be corrected was selected to be a low-energy projection image (<italic>P</italic><sub><italic>L</italic></sub>; tube voltage, 70 kV) in consideration of the influences of tube voltage in clinical use and metal artifacts in polychromatic X-ray imaging [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. In the presence of high-energy, the difference in the linear attenuation coefficient between the normal tissues becomes narrow, and the contrast tends to decrease. Accordingly, low energy was selected in terms of retention of contrast in normal tissue as well as MAR. The average mean squared error between the required residual projection images and the estimated images from included artifact projection (with noise) image input can be implemented as the loss function <italic>q</italic> to learn the trainable parameters <italic>&#948;</italic> (SGDM with the weight decay of 0.0001, momentum of 0.9, initial learning rate of 0.1, and hyper-parameters mini-batch size and epochs) in the DnCNN [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>]. With regard to <italic>&#948;</italic>, mini-batch size and epochs are hyper-parameters that affect MAR [<xref ref-type="bibr" rid="pone.0222406.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0222406.ref024">24</xref>]. We evaluated the optimal parameter, and we have applied the parameters in the &#8220;Evaluation&#8221; section below.
<disp-formula id="pone.0222406.e010">
<alternatives>
<graphic id="pone.0222406.e010g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e010" ns0:type="simple" />
<ns1:math display="block" id="M10">
<ns1:mrow><ns1:mi>q</ns1:mi><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>&#948;</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>&#966;</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>=</ns1:mo><ns1:mfrac><ns1:mn>1</ns1:mn><ns1:mrow><ns1:mn>2</ns1:mn><ns1:mi>N</ns1:mi></ns1:mrow></ns1:mfrac><ns1:msubsup><ns1:mrow><ns1:mstyle displaystyle="true"><ns1:munderover><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>j</ns1:mi><ns1:mo>=</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow><ns1:mi>N</ns1:mi></ns1:munderover><ns1:mrow><ns1:mrow><ns1:mo>&#8214;</ns1:mo><ns1:mrow><ns1:mi>U</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:msub><ns1:mi>L</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow></ns1:msub><ns1:mo>;</ns1:mo><ns1:mi>&#948;</ns1:mi></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:msub><ns1:mi>L</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:mi>V</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>p</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:msub><ns1:mi>g</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mo>&#8214;</ns1:mo></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow><ns1:mi>G</ns1:mi><ns1:mn>2</ns1:mn></ns1:msubsup></ns1:mrow>
</ns1:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where learned a residual mapping <italic>U</italic>(<italic>P</italic><sub><italic>L</italic></sub>), <inline-formula id="pone.0222406.e011"><alternatives><graphic id="pone.0222406.e011g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e011" ns0:type="simple" /><ns1:math display="inline" id="M11"><ns1:mrow><ns1:msubsup><ns1:mrow><ns1:mrow><ns1:mo>{</ns1:mo><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:msub><ns1:mi>L</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow></ns1:msub><ns1:mo>,</ns1:mo><ns1:mi>V</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>p</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:msub><ns1:mi>g</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mo>}</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:mi>j</ns1:mi><ns1:mo>=</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow><ns1:mi>N</ns1:mi></ns1:msubsup></ns1:mrow></ns1:math></alternatives></inline-formula> represents <italic>N</italic> artifact-free training projection image (patch: <italic>N</italic> = 32) pairs and output trained network <italic>&#966;</italic>.</p>
<p>With regard to deep architecture [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>], considering a DnCNN with depth <italic>D</italic>, there are three types of layers as follows: (1) convolution + rectifier linear unit (ReLU) [<xref ref-type="bibr" rid="pone.0222406.ref035">35</xref>] (the first layer), 64 filters of size 3 &#215; 3 &#215; 1 are used to generate 64 feature maps and ReLU (max[0, &#8901;]) is then utilized for non-linearity; (2) convolution + batch normalization + ReLU (layers 2~[<italic>D</italic>&#8722;1]), 64 filters of size 3 &#215; 3 &#215; 64 are employed and between convolution and ReLU, batch normalization [<xref ref-type="bibr" rid="pone.0222406.ref034">34</xref>] is added; (3) convolution (the last layer), filters of size 3 &#215; 3 &#215; 64 are used to rebuild the output. In this study, network depth was set to 20, scanning step size (horizontal and vertical directions) was set to &#8220;1,&#8221; and the zero padding size was set to &#8220;1&#8221; in each of the positions (upper, lower, left, and right positions) in the DnCNN [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>].</p>
<p>The loss function <italic>q</italic> in Eq (<xref ref-type="disp-formula" rid="pone.0222406.e010">7</xref>) is deployed to learn the residual mapping <italic>U</italic>(<italic>P</italic><sub><italic>L</italic></sub>) for residual prediction. The trained network <italic>&#966;</italic> is activated to estimate the residual projection image.
<disp-formula id="pone.0222406.e012">
<alternatives>
<graphic id="pone.0222406.e012g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e012" ns0:type="simple" />
<ns1:math display="block" id="M12">
<ns1:mrow><ns1:mi>I</ns1:mi><ns1:mi>m</ns1:mi><ns1:msub><ns1:mi>g</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi mathvariant="normal">Re</ns1:mi><ns1:mi>s</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:mi>&#946;</ns1:mi><ns1:mspace width="0.25em" /><ns1:mi>&#949;</ns1:mi><ns1:mstyle displaystyle="true"><ns1:munderover><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>Z</ns1:mi><ns1:mo>=</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow><ns1:mi>Z</ns1:mi></ns1:munderover><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mover accent="true"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi><ns1:mi>Z</ns1:mi></ns1:msub></ns1:mrow><ns1:mo stretchy="true">&#175;</ns1:mo></ns1:mover><ns1:mo>*</ns1:mo><ns1:msub><ns1:mi>&#966;</ns1:mi><ns1:mi>Z</ns1:mi></ns1:msub><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi><ns1:mi>Z</ns1:mi></ns1:msub><ns1:mo>*</ns1:mo><ns1:msub><ns1:mi>P</ns1:mi><ns1:mi>L</ns1:mi></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow>
</ns1:math>
</alternatives>
<label>(8)</label>
</disp-formula>
where <italic>Img</italic><sub>&#8722;Re<italic>s</italic></sub> is the estimated residual of <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub> with respect to <italic>P</italic><sub><italic>L</italic></sub>, <italic>&#946;</italic> is the scanning step size, <italic>&#949;</italic> is the regularization parameter, <italic>f</italic><sub><italic>z</italic></sub> is the <italic>z</italic>th convolution filter kernel, and <inline-formula id="pone.0222406.e013"><alternatives><graphic id="pone.0222406.e013g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e013" ns0:type="simple" /><ns1:math display="inline" id="M13"><ns1:mrow><ns1:mover accent="true"><ns1:mrow><ns1:msub><ns1:mi>f</ns1:mi><ns1:mi>z</ns1:mi></ns1:msub></ns1:mrow><ns1:mo stretchy="true">&#175;</ns1:mo></ns1:mover></ns1:mrow></ns1:math></alternatives></inline-formula> is the adjoint filter of <italic>f</italic><sub><italic>z</italic></sub>. The influence function <italic>&#966;</italic><sub><italic>z</italic></sub>(&#8901;)can be regarded as pointwise nonlinearity applied to the convolution feature map Eq (<xref ref-type="disp-formula" rid="pone.0222406.e012">8</xref>). Eq (<xref ref-type="disp-formula" rid="pone.0222406.e012">8</xref>) is a two-layer feed-forward CNN. The CNN architecture further generalizes one-stage trainable nonlinear reaction diffusion (TNRD) [<xref ref-type="bibr" rid="pone.0222406.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0222406.ref037">37</xref>] from three aspects:</p>
<p>(1) Replacing the influence function with ReLU to ease CNN training;</p>
<p>(2) Increasing the CNN depth to improve the capacity in modeling image characteristics; (3) incorporating batch normalization to boost the performance.</p>
<p>The connection with one-stage TNRD provides insights into the use of residual learning for CNN-based image restoration [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>].</p>
<p>The estimated residual projection image is subtracted from the original projection image to obtain an artifact-reduced projection image.</p>
<disp-formula id="pone.0222406.e014">
<alternatives>
<graphic id="pone.0222406.e014g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e014" ns0:type="simple" />
<ns1:math display="block" id="M14">
<ns1:mrow><ns1:mi>c</ns1:mi><ns1:mi>o</ns1:mi><ns1:msub><ns1:mi>r</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:msub><ns1:mi>P</ns1:mi><ns1:mi>L</ns1:mi></ns1:msub><ns1:mo>&#8722;</ns1:mo><ns1:mi>I</ns1:mi><ns1:mi>m</ns1:mi><ns1:msub><ns1:mi>g</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi mathvariant="normal">Re</ns1:mi><ns1:mi>s</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow>
</ns1:math>
</alternatives>
<label>(9)</label>
</disp-formula>
<p>Different reconstruction algorithms have been examined for achieving the metal artifact reduction in arthroplasty images. Among these, a superior performance was obtained using the MLEM method [<xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>]. A two step- MLEM algorithm, that comprises of a forward step (for modeling the DT acquisition process) and a backward step (for updating the reconstructed object) per iteration has also been proposed [<xref ref-type="bibr" rid="pone.0222406.ref014">14</xref>]. The MLEM algorithm is employed iteratively, so that there is resemblance between the reconstructed volume projections, deduced from an image formation model, and the experimental projections. Thus, we used the MLEM algorithm for reconstructing the projection images with much lower artifacts. Besides, as the noise tends to be more in artifact-curtailed projection data, we suggested the MAR (adaptive filtering) processing to be employed [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>] during this reconstruction process. We anticipate a further decrease in both noise and metal artifacts by MAR processing (<xref ref-type="fig" rid="pone.0222406.g005">Fig 5</xref>).</p>
<fig id="pone.0222406.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Flowchart of the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm.</title>
<p>The DnCNN-MARHR algorithm was employed to decrease metal artifacts in weighted hybrid reconstructed images (maximum likelihood expectation maximization [MLEM] and back projection). This was achieved using a training network (mini-batch stochastic gradient descent algorithm with momentum) to estimate residual reference images and object images with projection data and subtract the estimated residual images from the object images. Abbreviations: DnCNN = denoising convolutional neural network, SGDM = mini-batch stochastic gradient descent algorithm with momentum, BP = back projection.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g005" ns0:type="simple" />
</fig>
<p>The following algorithm for reconstruction and adaptive filtering processing [<xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>] for the real space (post-reconstruction processing) was employed:
<disp-formula id="pone.0222406.e015">
<alternatives>
<graphic id="pone.0222406.e015g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e015" ns0:type="simple" />
<ns1:math display="block" id="M15">
<ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>L</ns1:mi><ns1:mi>E</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:msub><ns1:mi>N</ns1:mi><ns1:mrow><ns1:mi>u</ns1:mi><ns1:mo>+</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow></ns1:msub></ns1:mrow></ns1:msub><ns1:mo>&#8592;</ns1:mo><ns1:mi>M</ns1:mi><ns1:mi>L</ns1:mi><ns1:mi>E</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:msub><ns1:mi>N</ns1:mi><ns1:mi>u</ns1:mi></ns1:msub></ns1:mrow></ns1:msub><ns1:mfrac><ns1:mrow><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:msup><ns1:mi>X</ns1:mi><ns1:mi>T</ns1:mi></ns1:msup><ns1:mfrac><ns1:mrow><ns1:mi>c</ns1:mi><ns1:mi>o</ns1:mi><ns1:msub><ns1:mi>r</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub></ns1:mrow><ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>L</ns1:mi><ns1:mi>E</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:msub><ns1:mi>N</ns1:mi><ns1:mi>u</ns1:mi></ns1:msub></ns1:mrow></ns1:msub></ns1:mrow></ns1:mfrac></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:msup><ns1:mi>X</ns1:mi><ns1:mi>T</ns1:mi></ns1:msup><ns1:mn>1</ns1:mn></ns1:mrow></ns1:mfrac></ns1:mrow>
</ns1:math>
</alternatives>
<label>(10)</label>
</disp-formula>
<disp-formula id="pone.0222406.e016">
<alternatives>
<graphic id="pone.0222406.e016g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e016" ns0:type="simple" />
<ns1:math display="block" id="M16">
<ns1:mrow><ns1:mi>B</ns1:mi><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:mi>N</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>&#8592;</ns1:mo><ns1:msup><ns1:mi>X</ns1:mi><ns1:mi>T</ns1:mi></ns1:msup><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>c</ns1:mi><ns1:mi>o</ns1:mi><ns1:msub><ns1:mi>r</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>i</ns1:mi><ns1:mi>m</ns1:mi><ns1:mi>g</ns1:mi></ns1:mrow></ns1:msub><ns1:mo stretchy="false">)</ns1:mo></ns1:mrow>
</ns1:math>
</alternatives>
<label>(11)</label>
</disp-formula>
<disp-formula id="pone.0222406.e017">
<alternatives>
<graphic id="pone.0222406.e017g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e017" ns0:type="simple" />
<ns1:math display="block" id="M17">
<ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>A</ns1:mi><ns1:msub><ns1:mi>R</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:mi>N</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>L</ns1:mi><ns1:mi>E</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:mi>N</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>*</ns1:mo><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mn>1</ns1:mn><ns1:mo>&#8722;</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow><ns1:mo>+</ns1:mo><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:mi>B</ns1:mi><ns1:msub><ns1:mi>P</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:mi>N</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>*</ns1:mo><ns1:mi>w</ns1:mi></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow>
</ns1:math>
</alternatives>
<label>(12)</label>
</disp-formula>
The respective parameter definitions used in Eqs (<xref ref-type="disp-formula" rid="pone.0222406.e015">10</xref>), (<xref ref-type="disp-formula" rid="pone.0222406.e016">11</xref>) and (<xref ref-type="disp-formula" rid="pone.0222406.e017">12</xref>) are shown below.</p>
<p>Initialize: <inline-formula id="pone.0222406.e018"><alternatives><graphic id="pone.0222406.e018g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e018" ns0:type="simple" /><ns1:math display="inline" id="M18"><ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>L</ns1:mi><ns1:mi>E</ns1:mi><ns1:msub><ns1:mi>M</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>C</ns1:mi><ns1:mi>N</ns1:mi><ns1:msub><ns1:mi>N</ns1:mi><ns1:mn>0</ns1:mn></ns1:msub></ns1:mrow></ns1:msub></ns1:mrow></ns1:math></alternatives></inline-formula>; all voxels can be initialized to 1.0.</p>
<p><italic>X</italic><sup><italic>T</italic></sup> is back projection, <italic>X</italic> is multiplication by the system matrix, <italic>T</italic> (superscript) is the matrix response, <italic>u</italic> is the number of iterations, <italic>MLEM</italic><sub>&#8722;<italic>DnCNN</italic></sub> is the MLEM [iteration (convergence): 30] image from artifact-reduced projection, <italic>BP</italic><sub>&#8722;<italic>DnCNN</italic></sub> is the back-projection image from artifact-reduced projection, <italic>MLEM</italic><sub>&#8722;<italic>DnCNN</italic></sub> is the DnCNN-MARHR image, and <italic>w</italic> is the weighting coefficient.</p>
</sec>
</sec>
<sec id="sec007">
<title>Evaluation</title>
<sec id="sec008">
<title>Optimization parameters for mini-batch size, epochs, and weighting coefficient (<italic>w</italic>)</title>
<p>According to Gomi et al. [<xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>, <xref ref-type="bibr" rid="pone.0222406.ref015">15</xref>], a weighting coefficient of 0.7 is optimal for effectively processing MAR. Considering these results, the initial weighting coefficient (assumption) was set to 0.7. In the study by Zhang et al. [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>], evaluations were performed by setting epochs to 50. In addition, it has been reported that effective MAR can be realized by increasing epochs in terms of MAR [<xref ref-type="bibr" rid="pone.0222406.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0222406.ref024">24</xref>]. It is considered necessary to increase epochs to realize effective MAR according to these reported results. In this study, the initial epochs (assumption) value was set to 60 considering reports of a value of 50 or more for MAR [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>, <xref ref-type="bibr" rid="pone.0222406.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0222406.ref024">24</xref>]. The initial value (assumption) was set as follows: epochs, 60 and weighting coefficient (<italic>w</italic>), 0.7, and the mini-batch size optimization and validity of the assumed initial value (epochs and weighting coefficient) setting were evaluated. We set the patch size as 32 &#215; 32, and crop [mini-batch size] &#215; [maximum number of iterations: epoch &#215; number of projection (37)] patches to train the model.</p>
<p>Reconstruction was accomplished using DT system-derived real projection data. MATLAB (Mathworks) was employed for image reconstruction and processing. Artifact index (AI) was deduced for evaluating the effect of MAR on each image in the in-focus plane [<xref ref-type="bibr" rid="pone.0222406.ref038">38</xref>]. Optimization was evaluated using the AI, and the lowest AI value and standard error were selected as the optimum parameters.</p>
</sec>
<sec id="sec009">
<title>Evaluation of MAR</title>
<p>We calculated the AI to assess the effect of MAR on each in-focus plane image. To compare the difference between DnCNN-MARHR and the conventional algorithm, the difference was evaluated using differential images and mean square error (MSE) in the in-focus plane. We further ascertained the artifact spread function (ASF) to determine the influence of metal artifacts on the features of rebuilt image in the neighboring out-of-plane zone [<xref ref-type="bibr" rid="pone.0222406.ref014">14</xref>]. Texture analysis [<xref ref-type="bibr" rid="pone.0222406.ref039">39</xref>] was used to evaluate the homogeneity of the entire image including metal artifacts. Comparison with the DnCNN-MARHR algorithm was performed by selecting an effective algorithm for MAR (DEMDRA, VM [140 keV], polychromatic MLEM-MAR [70 kV], polychromatic FBP (kernel: Shepp &amp; Logan)-MAR [70 kV], and polychromatic simultaneous algebraic reconstruction technique-TV [SART-TV] [<xref ref-type="bibr" rid="pone.0222406.ref013">13</xref>] MAR [140 kV]) reported by Gomi et al. [<xref ref-type="bibr" rid="pone.0222406.ref016">16</xref>]. The previously reported iteration numbers (DEMDRA, VM, MLEM; 30, SART-TV; 10) were applied to these conventional algorithms for MAR [<xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>]. An iteration number for TV minimization of 100 and length per gradient-descent step of 50 were considered optimal parameters for SART-TV [<xref ref-type="bibr" rid="pone.0222406.ref009">9</xref>]. DnCNN was evaluated using the application image of optimization parameters.</p>
</sec>
<sec id="sec010">
<title>Artifact index (AI)</title>
<p>Quantification of the degree of metal artifacts, was done using the AI, which permits low-frequency artifact determination. The AI of identified metal artifacts was as follows:
<disp-formula id="pone.0222406.e019">
<alternatives>
<graphic id="pone.0222406.e019g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e019" ns0:type="simple" />
<ns1:math display="block" id="M19">
<ns1:mrow><ns1:mi>A</ns1:mi><ns1:msub><ns1:mi>I</ns1:mi><ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>n</ns1:mi></ns1:mrow></ns1:msub><ns1:mo>=</ns1:mo><ns1:mi>s</ns1:mi><ns1:mi>q</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>t</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mrow><ns1:mo>|</ns1:mo><ns1:mrow><ns1:mi>A</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>t</ns1:mi><ns1:mi>i</ns1:mi><ns1:mi>f</ns1:mi><ns1:mi>a</ns1:mi><ns1:mi>c</ns1:mi><ns1:msub><ns1:mi>t</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:msub><ns1:mi>I</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>n</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>B</ns1:mi><ns1:msub><ns1:mi>G</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:mi>I</ns1:mi></ns1:mrow><ns1:mo>|</ns1:mo></ns1:mrow></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow>
</ns1:math>
</alternatives>
<label>(13)</label>
</disp-formula>
where <italic>n</italic> = 1, 2,&#8230;, 10 defines the formula for <italic>Artifact</italic>_<italic>ROI</italic>_<italic>n</italic> and <italic>Artifact</italic>_<italic>ROI</italic>_1, <italic>Artifact</italic>_<italic>ROI</italic>_2,&#8230;, <italic>Artifact</italic>_<italic>ROI</italic>_10 that represent the corresponding regions of interest (ROIs) for the relative standard deviations (SDs) of real features (metal artifacts) in the in-focus plane. <italic>BG</italic>_<italic>ROI</italic> is the relative SD of the background in the in-focus plane [<xref ref-type="fig" rid="pone.0222406.g006">Fig 6</xref> (a)]. For evaluation of the each features (metal artifacts) and background, the ROI was set at 4 &#215; 14 pixels.</p>
<fig id="pone.0222406.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g006</object-id>
<label>Fig 6</label>
<caption>
<title>ROI setting diagram for AI calculation and optimization verification results.</title>
<p>(a) Metal artifacts obtained employing the artifact index (AI) of the selected characteristics. The in-focus plane image displays the background areas and metal artifact of the AI measurements. The AIs resulting from differences in the mini-batch size (b), epochs (c), and weighting coefficient (<italic>w</italic>) in the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) images are shown (d). The settings of mini-batch size of 544, epochs of 60, and weighting coefficient (<italic>w</italic>) of 0.7 generated the maximum artifact decreasing effect. The error bar represents the standard error.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g006" ns0:type="simple" />
</fig>
</sec>
<sec id="sec011">
<title>Mean square error (MSE)</title>
<p>The MSE of identified in-focus plane image is given as below:
<disp-formula id="pone.0222406.e020">
<alternatives>
<graphic id="pone.0222406.e020g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e020" ns0:type="simple" />
<ns1:math display="block" id="M20">
<ns1:mrow><ns1:mi>M</ns1:mi><ns1:mi>S</ns1:mi><ns1:mi>E</ns1:mi><ns1:mo>=</ns1:mo><ns1:mfrac><ns1:mn>1</ns1:mn><ns1:mrow><ns1:mi>m</ns1:mi><ns1:mi>n</ns1:mi></ns1:mrow></ns1:mfrac><ns1:msup><ns1:mrow><ns1:mstyle displaystyle="true"><ns1:munderover><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>=</ns1:mo><ns1:mn>0</ns1:mn></ns1:mrow><ns1:mrow><ns1:mi>m</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow></ns1:munderover><ns1:mrow><ns1:mstyle displaystyle="true"><ns1:munderover><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>j</ns1:mi><ns1:mo>=</ns1:mo><ns1:mn>0</ns1:mn></ns1:mrow><ns1:mrow><ns1:mi>n</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mn>1</ns1:mn></ns1:mrow></ns1:munderover><ns1:mrow><ns1:mrow><ns1:mo>[</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>K</ns1:mi><ns1:mrow><ns1:mi>r</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>f</ns1:mi></ns1:mrow></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi><ns1:mo stretchy="false">)</ns1:mo><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mi>V</ns1:mi><ns1:mrow><ns1:mi>o</ns1:mi><ns1:mi>b</ns1:mi><ns1:mi>j</ns1:mi></ns1:mrow></ns1:msub><ns1:mo stretchy="false">(</ns1:mo><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi><ns1:mo stretchy="false">)</ns1:mo></ns1:mrow><ns1:mo>]</ns1:mo></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow></ns1:mstyle></ns1:mrow><ns1:mn>2</ns1:mn></ns1:msup></ns1:mrow>
</ns1:math>
</alternatives>
<label>(14)</label>
</disp-formula>
where, <italic>K</italic><sub><italic>ref</italic></sub>(<italic>i</italic>,<italic>j</italic>) is the (<italic>i</italic>,<italic>j</italic>)th entry of a DnCNN-MARHR image and <italic>V</italic><sub><italic>ref</italic></sub>(<italic>i</italic>,<italic>j</italic>) is the (<italic>i</italic>,<italic>j</italic>)th entry of an each conventional algorithm image.</p>
</sec>
<sec id="sec012">
<title>Artifact spread function (ASF)</title>
<p>Wu et al. proposed An ASF metric has been proposed by Wu et al., and this takes into account not only the objects in the focus plane that cause artifacts, but also the effects on these objects, arising from out-of-plane [<xref ref-type="bibr" rid="pone.0222406.ref014">14</xref>]. The resultant measure of ASF reveals the DT&#8217;s capability to distinguish superimposed features along the direction of tomographic slice. The ASF of artifacts in the image plane is given as below:
<disp-formula id="pone.0222406.e021">
<alternatives>
<graphic id="pone.0222406.e021g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e021" ns0:type="simple" />
<ns1:math display="block" id="M21">
<ns1:mrow><ns1:mi>A</ns1:mi><ns1:mi>S</ns1:mi><ns1:mi>F</ns1:mi><ns1:mo>=</ns1:mo><ns1:mfrac><ns1:mrow><ns1:mi>A</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>t</ns1:mi><ns1:mi>i</ns1:mi><ns1:mi>f</ns1:mi><ns1:mi>a</ns1:mi><ns1:mi>c</ns1:mi><ns1:msub><ns1:mi>t</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:mi>I</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mi>z</ns1:mi><ns1:mo>)</ns1:mo></ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>B</ns1:mi><ns1:msub><ns1:mi>G</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:mi>I</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mi>z</ns1:mi><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:mi>A</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>t</ns1:mi><ns1:mi>i</ns1:mi><ns1:mi>f</ns1:mi><ns1:mi>a</ns1:mi><ns1:mi>c</ns1:mi><ns1:msub><ns1:mi>t</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:mi>I</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>z</ns1:mi><ns1:mn>0</ns1:mn></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow><ns1:mo>&#8722;</ns1:mo><ns1:mi>B</ns1:mi><ns1:msub><ns1:mi>G</ns1:mi><ns1:mo>&#8722;</ns1:mo></ns1:msub><ns1:mi>R</ns1:mi><ns1:mi>O</ns1:mi><ns1:mi>I</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:msub><ns1:mi>z</ns1:mi><ns1:mn>0</ns1:mn></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac></ns1:mrow>
</ns1:math>
</alternatives>
<label>(15)</label>
</disp-formula>
where <italic>z</italic><sub>0</sub> and <italic>z</italic> represent the positions of the real features (i.e., metal artifacts) in the in-focus and out-of-plane images, respectively; the ROIs for the mean pixel intensities of the features and background in the in-focus-plane image are shown as <italic>Artifact</italic>_<italic>ROI</italic> (<italic>z</italic><sub>0</sub>) and <italic>BG</italic>_<italic>ROI</italic> (<italic>z</italic><sub>0</sub>), respectively; and in the out-of-plane image, the corresponding ROIs are <italic>Artifact</italic>_<italic>ROI</italic> (<italic>z</italic>) and <italic>BG</italic>_<italic>ROI</italic> (<italic>z</italic>). The size of ROI for assessing the background and features (i.e., metal artifacts) was 4 &#215; 14 pixels.</p>
</sec>
<sec id="sec013">
<title>Texture analysis</title>
<p>The gray-level co-occurrence matrix (GLCM) is a statistical texture inspection method that takes the spatial relationship of pixels into consideration. The GLCM function creates a GLCM by calculating how often a pair of pixels with a specified value and a specified spatial relationship occurs in an image. By extracting statistical information from this matrix, the features of the texture of the image can be obtained. Texture analysis can quantitatively analyze the variation of image intensity in an image [<xref ref-type="bibr" rid="pone.0222406.ref039">39</xref>]. Before computation of texture features, pixel intensities were discretized to 16 gray levels [<xref ref-type="bibr" rid="pone.0222406.ref039">39</xref>]. In addition, pixel values were rescaled between the mean&#8201;&#177;&#8201;SD. The statistical properties of the images derived from the GLCM in this study were evaluated using &#8220;inverse difference moment (homogeneity),&#8221; &#8220;contrast (dissimilarity),&#8221; and &#8220;correlation,&#8221; which are defined as follows:
<disp-formula id="pone.0222406.e022">
<alternatives>
<graphic id="pone.0222406.e022g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e022" ns0:type="simple" />
<ns1:math display="block" id="M22">
<ns1:mrow><ns1:mi>I</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>v</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>s</ns1:mi><ns1:mi>e</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>D</ns1:mi><ns1:mi>i</ns1:mi><ns1:mi>f</ns1:mi><ns1:mi>f</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>c</ns1:mi><ns1:mi>e</ns1:mi><ns1:mo>_</ns1:mo><ns1:mi>M</ns1:mi><ns1:mi>o</ns1:mi><ns1:mi>m</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>t</ns1:mi><ns1:mo>=</ns1:mo><ns1:mstyle displaystyle="true"><ns1:munder><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow></ns1:munder><ns1:mrow><ns1:mfrac><ns1:mrow><ns1:mi>p</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:mn>1</ns1:mn><ns1:mo>+</ns1:mo><ns1:mrow><ns1:mo>|</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow><ns1:mo>|</ns1:mo></ns1:mrow></ns1:mrow></ns1:mfrac></ns1:mrow></ns1:mstyle></ns1:mrow>
</ns1:math>
</alternatives>
<label>(16)</label>
</disp-formula>
<disp-formula id="pone.0222406.e023">
<alternatives>
<graphic id="pone.0222406.e023g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e023" ns0:type="simple" />
<ns1:math display="block" id="M23">
<ns1:mrow><ns1:mi>C</ns1:mi><ns1:mi>o</ns1:mi><ns1:mi>n</ns1:mi><ns1:mi>t</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>a</ns1:mi><ns1:mi>s</ns1:mi><ns1:mi>t</ns1:mi><ns1:mo>=</ns1:mo><ns1:msup><ns1:mrow><ns1:mstyle displaystyle="true"><ns1:munder><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow></ns1:munder><ns1:mrow><ns1:mrow><ns1:mo>|</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow><ns1:mo>|</ns1:mo></ns1:mrow></ns1:mrow></ns1:mstyle></ns1:mrow><ns1:mn>2</ns1:mn></ns1:msup><ns1:mi>p</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow>
</ns1:math>
</alternatives>
<label>(17)</label>
</disp-formula>
<disp-formula id="pone.0222406.e024">
<alternatives>
<graphic id="pone.0222406.e024g" mimetype="image" position="anchor" ns0:href="info:doi/10.1371/journal.pone.0222406.e024" ns0:type="simple" />
<ns1:math display="block" id="M24">
<ns1:mrow><ns1:mi>C</ns1:mi><ns1:mi>o</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>r</ns1:mi><ns1:mi>e</ns1:mi><ns1:mi>l</ns1:mi><ns1:mi>a</ns1:mi><ns1:mi>t</ns1:mi><ns1:mi>i</ns1:mi><ns1:mi>o</ns1:mi><ns1:mi>n</ns1:mi><ns1:mo>=</ns1:mo><ns1:mstyle displaystyle="true"><ns1:munder><ns1:mo>&#8721;</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow></ns1:munder><ns1:mrow><ns1:mfrac><ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mi>&#956;</ns1:mi><ns1:mi>i</ns1:mi></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mi>j</ns1:mi><ns1:mo>&#8722;</ns1:mo><ns1:msub><ns1:mi>&#956;</ns1:mi><ns1:mi>j</ns1:mi></ns1:msub></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow><ns1:mi>p</ns1:mi><ns1:mrow><ns1:mo>(</ns1:mo><ns1:mrow><ns1:mi>i</ns1:mi><ns1:mo>,</ns1:mo><ns1:mi>j</ns1:mi></ns1:mrow><ns1:mo>)</ns1:mo></ns1:mrow></ns1:mrow><ns1:mrow><ns1:msub><ns1:mi>&#963;</ns1:mi><ns1:mi>i</ns1:mi></ns1:msub><ns1:msubsup><ns1:mi>&#963;</ns1:mi><ns1:mi>j</ns1:mi><ns1:mrow /></ns1:msubsup></ns1:mrow></ns1:mfrac></ns1:mrow></ns1:mstyle></ns1:mrow>
</ns1:math>
</alternatives>
<label>(18)</label>
</disp-formula>
where <italic>p</italic>(<italic>i</italic>,<italic>j</italic>) is the (<italic>i</italic>,<italic>j</italic>)th entry of a normalized gray-level spatial dependence matrix, and <italic>&#956;</italic><sub><italic>i</italic></sub>,<italic>&#956;</italic><sub><italic>j</italic></sub> and <italic>&#963;</italic><sub><italic>i</italic></sub> and <italic>&#963;</italic><sub><italic>j</italic></sub> are the means and SDs of <italic>p</italic><sub><italic>i</italic></sub> and <italic>p</italic><sub><italic>j</italic></sub>, respectively.</p>
</sec>
</sec>
<sec id="sec014" sec-type="results">
<title>Results</title>
<p>The initial value (assumption) was set as follows: epochs, 60 and weighting coefficient (<italic>w</italic>), 0.7, and the mini-batch size was changed to 128, 256, 384, 464, 512, 544, 552, 576, and 640. The AI and standard error value of mini-batch size 544 were the lowest [<xref ref-type="fig" rid="pone.0222406.g006">Fig 6(B)</xref>]. Next, to verify optimization of the assumed initial value (epochs, 60 and weighting coefficient [<italic>w</italic>], 0.7) with a mini-batch size of 544, the AI and standard error were measured with epochs of 10, 20, 40, 60, 80, and 100, and weighting coefficients of 0.5 to 0.9 [<xref ref-type="fig" rid="pone.0222406.g006">Fig 6(C)</xref>]. For epochs of 60 and a weighting coefficient (<italic>w</italic>) of 0.7, the AI value and standard error were the lowest [<xref ref-type="fig" rid="pone.0222406.g006">Fig 6(D)</xref>]. Therefore, learning was performed by setting the mini-batch size as 544, epochs as 60 (hyper-parameter), and weighting coefficient (<italic>w</italic>) of blended image processing as 0.7 in the DnCNN-MARHR algorithm (<xref ref-type="fig" rid="pone.0222406.g007">Fig 7</xref>).</p>
<fig id="pone.0222406.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g007</object-id>
<label>Fig 7</label>
<caption>
<title>AI surface plot with epochs and weighting coefficients when mini-batch size at 544.</title>
<p>The surface plot was processed by cubic linear interpolation.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g007" ns0:type="simple" />
</fig>
<p><xref ref-type="fig" rid="pone.0222406.g008">Fig 8</xref> shows the reconstructed images of the prosthetic phantom attained with the DnCNN-MARHR algorithm or each established algorithm for reconstruction with MAR processing. Remarkably, DT images produced employing the DnCNN-MARHR algorithm showed decreased metal artifacts in the X-ray sweep direction (i.e., vertical direction), specifically in the prosthetic phantom&#8217;s peripheral regions. On the other hand, images produced with the help of FBP-MAR demonstrated more noise and metal artifacts. Comparison of the difference between DnCNN-MARHR and the conventional algorithm resulted in the smallest VM (<xref ref-type="table" rid="pone.0222406.t002">Table 2</xref>).</p>
<fig id="pone.0222406.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Comparisons among the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm and the traditional reconstruction algorithms with metal artifact reduction (MAR) processing in the in-focus plane.</title>
<p>(DnCNN-MARHR (a), 0.8029&#8211;0.9119; DEMDRA (b), 0.9597&#8211;0.9914; dual-energy virtual monochromatic [VM]-MAR [140 keV] (c), 0.9487&#8211;0.9934; maximum likelihood expectation maximization [MLEM]-MAR [70 kV] (d), 0.9411&#8211;0.9983; filtered back projection [FBP, kernel: Shepp &amp; Logan]-MAR [70 kV] (e), 0.5676&#8211;0.6117; simultaneous algebraic reconstruction technique-total variation [SART-TV]-MAR [140 kV] (f), 0.7577&#8211;0.8184, difference between DnCNN-MARHR and DEMDRA (g), 0&#8211;0.1047; difference between DnCNN-MARHR and [VM]-MAR [140 keV] (h), 0&#8211;0.1047; difference between DnCNN-MARHR and [MLEM]-MAR [70 kV] (i), 0&#8211;0.1047; difference between DnCNN-MARHR and [SART-TV]-MAR [140 kV] (j), 0&#8211;0.1047; difference between DnCNN-MARHR and [FBP, kernel: Shepp &amp; Logan]-MAR [70 kV] (k), 0&#8211;0.1047) The display variety of the prosthetic phantom is changed to make visual comparison of the contrast and background gray levels. The X-ray source is moved along the image vertically. In the displayed areas, the artifact indices are determined.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g008" ns0:type="simple" />
</fig>
<table-wrap id="pone.0222406.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.t002</object-id>
<label>Table 2</label> <caption><title>Mean square error (MSE) between each reconstruction algorithm.</title></caption>
<alternatives>
<graphic id="pone.0222406.t002g" mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.t002" ns0:type="simple" />
<table>
<colgroup>
<col align="left" valign="middle" />
<col align="left" valign="middle" />
</colgroup>
<thead>
<tr>
<th align="left" />
<th align="center">MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><bold>DnCNN-MARHR between DEMDRA</bold></td>
<td align="center">3.8048e-05</td>
</tr>
<tr>
<td align="left"><bold>DnCNN-MARHR between VM with MAR(140keV)</bold></td>
<td align="center">3.5683e-05</td>
</tr>
<tr>
<td align="left"><bold>DnCNN-MARHR between MLEM with MAR(70kV)</bold></td>
<td align="center">3.7185e-04</td>
</tr>
<tr>
<td align="left"><bold>DnCNN-MARHR between SART-TV with MAR(140kV)</bold></td>
<td align="center">9.6985e-05</td>
</tr>
<tr>
<td align="left"><bold>DnCNN-MARHR between FBP with MAR(70kV)</bold></td>
<td align="center">1.0318e-04</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Results of the comparison of the mean square error (MSE) between the DnCNN-MARHR image and each MAR image. (Comparison image is in-focus plane).</p></fn>
</table-wrap-foot>
</table-wrap>
<p><xref ref-type="fig" rid="pone.0222406.g009">Fig 9</xref> shows the positioning of the ROI in the prosthetic phantom and a graph of the AI results. The DEMDRA gave rise to the smallest values of metal artifact characteristics, irrespective of the status of MAR processing (mean AI &#177; standard error, 0.01426 &#177; 0.0022). The difference in AI values between the DnCNN-MARHR algorithm and DEMDRA was small, and the value was lower than that for VM (140 keV) used as a reference image in the training network, confirming the usefulness of MAR (DnCNN-MARHR, 0.01557 &#177; 0.0017; VM-MAR, 0.01794 &#177; 0.0025). Metal artifact production was dependent on the reconstruction algorithm type for polychromatic imaging algorithms using MAR processing (MLEM-MAR [70 kV], 0.0195 &#177; 0.0033; SART-TV-MAR [140 kV], 0.0207 &#177; 0.0029; FBP-MAR [70 kV], 0.0333 &#177; 0.0069).</p>
<fig id="pone.0222406.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Comparisons of the artifact indices (AIs) determined for in-focus plane images procured via the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm and the traditional reconstruction algorithms with metal artifact reduction (MAR) processing.</title>
<p>Metal artifacts originated from the AIs of 10 selected metal artifact areas (features) and one background area are presented in the in-focus plane. The results are mean &#177; standard error.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g009" ns0:type="simple" />
</fig>
<p><xref ref-type="fig" rid="pone.0222406.g010">Fig 10</xref> shows a plot of the ASF results and the ROI in the prosthetic phantom. The DnCNN-MARHR algorithm produced the maximum decrease in metal artifacts. However, the FBP-MAR (70 kV) algorithm gave rise to elevated metal artifacts. The DEMDRA, VM-MAR (140 keV), MLEM-MAR (70 kV), and SART-TV-MAR (140 kV) algorithms did not produce any significant alterations in the artifact level.</p>
<fig id="pone.0222406.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g010</object-id>
<label>Fig 10</label>
<caption>
<title>ROI setting diagram and ASF calculation result for ASF.</title>
<p>(Figure) Metal artifacts derived using the artifact spread function (ASF) of the selected features. The in-focus plane image displays the metal artifact and background areas of the measurements of ASF. (Chart) Plots of the ASF vs. the slice numbers from the in-focus planes of the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm and the conventional reconstruction algorithms with metal artifact reduction (MAR) processing.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g010" ns0:type="simple" />
</fig>
<p><xref ref-type="fig" rid="pone.0222406.g011">Fig 11</xref> shows the GLCM calculated using texture analysis with comparison of the feature quantities of &#8220;inverse difference moment (homogeneity)&#8221; and &#8220;contrast (dissimilarity)&#8221; and presents the results. The DnCNN-MARHR algorithm showed the best performance regarding the low noise variation image and homogeneous image in the texture analysis (inverse difference moment: DnCNN-MARHR, 0.965; DEMDRA, 0.952; VM-MAR [140 keV], 0.958; MLEM-MAR [70 kV], 0.955; FBP-MAR [70 kV], 0.905; SART-TV-MAR [140 kV], 0.955; and contrast: DnCNN-MARHR, 0.070; DEMDRA, 0.099; VM-MAR [140 keV], 0.085; MLEM-MAR [70 kV], 0.097; FBP-MAR [70 kV], 0.315; SART-TV-MAR [140 kV], 0.104). For the whole image, the measure of the &#8220;correlation&#8221; between a pixel and the neighboring area was as follows: DnCNN-MARHR, 0.993; DEMDRA, 0.992; VM-MAR (140 keV), 0.993; MLEM-MAR (70 kV), 0.992; FBP-MAR (70 kV), 0.926; SART-TV-MAR (140 kV), 0.990.</p>
<fig id="pone.0222406.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0222406.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Texture analysis results.</title>
<p>Comparisons of the inverse different moment (homogeneity) (a) and contrast (dissimilarity) (b) of in-focus plane images obtained via the denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm and the conventional reconstruction algorithms with metal artifact reduction (MAR) processing.</p>
</caption>
<graphic mimetype="image" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.g011" ns0:type="simple" />
</fig>
<p>Training was implemented by MATLAB on two CPU (Intel(R) Xeon(R) E5-2620 v4, 2.10GHz) and one GPU (NVIDIA Tesla K40c, 12GB) systems. The network required approximately 15 h for training. The reconstruction time was approximately 30 minutes for DnCNN-MARHR (not included in the training network) and DEMDRA approximately 20 minutes for MLEM and SART-TV, and approximately 2 minutes for FBP.</p>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion and conclusions</title>
<p>In the present prosthetic phantom study, we compared our DnCNN-MARHR algorithm and different traditional DT reconstruction algorithms without and with MAR processing.</p>
<p>We found that our newly developed DnCNN using the training network algorithm DnCNN-MARHR had adequate overall performance. The DnCNN-MARHR images showed better results that are unaffected by the metal type present in the prosthetic phantom. In addition, this algorithm was efficient in getting rid-off the noise artifacts from images, specifically at higher distances from metal objects. Especially, this algorithm was principally useful for decreasing artifacts related to out-of-plane effects on objects causing artifacts in the focus plane. This algorithm might be a favorable new choice for prostheses imaging, as it yielded 3D visualizations in images with reduced artifacts that were much better than those in images processed employing traditional algorithms. In this DnCNN-MARHR algorithm, the versatility of selecting the imaging parameters, that is dependent on the required final images and conditions of prosthetic imaging, might be useful to users. Regarding the success or failure of our proposed method, when it is applied in other cases, the key points are the accuracy involved in the VM X-ray process and the method of extraction of the residual image during learning with high accuracy. For example, an effective MAR may not be expected in cases where normal tissues and artificial bones have a complicated arrangement relation.</p>
<p>The proposed DnCNN method should help find a suitable correction map <italic>q</italic>:<italic>P</italic><sub><italic>L</italic></sub>&#8614;<italic>Img</italic><sub>&#8722;Re<italic>s</italic></sub> for MAR in such a way that <italic>U</italic>(<italic>P</italic><sub><italic>L</italic></sub>)&#8776;<italic>Img</italic><sub>&#8722;Re<italic>s</italic></sub>, where <italic>P</italic><sub><italic>L</italic></sub> is the attenuation distribution at fixed energy <italic>L</italic> [<xref ref-type="bibr" rid="pone.0222406.ref019">19</xref>]. The map <italic>q</italic> should consider <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub>, as <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub> is considered as prior information of DT projection images. Therefore, <italic>q</italic>(<italic>P</italic><sub><italic>L</italic></sub>) should be ascertained by not only <italic>P</italic><sub><italic>L</italic></sub> but also <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub>. Owing to the highly nonlinear and complicated structure of <italic>VM</italic><sub>&#8722;<italic>p</italic>&#8722;<italic>img</italic></sub>, it could be quite difficult to determine <italic>q</italic> without using DnCNN methods.</p>
<p>With regard to the DnCNN step, the strength is fusion of helpful facts from various sources to prevent profound artifacts, whereas the limitation is that not all artifacts can be removed, with mild artifacts typically remaining [<xref ref-type="bibr" rid="pone.0222406.ref023">23</xref>]. With regard to adaptive filtering processing in prior image-based MAR methods, moderate artifacts can be removed and a satisfactory prior image can be generated. The success of adaptive filtering processing needs to still be established by imaging, and any noticed artifacts might be due to the absence of the high level normal contributions of artifact-free voxels. Even though, normal contributions are initially made by these voxels, their values decline slightly after removing the largest normal contribution. This means, for each voxel, there will be a rejection of one contribution that is abnormal, while the remaining contributions, along with the largest normal contribution, will be used. Thus, artifact-containing voxels are likely to have elevated values than the surrounding artifact-free voxels. However, when there are major artifacts, the prior image generally suffers from tissue misclassification. By combining the adaptive filtering processing with DnCNN, only with fewer epochs DnCNN training can be stopped, and the procured prior DnCNN is not influenced by tissue misclassification (<xref ref-type="fig" rid="pone.0222406.g011">Fig 11</xref>).</p>
<p>The following two factors are important to ascertain exceptional performance of the DnCNN-MARHR algorithm: choosing the right MAR method and training data preparation. Sufficient data for the DnCNN to discriminate artifacts from tissue structures is provided by the appropriately selected MAR method. The preparation of training data ascertains general application of the trained DnCNN by including as many types of metal artifacts as feasible. Thus, it can be considered that the effect of MAR was useful in the longitudinal direction (<xref ref-type="fig" rid="pone.0222406.g010">Fig 10</xref>).</p>
<p>TV minimization supposes that a true image is relatively uniform and piece wise. These TV minimization approaches can effectively prevent inadmissible solutions [<xref ref-type="bibr" rid="pone.0222406.ref024">24</xref>], but noise and artifacts appear as deviations or valleys and peaks, which will have comparatively larger TV values since TV is described as the sum of the first-order derivative magnitudes [<xref ref-type="bibr" rid="pone.0222406.ref013">13</xref>], and therefore, their applicability is limited to computed clinical imaging. The DnCNN has the capability to learn nonlinear regression for different sources of artifacts, because it efficiently employs complicated prior knowledge of artifacts and DT images.</p>
<p>In the AI analysis, metal artifacts showed almost an equal MAR effect as the conventional DEMDRA. The SGDM method employed in the DnCNN-MARHR algorithm uses a subset of the training set (mini-batch) to evaluate gradients and update parameters. In general, the DnCNN (or CNN) is usually trained iteratively using multiple image batches, and it is possible to speed up learning without losing accuracy by increasing the mini-batch size. It is considered that reduction of high-frequency metal artifacts cannot be significantly improved owing to the influence of the decomposition/restoration process accompanying the mini-batch and the convolution processing.</p>
<p>Wolterink et al. [<xref ref-type="bibr" rid="pone.0222406.ref022">22</xref>] report that they were useful for noise reduction by using CNN based generative adversarial networks (GAN) in low-dose CT. The results demonstrate that training with adversarial feedback from a discriminator CNN can produce images that resemble more in appearance to the normal-dose CT than training in the absence of a discriminator CNN [<xref ref-type="bibr" rid="pone.0222406.ref022">22</xref>]. A similar trend was found in our results this time. We think that feedback from avoids smoothing in the image and permits quantification of including metal artifacts objects in DT scans, more accurately.</p>
<p>Our DnCNN-MARHR algorithm has some limitations. First, the algorithm does not take into account metal artifacts that come from photon starvation. The functioning of the learning-based projection data correction method could be perfected by improving the forward model, which precisely represents different realistic artifacts. Second, the suggested learning model is intended for a particular type of phantom implant and it does not work efficiently when the trained network is adapted to projection data correction from totally different scanning geometries. Future studies is required to develop a learning model, which can be used in general cases.</p>
<p>We successfully developed a DnCNN-based algorithm for MAR in DT for arthroplasty. Our DnCNN-MARHR algorithm is particularly useful for reducing artifacts associated with out-of-plane effects on artifact-causing objects in the focus plane, and it is not affected by tissue misclassification.</p>
</sec>
</body>
<back>
<ack>
<p>We wish to thank Mr. Kazuaki Suwa and Yuuki Watanabe at Department of Radiology Dokkyo Medical University Koshigaya Hospital for support on experiment.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0222406.ref001"><label>1</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Tang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Guo</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Digital tomosynthesis with metal artifact reduction for assessing cementless hip arthroplasty: a diagnostic cohort study of 48 patients</article-title>. <source>Skeletal Radiol</source>. <year>2016</year>;<volume>45</volume>(<issue>11</issue>):<fpage>1523</fpage>&#8211;<lpage>32</lpage>. Epub 2016/09/04. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s00256-016-2466-8" ns0:type="simple">10.1007/s00256-016-2466-8</ext-link></comment> <object-id pub-id-type="pmid">27589968</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref002"><label>2</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gothlin</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Geijer</surname> <given-names>M</given-names></name>. <article-title>The utility of digital linear tomosynthesis imaging of total hip joint arthroplasty with suspicion of loosening: a prospective study in 40 patients</article-title>. <source>Biomed Res Int</source>. <year>2013</year>;<volume>2013</volume>:<fpage>594631</fpage>. Epub 2013/10/01. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1155/2013/594631" ns0:type="simple">10.1155/2013/594631</ext-link></comment> <object-id pub-id-type="pmid">24078921</object-id>; PubMed Central PMCID: PMC3776365.</mixed-citation></ref>
<ref id="pone.0222406.ref003"><label>3</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Machida</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Yuhara</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Mori</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ueno</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Moribe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Sabol</surname> <given-names>JM</given-names></name>. <article-title>Optimizing parameters for flat-panel detector digital tomosynthesis</article-title>. <source>Radiographics</source>. <year>2010</year>;<volume>30</volume>(<issue>2</issue>):<fpage>549</fpage>&#8211;<lpage>62</lpage>. Epub 2010/03/17. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1148/rg.302095097" ns0:type="simple">10.1148/rg.302095097</ext-link></comment> <object-id pub-id-type="pmid">20228334</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref004"><label>4</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Duryea</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dobbins</surname> <given-names>JT</given-names> <suffix>3rd</suffix></name>, <name name-style="western"><surname>Lynch</surname> <given-names>JA</given-names></name>. <article-title>Digital tomosynthesis of hand joints for arthritis assessment</article-title>. <source>Med Phys</source>. <year>2003</year>;<volume>30</volume>(<issue>3</issue>):<fpage>325</fpage>&#8211;<lpage>33</lpage>. Epub 2003/04/04. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1118/1.1543573" ns0:type="simple">10.1118/1.1543573</ext-link></comment> <object-id pub-id-type="pmid">12674232</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref005"><label>5</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Dobbins</surname> <given-names>JT</given-names> <suffix>3rd</suffix></name>, <name name-style="western"><surname>Godfrey</surname> <given-names>DJ</given-names></name>. <article-title>Digital x-ray tomosynthesis: current state of the art and clinical potential</article-title>. <source>Phys Med Biol</source>. <year>2003</year>;<volume>48</volume>(<issue>19</issue>):<fpage>R65</fpage>&#8211;<lpage>106</lpage>. Epub 2003/10/29. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1088/0031-9155/48/19/r01" ns0:type="simple">10.1088/0031-9155/48/19/r01</ext-link></comment> <object-id pub-id-type="pmid">14579853</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref006"><label>6</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gomi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hirano</surname> <given-names>H</given-names></name>. <article-title>Clinical potential of digital linear tomosynthesis imaging of total joint arthroplasty</article-title>. <source>J Digit Imaging</source>. <year>2008</year>;<volume>21</volume>(<issue>3</issue>):<fpage>312</fpage>&#8211;<lpage>22</lpage>. Epub 2007/06/09. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s10278-007-9040-9" ns0:type="simple">10.1007/s10278-007-9040-9</ext-link></comment> <object-id pub-id-type="pmid">17557182</object-id>; PubMed Central PMCID: PMC3043838.</mixed-citation></ref>
<ref id="pone.0222406.ref007"><label>7</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gomi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sakai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Goto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Takeda</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Umeda</surname> <given-names>T</given-names></name>. <article-title>Comparison of Reconstruction Algorithms for Decreasing the Exposure Dose During Digital Tomosynthesis for Arthroplasty: a Phantom Study</article-title>. <source>J Digit Imaging</source>. <year>2016</year>;<volume>29</volume>(<issue>4</issue>):<fpage>488</fpage>&#8211;<lpage>95</lpage>. Epub 2016/03/05. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s10278-016-9876-y" ns0:type="simple">10.1007/s10278-016-9876-y</ext-link></comment> <object-id pub-id-type="pmid">26943661</object-id>; PubMed Central PMCID: PMC4942396.</mixed-citation></ref>
<ref id="pone.0222406.ref008"><label>8</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Becker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Martini</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Higashigaito</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Guggenberger</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Andreisek</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Frauenfelder</surname> <given-names>T</given-names></name>. <article-title>Dose Reduction in Tomosynthesis of the Wrist</article-title>. <source>AJR Am J Roentgenol</source>. <year>2017</year>;<volume>208</volume>(<issue>1</issue>):<fpage>159</fpage>&#8211;<lpage>64</lpage>. Epub 2016/10/21. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2214/AJR.16.16729" ns0:type="simple">10.2214/AJR.16.16729</ext-link></comment> <object-id pub-id-type="pmid">27762599</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref009"><label>9</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gomi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sakai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Goto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Umeda</surname> <given-names>T</given-names></name>. <article-title>Evaluation of digital tomosynthesis reconstruction algorithms used to reduce metal artifacts for arthroplasty: A phantom study</article-title>. <source>Phys Med</source>. <year>2017</year>;<volume>42</volume>:<fpage>28</fpage>&#8211;<lpage>38</lpage>. Epub 2017/11/28. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.ejmp.2017.07.023" ns0:type="simple">10.1016/j.ejmp.2017.07.023</ext-link></comment> <object-id pub-id-type="pmid">29173918</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref010"><label>10</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Candes</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Romberg</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tao</surname> <given-names>T</given-names></name>. <article-title>Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information</article-title>. <source>IEEE Trans Inf Theory</source>. <year>2006</year>;<volume>52</volume>:<fpage>489</fpage>&#8211;<lpage>509</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TIT.2005.862083" ns0:type="simple">10.1109/TIT.2005.862083</ext-link></comment></mixed-citation></ref>
<ref id="pone.0222406.ref011"><label>11</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Sidky</surname> <given-names>EY</given-names></name>, <name name-style="western"><surname>Pan</surname> <given-names>X</given-names></name>. <article-title>Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization</article-title>. <source>Phys Med Biol</source>. <year>2008</year>;<volume>53</volume>(<issue>17</issue>):<fpage>4777</fpage>&#8211;<lpage>807</lpage>. Epub 2008/08/15. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1088/0031-9155/53/17/021" ns0:type="simple">10.1088/0031-9155/53/17/021</ext-link></comment> <object-id pub-id-type="pmid">18701771</object-id>; PubMed Central PMCID: PMC2630711.</mixed-citation></ref>
<ref id="pone.0222406.ref012"><label>12</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Aharon</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Elad</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rruckstein</surname> <given-names>A</given-names></name>. <article-title>A K-SVD an algorithm for denoising overcomplete dictionaries for sparse representation</article-title>. <source>IEEE Trans Signal Process</source>. <year>2006</year>;<volume>54</volume>:<fpage>4311</fpage>&#8211;<lpage>22</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TSP.2006.881199" ns0:type="simple">10.1109/TSP.2006.881199</ext-link></comment></mixed-citation></ref>
<ref id="pone.0222406.ref013"><label>13</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Du</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Xiang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Wei</surname> <given-names>Z</given-names></name>. <article-title>Evaluation of hybrid SART + OS + TV iterative reconstruction algorithm for optical-CT gel dosimeter imaging</article-title>. <source>Phys Med Biol</source>. <year>2016</year>;<volume>61</volume>(<issue>24</issue>):<fpage>8425</fpage>&#8211;<lpage>39</lpage>. Epub 2016/11/16. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1088/0031-9155/61/24/8425" ns0:type="simple">10.1088/0031-9155/61/24/8425</ext-link></comment> <object-id pub-id-type="pmid">27845916</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref014"><label>14</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Wu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Rafferty</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Kopans</surname> <given-names>DB</given-names></name>. <article-title>A comparison of reconstruction algorithms for breast tomosynthesis</article-title>. <source>Med Phys</source>. <year>2004</year>;<volume>31</volume>(<issue>9</issue>):<fpage>2636</fpage>&#8211;<lpage>47</lpage>. Epub 2004/10/19. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1118/1.1786692" ns0:type="simple">10.1118/1.1786692</ext-link></comment> <object-id pub-id-type="pmid">15487747</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref015"><label>15</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gomi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hirano</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Umeda</surname> <given-names>T</given-names></name>. <article-title>Evaluation of the X-ray digital linear tomosynthesis reconstruction processing method for metal artifact reduction</article-title>. <source>Comput Med Imaging Graph</source>. <year>2009</year>;<volume>33</volume>(<issue>4</issue>):<fpage>267</fpage>&#8211;<lpage>74</lpage>. Epub 2009/02/25. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.compmedimag.2009.01.004" ns0:type="simple">10.1016/j.compmedimag.2009.01.004</ext-link></comment> <object-id pub-id-type="pmid">19237263</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref016"><label>16</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Gomi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sakai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Goto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>Y</given-names></name>. <article-title>Development of a novel algorithm for metal artifact reduction in digital tomosynthesis using projection-based dual-energy material decomposition for arthroplasty: A phantom study</article-title>. <source>Phys Med</source>. <year>2018</year>;<volume>53</volume>:<fpage>4</fpage>&#8211;<lpage>16</lpage>. Epub 2018/09/23. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.ejmp.2018.07.011" ns0:type="simple">10.1016/j.ejmp.2018.07.011</ext-link></comment> <object-id pub-id-type="pmid">30241753</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref017"><label>17</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Wellenberg</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Boomsma</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>van Osch</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Vlassenbroek</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Milles</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Edens</surname> <given-names>MA</given-names></name>, <etal>et al</etal>. <article-title>Low-dose CT imaging of a total hip arthroplasty phantom using model-based iterative reconstruction and orthopedic metal artifact reduction</article-title>. <source>Skeletal Radiol</source>. <year>2017</year>;<volume>46</volume>(<issue>5</issue>):<fpage>623</fpage>&#8211;<lpage>32</lpage>. Epub 2017/02/17. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1007/s00256-017-2580-2" ns0:type="simple">10.1007/s00256-017-2580-2</ext-link></comment> <object-id pub-id-type="pmid">28204857</object-id>; PubMed Central PMCID: PMC5355502.</mixed-citation></ref>
<ref id="pone.0222406.ref018"><label>18</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Funama</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Taguchi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Utsunomiya</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Oda</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hirata</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yuki</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>A newly-developed metal artifact reduction algorithm improves the visibility of oral cavity lesions on 320-MDCT volume scans</article-title>. <source>Phys Med</source>. <year>2015</year>;<volume>31</volume>(<issue>1</issue>):<fpage>66</fpage>&#8211;<lpage>71</lpage>. Epub 2014/12/03. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.ejmp.2014.10.003" ns0:type="simple">10.1016/j.ejmp.2014.10.003</ext-link></comment> <object-id pub-id-type="pmid">25455439</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref019"><label>19</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Zuo</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Meng</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>L</given-names></name>. <article-title>Beyond a gauaaian denoiser: residual learning of deep CNN for image denoising</article-title>. <source>IEEE Trans Image Process</source>. <year>2017</year>;<volume>26</volume>(<issue>7</issue>):<fpage>3142</fpage>&#8211;<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TIP.2017.2662206" ns0:type="simple">10.1109/TIP.2017.2662206</ext-link></comment> <object-id pub-id-type="pmid">28166495</object-id></mixed-citation></ref>
<ref id="pone.0222406.ref020"><label>20</label><mixed-citation publication-type="other" ns0:type="simple">Yoon Y, Jeon HG, Yoo D, Lee JY, Kweon IS. Learning a deep convolutional network for light-field image super-resolution IEEE international conference on computer vision workshop. 2015:57&#8211;65. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/ICCVW.2015.17" ns0:type="simple">10.1109/ICCVW.2015.17</ext-link></comment></mixed-citation></ref>
<ref id="pone.0222406.ref021"><label>21</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Kalra</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Lin</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Liao</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2017</year>;<volume>36</volume>(<issue>12</issue>):<fpage>2524</fpage>&#8211;<lpage>35</lpage>. Epub 2017/06/18. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TMI.2017.2715284" ns0:type="simple">10.1109/TMI.2017.2715284</ext-link></comment> <object-id pub-id-type="pmid">28622671</object-id>; PubMed Central PMCID: PMC5727581.</mixed-citation></ref>
<ref id="pone.0222406.ref022"><label>22</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Wolterink</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Leiner</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Viergever</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Isgum</surname> <given-names>I</given-names></name>. <article-title>Generative Adversarial Networks for Noise Reduction in Low-Dose CT</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2017</year>;<volume>36</volume>(<issue>12</issue>):<fpage>2536</fpage>&#8211;<lpage>45</lpage>. Epub 2017/06/03. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TMI.2017.2708987" ns0:type="simple">10.1109/TMI.2017.2708987</ext-link></comment> <object-id pub-id-type="pmid">28574346</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref023"><label>23</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>H</given-names></name>. <article-title>Convolutional Neural Network Based Metal Artifact Reduction in X-Ray Computed Tomography</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2018</year>;<volume>37</volume>(<issue>6</issue>):<fpage>1370</fpage>&#8211;<lpage>81</lpage>. Epub 2018/06/06. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TMI.2018.2823083" ns0:type="simple">10.1109/TMI.2018.2823083</ext-link></comment> <object-id pub-id-type="pmid">29870366</object-id>; PubMed Central PMCID: PMC5998663.</mixed-citation></ref>
<ref id="pone.0222406.ref024"><label>24</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Park</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>HP</given-names></name>, <name name-style="western"><surname>Seo</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Chung</surname> <given-names>YE</given-names></name>. <article-title>CT sinogram-consistency learning for metal-induced beam hardening correction</article-title>. <source>Med Phys</source>. <year>2018</year>;<volume>45</volume>(<issue>12</issue>):<fpage>5376</fpage>&#8211;<lpage>84</lpage>. Epub 2018/09/22. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1002/mp.13199" ns0:type="simple">10.1002/mp.13199</ext-link></comment> <object-id pub-id-type="pmid">30238586</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref025"><label>25</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Pessis</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Campagna</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Sverzut</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Bach</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rodallec</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Guerini</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Virtual monochromatic spectral imaging with fast kilovoltage switching: reduction of metal artifacts at CT</article-title>. <source>Radiographics</source>. <year>2013</year>;<volume>33</volume>(<issue>2</issue>):<fpage>573</fpage>&#8211;<lpage>83</lpage>. Epub 2013/03/13. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1148/rg.332125124" ns0:type="simple">10.1148/rg.332125124</ext-link></comment> <object-id pub-id-type="pmid">23479714</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref026"><label>26</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Kuchenbecker</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Faby</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sawall</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lell</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kachelriess</surname> <given-names>M</given-names></name>. <article-title>Dual energy CT: how well can pseudo-monochromatic imaging reduce metal artifacts?</article-title> <source>Med Phys</source>. <year>2015</year>;<volume>42</volume>(<issue>2</issue>):<fpage>1023</fpage>&#8211;<lpage>36</lpage>. Epub 2015/02/06. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1118/1.4905106" ns0:type="simple">10.1118/1.4905106</ext-link></comment> <object-id pub-id-type="pmid">25652515</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref027"><label>27</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Yue</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Fan Rong</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ning</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ai Lian</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ru Xin</surname> <given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Reduction of metal artifacts from unilateral hip arthroplasty on dual-energy CT with metal artifact reduction software</article-title>. <source>Acta Radiol</source>. <year>2018</year>;<volume>59</volume>(<issue>7</issue>):<fpage>853</fpage>&#8211;<lpage>60</lpage>. Epub 2017/09/14. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1177/0284185117731475" ns0:type="simple">10.1177/0284185117731475</ext-link></comment> <object-id pub-id-type="pmid">28899125</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref028"><label>28</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Hegazy</surname> <given-names>MAA</given-names></name>, <name name-style="western"><surname>Eldib</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Hernandez</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cho</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Cho</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SY</given-names></name>. <article-title>Dual-energy-based metal segmentation for metal artifact reduction in dental computed tomography</article-title>. <source>Med Phys</source>. <year>2018</year>;<volume>45</volume>(<issue>2</issue>):<fpage>714</fpage>&#8211;<lpage>24</lpage>. Epub 2017/12/09. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1002/mp.12719" ns0:type="simple">10.1002/mp.12719</ext-link></comment> <object-id pub-id-type="pmid">29220087</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref029"><label>29</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Katsura</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Akahane</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kunimatsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Abe</surname> <given-names>O</given-names></name>. <article-title>Current and Novel Techniques for Metal Artifact Reduction at CT: Practical Guide for Radiologists</article-title>. <source>Radiographics</source>. <year>2018</year>;<volume>38</volume>(<issue>2</issue>):<fpage>450</fpage>&#8211;<lpage>61</lpage>. Epub 2018/03/13. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1148/rg.2018170102" ns0:type="simple">10.1148/rg.2018170102</ext-link></comment> <object-id pub-id-type="pmid">29528826</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref030"><label>30</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Maeda</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Matsumoto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Taniguchi</surname> <given-names>A</given-names></name>. <article-title>Compton-scattering measurement of diagnostic x-ray spectrum using high-resolution Schottky CdTe detector</article-title>. <source>Med Phys</source>. <year>2005</year>;<volume>32</volume>(<issue>6</issue>):<fpage>1542</fpage>&#8211;<lpage>7</lpage>. Epub 2005/07/15. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1118/1.1921647" ns0:type="simple">10.1118/1.1921647</ext-link></comment> <object-id pub-id-type="pmid">16013712</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref031"><label>31</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Alvarez</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Macovski</surname> <given-names>A</given-names></name>. <article-title>Energy-selective reconstructions in X-ray computerized tomography</article-title>. <source>Phys Med Biol</source>. <year>1976</year>;<volume>21</volume>(<issue>5</issue>):<fpage>733</fpage>&#8211;<lpage>44</lpage>. Epub 1976/09/01. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1088/0031-9155/21/5/002" ns0:type="simple">10.1088/0031-9155/21/5/002</ext-link></comment> <object-id pub-id-type="pmid">967922</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref032"><label>32</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Berger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hubbell</surname> <given-names>J</given-names></name>. <article-title>Photon cross sections on a personal computer</article-title>. <source>Gent Radiat Res</source>. <year>1987</year>:<fpage>1</fpage>&#8211;<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.2172/6016002" ns0:type="simple">10.2172/6016002</ext-link></comment></mixed-citation></ref>
<ref id="pone.0222406.ref033"><label>33</label><mixed-citation publication-type="other" ns0:type="simple">Sutskever I, Martens J, Dahl G, Hinton G. On the importance of initialization and momentum in deep learning. Proceedings of the 30th international conference on machine learning. 2013;PMLR 28(3):1139&#8211;47.</mixed-citation></ref>
<ref id="pone.0222406.ref034"><label>34</label><mixed-citation publication-type="other" ns0:type="simple">Ioffe S, Szegedy C. Batch normalization: accelerating deep network training by reducing internal covariate shift. International conference on machine learning. 2015:448&#8211;56.</mixed-citation></ref>
<ref id="pone.0222406.ref035"><label>35</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>. <article-title>Imagenet classification with deep convolutional neural networks</article-title>. <source>Advances in neural information processing systems</source>. <year>2012</year>:<fpage>1097</fpage>&#8211;<lpage>105</lpage>.</mixed-citation></ref>
<ref id="pone.0222406.ref036"><label>36</label><mixed-citation publication-type="other" ns0:type="simple">Chen Y, Yu W, Pock T. On learning optimized reaction diffusion processes for effective image restoration. IEEE Conference on Computer Vision and Pattern Recognition. 2015:5261&#8211;9. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/CVPR.2015.7299163" ns0:type="simple">10.1109/CVPR.2015.7299163</ext-link></comment></mixed-citation></ref>
<ref id="pone.0222406.ref037"><label>37</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Pock</surname> <given-names>T</given-names></name>. <article-title>Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</article-title>. <source>IEEE transactions on Pattern Analysis and Machine Intelligence</source>. <year>2017</year>;<volume>39</volume>(<issue>6</issue>):<fpage>1256</fpage>&#8211;<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TPAMI.2016.2596743" ns0:type="simple">10.1109/TPAMI.2016.2596743</ext-link></comment> <object-id pub-id-type="pmid">27529868</object-id></mixed-citation></ref>
<ref id="pone.0222406.ref038"><label>38</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Qian</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Qin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Qiu</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Metal artifacts reduction using monochromatic images from spectral CT: evaluation of pedicle screws in patients with scoliosis</article-title>. <source>Eur J Radiol</source>. <year>2013</year>;<volume>82</volume>(<issue>8</issue>):<fpage>e360</fpage>&#8211;<lpage>6</lpage>. Epub 2013/03/23. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1016/j.ejrad.2013.02.024" ns0:type="simple">10.1016/j.ejrad.2013.02.024</ext-link></comment> <object-id pub-id-type="pmid">23518146</object-id>.</mixed-citation></ref>
<ref id="pone.0222406.ref039"><label>39</label><mixed-citation publication-type="journal" ns0:type="simple"><name name-style="western"><surname>Haralick</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Shanmugam</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dinstein</surname> <given-names>I</given-names></name>. <article-title>Textural features for image classification</article-title>. <source>IEEE Trans Syst Man Cybern</source>. <year>1973</year>;<volume>SMC-3</volume>(<issue>6</issue>):<fpage>610</fpage>&#8211;<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" ns0:href="https://doi.org/10.1109/TSMC.1973.4309314" ns0:type="simple">10.1109/TSMC.1973.4309314</ext-link></comment></mixed-citation></ref>
</ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pone.0222406.r001" specific-use="decision-letter">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0222406.r001</article-id>
<title-group>
<article-title>Decision Letter 0</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name name-style="western">
<surname>Zeng</surname>
<given-names>Li</given-names>
</name>
<role>Academic Editor</role>
</contrib>
</contrib-group>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Li Zeng</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<related-object document-id="10.1371/journal.pone.0222406" document-id-type="doi" document-type="article" id="rel-obj001" link-type="peer-reviewed-article" />
<custom-meta-group>
<custom-meta>
<meta-name>Submission Version</meta-name>
<meta-value>0</meta-value>
</custom-meta>
</custom-meta-group>
</front-stub>
<body>
<p>
<named-content content-type="letter-date">26 Jul 2019</named-content>
</p>
<p>PONE-D-19-15441</p>
<p>Development of a novel denoising convolutional neural network-based algorithm for metal artifact reduction in digital tomosynthesis for arthroplasty: A phantom study</p>
<p>PLOS ONE</p>
<p>Dear Prof Gomi,</p>
<p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#8217;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
<p>We would appreciate receiving your revised manuscript by Sep 09 2019 11:59PM. When you are ready to submit your revision, log on to <ext-link ext-link-type="uri" ns0:href="https://www.editorialmanager.com/pone/" ns0:type="simple">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
<p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter.</p>
<p>To enhance the reproducibility of your results, we recommend that if applicable you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions see: <ext-link ext-link-type="uri" ns0:href="http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ns0:type="simple">http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link></p>
<p>Please include the following items when submitting your revised manuscript:</p>
<p><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). This letter should be uploaded as separate file and labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. This file should be uploaded as separate file and labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. This file should be uploaded as separate file and labeled 'Manuscript'.</p></list-item></list></p>
<p>Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
<p>We look forward to receiving your revised manuscript.</p>
<p>Kind regards,</p>
<p>Li Zeng</p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
<p>Journal requirements:</p>
<p>When submitting your revision, we need you to address these additional requirements.</p>
<p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p>
<p><ext-link ext-link-type="uri" ns0:href="http://www.journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ns0:type="simple">http://www.journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and <ext-link ext-link-type="uri" ns0:href="http://www.journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ns0:type="simple">http://www.journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link></p>
<p>2. Please ensure that you have fully discussed how the present study advances on your previous work in this area. Please ensure that you discuss how your work relates to, and advances upon, the following publication:</p>
<p>"Development of a novel algorithm for metal artifact reduction in digital tomosynthesis using projection-based dual-energy material decomposition for arthroplasty: A phantom study"</p>
<p><ext-link ext-link-type="uri" ns0:href="https://www.physicamedica.com/article/S1120-1797" ns0:type="simple">https://www.physicamedica.com/article/S1120-1797</ext-link>(18)31136-0/fulltext"</p>
<p>[Note: HTML markup is below. Please do not edit.]</p>
<p>Reviewers' comments:</p>
<p>Reviewer's Responses to Questions</p>
<p><bold>Comments to the Author</bold></p>
<p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
<p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
<p>Reviewer #1: Partly</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>2. Has the statistical analysis been performed appropriately and rigorously? </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
<p>The <ext-link ext-link-type="uri" ns0:href="http://www.plosone.org/static/policies.action#sharing" ns0:type="simple">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: No</p>
<p>**********</p>
<p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
<p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>5. Review Comments to the Author</p>
<p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
<p>Reviewer #1: The authors are developing a novel denoising convolutional neural network metal artifact reduction hybrid</p>
<p>reconstruction (DnCNN-MARHR) algorithm for decreasing metal objects in digital tomosynthesis (DT) for</p>
<p>arthroplasty employing projection data. The DnCNN-MARHR algorithm based on a training network</p>
<p>(mini-batch stochastic gradient descent algorithm with momentum) to estimate residual reference and object</p>
<p>images using projection data and subtract the estimated residual images from the object images, involving hybrid</p>
<p>and subjectively reconstructed image usage (back projection and maximum likelihood expectation maximization.</p>
<p>However, the proposed methodology is not new. The paper simply combines several preexisting and widely available techniques, such as, convolutional neural network, residual learning, mini-batch stochastic gradient descent algorithm, back projection maximum likelihood expectation maximization. In this context, what are the methodological and algorithmic contributions of the work to the research community?</p>
<p>#Comments</p>
<p>1. Over all the paper, I'm not sure the purpose of this paper is denoising or metal artifacts reduction.</p>
<p>2. The structure of the article is very confusing. For instance, the equation of the evaluation criteria (artifact index) is in the</p>
<p>Optimization parameters section and the other two evaluation criterias are in the Evaluation section.</p>
<p>3. The methods section is badly written. Many important aspects in the methodology are left unexplained in the article. The authors state to use low-energy projection image (PL) as input image and VM X-ray image as reference image for training workflow (Page 8, Line 159-160). There is no information on how many total data sets and how may data sets were allocated each to training, validation and testing.</p>
<p>4. It is very confusing in how to generate the reference projection images VM X-ray image? What is the meaning of the Ft, Fw and Ff in equation (5), how to determine the value of Ft, Fw and Ff? And why VM X-ray image can be the reference projection images for traning the DnCNN, there's still artifacts in this image in my opinion.</p>
<p>5. In fig 2, I cannot find the difference between the original image (PL) and artifact reduced projection image (Cor_img) from the DnCNN step. I suggest that the authors can directly use the original image (PL) and the equation (11) to obtain the final MAR image and make a comparison between this MAR image and DnCNN-MARHR image, I think the difference in the image quality between this MAR image and DnCNN-MARHR image is small.</p>
<p>Reviewer #2: The authors proposed a novel denoising convolutional neural network metal artifact reduction hybrid reconstruction (DnCNN-MARHR) algorithm to reduce the metal artifacts in digital tomosynthesis. The proposed method is based on a training network to estimate residual reference and the object images using projection. And then subtract the estimated residual images from the object images to get the artifact reduced projection. At last, the hybrid reconstruction algorithm was used to obtain the reconstructed tomosynthesis image with metal artifact reduction. And the authors executed a phantom study to compare the performance with different methods. Overall, the paper includes extensive work and the comparison studies are very clear. However, there are few limitations and the authors are encouraged to address the following concerns:</p>
<p>1. As far as I know, the material decomposition algorithm using dual-energy imaging technique needs a known material phantom to build the relationship between the projection (attenuation) and the material property in the calibration process. For the testing process, the projection of the unknown object with low and high energy was converted to the basis images with known materials in the projection domain. The virtual monochromatic images (VMIs) are generated by using the basis image and the attenuation coefficient according to the linear relation of the attenuation coefficient combination. Do you use the calibration phantom? Please provide more information on the content.</p>
<p>2. The DnCNN-MARHR algorithm is the major development of the study. And the Eq.(7) is the core to calculate the residual projection image. Please add more explanations or references.</p>
<p>3. The specification of the computing environment? How long does it take for training and testing process? Iteration number of different image reconstruction? The differences in the calculation time cost for DnCNN-MARHR algorithm and other methods.</p>
<p>4. What is the image size of the projection? Does it have any image pre-processing on the projections?</p>
<p>5. DEMDRA has the lowest AI value. Why not use DEMDRA image to be the reference image of the training network?</p>
<p>6. In generally, the metal artifacts could be reduced by increasing tube voltage for 3D X-ray imaging. (M.-J.Lee et al., &#8220;Overcoming artifacts from metallic orthopedic implants at high-field-strength MR imaging and multi-detector CT,&#8221; Radiographics, vol. 27, no. 3, pp. 791&#8211;803, 2007.) Why do you choose the projection with lower tube voltage to be the input image for DnCNN-MARHR algorithm?</p>
<p>7. Do you use any additional filters in the low and high tube voltage? Could you provide the energy spectrum of the low and high tube voltage setting?</p>
<p>8. How do you perform the data acquisition of the dual-energy tomosynthesis imaging? Is the imaging with different image parameters in the sequential process?</p>
<p>9. What is the total slice number of the reconstructed tomosynthesis image? What is the start height of the reconstruction from the detector surface? Where is the focal point during tomosynthesis imaging?</p>
<p>10. Line 313-315 Could you provide 2D AI surface plot with epochs and weighting coefficients when mini-batch size is 544?</p>
<p>11. Line 334-335 In Fig.2, the image of MLEM_DnCNN is the same as the polychromatic MLEM-MAR [70 kV]? And the image of BP_DnCNN is also the same as the polychromatic filtered back projection [FBP] MAR [70 kV]? Why do you combine the image of MLEM_DnCNN and BP_DnCNN? Is it empirical knowledge?</p>
<p>12. Could you provide the schematic diagram to illustrate the relationship of the in-focus plane and the out-of-plane in the Z-axis direction?</p>
<p>13. The execute time of DnCNN-MARHR algorithm (not include the training network)?</p>
<p>14. Line 447-448 the imaging parameters case by case? For the object in the different region or the various kind of object (e.g.: materials,&#8230;), the proposed algorithm could deal with it?</p>
<p>Minor corrections:</p>
<p>1. Line 137-138 Please normalize the expression of units. &#8211;mm &#956;m</p>
<p>2. Line 175-176 Please double check the formula correctness of Eq.(2) and Eq.(3). Does it miss the exponential mark?</p>
<p>3. Line 238 &#8220;Equation (6)&#8221;</p>
<p>4. Line 245 &#8220;Equation (7)&#8221;</p>
<p>**********</p>
<p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" ns0:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ns0:type="simple">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
<p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p>
<p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" ns0:href="https://www.plos.org/privacy-policy" ns0:type="simple">Privacy Policy</ext-link>.</p>
<p>Reviewer #1: No</p>
<p>Reviewer #2: Yes: Chia-Hao Chang</p>
<p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files to be viewed.]</p>
<p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link ext-link-type="uri" ns0:href="https://pacev2.apexcovantage.com/" ns0:type="simple">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <email ns0:type="simple">figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
</body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0222406.r002">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0222406.r002</article-id>
<title-group>
<article-title>Author response to Decision Letter 0</article-title>
</title-group>
<related-object document-id="10.1371/journal.pone.0222406" document-id-type="doi" document-type="peer-reviewed-article" id="rel-obj002" link-type="rebutted-decision-letter" object-id="10.1371/journal.pone.0222406.r001" object-id-type="doi" object-type="decision-letter" />
<custom-meta-group>
<custom-meta>
<meta-name>Submission Version</meta-name>
<meta-value>1</meta-value>
</custom-meta>
</custom-meta-group>
</front-stub>
<body>
<p>
<named-content content-type="author-response-date">19 Aug 2019</named-content>
</p>
<p>Inserted into the revised manuscript (PDF).</p>
<supplementary-material id="pone.0222406.s001" mimetype="application/pdf" position="float" ns0:href="info:doi/10.1371/journal.pone.0222406.s001" ns0:type="simple">
<label>Attachment</label>
<caption>
<p>Submitted filename: <named-content content-type="submitted-filename">rebuttal_letter.pdf</named-content></p>
</caption>
</supplementary-material>
</body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0222406.r003" specific-use="decision-letter">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0222406.r003</article-id>
<title-group>
<article-title>Decision Letter 1</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name name-style="western">
<surname>Zeng</surname>
<given-names>Li</given-names>
</name>
<role>Academic Editor</role>
</contrib>
</contrib-group>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Li Zeng</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<related-object document-id="10.1371/journal.pone.0222406" document-id-type="doi" document-type="article" id="rel-obj003" link-type="peer-reviewed-article" />
<custom-meta-group>
<custom-meta>
<meta-name>Submission Version</meta-name>
<meta-value>1</meta-value>
</custom-meta>
</custom-meta-group>
</front-stub>
<body>
<p>
<named-content content-type="letter-date">29 Aug 2019</named-content>
</p>
<p>[EXSCINDED]</p>
<p>Development of a denoising convolutional neural network-based algorithm for metal artifact reduction in digital tomosynthesis for arthroplasty: A phantom study</p>
<p>PONE-D-19-15441R1</p>
<p>Dear Dr. Gomi,</p>
<p>We are pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it complies with all outstanding technical requirements.</p>
<p>Within one week, you will receive an e-mail containing information on the amendments required prior to publication. When all required modifications have been addressed, you will receive a formal acceptance letter and your manuscript will proceed to our production department and be scheduled for publication.</p>
<p>Shortly after the formal acceptance letter is sent, an invoice for payment will follow. To ensure an efficient production and billing process, please log into Editorial Manager at <ext-link ext-link-type="uri" ns0:href="https://www.editorialmanager.com/pone/" ns0:type="simple">https://www.editorialmanager.com/pone/</ext-link>, click the "Update My Information" link at the top of the page, and update your user information. If you have any billing related questions, please contact our Author Billing department directly at <email ns0:type="simple">authorbilling@plos.org</email>.</p>
<p>If your institution or institutions have a press office, please notify them about your upcoming paper to enable them to help maximize its impact. If they will be preparing press materials for this manuscript, you must inform our press team as soon as possible and no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email ns0:type="simple">onepress@plos.org</email>.</p>
<p>With kind regards,</p>
<p>Li Zeng</p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
<p>Additional Editor Comments (optional):</p>
<p>Reviewers' comments:</p>
<p>Reviewer's Responses to Questions</p>
<p><bold>Comments to the Author</bold></p>
<p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#8220;Comments to the Author&#8221; section, enter your conflict of interest statement in the &#8220;Confidential to Editor&#8221; section, and submit your "Accept" recommendation.</p>
<p>Reviewer #1: All comments have been addressed</p>
<p>Reviewer #2: All comments have been addressed</p>
<p>**********</p>
<p>2. Is the manuscript technically sound, and do the data support the conclusions?</p>
<p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>3. Has the statistical analysis been performed appropriately and rigorously? </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
<p>The <ext-link ext-link-type="uri" ns0:href="http://www.plosone.org/static/policies.action#sharing" ns0:type="simple">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
<p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Yes</p>
<p>**********</p>
<p>6. Review Comments to the Author</p>
<p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
<p>Reviewer #1: (No Response)</p>
<p>Reviewer #2: Thank you for all your efforts to include new figures and add more explanations in the manuscript. The current version is much clearer and well supported with the further information provided. However, I suggest adding some definition of the material fractions(F_t, F_w, F_f), XDTS_EL, XDTS_EH in Equation (5). That would help readers to understand the physical meanings of this equation.</p>
<p>**********</p>
<p>7. PLOS authors have the option to publish the peer review history of their article (<ext-link ext-link-type="uri" ns0:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ns0:type="simple">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
<p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p>
<p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link ext-link-type="uri" ns0:href="https://www.plos.org/privacy-policy" ns0:type="simple">Privacy Policy</ext-link>.</p>
<p>Reviewer #1: No</p>
<p>Reviewer #2: No</p>
</body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0222406.r004" specific-use="acceptance-letter">
<front-stub>
<article-id pub-id-type="doi">10.1371/journal.pone.0222406.r004</article-id>
<title-group>
<article-title>Acceptance letter</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name name-style="western">
<surname>Zeng</surname>
<given-names>Li</given-names>
</name>
<role>Academic Editor</role>
</contrib>
</contrib-group>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Li Zeng</copyright-holder>
<license ns0:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" ns0:href="http://creativecommons.org/licenses/by/4.0/" ns0:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<related-object document-id="10.1371/journal.pone.0222406" document-id-type="doi" document-type="article" id="rel-obj004" link-type="peer-reviewed-article" />
</front-stub>
<body>
<p>
<named-content content-type="letter-date">4 Sep 2019</named-content>
</p>
<p>PONE-D-19-15441R1 </p>
<p>Development of a denoising convolutional neural network-based algorithm for metal artifact reduction in digital tomosynthesis for arthroplasty: A phantom study </p>
<p>Dear Dr. Gomi:</p>
<p>I am pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
<p>If your institution or institutions have a press office, please notify them about your upcoming paper at this point, to enable them to help maximize its impact. If they will be preparing press materials for this manuscript, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email ns0:type="simple">onepress@plos.org</email>.</p>
<p>For any other questions or concerns, please email <email ns0:type="simple">plosone@plos.org</email>. </p>
<p>Thank you for submitting your work to PLOS ONE.</p>
<p>With kind regards,</p>
<p>PLOS ONE Editorial Office Staff</p>
<p>on behalf of</p>
<p>Professor Li Zeng  </p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
</body>
</sub-article>
</article>